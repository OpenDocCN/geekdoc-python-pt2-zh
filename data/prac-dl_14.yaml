- en: '**14'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**14'
- en: EXPERIMENTS WITH CIFAR-10**
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 对CIFAR-10的实验**
- en: '![image](Images/common.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/common.jpg)'
- en: In this chapter, we’ll perform a series of experiments with the CIFAR-10 dataset
    we built in [Chapter 5](ch05.xhtml#ch05). First, we’ll see how two models, one
    shallow, the other deeper, perform on the full dataset. After that, we’ll work
    with grouped subsets of the entire dataset to see if we can tell the difference
    between animals and vehicles. Next, we’ll answer the question of what’s better
    for the CIFAR-10 dataset, a single multiclass model or a set of binary models,
    one per class.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将对我们在[第5章](ch05.xhtml#ch05)中构建的CIFAR-10数据集进行一系列实验。首先，我们将看看两个模型，一个浅层模型，另一个较深的模型，在完整数据集上的表现。之后，我们将使用整个数据集的分组子集，看看能否区分动物和交通工具。接下来，我们将回答一个问题：对于CIFAR-10数据集，是单一的多分类模型更好，还是一组二分类模型，每个类别一个。
- en: We’ll close the chapter by introducing transfer learning and fine-tuning. These
    are important concepts, often confounded, that are widely used in the machine
    learning community, so we should develop an intuitive feel for how they work.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章结束时介绍迁移学习和微调。这些是重要的概念，通常会混淆，且在机器学习社区中广泛使用，因此我们应该培养对它们如何工作的直觉理解。
- en: A CIFAR-10 Refresher
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CIFAR-10复习
- en: Before we dive into the experiments, let’s refamiliarize ourselves with the
    dataset we’re working with. CIFAR-10 is a 10-class dataset from the Canadian Institute
    for Advanced Research (CIFAR). We built this dataset in [Chapter 5](ch05.xhtml#ch05)
    but deferred its use until now. CIFAR-10 consists of 32×32-pixel RGB images of
    animals (six classes) and vehicles (four classes). Take a look at [Figure 5-4](ch05.xhtml#ch5fig4)
    for some sample images. The training set has 50,000 images, 5,000 from each class,
    so it is a balanced dataset. The test set consists of 10,000 images, 1,000 from
    each class. CIFAR-10 is probably the second most widely used standard dataset
    in machine learning after MNIST. There is also a 100-class version, CIFAR-100,
    that we’ll not work with in this book, but you’ll see it pop up often in the literature.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入实验之前，让我们重新熟悉一下我们正在使用的数据集。CIFAR-10是一个来自加拿大高级研究院（CIFAR）的10类数据集。我们在[第5章](ch05.xhtml#ch05)中构建了这个数据集，但直到现在才开始使用它。CIFAR-10包含32×32像素的RGB图像，其中有动物（六个类别）和交通工具（四个类别）。可以查看[图5-4](ch05.xhtml#ch5fig4)来查看一些样本图像。训练集有50,000张图像，每个类别有5,000张，因此它是一个平衡数据集。测试集包含10,000张图像，每个类别有1,000张。CIFAR-10可能是继MNIST之后，机器学习中第二个最广泛使用的标准数据集。还有一个100类版本CIFAR-100，我们在本书中不会使用它，但你会在文献中经常看到它。
- en: As of this writing, the best performing model on unaugmented CIFAR-10 has achieved
    a 1 percent error on the test set ([benchmarks.ai](http://benchmarks.ai)). The
    model that did this has 557 million parameters. Our models will be significantly
    smaller and have a much larger test error. However, this is a true image dataset,
    unlike MNIST, which is very clean and has a uniform black background for every
    digit. Because of the variation in natural images, especially in their backgrounds,
    we might expect models to have a harder time learning the CIFAR-10 classes compared
    to MNIST.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 截至目前，最佳的未经增强的CIFAR-10模型在测试集上的错误率已达1% ([benchmarks.ai](http://benchmarks.ai))。这个模型拥有5.57亿个参数。我们将使用的模型会小得多，且测试误差会大得多。然而，这是一个真实的图像数据集，不像MNIST那样非常干净，并且每个数字的背景都是统一的黑色。由于自然图像，特别是其背景的变化，我们可以预期模型在学习CIFAR-10类时会比在MNIST上更加困难。
- en: 'For reference throughout the chapter, here are CIFAR-10 classes:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章参考的CIFAR-10类别如下：
- en: '| **Label** | **Class** | **Label** | **Class** |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| **标签** | **类别** | **标签** | **类别** |'
- en: '| --- | --- | --- | --- |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 0 | airplane | 5 | dog |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 飞机 | 5 | 狗 |'
- en: '| 1 | automobile | 6 | frog |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 汽车 | 6 | 蛙 |'
- en: '| 2 | bird | 7 | horse |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 鸟 | 7 | 马 |'
- en: '| 3 | cat | 8 | ship |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 猫 | 8 | 船 |'
- en: '| 4 | deer | 9 | truck |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 鹿 | 9 | 卡车 |'
- en: Working with the Full CIFAR-10 Dataset
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用完整的CIFAR-10数据集
- en: Let’s train two different models on the entire CIFAR-10 dataset. The first model
    is the same one we used in [Chapter 13](ch13.xhtml#ch13) for the MNIST dataset.
    We’ll refer to this model as our *shallow model* because it has only two convolutional
    layers. We’ll need to adapt it a touch for the 32 × 32 RGB inputs, but that’s
    straightforward enough to do. The second model, which we’ll call our *deep model*,
    uses multiple convolutional layers before the pooling and fully connected layers.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在整个CIFAR-10数据集上训练两个不同的模型。第一个模型与我们在[第13章](ch13.xhtml#ch13)中用于MNIST数据集的模型相同。我们将这个模型称为*浅层模型*，因为它只有两个卷积层。我们需要稍微调整一下，以适应32
    × 32的RGB输入，但这非常容易实现。第二个模型，我们称之为*深层模型*，在池化层和全连接层之前使用了多个卷积层。
- en: Additionally, we’ll experiment with both stochastic gradient descent and Adadelta
    as our optimization algorithms. We’ll fix the minibatch size at 64 and train for
    60 epochs for a total of 46,875 gradient descent steps. For SGD, we’ll use a learning
    rate of 0.01 and a momentum of 0.9\. Recall, Adadelta is adaptive and alters the
    learning rate on the fly. We can decrease the learning rate for SGD as training
    progresses, but 0.01 is relatively small, and we have a large number of gradient
    descent steps, so we’ll just leave it a constant.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们将尝试使用随机梯度下降（SGD）和Adadelta作为优化算法。我们将批量大小固定为64，并训练60个周期，总共进行46,875次梯度下降步骤。对于SGD，我们将使用学习率0.01和动量0.9。请记住，Adadelta是自适应的，会动态调整学习率。我们可以随着训练的进行降低SGD的学习率，但由于0.01已经比较小，而且梯度下降的步骤很多，所以我们将保持其不变。
- en: The shallow model has 1,626,442 parameters, while the deep model has only 1,139,338\.
    The deep model is deep because it has more layers, but because each convolutional
    layer is using exact convolution, the output decreases by two each time (for a
    3 × 3 kernel). Therefore, the flatten layer after the pooling layer has only 7,744
    values compared to 12,544 for the shallow model. The weight matrix between the
    flatten layer and the dense layer of 128 nodes contains the vast majority of the
    parameters, 7,744 × 128 = 991,232 compared to 12,544 × 128 = 1,605,632\. Thus,
    going deeper has actually reduced the number of parameters to learn. This slightly
    counterintuitive result reminds us of the large expense incurred by fully connected
    layers and some of the initial motivation for the creation of CNNs.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 浅层模型有1,626,442个参数，而深层模型只有1,139,338个。深层模型之所以“深”是因为它有更多的层，但由于每个卷积层使用的是精确卷积，每次输出都会减少2（对于3
    × 3的卷积核）。因此，池化层后的flatten层只有7,744个值，而浅层模型则有12,544个值。flatten层和128节点的全连接层之间的权重矩阵包含了大多数的参数，7,744
    × 128 = 991,232，而浅层模型为12,544 × 128 = 1,605,632。因此，增加层数实际上减少了需要学习的参数数量。这个略显反直觉的结果提醒我们，全连接层的开销很大，这也是卷积神经网络（CNN）最初被提出的动机之一。
- en: Building the Models
  id: totrans-20
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 构建模型
- en: You’ll find the code for the shallow model in *cifar10_cnn.py* (Adadelta) and
    *cifar10_cnn_SGD.py* (SGD). We’ll work through the code in pieces. The shallow
    model starts in much the same way as for the MNIST dataset, as shown in [Listing
    14-1](ch14.xhtml#ch14lis1).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在*cifar10_cnn.py*（Adadelta）和*cifar10_cnn_SGD.py*（SGD）中找到浅层模型的代码。我们将分步讲解这些代码。浅层模型的构建方式与MNIST数据集的方式类似，如[Listing
    14-1](ch14.xhtml#ch14lis1)所示。
- en: import keras
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: import keras
- en: from keras.models import Sequential
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: from keras.models import Sequential
- en: from keras.layers import Dense, Dropout, Flatten
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: from keras.layers import Dense, Dropout, Flatten
- en: from keras.layers import Conv2D, MaxPooling2D
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: from keras.layers import Conv2D, MaxPooling2D
- en: from keras import backend as K
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: from keras import backend as K
- en: import numpy as np
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: import numpy as np
- en: batch_size = 64
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: batch_size = 64
- en: num_classes = 10
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: num_classes = 10
- en: epochs = 60
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: epochs = 60
- en: img_rows, img_cols = 32, 32
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: img_rows, img_cols = 32, 32
- en: x_train = np.load("cifar10_train_images.npy")
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: x_train = np.load("cifar10_train_images.npy")
- en: y_train = np.load("cifar10_train_labels.npy")
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: y_train = np.load("cifar10_train_labels.npy")
- en: x_test = np.load("cifar10_test_images.npy")
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: x_test = np.load("cifar10_test_images.npy")
- en: y_test = np.load("cifar10_test_labels.npy")
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: y_test = np.load("cifar10_test_labels.npy")
- en: 'if K.image_data_format() == ''channels_first'':'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 K.image_data_format() == 'channels_first'：
- en: x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)
- en: x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)
- en: input_shape = (3, img_rows, img_cols)
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: input_shape = (3, img_rows, img_cols)
- en: 'else:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 否则：
- en: x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)
- en: x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)
- en: input_shape = (img_rows, img_cols, 3)
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: input_shape = (img_rows, img_cols, 3)
- en: x_train = x_train.astype('float32')
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: x_train = x_train.astype('float32')
- en: x_test = x_test.astype('float32')
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: x_test = x_test.astype('float32')
- en: (*\newpage*)
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: (*\newpage*)
- en: x_train /= 255
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: x_train /= 255
- en: x_test /= 255
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: x_test /= 255
- en: y_train = keras.utils.to_categorical(y_train, num_classes)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: y_train = keras.utils.to_categorical(y_train, num_classes)
- en: y_test = keras.utils.to_categorical(y_test, num_classes)
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: y_test = keras.utils.to_categorical(y_test, num_classes)
- en: '*Listing 14-1: Preparing the CIFAR-10 dataset*'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '*Listing 14-1: 准备 CIFAR-10 数据集*'
- en: We import the necessary modules and load the CIFAR-10 dataset from the NumPy
    files we created in [Chapter 5](ch05.xhtml#ch05). Notice that the image dimensions
    are now 32 × 32, not 28 × 28, and that the number of channels is 3 (RGB) instead
    of 1 (grayscale). As before, we scale the inputs by 255 to map the images to [0,1]
    and convert the label numbers to one-hot vectors using `to_categorical`.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们导入必要的模块，并从 [第5章](ch05.xhtml#ch05) 中创建的 NumPy 文件加载 CIFAR-10 数据集。注意，图像的尺寸现在是
    32 × 32，而不是 28 × 28，并且通道数是 3（RGB），而不是 1（灰度）。像之前一样，我们将输入数据缩放为 255，以将图像映射到 [0,1]，并使用
    `to_categorical` 将标签数字转换为 one-hot 向量。
- en: Next, we define the model architecture ([Listing 14-2](ch14.xhtml#ch14lis2)).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们定义模型架构（[Listing 14-2](ch14.xhtml#ch14lis2)）。
- en: model = Sequential()
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: model = Sequential()
- en: model.add(Conv2D(32, kernel_size=(3, 3),
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: model.add(Conv2D(32, kernel_size=(3, 3),
- en: activation='relu',
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: activation='relu',
- en: input_shape=input_shape))
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: input_shape=input_shape))
- en: model.add(Conv2D(64, (3, 3), activation='relu'))
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: model.add(Conv2D(64, (3, 3), activation='relu'))
- en: model.add(MaxPooling2D(pool_size=(2, 2)))
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: model.add(MaxPooling2D(pool_size=(2, 2)))
- en: model.add(Dropout(0.25))
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: model.add(Dropout(0.25))
- en: model.add(Flatten())
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: model.add(Flatten())
- en: model.add(Dense(128, activation='relu'))
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: model.add(Dense(128, activation='relu'))
- en: model.add(Dropout(0.5))
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: model.add(Dropout(0.5))
- en: model.add(Dense(num_classes, activation='softmax'))
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: model.add(Dense(num_classes, activation='softmax'))
- en: model.compile(loss=keras.losses.categorical_crossentropy,
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: model.compile(loss=keras.losses.categorical_crossentropy,
- en: optimizer=keras.optimizers.Adadelta(),
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: optimizer=keras.optimizers.Adadelta(),
- en: metrics=['accuracy'])
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: metrics=['accuracy'])
- en: '*Listing 14-2: Building the shallow CIFAR-10 model*'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '*Listing 14-2: 构建浅层 CIFAR-10 模型*'
- en: This step is identical to the MNIST version for the shallow model (see [Listing
    13-1](ch13.xhtml#ch13lis1)). For the deep model, we add more convolutional layers,
    as shown in [Listing 14-3](ch14.xhtml#ch14lis3).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这一步与浅层模型的 MNIST 版本相同（参见 [Listing 13-1](ch13.xhtml#ch13lis1)）。对于深度模型，我们添加了更多的卷积层，如
    [Listing 14-3](ch14.xhtml#ch14lis3) 中所示。
- en: model = Sequential()
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: model = Sequential()
- en: model.add(Conv2D(32, kernel_size=(3, 3),
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: model.add(Conv2D(32, kernel_size=(3, 3),
- en: activation='relu',
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: activation='relu',
- en: input_shape=input_shape))
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: input_shape=input_shape))
- en: model.add(Conv2D(64, (3,3), activation='relu'))
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: model.add(Conv2D(64, (3,3), activation='relu'))
- en: model.add(Conv2D(64, (3,3), activation='relu'))
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: model.add(Conv2D(64, (3,3), activation='relu'))
- en: model.add(Conv2D(64, (3,3), activation='relu'))
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: model.add(Conv2D(64, (3,3), activation='relu'))
- en: model.add(Conv2D(64, (3,3), activation='relu'))
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: model.add(Conv2D(64, (3,3), activation='relu'))
- en: model.add(MaxPooling2D(pool_size=(2,2)))
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: model.add(MaxPooling2D(pool_size=(2,2)))
- en: model.add(Dropout(0.25))
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: model.add(Dropout(0.25))
- en: model.add(Flatten())
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: model.add(Flatten())
- en: model.add(Dense(128, activation='relu'))
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: model.add(Dense(128, activation='relu'))
- en: model.add(Dropout(0.5))
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: model.add(Dropout(0.5))
- en: model.add(Dense(128, activation='relu'))
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: model.add(Dense(128, activation='relu'))
- en: model.add(Dropout(0.5))
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: model.add(Dropout(0.5))
- en: model.add(Dense(num_classes, activation='softmax'))
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: model.add(Dense(num_classes, activation='softmax'))
- en: model.compile(loss=keras.losses.categorical_crossentropy,
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: model.compile(loss=keras.losses.categorical_crossentropy,
- en: optimizer=keras.optimizers.Adadelta(),
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: optimizer=keras.optimizers.Adadelta(),
- en: metrics=['accuracy'])
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: metrics=['accuracy'])
- en: '*Listing 14-3: Building the deep CIFAR-10 model*'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '*Listing 14-3: 构建深度 CIFAR-10 模型*'
- en: The extra convolutional layers give the model the opportunity to learn a better
    representation of the input data, which for CIFAR-10 is more complex than the
    simple MNIST images. The representation might be better because a deeper network
    can learn more abstract representations that encompass larger structures in the
    inputs.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 额外的卷积层为模型提供了更好地学习输入数据表示的机会，而对于 CIFAR-10 来说，这比简单的 MNIST 图像要复杂得多。表示可能会更好，因为深度网络可以学习更抽象的表示，涵盖输入数据中的更大结构。
- en: The code snippets in [Listings 14-2](ch14.xhtml#ch14lis2) and [14-3](ch14.xhtml#ch14lis3)
    compile the model using Adadelta as the optimization algorithm. We also want a
    version of each that uses SGD. If we replace the reference to `Adadelta()` in
    the `compile` method with the following
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '[Listings 14-2](ch14.xhtml#ch14lis2) 和 [14-3](ch14.xhtml#ch14lis3) 中的代码片段使用
    Adadelta 作为优化算法编译模型。我们还想要一个使用 SGD 的版本。如果我们将 `compile` 方法中的 `Adadelta()` 替换为以下内容'
- en: '[PRE0]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: we’ll use SGD with the learning rate and momentum values we indicated earlier.
    For completeness, the rest of the code for both shallow and deep models is shown
    in [Listing 14-4](ch14.xhtml#ch14lis4).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用之前提到的学习率和动量值来进行SGD优化。为完整起见，浅层和深层模型的其余代码请参见[清单14-4](ch14.xhtml#ch14lis4)。
- en: print("Model parameters = %d" % model.count_params())
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: print("模型参数 = %d" % model.count_params())
- en: print(model.summary())
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: print(model.summary())
- en: history = model.fit(x_train, y_train,
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: history = model.fit(x_train, y_train,
- en: batch_size=batch_size,
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: batch_size=batch_size,
- en: epochs=epochs,
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: epochs=epochs,
- en: verbose=1,
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: verbose=1,
- en: validation_data=(x_test[:1000], y_test[:1000]))
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: validation_data=(x_test[:1000], y_test[:1000]))
- en: score = model.evaluate(x_test[1000:], y_test[1000:], verbose=0)
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: score = model.evaluate(x_test[1000:], y_test[1000:], verbose=0)
- en: print('Test loss:', score[0])
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: print('测试损失:', score[0])
- en: print('Test accuracy:', score[1])
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: print('测试准确率:', score[1])
- en: model.save("cifar10_cnn_model.h5")
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: model.save("cifar10_cnn_model.h5")
- en: '*Listing 14-4: Training and testing the CIFAR-10 models*'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单14-4：训练和测试CIFAR-10模型*'
- en: This code summarizes the model architecture and number of parameters, trains
    by calling the `fit` method using the first 1,000 test samples for validation,
    and then evaluates the trained model on the remaining 9,000 test samples by calling
    the `evaluate` method. We report the test loss and accuracy. Then we write the
    model to disk (`save`), and store the history showing the per epoch loss and accuracy
    during training. We’ll use the history files to generate plots showing the loss
    and error (1 – accuracy) as a function of the training epoch.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码总结了模型架构和参数数量，通过调用`fit`方法，使用前1,000个测试样本进行验证训练，然后通过调用`evaluate`方法在剩余的9,000个测试样本上评估训练好的模型。我们报告测试损失和准确率。接着，我们将模型保存到磁盘（`save`），并存储显示每个训练周期的损失和准确率的历史记录。我们将使用这些历史记录文件生成图表，展示损失和错误（1
    – 准确率）随训练周期变化的情况。
- en: '[Listing 14-4](ch14.xhtml#ch14lis4) gives us four files: shallow model + Adadelta,
    shallow model + SGD, deep model + Adadelta, and deep model + SGD. Let’s run each
    of these to see our final test accuracy and then look at plots of the training
    process to see what we can learn.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '[清单14-4](ch14.xhtml#ch14lis4)给我们提供了四个文件：浅层模型 + Adadelta，浅层模型 + SGD，深层模型 + Adadelta，以及深层模型
    + SGD。让我们运行这些文件，查看最终的测试准确率，并查看训练过程的图表，看看我们能从中学到什么。'
- en: Running the code trains and evaluates the models. This takes some time on our
    CPU-only system, about eight hours total. The random initialization Keras uses
    means that when you run the code yourself, you should see slightly different answers.
    When I ran the code, I got [Table 14-1](ch14.xhtml#ch14tab1).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 运行代码将训练并评估模型。在我们的仅限CPU的系统上，这需要一些时间，总共大约八个小时。Keras使用的随机初始化意味着，当你自己运行代码时，你可能会得到稍有不同的结果。当我运行这段代码时，我得到了[表14-1](ch14.xhtml#ch14tab1)。
- en: '**Table 14-1:** Test Set Accuracies by Model Size and Optimizer'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '**表14-1：根据模型大小和优化器的测试集准确率**'
- en: '|  | **Shallow** | **Deep** |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '|  | **浅层** | **深层** |'
- en: '| --- | --- | --- |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Adadelta | 71.9% | 74.8% |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| Adadelta | 71.9% | 74.8% |'
- en: '| SGD | 70.0% | 72.8% |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| SGD | 70.0% | 72.8% |'
- en: The table tells us that using Adadelta gave us a more accurate model for both
    shallow and deep models compared to SGD. We also see that the deep model outperforms
    the shallow model regardless of optimizer. Adaptive optimizers like Adadelta and
    Adam (also in Keras) are generally preferred to plain old SGD for this reason.
    However, I have seen claims that SGD is ultimately just as good or better once
    the learning rate is set up right and decreased as training proceeds. Of course,
    nothing prevents us from starting with an adaptive optimizer and then switching
    to SGD after some number of epochs. The idea here is that the adaptive optimizer
    “gets close” to a minimum of the loss function while SGD fine-tunes the process
    at that point.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这张表告诉我们，使用Adadelta比SGD为浅层和深层模型提供了更精确的模型。我们还可以看到，不论优化器是什么，深层模型都优于浅层模型。由于这个原因，像Adadelta和Adam（也在Keras中）这样的自适应优化器通常优于传统的SGD。然而，我也看到有人声称，一旦学习率设置得当，并随着训练过程的进行逐渐降低，SGD最终和Adadelta一样好，甚至更好。当然，没什么能阻止我们在某个时期使用自适应优化器，然后在训练进行若干周期后切换为SGD。这里的想法是，自适应优化器“接近”损失函数的最小值，而SGD在这一点上进行精细调整。
- en: Analyzing the Models
  id: totrans-115
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 分析模型
- en: Let’s look at how the loss changes during training. [Figure 14-1](ch14.xhtml#ch14fig1)
    shows the loss per epoch for the shallow and deep models using Adadelta (top)
    and SGD (bottom).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看训练过程中损失的变化。[图14-1](ch14.xhtml#ch14fig1)展示了使用Adadelta（上图）和SGD（下图）时浅层和深层模型每个周期的损失。
- en: '![image](Images/14fig01.jpg)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/14fig01.jpg)'
- en: '*Figure 14-1: Training loss for shallow and deep models using Adadelta (top)
    and SGD (bottom)*'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '*图14-1：使用Adadelta（上图）和SGD（下图）训练浅层和深层模型的损失*'
- en: Starting with the Adadelta loss plot, we see that compared to SGD, the loss
    is not as low. We also see that for the shallow model, the loss is increasing
    slightly per epoch. This is a counterintuitive result and seems to contradict
    conventional wisdom that the training loss should only decrease. There are reports
    of this happening with Adam, another adaptive optimizer, so it is likely an artifact
    of the adaptation algorithm. Regardless, as we saw in [Table 14-1](ch14.xhtml#ch14tab1),
    Adadelta leads to higher accuracies for both shallow and deep models.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 从Adadelta的损失图开始，我们可以看到与SGD相比，损失并没有那么低。我们还看到浅层模型的损失在每个epoch中略微增加。这是一个反直觉的结果，似乎与传统的观念相悖——即训练损失应该只会下降。有报告称在Adam（另一种自适应优化器）中也会出现这种情况，因此这很可能是自适应算法的产物。无论如何，正如我们在[表14-1](ch14.xhtml#ch14tab1)中看到的，Adadelta在浅层和深层模型上都能带来更高的准确性。
- en: On the bottom of [Figure 14-1](ch14.xhtml#ch14fig1), we see that SGD leads to
    a smaller loss for the shallow model compared to the deep model. This is typically
    interpreted as a hint for potential overfitting. The model is learning the details
    of the training set as the loss tends to 0\. The shallow model using SGD was the
    least performant model according to [Table 14-1](ch14.xhtml#ch14tab1). The deep
    model using SGD did not have such a small loss, at least up to 60 training epochs.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图14-1](ch14.xhtml#ch14fig1)的底部，我们看到SGD使得浅层模型的损失比深层模型更小。这通常被解读为可能出现过拟合的提示。当损失趋向0时，模型正在学习训练集的细节。根据[表14-1](ch14.xhtml#ch14tab1)，使用SGD的浅层模型是表现最差的模型。使用SGD的深层模型并没有出现如此小的损失，至少在训练了60个epochs之前没有。
- en: What about the validation set accuracy during training? [Figure 14-2](ch14.xhtml#ch14fig2)
    plots the *error* by epoch. The error is easier to understand visually; it should
    tend toward 0 as accuracy increases. Again, the Adadelta models are on the top,
    and the SGD models are on the bottom.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，训练过程中验证集的准确性如何呢？[图14-2](ch14.xhtml#ch14fig2)按epoch绘制了*误差*。误差在视觉上更容易理解；它应该随着准确性的提高而趋近于0。同样，Adadelta模型在上方，SGD模型在下方。
- en: As expected, regardless of optimizer, the deeper model performed better and
    had a lower validation set error during training. Note, the validation set error
    is not the final, held-out test set error, but instead the portion of the test
    set used during training, the first 1,000 samples in this case.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期的那样，无论使用什么优化器，深层模型表现更好，并且在训练过程中验证集的误差较低。请注意，验证集的误差不是最终的、保留的测试集误差，而是训练过程中使用的测试集部分，在这个例子中是前1,000个样本。
- en: 'The SGD curves on the bottom of [Figure 14-2](ch14.xhtml#ch14fig2) follow what
    our intuition should tell us: as the model trains, it gets better, leading to
    a smaller error. The deep model quickly overtakes the shallow model—again, an
    intuitive result. Also, the curves are relatively smooth as the model gets better
    and better.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图14-2](ch14.xhtml#ch14fig2)底部的SGD曲线符合我们的直觉：随着模型训练的进行，它变得更好，导致误差变小。深层模型很快超越了浅层模型——这也是直观的结果。同时，随着模型的不断改进，曲线变得相对平滑。
- en: The Adadelta error plots on the top of [Figure 14-2](ch14.xhtml#ch14fig2) are
    a different story. There is an obvious decrease in the error after the first few
    epochs. However, after that, the validation set error jumps around somewhat chaotically
    though still following our intuition that the deep model should have a smaller
    error than the shallow model. This chaotic result is due to the adaptive nature
    of the Adadelta algorithm, which is adjusting the learning rate on the fly to
    search for a better minimum. From the results of [Table 14-1](ch14.xhtml#ch14tab1),
    it’s clear that Adadelta is finding better-performing models.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '[图14-2](ch14.xhtml#ch14fig2)顶部的Adadelta误差图呈现出不同的情况。在前几个epoch之后，误差显著下降。然而，之后验证集的误差出现了些许混乱的波动，尽管仍然符合我们直觉的判断，即深层模型的误差应该小于浅层模型。这个混乱的结果是由于Adadelta算法的自适应特性，它在调整学习率时试图寻找更好的最小值。从[表14-1](ch14.xhtml#ch14tab1)的结果可以看出，Adadelta找到了表现更好的模型。'
- en: '![image](Images/14fig02.jpg)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/14fig02.jpg)'
- en: '*Figure 14-2: Validation set error for shallow and deep models using Adadelta
    (top) and SGD (bottom)*'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '*图14-2：使用Adadelta（上图）和SGD（下图）的浅层和深层模型的验证集误差*'
- en: These experiments tell us that adaptive optimization algorithms and deeper networks
    (to a point) tend toward better-performing models. While recognizing the danger
    inherent in attempting to offer advice in this field, it seems safe to say that
    one should start with adaptive optimization and use a large enough model. To find
    out just what *large enough* means, I suggest starting with a modest model and,
    after training, making it deeper and seeing if that improves things. Eventually,
    the model will be too large for the training set, so there will be a cutoff point
    where increasing the size of the model no longer helps. In that case, get more
    training data, if possible.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这些实验告诉我们，自适应优化算法和更深的网络（到一定程度）倾向于产生更好的模型。虽然在尝试提供此领域建议时存在风险，但可以放心地说，应该从自适应优化算法开始，并使用一个足够大的模型。为了了解什么是*足够大*，我建议从一个适中的模型开始，训练后再让模型变得更深，看看是否能改善结果。最终，模型会变得太大，以至于无法适应训练集，所以会有一个临界点，超过这个点后，增加模型的大小不再有帮助。在这种情况下，如果可能的话，获取更多的训练数据。
- en: Let’s now shift our attention to working with subsets of CIFAR-10.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们把注意力转向处理CIFAR-10的子集。
- en: Animal or Vehicle?
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 动物还是车辆？
- en: Four of the ten classes in CIFAR-10 are vehicles; the remaining six are animals.
    Let’s build a model to separate the two and see what we can learn from it. We
    already have the images; all we need do is recode the labels so that all the vehicles
    are marked as class 0 and all the animals as class 1\. Doing this is straightforward,
    as shown in [Listing 14-5](ch14.xhtml#ch14lis5).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: CIFAR-10中的十个类别中有四个是车辆，其余六个是动物。让我们构建一个模型来区分这两者，看看我们能从中学到什么。我们已经有了图像；我们需要做的就是重新编码标签，将所有车辆标记为类别0，所有动物标记为类别1。这样做很简单，如[Listing
    14-5](ch14.xhtml#ch14lis5)所示。
- en: import numpy as np
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: import numpy as np
- en: y_train = np.load("cifar10_train_labels.npy")
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: y_train = np.load("cifar10_train_labels.npy")
- en: y_test  = np.load("cifar10_test_labels.npy")
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: y_test = np.load("cifar10_test_labels.npy")
- en: 'for i in range(len(y_train)):'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 'for i in range(len(y_train)):'
- en: 'if (y_train[i] in [0,1,8,9]):'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 'if (y_train[i] in [0,1,8,9]):'
- en: y_train[i] = 0
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: y_train[i] = 0
- en: 'else:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 'else:'
- en: y_train[i] = 1
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: y_train[i] = 1
- en: 'for i in range(len(y_test)):'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 'for i in range(len(y_test)):'
- en: 'if (y_test[i] in [0,1,8,9]):'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 'if (y_test[i] in [0,1,8,9]):'
- en: y_test[i] = 0
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: y_test[i] = 0
- en: 'else:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 'else:'
- en: y_test[i] = 1
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: y_test[i] = 1
- en: np.save("cifar10_train_animal_vehicle_labels.npy", y_train)
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: np.save("cifar10_train_animal_vehicle_labels.npy", y_train)
- en: np.save("cifar10_test_animal_vehicle_labels.npy", y_test)
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: np.save("cifar10_test_animal_vehicle_labels.npy", y_test)
- en: '*Listing 14-5: Adjusting the labels of CIFAR-10 into vehicles (class 0) and
    animals (class 1)*'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '*Listing 14-5: 将CIFAR-10的标签调整为车辆（类别0）和动物（类别1）*'
- en: We load the existing train and test label files, already matched in order with
    the train and test image files, and build new label vectors mapping the vehicle
    classes—classes 0, 1, 8, and 9—to 0 and all the others to 1.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们加载现有的训练和测试标签文件，这些文件已与训练和测试图像文件按顺序匹配，并构建新的标签向量，将车辆类别——类别0、1、8和9——映射为0，将其他所有类别映射为1。
- en: The code in the previous section for building and training the model remains
    the same except for the definition of the model architecture and the particular
    file we load for the train and test labels. The number of classes (`num_classes`)
    is set to 2, the minibatch size is 128, and we’ll train for 12 epochs. The training
    set isn’t completely balanced—there are 20,000 vehicles and 30,000 animals—but
    the imbalance isn’t severe, so we should be in good shape. Remember that when
    one class is scarce, it becomes difficult for the model to learn it well. We’ll
    stick with Adadelta as the optimizer and use the first 1,000 test samples for
    validation and the remaining 9,000 for final test. We’ll use the same shallow
    architecture used in the previous section.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 前一节中构建和训练模型的代码保持不变，除了模型架构的定义和我们加载的训练与测试标签文件。类别数量（`num_classes`）设置为2，迷你批量大小为128，我们将训练12个周期。训练集并不完全平衡——有20,000辆车和30,000只动物——但这种不平衡并不严重，所以我们应该没问题。记住，当某一类别较为稀缺时，模型很难很好地学习它。我们将继续使用Adadelta作为优化器，并用前1,000个测试样本进行验证，剩下的9,000个用于最终测试。我们将使用前一节中使用的相同的浅层架构。
- en: Training this model on the CIFAR-10 images with the recoded labels gives us
    a final test accuracy of 93.6 percent. Let’s be a little pedantic and calculate
    all the performance metrics from [Chapter 11](ch11.xhtml#ch11). To do this, we
    update the `tally_predictions` function defined in that chapter ([Listing 11-1](ch11.xhtml#ch11lis1))
    to work with a Keras model. We’ll also use `basic_metrics` ([Listing 11-2](ch11.xhtml#ch11lis2))
    and `advanced_metrics` ([Listing 11-3](ch11.xhtml#ch11lis3)) from [Chapter 11](ch11.xhtml#ch11).
    The updated code for `tally_predictions` is shown in [Listing 14-6](ch14.xhtml#ch14lis6).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在 CIFAR-10 图像上训练此模型，并使用重新编码的标签，最终测试准确率为 93.6%。让我们稍微细致一点，从 [第11章](ch11.xhtml#ch11)
    中计算所有性能指标。为此，我们更新了该章中定义的 `tally_predictions` 函数（[第11-1节](ch11.xhtml#ch11lis1)），使其能够与
    Keras 模型一起使用。我们还将使用 [第11章](ch11.xhtml#ch11) 中的 `basic_metrics`（[第11-2节](ch11.xhtml#ch11lis2)）和
    `advanced_metrics`（[第11-3节](ch11.xhtml#ch11lis3)）。更新后的 `tally_predictions` 代码显示在
    [第14-6节](ch14.xhtml#ch14lis6) 中。
- en: 'def tally_predictions(model, x, y):'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 'def tally_predictions(model, x, y):'
- en: pp = model.predict(x)
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: pp = model.predict(x)
- en: p = np.zeros(pp.shape[0], dtype="uint8")
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: p = np.zeros(pp.shape[0], dtype="uint8")
- en: '❶ for i in range(pp.shape[0]):'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '❶ for i in range(pp.shape[0]):'
- en: p[i] = 0 if (pp[i,0] > pp[i,1]) else 1
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: p[i] = 0 if (pp[i,0] > pp[i,1]) else 1
- en: tp = tn = fp = fn = 0
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: tp = tn = fp = fn = 0
- en: 'for i in range(len(y)):'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 'for i in range(len(y)):'
- en: 'if (p[i] == 0) and (y[i] == 0):'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 'if (p[i] == 0) and (y[i] == 0):'
- en: tn += 1
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: tn += 1
- en: 'elif (p[i] == 0) and (y[i] == 1):'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 'elif (p[i] == 0) and (y[i] == 1):'
- en: fn += 1
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: fn += 1
- en: 'elif (p[i] == 1) and (y[i] == 0):'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 'elif (p[i] == 1) and (y[i] == 0):'
- en: fp += 1
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: fp += 1
- en: 'else:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 'else:'
- en: tp += 1
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: tp += 1
- en: score = float(tp+tn) / float(tp+tn+fp+fn)
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: score = float(tp+tn) / float(tp+tn+fp+fn)
- en: return [tp, tn, fp, fn, score]
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: return [tp, tn, fp, fn, score]
- en: '*Listing 14-6: Calculating basic metrics for Keras models*'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '*第14-6节：为 Keras 模型计算基本指标*'
- en: 'We pass in the model, test samples (`x`), and test labels (`y`). Unlike the
    sklearn version of `tally_predictions`, here we first use the model to predict
    per class probabilities (`pp`). This returns a 2D array, one row for each sample
    in `x`, where the columns are the probabilities assigned per class. Here there
    are two columns because there are only two classes: vehicle or animal.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 我们传入模型、测试样本（`x`）和测试标签（`y`）。与 sklearn 版本的 `tally_predictions` 不同，在这里我们首先使用模型来预测每个类别的概率（`pp`）。这会返回一个二维数组，每行对应一个
    `x` 中的样本，列表示每个类别的概率。这里有两列，因为只有两种类别：车辆或动物。
- en: Before we can tally the true positives, true negatives, false positives (vehicle
    classified as animal), and false negatives (animal classified as vehicle), we
    need to assign a class label to each test sample. We do this by looping over the
    predictions, row by row, and asking whether the probability for class 0 is greater
    than class 1 or not ❶. Once we have assigned a predicted class label (`p`), we
    can calculate the tallies and return them along with the overall score (accuracy).
    We pass the list returned by `tally_predictions` to `basic_metrics` and then pass
    the output of both of these functions to `advanced_metrics`, as in [Chapter 11](ch11.xhtml#ch11).
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们能够统计真正例、真负例、假正例（将车辆分类为动物）和假负例（将动物分类为车辆）之前，我们需要为每个测试样本分配一个类别标签。我们通过逐行遍历预测结果，并询问类别
    0 的概率是否大于类别 1 的概率 ❶ 来实现这一点。一旦我们分配了预测的类别标签（`p`），就可以计算统计值并返回它们以及整体得分（准确率）。我们将 `tally_predictions`
    返回的列表传递给 `basic_metrics`，然后将这两个函数的输出传递给 `advanced_metrics`，如 [第11章](ch11.xhtml#ch11)
    中所述。
- en: 'The full set of binary classifier metrics gives us the following:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 二元分类器的完整指标集为我们提供了以下结果：
- en: '| **Metric** | **Result** |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| **指标** | **结果** |'
- en: '| --- | --- |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| TP | 5,841 |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| TP | 5,841 |'
- en: '| FP | 4,80 |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| FP | 4,80 |'
- en: '| TN | 3,520 |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| TN | 3,520 |'
- en: '| FN | 159 |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| FN | 159 |'
- en: '| TPR (sensitivity, recall) | 0.9735 |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| TPR（敏感性，召回率） | 0.9735 |'
- en: '| TNR (specificity) | 0.8800 |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| TNR（特异性） | 0.8800 |'
- en: '| PPV (precision) | 0.9241 |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| PPV（精度） | 0.9241 |'
- en: '| NPV | 0.9568 |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| NPV | 0.9568 |'
- en: '| FPR | 0.1200 |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| FPR | 0.1200 |'
- en: '| FNR | 0.0265 |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| FNR | 0.0265 |'
- en: '| F1 | 0.9481 |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| F1 | 0.9481 |'
- en: '| MCC | 0.8671 |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| MCC | 0.8671 |'
- en: '| *κ* | 0.8651 |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| *κ* | 0.8651 |'
- en: '| Informedness | 0.8535 |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| 信息度 | 0.8535 |'
- en: '| Markedness | 0.8808 |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| 标度度 | 0.8808 |'
- en: '| Accuracy | 0.9361 |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| 准确率 | 0.9361 |'
- en: We see that this is a well-performing model although a specificity of 88 percent
    is a little on the low side. As argued in [Chapter 11](ch11.xhtml#ch11), the Matthews
    correlation coefficient (MCC) is possibly the best single number for characterizing
    a binary classifier. Here we have an MCC of 0.8671 out of 1.0, indicative of a
    good model.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到，这是一个表现良好的模型，尽管特异性为 88%，有些偏低。正如 [第11章](ch11.xhtml#ch11) 所论述的，马修斯相关系数（MCC）可能是描述二元分类器最好的单一指标。这里我们得到了
    0.8671 的 MCC，接近 1.0，表明模型表现良好。
- en: Recall that the *sensitivity* is the probability that an animal is called an
    “animal” by this model, and the *specificity* is the probability that a vehicle
    is called a “vehicle.” The *precision* is the probability that when the model
    assigns a label of “animal,” it is correct, and the *NPV (negative predictive
    value)* is the probability of the model being correct when it assigns a label
    of “vehicle.” Note also that the false positive rate (FPR) is 1 – specificity,
    and the false negative rate (FNR) is 1 – sensitivity.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，*敏感度*是模型将动物识别为“动物”的概率，*特异度*是模型将车辆识别为“车辆”的概率。*精度*是模型标记为“动物”时正确的概率，而*NPV（负预测值）*是模型将标签为“车辆”时正确的概率。还需注意，假阳性率（FPR）为
    1 – 特异度，假阴性率（FNR）为 1 – 敏感度。
- en: 'A little more code will calculate the ROC curve and its area:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 多一些代码将计算 ROC 曲线及其面积：
- en: '[PRE1]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Again, we pass in the trained model, the test samples (`x`), and the animal
    or vehicle labels (`y`). We also convert the output probabilities to class predictions,
    as we did in [Listing 14-6](ch14.xhtml#ch14lis6). The AUC is 0.9267, and [Figure
    14-3](ch14.xhtml#ch14fig3) shows the ROC curve (note the zoomed axes). This curve
    is steep and close to the upper-left corner of the plot—all good signs of a well-performing
    model.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们传入训练好的模型、测试样本（`x`）和动物或车辆标签（`y`）。我们还将输出的概率转换为类别预测，就像在[示例 14-6](ch14.xhtml#ch14lis6)中所做的那样。AUC
    为 0.9267，[图 14-3](ch14.xhtml#ch14fig3)显示了 ROC 曲线（请注意缩放后的坐标轴）。这条曲线陡峭且靠近图的左上角——这是一个表现良好的模型的所有好迹象。
- en: '![image](Images/14fig03.jpg)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/14fig03.jpg)'
- en: '*Figure 14-3: ROC curve for the animal or vehicle model*'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 14-3: 动物或车辆模型的 ROC 曲线*'
- en: We grouped animals and vehicles and asked a single model to learn something
    about the difference between them. Clearly, some characteristics differentiate
    the two classes, and the model has learned to use them successfully. However,
    unlike most binary classifiers, we know finer label assignments for the test data.
    For example, we know which of the animals are birds or deer or frogs. Likewise,
    we know which samples are airplanes, ships, or trucks.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将动物和车辆分组，并让一个模型学习它们之间的区别。显然，一些特征区分了这两个类别，模型成功地学会了使用这些特征。然而，与大多数二分类器不同，我们知道测试数据的更精细的标签分配。例如，我们知道哪些动物是鸟、鹿或青蛙。同样，我们也知道哪些样本是飞机、船或卡车。
- en: When the model makes a mistake, the mistake is either a false positive (calling
    a vehicle an animal) or a false negative (calling an animal a vehicle). We chose
    animals to be class 1, so false positives are cases where a vehicle was called
    an animal. The converse is true for false negatives. We can use the full class
    labels to tell us how many of the false positives are represented by which vehicle
    classes, and we can do the same for the false negatives to tell us which animal
    classes were assigned to the vehicle class. A few lines of code in [Listing 14-7](ch14.xhtml#ch14lis7)
    give us what we are after.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 当模型犯错时，错误要么是假阳性（将车辆误认为是动物），要么是假阴性（将动物误认为是车辆）。我们将动物设为类别 1，因此假阳性是将车辆误判为动物的情况。假阴性的反面情况亦然。我们可以使用完整的类别标签来告诉我们有多少假阳性是由哪些车辆类别组成的，我们也可以对假阴性做同样的事情，以告诉我们哪些动物类别被分配给了车辆类别。几行代码在[示例
    14-7](ch14.xhtml#ch14lis7)中展示了我们所需要的内容。
- en: import numpy as np
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: import numpy as np
- en: from keras.models import load_model
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: from keras.models import load_model
- en: x_test = np.load("cifar10_test_images.npy")/255.0
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: x_test = np.load("cifar10_test_images.npy")/255.0
- en: y_label= np.load("cifar10_test_labels.npy")
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: y_label= np.load("cifar10_test_labels.npy")
- en: y_test = np.load("cifar10_test_animal_vehicle_labels.npy")
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: y_test = np.load("cifar10_test_animal_vehicle_labels.npy")
- en: model = load_model("cifar10_cnn_animal_vehicle_model.h5")
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: model = load_model("cifar10_cnn_animal_vehicle_model.h5")
- en: pp = model.predict(x_test)
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: pp = model.predict(x_test)
- en: p = np.zeros(pp.shape[0], dtype="uint8")
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: p = np.zeros(pp.shape[0], dtype="uint8")
- en: 'for i in range(pp.shape[0]):'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 'for i in range(pp.shape[0]):'
- en: p[i] = 0 if (pp[i,0] > pp[i,1]) else 1
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: p[i] = 0 if (pp[i,0] > pp[i,1]) else 1
- en: hp = []; hn = []
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: hp = []; hn = []
- en: '❶ for i in range(len(y_test)):'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '❶ for i in range(len(y_test)):'
- en: 'if (p[i] == 0) and (y_test[i] == 1):'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 'if (p[i] == 0) and (y_test[i] == 1):'
- en: hn.append(y_label[i])
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: hn.append(y_label[i])
- en: 'elif (p[i] == 1) and (y_test[i] == 0):'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 'elif (p[i] == 1) and (y_test[i] == 0):'
- en: hp.append(y_label[i])
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: hp.append(y_label[i])
- en: hp = np.array(hp)
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: hp = np.array(hp)
- en: hn = np.array(hn)
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: hn = np.array(hn)
- en: a = np.histogram(hp, bins=10, range=[0,9])[0]
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: a = np.histogram(hp, bins=10, range=[0,9])[0]
- en: b = np.histogram(hn, bins=10, range=[0,9])[0]
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: b = np.histogram(hn, bins=10, range=[0,9])[0]
- en: 'print("vehicles as animals: %s" % np.array2string(a))'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 'print("将车辆识别为动物: %s" % np.array2string(a))'
- en: 'print("animals as vehicles: %s" % np.array2string(b))'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 'print("将动物识别为车辆: %s" % np.array2string(b))'
- en: '*Listing 14-7: Using the fine class labels to determine which classes account
    for false positives and false negatives*'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '*示例 14-7：使用精细的类别标签确定哪些类别导致假阳性和假阴性*'
- en: First, we load the test set images, actual labels (`y_label`), and animal or
    vehicle labels (`y_test`). Then, as before, we load the model and get the model
    predictions (`p`). We want to keep track of the actual class label for each false
    positive and false negative, the mistakes the classifier has made. We do this
    by looping over the predictions and comparing them to the animal or vehicle labels
    ❶. When there is an error, we keep the actual label of the sample, be it an FN
    (`hn`) or FP (`hp`). Note that this works because when we defined the animal or
    vehicle labels, we were careful to keep the order the same as the original label
    set.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们加载测试集图像、实际标签（`y_label`）和动物或车辆标签（`y_test`）。然后，和之前一样，我们加载模型并得到模型预测（`p`）。我们希望追踪每个假阳性和假阴性的实际类别标签，即分类器所犯的错误。我们通过遍历预测结果，并将其与动物或车辆标签进行比较来做到这一点❶。当发生错误时，我们保存样本的实际标签，无论是假阴性（`hn`）还是假阳性（`hp`）。注意，这样做之所以有效，是因为我们在定义动物或车辆标签时，确保了它们的顺序与原始标签集一致。
- en: Once we have the actual labels for all FP and FN cases, we use `histogram` to
    do the tallying for us. There are 10 actual class labels, so we tell `histogram`
    that we want to use 10 bins. We also need to specify the range for the bins (`range=[0,9]`).
    We want only the counts themselves, so we need to keep only the first array returned
    by `histogram`, hence the `[0]` at the end of the call. Finally, we print the
    arrays to get
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了所有假阳性（FP）和假阴性（FN）案例的实际标签，我们使用`histogram`来为我们统计。共有10个实际类别标签，因此我们告诉`histogram`我们希望使用10个区间。我们还需要指定区间的范围（`range=[0,9]`）。我们只需要计数值本身，所以我们只保留`histogram`返回的第一个数组，因此调用的最后加上了`[0]`。最后，我们打印数组得到：
- en: '[PRE2]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This means that of the vehicles the model called “animal,” 189 of them were
    of class 0, airplane. The vehicle class least likely to be identified as an animal
    is class 1, automobile. Ships and trucks were similarly likely to be mistaken
    for an animal. Going the other way, we see that class 2, birds, were most likely
    to be mistaken for vehicles and class 5, dogs, were least likely to be misclassified,
    though frogs were a close second.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着模型将189个“动物”识别为类别0，飞机。最不可能被误识为动物的车辆类别是类别1，汽车。船和卡车同样容易被误识为动物。反过来，我们看到类别2，鸟类，最容易被误识为车辆，而类别5，狗类，最不容易被误分类，尽管青蛙紧随其后。
- en: 'What to make of this? The most commonly misclassified vehicle is an airplane,
    while the most commonly misclassified animal is a bird. This makes sense: a picture
    of an airplane and a picture of a bird flying do look similar. I’ll leave it to
    you to make connections among the other categories.'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 该如何理解这些结果呢？最常被误分类的车辆是飞机，而最常被误分类的动物是鸟类。这是有道理的：飞机和飞行中的鸟类的图片确实看起来很相似。其他类别的关系就留给你去思考吧。
- en: Binary or Multiclass?
  id: totrans-226
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 二分类还是多分类？
- en: Conventional wisdom in machine learning is that a multiclass model will generally
    outperform multiple binary models. While this is almost certainly true for large
    datasets, large models, and situations with many classes, like the ImageNet dataset
    of 1,000 classes, how does it pan out for small models like the ones we’re working
    with in this chapter? Let’s find out.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，传统的观点认为，多分类模型通常比多个二分类模型更具优势。虽然对于大数据集、大模型以及有很多类别的情况，比如包含1,000个类别的ImageNet数据集，这几乎是肯定成立的，但对于我们在本章中使用的小模型来说，这种情况如何呢？让我们来探讨一下。
- en: There are 5,000 instances of each class in the CIFAR-10 dataset and 10 classes.
    This means we can train 10 binary models where the target class (class 1) is one
    of the 10 classes, and the other class is everything else. This is known as a
    *one-vs-rest* approach. To classify an unknown sample, we run it through each
    of the 10 classifiers and assign the label of the model returning the most confident
    answer. The datasets are all imbalanced, 5,000 class 1 instances to 45,000 class
    0, but, as we’ll see, there is still enough data to learn the difference between
    classes.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: CIFAR-10数据集中每个类别有5,000个实例，共有10个类别。这意味着我们可以训练10个二分类模型，其中目标类别（类别1）是10个类别之一，而其他类别则归为“其他”。这种方法被称为*一对多*方法。为了对未知样本进行分类，我们将其分别输入每个分类器，并根据返回的最有信心的答案来分配标签。所有数据集都是不平衡的，类别1有5,000个实例，类别0有45,000个实例，但正如我们所看到的，依然有足够的数据来学习类别之间的差异。
- en: We need some code to train 10 one-vs-rest models. We’ll use the shallow architecture
    we’ve used before, with a minibatch size of 128, and we’ll train for 12 epochs.
    Before we can train, however, we need to reassign the class labels for the train
    and test sets so that all instances of the target class are a 1 and everything
    else is a 0\. To build the per class labels, we’ll use [Listing 14-8](ch14.xhtml#ch14lis8).
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一些代码来训练10个一对多模型。我们将使用之前使用过的浅层架构，批量大小为128，并训练12个epochs。但是，在训练之前，我们需要重新分配训练集和测试集的类别标签，以便目标类别的所有实例都是1，其他所有实例都是0。为了构建每个类别的标签，我们将使用[Listing
    14-8](ch14.xhtml#ch14lis8)。
- en: import sys
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: import sys
- en: import numpy as np
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: import numpy as np
- en: ❶ class1 = eval("["+sys.argv[1]+"]")
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ class1 = eval("["+sys.argv[1]+"]")
- en: y_train = np.load("cifar10_train_labels.npy")
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: y_train = np.load("cifar10_train_labels.npy")
- en: y_test  = np.load("cifar10_test_labels.npy")
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: y_test = np.load("cifar10_test_labels.npy")
- en: 'for i in range(len(y_train)):'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 'for i in range(len(y_train)):'
- en: 'if (y_train[i] in class1):'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 'if (y_train[i] in class1):'
- en: y_train[i] = 1
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: y_train[i] = 1
- en: 'else:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 'else:'
- en: y_train[i] = 0
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: y_train[i] = 0
- en: 'for i in range(len(y_test)):'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 'for i in range(len(y_test)):'
- en: 'if (y_test[i] in class1):'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 'if (y_test[i] in class1):'
- en: y_test[i] = 1
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: y_test[i] = 1
- en: 'else:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 'else:'
- en: y_test[i] = 0
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: y_test[i] = 0
- en: np.save(sys.argv[2], y_train)
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: np.save(sys.argv[2], y_train)
- en: np.save(sys.argv[3], y_test)
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: np.save(sys.argv[3], y_test)
- en: '*Listing 14-8: Building the per class labels*'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '*Listing 14-8: 构建每个类别的标签*'
- en: This code makes use of the command line. To call it, use something like
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码利用了命令行。要调用它，可以使用类似下面的命令：
- en: '[PRE3]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The first argument is the desired target class label, here 1 for automobiles,
    and the next two arguments are the names in which to store the new label assignments
    for the train and test images. The code itself loops over the actual train and
    test labels, and if the label is the target class, the corresponding output label
    is 1; otherwise, it is 0.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个参数是所需的目标类别标签，这里是1（表示汽车），接下来的两个参数是存储训练集和测试集新标签分配的文件名。代码本身会遍历实际的训练集和测试集标签，如果标签是目标类别，则对应的输出标签为1；否则，输出标签为0。
- en: This code is more flexible than mapping a single class. By using `eval` ❶, we
    can pass in a comma-separated string of all the CIFAR-10 labels we want to treat
    as the target class. For example, to use this code to make labels for the animal
    versus vehicle example of the previous section, we’d make the first argument `2,3,4,5,6,7`.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码比映射单一类别更灵活。通过使用`eval` ❶，我们可以传入一个以逗号分隔的字符串，表示我们希望作为目标类别的所有CIFAR-10标签。例如，要使用此代码为上一节中的动物与车辆示例生成标签，我们会将第一个参数设为`2,3,4,5,6,7`。
- en: Once we have new labels for each of the 10 classes, we can use them to train
    10 models. All we need do is change `num_classes` to 2 and load each of the respective
    reassigned label files for `y_train` and `y_test`. At the bottom of the file,
    we need to change the call to `model.save` to store the per class models as well.
    We’ll assume the models are in files named *cifar10_cnn_<X>_model.h5* where *<X>*
    is a digit, 0–9, representing a CIFAR-10 class label. Our multiclass model is
    the shallow architecture trained on the full CIFAR-10 dataset for 12 epochs (*cifar10_cnn_model.h5*).
    To train the binary models, use the `train_single_models` script. This script
    calls *cifar10_cnn_arbitrary.py* to train a model using a specified binary dataset.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们为每个10个类别分配了新的标签，就可以用它们训练10个模型。我们需要做的就是将`num_classes`改为2，并加载分别为`y_train`和`y_test`重新分配标签的文件。在文件底部，我们需要更改`model.save`的调用，以便存储每个类别的模型。我们假设模型的文件名为*cifar10_cnn_<X>_model.h5*，其中*<X>*是一个数字，表示CIFAR-10的类别标签。我们的多类模型是基于完整的CIFAR-10数据集训练的浅层架构，训练了12个epochs（*cifar10_cnn_model.h5*）。要训练二分类模型，可以使用`train_single_models`脚本。该脚本调用*cifar10_cnn_arbitrary.py*，使用指定的二分类数据集训练模型。
- en: 'To test the models, we need to first load them all from disk along with the
    test set data. Then we need to run all the data through the multiclass model and
    each of the individual class models keeping the predictions. From the predictions,
    we can assign class labels and build confusion matrices to see how well each approach
    does. First, let’s load the test set and the models:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 测试模型时，我们首先需要从磁盘加载所有模型以及测试集数据。然后，我们需要通过多类模型和每个单独的类别模型运行所有数据，并保存预测结果。通过预测结果，我们可以分配类别标签并构建混淆矩阵，查看每种方法的效果如何。首先，让我们加载测试集和模型：
- en: '[PRE4]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Notice that we are scaling the test set by 255, as we did with the training
    data. We’ll keep the multiclass model in `mm` and load the 10 single class models
    into the list, `m`.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们对测试集进行了255的缩放，就像对训练数据所做的那样。我们将保持多类模型在`mm`中，并将10个单类别模型加载到列表`m`中。
- en: 'Next, we apply the models to each test set sample:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将模型应用于每个测试集样本：
- en: '[PRE5]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Calling `predict` with the 10,000 test samples returns a 10,000 × 10 matrix
    for the multiclass model or 10,000 × 2 for the individual models. Each row corresponds
    to a test sample, and each column is the model’s output for each class. For the
    multiclass case, we set `mp` to the maximum value across the columns (`axis=1`)
    to get a vector of 10,000 values, each of which is the predicted class label.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`predict`调用10,000个测试样本返回一个10,000 × 10的矩阵用于多分类模型，或者一个10,000 × 2的矩阵用于单独的模型。每一行对应一个测试样本，每一列是模型对每个类的输出。对于多分类情况，我们将`mp`设置为按列（`axis=1`）的最大值，从而得到一个包含10,000个值的向量，每个值对应一个预测的类标签。
- en: We loop over the individual models and call `predict`, keeping only the class
    1 probabilities. These are placed into `p`, where the rows are the individual
    model outputs for that class label, and the columns are the specific class 1 prediction
    probabilities for each of the 10,000 test samples. If we return the maximum value
    across the rows by using `argmax` and `axis=0`, we’ll get the class label of the
    model that had the highest predicted probability for each test sample. This is
    what is in `bp`.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 我们遍历各个单独的模型并调用`predict`，只保留类 1 的概率。这些概率被存入`p`，其中行表示该类标签的单个模型输出，列表示每个 10,000
    个测试样本的类 1 预测概率。如果我们通过使用`argmax`和`axis=0`返回行之间的最大值，我们就能得到每个测试样本的模型预测类标签。这就是`bp`中的内容。
- en: 'With our predictions in hand, we can generate the confusion matrices:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 拿到我们的预测结果后，我们可以生成混淆矩阵：
- en: '[PRE6]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Here rows represent the true class label, and columns represent the model’s
    predicted label. We also store the confusion matrices for future use.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 这里行表示真实的类标签，列表示模型预测的标签。我们还会将混淆矩阵存储以便以后使用。
- en: 'We can display the confusion matrices with the code in [Listing 14-9](ch14.xhtml#ch14lis9):'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用[列表 14-9](ch14.xhtml#ch14lis9)中的代码来显示混淆矩阵：
- en: print("One-vs-rest confusion matrix (rows true, cols predicted):")
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: print("一对多混淆矩阵（行是真实值，列是预测值）：")
- en: print("%s" % np.array2string(100*(cb/1000.0), precision=1))
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: print("%s" % np.array2string(100*(cb/1000.0), precision=1))
- en: print()
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: print()
- en: print("Multiclass confusion matrix:")
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: print("多分类混淆矩阵：")
- en: print("%s"  % np.array2string(100*(cm/1000.0), precision=1))
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: print("%s"  % np.array2string(100*(cm/1000.0), precision=1))
- en: '*Listing 14-9: Displaying the confusion matrices. See* cifar10_one_vs_many.py'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '*列表 14-9：显示混淆矩阵。参见* cifar10_one_vs_many.py'
- en: We divide the counts in `cb` and `cm` by 1,000 because each class is represented
    by that many samples in the test set. This converts the confusion matrix entries
    to a fraction and then a percent when multiplied by 100.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将`cb`和`cm`中的计数除以1,000，因为每个类在测试集中都有那么多样本。这将混淆矩阵条目转换为分数，再通过乘以 100 转换为百分比。
- en: So, how did we do? The multiple one-vs-rest classifiers produced
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们做得怎么样？多个一对多分类器产生了
- en: '| **Class** | **0** | **1** | **2** | **3** | **4** | **5** | **6** | **7**
    | **8** | **9** |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| **类** | **0** | **1** | **2** | **3** | **4** | **5** | **6** | **7** | **8**
    | **9** |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| **0** | **75.0** | 2.8 | 3.4 | 2.1 | 1.7 | 0.4 | 2.3 | 0.2 | 4.1 | 8.0 |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| **0** | **75.0** | 2.8 | 3.4 | 2.1 | 1.7 | 0.4 | 2.3 | 0.2 | 4.1 | 8.0 |'
- en: '| **1** | 0.8 | **84.0** | 0.2 | 0.9 | 0.3 | 0.3 | 1.1 | 0.0 | 1.2 | 11.2 |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| **1** | 0.8 | **84.0** | 0.2 | 0.9 | 0.3 | 0.3 | 1.1 | 0.0 | 1.2 | 11.2 |'
- en: '| **2** | 6.5 | 1.6 | **54.0** | 6.3 | 9.5 | 5.3 | 9.1 | 2.3 | 0.8 | 4.6 |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| **2** | 6.5 | 1.6 | **54.0** | 6.3 | 9.5 | 5.3 | 9.1 | 2.3 | 0.8 | 4.6 |'
- en: '| **3** | 1.6 | 3.6 | 3.8 | **52.1** | 7.1 | 12.9 | 10.6 | 2.2 | 0.9 | 5.2
    |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| **3** | 1.6 | 3.6 | 3.8 | **52.1** | 7.1 | 12.9 | 10.6 | 2.2 | 0.9 | 5.2
    |'
- en: '| **4** | 1.8 | 0.8 | 3.6 | 6.5 | **67.6** | 2.3 | 8.6 | 5.3 | 1.3 | 2.2 |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| **4** | 1.8 | 0.8 | 3.6 | 6.5 | **67.6** | 2.3 | 8.6 | 5.3 | 1.3 | 2.2 |'
- en: '| **5** | 1.4 | 1.4 | 3.5 | 16.9 | 4.7 | **61.8** | 4.0 | 2.6 | 0.5 | 3.2 |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| **5** | 1.4 | 1.4 | 3.5 | 16.9 | 4.7 | **61.8** | 4.0 | 2.6 | 0.5 | 3.2 |'
- en: '| **6** | 0.8 | 0.7 | 1.4 | 3.4 | 2.8 | 1.0 | **86.4** | 0.2 | 0.3 | 3.0 |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| **6** | 0.8 | 0.7 | 1.4 | 3.4 | 2.8 | 1.0 | **86.4** | 0.2 | 0.3 | 3.0 |'
- en: '| **7** | 1.5 | 1.3 | 1.7 | 4.9 | 5.2 | 5.2 | 1.5 | **71.5** | 0.1 | 7.1 |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| **7** | 1.5 | 1.3 | 1.7 | 4.9 | 5.2 | 5.2 | 1.5 | **71.5** | 0.1 | 7.1 |'
- en: '| **8** | 5.3 | 4.4 | 0.1 | 1.1 | 0.5 | 0.6 | 1.1 | 0.5 | **79.1** | 7.3 |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| **8** | 5.3 | 4.4 | 0.1 | 1.1 | 0.5 | 0.6 | 1.1 | 0.5 | **79.1** | 7.3 |'
- en: '| **9** | 1.7 | 4.0 | 0.2 | 0.8 | 0.1 | 0.4 | 0.5 | 0.3 | 0.8 | **91.2** |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| **9** | 1.7 | 4.0 | 0.2 | 0.8 | 0.1 | 0.4 | 0.5 | 0.3 | 0.8 | **91.2** |'
- en: And the multiclass classifier came up with
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 而多分类分类器的结果是
- en: '| **Class** | **0** | **1** | **2** | **3** | **4** | **5** | **6** | **7**
    | **8** | **9** |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '| **类** | **0** | **1** | **2** | **3** | **4** | **5** | **6** | **7** | **8**
    | **9** |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| **0** | **70.2** | 1.6 | 6.0 | 2.6 | 3.3 | 0.5 | 1.8 | 0.9 | 9.8 | 3.3 |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| **0** | **70.2** | 1.6 | 6.0 | 2.6 | 3.3 | 0.5 | 1.8 | 0.9 | 9.8 | 3.3 |'
- en: '| **1** | 2.0 | **79.4** | 1.0 | 1.3 | 0.5 | 0.5 | 1.3 | 0.4 | 2.8 | 10.8 |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| **1** | 2.0 | **79.4** | 1.0 | 1.3 | 0.5 | 0.5 | 1.3 | 0.4 | 2.8 | 10.8 |'
- en: '| **2** | 5.2 | 0.6 | **56.2** | 6.6 | 13.5 | 6.1 | 7.3 | 2.6 | 1.4 | 0.5 |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '| **2** | 5.2 | 0.6 | **56.2** | 6.6 | 13.5 | 6.1 | 7.3 | 2.6 | 1.4 | 0.5 |'
- en: '| **3** | 1.2 | 1.1 | 7.2 | **57.7** | 10.2 | 11.5 | 7.3 | 1.7 | 1.2 | 0.9
    |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
  zh: '| **3** | 1.2 | 1.1 | 7.2 | **57.7** | 10.2 | 11.5 | 7.3 | 1.7 | 1.2 | 0.9
    |'
- en: '| **4** | 1.9 | 0.2 | 5.2 | 4.6 | **77.4** | 1.6 | 4.8 | 2.7 | 1.5 | 0.1 |'
  id: totrans-291
  prefs: []
  type: TYPE_TB
  zh: '| **4** | 1.9 | 0.2 | 5.2 | 4.6 | **77.4** | 1.6 | 4.8 | 2.7 | 1.5 | 0.1 |'
- en: '| **5** | 1.0 | 0.2 | 6.4 | 20.7 | 7.7 | **56.8** | 2.7 | 3.5 | 0.8 | 0.2 |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
  zh: '| **5** | 1.0 | 0.2 | 6.4 | 20.7 | 7.7 | **56.8** | 2.7 | 3.5 | 0.8 | 0.2 |'
- en: '| **6** | 0.3 | 0.1 | 4.5 | 5.2 | 5.7 | 1.5 | **82.4** | 0.0 | 0.0 | 0.3 |'
  id: totrans-293
  prefs: []
  type: TYPE_TB
  zh: '| **6** | 0.3 | 0.1 | 4.5 | 5.2 | 5.7 | 1.5 | **82.4** | 0.0 | 0.0 | 0.3 |'
- en: '| **7** | 1.4 | 0.2 | 4.0 | 6.3 | 10.1 | 4.1 | 0.9 | **71.7** | 0.1 | 1.2 |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
  zh: '| **7** | 1.4 | 0.2 | 4.0 | 6.3 | 10.1 | 4.1 | 0.9 | **71.7** | 0.1 | 1.2 |'
- en: '| **8** | 4.7 | 3.0 | 0.8 | 2.0 | 1.3 | 0.6 | 1.0 | 0.6 | **82.6** | 3.4 |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
  zh: '| **8** | 4.7 | 3.0 | 0.8 | 2.0 | 1.3 | 0.6 | 1.0 | 0.6 | **82.6** | 3.4 |'
- en: '| **9** | 2.4 | 6.1 | 0.7 | 2.6 | 1.2 | 0.7 | 1.2 | 1.6 | 3.2 | **80.3** |'
  id: totrans-296
  prefs: []
  type: TYPE_TB
  zh: '| **9** | 2.4 | 6.1 | 0.7 | 2.6 | 1.2 | 0.7 | 1.2 | 1.6 | 3.2 | **80.3** |'
- en: 'The diagonals are the correct class assignments. Ideally, the matrix would
    be only diagonal elements. All other elements are mistakes, cases where the model
    or models chose the wrong label. Since each class is equally represented in the
    test set, we can calculate an overall accuracy for both models by using the unweighted
    average of the diagonals. If we do this, we get the following:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 对角线上的元素是正确的类别分配。理想情况下，矩阵应仅包含对角线元素。其他所有元素都是错误的，表示模型或模型选择了错误的标签。由于每个类别在测试集中的表示相同，我们可以通过使用对角线元素的无权平均值来计算两个模型的总体准确率。如果我们这样做，得到如下结果：
- en: 'one-vs-rest: 72.3%'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 一对多模型：72.3%
- en: 'multiclass: 71.5%'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 多类模型：71.5%
- en: The one-vs-rest classifiers have the slight edge in this case, though the difference
    is less than 1 percent. Of course, we needed to do 10 times the work to get the
    one-vs-rest confusion matrix—ten classifiers were used instead of just one. The
    multiclass model was about 10 percent better on class 4 (deer) than the one-vs-rest
    models, but it was approximately 11 percent worse on class 9 (trucks). These are
    the two most substantial per class differences in accuracy. The multiclass model
    is confusing trucks with class 8, ships (3.2 percent), and class 1, cars (6.1
    percent), more often than the one-vs-rest models. We can see how this might happen.
    Trucks and cars have wheels, and trucks and ships are (especially at the low resolution
    of CIFAR-10) both box-like.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，一对多分类器略微占优，尽管差异不到1%。当然，我们需要做10倍的工作才能得到一对多的混淆矩阵——使用了十个分类器，而不是一个。多类模型在类别4（鹿）上的表现比一对多模型好约10%，但在类别9（卡车）上的表现则差约11%。这些是每个类别的最大准确度差异。多类模型将卡车与类别8（船）(3.2%)和类别1（汽车）(6.1%)混淆的频率高于一对多模型。我们可以看到这可能发生的原因。卡车和汽车都有轮子，卡车和船（尤其是在CIFAR-10的低分辨率下）都是方形的。
- en: Did we arrive at a definitive answer regarding one-vs-rest or multiclass models?
    No, nor could we in general. However, we did, objectively, get slightly better
    performance by using the multiple models.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 我们是否得出了关于一对多（one-vs-rest）与多类（multiclass）模型的明确答案？没有，一般来说我们也无法得出。尽管如此，客观上，通过使用多个模型，我们确实获得了略微更好的性能。
- en: One argument given against using multiple models, besides the extra computation
    necessary, is that using a single model for multiple classes provides the model
    with the opportunity to see examples that are similar to a particular class but
    are not instances of that class. These hard negatives serve to regularize the
    model by forcing it to (indirectly) pay attention to features that are dissimilar
    between classes instead of features that might be strongly associated with a class
    but are also present in other classes. We first encountered hard negatives in
    [Chapter 4](ch04.xhtml#ch04).
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 一个反对使用多个模型的论点是，除了额外的计算开销外，使用单一模型处理多个类别会让模型有机会看到与某一特定类别相似的样本，但这些样本并不是该类别的实例。这些难样本（hard
    negatives）通过强迫模型（间接地）关注类别之间的不同特征，而不是可能与某一类别强相关但也出现在其他类别中的特征，从而对模型进行正则化。我们首次在[第4章](ch04.xhtml#ch04)遇到难样本。
- en: However, in this case, it’s difficult to say that the argument holds. For the
    multiclass model, class 9 (trucks) was more likely to be confused with class 1
    (car, 6.1 percent) than one-vs-rest models (4.0 percent). One possible explanation
    might be that the multiclass model was forced, with limited training data, to
    try to learn the difference between trucks, cars, and other vehicles, while the
    one-vs-rest models were, individually, trying to learn only the difference between
    a truck and any other vehicle.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在这种情况下，很难说这个论点成立。对于多类模型，类别9（卡车）更容易与类别1（汽车，6.1%）混淆，而不是一对多（one-vs-rest）模型（4.0%）。一个可能的解释是，多类模型在有限的训练数据下被迫尝试学习卡车、汽车和其他车辆之间的区别，而一对多模型则单独地尝试学习卡车与其他任何车辆之间的区别。
- en: Transfer Learning
  id: totrans-304
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 迁移学习
- en: We’ll use the term *transfer learning* to refer to taking a pretrained deep
    network and using it to produce new features for another machine learning model.
    Our transfer learning example will be a toy model meant to show the process, but
    many models have been built using features generated by large pretrained networks
    that used huge datasets. In particular, many models have been built using features
    generated by AlexNet and the various ResNet architectures, which were pretrained
    on the ImageNet dataset.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用*迁移学习*这个术语，指的是采用一个预训练的深度网络，并将其用于为另一个机器学习模型生成新的特征。我们的迁移学习示例将是一个小型模型，旨在展示这一过程，但许多模型已经使用了由大型预训练网络生成的特征，这些网络使用了庞大的数据集。特别是，许多模型已经使用了由AlexNet和各种ResNet架构生成的特征，而这些网络是在ImageNet数据集上进行预训练的。
- en: 'We’ll use the pretrained model to turn input images into output feature vectors,
    which we’ll then use to train classical machine learning models. When a model
    is used to turn an input into another feature representation, typically a new
    feature vector, the output is often called an *embedding*: we are using the pretrained
    network to embed the inputs we want to classify into another space—one that we
    hope will let us build a useful model. We can use transfer learning when the model
    we want to develop has too few training examples to make a good model on its own.'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用预训练模型将输入图像转换为输出特征向量，然后我们将用这些特征向量来训练经典的机器学习模型。当一个模型被用来将输入转换为另一个特征表示，通常是新的特征向量时，输出通常被称为*嵌入*：我们正在使用预训练的网络将我们想要分类的输入嵌入到另一个空间——我们希望这个空间能帮助我们构建一个有用的模型。当我们想要开发的模型有太少的训练样本，无法单独生成一个好的模型时，我们可以使用迁移学习。
- en: When using transfer learning, it is helpful to know or believe that both models
    were trained using similar data. If you read the literature, you’ll find that
    this is true for many of the typical transfer learning examples. The inputs are
    natural images of some class, and the embedding models were trained on natural
    images. By natural image, I mean a photograph of something in the world as opposed
    to an x-ray or other medical image. Clearly, the CIFAR-10 images and the MNIST
    images are quite different from each other, so we shouldn’t hope for too much
    success with transfer learning. We’re using what we have on hand to demonstrate
    the technique.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用迁移学习时，了解或相信两个模型是使用相似的数据进行训练的，会非常有帮助。如果你阅读文献，你会发现许多典型的迁移学习示例确实如此。输入是某一类别的自然图像，而嵌入模型是在自然图像上训练的。这里的“自然图像”指的是世界上某物的照片，而不是X光或其他医学影像。显然，CIFAR-10图像和MNIST图像之间有很大的差异，所以我们不应该指望在迁移学习上取得太大的成功。我们只是用现有的条件来展示这一技术。
- en: We’ll use a shallow CIFAR-10 model like the ones we just saw to generate the
    embedding vectors. This model was trained on the full CIFAR-10 dataset for 12
    epochs. We’ll embed the MNIST dataset by passing the MNIST digit images through
    the pretrained model, keeping the output of the Dense layer, the 128-node vectors
    used to generate the 10-class softmax predictions.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一个浅层的CIFAR-10模型，就像我们刚刚看到的那些模型，用来生成嵌入向量。这个模型在完整的CIFAR-10数据集上训练了12个epoch。我们将通过将MNIST数字图像传递给预训练模型，并保持Dense层的输出，即用于生成10类softmax预测的128节点向量，来嵌入MNIST数据集。
- en: We need to consider a few things before making the embedding. First, the CIFAR-10
    model was trained on 32 × 32 RGB images. Therefore, we need to make the MNIST
    digit images fit this input expectation. Second, even though there are 10 classes
    for both CIFAR-10 and MNIST, this is only a coincidence; in practice, the number
    of classes between the two datasets do not need to match.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行嵌入之前，我们需要考虑一些问题。首先，CIFAR-10 模型是基于 32 × 32 RGB 图像训练的。因此，我们需要调整 MNIST 数字图像以适应这一输入要求。其次，尽管
    CIFAR-10 和 MNIST 都有 10 个类别，但这只是巧合；实际上，这两个数据集之间的类别数不需要匹配。
- en: How should we get the 28 × 28 MNIST images into a model that’s expecting 32
    × 32 RGB images? Typically, when working with image data and transfer learning,
    we’ll resize the images to make them fit. Here, since the MNIST digits are smaller
    than the CIFAR-10 images, we can center the 28 × 28 digit image in the middle
    of a 32 × 32 input. Moreover, we can turn a grayscale image into an RGB image
    by setting each channel (red, green, and blue) to the single grayscale input.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该如何将 28 × 28 的 MNIST 图像输入到一个期望 32 × 32 RGB 图像的模型中呢？通常，在处理图像数据和迁移学习时，我们会调整图像大小以适应模型。在这里，由于
    MNIST 数字图像比 CIFAR-10 图像小，我们可以将 28 × 28 的数字图像居中放置在 32 × 32 的输入图像中。此外，我们可以通过将每个通道（红色、绿色和蓝色）设置为单一的灰度输入，将灰度图像转换为
    RGB 图像。
- en: 'The code for all of the following is in *transfer_learning.py*. Setting up
    the embedding process looks like this:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 以下所有代码都在 *transfer_learning.py* 文件中。设置嵌入过程如下所示：
- en: '[PRE7]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We first load the modules we need from Keras. Then we load the Keras model file,
    *cifar10_cnn_model.h5*, which contains a shallow model from the first section
    of this chapter trained for 12 epochs on the full CIFAR-10 dataset.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先从 Keras 中加载所需的模块。然后，我们加载 Keras 模型文件，*cifar10_cnn_model.h5*，该文件包含本章第一部分训练了
    12 轮的浅层模型，训练使用了完整的 CIFAR-10 数据集。
- en: Once we have the data loaded and scaled, we can pass each MNIST train and test
    image through the Keras model and extract the 128-node vector from the Dense layer.
    This turns each MNIST image into a 128-element vector; see [Listing 14-10](ch14.xhtml#ch14lis10).
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据加载并缩放完成，我们就可以将每张 MNIST 训练和测试图像传递给 Keras 模型，并从 Dense 层提取 128 节点的向量。这样，每张
    MNIST 图像就变成了一个 128 元素的向量；请参见 [列表 14-10](ch14.xhtml#ch14lis10)。
- en: train = np.zeros((60000,128))
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: train = np.zeros((60000,128))
- en: k = 0
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: k = 0
- en: 'for i in range(600):'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 'for i in range(600):'
- en: t = np.zeros((100,32,32,3))
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: t = np.zeros((100,32,32,3))
- en: ❶ t[:,2:30,2:30,0] = x_train[k:(k+100)]
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ t[:,2:30,2:30,0] = x_train[k:(k+100)]
- en: t[:,2:30,2:30,1] = x_train[k:(k+100)]
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: t[:,2:30,2:30,1] = x_train[k:(k+100)]
- en: t[:,2:30,2:30,2] = x_train[k:(k+100)]
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: t[:,2:30,2:30,2] = x_train[k:(k+100)]
- en: _ = model.predict(t)
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: _ = model.predict(t)
- en: ❷ out = [model.layers[5].output]
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ out = [model.layers[5].output]
- en: func = K.function([model.input, K.learning_phase()], out)
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: func = K.function([model.input, K.learning_phase()], out)
- en: (*\newpage*)
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: (*\newpage*)
- en: train[k:(k+100),:] = func([t, 1.])[0]
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: train[k:(k+100),:] = func([t, 1.])[0]
- en: k += 100
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: k += 100
- en: np.save("mnist_train_embedded.npy", train)
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: np.save("mnist_train_embedded.npy", train)
- en: test = np.zeros((10000,128))
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: test = np.zeros((10000,128))
- en: k = 0
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: k = 0
- en: 'for i in range(100):'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 'for i in range(100):'
- en: t = np.zeros((100,32,32,3))
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: t = np.zeros((100,32,32,3))
- en: t[:,2:30,2:30,0] = x_test[k:(k+100)]
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: t[:,2:30,2:30,0] = x_test[k:(k+100)]
- en: t[:,2:30,2:30,1] = x_test[k:(k+100)]
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: t[:,2:30,2:30,1] = x_test[k:(k+100)]
- en: t[:,2:30,2:30,2] = x_test[k:(k+100)]
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: t[:,2:30,2:30,2] = x_test[k:(k+100)]
- en: _ = model.predict(t)
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: _ = model.predict(t)
- en: out = [model.layers[5].output]
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: out = [model.layers[5].output]
- en: func = K.function([model.input, K.learning_phase()], out)
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: func = K.function([model.input, K.learning_phase()], out)
- en: test[k:(k+100),:] = func([t, 1.])[0]
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: test[k:(k+100),:] = func([t, 1.])[0]
- en: k += 100
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: k += 100
- en: np.save("mnist_test_embedded.npy", test)
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: np.save("mnist_test_embedded.npy", test)
- en: '*Listing 14-10: Running the MNIST images through the pretrained CIFAR-10 model*'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: '*列表 14-10：通过预训练的 CIFAR-10 模型运行 MNIST 图像*'
- en: There are 60,000 MNIST training images. We pass each through the Keras model
    in blocks of 100 to be more efficient than processing each image individually;
    this means we need to process 600 sets of 100\. We do the same for the test images,
    of which there are 10,000, so we process 100 sets of 100\. We’ll store the output
    vectors in `train` and `test`.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: MNIST 训练集有 60,000 张图像。我们将每 100 张图像一组地传递给 Keras 模型，以提高效率，而不是单独处理每张图像；这意味着我们需要处理
    600 组 100 张图像。同样，测试集有 10,000 张图像，因此我们处理 100 组 100 张图像。我们会将输出向量存储在 `train` 和 `test`
    中。
- en: 'The processing loop for both the train and test images first creates a temporary
    array, `t`, to hold the current set of 100 images. To use the Keras model `predict`
    method, we need a four-dimensional input: the number of images, height, width,
    and number of channels. We load `t` by copying the current set of 100 train or
    test images, indexed by `k`, to `t`; we do that three times, once for each channel
    ❶. With `t` loaded, we call the `predict` method of the model. We throw the output
    away, since we’re after the values output by the Dense layer of the Keras model.
    This is layer 5 for the shallow architecture ❷. The output of `func` is the 100
    output vectors of the Dense layer we get after passing the inputs through the
    network. We assign these to the current block of 100 in `train` and move to the
    next set of 100\. When we’ve processed the entire MNIST dataset, we keep the embedded
    vectors in a NumPy file. Then we repeat every step we used to process the training
    set for the test set.'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 对于训练和测试图像的处理循环，首先创建一个临时数组` t`来存储当前的 100 张图像。为了使用 Keras 模型的 `predict` 方法，我们需要一个四维输入：图像的数量、高度、宽度和通道数。我们通过将当前的
    100 张训练或测试图像（由 `k` 索引）复制到 `t` 中来加载 `t`；我们这样做三次，每次处理一个通道 ❶。加载完 `t` 后，我们调用模型的 `predict`
    方法。我们抛弃输出，因为我们关心的是 Keras 模型的 Dense 层输出的值。这是浅层架构的第 5 层 ❷。`func` 的输出是通过网络传递输入后，Dense
    层的 100 个输出向量。我们将这些向量分配到当前的 100 个 `train` 样本块中，然后转到下一组 100 个样本。当我们处理完整个 MNIST 数据集后，我们将嵌入向量保存在一个
    NumPy 文件中。然后我们重复处理训练集的每个步骤来处理测试集。
- en: At this point, we have our embedded vectors, so it’s natural to ask whether
    or not the embedding is helping separate the classes. We can see if this is true
    by using a t-SNE plot of the vectors by class label ([Figure 14-4](ch14.xhtml#ch14fig4)).
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们已经得到了嵌入向量，因此自然而然地会问嵌入是否有助于分离类。我们可以通过使用按类标签绘制的 t-SNE 向量图（[图 14-4](ch14.xhtml#ch14fig4)）来验证这一点。
- en: '![image](Images/14fig04.jpg)'
  id: totrans-346
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/14fig04.jpg)'
- en: '*Figure 14-4: t-SNE plot showing the separation by class for the embedded MNIST
    digit vectors*'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 14-4：t-SNE 图显示了按类分离的嵌入 MNIST 数字向量*'
- en: Compare this figure with [Figure 12-10](ch12.xhtml#ch12fig10), which shows the
    separation for a model trained explicitly on MNIST digits. That model shows a
    clear, unambiguous separation of the classes, but [Figure 14-4](ch14.xhtml#ch14fig4)
    is far less clear. However, even though there is overlap, there are concentrations
    of the classes in different parts of the plot, so we have some reason to hope
    that a model might be able to learn how to classify digits using these vectors.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 将此图与[图 12-10](ch12.xhtml#ch12fig10)进行比较，该图显示了一个显式在 MNIST 数字上训练的模型的分离情况。该模型显示了类之间明确无误的分离，但[图
    14-4](ch14.xhtml#ch14fig4)则远不如此清晰。然而，尽管存在重叠，图中不同部分仍然有类的集中分布，所以我们有理由相信，某个模型可能能够利用这些向量学习如何对数字进行分类。
- en: Let’s train some models using the embedded vectors. For this, we’ll head back
    into the world of classical machine learning. We’ll train some of the models we
    trained in [Chapter 7](ch07.xhtml#ch07) by using the vector form of the MNIST
    digits images.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用嵌入向量训练一些模型。为此，我们将回到经典机器学习的世界。我们将使用 MNIST 数字图像的向量形式训练在[第7章](ch07.xhtml#ch07)中训练过的一些模型。
- en: The code to train and test the models is straightforward. We’ll train a Nearest
    Centroid, 3-Nearest Neighbor, Random Forest with 50 trees, and a linear SVM with
    *C* = 0.1, as shown in [Listing 14-11](ch14.xhtml#ch14lis11).
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 训练和测试模型的代码是直接的。我们将训练一个最近质心模型、一个 3 最近邻模型、一个具有 50 棵树的随机森林和一个线性 SVM（*C* = 0.1），如[清单
    14-11](ch14.xhtml#ch14lis11)所示。
- en: from sklearn.neighbors import KNeighborsClassifier
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: from sklearn.neighbors import KNeighborsClassifier
- en: from sklearn.ensemble import RandomForestClassifier
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: from sklearn.ensemble import RandomForestClassifier
- en: from sklearn.neighbors import NearestCentroid
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: from sklearn.neighbors import NearestCentroid
- en: from sklearn.svm import LinearSVC
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: from sklearn.svm import LinearSVC
- en: clf0 = NearestCentroid()
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: clf0 = NearestCentroid()
- en: clf0.fit(train, y_train)
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: clf0.fit(train, y_train)
- en: nscore = clf0.score(test, y_test)
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: nscore = clf0.score(test, y_test)
- en: clf1 = KNeighborsClassifier(n_neighbors=3)
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: clf1 = KNeighborsClassifier(n_neighbors=3)
- en: clf1.fit(train, y_train)
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: clf1.fit(train, y_train)
- en: kscore = clf1.score(test, y_test)
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: kscore = clf1.score(test, y_test)
- en: clf2 = RandomForestClassifier(n_estimators=50)
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: clf2 = RandomForestClassifier(n_estimators=50)
- en: clf2.fit(train, y_train)
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: clf2.fit(train, y_train)
- en: rscore = clf2.score(test, y_test)
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: rscore = clf2.score(test, y_test)
- en: clf3 = LinearSVC(C=0.1)
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: clf3 = LinearSVC(C=0.1)
- en: clf3.fit(train, y_train)
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: clf3.fit(train, y_train)
- en: sscore = clf3.score(test, y_test)
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: sscore = clf3.score(test, y_test)
- en: 'print("Nearest Centroid    : %0.2f" % nscore)'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 'print("Nearest Centroid    : %0.2f" % nscore)'
- en: 'print("3-NN                : %0.2f" % kscore)'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 'print("3-NN                : %0.2f" % kscore)'
- en: 'print("Random Forest       : %0.2f" % rscore)'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 'print("随机森林       : %0.2f" % rscore)'
- en: 'print("SVM                 : %0.2f" % sscore)'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 'print("SVM                 : %0.2f" % sscore)'
- en: '*Listing 14-11: Training classical models using the MNIST embedded vectors*'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单14-11：使用MNIST嵌入向量训练经典模型*'
- en: We load the relevant sklearn modules, create the specific model instances, and
    call `fit`, passing in the 128-element training vectors and the associated class
    labels. The `score` method returns the overall accuracy of the now trained model
    on the test set.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 我们加载相关的sklearn模块，创建特定的模型实例，并调用`fit`，传入128维的训练向量和相应的类别标签。`score`方法返回当前已训练模型在测试集上的整体准确度。
- en: Running this code gives us scores of
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 运行这段代码可以得到以下分数：
- en: '| **Model** | **Score** |'
  id: totrans-374
  prefs: []
  type: TYPE_TB
  zh: '| **模型** | **得分** |'
- en: '| --- | --- |'
  id: totrans-375
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Nearest Centroid | 0.6799 |'
  id: totrans-376
  prefs: []
  type: TYPE_TB
  zh: '| 最近质心（Nearest Centroid） | 0.6799 |'
- en: '| 3-Nearest Neighbors | 0.9010 |'
  id: totrans-377
  prefs: []
  type: TYPE_TB
  zh: '| 3-最近邻（3-Nearest Neighbors） | 0.9010 |'
- en: '| Random Forest (50) | 0.8837 |'
  id: totrans-378
  prefs: []
  type: TYPE_TB
  zh: '| 随机森林 (50) | 0.8837 |'
- en: '| SVM (C=0.1) | 0.8983 |'
  id: totrans-379
  prefs: []
  type: TYPE_TB
  zh: '| SVM (C=0.1) | 0.8983 |'
- en: 'which we can compare to the scaled scores for same models in [Table 7-10](ch07.xhtml#ch7tab10):'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将其与同一模型在[表 7-10](ch07.xhtml#ch7tab10)中缩放后的得分进行比较：
- en: '| **Model** | **Score** |'
  id: totrans-381
  prefs: []
  type: TYPE_TB
  zh: '| **模型** | **得分** |'
- en: '| --- | --- |'
  id: totrans-382
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Nearest Centroid | 0.8203 |'
  id: totrans-383
  prefs: []
  type: TYPE_TB
  zh: '| 最近质心（Nearest Centroid） | 0.8203 |'
- en: '| 3-Nearest Neighbors | 0.9705 |'
  id: totrans-384
  prefs: []
  type: TYPE_TB
  zh: '| 3-最近邻（3-Nearest Neighbors） | 0.9705 |'
- en: '| Random Forest (50) | 0.9661 |'
  id: totrans-385
  prefs: []
  type: TYPE_TB
  zh: '| 随机森林 (50) | 0.9661 |'
- en: '| SVM (C =0.1) | 0.9181 |'
  id: totrans-386
  prefs: []
  type: TYPE_TB
  zh: '| SVM (C =0.1) | 0.9181 |'
- en: 'Clearly, in this case, our embedding is not giving us a head start over the
    raw data. We should not be surprised by this: we knew our two datasets were fairly
    distinct, and the t-SNE plot showed that the pretrained CIFAR-10 model was not
    ideally suited to separating the MNIST images in the embedding space. The poor
    separation of the classes in [Figure 14-4](ch14.xhtml#ch14fig4) explains the poor
    performance of the Nearest Centroid model: 68 percent accuracy versus 82 percent
    when trained on the digit images themselves. Moreover, by their very nature, digit
    images are already distinct from each other, especially on a uniform background,
    since the digits were intended by humans to be easily distinguished by sight.'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，在这种情况下，我们的嵌入方式并没有给我们带来比原始数据更多的优势。对此我们不应该感到惊讶：我们知道我们的两个数据集是相当不同的，并且t-SNE图表显示预训练的CIFAR-10模型并不适合在嵌入空间中区分MNIST图像。图[14-4](ch14.xhtml#ch14fig4)中类别的分离效果差解释了最近质心模型表现不佳的原因：68%的准确率与在手写数字图像上训练时的82%相比差距明显。而且，从本质上来说，数字图像本身就已经是彼此区分开的，尤其是在统一背景下，因为这些数字是由人类设计的，目的是让视觉上容易区分。
- en: 'A bit of code gives us the confusion matrix for any of these models:'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 一段代码可以为我们提供任何这些模型的混淆矩阵：
- en: '[PRE8]'
  id: totrans-389
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Here `clf` is any of the models, `test` is the embedded test set, and `y_test`
    is the labels. We return the confusion matrix with counts in each element, so
    we divide by the sum of the rows, since the row represents the true label, and
    multiply by 100 to get percents. Then we print the array using NumPy commands
    to get a single digit of accuracy and no scientific notation.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 这里`clf`是任何一个模型，`test`是嵌入后的测试集，`y_test`是标签。我们返回包含每个元素计数的混淆矩阵，所以我们按行的总和进行除法操作，因为每一行代表真实标签，然后乘以100来得到百分比。接着，我们使用NumPy命令打印数组，获得单一数字的准确率，且不会使用科学记数法。
- en: 'We know already why the Nearest Centroid result is so poor. What about the
    Random Forest and SVM? The confusion matrix for the Random Forest model is shown
    here:'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经知道为什么最近质心（Nearest Centroid）结果这么差。那么随机森林（Random Forest）和支持向量机（SVM）怎么样呢？下面是随机森林模型的混淆矩阵：
- en: '| **Class** | **0** | **1** | **2** | **3** | **4** | **5** | **6** | **7**
    | **8** | **9** |'
  id: totrans-392
  prefs: []
  type: TYPE_TB
  zh: '| **类别** | **0** | **1** | **2** | **3** | **4** | **5** | **6** | **7** |
    **8** | **9** |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-393
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| **0** | 96.7 | 0.0 | 0.5 | 0.5 | 0.4 | 0.2 | 0.9 | 0.0 | 0.4 | 0.3 |'
  id: totrans-394
  prefs: []
  type: TYPE_TB
  zh: '| **0** | 96.7 | 0.0 | 0.5 | 0.5 | 0.4 | 0.2 | 0.9 | 0.0 | 0.4 | 0.3 |'
- en: '| **1** | 0.0 | 98.6 | 0.5 | 0.0 | 0.4 | 0.1 | 0.4 | 0.0 | 0.1 | 0.1 |'
  id: totrans-395
  prefs: []
  type: TYPE_TB
  zh: '| **1** | 0.0 | 98.6 | 0.5 | 0.0 | 0.4 | 0.1 | 0.4 | 0.0 | 0.1 | 0.1 |'
- en: '| **2** | 1.8 | 0.2 | 87.0 | 2.5 | 1.0 | 1.0 | 1.7 | 0.8 | 4.1 | 0.6 |'
  id: totrans-396
  prefs: []
  type: TYPE_TB
  zh: '| **2** | 1.8 | 0.2 | 87.0 | 2.5 | 1.0 | 1.0 | 1.7 | 0.8 | 4.1 | 0.6 |'
- en: '| **3** | 1.1 | 0.1 | 2.5 | **80.8** | 0.2 | **6.7** | 0.9 | 1.1 | **6.0**
    | 1.6 |'
  id: totrans-397
  prefs: []
  type: TYPE_TB
  zh: '| **3** | 1.1 | 0.1 | 2.5 | **80.8** | 0.2 | **6.7** | 0.9 | 1.1 | **6.0**
    | 1.6 |'
- en: '| **4** | 0.3 | 0.4 | 1.3 | 0.0 | 88.3 | 0.1 | 1.9 | 1.7 | 0.6 | 5.2 |'
  id: totrans-398
  prefs: []
  type: TYPE_TB
  zh: '| **4** | 0.3 | 0.4 | 1.3 | 0.0 | 88.3 | 0.1 | 1.9 | 1.7 | 0.6 | 5.2 |'
- en: '| **5** | 0.6 | 0.8 | 0.7 | **9.8** | 1.6 | **78.8** | **1.8** | 1.1 | 1.6
    | 0.8 |'
  id: totrans-399
  prefs: []
  type: TYPE_TB
  zh: '| **5** | 0.6 | 0.8 | 0.7 | **9.8** | 1.6 | **78.8** | **1.8** | 1.1 | 1.6
    | 0.8 |'
- en: '| **6** | 3.0 | 0.4 | 0.6 | 0.0 | 0.7 | 1.0 | 93.5 | 0.2 | 0.4 | 0.0 |'
  id: totrans-400
  prefs: []
  type: TYPE_TB
  zh: '| **6** | 3.0 | 0.4 | 0.6 | 0.0 | 0.7 | 1.0 | 93.5 | 0.2 | 0.4 | 0.0 |'
- en: '| **7** | 0.2 | 1.0 | 2.9 | 0.1 | 2.7 | 0.4 | 0.0 | 87.7 | 0.7 | 4.4 |'
  id: totrans-401
  prefs: []
  type: TYPE_TB
  zh: '| **7** | 0.2 | 1.0 | 2.9 | 0.1 | 2.7 | 0.4 | 0.0 | 87.7 | 0.7 | 4.4 |'
- en: '| **8** | 1.4 | 0.1 | 2.7 | 5.0 | 1.5 | 1.6 | 0.6 | 0.8 | 84.0 | 2.0 |'
  id: totrans-402
  prefs: []
  type: TYPE_TB
  zh: '| **8** | 1.4 | 0.1 | 2.7 | 5.0 | 1.5 | 1.6 | 0.6 | 0.8 | 84.0 | 2.0 |'
- en: '| **9** | 2.2 | 0.2 | 1.3 | 1.6 | 2.9 | 0.6 | 0.3 | 3.4 | 1.5 | 86.2 |'
  id: totrans-403
  prefs: []
  type: TYPE_TB
  zh: '| **9** | 2.2 | 0.2 | 1.3 | 1.6 | 2.9 | 0.6 | 0.3 | 3.4 | 1.5 | 86.2 |'
- en: We’ve highlighted the two lowest-performing classes, 3 and 5, along with the
    two digits they are most often confused with. We see that the model is confusing
    3’s with 5’s and 8’s. The SVM confusion matrix shows the same effect. If we take
    [Figure 14-4](ch14.xhtml#ch14fig4) and show only classes 3, 5, and 8, then we
    get [Figure 14-5](ch14.xhtml#ch14fig5). Considerable mixing between the classes
    is plain to see.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经突出了表现最差的两个类别，3和5，并标出了它们最常混淆的两个数字。我们看到模型将3与5和8混淆。SVM的混淆矩阵也显示了相同的效果。如果我们查看[图14-4](ch14.xhtml#ch14fig4)，并只显示类别3、5和8，那么我们会得到[图14-5](ch14.xhtml#ch14fig5)。这三者之间有显著的混淆。
- en: '![image](Images/14fig05.jpg)'
  id: totrans-405
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/14fig05.jpg)'
- en: '*Figure 14-5: t-SNE plot showing class 3 (plus), class 5 (cross), and class
    8 (triangle right)*'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: '*图14-5：t-SNE图，显示类别3（加号）、类别5（叉号）和类别8（右三角形）*'
- en: The purpose of this section was to introduce the idea of transfer learning through
    an example that used the datasets we had on hand. As you can see, this experiment
    was not a success. The datasets we used were very different from each other, so
    we might have expected this to be the case, but it was useful to verify for ourselves.
    In the next section, we’ll see how we can go one step beyond transfer learning.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的目的是通过一个使用我们手头数据集的示例介绍迁移学习的概念。正如你所看到的，这个实验并不成功。我们使用的数据集彼此差异很大，因此我们本来就可能预料到这种情况，但通过验证这一点，我们还是获得了有用的信息。在下一节中，我们将看到如何在迁移学习的基础上更进一步。
- en: Fine-Tuning a Model
  id: totrans-408
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 微调模型
- en: In the previous section, we defined transfer learning as using weights from
    a model trained on one dataset with data from a (hopefully very similar) dataset.
    We used the weights to map the inputs to a new space and trained models on the
    mapped data. In this section, we’ll do something similar, but instead of leaving
    the weights as they are, we’ll let the weights vary while we continue training
    the model with a new, smaller dataset. We are calling this *fine-tuning*.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，我们将迁移学习定义为使用一个在某个数据集上训练过的模型的权重，并将这些权重应用于一个（希望非常相似的）新数据集。我们利用这些权重将输入映射到一个新的空间，并在映射后的数据上训练模型。在这一节中，我们将做类似的事情，但与其保持权重不变，我们将在继续训练模型的过程中，让权重随着新的、更小的数据集而变化。我们称之为*微调*。
- en: In fine-tuning, we are training a neural network, but instead of initializing
    the weights to random values, selected according to an intelligent initialization
    scheme, we start with the weights from a model trained on a similar but different
    dataset. We might use fine-tuning when we do not have a lot of training data,
    but we believe our data comes from a distribution that’s very similar to one for
    which we have either a lot of data or a trained model. For example, we might have
    access to the weights of a large model trained with a large dataset, like the
    ImageNet dataset we’ve mentioned previously. It is quite simple to download such
    a pretrained model. Additionally, we might have a small dataset of images for
    classes that are not in ImageNet; say, photographs of guppies, angelfish, and
    tetras. These are popular freshwater aquarium fish not in ImageNet. We can start
    with a larger model pretrained on ImageNet and fine-tune using the smaller fish
    dataset. That way, we can take advantage of the fact that the model is already
    well adapted to inputs of this kind and, hopefully, get a good model with a small
    dataset.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 在微调中，我们正在训练一个神经网络，但不是将权重初始化为随机值（这些随机值是根据智能初始化方案选择的），而是从一个在相似但不同数据集上训练的模型开始。我们可能在没有大量训练数据的情况下使用微调，但我们相信我们的数据来自于与我们已有大量数据或训练模型的数据分布非常相似的情况。例如，我们可能能够访问一个使用大数据集训练的大型模型的权重，就像我们之前提到的ImageNet数据集。下载这样的预训练模型非常简单。此外，我们可能拥有一个小数据集，包含ImageNet中没有的类别的图像；比如说，孔雀鱼、天使鱼和四线鱼的照片。这些是流行的淡水观赏鱼，ImageNet中没有。我们可以从一个在ImageNet上预训练的大模型开始，并利用这个小型鱼类数据集进行微调。这样，我们就能够利用模型已经很好地适应此类输入的事实，并希望通过小数据集获得一个好的模型。
- en: Our experiment will use CIFAR-10\. Our goal is to train a model to differentiate
    between images of dogs and cats using the deep architecture from the first section
    of this chapter. However, our dataset is small; we have approximately 500 images
    of each class to work with. We also have a larger dataset, all the vehicles from
    CIFAR-10.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实验将使用CIFAR-10数据集。我们的目标是训练一个模型，利用本章第一节中的深度架构区分狗和猫的图像。然而，我们的数据集较小；每个类别大约有500张图片。我们还拥有一个更大的数据集，包含CIFAR-10中的所有车辆图像。
- en: 'Therefore, we’ll train the following models with this data:'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们将使用这些数据训练以下模型：
- en: The shallow architecture using the small dog and cat dataset.
  id: totrans-413
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用小型狗猫数据集的浅层架构。
- en: The deep architecture using the small dog and cat dataset.
  id: totrans-414
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用小型狗猫数据集的深度架构。
- en: The deep architecture pretrained on the vehicle data and fine-tuned on the small
    dog and cat dataset.
  id: totrans-415
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在车辆数据上预训练并在小型狗猫数据集上微调的深度架构。
- en: For the last case, we’ll train several variations using different combinations
    of frozen weights.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 对于最后的情况，我们将使用不同的冻结权重组合训练几个变体。
- en: Building Our Datasets
  id: totrans-417
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 构建我们的数据集
- en: Before we get to fine-tuning, we need to build our datasets. We’ll use unaugmented
    CIFAR-10 to construct the small dog and cat dataset. We’ll use *augmented* CIFAR-10
    to construct the vehicle dataset. We augmented CIFAR-10 in [Chapter 5](ch05.xhtml#ch05).
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行微调之前，我们需要构建我们的数据集。我们将使用未增强的CIFAR-10来构建小型狗猫数据集。我们将使用*增强过的* CIFAR-10来构建车辆数据集。我们在[第5章](ch05.xhtml#ch05)中增强了CIFAR-10。
- en: Building the small dog and cat dataset is straightforward, as shown in [Listing
    14-12](ch14.xhtml#ch14lis12).
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 构建小型狗猫数据集是直接的，如[清单 14-12](ch14.xhtml#ch14lis12)所示。
- en: x_train = np.load("cifar10_train_images.npy")[:,2:30,2:30,:]
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: x_train = np.load("cifar10_train_images.npy")[:,2:30,2:30,:]
- en: y_train = np.load("cifar10_train_labels.npy")
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: y_train = np.load("cifar10_train_labels.npy")
- en: x_test = np.load("cifar10_test_images.npy")[:,2:30,2:30,:]
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: x_test = np.load("cifar10_test_images.npy")[:,2:30,2:30,:]
- en: y_test = np.load("cifar10_test_labels.npy")
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: y_test = np.load("cifar10_test_labels.npy")
- en: xtrn = []; ytrn = []
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: xtrn = []; ytrn = []
- en: xtst = []; ytst = []
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: xtst = []; ytst = []
- en: 'for i in range(y_train.shape[0]):'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 'for i in range(y_train.shape[0]):'
- en: 'if (y_train[i]==3):'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 'if (y_train[i]==3):'
- en: xtrn.append(x_train[i])
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: xtrn.append(x_train[i])
- en: ytrn.append(0)
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: ytrn.append(0)
- en: 'if (y_train[i]==5):'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 'if (y_train[i]==5):'
- en: xtrn.append(x_train[i])
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: xtrn.append(x_train[i])
- en: ytrn.append(1)
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: ytrn.append(1)
- en: 'for i in range(y_test.shape[0]):'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 'for i in range(y_test.shape[0]):'
- en: 'if (y_test[i]==3):'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 'if (y_test[i]==3):'
- en: xtst.append(x_test[i])
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: xtst.append(x_test[i])
- en: ytst.append(0)
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: ytst.append(0)
- en: 'if (y_test[i]==5):'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 'if (y_test[i]==5):'
- en: xtst.append(x_test[i])
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: xtst.append(x_test[i])
- en: ytst.append(1)
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: ytst.append(1)
- en: np.save("cifar10_train_cat_dog_small_images.npy", np.array(xtrn)[:1000])
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: np.save("cifar10_train_cat_dog_small_images.npy", np.array(xtrn)[:1000])
- en: np.save("cifar10_train_cat_dog_small_labels.npy", np.array(ytrn)[:1000])
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: np.save("cifar10_train_cat_dog_small_labels.npy", np.array(ytrn)[:1000])
- en: np.save("cifar10_test_cat_dog_small_images.npy", np.array(xtst)[:1000])
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: np.save("cifar10_test_cat_dog_small_images.npy", np.array(xtst)[:1000])
- en: np.save("cifar10_test_cat_dog_small_labels.npy", np.array(ytst)[:1000])
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: np.save("cifar10_test_cat_dog_small_labels.npy", np.array(ytst)[:1000])
- en: '*Listing 14-12: Building the small dog and cat dataset*'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单 14-12：构建小型狗猫数据集*'
- en: We load the full CIFAR-10 data, train and test, and then loop over each sample.
    If the class is 3, cat, or 5, dog, we add the image and label to our lists, making
    sure to recode the class label so that 0 is cat and 1 is dog. When all the samples
    have been added, we keep the first 1,000 and write them to disk to be our small
    dog and cat training and test sets. Keeping the first 1,000 samples gives us a
    dataset that is close to split 50/50 between classes.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 我们加载完整的CIFAR-10数据，进行训练和测试，然后遍历每个样本。如果类别是3（猫）或5（狗），我们将图像和标签添加到我们的列表中，并确保重新编码类别标签，使0表示猫，1表示狗。当所有样本都添加完毕后，我们保留前1000个并写入磁盘，作为我们的小型狗猫训练和测试集。保留前1000个样本让我们得到一个大约50/50分配的类别数据集。
- en: Notice that immediately after loading the CIFAR-10 images, we subscript them
    with `[:,2:30,2:30,:]`. Recall, the augmented version of the dataset includes
    small shifts of the image, so when we built it in [Chapter 5](ch05.xhtml#ch05),
    we reduced the size from 32 × 32 to 28 × 8\. Therefore, when we build our vehicle
    dataset, we’ll be working with images that are 28×28 pixels. The subscript extracts
    the center 28 × 28 region of each image. The first dimension is the number of
    images in the train or test set. The last dimension is the number of channels—three
    since these are RGB images.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在加载CIFAR-10图像后，我们通过`[:,2:30,2:30,:]`进行下标切片。回想一下，增强版本的数据集包括图像的微小偏移，因此当我们在[第5章](ch05.xhtml#ch05)中构建它时，将尺寸从32×32减少到28×28。因此，当我们构建车辆数据集时，我们将处理28×28像素的图像。下标提取了每张图像的中心28×28区域。第一个维度是训练集或测试集中的图像数量。最后一个维度是通道数——由于这些是RGB图像，因此为三个通道。
- en: Building the vehicle dataset is equally straightforward ([Listing 14-13](ch14.xhtml#ch14lis13)).
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 构建车辆数据集同样简单直接（[列表 14-13](ch14.xhtml#ch14lis13)）。
- en: x_train = np.load("cifar10_aug_train_images.npy")
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: x_train = np.load("cifar10_aug_train_images.npy")
- en: y_train = np.load("cifar10_aug_train_labels.npy")
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: y_train = np.load("cifar10_aug_train_labels.npy")
- en: x_test = np.load("cifar10_aug_test_images.npy")
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: x_test = np.load("cifar10_aug_test_images.npy")
- en: y_test = np.load("cifar10_test_labels.npy")
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: y_test = np.load("cifar10_test_labels.npy")
- en: vehicles= [0,1,8,9]
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: vehicles= [0,1,8,9]
- en: xv_train = []; xv_test = []
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: xv_train = []; xv_test = []
- en: yv_train = []; yv_test = []
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: yv_train = []; yv_test = []
- en: 'for i in range(y_train.shape[0]):'
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 'for i in range(y_train.shape[0]):'
- en: 'if (y_train[i] in vehicles):'
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 'if (y_train[i] in vehicles):'
- en: xv_train.append(x_train[i])
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: xv_train.append(x_train[i])
- en: yv_train.append(vehicles.index(y_train[i]))
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: yv_train.append(vehicles.index(y_train[i]))
- en: 'for i in range(y_test.shape[0]):'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 'for i in range(y_test.shape[0]):'
- en: 'if (y_test[i] in vehicles):'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 'if (y_test[i] in vehicles):'
- en: xv_test.append(x_test[i])
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: xv_test.append(x_test[i])
- en: yv_test.append(vehicles.index(y_test[i]))
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: yv_test.append(vehicles.index(y_test[i]))
- en: np.save("cifar10_train_vehicles_images.npy", np.array(xv_train))
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: np.save("cifar10_train_vehicles_images.npy", np.array(xv_train))
- en: np.save("cifar10_train_vehicles_labels.npy", np.array(yv_train))
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: np.save("cifar10_train_vehicles_labels.npy", np.array(yv_train))
- en: np.save("cifar10_test_vehicles_images.npy", np.array(xv_test))
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: np.save("cifar10_test_vehicles_images.npy", np.array(xv_test))
- en: np.save("cifar10_test_vehicles_labels.npy", np.array(yv_test))
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: np.save("cifar10_test_vehicles_labels.npy", np.array(yv_test))
- en: '*Listing 14-13: Building the vehicle dataset*'
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: '*列表 14-13：构建车辆数据集*'
- en: Here we work with the augmented versions. The augmented test set is 28×28 pixels
    per image using the central region of the original test set. Also, as we loop
    through the train and test sets looking for samples that are in one of the vehicle
    classes, we can do our recoding of the class label by asking for the index into
    the vehicles list of the element matching the current sample’s class label, hence
    using `index` on `vehicles`. The vehicle dataset has 200,000 samples in the training
    set, 50,000 from each of the four classes.
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用增强后的版本。增强后的测试集每张图像为28×28像素，使用原始测试集的中心区域。此外，当我们遍历训练集和测试集，寻找属于某一车辆类别的样本时，可以通过索引车辆类别列表来重新编码类别标签，因此使用`index`来查找`vehicles`中的当前样本的类别标签。车辆数据集在训练集中的样本数为200,000，其中每个类别有50,000个样本。
- en: To proceed then, we need to (1) train the deep model on the vehicle dataset;
    (2) adapt the model to the dog and cat dataset; and (3) train the deep model initialized
    with the weights from the vehicle model. We’ll also train the shallow and deep
    models from scratch, using the dog and cat dataset for comparison purposes.
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要进行以下操作：（1）在车辆数据集上训练深度模型；（2）将模型调整到狗和猫数据集；（3）使用车辆模型的权重初始化深度模型并进行训练。我们还将从头开始训练浅层和深度模型，使用狗和猫数据集进行对比。
- en: 'We gave the code for the deep model in the first section of this chapter so
    we won’t reproduce it here. In particular, see [Listing 14-3](ch14.xhtml#ch14lis3).
    The code itself is in the file *cifar10_cnn_vehicles.py*. The relevant changes
    for the vehicle model are shown here:'
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本章的第一节中提供了深度模型的代码，因此这里不再重复。具体请参见[列表 14-3](ch14.xhtml#ch14lis3)。代码本身位于文件 *cifar10_cnn_vehicles.py*
    中。与车辆模型相关的更改如下所示：
- en: '[PRE9]'
  id: totrans-471
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We use a minibatch size of 64\. There are four classes (airplane, automobile,
    ship, truck), and we’ll train for 12 epochs. When we’re done training, we’ll store
    the model in *cifar10_cnn_vehicles_model.h5* so we can use its weights and biases
    for fine-tuning the dog and cat model. Training this model takes several hours
    on our CPU system. The final test accuracy is 88.2 percent, so it is performing
    well enough for our purposes.
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用64的迷你批次大小。共有四个类别（飞机、汽车、船、卡车），我们将训练12个epoch。训练完成后，我们将把模型存储在*cifar10_cnn_vehicles_model.h5*文件中，以便我们可以使用它的权重和偏差来微调狗和猫的模型。这个模型的训练在我们的CPU系统上需要几个小时。最终的测试准确率为88.2%，因此它的表现足以满足我们的需求。
- en: Adapting Our Model for Fine-Tuning
  id: totrans-473
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 调整我们的模型以进行微调
- en: Now we need to adapt the vehicle model for the dog and cat dataset and fine-tuning.
    Specifically, we need to replace the top softmax layer that expects four classes
    with one that expects two. We also need to decide which layer’s weights we’ll
    freeze and which we’ll update during training. This step is essential, and we’ll
    see how our choices affect the fine-tuning results.
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要调整车辆模型以适应狗和猫数据集并进行微调。具体来说，我们需要将期望四个类别的顶部softmax层替换为期望两个类别的层。我们还需要决定在训练过程中冻结哪些层的权重，更新哪些层的权重。这个步骤至关重要，我们将看到我们的选择如何影响微调的结果。
- en: When fine-tuning, it’s standard practice to freeze lower-level weights; they
    are not updated at all when training. The idea here is that if our new data is
    similar to the data used for the pretraining step, the lower levels of the model
    are already adapted, and we should not change them. We allow only the higher-level
    layers to change as these are the ones that need to learn about the representation
    of the new data. Which layers we freeze and which we allow to train depends on
    the size of the model and the data itself. Experimentation is required. Note that
    the transfer learning of the previous section can be considered fine-tuning with
    all the weights frozen.
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 在微调时，通常的做法是冻结低层权重；它们在训练过程中完全不会更新。这里的想法是，如果我们的新数据与预训练步骤中使用的数据相似，那么模型的低层已经适应了这些数据，我们不应该去改变它们。我们只允许高层网络进行调整，因为这些层需要学习新数据的表示。我们冻结哪些层，允许训练哪些层，取决于模型的大小和数据本身。这需要实验。请注意，上一节中的迁移学习可以看作是将所有权重冻结的微调。
- en: 'Note that if we’re using SGD with fine-tuning, we typically reduce the learning
    rate by a factor of, say, 10\. The rationale is the same as for freezing the lower-level
    weights: the model is already “close” to a desired minimum of the error function,
    so we don’t need big steps to find it. Our experiment will use Adadelta, which
    will adjust the learning rate step size for us.'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，如果我们在微调时使用SGD，通常会将学习率降低一个数量级，比如10。这样做的原因与冻结低层权重时的思路相同：模型已经“接近”误差函数的理想最小值，因此我们不需要大的步长来找到它。我们的实验将使用Adadelta，它会自动调整学习率的步长。
- en: The deep model has multiple convolutional layers. We’ll experiment with freezing
    the first two; these are the lowest and are most likely already tuned to the low-level
    features of the CIFAR-10 dataset, at least the vehicles. Of course, since our
    dog and cat images come from CIFAR-10 as well, we know that they are from the
    same parent distribution or domain as the vehicle images. We’ll also experiment
    with a model that freezes all the convolutional layers and allows only the dense
    layers to be adapted during training. Doing this is reminiscent of transfer learning,
    though we’ll allow the dense layers to update their weights.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 深度模型有多个卷积层。我们将尝试冻结前两个层；它们是最底层的，可能已经调整为适应CIFAR-10数据集中的低层特征，至少是车辆部分。当然，由于我们的狗和猫图像也来自CIFAR-10，因此我们知道它们与车辆图像来自相同的父分布或领域。我们还将尝试一个冻结所有卷积层，只允许密集层在训练期间进行调整的模型。这样做类似于迁移学习，尽管我们允许密集层更新它们的权重。
- en: Let’s create the code for fine-tuning by using the vehicle model that we trained
    earlier ([Listing 14-14](ch14.xhtml#ch14lis14)).
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过使用我们之前训练的车辆模型来创建微调的代码（[Listing 14-14](ch14.xhtml#ch14lis14)）。
- en: import keras
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: import keras
- en: from keras.models import load_model
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: from keras.models import load_model
- en: from keras.layers import Dense
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: from keras.layers import Dense
- en: from keras import backend as K
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: from keras import backend as K
- en: import numpy as np
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: import numpy as np
- en: batch_size = 64
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: batch_size = 64
- en: num_classes = 2
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: num_classes = 2
- en: epochs = 36
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: epochs = 36
- en: img_rows, img_cols = 28,28
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: img_rows, img_cols = 28,28
- en: x_train = np.load("cifar10_train_cat_dog_small_images.npy")
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: x_train = np.load("cifar10_train_cat_dog_small_images.npy")
- en: y_train = np.load("cifar10_train_cat_dog_small_labels.npy")
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: y_train = np.load("cifar10_train_cat_dog_small_labels.npy")
- en: x_test = np.load("cifar10_test_cat_dog_small_images.npy")
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: x_test = np.load("cifar10_test_cat_dog_small_images.npy")
- en: y_test = np.load("cifar10_test_cat_dog_small_labels.npy")
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: y_test = np.load("cifar10_test_cat_dog_small_labels.npy")
- en: 'if K.image_data_format() == ''channels_first'':'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 'if K.image_data_format() == ''channels_first'':'
- en: x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)
- en: x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)
- en: input_shape = (3, img_rows, img_cols)
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: input_shape = (3, img_rows, img_cols)
- en: 'else:'
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 'else:'
- en: x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)
- en: x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)
- en: input_shape = (img_rows, img_cols, 3)
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: input_shape = (img_rows, img_cols, 3)
- en: x_train = x_train.astype('float32')
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: x_train = x_train.astype('float32')
- en: x_test = x_test.astype('float32')
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: x_test = x_test.astype('float32')
- en: x_train /= 255
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: x_train /= 255
- en: x_test /= 255
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: x_test /= 255
- en: y_train = keras.utils.to_categorical(y_train, num_classes)
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: y_train = keras.utils.to_categorical(y_train, num_classes)
- en: y_test = keras.utils.to_categorical(y_test, num_classes)
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: y_test = keras.utils.to_categorical(y_test, num_classes)
- en: '*Listing 14-14: Fine-tuning the vehicle model. See* cifar10_cnn_cat_dog_fine_tune_3.py.'
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: '*示例 14-14：微调车辆模型。参见* cifar10_cnn_cat_dog_fine_tune_3.py。'
- en: These lines should be familiar by now. First we load and preprocess the small
    dog and cat dataset. Note that we are using a minibatch size of 64, two classes
    (0 = cat, 1 = dog), and 36 epochs.
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 这些行现在应该很熟悉了。首先我们加载并预处理小型的猫狗数据集。注意，我们使用的批量大小为64，类别为两个（0 = 猫，1 = 狗），并且设置为36个训练周期。
- en: Next, we need to load the vehicle model, strip off its top layer, and replace
    it with a two-class softmax ([Listing 14-15](ch14.xhtml#ch14lis15)). This is also
    where we will freeze some combination of the first two convolutional layers.
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要加载车辆模型，移除其顶部层，并用一个两类的 softmax 层替代（[示例 14-15](ch14.xhtml#ch14lis15)）。这里也是我们冻结前两个卷积层某些组合的地方。
- en: model = load_model("cifar10_cnn_vehicles_model.h5")
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: model = load_model("cifar10_cnn_vehicles_model.h5")
- en: ❶ model.layers.pop()
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ model.layers.pop()
- en: ❷ model.outputs = [model.layers[-1].output]
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ model.outputs = [model.layers[-1].output]
- en: model.layers[-1].outbound_nodes = []
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: model.layers[-1].outbound_nodes = []
- en: ❸ model.add(Dense(num_classes, name="softmax", activation='softmax'))
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ model.add(Dense(num_classes, name="softmax", activation='softmax'))
- en: ❹ model.layers[0].trainable = False
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ model.layers[0].trainable = False
- en: model.layers[1].trainable = False
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: model.layers[1].trainable = False
- en: model.compile(loss=keras.losses.categorical_crossentropy,
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: model.compile(loss=keras.losses.categorical_crossentropy,
- en: optimizer=keras.optimizers.Adadelta(),
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: optimizer=keras.optimizers.Adadelta(),
- en: metrics=['accuracy'])
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: metrics=['accuracy'])
- en: '*Listing 14-15: Adjusting the vehicle model for dogs and cats*'
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: '*示例 14-15：调整车辆模型以适应猫狗数据集*'
- en: After we load the model, we use Keras to remove the top layer ❶. We need to
    patch the model to make the next-to-top layer look like the top layer; this allows
    the `add` method to work correctly ❷. Then, we add a new softmax layer for two
    classes ❸. This example is set to freeze the weights of the first two convolutional
    layers ❹. We’ll test each possible combination involving the first two convolutional
    layers. Finally, we compile the updated model and specify the Adadelta optimizer.
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: 加载模型后，我们使用 Keras 移除顶部层 ❶。我们需要修改模型，使得倒数第二层看起来像顶部层；这样可以确保`add`方法正确工作 ❷。接着，我们为两个类别添加一个新的
    softmax 层 ❸。本例设置冻结前两个卷积层的权重 ❹。我们将测试涉及前两个卷积层的每种可能组合。最后，我们编译更新后的模型，并指定 Adadelta
    优化器。
- en: We train the model by calling the `fit` method, as before as shown in [Listing
    14-16](ch14.xhtml#ch14lis16).
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过调用`fit`方法来训练模型，正如之前在[示例 14-16](ch14.xhtml#ch14lis16)中所示。
- en: score = model.evaluate(x_test[100:], y_test[100:], verbose=0)
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: score = model.evaluate(x_test[100:], y_test[100:], verbose=0)
- en: print('Initial test loss:', score[0])
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: print('初始测试损失：', score[0])
- en: print('Initial test accuracy:', score[1])
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: print('初始测试准确率：', score[1])
- en: history = model.fit(x_train, y_train,
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: history = model.fit(x_train, y_train,
- en: batch_size=batch_size,
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: batch_size=batch_size,
- en: epochs=epochs,
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: epochs=epochs,
- en: verbose=0,
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: verbose=0,
- en: validation_data=(x_test[:100], y_test[:100]))
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: validation_data=(x_test[:100], y_test[:100]))
- en: score = model.evaluate(x_test[100:], y_test[100:], verbose=0)
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: score = model.evaluate(x_test[100:], y_test[100:], verbose=0)
- en: print('Test loss:', score[0])
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: print('测试损失：', score[0])
- en: print('Test accuracy:', score[1])
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
  zh: print('测试准确率：', score[1])
- en: model.save("cifar10_cnn_cat_dog_fine_tune_3_model.h5")
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
  zh: model.save("cifar10_cnn_cat_dog_fine_tune_3_model.h5")
- en: '*Listing 14-16: Training and testing the dog and cat model*'
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: '*示例 14-16：训练和测试猫狗模型*'
- en: We are calling `evaluate` using the last 90 percent of the test data, *before*
    calling `fit`. This will give us an indication of how well the dog and cat model
    does when using the vehicle weights as they are. Then we call `fit` and `evaluate`
    a second time. Finally, we save the model and the training history. This model
    froze both of the first two convolutional layers. Other models will freeze or
    unfreeze these layers for the remaining three possibilities.
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在调用 `fit` 之前，使用最后 90% 的测试数据调用 `evaluate`。这将给我们一个关于狗与猫模型在使用车辆权重时表现如何的指示。然后我们第二次调用
    `fit` 和 `evaluate`。最后，我们保存模型和训练历史。这些模型冻结了前两个卷积层。其他模型将在剩余的三种可能性中冻结或解冻这些层。
- en: 'We mentioned earlier that we’d also train a model by freezing all of the convolutional
    layers. In essence, this is saying that we want to preserve whatever new representation
    the vehicle model learned and apply it directly to the dog and cat model , allowing
    only the top fully connected layers to adjust themselves. This is almost the same
    as the transfer learning approach of the previous section. To freeze all the convolutional
    layers, we replace the direct assignments to specific layers’ `trainable` property
    with a loop over all the layers:'
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前提到过，我们还会训练一个冻结所有卷积层的模型。本质上，这就是说我们希望保留车辆模型所学习的所有新表示，并直接将其应用于狗与猫模型，只允许顶部的全连接层自我调整。这几乎与上一节的迁移学习方法相同。为了冻结所有卷积层，我们用一个循环替换了对特定层
    `trainable` 属性的直接赋值：
- en: '[PRE10]'
  id: totrans-537
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Testing Our Model
  id: totrans-538
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 测试我们的模型
- en: Let’s run the fine-tuning tests. We’ll train each possible combination six times
    so we can get statistics on the mean accuracies. This accounts for the stochastic
    nature of the initialization process. Although we initialized the model with pretrained
    weights, we added a new top softmax layer with two outputs. The output of the
    dense layer below it has 128 nodes, so each model needs to randomly initialize
    128 × 2 + 2 = 258 weights and biases for the new layer. This is the source of
    the difference.
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进行微调测试。我们将训练每种可能的组合六次，以便获得均值准确度的统计数据。这考虑到了初始化过程的随机性。尽管我们使用预训练权重初始化了模型，但我们增加了一个新的顶部
    softmax 层，具有两个输出。其下方的全连接层有 128 个节点，因此每个模型需要随机初始化 128 × 2 + 2 = 258 个权重和偏置，这就是差异的来源。
- en: Without training, the initial model accuracy hovers around 50 to 51 percent,
    with each model slightly different because of the initialization we just mentioned.
    This is a two-class model, so this means that without any training, it is randomly
    guessing between dog and cat.
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: 在未经过训练的情况下，初始模型的准确度大约在 50 到 51 百分之间，每个模型略有不同，因为我们刚才提到的初始化过程。这是一个二分类模型，这意味着在没有任何训练的情况下，它随机地在狗和猫之间进行猜测。
- en: After we have trained all of the models and tallied all of the per model accuracies,
    we get [Table 14-2](ch14.xhtml#ch14tab2), where we present accuracy as mean ±
    standard error.
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练完所有模型并统计每个模型的准确度后，我们得到 [表 14-2](ch14.xhtml#ch14tab2)，其中呈现了准确度的均值 ± 标准误差。
- en: '**Table 14-2:** Dog and Cat Test Set Accuracies for the Shallow, Deep, and
    Fine-Tuned Deep Models'
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
  zh: '**表 14-2：** 浅层、深层和微调深层模型在狗与猫测试集上的准确度'
- en: '| **Model** | **Freeze Conv0** | **Freeze Conv1** | **Accuracy (%)** |'
  id: totrans-543
  prefs: []
  type: TYPE_TB
  zh: '| **模型** | **冻结 Conv0** | **冻结 Conv1** | **准确度 (%)** |'
- en: '| --- | --- | --- | --- |'
  id: totrans-544
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Shallow | – | – | 64.375 ± 0.388 |'
  id: totrans-545
  prefs: []
  type: TYPE_TB
  zh: '| 浅层 | – | – | 64.375 ± 0.388 |'
- en: '| Deep | – | – | 61.142 ± 0.509 |'
  id: totrans-546
  prefs: []
  type: TYPE_TB
  zh: '| 深层 | – | – | 61.142 ± 0.509 |'
- en: '| Fine-tune 0 | False | False | 62.683 ± 3.689 |'
  id: totrans-547
  prefs: []
  type: TYPE_TB
  zh: '| 微调 0 | 假 | 假 | 62.683 ± 3.689 |'
- en: '| Fine-tune 1 | True | False | 69.142 ± 0.934 |'
  id: totrans-548
  prefs: []
  type: TYPE_TB
  zh: '| 微调 1 | 真 | 假 | 69.142 ± 0.934 |'
- en: '| Fine-tune 2 | False | True | 68.842 ± 0.715 |'
  id: totrans-549
  prefs: []
  type: TYPE_TB
  zh: '| 微调 2 | 假 | 真 | 68.842 ± 0.715 |'
- en: '| Fine-tune 3 | True | True | 70.050 ± 0.297 |'
  id: totrans-550
  prefs: []
  type: TYPE_TB
  zh: '| 微调 3 | 真 | 真 | 70.050 ± 0.297 |'
- en: '| Freeze all | – | – | 57.042 ± 0.518 |'
  id: totrans-551
  prefs: []
  type: TYPE_TB
  zh: '| 冻结所有 | – | – | 57.042 ± 0.518 |'
- en: 'What to make of these results? First, we see that training the deep architecture
    from scratch with the small dog and cat dataset is not particularly effective:
    only about 61 percent accurate. Training the shallow architecture from scratch
    does better, with an accuracy of around 64 percent. These are our baselines. Will
    fine-tuning a model trained on different data help? From looking at the fine-tune
    results, the answer is “yes,” but clearly, not all the fine-tuning options are
    equally effective: two are even worse than the best from-scratch result (“Fine-tune
    0” and “Freeze all”). So, we do not want to freeze all the convolutional layers,
    nor do we want to be free to update all of them.'
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: 如何理解这些结果？首先，我们看到用小型狗猫数据集从头训练深度架构并不是特别有效：准确率只有大约61%。从头训练浅层架构效果更好，准确率约为64%。这些是我们的基准。微调在不同数据上训练的模型是否有帮助？从微调结果来看，答案是“是的”，但显然并非所有微调选项都是同样有效的：有两个甚至比最好的从零开始的结果更差（“微调0”和“冻结所有”）。因此，我们不想冻结所有的卷积层，也不想让它们都可以自由更新。
- en: This leaves fine-tune models 1, 2, and 3 to consider. The “Fine-tune 3” model
    performed best, though the differences between these models are not statistically
    significant. Let’s go with freezing the first two convolutional layers, then.
    What might be happening to make this approach better than the other models? By
    freezing these lowest layers, we are fixing them and preventing them from being
    changed by training. These layers were trained on a much larger vehicle dataset
    that included standard augmentations like shifts and rotates. And, as we already
    saw in [Figure 12-4](ch12.xhtml#ch12fig4), the kernels learned by these lower
    layers are edge and texture detectors. They have been conditioned to learn about
    the sorts of structures present in CIFAR-10 images, and, since our dog and cat
    dataset is also from CIFAR-10, it is reasonable to believe that the same kernels
    will be useful with those images as well.
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得我们需要考虑微调模型1、2和3。“微调3”模型表现最佳，尽管这些模型之间的差异在统计上并不显著。那么，我们选择冻结前两个卷积层吧。那么，是什么使得这种方法比其他模型更好呢？通过冻结这两个最底层，我们将它们固定住，防止它们在训练过程中被改变。这些层是在一个包含标准数据增强（如平移和旋转）的更大车辆数据集上训练的。而且，正如我们在[图12-4](ch12.xhtml#ch12fig4)中看到的，这些低层学到的卷积核是边缘和纹理检测器。它们已经被训练来学习CIFAR-10图像中存在的各种结构，鉴于我们的狗猫数据集也是来自CIFAR-10，因此可以合理地认为相同的卷积核在这些图像中也会很有用。
- en: However, when we froze all the convolutional layers of the deep architecture,
    we saw a significant decrease in performance. This implies that higher-level convolutional
    layers are not well-adapted to the dog and cat structures, which, again, makes
    perfect sense. Because of their effective receptive fields, higher layers are
    learning about larger structures in the input images; these are also the larger
    structures that distinguish dogs from cats. If we cannot modify these layers,
    there is no opportunity for them to be conditioned on the very things that we
    need them to learn.
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当我们冻结了深度架构的所有卷积层时，我们看到了性能的显著下降。这意味着高层卷积层并没有很好地适应狗和猫的结构，这也完全合理。由于它们的有效感受野，高层学习的是输入图像中的更大结构；这些也是区分狗和猫的较大结构。如果我们不能修改这些层，就没有机会让它们专门学习我们需要它们学习的东西。
- en: 'This fine-tuning example shows the power of the technique when it is applicable.
    However, like most things in machine learning, there is only intuition as to why
    and when it’s successful. Recent work has shown that sometimes, fine-tuning a
    large model trained on a dataset that is not very close to the intended dataset
    can lead to performance that is no better than training a shallower model, provided
    enough data is present. For example, see “Transfusion: Understanding Transfer
    Learning for Medical Imaging” by Maithra Raghu et al. This paper uses transfer
    learning/fine-tuning between pretrained ImageNet models and medical images and
    shows that shallow models trained from scratch are often just as good.'
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: '这个微调示例展示了当该技术适用时的强大功能。然而，像大多数机器学习中的事情一样，对于为何以及何时成功，只有直觉。最近的研究表明，有时候，微调一个在与目标数据集相差较大的数据集上训练的大模型，可能导致的表现并不比训练一个较浅的模型好，前提是数据足够充足。例如，请参阅Maithra
    Raghu等人撰写的“Transfusion: Understanding Transfer Learning for Medical Imaging”。这篇论文在预训练的ImageNet模型和医学影像之间使用迁移学习/微调，并表明从零开始训练的浅层模型往往效果相当好。'
- en: Summary
  id: totrans-556
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 总结
- en: This chapter explored convolutional neural networks applied to the CIFAR-10
    dataset. We started by training two architectures, one shallow, the other deep,
    on the full dataset. We then asked whether or not we can train a model to distinguish
    between animals and vehicles. Next, we answered the question of whether or not
    a single multiclass model or multiple binary models performed better for CIFAR-10\.
    After this, we introduced two fundamental techniques, transfer learning and fine-tuning,
    and showed how to implement them in Keras. These techniques should be understood
    and in your deep learning bag of tricks going forward.
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
  zh: 本章探讨了卷积神经网络在CIFAR-10数据集上的应用。我们首先在完整的数据集上训练了两个架构，一个较浅，另一个较深。接着，我们提出了一个问题：我们是否能训练出一个模型来区分动物和交通工具。然后，我们回答了是否单一的多分类模型或多个二分类模型在CIFAR-10上表现更好。之后，我们介绍了两种基础技术，迁移学习和微调，并展示了如何在Keras中实现这些技术。今后，这些技术应该是你深度学习技能库中的一部分。
- en: In the next chapter, we’ll present a case study with a dataset we have not yet
    worked with. We’ll assume the role of data scientists tasked with making a model
    for this dataset and work our way through, from initial data processing to model
    exploration and final model construction.
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将呈现一个案例研究，使用一个我们尚未处理过的数据集。我们将扮演数据科学家的角色，任务是为该数据集构建一个模型，并从初步的数据处理到模型探索，再到最终的模型构建，一步步进行。

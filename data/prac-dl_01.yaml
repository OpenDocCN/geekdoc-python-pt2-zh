- en: '**1'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**1'
- en: GETTING STARTED**
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 开始使用**
- en: '![image](Images/common.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/common.jpg)'
- en: This chapter introduces our operating environment and details how to set it
    up. It also includes a primer on some of the math we will encounter. We’ll end
    with a brief note about graphics processors, or GPUs, which you may have heard
    are essential for deep learning. For our purposes, they’re not, so don’t worry—this
    book won’t suddenly cost you a lot of money.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了我们的操作环境，并详细讲解如何设置它。它还包括一些我们将遇到的数学基础知识。最后，我们会简要提及图形处理单元（GPU），你可能听说它们对深度学习至关重要。但就我们而言，它们并非必需，因此不必担心——本书不会突然让你花费大量资金。
- en: The Operating Environment
  id: totrans-4
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 操作环境
- en: In this section, we’ll detail the environment we’ll assume throughout the remainder
    of the book. Our underlying assumption is that we’re using a 64-bit Linux system.
    The exact distribution is not critical, but to make things simpler in the presentation,
    we’ll also assume that we’re using Ubuntu 20.04\. Given the excellent support
    behind the Ubuntu distribution, we trust that any newer distributions will also
    work similarly. The Python language is our *lingua franca*, the common language
    of machine learning. Specifically, we’ll use Python 3.8.2; that’s the version
    used by Ubuntu 20.04.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将详细介绍我们假设的环境，这个环境贯穿本书的其余部分。我们的基本假设是我们使用的是 64 位的 Linux 系统。具体的发行版并不关键，但为了简化展示，我们假设使用的是
    Ubuntu 20.04。考虑到 Ubuntu 发行版的优异支持，我们相信任何更新的发行版也能以类似的方式工作。Python 语言是我们的*通用语言*，是机器学习的共同语言。具体来说，我们将使用
    Python 3.8.2，这是 Ubuntu 20.04 使用的版本。
- en: Let’s look at a quick overview of the Python toolkits that we’ll be using.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速概览一下我们将使用的 Python 工具包。
- en: NumPy
  id: totrans-7
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: NumPy
- en: '*NumPy* is a Python library that adds array processing abilities to Python.
    While Python lists can be used like one-dimensional arrays, in practice they are
    too slow and inflexible. The NumPy library adds the array features missing from
    Python—features that are necessary for many scientific applications. NumPy is
    a base library required by all the other libraries we’ll use.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '*NumPy* 是一个 Python 库，增加了数组处理的功能。虽然 Python 列表可以像一维数组一样使用，但实际上它们速度太慢且不够灵活。NumPy
    库弥补了 Python 中缺少的数组特性，这些特性对许多科学应用至关重要。NumPy 是我们将使用的所有其他库的基础库。'
- en: scikit-learn
  id: totrans-9
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: scikit-learn
- en: All of the traditional machine learning models we’ll explore in this book are
    found in the superb scikit-learn library, or *sklearn*, as it’s usually called
    when loaded into Python. Note also that we’re writing *scikit-learn* without caps
    as this is how the authors consistently refer to it in their documentation. This
    library uses NumPy arrays. It implements a standardized interface to many different
    machine learning models as well as an entire host of other functionality that
    we won’t even have time to touch. I strongly encourage you to review the official
    sklearn documentation ([https://scikit-learn.org/stable/documentation.html](https://scikit-learn.org/stable/documentation.html))
    as you become more and more familiar with machine learning and the tools behind
    it.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中我们将探讨的所有传统机器学习模型都可以在优秀的 scikit-learn 库中找到，通常当加载到 Python 中时，它被称为*sklearn*。还需要注意的是，我们在书中将*scikit-learn*全小写，这是因为文档作者一致如此称呼该库。这个库使用
    NumPy 数组，提供了许多不同机器学习模型的标准化接口，并且包含了大量我们无法触及的其他功能。我强烈建议你在熟悉机器学习及其背后工具的过程中，查看官方的
    sklearn 文档（[https://scikit-learn.org/stable/documentation.html](https://scikit-learn.org/stable/documentation.html)）。
- en: Keras with TensorFlow
  id: totrans-11
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用 TensorFlow 的 Keras
- en: 'Deep learning is hard enough to understand, let alone implement efficiently
    and correctly, so instead of attempting to write convolutional neural networks
    from scratch, we’ll use one of the popular toolkits already in active development.
    From its inception, the deep learning community has supported the development
    of toolkits to make deep networks easier to use and has made the toolkits open
    source with very generous licenses. At the time of this writing, there are many
    popular toolkits we could have used in Python. Among many others, these include
    the following:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习已经足够难以理解，更不用说高效且正确地实现它了，因此我们不打算从头编写卷积神经网络，而是将使用已在积极开发的流行工具包之一。从一开始，深度学习社区就支持工具包的开发，以便更容易使用深度网络，并且以非常宽松的开源许可证发布了这些工具包。在写作本书时，我们可以在
    Python 中使用许多流行的工具包。除了其他工具包之外，以下是其中的一些：
- en: Keras
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Keras
- en: PyTorch
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTorch
- en: Caffe
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Caffe
- en: Caffe2
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Caffe2
- en: Apache MXnet
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Apache MXnet
- en: Some of these toolkits are waxing, and others appear to be waning. But the one
    that has probably the most active following at present is Keras with the TensorFlow
    backend, so that’s the one we’ll use here.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这些工具包中有些正在流行，而有些似乎在衰退。但目前可能拥有最多活跃追随者的是使用 TensorFlow 后端的 Keras，因此我们将在这里使用这个。
- en: '*Keras* (*[https://keras.io/](https://keras.io/)*) is a Python deep learning
    toolkit that uses the TensorFlow toolkit (*[https://www.tensorflow.org/](https://www.tensorflow.org/)*)
    under the hood. *TensorFlow* is an open source Google product that implements
    the core functionality of deep neural networks for many different platforms. We
    selected Keras not only because it’s popular and in active development, but also
    because it’s straightforward to use. Our goal is to become familiar with deep
    learning to the point where we can implement models and use them with a minimum
    of programming overhead.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '*Keras* (*[https://keras.io/](https://keras.io/)* ) 是一个 Python 深度学习工具包，底层使用
    TensorFlow 工具包 (*[https://www.tensorflow.org/](https://www.tensorflow.org/)*)。*TensorFlow*
    是一个开源的 Google 产品，实现了深度神经网络的核心功能，支持多个平台。我们选择 Keras 不仅因为它很受欢迎且正在积极开发，还因为它使用起来很简单。我们的目标是熟悉深度学习，达到能够实现模型并在最小的编程开销下使用它们的程度。'
- en: Installing the Toolkits
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装工具包
- en: We can’t reasonably give an exhaustive guide for installing the toolkits on
    all systems and hardware. Instead, we’ll provide step-by-step instructions for
    the specific operating system we’ll use as the reference system. These steps,
    along with the minimum version numbers of the libraries, should be enough for
    most readers to get a working system in place.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们无法合理地提供在所有系统和硬件上安装工具包的详尽指南。相反，我们将为我们所使用的特定操作系统提供逐步的安装说明，并将其作为参考系统。这些步骤以及库的最小版本号，应该足够大多数读者能够安装并运行工作系统。
- en: Remember, we’re assuming that we’re working in a Linux environment, specifically
    Ubuntu 20.04\. Ubuntu is a widely used Linux distribution, and it runs on almost
    any modern computer system. Other Linux distributions will work, as will macOS,
    but the instructions here are specific to Ubuntu. For the most part, the machine
    learning community has left the Windows operating system. Still, individuals have
    ported toolkits to Windows; therefore, an adventurous reader might give Windows
    a try.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，我们假设我们在 Linux 环境中工作，具体来说是在 Ubuntu 20.04 上。Ubuntu 是一个广泛使用的 Linux 发行版，几乎可以在任何现代计算机系统上运行。其他
    Linux 发行版和 macOS 也能正常工作，但这里的说明仅适用于 Ubuntu。大部分机器学习社区已经放弃了 Windows 操作系统，但仍然有人将工具包移植到
    Windows；因此，勇于尝试的读者可以尝试在 Windows 上使用。
- en: 'A freshly installed Ubuntu 20.04 base desktop system gives us Python 3.8.2
    for free. To install the remaining packages, we need to go into a shell and execute
    the sequence of steps below in the order given:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 新安装的 Ubuntu 20.04 基础桌面系统免费提供 Python 3.8.2。为了安装其余的包，我们需要进入一个 shell 并按照下面给出的步骤顺序执行：
- en: $ sudo apt - get update
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: $ sudo apt - get update
- en: $ sudo apt - get install python3 - pip
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: $ sudo apt - get install python3 - pip
- en: $ sudo apt - get install build - essential python3 - dev
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: $ sudo apt - get install build - essential python3 - dev
- en: $ sudo apt - get install python3 - setuptools python3 - numpy
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: $ sudo apt - get install python3 - setuptools python3 - numpy
- en: $ sudo apt - get install python3 - scipy libatlas - base - dev
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: $ sudo apt - get install python3 - scipy libatlas - base - dev
- en: $ sudo apt - get install python3 - matplotlib
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: $ sudo apt - get install python3 - matplotlib
- en: $ pip3 install scikit - learn
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: $ pip3 install scikit - learn
- en: $ pip3 install tensorflow
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: $ pip3 install tensorflow
- en: $ pip3 install pillow
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: $ pip3 install pillow
- en: $ pip3 install h5py
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: $ pip3 install h5py
- en: $ pip3 install keras
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: $ pip3 install keras
- en: 'Once the installation is complete, we’ll have installed the following versions
    of the libraries and toolkits:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完成后，我们将安装以下版本的库和工具包：
- en: NumPy 1.17.4
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy 1.17.4
- en: sklearn 0.23.2
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: sklearn 0.23.2
- en: keras 2.4.3
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: keras 2.4.3
- en: tensorflow 2.2.0
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: tensorflow 2.2.0
- en: pillow 7.0.0
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: pillow 7.0.0
- en: h5py 2.10.0
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: h5py 2.10.0
- en: matplotlib 3.1.2
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: matplotlib 3.1.2
- en: The pillow library is an image processing library, h5py is a library for working
    with HDF5 format data files, and matplotlib is for plotting. *HDF5* is a generic,
    hierarchical file format for storing scientific data. Keras uses it to store model
    parameters.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: pillow 库是一个图像处理库，h5py 是一个处理 HDF5 格式数据文件的库，matplotlib 用于绘图。*HDF5* 是一种通用的层次化文件格式，用于存储科学数据。Keras
    使用它来存储模型参数。
- en: The following two sections are light introductions to some of the math that
    will creep into the book.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 以下两个部分是本书中将涉及的一些数学概念的简单介绍。
- en: Basic Linear Algebra
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基本线性代数
- en: We’re about to look at vectors and matrices. The math that deals with these
    concepts falls under the general heading of *linear algebra*, or matrix theory.
    As you might imagine, linear algebra is a complex field. All we need to know for
    this book is what a vector is, what a matrix is, and how we can multiply two vectors,
    or two matrices, or vectors and matrices together. We’ll see later on that this
    gives us a powerful way to implement specific models, particularly neural networks.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们即将深入研究向量和矩阵。处理这些概念的数学属于*线性代数*或矩阵理论的范畴。正如你可能想象的那样，线性代数是一个复杂的领域。对于本书，我们只需要了解什么是向量，什么是矩阵，以及如何将两个向量、两个矩阵，或向量和矩阵相乘。稍后我们将看到，这为我们提供了一种强大的方式来实现特定的模型，特别是神经网络。
- en: Let’s begin by looking at vectors.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从向量开始。
- en: Vectors
  id: totrans-48
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 向量
- en: A *vector* is a one-dimensional list of numbers. Mathematically, a vector might
    appear as
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '*向量*是一个一维的数字列表。数学上，向量可能表现为'
- en: '*a* = [0, 1, 2, 3, 4]'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '*a* = [0, 1, 2, 3, 4]'
- en: with the third element given as *a*[2] = 2\. Notice we’re following the programming
    convention of indexing from zero, so *a*[2] gives us the third element in the
    vector.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个元素表示为 *a*[2] = 2。请注意，我们遵循从零开始索引的编程惯例，所以 *a*[2] 给我们的是向量中的第三个元素。
- en: 'The vector above was written horizontally and therefore is known as a *row
    vector*. When used in mathematical expressions, however, vectors are usually assumed
    to be written vertically:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的向量是水平书写的，因此被称为*行向量*。然而，在数学表达式中，向量通常被假定为垂直书写：
- en: '![Image](Images/004equ02.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![Image](Images/004equ02.jpg)'
- en: 'When written vertically, a vector is known as a *column vector*. This vector
    has five elements and is denoted as a five-element column vector. In this book,
    we’ll typically use vectors to represent one *sample*: one set of features that
    we’ll input to a model.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 当向量垂直书写时，它被称为*列向量*。这个向量有五个元素，被表示为五元素列向量。在本书中，我们通常使用向量表示一个*样本*：一组我们输入到模型中的特征。
- en: Mathematically, vectors are used to represent points in space. If we’re talking
    about the two-dimensional (2D) Cartesian plane, we locate a point with a vector
    of two numbers, (*x*,*y*), where *x* is the distance along the x-axis and *y*
    is the distance along the y-axis. That vector represents a point in two dimensions,
    even though the vector itself has only one dimension. If we have three dimensions,
    we need a vector with three elements, (*x*,*y*,*z*).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在数学上，向量用来表示空间中的点。如果我们谈论的是二维（2D）笛卡尔平面，我们用一个由两个数字组成的向量（*x*, *y*）来定位一个点，其中 *x*
    是沿 x 轴的距离，*y* 是沿 y 轴的距离。这个向量表示一个二维的点，即使这个向量本身只有一个维度。如果我们有三维空间，我们需要一个包含三个元素的向量（*x*,
    *y*, *z*）。
- en: In machine learning, since we often use vectors to represent the inputs to our
    models, we’ll be working with dozens to hundreds of dimensions. Of course, we
    can’t plot them as points in a space, but mathematically, that’s what they are.
    As we’ll see, some models, such as the *k*-Nearest Neighbors model, use the feature
    vectors as just that—points in a high-dimensional space.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，由于我们通常使用向量来表示模型的输入，所以我们将处理从几十到几百维的向量。当然，我们不能将它们作为空间中的点来绘制，但从数学角度来看，它们就是这样。正如我们将看到的，一些模型，比如*k*-最近邻模型，就将特征向量作为—高维空间中的点。
- en: Matrices
  id: totrans-57
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 矩阵
- en: 'A *matrix* is a two-dimensional array of numbers where we index a particular
    entry by its row number and column number. For example, this is a matrix:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '*矩阵*是一个二维的数字数组，我们通过其行号和列号来索引特定的条目。例如，这是一个矩阵：'
- en: '![Image](Images/005equ01.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![Image](Images/005equ01.jpg)'
- en: If we want to refer to the 6, we write *a*[1,2] = 6\. Again, we’re indexing
    from zero. Because this matrix *a* has three rows and three columns, we call it
    a 3 × 3 matrix.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想引用 6，我们写 *a*[1,2] = 6。同样，我们从零开始索引。因为这个矩阵 *a* 有三行三列，所以我们称它为一个 3 × 3 矩阵。
- en: Multiplying Vectors and Matrices
  id: totrans-61
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 向量与矩阵的乘法
- en: 'The simplest way to think of multiplying two vectors together is to multiply
    their corresponding elements. For example:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 将两个向量相乘的最简单方式是将它们的对应元素相乘。例如：
- en: '[1, 2, 3] × [4, 5, 6] = [4, 10, 18]'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[1, 2, 3] × [4, 5, 6] = [4, 10, 18]'
- en: This is the most common way to multiply an array when using a toolkit like NumPy,
    and we’ll make heavy use of this in the chapters that follow. However, in mathematics,
    this is seldom actually done.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这是使用像 NumPy 这样的工具包时最常见的数组乘法方式，我们将在接下来的章节中广泛使用这一方式。然而，在数学中，实际上很少这样做。
- en: When multiplying vectors together mathematically, we need to know if they are
    row or column vectors. We’ll work with two vectors, *A* = (*a*,*b*,*c*), and *B*
    = (*d*,*e*,*f* ), which, following mathematical convention, are assumed to be
    column vectors. Adding a superscript *T* turns a column vector into a row vector.
    The mathematically allowed ways to multiply *A* and *B* are
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们将向量相乘时，需要知道它们是行向量还是列向量。我们将使用两个向量，*A* = (*a*,*b*,*c*) 和 *B* = (*d*,*e*,*f*)，按照数学惯例，它们被假定为列向量。添加一个上标
    *T* 会将列向量转变为行向量。数学上允许的乘法方式有：
- en: '![Image](Images/005equ02.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![Image](Images/005equ02.jpg)'
- en: which is called the *outer product* and
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这叫做*外积*，并且
- en: '![Image](Images/005equ03.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![Image](Images/005equ03.jpg)'
- en: which is called the *inner product*, or *dot product*. Notice that the outer
    product becomes a matrix, and the inner product becomes a single number, a *scalar*.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这叫做*内积*，或称为*点积*。注意，外积得到的是矩阵，而内积得到的是一个单一的数字，一个*标量*。
- en: When multiplying a matrix and a vector, the vector is typically on the right
    side of the matrix. The multiplication can proceed if the number of columns in
    the matrix matches the number of elements in the vector, again assumed to be a
    column vector. The result is also a vector with as many elements as there are
    rows in the matrix (read *ax* + *by* + *cz* as a single element).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 当矩阵和向量相乘时，向量通常位于矩阵的右侧。如果矩阵的列数与向量的元素数相匹配，乘法可以进行，这里假设向量是列向量。结果也是一个向量，其元素个数与矩阵的行数相等（将*ax*
    + *by* + *cz* 视为一个单一元素）。
- en: 'For example:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 例如：
- en: '![Image](Images/006equ01.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![Image](Images/006equ01.jpg)'
- en: 'Here we’ve multiplied a 2 × 3 matrix by a 3 × 1 column vector to get a 2 ×
    1 output vector. Notice that the number of columns of the matrix and the number
    of rows of the vector match. If they do not, then the multiplication is not defined.
    Also, notice that the values in the output vector are sums of products of the
    matrix and vector. This same rule applies when multiplying two matrices:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们将一个 2 × 3 矩阵与一个 3 × 1 列向量相乘，得到一个 2 × 1 的输出向量。注意，矩阵的列数与向量的行数要匹配。如果不匹配，乘法是未定义的。同时，注意输出向量中的值是矩阵与向量的乘积之和。这个规则在乘法两个矩阵时也适用：
- en: '![Image](Images/006equ02.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![Image](Images/006equ02.jpg)'
- en: Here multiplying a 2 × 3 matrix by a 3 × 2 matrix has given us a 2 × 2 answer.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这里将一个 2 × 3 矩阵与一个 3 × 2 矩阵相乘，得到了一个 2 × 2 的结果。
- en: When we get to convolutional neural networks, we’ll work with arrays that have
    three and even four dimensions. Generically, these are referred to as *tensors*.
    If we imagine a stack of matrices, all the same size, we get a three-dimensional
    tensor, and we can use the first index to refer to any one of the matrices and
    the remaining two indices to refer to a particular element of that matrix. Similarly,
    if we have a stack of three-dimensional tensors, we have a four-dimensional tensor,
    and we can use the first index of that to refer to any one of the three-dimensional
    tensors.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们进入卷积神经网络时，我们将处理具有三维甚至四维的数组。通常，这些被称为*张量*。如果我们想象一堆大小相同的矩阵，我们就得到了一个三维张量，我们可以使用第一个索引来引用其中任何一个矩阵，剩余的两个索引来引用该矩阵中的特定元素。类似地，如果我们有一堆三维张量，我们就得到了一个四维张量，我们可以使用其第一个索引来引用任何一个三维张量。
- en: The main points of this section are that vectors have one dimension, matrices
    have two dimensions, there are rules for multiplying these objects together, and
    our toolkits will work with four-dimensional tensors in the end. We’ll review
    some of these points as we encounter them later in the book.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的重点是，向量是一维的，矩阵是二维的，有规则可以将这些对象相乘，最终我们的工具包将会处理四维张量。我们将在书中后面遇到时回顾这些要点。
- en: Statistics and Probability
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 统计与概率
- en: The topics of statistics and probability are so broad that often it’s better
    to either say almost nothing or to write a book or two. Therefore, I’ll mention
    only key ideas that we’ll use throughout the book and leave the rest to you to
    pick up as you see fit. I’ll assume you know some basic things about probability
    from flipping coins and rolling dice.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 统计和概率的主题非常广泛，以至于通常最好什么都不说，或者写几本书。因此，我将只提到一些我们将在全书中使用的关键概念，剩下的部分则交给你根据需要自行学习。我假设你对投掷硬币和掷骰子有一些基础的概率知识。
- en: Descriptive Statistics
  id: totrans-80
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 描述性统计
- en: When we do experiments, we need to report the results in some meaningful way.
    Typically, for us, we’ll report results as the mean (arithmetic average) plus
    or minus a quantity known as the *standard error of the mean (SE)*. Let’s define
    the standard error of the mean through an example.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们进行实验时，我们需要以某种有意义的方式报告结果。通常，对于我们来说，我们会报告结果为均值（算术平均数）加减一个叫做*均值标准误差（SE）*的量。我们通过一个例子来定义均值的标准误差。
- en: If we have many measurements *x*, say the length of a part of a flower, then
    we can calculate the mean (![Image](Images/xbar.jpg)) by adding all the values
    together and dividing by the number of values we added. Then, once we have the
    mean, we can calculate the average spread of the individual values around the
    mean by subtracting each value from the mean, squaring the result, and adding
    all these squared values together before dividing by the number of values we added
    minus one. This number is the *variance*. If we take the square root of this value,
    we get the *standard deviation* (*σ*), which we’ll see again below. With the standard
    deviation, we can calculate the standard error of the mean as ![Image](Images/007equ01.jpg),
    where *n* is the number of values that we used to calculate the mean. The smaller
    the SE is, the more tightly the values are clustered around the mean. We can interpret
    this value as the uncertainty we have about the mean value. This means we expect
    the actual mean, which we don’t really know, to be between ![Image](Images/007equ02.jpg)
    and ![Image](Images/007equ03.jpg).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有很多测量值*x*，比如说一朵花的一部分的长度，那么我们可以通过将所有的数值加起来，并除以加起来的数值的数量，来计算均值 (![Image](Images/xbar.jpg))。然后，一旦我们有了均值，我们可以通过将每个数值减去均值、平方结果并将所有这些平方值加起来，再除以加起来的数值数量减去一，来计算个别数值围绕均值的平均分散程度。这个数值就是*方差*。如果我们取这个数值的平方根，就能得到*标准差*（*σ*），我们稍后还会看到它。通过标准差，我们可以计算均值的标准误差为
    ![Image](Images/007equ01.jpg)，其中*n*是用于计算均值的数值数量。SE越小，说明数值越紧密地集中在均值周围。我们可以将这个值解释为我们对均值的确定性程度。意味着我们期望实际均值（我们并不真正知道它）位于
    ![Image](Images/007equ02.jpg) 和 ![Image](Images/007equ03.jpg) 之间。
- en: Sometimes, we’ll talk about the median instead of the mean. The *median* is
    the middle value, the value that half of our samples are below and half are above.
    To find the median for a set of values, we first sort the values numerically and
    then find the middle value. This is the exact middle value if we have an odd number
    of samples, or the mean of the two middle values if we have an even number of
    samples. The median is sometimes more useful than the mean if the samples do not
    have a good, even spread around the mean. The classic example is income. A few
    very rich people move the mean income up to the point where it does not have much
    meaning. Instead, the median, the value where half the people make less and half
    make more, is more representative.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，我们会谈论中位数而不是均值。*中位数*是中间值，表示一半的样本值低于它，另一半高于它。要找到一组数值的中位数，我们首先按数值大小排序，然后找到中间的值。如果样本数是奇数，中位数就是正中间的值；如果样本数是偶数，中位数就是中间两个值的均值。如果样本分布不均匀，中位数有时比均值更有用。经典的例子是收入。少数非常富有的人会把均值拉高，导致均值的意义不大。相反，中位数，即一半人收入低于它，另一半收入高于它，更具代表性。
- en: 'In later chapters, we’ll talk about *descriptive statistics*. These are values
    derived from a dataset that can be used to understand the dataset. We just mentioned
    three of them: the mean, the median, and the standard deviation. We’ll see how
    to use these and how they can be plotted to help us understand a dataset.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在后续章节中，我们将讨论*描述性统计*。这些是从数据集中得出的数值，可以用来理解数据集。我们刚才提到了其中的三个：均值、中位数和标准差。我们将学习如何使用这些指标以及如何将它们绘制出来，以帮助我们理解数据集。
- en: Probability Distributions
  id: totrans-85
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 概率分布
- en: In this book, we’ll talk about something known as a *probability distribution*.
    You can think of it as an oracle of sorts—something that, when asked, will give
    us a number or set of numbers. For example, when we train a model, we use numbers,
    or sets of numbers, that we measure; we can think of those numbers as coming from
    a probability distribution. We’ll refer to that distribution as the *parent distribution*.
    Think of it as the thing that generates the data we’ll feed our model; another,
    more Platonic, way to think about it is as the ideal set of data that our data
    is approximating.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我们将讨论一个被称为*概率分布*的东西。你可以把它看作是某种神谕——当被问及时，会给我们一个数字或一组数字。例如，当我们训练模型时，我们使用我们测量的数字或数字集合；我们可以把这些数字看作来自概率分布。我们将称之为*父分布*。可以将其视为生成我们将馈送给模型的数据的东西；另一种更柏拉图式的思考方式是将其视为我们的数据正在逼近的理想数据集。
- en: 'Probability distributions come in many different forms; some even have names.
    The two that we’ll encounter are the two most common: uniform and normal distributions.
    You’ve already encountered a uniform distribution: it’s what we get if we roll
    a fair die. If the die has six sides, we know that the likelihood of getting any
    value, 1 through 6, is the same. If we roll the die 100 times and tally the numbers
    that come up, we know that the tally will be roughly equal for each number and
    that in the long run, we can easily convince ourselves that the number will even
    out.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 概率分布有许多不同的形式；一些甚至有名字。我们将遇到的两种最常见的是均匀分布和正态分布。您已经遇到了均匀分布：这是我们掷一个公平的骰子所得到的。如果骰子有六个面，我们知道得到任何值，从1到6的可能性是相同的。如果我们掷100次骰子并记录出现的数字，我们知道每个数字的记录大致相等，并且在长期内，我们可以很容易地说服自己数字会平衡。
- en: A *uniform distribution* is an oracle that is equally likely to give us any
    of its allowed responses. Mathematically, we’ll write uniform distributions as
    *U*(*a*,*b*) where *U* means uniform and *a* and *b* are the range of values it
    will use to bracket its response. Unless we specify the distribution gives only
    integers, any real number is allowed as the response. Notationally, we write *x*
    ~ *U*(0,1) to mean that *x* is a value returned by the oracle that gives real
    numbers in the range (0,1) with equal likelihood. Also, note that using “(" and
    “)" to bracket a range excludes the associated bound, while using “[" and “]"
    includes it. Thus *U*[0,1) returns values from 0 to 1, including 0 but excluding
    1.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 一个*均匀分布*是一个神谕，它同等可能地给出它允许的任何响应。在数学上，我们将均匀分布写为*U*(*a*,*b*)，其中*U*表示均匀分布，*a*和*b*是它用于括起其响应的值的范围。除非我们指定分布仅给出整数，否则任何实数都可以作为响应。在符号上，我们写*x*
    ~ *U*(0,1)来表示*x*是由神谕返回的值，该神谕在范围(0,1)内以相等的可能性给出。此外，请注意，使用“(”和“)”来括起范围会排除相关边界，而使用“[”和“]”会包括它。因此*U*[0,1)返回从0到1的值，包括0但不包括1。
- en: A *normal distribution*, also called a *Gaussian* distribution, is visually
    a bell curve—a shape where one value is most likely, and then the likelihood of
    the other values decreases as one gets further from the most likely value. The
    most likely value is the mean, ![Image](Images/xbar.jpg), and the parameter that
    controls how quickly the likelihood drops to zero (without ever really reaching
    it) is the standard deviation, *σ* (sigma). For our purposes, if we want a sample
    from a normal distribution, we’ll write ![Image](Images/008equ01.jpg) to mean
    *x* is drawn from a normal distribution with a mean of ![Image](Images/xbar.jpg)
    and a standard deviation of *σ*.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 一个*正态分布*，也称为*高斯*分布，在视觉上是一个钟形曲线——一个值最有可能，然后随着远离最可能值，其他值的可能性逐渐降低。最可能的值是平均值，![Image](Images/xbar.jpg)，控制可能性多快下降到零（但从未真正达到）的参数是标准差，*σ*（西格玛）。对于我们的目的，如果我们想要从正态分布中取样，我们将写![Image](Images/008equ01.jpg)表示*x*是从均值为![Image](Images/xbar.jpg)、标准差为*σ*的正态分布中抽取的样本。
- en: Statistical Tests
  id: totrans-90
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 统计检验
- en: Another topic that will pop up from time to time is the idea of a *statistical
    test*, a measurement used to decide if a particular hypothesis is likely true
    or not. Typically, the hypothesis relates to two sets of measurements, and the
    hypothesis is that the two sets of measurements came from the same parent distribution.
    If the statistic calculated by the test is outside of a certain range, we reject
    the hypothesis and claim we have evidence that the two sets of measurements are
    *not* from the same parent distribution.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个不时会出现的话题是*统计检验*的概念，这是一种用来判断某个假设是否可能成立的测量方法。通常，假设涉及到两组测量数据，假设是这两组测量来自同一个母体分布。如果检验计算出的统计量超出了某个范围，我们就会拒绝这个假设，并声称有证据表明这两组测量*不*来自同一个母体分布。
- en: Here, we’ll usually use the *t-test*, a common statistical test that assumes
    our data is normally distributed. Because we assumed that our data is normally
    distributed, which may or may not be true, the t-test is known as a *parametric
    test*.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们通常会使用* t 检验*，这是一种常见的统计检验，假设我们的数据是正态分布的。由于我们假设数据是正态分布的，这一假设可能对也可能不对，所以
    t 检验被称为*参数检验*。
- en: Sometimes, we’ll use another test, the *Mann–Whitney U test*, which is like
    a t-test in that it helps us decide if two samples are from the same parent distribution,
    but it makes no assumption about how the data values in the sample are themselves
    distributed. Tests like these are known as *nonparametric tests*.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，我们会使用另一种检验，*曼–惠特尼 U 检验*，它与 t 检验类似，帮助我们判断两个样本是否来自同一个母体分布，但它不对样本中数据值的分布做任何假设。像这样的检验被称为*非参数检验*。
- en: Whether the test is parametric or nonparametric, the value we ultimately get
    from the test is called a *p-value*. It represents the probability that we would
    see the test statistic value we calculated if the hypothesis that the samples
    come from the same parent distribution is true. If the *p*-value is low, we have
    evidence that the hypothesis is not true.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 无论检验是参数检验还是非参数检验，我们最终得到的值被称为*p*-值。它表示在假设样本来自同一个母体分布的前提下，我们计算出的检验统计量值出现的概率。如果*p*-值较低，我们有证据表明假设不成立。
- en: The usual *p*-value cutoff is 0.05, indicating a 1 in 20 chance that we’d measure
    the test statistic value (t-test or Mann–Whitney U) even if the samples came from
    the same parent distribution. However, in recent years, it has become clear that
    this threshold is too generous. When *p*-values are near 0.05, but not above,
    we begin to think there is some evidence against the hypothesis. If the *p*-value
    is, say, 0.001 or even less, then we have strong evidence that the samples are
    not from the same parent distribution. In this case, we say that the difference
    is *statistically significant*.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 通常的*p*-值临界值是0.05，这意味着如果样本来自同一个母体分布，那么我们有1/20的机会测量到该检验统计量（t检验或曼–惠特尼U检验）。然而，近年来已经明确这个临界值过于宽松。当*p*-值接近0.05，但不超过时，我们开始怀疑有一些证据反对假设。如果*p*-值是0.001甚至更小，那么我们就有强有力的证据表明这些样本不来自同一个母体分布。在这种情况下，我们称差异是*统计显著*的。
- en: Graphics Processing Units
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 图形处理单元
- en: One of the enabling technologies for modern deep learning was the development
    of powerful *graphics processing units (GPUs)*. These are co-computers implemented
    on graphics cards. Originally designed for video gaming, the highly parallel nature
    of GPUs has been adapted to the extreme computational demands of deep neural network
    models. Many of the advances of recent years would not have been possible without
    the supercomputer-like abilities GPUs provide to even basic desktop computers.
    NVIDIA is the leader in the creation of GPUs for deep learning, and via its Compute
    Unified Device Architecture (CUDA), NVIDIA has been foundational to the success
    of deep learning. It’s not an understatement to say that without GPUs, deep learning
    would not have happened, or at least not been so widely used.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现代深度学习的一个重要技术是*图形处理单元（GPU）*的发展。这些是实现于显卡上的协同计算机。最初为视频游戏设计，GPU的高度并行特性已被应用于深度神经网络模型的极高计算需求。近年来的许多进展如果没有GPU提供的类似超级计算机的能力，即使是普通的桌面计算机，也不可能实现。NVIDIA是深度学习GPU创建的领导者，并且通过其计算统一设备架构（CUDA），NVIDIA为深度学习的成功奠定了基础。毫不夸张地说，如果没有GPU，深度学习就不可能发生，至少不会如此广泛应用。
- en: That said, we’re not expecting GPUs to be present for the models we’ll work
    with in this book. We’ll use small enough datasets and models so that we can train
    in a reasonable amount of time using just a CPU. We’ve already enforced this decision
    in the packages we’ve installed, since the version of TensorFlow we installed
    is a CPU-only version.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 也就是说，我们并不指望在本书中使用的模型中配备 GPU。我们将使用足够小的数据集和模型，以便仅使用 CPU 就能在合理的时间内完成训练。我们已经在安装的包中强制执行了这一决定，因为我们安装的
    TensorFlow 版本是仅支持 CPU 的版本。
- en: If you do have a CUDA-capable GPU and you want to use it for the deep learning
    portion of this book, please do so, but don’t think that you need to purchase
    one to run the examples. If you’re using a GPU, be sure to have CUDA properly
    installed before installing the packages indicated previously and be sure to install
    a GPU-enabled version of TensorFlow. The sklearn toolkit is CPU only.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你确实拥有支持 CUDA 的 GPU，并希望将其用于本书的深度学习部分，可以使用它，但不要认为你需要购买一个 GPU 来运行示例。如果你使用 GPU，请确保在安装前正确安装
    CUDA，并确保安装支持 GPU 的 TensorFlow 版本。sklearn 工具包仅支持 CPU。
- en: Summary
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we summarized our operating environment. Next, we described
    the essential Python toolkits we’ll use throughout the book and gave detailed
    instructions for installing the toolkits assuming an Ubuntu 20.04 Linux distribution.
    As mentioned, the toolkits will work just as nicely on many other Linux distributions
    as well as macOS. We then briefly reviewed some of the math we’ll encounter later
    and ended with an explanation of why we do not need GPUs for our models.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们总结了我们的操作环境。接下来，我们介绍了本书中将要使用的基本 Python 工具包，并假设使用 Ubuntu 20.04 Linux 发行版，详细说明了安装工具包的步骤。如前所述，这些工具包在许多其他
    Linux 发行版以及 macOS 上也能很好地工作。然后，我们简要回顾了后面会涉及到的一些数学内容，最后解释了为什么我们的模型不需要 GPU。
- en: In the next chapter, we’ll review the fundamentals of Python.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将回顾 Python 的基础知识。

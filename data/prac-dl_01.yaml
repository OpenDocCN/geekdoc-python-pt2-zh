- en: '**1'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**1'
- en: GETTING STARTED**
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 开始使用**
- en: '![image](Images/common.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/common.jpg)'
- en: This chapter introduces our operating environment and details how to set it
    up. It also includes a primer on some of the math we will encounter. We’ll end
    with a brief note about graphics processors, or GPUs, which you may have heard
    are essential for deep learning. For our purposes, they’re not, so don’t worry—this
    book won’t suddenly cost you a lot of money.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了我们的操作环境，并详细说明了如何进行设置。它还包含了我们将遇到的一些数学基础知识。最后，我们简要介绍了图形处理单元（GPU），你可能听说过它们对深度学习至关重要。对于我们的用途来说，GPU并不是必须的，所以不用担心——这本书不会突然让你花费很多钱。
- en: The Operating Environment
  id: totrans-4
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 操作环境
- en: In this section, we’ll detail the environment we’ll assume throughout the remainder
    of the book. Our underlying assumption is that we’re using a 64-bit Linux system.
    The exact distribution is not critical, but to make things simpler in the presentation,
    we’ll also assume that we’re using Ubuntu 20.04\. Given the excellent support
    behind the Ubuntu distribution, we trust that any newer distributions will also
    work similarly. The Python language is our *lingua franca*, the common language
    of machine learning. Specifically, we’ll use Python 3.8.2; that’s the version
    used by Ubuntu 20.04.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将详细介绍我们将在本书其余部分假定的环境。我们假设的基本环境是使用64位Linux系统。具体的发行版并不关键，但为了简化演示，我们假设使用的是Ubuntu
    20.04。鉴于Ubuntu发行版背后有出色的支持，我们相信任何较新的发行版也会以类似的方式运行。Python语言是我们的*通用语言*，是机器学习的共同语言。具体来说，我们将使用Python
    3.8.2，这是Ubuntu 20.04使用的版本。
- en: Let’s look at a quick overview of the Python toolkits that we’ll be using.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速浏览一下我们将使用的Python工具包。
- en: NumPy
  id: totrans-7
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: NumPy
- en: '*NumPy* is a Python library that adds array processing abilities to Python.
    While Python lists can be used like one-dimensional arrays, in practice they are
    too slow and inflexible. The NumPy library adds the array features missing from
    Python—features that are necessary for many scientific applications. NumPy is
    a base library required by all the other libraries we’ll use.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '*NumPy* 是一个Python库，它为Python增加了数组处理能力。虽然Python的列表可以用作一维数组，但在实际应用中，它们太慢且不够灵活。NumPy库添加了Python中缺失的数组功能——这些功能对于许多科学应用来说是必需的。NumPy是我们将使用的所有其他库的基础库。'
- en: scikit-learn
  id: totrans-9
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: scikit-learn
- en: All of the traditional machine learning models we’ll explore in this book are
    found in the superb `scikit-learn` library, or *sklearn*, as it’s usually called
    when loaded into Python. Note also that we’re writing *scikit-learn* without caps
    as this is how the authors consistently refer to it in their documentation. This
    library uses NumPy arrays. It implements a standardized interface to many different
    machine learning models as well as an entire host of other functionality that
    we won’t even have time to touch. I strongly encourage you to review the official
    sklearn documentation ([https://scikit-learn.org/stable/documentation.html](https://scikit-learn.org/stable/documentation.html))
    as you become more and more familiar with machine learning and the tools behind
    it.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中我们将探讨的所有传统机器学习模型都可以在出色的`scikit-learn`库中找到，通常当它加载到Python中时，被称为*sklearn*。还需要注意的是，我们写的是*scikit-learn*而不是大写的，因为这是作者在其文档中一致使用的方式。这个库使用NumPy数组。它实现了许多不同机器学习模型的标准化接口，以及一整套我们没有时间涉及的其他功能。我强烈建议你在逐渐熟悉机器学习和其背后的工具时，查阅官方的sklearn文档（[https://scikit-learn.org/stable/documentation.html](https://scikit-learn.org/stable/documentation.html)）。
- en: Keras with TensorFlow
  id: totrans-11
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 带TensorFlow的Keras
- en: 'Deep learning is hard enough to understand, let alone implement efficiently
    and correctly, so instead of attempting to write convolutional neural networks
    from scratch, we’ll use one of the popular toolkits already in active development.
    From its inception, the deep learning community has supported the development
    of toolkits to make deep networks easier to use and has made the toolkits open
    source with very generous licenses. At the time of this writing, there are many
    popular toolkits we could have used in Python. Among many others, these include
    the following:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习已经足够难以理解，更不用说高效且正确地实现了。因此，既然我们不打算从头开始编写卷积神经网络，我们将使用已经在积极开发中的流行工具包。从深度学习诞生之初，社区就支持工具包的开发，以便让深度网络更易于使用，并且这些工具包都是开源的，并且有非常慷慨的许可证。写这本书时，我们可以在Python中使用许多流行的工具包。以下是其中的一些：
- en: Keras
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Keras
- en: PyTorch
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTorch
- en: Caffe
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Caffe
- en: Caffe2
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Caffe2
- en: Apache MXnet
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Apache MXnet
- en: Some of these toolkits are waxing, and others appear to be waning. But the one
    that has probably the most active following at present is Keras with the TensorFlow
    backend, so that’s the one we’ll use here.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这些工具包中的一些正在兴起，而另一些似乎正在衰退。但是，目前可能拥有最多活跃用户的工具包是使用 TensorFlow 后端的 Keras，因此我们将在这里使用它。
- en: '*Keras* (*[https://keras.io/](https://keras.io/)*) is a Python deep learning
    toolkit that uses the TensorFlow toolkit (*[https://www.tensorflow.org/](https://www.tensorflow.org/)*)
    under the hood. *TensorFlow* is an open source Google product that implements
    the core functionality of deep neural networks for many different platforms. We
    selected Keras not only because it’s popular and in active development, but also
    because it’s straightforward to use. Our goal is to become familiar with deep
    learning to the point where we can implement models and use them with a minimum
    of programming overhead.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '*Keras* (*[https://keras.io/](https://keras.io/)* ) 是一个 Python 深度学习工具包，底层使用
    TensorFlow 工具包 (*[https://www.tensorflow.org/](https://www.tensorflow.org/)* )。*TensorFlow*
    是一个开源的 Google 产品，旨在为多种平台实现深度神经网络的核心功能。我们选择 Keras 不仅因为它流行且在积极开发中，还因为它易于使用。我们的目标是熟悉深度学习，直到能够实现模型并以最小的编程开销使用它们。'
- en: Installing the Toolkits
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装工具包
- en: We can’t reasonably give an exhaustive guide for installing the toolkits on
    all systems and hardware. Instead, we’ll provide step-by-step instructions for
    the specific operating system we’ll use as the reference system. These steps,
    along with the minimum version numbers of the libraries, should be enough for
    most readers to get a working system in place.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们无法合理地为所有系统和硬件提供安装工具包的详尽指南。相反，我们将为我们将用作参考系统的特定操作系统提供逐步安装说明。这些步骤以及库的最低版本号应该足以帮助大多数读者搭建一个可用的系统。
- en: Remember, we’re assuming that we’re working in a Linux environment, specifically
    Ubuntu 20.04\. Ubuntu is a widely used Linux distribution, and it runs on almost
    any modern computer system. Other Linux distributions will work, as will macOS,
    but the instructions here are specific to Ubuntu. For the most part, the machine
    learning community has left the Windows operating system. Still, individuals have
    ported toolkits to Windows; therefore, an adventurous reader might give Windows
    a try.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，我们假设我们在 Linux 环境下工作，特别是 Ubuntu 20.04。Ubuntu 是一个广泛使用的 Linux 发行版，几乎可以在任何现代计算机系统上运行。其他
    Linux 发行版以及 macOS 也可以使用，但这里的说明是特定于 Ubuntu 的。大多数机器学习社区已经离开了 Windows 操作系统，尽管个人已将工具包移植到
    Windows，因此，具有冒险精神的读者可以尝试在 Windows 上使用。
- en: 'A freshly installed Ubuntu 20.04 base desktop system gives us Python 3.8.2
    for free. To install the remaining packages, we need to go into a shell and execute
    the sequence of steps below in the order given:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 新安装的 Ubuntu 20.04 基础桌面系统免费提供 Python 3.8.2。为了安装其余的软件包，我们需要进入终端并按照下面给出的步骤顺序执行：
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Once the installation is complete, we’ll have installed the following versions
    of the libraries and toolkits:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完成后，我们将安装以下版本的库和工具包：
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The `pillow` library is an image processing library, `h5py` is a library for
    working with HDF5 format data files, and `matplotlib` is for plotting. *HDF5*
    is a generic, hierarchical file format for storing scientific data. Keras uses
    it to store model parameters.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '`pillow` 库是一个图像处理库，`h5py` 是用于处理 HDF5 格式数据文件的库，`matplotlib` 用于绘图。*HDF5* 是一种通用的、层次化的文件格式，用于存储科学数据。Keras
    使用它来存储模型参数。'
- en: The following two sections are light introductions to some of the math that
    will creep into the book.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 以下两部分是对一些将在本书中出现的数学概念的简要介绍。
- en: Basic Linear Algebra
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基本线性代数
- en: We’re about to look at vectors and matrices. The math that deals with these
    concepts falls under the general heading of *linear algebra*, or matrix theory.
    As you might imagine, linear algebra is a complex field. All we need to know for
    this book is what a vector is, what a matrix is, and how we can multiply two vectors,
    or two matrices, or vectors and matrices together. We’ll see later on that this
    gives us a powerful way to implement specific models, particularly neural networks.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要学习向量和矩阵。涉及这些概念的数学属于*线性代数*（或矩阵理论）的范畴。正如你可以想象的那样，线性代数是一个复杂的领域。对于本书来说，我们需要知道的只是向量是什么，矩阵是什么，以及如何将两个向量、两个矩阵或向量与矩阵相乘。稍后我们将看到，这为我们实现特定的模型，特别是神经网络，提供了一种强大的方法。
- en: Let’s begin by looking at vectors.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从向量开始。
- en: Vectors
  id: totrans-32
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 向量
- en: A *vector* is a one-dimensional list of numbers. Mathematically, a vector might
    appear as
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '*向量*是一个一维的数字列表。从数学角度来看，向量可能表现为'
- en: '*a* = [0, 1, 2, 3, 4]'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '*a* = [0, 1, 2, 3, 4]'
- en: with the third element given as *a*[2] = 2\. Notice we’re following the programming
    convention of indexing from zero, so *a*[2] gives us the third element in the
    vector.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个元素是 *a*[2] = 2。注意我们遵循从零开始索引的编程惯例，所以 *a*[2] 给我们的是向量中的第三个元素。
- en: 'The vector above was written horizontally and therefore is known as a *row
    vector*. When used in mathematical expressions, however, vectors are usually assumed
    to be written vertically:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的向量是水平书写的，因此它被称为*行向量*。然而，在数学表达式中，通常假设向量是垂直书写的：
- en: '![Image](Images/004equ02.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![Image](Images/004equ02.jpg)'
- en: 'When written vertically, a vector is known as a *column vector*. This vector
    has five elements and is denoted as a five-element column vector. In this book,
    we’ll typically use vectors to represent one *sample*: one set of features that
    we’ll input to a model.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 当垂直书写时，向量称为*列向量*。这个向量有五个元素，被表示为一个五元素的列向量。在本书中，我们通常使用向量表示一个*样本*：我们将输入模型的一组特征。
- en: Mathematically, vectors are used to represent points in space. If we’re talking
    about the two-dimensional (2D) Cartesian plane, we locate a point with a vector
    of two numbers, (*x*,*y*), where *x* is the distance along the x-axis and *y*
    is the distance along the y-axis. That vector represents a point in two dimensions,
    even though the vector itself has only one dimension. If we have three dimensions,
    we need a vector with three elements, (*x*,*y*,*z*).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学上讲，向量用于表示空间中的点。如果我们讨论的是二维（2D）笛卡尔平面，我们用一个由两个数字组成的向量（*x*，*y*）来定位一个点，其中 *x*
    是沿 x 轴的距离，*y* 是沿 y 轴的距离。这个向量代表一个二维的点，尽管这个向量本身只有一维。如果我们有三维空间，我们需要一个包含三个元素的向量（*x*，*y*，*z*）。
- en: In machine learning, since we often use vectors to represent the inputs to our
    models, we’ll be working with dozens to hundreds of dimensions. Of course, we
    can’t plot them as points in a space, but mathematically, that’s what they are.
    As we’ll see, some models, such as the *k*-Nearest Neighbors model, use the feature
    vectors as just that—points in a high-dimensional space.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，由于我们经常使用向量来表示模型的输入，我们将处理几十到上百维的向量。当然，我们不能将它们作为空间中的点来绘制，但是从数学角度来看，它们就是这样。正如我们将看到的那样，一些模型，比如
    *k*-最近邻模型，会将特征向量视为——在高维空间中的点。
- en: Matrices
  id: totrans-41
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 矩阵
- en: 'A *matrix* is a two-dimensional array of numbers where we index a particular
    entry by its row number and column number. For example, this is a matrix:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '*矩阵*是一个二维的数字数组，我们通过行号和列号来索引特定的条目。例如，这是一个矩阵：'
- en: '![Image](Images/005equ01.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![Image](Images/005equ01.jpg)'
- en: If we want to refer to the 6, we write *a*[1,2] = 6\. Again, we’re indexing
    from zero. Because this matrix *a* has three rows and three columns, we call it
    a 3 × 3 matrix.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想引用6，我们写作 *a*[1,2] = 6。再次说明，我们是从零开始索引的。因为这个矩阵 *a* 有三行三列，所以我们称它为一个 3 × 3
    矩阵。
- en: Multiplying Vectors and Matrices
  id: totrans-45
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 向量和矩阵的乘法
- en: 'The simplest way to think of multiplying two vectors together is to multiply
    their corresponding elements. For example:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的理解两个向量相乘的方式是将它们对应的元素相乘。例如：
- en: '[1, 2, 3] × [4, 5, 6] = [4, 10, 18]'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[1, 2, 3] × [4, 5, 6] = [4, 10, 18]'
- en: This is the most common way to multiply an array when using a toolkit like NumPy,
    and we’ll make heavy use of this in the chapters that follow. However, in mathematics,
    this is seldom actually done.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这是使用像 NumPy 这样的工具包进行数组乘法时最常见的方式，在接下来的章节中我们将大量使用这种方式。然而，在数学中，实际上很少这么做。
- en: When multiplying vectors together mathematically, we need to know if they are
    row or column vectors. We’ll work with two vectors, *A* = (*a*,*b*,*c*), and *B*
    = (*d*,*e*,*f* ), which, following mathematical convention, are assumed to be
    column vectors. Adding a superscript *T* turns a column vector into a row vector.
    The mathematically allowed ways to multiply *A* and *B* are
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 当数学上进行向量相乘时，我们需要知道它们是行向量还是列向量。我们将使用两个向量，*A* = (*a*,*b*,*c*) 和 *B* = (*d*,*e*,*f*)，根据数学惯例，它们被假定为列向量。加上上标
    *T* 会将列向量转为行向量。*A* 和 *B* 的乘法在数学上允许的方式有：
- en: '![Image](Images/005equ02.jpg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![Image](Images/005equ02.jpg)'
- en: which is called the *outer product* and
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这被称为*外积*，并且
- en: '![Image](Images/005equ03.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![Image](Images/005equ03.jpg)'
- en: which is called the *inner product*, or *dot product*. Notice that the outer
    product becomes a matrix, and the inner product becomes a single number, a *scalar*.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这被称为*内积*，或*点积*。注意，外积会变成一个矩阵，而内积则变成一个单一的数字，即*标量*。
- en: When multiplying a matrix and a vector, the vector is typically on the right
    side of the matrix. The multiplication can proceed if the number of columns in
    the matrix matches the number of elements in the vector, again assumed to be a
    column vector. The result is also a vector with as many elements as there are
    rows in the matrix (read *ax* + *by* + *cz* as a single element).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们将矩阵和向量相乘时，向量通常位于矩阵的右侧。如果矩阵的列数与向量的元素数匹配（假设向量是列向量），则可以进行乘法运算。结果也是一个向量，元素数量等于矩阵的行数（读取*ax*
    + *by* + *cz* 作为一个单独的元素）。
- en: 'For example:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 例如：
- en: '![Image](Images/006equ01.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![Image](Images/006equ01.jpg)'
- en: 'Here we’ve multiplied a 2 × 3 matrix by a 3 × 1 column vector to get a 2 ×
    1 output vector. Notice that the number of columns of the matrix and the number
    of rows of the vector match. If they do not, then the multiplication is not defined.
    Also, notice that the values in the output vector are sums of products of the
    matrix and vector. This same rule applies when multiplying two matrices:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们将一个 2 × 3 矩阵与一个 3 × 1 的列向量相乘，得到了一个 2 × 1 的输出向量。注意，矩阵的列数与向量的行数匹配。如果不匹配，则乘法运算是未定义的。此外，注意输出向量中的值是矩阵和向量乘积的和。这个规则同样适用于两个矩阵的乘法：
- en: '![Image](Images/006equ02.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![Image](Images/006equ02.jpg)'
- en: Here multiplying a 2 × 3 matrix by a 3 × 2 matrix has given us a 2 × 2 answer.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这里将一个 2 × 3 矩阵与一个 3 × 2 矩阵相乘，得到了一个 2 × 2 的结果。
- en: When we get to convolutional neural networks, we’ll work with arrays that have
    three and even four dimensions. Generically, these are referred to as *tensors*.
    If we imagine a stack of matrices, all the same size, we get a three-dimensional
    tensor, and we can use the first index to refer to any one of the matrices and
    the remaining two indices to refer to a particular element of that matrix. Similarly,
    if we have a stack of three-dimensional tensors, we have a four-dimensional tensor,
    and we can use the first index of that to refer to any one of the three-dimensional
    tensors.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们研究卷积神经网络时，我们将处理具有三维甚至四维的数组。一般来说，这些被称为*张量*。如果我们想象一堆大小相同的矩阵，我们得到的是一个三维张量，可以使用第一个索引来引用任何一个矩阵，剩下的两个索引来引用该矩阵中的特定元素。类似地，如果我们有一堆三维张量，我们就得到了四维张量，可以使用其第一个索引来引用任何一个三维张量。
- en: The main points of this section are that vectors have one dimension, matrices
    have two dimensions, there are rules for multiplying these objects together, and
    our toolkits will work with four-dimensional tensors in the end. We’ll review
    some of these points as we encounter them later in the book.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的主要内容是：向量是单维的，矩阵是二维的，存在将这些对象相乘的规则，最终我们的工具包将处理四维张量。我们将在本书后面遇到这些内容时再做回顾。
- en: Statistics and Probability
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 统计学和概率学
- en: The topics of statistics and probability are so broad that often it’s better
    to either say almost nothing or to write a book or two. Therefore, I’ll mention
    only key ideas that we’ll use throughout the book and leave the rest to you to
    pick up as you see fit. I’ll assume you know some basic things about probability
    from flipping coins and rolling dice.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 统计学和概率学的主题非常广泛，以至于通常最好要么几乎什么都不说，要么写一本或两本书。因此，我将只提及我们在本书中会使用的关键概念，其他的内容你可以根据需要自行掌握。我假设你已经知道一些关于抛硬币和掷骰子的基本概率知识。
- en: Descriptive Statistics
  id: totrans-64
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 描述性统计
- en: When we do experiments, we need to report the results in some meaningful way.
    Typically, for us, we’ll report results as the mean (arithmetic average) plus
    or minus a quantity known as the *standard error of the mean (SE)*. Let’s define
    the standard error of the mean through an example.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们进行实验时，我们需要以某种有意义的方式报告结果。通常，对于我们来说，我们会报告结果为均值（算术平均值）加减一个称为*均值标准误差（SE）*的量。我们通过一个例子来定义均值标准误差。
- en: If we have many measurements *x*, say the length of a part of a flower, then
    we can calculate the mean (![Image](Images/xbar.jpg)) by adding all the values
    together and dividing by the number of values we added. Then, once we have the
    mean, we can calculate the average spread of the individual values around the
    mean by subtracting each value from the mean, squaring the result, and adding
    all these squared values together before dividing by the number of values we added
    minus one. This number is the *variance*. If we take the square root of this value,
    we get the *standard deviation* (*σ*), which we’ll see again below. With the standard
    deviation, we can calculate the standard error of the mean as ![Image](Images/007equ01.jpg),
    where *n* is the number of values that we used to calculate the mean. The smaller
    the SE is, the more tightly the values are clustered around the mean. We can interpret
    this value as the uncertainty we have about the mean value. This means we expect
    the actual mean, which we don’t really know, to be between ![Image](Images/007equ02.jpg)
    and ![Image](Images/007equ03.jpg).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有很多测量值*x*，比如说一朵花的一部分的长度，那么我们可以通过将所有值相加并除以我们相加的值的个数来计算均值 (![Image](Images/xbar.jpg))。然后，一旦得到均值，我们可以通过将每个值与均值相减、将结果平方，并将这些平方值加总起来，再除以我们加总的值的个数减去一，来计算各个值围绕均值的平均分布。这一数值就是*方差*。如果我们取这个值的平方根，就能得到*标准差*（*σ*），我们将在下面再次看到它。通过标准差，我们可以计算均值的标准误差，公式为![Image](Images/007equ01.jpg)，其中*n*是我们用来计算均值的值的数量。标准误差越小，表示值越紧密地聚集在均值周围。我们可以把这个值解释为我们对于均值的
    uncertainty（不确定性）。这意味着我们预计实际均值（我们并不知道的）会介于![Image](Images/007equ02.jpg)和![Image](Images/007equ03.jpg)之间。
- en: Sometimes, we’ll talk about the median instead of the mean. The *median* is
    the middle value, the value that half of our samples are below and half are above.
    To find the median for a set of values, we first sort the values numerically and
    then find the middle value. This is the exact middle value if we have an odd number
    of samples, or the mean of the two middle values if we have an even number of
    samples. The median is sometimes more useful than the mean if the samples do not
    have a good, even spread around the mean. The classic example is income. A few
    very rich people move the mean income up to the point where it does not have much
    meaning. Instead, the median, the value where half the people make less and half
    make more, is more representative.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，我们会讨论中位数而不是均值。*中位数*是中间的值，它将一半的样本值分布在它的下方，另一半分布在它的上方。为了找到一组值的中位数，我们首先按数值对这些值进行排序，然后找出中间的值。如果样本数是奇数，那么这个值就是精确的中间值；如果样本数是偶数，那么中位数是两个中间值的平均值。如果样本在均值周围没有良好、均匀的分布，那么中位数有时比均值更有用。经典的例子是收入。少数非常富有的人会把均收入推高到一个没有多大意义的水平。相反，中位数——即一半人收入低于它，一半人收入高于它——更具代表性。
- en: 'In later chapters, we’ll talk about *descriptive statistics*. These are values
    derived from a dataset that can be used to understand the dataset. We just mentioned
    three of them: the mean, the median, and the standard deviation. We’ll see how
    to use these and how they can be plotted to help us understand a dataset.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在后面的章节中，我们将讨论*描述性统计*。这些是从数据集中派生出的值，可以用来理解数据集。我们刚刚提到过其中的三个：均值、中位数和标准差。我们将学习如何使用这些值，并如何将它们绘制出来，帮助我们理解数据集。
- en: Probability Distributions
  id: totrans-69
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 概率分布
- en: In this book, we’ll talk about something known as a *probability distribution*.
    You can think of it as an oracle of sorts—something that, when asked, will give
    us a number or set of numbers. For example, when we train a model, we use numbers,
    or sets of numbers, that we measure; we can think of those numbers as coming from
    a probability distribution. We’ll refer to that distribution as the *parent distribution*.
    Think of it as the thing that generates the data we’ll feed our model; another,
    more Platonic, way to think about it is as the ideal set of data that our data
    is approximating.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们将讨论一种被称为*概率分布*的概念。你可以把它看作是一种预言者——一种当被询问时，会给我们一个数字或一组数字的东西。例如，当我们训练一个模型时，我们使用的是我们测量的数字或数字集合；我们可以把这些数字看作是来自一个概率分布。我们将把这种分布称为*母体分布*。把它看作是生成我们输入模型的数据的东西；另一种更具柏拉图式的思维方式是，它是我们数据所逼近的理想数据集。
- en: 'Probability distributions come in many different forms; some even have names.
    The two that we’ll encounter are the two most common: uniform and normal distributions.
    You’ve already encountered a uniform distribution: it’s what we get if we roll
    a fair die. If the die has six sides, we know that the likelihood of getting any
    value, 1 through 6, is the same. If we roll the die 100 times and tally the numbers
    that come up, we know that the tally will be roughly equal for each number and
    that in the long run, we can easily convince ourselves that the number will even
    out.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 概率分布有许多不同的形式；其中一些甚至有专门的名称。我们将遇到的两种分布是最常见的两种：均匀分布和正态分布。你已经接触过均匀分布：这就是我们掷骰子时得到的结果。如果骰子有六个面，我们知道得到1到6中的任何一个数的概率是相同的。如果我们掷100次骰子并统计每个数字出现的次数，我们知道每个数字的统计结果大致相同，并且从长远来看，我们可以轻松地证明这些数字最终会趋于平衡。
- en: A *uniform distribution* is an oracle that is equally likely to give us any
    of its allowed responses. Mathematically, we’ll write uniform distributions as
    *U*(*a*,*b*) where *U* means uniform and *a* and *b* are the range of values it
    will use to bracket its response. Unless we specify the distribution gives only
    integers, any real number is allowed as the response. Notationally, we write *x*
    ~ *U*(0,1) to mean that *x* is a value returned by the oracle that gives real
    numbers in the range (0,1) with equal likelihood. Also, note that using “(" and
    “)" to bracket a range excludes the associated bound, while using “[" and “]"
    includes it. Thus *U*[0,1) returns values from 0 to 1, including 0 but excluding
    1.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '*均匀分布*是一个神谕，给出的每个响应的可能性是相等的。从数学上讲，我们将均匀分布写作*U*(*a*,*b*)，其中*U*表示均匀分布，*a*和*b*是它用来限定响应范围的值。除非我们特别说明分布只给出整数，否则任何实数都可以作为响应。在符号上，我们写作*x*
    ~ *U*(0,1)，意味着*x*是由神谕返回的一个值，范围在(0,1)之间，且每个值的出现概率相等。同时，请注意，使用“("和“)”来括起一个范围时，会排除相应的边界，而使用“["和“]”则会包括边界。因此，*U*[0,1)返回从0到1的值，包含0但不包含1。'
- en: A *normal distribution*, also called a *Gaussian* distribution, is visually
    a bell curve—a shape where one value is most likely, and then the likelihood of
    the other values decreases as one gets further from the most likely value. The
    most likely value is the mean, ![Image](Images/xbar.jpg), and the parameter that
    controls how quickly the likelihood drops to zero (without ever really reaching
    it) is the standard deviation, *σ* (sigma). For our purposes, if we want a sample
    from a normal distribution, we’ll write ![Image](Images/008equ01.jpg) to mean
    *x* is drawn from a normal distribution with a mean of ![Image](Images/xbar.jpg)
    and a standard deviation of *σ*.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '*正态分布*，也叫做*高斯*分布，形状上是一个钟形曲线——在这种形状中，一个值最为可能，随着与最可能值的距离增大，其他值的可能性逐渐减小。最可能的值是均值，![Image](Images/xbar.jpg)，而控制可能性下降至零（但永远不会真正达到零）的参数是标准差，*σ*（sigma）。对于我们的目的，如果我们想从正态分布中获取一个样本，我们会写作![Image](Images/008equ01.jpg)，表示*x*是从一个均值为![Image](Images/xbar.jpg)且标准差为*σ*的正态分布中抽取的。'
- en: Statistical Tests
  id: totrans-74
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 统计检验
- en: Another topic that will pop up from time to time is the idea of a *statistical
    test*, a measurement used to decide if a particular hypothesis is likely true
    or not. Typically, the hypothesis relates to two sets of measurements, and the
    hypothesis is that the two sets of measurements came from the same parent distribution.
    If the statistic calculated by the test is outside of a certain range, we reject
    the hypothesis and claim we have evidence that the two sets of measurements are
    *not* from the same parent distribution.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个偶尔出现的主题是*统计检验*的概念，这是用来判断某个假设是否可能为真的一种测量方法。通常，假设与两组测量相关，假设是这两组测量来自同一个母体分布。如果通过检验计算得到的统计量超出了某个范围，我们就会拒绝该假设，并宣称我们有证据表明这两组测量数据*不是*来自同一个母体分布。
- en: Here, we’ll usually use the *t-test*, a common statistical test that assumes
    our data is normally distributed. Because we assumed that our data is normally
    distributed, which may or may not be true, the t-test is known as a *parametric
    test*.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们通常使用* t检验*，这是一种常见的统计检验，假设我们的数据服从正态分布。由于我们假设数据服从正态分布，虽然这可能为真也可能不为真，因此t检验被称为*参数检验*。
- en: Sometimes, we’ll use another test, the *Mann–Whitney U test*, which is like
    a t-test in that it helps us decide if two samples are from the same parent distribution,
    but it makes no assumption about how the data values in the sample are themselves
    distributed. Tests like these are known as *nonparametric tests*.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，我们会使用另一种检验——*Mann–Whitney U检验*，它类似于t检验，帮助我们判断两个样本是否来自相同的母体分布，但它不对样本数据值的分布做任何假设。像这样的检验被称为*非参数检验*。
- en: Whether the test is parametric or nonparametric, the value we ultimately get
    from the test is called a *p-value*. It represents the probability that we would
    see the test statistic value we calculated if the hypothesis that the samples
    come from the same parent distribution is true. If the *p*-value is low, we have
    evidence that the hypothesis is not true.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 无论测试是参数化的还是非参数化的，最终从测试中得到的值称为*p值*。它表示如果假设样本来自相同的母体分布为真，我们计算出的检验统计量值出现的概率。如果*p值*较低，那么我们有证据表明该假设不成立。
- en: The usual *p*-value cutoff is 0.05, indicating a 1 in 20 chance that we’d measure
    the test statistic value (t-test or Mann–Whitney U) even if the samples came from
    the same parent distribution. However, in recent years, it has become clear that
    this threshold is too generous. When *p*-values are near 0.05, but not above,
    we begin to think there is some evidence against the hypothesis. If the *p*-value
    is, say, 0.001 or even less, then we have strong evidence that the samples are
    not from the same parent distribution. In this case, we say that the difference
    is *statistically significant*.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 通常的*p值*临界值是0.05，表示即使样本来自相同的母体分布，我们测量到该检验统计量值（t检验或Mann–Whitney U检验）的概率为20分之一。然而，近年来，已经明确这个临界值过于宽松。当*p值*接近0.05，但没有超过时，我们开始认为有一定证据反对假设。如果*p值*是0.001甚至更低，那么我们有强有力的证据表明样本来自不同的母体分布。在这种情况下，我们称这种差异为*统计显著*。
- en: Graphics Processing Units
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 图形处理单元
- en: One of the enabling technologies for modern deep learning was the development
    of powerful *graphics processing units (GPUs)*. These are co-computers implemented
    on graphics cards. Originally designed for video gaming, the highly parallel nature
    of GPUs has been adapted to the extreme computational demands of deep neural network
    models. Many of the advances of recent years would not have been possible without
    the supercomputer-like abilities GPUs provide to even basic desktop computers.
    NVIDIA is the leader in the creation of GPUs for deep learning, and via its Compute
    Unified Device Architecture (CUDA), NVIDIA has been foundational to the success
    of deep learning. It’s not an understatement to say that without GPUs, deep learning
    would not have happened, or at least not been so widely used.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现代深度学习的一个重要推动技术是强大的*图形处理单元（GPU）*的发展。GPU是实现于显卡上的协处理器。最初为视频游戏设计，GPU的高度并行特性已被应用于深度神经网络模型的极端计算需求。近年来的许多进展若没有GPU为即使是基础台式计算机提供的超级计算机般的能力，是不可能实现的。NVIDIA是深度学习GPU创作的领导者，通过其计算统一设备架构（CUDA），NVIDIA在深度学习成功中发挥了基础性作用。毫不夸张地说，如果没有GPU，深度学习可能就不会发生，或者至少不会被如此广泛应用。
- en: That said, we’re not expecting GPUs to be present for the models we’ll work
    with in this book. We’ll use small enough datasets and models so that we can train
    in a reasonable amount of time using just a CPU. We’ve already enforced this decision
    in the packages we’ve installed, since the version of TensorFlow we installed
    is a CPU-only version.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，我们并不期望在本书中使用的模型需要GPU。我们将使用足够小的数据集和模型，以便仅使用CPU在合理的时间内进行训练。我们在已安装的包中已经强制执行了这一决定，因为我们安装的TensorFlow版本是仅支持CPU的版本。
- en: If you do have a CUDA-capable GPU and you want to use it for the deep learning
    portion of this book, please do so, but don’t think that you need to purchase
    one to run the examples. If you’re using a GPU, be sure to have CUDA properly
    installed before installing the packages indicated previously and be sure to install
    a GPU-enabled version of TensorFlow. The sklearn toolkit is CPU only.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有一块支持CUDA的GPU，并且想在本书的深度学习部分使用它，当然可以，但不要认为你需要购买一块GPU来运行示例。如果使用GPU，确保在安装前述包时已经正确安装CUDA，并且安装支持GPU的TensorFlow版本。sklearn工具包仅支持CPU。
- en: Summary
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we summarized our operating environment. Next, we described
    the essential Python toolkits we’ll use throughout the book and gave detailed
    instructions for installing the toolkits assuming an Ubuntu 20.04 Linux distribution.
    As mentioned, the toolkits will work just as nicely on many other Linux distributions
    as well as macOS. We then briefly reviewed some of the math we’ll encounter later
    and ended with an explanation of why we do not need GPUs for our models.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们总结了我们的操作环境。接下来，我们描述了本书中将使用的基本 Python 工具包，并假设使用 Ubuntu 20.04 Linux 发行版，给出了详细的安装说明。如前所述，这些工具包在许多其他
    Linux 发行版以及 macOS 上也能顺利运行。然后，我们简要回顾了稍后会遇到的一些数学内容，并以解释为什么我们的模型不需要 GPU 作为结尾。
- en: In the next chapter, we’ll review the fundamentals of Python.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将回顾 Python 的基础知识。

- en: '10'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '10'
- en: BIG O AND PROGRAM EFFICIENCY
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 大O符号与程序效率
- en: '![image](Images/common.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/common.jpg)'
- en: 'In the first seven chapters of this book, we focused on writing programs that
    were correct: for any valid input, we wanted our program to produce the desired
    output. In addition to correct code, though, we generally want efficient code,
    code that runs quickly even in the face of huge amounts of input. You may have
    received the occasional time limit exceeded error when working through the first
    seven chapters, but our first formal foray into program efficiency wasn’t until
    [Chapter 8](ch08.xhtml#ch08), when we solved Email Addresses. We saw there that
    sometimes we need to make our programs more efficient so that they can finish
    within a given time limit.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的前七章中，我们专注于编写正确的程序：对于任何有效的输入，我们希望程序能够输出期望的结果。然而，除了正确的代码，我们通常还希望代码高效，能够在大量输入下仍然快速运行。你可能在阅读前七章时偶尔遇到过时间超限的错误，但我们正式进入程序效率的讨论是在[第8章](ch08.xhtml#ch08)，当时我们解决了电子邮件地址的问题。我们在那时看到，有时我们需要提高程序的效率，以便它们能在规定的时间内完成。
- en: 'In this chapter, we’ll first learn how programmers think and communicate about
    program efficiency. Then, we’ll study two problems where we’ll need to write efficient
    code: determining the most desired piece of a scarf and painting a ribbon.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们首先将学习程序员如何思考和沟通程序效率。然后，我们将研究两个需要编写高效代码的问题：确定围巾的最理想部分和绘制丝带。
- en: 'For each problem, we’ll see that our initial ideas lead to an algorithm that
    would not be efficient enough. But we’ll keep at it until we design a faster algorithm
    for the same problem, one that’s dramatically more efficient than before. This
    exemplifies a common workflow for programmers: first, come up with a correct algorithm;
    then, only if needed, make it faster.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个问题，我们会发现最初的想法会导致一个效率不够高的算法。但我们会坚持下去，直到我们为同一个问题设计出一个更快的算法，比之前高效得多。这 exemplifies（体现）了程序员的常见工作流程：首先，提出一个正确的算法；然后，只有在需要时，再让它变得更快。
- en: The Problem with Timing
  id: totrans-6
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定时问题
- en: Each competitive programming problem that we solve in this book has a time limit
    on how long our program will be allowed to run. (I began including time limits
    in the problem descriptions of [Chapter 8](ch08.xhtml#ch08), when we started running
    into programming problems where efficiency is a serious concern.) If our program
    exceeds the time limit, then the judge terminates our program with a time limit
    exceeded error. A time limit is designed to prevent solutions that are too slow
    from passing the test cases. For example, perhaps we come up with a complete-search
    solution but the author of the problem has worked out a solution that’s much faster.
    That faster solution may be a variation of complete search, as it was when we
    solved the Cow Baseball problem in [Chapter 9](ch09.xhtml#ch09), or it may be
    a different approach entirely. Regardless, the time limit may be set such that
    our complete-search solution will not finish in time. As such, in addition to
    being correct, we may need our programs to be fast.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中我们解决的每一个竞赛编程问题，都有一个时间限制，规定了我们的程序运行的最长时间。（从[第8章](ch08.xhtml#ch08)开始，我就将时间限制包括在问题描述中，那时我们开始遇到效率成为严重问题的编程题。）如果我们的程序超过时间限制，评测系统将终止程序并给出时间超限的错误提示。时间限制旨在防止过慢的解决方案通过测试用例。例如，可能我们提出了一个完全搜索的解决方案，但问题的作者已经想出了一个更快的解决方案。那个更快的解决方案可能是完全搜索的变体，正如我们在[第9章](ch09.xhtml#ch09)解决《牛的棒球问题》时那样，或者可能是完全不同的方法。不管怎样，时间限制的设置可能使得我们的完全搜索解法无法按时完成。因此，除了保证正确性，我们的程序可能还需要足够快。
- en: We can run a program to explore whether it is efficient enough. For example,
    think back to “Efficiency of Searching a List” in [Chapter 8](ch08.xhtml#ch08)
    when we tried to solve Email Addresses using a list. We ran code that used bigger
    and bigger lists to get a sense of the amount of time taken by list operations.
    This kind of testing can give us some understanding of the efficiency of our programs.
    If our program is too slow, according to the time limit for the problem, then
    we know that we need to optimize the current code or find a wholly new approach.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以运行程序来探索它是否足够高效。例如，回想一下在[第8章](ch08.xhtml#ch08)中“搜索列表的效率”部分，我们尝试使用列表来解决电子邮件地址的问题。我们运行了使用越来越大的列表的代码，以了解列表操作所需的时间。这种测试可以帮助我们理解程序的效率。如果我们的程序太慢，超过了问题的时间限制，那么我们就知道需要优化当前的代码或找到一种全新的方法。
- en: The amount of time taken by a program depends on the computer it is being run
    on. We don’t know what kind of computer the judge is using, but running the program
    on our own computer is still informative because the judge is probably using a
    computer that’s at least as fast as ours. Say that we run our program on our laptop
    and it takes 30 seconds on some small test case. If the problem time limit is
    three seconds, we can be confident that our program is simply not fast enough.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 程序所需的时间取决于运行它的计算机。我们无法得知评测机使用的是什么类型的计算机，但在我们自己的计算机上运行程序仍然有参考价值，因为评测机可能至少和我们的计算机一样快。假设我们在笔记本上运行程序，某个小的测试用例需要30秒。如果问题的时间限制是三秒钟，我们可以确定我们的程序明显不够快。
- en: An exclusive focus on time limits, however, is limiting. Think about our first
    solution to Cow Baseball in [Chapter 9](ch09.xhtml#ch09). We didn’t need to run
    that code to determine how slow it would be. That’s because we were able to characterize
    the program in terms of the amount of work that it would do if we did run it.
    For example, in “Efficiency of Our Program” on [page 253](ch09.xhtml#ch09lev2sec16),
    we said that for *n* cows, our program processes *n*³ triples of cows. Notice
    that our focus here is not on the number of seconds our program would take to
    run, but on how much work it does in terms of the amount of input *n*.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，单纯专注于时间限制是有限的。想一想我们在[第9章](ch09.xhtml#ch09)中对牛棒球问题的第一个解法。我们并不需要运行代码来确定它的执行速度。这是因为我们能够通过程序需要执行的工作量来描述程序的效率，就算我们没有真正运行它。例如，在[第253页](ch09.xhtml#ch09lev2sec16)的“程序效率”部分，我们提到，对于*n*头牛，我们的程序会处理*n*³个牛的三元组。请注意，我们关注的不是程序运行所需的秒数，而是它在处理输入*n*时所需的工作量。
- en: 'There are significant advantages to this kind of analysis compared to running
    our programs and recording execution times. Here are five:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 与运行程序并记录执行时间相比，这种分析方法有显著的优势。以下是五个优点：
- en: '**Execution time depends on the computer** Timing our program tells us only
    how long our program takes on one computer. That’s very specific information,
    and it gives us little in the way of understanding what to expect when the program
    is run on other computers. When working through the book, you may have also noticed
    that the time taken by a program varies from run to run, even on the same computer.
    For example, you might run a program on a test case and find that it takes three
    seconds; you might then run it again, on the same test case, and find that it
    takes two-and-a-half seconds or three-and-a-half seconds. The reason for this
    difference is that your operating system is managing your computing resources,
    shunting them around to different tasks as needed. The decisions that your operating
    system makes influence the runtime of your program.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**执行时间依赖于计算机**。对我们的程序进行计时，只能告诉我们程序在某一台计算机上运行需要多长时间。这是非常具体的信息，对于了解程序在其他计算机上的运行表现帮助不大。当你在阅读本书时，可能也注意到，即使在同一台计算机上，程序的执行时间也会有所不同。例如，你可能会在一个测试用例上运行程序，发现它需要三秒钟；然后你再运行同一个测试用例，可能发现它需要两秒半或三秒半。这种差异的原因在于，操作系统正在管理你的计算资源，并根据需要将它们分配给不同的任务。操作系统的决策会影响程序的运行时间。'
- en: '**Execution time depends on the test case** Timing our program on a test case
    tells us only how long our program takes on that test case. Suppose that our program
    takes three seconds to run on a small test case. That may seem fast, but here’s
    the truth about small test cases: every reasonable solution for a problem will
    quickly be able to solve those. If I ask you to tell me the number of unique email
    addresses among 10 email addresses, or the number of triples of cows among 10
    cows, you can quickly do it with the first correct idea that you have. What’s
    interesting, then, are large test cases. They are the ones where algorithmic ingenuity
    pays off. How long will our program take on a large test case or on a huge test
    case? We don’t know. We’d have to run our program on those test cases, too. Even
    if we did that, there could be specific kinds of test cases that trigger poorer
    performance. We may be led to believe that our program is faster than it is.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**执行时间依赖于测试用例** 对程序进行计时只会告诉我们它在某个测试用例上运行了多长时间。假设我们的程序在一个小型测试用例上运行需要三秒钟。这看起来很快，但关于小型测试用例的真相是：每个合理的解决方案都能很快解决这些问题。如果我让你告诉我10个电子邮件地址中有多少个不同的地址，或者在10头牛中有多少组三个牛的组合，你可以通过第一个正确的想法迅速解决。真正有趣的是大型测试用例。它们是算法创新得以体现的地方。我们的程序在大型测试用例或巨型测试用例上需要多久？我们不知道。我们还需要在这些测试用例上运行程序。即使我们这么做了，也可能会有特定类型的测试用例导致程序性能较差。我们可能会误以为程序比实际更快。'
- en: '**The program requires implementation** We can’t time something that we don’t
    implement. Suppose that we’re thinking about a problem and come up with an idea
    for how to solve it. Is it fast? Although we could implement it to find out, it
    would be nice to know, in advance, whether or not the idea is likely to lead to
    a fast program. You would not implement a program that you knew, at the outset,
    would be incorrect. It would similarly be nice to know, at the outset, that a
    program would be too slow.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**程序需要实现** 我们无法对一个尚未实现的程序进行计时。假设我们正在思考一个问题，并想到一个解决方案。它快吗？尽管我们可以通过实现它来找出答案，但如果能提前知道这个想法是否可能导致一个快速的程序，那将会更好。你不会实现一个你一开始就知道会出错的程序。同样，知道一个程序一开始就会太慢也是很有用的。'
- en: '**Timing doesn’t explain slowness** If we find that our program is too slow,
    then our next task is to design a faster one. However, simply timing a program
    gives us no insight into why our program is slow. It just is. Further, if we manage
    to think up a possible improvement to our program, we’d need to implement it to
    see whether or not it helps.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**计时并不能解释程序的慢速** 如果我们发现程序太慢，那么接下来的任务就是设计一个更快的程序。然而，单纯地计时程序并不能让我们深入了解程序为何慢。它只是慢而已。更进一步地，如果我们想到可能的改进方案，还需要实际实现它，以确定是否能提升性能。'
- en: '**Execution time is not easily communicated** For many of the reasons listed,
    it’s difficult to use execution time to talk to other people about the efficiency
    of algorithms. Execution time is too specific: it depends on the computer, operating
    system, test case, programming language, and particular implementation that’s
    used. We’d have to provide all of this information to others interested in the
    efficiency of our algorithm.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**执行时间不容易传达** 由于许多原因，使用执行时间与他人讨论算法的效率是困难的。执行时间过于具体：它依赖于计算机、操作系统、测试用例、编程语言以及所使用的具体实现。我们必须提供所有这些信息，才能让其他人了解我们算法的效率。'
- en: 'Not to worry: computer scientists have devised a notation that addresses these
    shortcomings of timing. It’s independent of the computer, independent of test
    case, and independent of a particular implementation. It signals why a slow program
    is slow. It’s easily communicated. It’s called *big O*, and it’s coming right
    up.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 不用担心：计算机科学家已经设计了一种符号来解决计时的这些不足之处。它独立于计算机、独立于测试用例，并且独立于特定的实现。它能指示为什么一个程序会慢。它易于传达。这就是*大O表示法*，接下来就会介绍。
- en: Big O
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 大O表示法
- en: Big O is a notation that computer scientists use to concisely describe the efficiency
    of algorithms. The key concept here is the *efficiency class*, which tells you
    how fast an algorithm is or, equivalently, how much work it does. The faster an
    algorithm, the less work it does; the slower an algorithm, the more work it does.
    Each algorithm belongs to an efficiency class; the efficiency class tells you
    how much work that algorithm does relative to the amount of input that it must
    process. To understand big O, we need to understand these efficiency classes.
    We’re now going to study seven of the most common ones. We’ll see those that do
    the least amount of work, the ones you’ll hope your algorithms fit into. We’ll
    also see those that do considerably more work, the ones whose algorithms will
    probably give you time limit exceeded errors.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 大O表示法是计算机科学家用来简洁描述算法效率的符号。这里的关键概念是*效率类*，它告诉你算法的运行速度，或者更确切地说，它告诉你算法做了多少工作。算法越快，做的工作就越少；算法越慢，做的工作就越多。每个算法都属于一个效率类；效率类告诉你该算法在处理必须处理的输入时，所做的工作量。为了理解大O，我们需要了解这些效率类。我们现在将学习七种最常见的效率类。我们将看到那些做最少工作的算法——你希望你的算法能符合这些效率类。我们还将看到那些做更多工作的算法——这些算法可能会让你遇到“超时限制”错误。
- en: Constant Time
  id: totrans-20
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 常数时间
- en: The most desirable algorithms are those that don’t do more work as the amount
    of input increases. No matter the problem instance, such an algorithm takes about
    the same number of steps. These are called *constant-time* algorithms.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 最理想的算法是那些随着输入量增加而不增加工作量的算法。无论问题实例如何，这种算法所需要的步骤数大致相同。这样的算法被称为*常数时间*算法。
- en: 'This is hard to believe, right? An algorithm that does about the same amount
    of work, no matter what? Indeed, solving a problem with such an algorithm is rare.
    But when you can do it, rejoice: you can’t do any better than that.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这很难相信，对吧？一个做大致相同工作量的算法，无论输入是什么？的确，能用这种算法解决问题是很少见的。但当你能做到时，值得高兴：你无法做得比这更好了。
- en: 'We’ve managed to solve a few problems in this book using constant-time algorithms.
    Think back to the Telemarketers problem in [Chapter 2](ch02.xhtml#ch02), where
    we had to determine whether the provided phone number belongs to a telemarketer.
    I’ve reproduced our solution from [Listing 2-2](ch02.xhtml#ch02ex02) here:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经通过常数时间算法解决了这本书中的一些问题。回想一下在[第二章](ch02.xhtml#ch02)中，我们需要确定提供的电话号码是否属于推销员。我在这里重新展示了我们在[清单2-2](ch02.xhtml#ch02ex02)中的解决方案：
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Our solution does the same amount of work no matter what the four digits of
    the phone number are. The code starts by reading the input. Then it makes some
    comparisons with `num1`, `num2`, `num3`, and `num4`. If the phone number belongs
    to a telemarketer, we output something; if it doesn’t belong to a telemarketer,
    we output something else. There’s no input that can make our program do more work
    than this.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的解决方案做的工作量相同，无论电话号码的四个数字是什么。代码首先读取输入。然后它会与`num1`、`num2`、`num3`和`num4`做一些比较。如果电话号码属于推销员，我们输出某些内容；如果不属于推销员，我们输出其他内容。没有任何输入能让我们的程序做比这更多的工作。
- en: 'Earlier in [Chapter 2](ch02.xhtml#ch02), we solved Winning Team. Did we solve
    that one in constant time, too? We did! Here’s the solution from [Listing 2-1](ch02.xhtml#ch02ex01):'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第二章](ch02.xhtml#ch02)的前面，我们解决了“获胜团队”问题。我们也用了常数时间来解决它吗？是的！这里是我们在[清单2-1](ch02.xhtml#ch02ex01)中的解决方案：
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We read the input, compute the total points for the Apples, compute the total
    points for the Bananas, compare those totals, and output a message. It doesn’t
    matter how many points the Apples or Bananas have—our program always does the
    same amount of work.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们读取输入，计算苹果的总分，计算香蕉的总分，比较这两个总分，并输出一条信息。苹果或香蕉的分数多少并不重要——我们的程序始终做相同量的工作。
- en: Hold on—what if the Apples scored zillions and zillions of three-point shots?
    Surely, it takes longer for the computer to work with ginormous numbers than small
    numbers like 10 or 50? While that’s true, we don’t have to worry about that here.
    The problem description states that each team scores at most 100 of each type
    of play. We’re therefore working with small numbers, and it’s fair to say that
    the computer can read or operate on these numbers in a constant number of steps.
    In general, you can think of numbers up to a few billion as “small.”
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 等一下——如果苹果队投进了无数个三分球怎么办？难道计算机处理这么巨大的数字不会比处理像 10 或 50 这样的小数字需要更长的时间吗？虽然这是事实，但我们在这里不需要担心这个问题。问题描述中说明每支队伍每种类型的得分最多是
    100 次。因此，我们处理的是小数字，可以公平地说计算机可以在固定的步骤数内读取或操作这些数字。一般来说，你可以将几亿以下的数字视为“小”数字。
- en: In big O notation, we say that a constant-time algorithm is *O*(1). The 1 doesn’t
    mean that you’re stuck performing only one step in a constant-time algorithm.
    If you perform a fixed number of steps, like 10 or even 10,000, it’s still constant
    time. But don’t write *O*(10) or *O*(10000)—all constant-time algorithms are denoted
    *O*(1).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在大 O 表示法中，我们说一个常数时间算法是 *O*(1)。这里的 1 并不意味着你只能在常数时间算法中执行一步操作。如果你执行固定次数的步骤，比如 10
    步或甚至 10,000 步，它仍然是常数时间。但不要写 *O*(10) 或 *O*(10000)—所有常数时间算法都表示为 *O*(1)。
- en: Linear Time
  id: totrans-31
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 线性时间
- en: Most algorithms are not constant-time algorithms. Instead, they do an amount
    of work that depends on the amount of input. For example, they do more work to
    process 1,000 values than they do to process 10 values. What distinguishes these
    algorithms from each other is the relationship between the amount of input and
    the amount of work that the algorithm does.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数算法不是常数时间算法。相反，它们的工作量取决于输入量。例如，它们处理 1,000 个值时要做的工作比处理 10 个值时要做的工作多。区分这些算法的特点在于输入量与算法所做的工作量之间的关系。
- en: A *linear-time* algorithm is one with a linear relationship between the amount
    of input and the amount of work done. Suppose we run a linear-time algorithm on
    an input with 50 values, and then we run it again on an input with 100 values.
    The algorithm will do about twice as much work on the 100 values compared with
    on the 50 values.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '*线性时间* 算法是指输入量与工作量之间存在线性关系的算法。假设我们在一个包含 50 个值的输入上运行一个线性时间算法，然后再在一个包含 100 个值的输入上运行它。与处理
    50 个值相比，算法在处理 100 个值时将大约多做一倍的工作。'
- en: 'For an example, let’s look at the Three Cups problem from [Chapter 3](ch03.xhtml#ch03).
    We solved that problem in [Listing 3-1](ch03.xhtml#ch03ex01), and I’ve reproduced
    our solution here:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个例子，让我们来看一下 [第 3 章](ch03.xhtml#ch03)中的三杯问题。我们在 [清单 3-1](ch03.xhtml#ch03ex01)
    中解决了这个问题，我在这里重现了我们的解决方案：
- en: '[PRE2]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: There’s a `for` loop ❶, and the amount of work that it does depends linearly
    on the amount of input. If there are five swaps to process, then the loop iterates
    five times. If there are 10 swaps to process, then the loop iterates 10 times.
    Each iteration of the loop performs a constant number of comparisons and may change
    what `ball_location` refers to. Therefore, the amount of work that this algorithm
    does is directly proportional to the number of swaps.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个 `for` 循环 ❶，它所做的工作量与输入量成线性关系。如果有 5 次交换需要处理，那么循环就迭代 5 次。如果有 10 次交换需要处理，那么循环就迭代
    10 次。每次循环迭代都执行固定数量的比较，并可能改变 `ball_location` 所指的内容。因此，这个算法所做的工作量与交换次数成正比。
- en: We typically use *n* to refer to the amount of input provided to a problem.
    Here, *n* is the number of swaps. If there are 5 swaps that we need to perform,
    then *n* is 5; if there are 10 swaps that we need to perform, then *n* is 10.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常用 *n* 来表示问题输入的数量。在这里，*n* 是交换的次数。如果我们需要执行 5 次交换，那么 *n* 就是 5；如果我们需要执行 10 次交换，那么
    *n* 就是 10。
- en: If there are *n* swaps, then our program does about *n* work. That’s because
    the `for` loop performs *n* iterations, each of which performs a constant number
    of steps. We don’t care how many steps it performs on each iteration, as long
    as it’s a constant number. Whether the algorithm performs a total of *n* steps
    or 10*n* steps or 10,000*n* steps, it’s a linear-time algorithm. In big O notation,
    we say that this algorithm is *O*(*n*).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有 *n* 次交换，那么我们的程序大约做 *n* 次工作。这是因为 `for` 循环执行了 *n* 次迭代，每次迭代都执行固定数量的步骤。我们不关心每次迭代执行多少步骤，只要它是固定数量的。不管算法总共执行了
    *n* 步、10*n* 步还是 10,000*n* 步，它都是一个线性时间算法。在大 O 表示法中，我们说这个算法是 *O*(*n*)。
- en: When using big O notation, we don’t include numbers in front of *n*. For example,
    an algorithm that takes 10*n* steps is written *O*(*n*), not *O*(10*n*). This
    helps us focus on the fact that the algorithm is linear time and away from the
    specifics of the linear relationship.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用大O表示法时，我们不包括*n*前面的数字。例如，一个需要 10*n* 步骤的算法应该写成 *O*(*n*)，而不是 *O*(10*n*)。这帮助我们集中注意算法是线性时间，而不是线性关系的具体细节。
- en: What if an algorithm takes 2*n* + 8 steps—what kind of algorithm is this? This
    is still linear time! The reason is that the linear term (2*n*) will come to dominate
    the constant term (8) as soon as *n* is big enough. For example, if *n* is 5,000,
    then 8*n* is 40,000\. The number 8 is so small compared to 40,000 that we may
    as well ignore it. In big O notation, we ignore everything except the dominant
    terms.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个算法需要 2*n* + 8 步——这是什么类型的算法？这仍然是线性时间！原因是，当*n*足够大时，线性项（2*n*）将会主导常数项（8）。例如，如果*n*是5000，那么
    8*n* 就是40000。数字8相比于40000是如此微不足道，以至于我们可以忽略它。在大O表示法中，我们忽略除了主导项之外的所有项。
- en: Many Python operations take constant time to do their work. For example, appending
    to a list, adding to a dictionary, or indexing a sequence or dictionary all take
    constant time.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 许多Python操作执行工作时需要常数时间。例如，向列表添加元素、向字典中添加元素或索引序列或字典都需要常数时间。
- en: But some Python operations take linear time to do their work. Be careful to
    count them as linear time and not constant time. For example, using the Python
    `input` function to read a long string takes linear time, because Python has to
    read each character on the line of input. Any operation that examines each character
    of a string or value in a list takes linear time as well.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 但是有些Python操作执行工作时需要线性时间。请小心将它们计算为线性时间，而不是常数时间。例如，使用Python的`input`函数读取一个长字符串需要线性时间，因为Python必须逐个字符地读取输入行。任何检查字符串中每个字符或列表中每个值的操作也需要线性时间。
- en: If an algorithm reads *n* values and processes each value in a constant number
    of steps, then it is a linear-time algorithm.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个算法读取 *n* 个值，并且以常数步骤处理每个值，那么它就是线性时间算法。
- en: 'We don’t need to go far to see another linear-time algorithm—our solution to
    Occupied Spaces in [Chapter 3](ch03.xhtml#ch03) is another such example. I’ve
    reproduced our solution from [Listing 3-3](ch03.xhtml#ch03ex03) here:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不用走得很远就能看到另一个线性时间算法——我们在[第3章](ch03.xhtml#ch03)中解决的占用空间问题就是另一个例子。我在这里复现了我们在[示例
    3-3](ch03.xhtml#ch03ex03)中的解决方案：
- en: '[PRE3]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We let *n* be the number of parking spaces. The pattern is the same as for
    Three Cups: we read the input and then perform a constant number of steps for
    each parking space.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们让 *n* 为停车位的数量。模式与三杯问题相同：我们读取输入，然后为每个停车位执行常数数量的步骤。
- en: '**CONCEPT CHECK**'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**概念检查**'
- en: In [Listing 1-1](ch01.xhtml#ch01ex01), we solved the Word Count problem. Here’s
    the code for that solution.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在[示例 1-1](ch01.xhtml#ch01ex01)中，我们解决了单词计数问题。这里是该解决方案的代码。
- en: '[PRE4]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: What is the big O efficiency of our algorithm?
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的算法的大O效率是多少？
- en: A. *O*(1)
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: A. *O*(1)
- en: B. *O*(*n*)
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: B. *O*(*n*)
- en: 'Answer: B. It’s tempting to think that this algorithm is *O*(1). After all,
    there’s no loop anywhere, and it looks like the algorithm is performing just three
    steps: read the input, call `count` to count the number of words, and output the
    number of words.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 答案：B. 很容易认为这个算法是*O*(1)。毕竟，代码中没有任何循环，看起来算法只执行了三步：读取输入，调用`count`来计算单词数量，输出单词数量。
- en: But this algorithm is *O*(*n*), where *n* is the number of characters in the
    input. It takes linear time for the `input` function to read the input, because
    it has to read the input character by character. Using the `count` method also
    takes linear time, because it has to process each character of the string to find
    matches. So this algorithm performs a linear amount of work to read the input
    and a linear amount of work to count the words. That’s a linear amount of work
    overall.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 但这个算法是 *O*(*n*)，其中 *n* 是输入字符的数量。`input`函数读取输入需要线性时间，因为它必须逐个字符地读取输入。使用`count`方法也需要线性时间，因为它必须处理字符串中的每个字符以找到匹配项。所以，这个算法执行的工作量是线性的，既有读取输入的线性工作量，也有计数单词的线性工作量。总的来说，这是线性的工作量。
- en: '**CONCEPT CHECK**'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**概念检查**'
- en: 'In [Listing 1-2](ch01.xhtml#ch01ex02), we solved the Cone Volume problem. I’ve
    reproduced that solution here:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在[示例 1-2](ch01.xhtml#ch01ex02)中，我们解决了圆锥体体积问题。这里是我复现的解决方案：
- en: '[PRE5]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: What is the big O efficiency of our algorithm? (Recall that the maximum value
    for the radius and height is 100.)
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的算法的大O效率是多少？（回忆一下，半径和高度的最大值是100。）
- en: A. *O*(1)
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: A. *O*(1)
- en: B. *O*(*n*)
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: B. *O*(*n*)
- en: 'Answer: A. We’re dealing with small numbers here, so reading them from the
    input takes constant time. Calculating the volume takes constant time, too: it’s
    just a few mathematical operations. All we’re doing here, then, is a few constant-time
    steps. That’s a constant amount of work overall.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 答案：A。我们处理的是小数字，因此从输入中读取它们需要常数时间。计算体积也需要常数时间：这只是几个数学操作。因此，我们所做的只是一些常数时间的步骤。总体而言，这是一个常数量的工作。
- en: '**CONCEPT CHECK**'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**概念检查**'
- en: 'In [Listing 3-4](ch03.xhtml#ch03ex04), we solved the Data Plan problem. I’ve
    reproduced that solution here:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [Listing 3-4](ch03.xhtml#ch03ex04) 中，我们解决了数据计划问题。我已经在这里复现了该解决方案：
- en: '[PRE6]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: What is the big O efficiency of our algorithm?
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的算法的大 O 效率是什么？
- en: A. *O*(1)
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: A. *O*(1)
- en: B. *O*(*n*)
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: B. *O*(*n*)
- en: 'Answer: B. The pattern for this algorithm is similar to that of our solution
    to Three Cups or Occupied Spaces, except that it interleaves reading the input
    with processing it. We let *n* be the number of monthly megabyte values. The program
    performs a constant number of steps for each of these *n* input values. This is
    therefore an *O*(*n*) algorithm.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 答案：B。这个算法的模式类似于我们解决“三个杯子”或“占用空间”问题的解决方案，不同之处在于它将读取输入与处理输入交替进行。我们让 *n* 代表每月的兆字节数值。程序对这些
    *n* 个输入值执行一个常数数量的步骤。因此，这是一个 *O*(*n*) 算法。
- en: Quadratic Time
  id: totrans-69
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 二次时间
- en: So far we’ve discussed constant-time algorithms (those that don’t do more work
    as the amount of input increases) and linear-time algorithms (those that do more
    work linearly as the amount of input increases). Like a linear-time algorithm,
    a *quadratic-time* algorithm does more work as the amount of input increases;
    for example, it does more work to process 1,000 values than 10 values. Whereas
    we can get away with using a linear-time algorithm on relatively large amounts
    of input, we’ll be restricted to much smaller amounts of input on quadratic-time
    algorithms. We’ll see why next.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们讨论了常数时间算法（即随着输入量增加，工作量不变的算法）和线性时间算法（即随着输入量增加，工作量线性增加的算法）。像线性时间算法一样，*二次时间*
    算法随着输入量的增加而做更多的工作；例如，它处理 1,000 个值所做的工作比处理 10 个值时要多。虽然我们可以在相对较大的输入量上使用线性时间算法，但在二次时间算法上，我们将受到更小的输入量限制。接下来我们将看到原因。
- en: Typical Form
  id: totrans-71
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 典型形式
- en: 'A typical linear-time algorithm looks like this:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的线性时间算法如下所示：
- en: '[PRE7]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'In contrast, a typical quadratic-time algorithm looks like this:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，典型的二次时间算法如下所示：
- en: '[PRE8]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: For an input of *n* values, how many values does each algorithm process? The
    linear-time algorithm processes *n* values, one on each iteration of the `for`
    loop. The quadratic-time algorithm, in contrast, processes *n* values *on each
    iteration* of the outer `for` loop.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个包含 *n* 个值的输入，每个算法处理多少个值？线性时间算法处理 *n* 个值，每次在 `for` 循环的迭代中处理一个值。相比之下，二次时间算法在外部
    `for` 循环的每次迭代中处理 *n* 个值。
- en: On the first iteration of the outer `for` loop, *n* values are processed (one
    on each iteration of the inner `for` loop); on the second iteration of the outer
    `for` loop, *n* more values are processed (one on each iteration of the inner
    `for` loop); and so on. As the outer `for` loop iterates *n* times, the total
    number of values that are processed is *n* * *n*, or *n*². Two nested loops, each
    of which depends on *n*, gives rise to a quadratic-time algorithm. In big O notation,
    we say that a quadratic-time algorithm is *O*(*n*²).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在外部 `for` 循环的第一次迭代中，处理 *n* 个值（每次迭代处理一个值）；在外部 `for` 循环的第二次迭代中，处理 *n* 个值（每次迭代处理一个值）；依此类推。随着外部
    `for` 循环迭代 *n* 次，处理的值的总数是 *n* * *n*，即 *n*²。两个嵌套循环，每个循环都依赖于 *n*，产生了一个二次时间算法。在大
    O 记法中，我们说二次时间算法是 *O*(*n*²)。
- en: 'Let’s compare the amount of work done by linear-time and quadratic-time algorithms.
    Suppose that we’re processing an input of 1,000 values, meaning that *n* is 1,000\.
    A linear-time algorithm that takes *n* steps would take 1,000 steps. A quadratic-time
    algorithm that takes *n*² steps would take 1,000² = 1,000,000 steps. A million
    is way more than a thousand. But who cares: computers are really, really fast,
    right? Well, yes, and for an input of 1,000 values, we’re probably okay if we
    use a quadratic-time algorithm. In “Efficiency of Our Program” on [page 253](ch09.xhtml#ch09lev2sec16),
    I gave a conservative rule claiming that we can perform about five million steps
    per second. A million steps, then, should be doable in all but the strictest time
    limits.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们比较一下线性时间算法和二次时间算法的工作量。假设我们处理一个包含 1,000 个值的输入，这意味着 *n* 等于 1,000。一个需要 *n* 步的线性时间算法将执行
    1,000 步。一个需要 *n*² 步的二次时间算法将执行 1,000² = 1,000,000 步。一百万比一千多得多。但是谁在乎呢：计算机真的非常非常快，对吧？嗯，是的，对于一个包含
    1,000 个值的输入，如果我们使用二次时间算法，可能也没什么大问题。在 [第253页](ch09.xhtml#ch09lev2sec16)的《我们程序的效率》一节中，我给出了一个保守的规则，认为我们每秒可以执行大约五百万步。因此，一百万步应该在除最严格的时间限制外都能完成。
- en: But any optimism for a quadratic-time algorithm is short-lived. Watch what happens
    if we crank the number of input values up from 1,000 to 10,000\. The linear-time
    algorithm takes only 10,000 steps. The quadratic-algorithm takes 10,000² = 100,000,000
    steps. Hmmm . . . if we’re using a quadratic-time algorithm, now our computer
    isn’t looking so fast. While the linear-time algorithm still runs in milliseconds,
    the quadratic-time algorithm will take at least a few seconds. Time limit exceeded
    there, no question.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 但是对于二次时间算法的乐观期待是短暂的。看看当我们将输入值的数量从 1,000 增加到 10,000 时会发生什么。线性时间算法仅需 10,000 步。二次时间算法需要
    10,000² = 100,000,000 步。嗯……如果我们使用二次时间算法，计算机的速度就不那么快了。虽然线性时间算法仍然以毫秒为单位运行，但二次时间算法至少要花几秒钟。肯定会超时了，毫无疑问。
- en: '**CONCEPT CHECK**'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**概念检查**'
- en: What is the big O efficiency of the following algorithm?
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 以下算法的时间复杂度是多少？
- en: '[PRE9]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: A. *O*(1)
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: A. *O*(1)
- en: B. *O*(*n*)
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: B. *O*(*n*)
- en: C. *O*(*n*^(*2*))
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: C. *O*(*n*^(*2*))
- en: 'Answer: B. There are two nested loops here, so your first instinct might be
    to claim that this is a quadratic-time algorithm. Be careful, though, because
    the outer `for` loop iterates only 10 times, independent of the value of *n*.
    The total number of steps in this algorithm, therefore, is *10n*. There’s no *n*^(*2*)
    here; *10n* is linear, just like *n*. So, this is a linear-time algorithm, not
    a quadratic-time algorithm. We’d write its efficiency as *O*(*n*).'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 答案：B。这里有两个嵌套循环，所以你可能会直觉地认为这是一个二次时间算法。不过要小心，因为外层 `for` 循环仅执行 10 次，与 *n* 的值无关。因此，这个算法的总步骤数是
    *10n*。这里并没有 *n*^(*2*)，*10n* 是线性的，就像 *n* 一样。所以，这是一个线性时间算法，而不是二次时间算法。我们可以将其效率写作
    *O*(*n*)。
- en: '**CONCEPT CHECK**'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**概念检查**'
- en: What is the big O efficiency of the following algorithm?
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 以下算法的时间复杂度是多少？
- en: '[PRE10]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: A. *O*(1)
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: A. *O*(1)
- en: B. *O*(*n*)
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: B. *O*(*n*)
- en: C. *O*(*n*^(*2*))
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: C. *O*(*n*^(*2*))
- en: 'Answer: B. We have two loops here, and they both depend on *n*. Isn’t this
    quadratic time, then?'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 答案：B。这里有两个循环，它们都依赖于 *n*。那么这不就是二次时间复杂度吗？
- en: No! These two loops are sequential, not nested. The first loop takes *n* steps,
    and the second also takes *n* steps, for a total of *2n* steps. This is therefore
    a linear-time algorithm.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 不！这两个循环是顺序执行的，而不是嵌套的。第一个循环执行 *n* 步，第二个也执行 *n* 步，总共是 *2n* 步。因此，这是一个线性时间算法。
- en: Alternate Form
  id: totrans-95
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 备用形式
- en: 'When you see two nested loops where each depends on *n*, it’s a good bet that
    you’re looking at a quadratic-time algorithm. But it’s possible for a quadratic-time
    algorithm to arise even in the absence of such nested loops. We can find such
    an example in our first solution to the Email Addresses problem, [Listing 8-2](ch08.xhtml#ch08ex02).
    I’ve reproduced that solution here:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 当你看到两个嵌套循环，每个循环都依赖于 *n* 时，可以合理推测你可能面对的是一个二次时间算法。但即便没有这样的嵌套循环，二次时间算法也有可能出现。我们可以在我们解决电子邮件地址问题的第一个解法中找到这样的例子，[示例
    8-2](ch08.xhtml#ch08ex02)。我在这里重现了该解法：
- en: '[PRE11]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We’ll let *n* be the maximum number of email addresses that we see in our 10
    test cases. The outer `for` loop iterates 10 times; the inner `for` loop iterates
    at most *n* times. We’re therefore processing at most 10*n* email addresses, which
    is linear in *n*.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 假设 *n* 是我们在10个测试用例中看到的最大电子邮件地址数量。外层 `for` 循环执行 10 次；内层 `for` 循环最多执行 *n* 次。因此，我们最多处理
    10*n* 个电子邮件地址，这在 *n* 上是线性的。
- en: Cleaning an email address ❶ takes a constant number of steps, so we don’t need
    to worry about that. But this is still *not* a linear-time algorithm, because
    each iteration of the inner `for` loop takes more than a constant number of steps.
    Specifically, checking whether an email address is already in our list ❷ takes
    work proportional to the number of email addresses already in the list, because
    Python has to search through the list. That’s a linear-time operation on its own!
    So we’re processing 10*n* email addresses, each of which requires *n* work, for
    a total of 10*n*², or quadratic-time, work. This quadratic-time performance is
    precisely why we received a time limit exceeded error with this code, leading
    us to use a set rather than a list.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 清理一个电子邮件地址 ❶ 需要恒定的步骤数，所以我们不需要担心这个。但这仍然不是线性时间算法，因为内层 `for` 循环的每次迭代都需要超过恒定步骤数的操作。具体来说，检查电子邮件地址是否已经在我们的列表中
    ❷ 需要与列表中已经存在的电子邮件地址数量成比例的操作，因为 Python 必须遍历列表。这本身就是一个线性时间的操作！所以我们处理了 10*n* 个电子邮件地址，每个电子邮件地址需要
    *n* 次操作，总共是 10*n*² 次操作，或者说是二次方时间复杂度的操作。正因为这段代码的二次方时间复杂度，我们才遇到了超时错误，最终我们使用了集合而不是列表。
- en: Cubic Time
  id: totrans-100
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 三次方时间
- en: If one loop can lead to linear time, and two nested loops can lead to quadratic
    time, then what about three nested loops? Three nested loops, each of which depends
    on *n*, leads to a *cubic-time* algorithm. In big O notation, we say that a cubic-time
    algorithm is *O*(*n*³).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个循环能导致线性时间，两个嵌套循环能导致二次方时间，那么三个嵌套循环会怎样呢？三个嵌套的循环，每个都依赖于 *n*，就会导致一个 *三次方时间*
    的算法。在大O记法中，我们说一个三次方时间算法是 *O*(*n*³)。
- en: 'If you thought quadratic-time algorithms were slow, wait till you see how slow
    cubic-time algorithms are. Suppose that *n* is 1,000\. We already know that a
    linear-time algorithm will take about 1,000 steps and that a quadratic-time algorithm
    will take about 1,000² = 1,000,000 steps. A cubic-time algorithm will take 1,000³
    = 1,000,000,000 steps. A billion steps! But it gets worse. For example, if *n*
    is 10,000, which is still a small amount of input, then a cubic-time algorithm
    will take 1,000,000,000,000 (that’s one trillion) steps. One trillion steps would
    take many minutes of computing time. No joke: a cubic-time algorithm is almost
    never good enough.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你认为二次方时间复杂度的算法很慢，那等你看到三次方时间复杂度的算法有多慢吧。假设 *n* 是 1,000。我们已经知道线性时间算法大约需要 1,000
    步，而二次方时间算法大约需要 1,000² = 1,000,000 步。三次方时间算法则需要 1,000³ = 1,000,000,000 步。十亿步！但事情更糟糕。例如，如果
    *n* 是 10,000，这仍然是一个较小的输入量，那么三次方时间算法将需要 1,000,000,000,000（也就是一万亿）步。一万亿步将需要几分钟的计算时间。不是开玩笑：三次方时间复杂度的算法几乎永远不够好。
- en: 'It certainly wasn’t good enough when we tried to use a cubic-time algorithm
    to solve Cow Baseball in [Listing 9-5](ch09.xhtml#ch09ex05). I’ve reproduced that
    solution here:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们尝试使用三次方时间复杂度的算法来解决[示例 9-5](ch09.xhtml#ch09ex05)中的牛棒球问题时，显然它并不够好。我在这里重新展示了那个解决方案：
- en: '[PRE12]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'You’ll see the telltale of cubic time in this code: three nested loops ❶ ❷
    ❸, each of which depends on the amount of input. As you’ll recall, the time limit
    for that problem was four seconds, and we could have up to 1,000 cows. A cubic-time
    algorithm, processing a billion triples, is way too slow.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 你会在这段代码中看到三次方时间的特征：三个嵌套的循环 ❶ ❷ ❸，每个循环的迭代次数都依赖于输入的数量。正如你记得的那样，这个问题的时间限制是四秒，并且我们最多可以有
    1,000 头牛。三次方时间复杂度的算法，处理十亿次迭代，显然太慢了。
- en: Multiple Variables
  id: totrans-106
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 多个变量
- en: 'In [Chapter 5](ch05.xhtml#ch05), we solved the Baker Bonus problem. I’ve reproduced
    our solution from [Listing 5-6](ch05.xhtml#ch05ex06) here:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第5章](ch05.xhtml#ch05)中，我们解决了贝克奖金问题。我在这里重新展示了我们在[示例 5-6](ch05.xhtml#ch05ex06)中的解决方案：
- en: '[PRE13]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: What is the big O efficiency of this algorithm? There are some nested loops
    in here, so a first guess is that this algorithm is *O*(*n*²). But what is *n*?
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这个算法的时间复杂度是什么？这里有一些嵌套循环，所以第一反应是这个算法的时间复杂度是 *O*(*n*²)。但是 *n* 代表什么呢？
- en: 'In the problems we’ve discussed to this point in the chapter, we used the single
    variable *n* to represent the amount of input: *n* could be the number of swaps
    or the number of parking spaces or the number of email addresses or the number
    of cows. But in the Baker Bonus problem, we’re dealing with two-dimensional input,
    so we need *two* variables to represent its amount. We’ll call the first variable
    *d*, the number of days; we’ll call the second *f*, the number of franchisees.
    More formally, because there are multiple test cases per input, we’ll let *d*
    be the maximum number of days and *f* the maximum number of franchisees. We need
    to give the big O efficiency in terms of *both d* and *f*.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章迄今为止讨论的问题中，我们使用单一变量 *n* 来表示输入的量：*n* 可能是交换的次数、停车位的数量、电子邮件地址的数量或奶牛的数量。但在贝克奖金问题中，我们处理的是二维输入，因此我们需要
    *两个* 变量来表示其数量。我们将第一个变量称为 *d*，表示天数；第二个变量称为 *f*，表示加盟商的数量。更正式地说，由于每个输入包含多个测试案例，我们将
    *d* 定义为天数的最大值，*f* 定义为加盟商的最大值。我们需要在 *d* 和 *f* 的基础上给出大 O 效率。
- en: 'Our algorithm consists of three major components: reading the input, calculating
    the number of bonuses from the rows, and calculating the number of bonuses from
    the columns. Let’s take a look at each of these.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的算法由三个主要部分组成：读取输入、根据行计算奖金数量和根据列计算奖金数量。让我们分别来看一下每个部分。
- en: To read the input ❶, we perform *d* iterations of the outer loop. On each of
    these iterations we read a row and call `split`, which takes about *f* steps.
    We take another *f* steps to loop through the values and convert them to integers.
    In total, then, each of the *d* iterations performs a number of steps proportional
    to *f*. Reading the input therefore takes *O*(*df*) time.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 为了读取输入 ❶，我们执行 *d* 次外循环。在每次迭代中，我们读取一行并调用 `split`，这个过程大约需要 *f* 步。然后我们再花 *f* 步遍历这些值并将它们转换为整数。总的来说，每次
    *d* 次迭代都执行与 *f* 成比例的步骤。因此，读取输入需要 *O*(*df*) 时间。
- en: Now for the row bonuses ❷. The outer loop here loops *d* times. Each of these
    iterations calls `sum`, which takes *f* steps because it has to add up *f* values.
    Like reading the input, then, this part of the algorithm is *O*(*df*).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 现在来看行奖金 ❷。这里的外循环执行 *d* 次。每次迭代都调用 `sum`，该操作需要 *f* 步，因为它必须加总 *f* 个值。因此，与读取输入一样，这部分算法是
    *O*(*df*)。
- en: Finally, let’s look at the code for the column bonuses ❸. The outer loop loops
    *f* times. Each of those iterations leads to the inner loop iterating *d* times.
    The total here, again, is *O*(*df*).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们看一下列奖金 ❸ 的代码。外循环执行 *f* 次。每次迭代都导致内循环执行 *d* 次。这里的总时间复杂度同样是 *O*(*df*)。
- en: Each component of this algorithm is *O*(*df*). Adding three *O*(*df*) components
    together yields an *O*(*df*) algorithm overall.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法的每个组件是 *O*(*df*)。将三个 *O*(*df*) 组件加在一起，整体算法是 *O*(*df*)。
- en: '**CONCEPT CHECK**'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '**概念检查**'
- en: What is the big O efficiency of the following algorithm?
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 以下算法的大 O 效率是多少？
- en: '[PRE14]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: A. *O*(1)
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: A. *O*(1)
- en: B. *O*(*n*)
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: B. *O*(*n*)
- en: C. *O*(*n*^(*2*))
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: C. *O*(*n*^(*2*))
- en: D. *O*(*m*+*n*)
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: D. *O*(*m*+*n*)
- en: E. *O*(*mn*)
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: E. *O*(*mn*)
- en: 'Answer: D. The first loop depends on *m*, and the second depends on *n*. The
    loops are sequential, not nested, so their work is added rather than multiplied.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 答案：D。第一个循环依赖于 *m*，第二个循环依赖于 *n*。这些循环是顺序执行的，而不是嵌套的，因此它们的工作量是相加而非相乘。
- en: Log Time
  id: totrans-125
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 对数时间
- en: In “Efficiency of Our Program” on [page 255](ch09.xhtml#ch09lev2sec18), we discussed
    the difference between linear search and binary search. A linear search finds
    a value in a list by searching the list from beginning to end. That’s an *O*(*n*)
    algorithm. It works whether or not the list is sorted. A binary search, by contrast,
    works only on a sorted list. But if you have a sorted list, then binary search
    is blazingly fast.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第255页](ch09.xhtml#ch09lev2sec18)的《程序效率》中，我们讨论了线性搜索与二分搜索的区别。线性搜索通过从头到尾搜索列表来查找值。这是一个
    *O*(*n*) 算法，无论列表是否已排序都能工作。相比之下，二分搜索仅适用于已排序的列表。但如果你有一个已排序的列表，二分搜索会非常迅速。
- en: Binary search works by comparing the value we’re searching for to the value
    at the middle of the list. If the value at the middle of the list is larger than
    the value we’re searching for, we continue searching in the left half of the list.
    If the value at the middle of the list is smaller than the value we’re searching
    for, we continue searching in the right half of the list. We keep doing this,
    ignoring half of the list each time, until we find the value that we’re looking
    for.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 二分搜索通过将我们要搜索的值与列表中间的值进行比较来工作。如果列表中间的值大于我们要搜索的值，我们继续在列表的左半部分进行搜索。如果列表中间的值小于我们要搜索的值，我们继续在列表的右半部分进行搜索。我们一直这样做，每次忽略列表的一半，直到找到我们要找的值。
- en: Suppose we use binary search to find a value in a list of 512 values. How many
    steps does it take? Well, after one step, we’ve ignored half the list, so we’re
    left with about 512 / 2 = 256 values. (It doesn’t matter whether our value is
    larger than half of the values in the list or smaller than half the values in
    the list; in each case, we ignore one half of the list.) After two steps, we’re
    left with 256 / 2 = 128 values. After three steps, we’re left with 128 / 2 = 64
    values. Continuing, after four steps we have 32 values, after five steps we have
    16 values, after six steps we have 8 values, after seven steps we have 4 values,
    after eight steps we have 2 values, and after nine steps we have only 1 value.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们使用二分搜索在一个包含 512 个值的列表中查找某个值。需要多少步？嗯，经过第一步后，我们忽略了一半的列表，所以剩下大约 512 / 2 = 256
    个值。（无论我们的值是大于列表中一半的值，还是小于列表中一半的值，都会忽略列表的一半。）第二步后，剩下 256 / 2 = 128 个值。第三步后，剩下 128
    / 2 = 64 个值。继续下去，第四步后剩下 32 个值，第五步后剩下 16 个值，第六步后剩下 8 个值，第七步后剩下 4 个值，第八步后剩下 2 个值，第九步后只剩下
    1 个值。
- en: 'Nine steps—that’s it! That’s way better than taking up to 512 steps using linear
    search. Binary search does far less work than a linear-time algorithm. But what
    kind of algorithm is it? It’s not constant time: while it takes very few steps,
    the number of steps does increase a little as the amount of input increases.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 九步——就这么简单！这比使用线性搜索最多需要 512 步要好得多。二分搜索比线性时间算法要少做很多工作。但它是什么样的算法呢？它不是常数时间：虽然它需要的步骤很少，但随着输入量的增加，步骤数确实会略微增加。
- en: Binary search is an example of a *logarithmic-time* or *log-time* algorithm.
    In big O notation, we say that a logarithmic-time algorithm is *O*(log *n*).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 二分搜索是一个 *对数时间* 或 *对数时间* 算法的例子。在大 O 符号中，我们说一个对数时间算法是 *O*(log *n*)。
- en: Logarithmic-time refers to the logarithm function in mathematics. Given a number,
    this function tells you the number of times you have to divide that number by
    a base to get to 1 or less. The base we typically use in computer science is 2,
    so we’re looking for the number of times you have to divide a number by 2 to get
    to 1 or less. For example, it takes 9 divisions by 2 to take 512 down to 1\. We
    write this as log[2] 512 = 9.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 对数时间是指数学中的对数函数。给定一个数字，这个函数告诉你需要将该数字除以一个基数多少次，才能得到 1 或更小。我们在计算机科学中通常使用的基数是 2，所以我们要找的是将一个数字除以
    2 多少次才能得到 1 或更小。例如，要将 512 除到 1，需要 9 次除法。我们写作 log[2] 512 = 9。
- en: The logarithm function is the inverse of the exponential function, the latter
    of which may be more familiar to you. Another way to calculate log[2] 512 is to
    find the power *p* so that 2*^p* = 512\. Since 2⁹ = 512, we confirm that log[2]
    512 = 9.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 对数函数是指数函数的反函数，后者可能对你来说更加熟悉。另一种计算 log[2] 512 的方法是找到指数 *p*，使得 2*^p* = 512。由于 2⁹
    = 512，我们确认 log[2] 512 = 9。
- en: It’s shocking how slowly the logarithm function grows. For example, consider
    a list of one million values. How many steps would binary search take to search
    that? It takes log[2] 1,000,000 steps, which is only about 20\. Logarithmic-time
    is much closer to constant-time than it is to linear-time. It’s a huge win any
    time you can replace a linear-time algorithm by a logarithmic-time one.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 对数函数增长得如此缓慢，令人吃惊。例如，考虑一个包含一百万个值的列表。二分搜索要搜索这个列表需要多少步？它需要 log[2] 1,000,000 步，这大约是
    20 步。对数时间比常数时间要接近得多，而不是线性时间。每当你能用对数时间算法代替线性时间算法时，这都是一次巨大的胜利。
- en: n log n Time
  id: totrans-134
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: n log n 时间
- en: 'In [Chapter 5](ch05.xhtml#ch05), we solved the Village Neighborhood problem.
    I’ve reproduced our solution from [Listing 5-1](ch05.xhtml#ch05ex01) here:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [第 5 章](ch05.xhtml#ch05)中，我们解决了《村庄邻里问题》。我在这里重新展示了我们在 [列表 5-1](ch05.xhtml#ch05ex01)
    中的解法：
- en: '[PRE15]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Looks like a linear-time algorithm, eh? I mean, there’s a linear-time loop to
    read the input ❶ and another linear-time loop to find the minimum size ❸. Is this
    code *O*(*n*), then?
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来像是线性时间算法，对吧？我的意思是，这里有一个线性时间的循环来读取输入❶，还有另一个线性时间的循环来找最小值❸。那么，这段代码是*O*(*n*)吗？
- en: It’s too early to tell! The reason is that we haven’t yet taken into account
    that we sort the positions ❷. We can’t just ignore that; we need to know about
    the efficiency of sorting. As we’ll see, sorting is slower than linear time. So,
    since sorting is the slowest step here, whatever the efficiency is of sorting
    will be the efficiency overall.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 现在判断还为时过早！原因是我们还没有考虑到我们排序的位置❷。我们不能忽略这一点；我们需要了解排序的效率。正如我们将看到的那样，排序比线性时间要慢。因此，由于排序是这里最慢的步骤，无论排序的效率如何，它将决定整体的效率。
- en: 'Programmers and computer scientists have devised many sorting algorithms, and
    these algorithms can roughly be divided into two groups. The first group consists
    of algorithms that take *O*(*n*²) time. The three most famous of these sorting
    algorithms are bubble sort, selection sort, and insertion sort. You can learn
    more about these sorting algorithms on your own if you like, but we won’t need
    to know anything about them to continue here. All we have to keep in mind is that
    *O*(*n*²) can be quite slow. For example, to sort a list of 10,000 values, an
    *O*(*n*²) sorting algorithm would take about 10,000² = 100,000,000 steps. As we
    know, this would take any computer at least a few seconds. That’s pretty disappointing:
    sorting 10,000 values feels like something computers should be able to do almost
    instantly.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 程序员和计算机科学家们设计了许多排序算法，这些算法大致可以分为两组。第一组包括需要*O*(*n*²)时间的算法。这些排序算法中最著名的三种是冒泡排序、选择排序和插入排序。如果你愿意，可以自行学习这些排序算法的更多内容，但在这里我们不需要了解它们的任何细节。我们要记住的只是，*O*(*n*²)可能非常慢。例如，要对一个包含10,000个值的列表进行排序，*O*(*n*²)排序算法需要大约10,000²
    = 100,000,000步。正如我们所知道的，这至少需要几秒钟的时间。这个结果相当令人失望：排序10,000个值似乎是计算机应该能够几乎瞬间完成的任务。
- en: 'Enter the second group of sorting algorithms. This group consists of algorithms
    that take only *O*(*n* log *n*) time. There are two famous sorting algorithms
    in this group: quick sort and merge sort. Again, you’re free to look them up if
    you like, but we don’t need the details here.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 进入第二组排序算法。这一组包括那些只需要*O*(*n* log *n*)时间的算法。这个组里有两个著名的排序算法：快速排序和归并排序。同样的，如果你愿意，可以自己查找这些算法，但在这里我们不需要了解具体细节。
- en: What does *O*(*n* log *n*) mean? Don’t let the notation confuse you. It’s just
    the multiplication of *n* by log *n*. Let’s try this out on a list of 10,000 values.
    Here, we have 10,000 * log 10,000 steps, which is only about 132,877\. This is
    a very small number of steps, especially compared to the 100,000,000 steps taken
    by the *O*(*n*²) sorting algorithms.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '*O*(*n* log *n*)是什么意思？不要让符号弄混淆了你。这只是*n*和log *n*的乘积。我们来尝试一下处理一个包含10,000个值的列表。在这里，我们有10,000
    * log 10,000步，这只有大约132,877步。这是一个非常小的步数，特别是和需要100,000,000步的*O*(*n*²)排序算法相比。'
- en: 'Now we can ask the question we really care about: what sorting algorithm is
    Python using when we ask it to sort a list? Answer: an *O*(*n* log *n*) one! (It’s
    called Timsort. If you’d like to learn more, start with merge sort, because Timsort
    is a souped-up merge sort.) No slow *O*(*n*²) sorting here. In general, sorting
    is so fast—so close to linear time—that we can use it without affecting our efficiency
    too much.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以问我们真正关心的问题：当我们要求Python对一个列表进行排序时，它使用的是哪种排序算法？答案是：*O*(*n* log *n*)的算法！（它叫Timsort。如果你想了解更多，建议从归并排序开始，因为Timsort是一个加强版的归并排序。）这里没有慢的*O*(*n*²)排序算法。通常，排序是如此快速——几乎接近线性时间——我们可以使用它而不会对效率产生太大的影响。
- en: Returning to Village Neighborhood, now we see that its efficiency is not *O*(*n*)
    but, because of the sort, *O*(*n* log *n*). In practice, an *O*(*n* log *n*) algorithm
    only does a little more work than an *O*(*n*) algorithm and far less than an *O*(*n*²)
    algorithm. If your goal is to design an *O*(*n*) algorithm, designing one that’s
    *O*(*n* log *n*) is probably good enough.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 回到“村庄邻里”这个例子，现在我们看到它的效率不是*O*(*n*)，而是由于排序的原因，变成了*O*(*n* log *n*)。实际上，*O*(*n*
    log *n*)算法所做的工作只比*O*(*n*)算法多一点，而远少于*O*(*n*²)算法。如果你的目标是设计一个*O*(*n*)算法，那么设计一个*O*(*n*
    log *n*)的算法应该已经足够好了。
- en: Handling Function Calls
  id: totrans-144
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 处理函数调用
- en: Starting in [Chapter 6](ch06.xhtml#ch06), we wrote our own functions to help
    us design larger programs. In our big O analysis, we need to be careful to include
    the work done when we call these functions.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 从[第六章](ch06.xhtml#ch06)开始，我们编写了自己的函数，帮助我们设计更大的程序。在我们的大 O 分析中，我们需要小心地包括调用这些函数时所做的工作。
- en: 'Let’s revisit the Card Game problem from [Chapter 6](ch06.xhtml#ch06). We solved
    it in [Listing 6-1](ch06.xhtml#ch06ex01), and part of our solution involved calling
    our `no_high` function. I’ve reproduced that solution here:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下[第六章](ch06.xhtml#ch06)中的卡片游戏问题。我们在[清单 6-1](ch06.xhtml#ch06ex01)中解决了这个问题，我们的解决方案的一部分是调用了我们的`no_high`函数。我在这里重新展示了该解决方案：
- en: '[PRE16]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We’ll use *n* to represent the number of cards. The `no_high` function ❶ takes
    a list and uses `in` on it, so we might conclude that it is *O*(*n*) time. (`in`
    may have to search the whole list to find what it’s looking for, after all.) However,
    we only ever call `no_high` with lists of constant size—maximum four cards—so
    we can treat each call of `no_high` as *O*(1) time.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 *n* 来表示卡片的数量。`no_high`函数 ❶ 需要一个列表并对其使用`in`操作，因此我们可能会得出它是 *O*(*n*) 时间复杂度的结论（毕竟，`in`
    可能需要搜索整个列表来找到它要找的东西）。然而，我们只会在常数大小的列表——最多四张卡片——上调用`no_high`，所以我们可以将每次调用`no_high`视为
    *O*(1) 时间复杂度。
- en: Now that we understand the efficiency of `no_high`, we can determine the big
    O efficiency of the complete program. We begin with a loop that takes *O*(*n*)
    time to read the cards ❷. We then enter another loop that iterates *n* times ❸.
    Each iteration takes just a constant number of steps, possibly including a call
    of `no_high` that takes a constant number of steps. This loop, then, takes *O*(*n*)
    time. The program therefore consists of two *O*(*n*) pieces, so it is *O*(*n*)
    overall.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们理解了`no_high`的效率后，我们可以确定完整程序的大 O 效率。我们从一个循环开始，这个循环花费 *O*(*n*) 时间来读取卡片 ❷。然后我们进入另一个循环，它迭代
    *n* 次 ❸。每次迭代仅需常数步骤，可能包括调用`no_high`，该函数也只需要常数步骤。因此，这个循环花费 *O*(*n*) 时间。因此，程序由两个
    *O*(*n*) 部分组成，总的时间复杂度是 *O*(*n*)。
- en: Be careful to accurately judge the amount of work performed when a function
    is called. As you just saw with `no_high`, this may involve looking at both the
    function itself and the context in which it is called.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 小心准确判断函数调用时执行的工作量。正如你刚刚看到的`no_high`，这可能涉及到同时观察函数本身以及它被调用的上下文。
- en: '**CONCEPT CHECK**'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '**概念检查**'
- en: What is the big O efficiency of the following algorithm?
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 以下算法的大 O 效率是多少？
- en: '[PRE17]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: A. *O*(1)
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: A. *O*(1)
- en: B. *O*(*n*)
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: B. *O*(*n*)
- en: C. *O*(*n*^(*2*))
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: C. *O*(*n*^(*2*))
- en: 'Answer: C. The loop in the main program iterates *n* times. On each iteration,
    we call function `f`, which itself has a loop that iterates *n* times.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 答案：C. 主程序中的循环迭代了 *n* 次。在每次迭代中，我们调用函数`f`，而`f`本身也有一个循环，迭代 *n* 次。
- en: Summary
  id: totrans-158
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 总结
- en: The algorithms that do the least work are *O*(1), followed by *O*(log *n*),
    followed by *O*(*n*), followed by *O*(*n* log *n*). Have you solved a problem
    using one of these four? If so, you’re probably done. If not, then depending on
    the time limit, you may have more work to do.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 执行工作最少的算法是 *O*(1)，接着是 *O*(log *n*)，然后是 *O*(*n*)，再接着是 *O*(*n* log *n*)。你曾经用其中一个算法解决过问题吗？如果是，那么你可能已经完成。如果不是，那么根据时间限制，你可能还有更多工作要做。
- en: We’re now going to look at two problems where a straightforward solution will
    not be efficient enough—it won’t run within the time limit. Using what we just
    learned about big O, we’ll be able to predict this inefficiency even without implementing
    the code! We’ll then work on a faster solution and implement it to solve the problem
    within the time limit.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将来看两个问题，在这些问题中，直接的解决方案效率不足——它在时间限制内无法运行。利用我们刚刚学到的大 O 表示法，我们即使不实现代码，也能够预测出这种低效！然后我们将尝试一个更快速的解决方案，并实现它，以在时间限制内解决问题。
- en: 'Problem #24: Longest Scarf'
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '问题 #24：最长围巾'
- en: 'In this problem, we’ll determine the longest desired scarf that we can produce
    by cutting an initial scarf. After reading the following description, pause: how
    would you solve it? Can you come up with multiple algorithms whose efficiency
    you’d like to investigate?'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个问题中，我们将确定通过剪裁初始围巾，可以生产出最长的目标围巾。阅读完以下描述后，停下来想一想：你会如何解决它？你能提出多个算法并分析它们的效率吗？
- en: This is DMOJ problem `dmopc20c2p2`.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 这是DMOJ问题`dmopc20c2p2`。
- en: The Challenge
  id: totrans-164
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 挑战
- en: You have a scarf whose length is *n* feet, and each foot has a specific color.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 你有一条长度为 *n* 英尺的围巾，每一英尺都有一个特定的颜色。
- en: You also have *m* relatives. Each relative indicates what their desired scarf
    looks like by specifying the color of its first foot and last foot.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 你还有 *m* 个亲戚。每个亲戚通过指定围巾的第一英尺和最后一英尺的颜色，来表示他们想要的围巾样式。
- en: Your goal is to cut your original scarf in such a way as to produce the longest
    desired scarf for one of your relatives.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 你的目标是将原始围巾剪裁成一种方式，以便为某个亲戚制作出最长的所需围巾。
- en: Input
  id: totrans-168
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 输入
- en: 'The input consists of the following lines:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 输入包括以下几行：
- en: A line containing the integer scarf length *n* and integer number of relatives
    *m*, separated by a space. *n* and *m* are each between 1 and 100,000.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一行包含整数围巾长度*n*和整数亲戚人数*m*，二者由空格分隔。*n*和*m*的值都在1到100,000之间。
- en: A line containing *n* integers separated by spaces. Each integer specifies the
    color of one foot of scarf in order from the first foot to the last foot. Each
    integer is between 1 and 1,000,000.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一行包含*n*个整数，整数之间由空格分隔。每个整数表示围巾的一个脚的颜色，顺序从第一个脚到最后一个脚。每个整数的值在1到1,000,000之间。
- en: '*m* lines, one per relative, containing two integers separated by a space.
    These numbers describe the relative’s desired scarf: the first integer is the
    desired color of the first foot, and the second integer is the desired color of
    the last foot.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*m*行，每行一个亲戚，包含两个整数，中间用空格分隔。这两个数描述了亲戚所需的围巾：第一个整数是所需围巾的第一个脚的颜色，第二个整数是所需围巾的最后一个脚的颜色。'
- en: Output
  id: totrans-173
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 输出
- en: Output the length of the longest desired scarf that can be produced by cutting
    your original scarf.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 输出通过剪裁原始围巾能制作的最长所需围巾的长度。
- en: The time limit for solving the test cases is 0.4 seconds.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 解决测试用例的时间限制是0.4秒。
- en: Exploring a Test Case
  id: totrans-176
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 探索一个测试用例
- en: 'Let’s make sure we know exactly what is being asked by working through a small
    test case. Here it is:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们确保通过处理一个小的测试用例来准确理解所问的问题。以下是测试用例：
- en: '[PRE18]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We have a scarf that’s 6 feet long and three relatives. The color of each foot
    of the scarf is 18, 4, 4, 2, 1, and 2\. What’s the longest desired scarf we can
    make?
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一条6英尺长的围巾和三个亲戚。围巾的每个脚的颜色依次是18、4、4、2、1和2。那么我们能做出最长的所需围巾是什么？
- en: 'The first relative wants a scarf whose first foot is color 1 and whose last
    foot is color 2\. The best we can do is give this relative a 2-foot scarf: the
    2 feet (colors 1 and 2) at the end of the scarf.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个亲戚想要一条围巾，其第一个脚是颜色1，最后一个脚是颜色2。我们能做的最好是给这个亲戚一条2英尺长的围巾：围巾的最后两脚（颜色1和颜色2）。
- en: 'The second relative wants a scarf whose first foot is color 4 and whose last
    foot is color 2\. We can give them a 5-foot scarf: 4, 4, 2, 1, 2.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个亲戚想要一条围巾，其第一个脚是颜色4，最后一个脚是颜色2。我们可以给他们一条5英尺长的围巾：4, 4, 2, 1, 2。
- en: 'The third relative wants a scarf whose first foot is color 18 and whose last
    foot is color 4\. We can give them a 3-foot scarf: 18, 4, 4.'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个亲戚想要一条围巾，其第一个脚是颜色18，最后一个脚是颜色4。我们可以给他们一条3英尺长的围巾：18, 4, 4。
- en: The maximum length of a desired scarf that we can make is 5, so that’s the answer
    for this test case.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以制作的最长围巾长度为5，因此这是该测试用例的答案。
- en: Algorithm 1
  id: totrans-184
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 算法1
- en: 'The way we just processed that test case might immediately suggest to you an
    algorithm that we can use to solve this problem. Namely, we should be able to
    go through the relatives and figure out the maximum length of a desired scarf
    for each one. For example, the maximum length for the first relative might be
    2, so we remember that. The maximum length for the second relative might be 5\.
    That’s longer than 2, so we remember the 5\. The maximum length for the third
    relative might be 3\. This isn’t greater than 5—no change here. If this reminds
    you of a complete-search algorithm ([Chapter 9](ch09.xhtml#ch09)): good, because
    it is one!'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚才处理这个测试用例的方法可能立刻给你启发，帮助你想到一种可以用来解决这个问题的算法。也就是说，我们应该能逐个检查亲戚，找出每个亲戚所需围巾的最大长度。例如，第一个亲戚的最大长度可能是2，因此我们记下这个值。第二个亲戚的最大长度可能是5。这个比2长，所以我们记下5。第三个亲戚的最大长度可能是3。但这并不超过5——所以没有变化。如果这让你想到了一个完全搜索的算法（[第9章](ch09.xhtml#ch09)）：很好，因为这正是一个！
- en: There are *m* relatives. If we knew how long it would take us to process each
    relative, then we’d be able to work out the big O efficiency we’d be dealing with.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 有*m*个亲戚。如果我们知道处理每个亲戚所需的时间，那么我们就能计算出我们需要处理的时间复杂度。
- en: 'Here’s an idea: for each relative, let’s find the leftmost index of the color
    of the first foot and the rightmost index of the color of the last foot. Once
    we had these indices, then no matter how long the scarf, we could use these indices
    to quickly determine the length of the longest desired scarf for this relative.
    For example, if the leftmost index of the color of the first foot is 100 and the
    rightmost index of the color of the last foot is 110, then their longest desired
    scarf is 110 – 100 + 1 = 11.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个想法：对于每个亲戚，让我们找到第一个脚的颜色的最左边索引和最后一个脚的颜色的最右边索引。一旦找到了这些索引，无论围巾多长，我们都可以利用这些索引快速确定该亲戚所需的最长围巾的长度。例如，如果第一个脚的颜色的最左边索引是
    100，最后一个脚的颜色的最右边索引是 110，那么他们所需的最长围巾是 110 – 100 + 1 = 11。
- en: Depending on how we try to find these indices, we might be lucky and find them
    quickly. For example, we might scan from the left for the leftmost index of the
    color of the first foot and scan from the right for the rightmost index of the
    color of the last foot. Then, if the color of the first foot is near the beginning
    of the scarf and the color of the last foot is near the end, we’ll discover these
    indices very quickly.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们寻找这些索引的方法，我们可能会很幸运地迅速找到它们。例如，我们可能从左边扫描以找到第一个脚的颜色的最左边索引，并从右边扫描以找到最后一个脚的颜色的最右边索引。然后，如果第一个脚的颜色靠近围巾的开头，最后一个脚的颜色靠近围巾的结尾，我们就能非常快速地发现这些索引。
- en: We might not be lucky, though. Finding one or both of the indices could take
    up to *n* steps. For example, suppose that a relative wants a scarf whose first
    foot is a color that shows up right at the end of the scarf or that doesn’t show
    up in the scarf at all. We will have to check the entire *n* feet of the scarf,
    one foot at a time, to figure this out.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们可能并不幸运。找到一个或两个索引可能需要多达 *n* 步。例如，假设某个亲戚想要的围巾第一个脚的颜色出现在围巾的最后，或者根本没有出现在围巾上。我们将不得不检查围巾的整个
    *n* 个脚，一次一个，才能搞清楚这一点。
- en: So, about *n* steps per relative. That’s linear time, and we know that linear
    time is fast. Are we good? No, because in this case the linear-time work is far
    more menacing than it may appear. Remember that we’d be doing this *O*(*n*) work
    for each of the *m* relatives. We therefore have an *O*(*mn*) algorithm overall.
    *m* and *n* can be as big as 100,000\. So, *mn* can be as big as 100,000 *** 100,000
    = 10,000,000,000\. That’s 10 billion! Given that we can do about five million
    operations per second and that our time limit is 0.4 seconds . . . yeah, we’re
    not even close. There’s no need to implement this algorithm. We’re certain that
    it will time out on large test cases. We may as well move on and spend our time
    implementing something else. (If you’re nevertheless curious about the code, please
    see the online resources associated with the book. Just remember that without
    even looking at the code, we already figured out that it would be too slow. The
    power of big O analysis is in helping us understand whether an algorithm is doomed
    even before we implement it.)
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，对于每个亲戚，约 *n* 步。那是线性时间，我们知道线性时间是很快的。我们可以接受吗？不，因为在这种情况下，线性时间的工作远比它看起来更具威胁。记住，我们将对每个
    *m* 个亲戚执行 *O*(*n*) 的工作。因此，我们的整体算法是 *O*(*mn*)。*m* 和 *n* 的值可能高达 100,000。这样，*mn*
    可能高达 100,000 *** 100,000 = 10,000,000,000。这是 100 亿！考虑到我们每秒能进行约五百万次操作，而我们的时间限制是
    0.4 秒……是的，我们远远不够。没有必要实现这个算法。我们确信它会在大规模测试用例中超时。我们不如继续前进，花时间实现其他东西。（如果你仍然对代码感兴趣，请查看与书籍相关的在线资源。只要记住，即使不看代码，我们已经意识到它会太慢。大
    O 分析的强大之处在于，它能帮助我们在实现之前就了解一个算法是否注定失败。）
- en: Algorithm 2
  id: totrans-191
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 算法 2
- en: We’re going to have to somehow process each of the relatives—there’s no getting
    around that. What we’ll focus on optimizing, then, is the amount of work that
    we do per relative. Unfortunately, processing a relative in the way we did in
    the previous section may cause us to check over a huge portion of the scarf. It’s
    this searching through the scarf, once per relative, that’s crushing us. We need
    to get that searching under control.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须以某种方式处理每个亲戚——这是无法避免的。那么，我们将专注于优化每个亲戚所需的工作量。不幸的是，以我们在上一节中所做的方式处理亲戚可能导致我们检查围巾的很大一部分。正是这种每处理一个亲戚就要扫描一遍围巾的搜索过程，压垮了我们。我们需要控制住这个搜索过程。
- en: 'Suppose that we could look through the scarf only once, up-front, before we
    knew anything about what the relatives wanted. We could remember two things about
    each color in the scarf: its leftmost index and its rightmost index. Then, no
    matter what each relative wants, we could figure out the maximum length of their
    desired scarf using the left and right indices that we had already stored.'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们只能在一开始就看一次围巾，在了解任何亲戚想要什么之前。我们可以记住围巾中每种颜色的两件事：它的最左索引和最右索引。然后，不管每个亲戚想要什么，我们都可以通过我们已经存储的左索引和右索引来计算他们所需围巾的最大长度。
- en: 'For example, assume we have this scarf:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们有这条围巾：
- en: '[PRE19]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We would store the following information for it:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 我们会为它存储以下信息：
- en: '| **Color** | **Leftmost index** | **Rightmost index** |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| **颜色** | **最左索引** | **最右索引** |'
- en: '| --- | --- | --- |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 1 | 4 | 4 |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 4 | 4 |'
- en: '| 2 | 3 | 5 |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 3 | 5 |'
- en: '| 4 | 1 | 2 |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 1 | 2 |'
- en: '| 18 | 0 | 0 |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| 18 | 0 | 0 |'
- en: Suppose that a relative wants a scarf whose first foot is color 1 and whose
    last foot is color 2\. We look up the leftmost index for color 1, which is 4,
    and the rightmost index for color 2, which is 5\. We then calculate 5 – 4 + 1
    = 2, and that’s the length of the longest desired scarf for this relative.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 假设某个亲戚想要一条围巾，第一只脚是颜色1，最后一只脚是颜色2。我们查找颜色1的最左索引，它是4，查找颜色2的最右索引，它是5。然后我们计算 5 – 4
    + 1 = 2，这就是这个亲戚所需围巾的最大长度。
- en: 'Amazing: no matter how long the scarf, we can just do a quick calculation for
    each relative. No more running through the scarf over and over. The only tricky
    thing here is how to calculate all the leftmost and rightmost indices for the
    colors and to do so by looking through the scarf only once.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 真棒：无论围巾多长，我们只需要为每个亲戚做一次快速计算。再也不需要反复浏览围巾。唯一棘手的是如何计算所有颜色的最左和最右索引，并且仅通过查看围巾一次来完成。
- en: The code is presented in [Listing 10-1](ch10.xhtml#ch10ex01). Try to figure
    out how the `leftmost_index` and `rightmost_index` dictionaries are constructed
    before you continue reading my explanation that follows.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 代码呈现在[列表 10-1](ch10.xhtml#ch10ex01)中。在继续阅读我接下来的解释之前，尝试理解`leftmost_index`和`rightmost_index`字典是如何构建的。
- en: '[PRE20]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '*Listing 10-1: Solving Longest Scarf, algorithm 2*'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '*列表 10-1：解决最长围巾问题，算法2*'
- en: 'This solution uses two dictionaries: one to keep track of the leftmost index
    for each color ❶ and one to keep track of the rightmost index for each color ❷.'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 该解决方案使用了两个字典：一个用于跟踪每种颜色的最左索引❶，另一个用于跟踪每种颜色的最右索引❷。
- en: 'As promised, we look at each foot of the scarf just once ❸. Here’s how we keep
    the `leftmost_index` and `rightmost_index` dictionaries up-to-date:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 如承诺，我们每次只看围巾的一只脚❸。下面是我们如何保持`leftmost_index`和`rightmost_index`字典实时更新的方法：
- en: If the color of the current foot has never been seen before ❹, then the current
    index serves as both the leftmost and rightmost index for this color.
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果当前脚的颜色以前从未见过❹，那么当前索引将既是该颜色的最左索引，也是最右索引。
- en: Otherwise, the color of the current foot has been seen before ❺. We don’t want
    to update the leftmost index for this color, because the current index is to the
    right of the old one. We *do* want to update the rightmost index, though, because
    we have found an index to the right of the old one.
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 否则，当前脚的颜色已经出现过❺。我们不想更新该颜色的最左索引，因为当前索引在旧索引的右侧。然而，我们确实想要更新最右索引，因为我们找到了一个位于旧索引右侧的索引。
- en: 'Now for the payoff: for each relative, we can simply look up the leftmost and
    rightmost indices from these dictionaries ❻. The maximum length of the desired
    scarf is the rightmost index of the color of the last foot, minus the leftmost
    index of the color of the first foot, plus one.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 现在来说说回报：对于每个亲戚，我们可以简单地从这些字典❻中查找最左索引和最右索引。所需围巾的最大长度是最后一只脚的颜色的最右索引减去第一只脚的颜色的最左索引，再加一。
- en: As I’ll argue now, this algorithm is far better than algorithm 1\. Reading the
    scarf takes *O*(*n*) time, as does processing the scarf ’s feet. That’s *O*(*n*)
    time so far. We then take a constant number of steps to process each relative
    (not *n* steps like before!), so that’s *O*(*m*) time. In total, we have an *O*(*m*
    + *n*) algorithm, rather than an *O*(*mn*) algorithm. Given that *m* and *n* can
    be at most 100,000, we’re doing only about 100,000 + 100,000 = 200,000 steps,
    easily done within the time limit. You can submit our code to the judge to prove
    it!
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我现在要论证的，这个算法比算法 1 要好得多。读取围巾的操作需要 *O*(*n*) 时间，处理围巾的脚也需要 *O*(*n*) 时间。到目前为止，总共是
    *O*(*n*) 时间。接下来，我们对每个相对进行常数次数的处理（不像之前那样是 *n* 步！），所以这是 *O*(*m*) 时间。总的来说，我们得到了一个
    *O*(*m* + *n*) 的算法，而不是一个 *O*(*mn*) 的算法。鉴于 *m* 和 *n* 最大为 100,000，我们只需进行大约 100,000
    + 100,000 = 200,000 步，完全可以在时间限制内完成。你可以把我们的代码提交给评测系统来验证！
- en: 'Problem #25: Ribbon Painting'
  id: totrans-214
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '问题 #25：绸带绘制'
- en: Here’s another problem where the first algorithm that we might come up with
    is too slow. We won’t waste much time on that algorithm, though, because our big
    O analysis will tell us all we need to know before we consider implementing the
    code. We’ll then spend our time designing a faster algorithm.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 这是另一个问题，其中我们可能首先想到的算法太慢了。不过我们不会浪费太多时间在这个算法上，因为我们的大 O 分析会在我们考虑实现代码之前告诉我们所有需要知道的内容。然后我们将花时间设计一个更快的算法。
- en: This is DMOJ problem `dmopc17c4p1`.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 DMOJ 问题 `dmopc17c4p1`。
- en: The Challenge
  id: totrans-217
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 挑战任务
- en: You have a purple ribbon whose length is *n* units. The first unit goes from
    position 0 up to but not including position 1, the second unit goes from position
    1 up to but not including position 2, and so on. You then carry out *q* paint
    strokes, each of which colors a segment of the ribbon blue.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 你有一条紫色绸带，长度为 *n* 单位。第一单位从位置 0 开始，直到但不包括位置 1，第二单位从位置 1 开始，直到但不包括位置 2，依此类推。然后你进行
    *q* 次油漆笔画，每次涂抹绸带的一段蓝色。
- en: Your goal is to determine the number of units of the ribbon that are still purple
    and the number of units of the ribbon that are now blue.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 你的目标是确定仍然是紫色的绸带单位数和现在是蓝色的单位数。
- en: Input
  id: totrans-220
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 输入
- en: 'The input consists of the following lines:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 输入包含以下几行：
- en: A line containing the integer ribbon length *n* and integer number of paint
    strokes *q*, separated by a space. *n* and *q* are each between 1 and 100,000.
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一行包含整数绸带长度 *n* 和油漆笔画的整数数量 *q*，两者用空格分隔。*n* 和 *q* 都在 1 到 100,000 之间。
- en: '*q* lines, one per paint stroke, containing two integers separated by a space.
    The first integer gives the starting position of the paint stroke; the second
    gives the ending position of the paint stroke. The starting position is guaranteed
    to be less than the ending position; each integer is between 0 and *n*. The paint
    stroke goes from the starting position up to but not including the ending position.
    As a quick example here, if a paint stroke has a starting position of 5 and an
    ending position of 12, then the stroke paints the ribbon from position 5 up to
    but not including position 12.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*q* 行，每行一个油漆笔画，包含两个整数，用空格分隔。第一个整数给出油漆笔画的起始位置；第二个整数给出油漆笔画的结束位置。起始位置保证小于结束位置；每个整数都在
    0 和 *n* 之间。油漆笔画从起始位置涂抹直到但不包括结束位置。这里给出一个简单的例子，如果油漆笔画的起始位置是 5，结束位置是 12，那么涂抹的区域是从位置
    5 到但不包括位置 12。'
- en: Output
  id: totrans-224
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 输出
- en: Output the number of units of the ribbon that are still purple, a space, and
    the number of units of the ribbon that are now blue.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 输出绸带仍然是紫色的单位数，一个空格，和现在是蓝色的单位数。
- en: The time limit for solving the test cases is 2 seconds.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 解决测试用例的时间限制为 2 秒。
- en: Exploring a Test Case
  id: totrans-227
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 探索一个测试用例
- en: 'Let’s look at a small test case. This test case will not only ensure that we’ve
    interpreted the problem correctly but also highlight the perils of a naive algorithm.
    Here it is:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来看一个小的测试用例。这个用例不仅能确保我们正确理解了问题，还能展示朴素算法的危险。这里是：
- en: '[PRE21]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Our ribbon’s length is 20, and there are four paint strokes. How much of the
    ribbon do our paint strokes turn blue?
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的绸带长度是 20，油漆笔画次数是四次。我们的油漆笔画将绸带的多少部分涂成蓝色？
- en: The first paint stroke paints one unit blue, the one that starts at position
    18.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 第一次油漆笔画涂抹的是起始位置为 18 的单个单位蓝色。
- en: The second paint stroke paints the units of ribbon starting at positions 4,
    5, 6, 7, and so on, all the way up to position 15\. That’s 12 units painted blue
    by this stroke, and 13 blue units in total.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 第二次油漆笔画涂抹的绸带单位是从位置 4、5、6、7 等等，一直到位置 15。这次笔画涂抹了 12 个单位，总共涂抹了 13 个蓝色单位。
- en: The third paint stroke paints 10 units blue. But all of those units are already
    blue from the second paint stroke! It would be a colossal waste of time indeed
    if we spent time “painting” anything with this paint stroke. Whatever algorithm
    we come up with better not fall into this time-wasting trap.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 第三次涂漆涂了10个蓝色单元，但这些单元都已经被第二次涂漆涂成蓝色！如果我们还花时间“涂漆”这些单元，那将是极大的时间浪费。无论我们提出什么算法，都最好避免这种时间浪费的陷阱。
- en: 'The fourth paint stroke paints 7 units blue. But again: all of these units
    are already blue!'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 第四次涂漆涂了7个蓝色单元。但同样：这些单元都已经是蓝色了！
- en: 'Now we’re done painting, and we have 13 blue units. There are 20 – 13 = 7 remaining
    purple units, so the correct output for this test case is:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们完成了涂漆，得到了13个蓝色单元。剩余的紫色单元为20 – 13 = 7个，所以该测试用例的正确输出是：
- en: '[PRE22]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Solving the Problem
  id: totrans-237
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 解决问题
- en: The maximum length of the ribbon is 100,000, and the maximum number of paint
    strokes is 100,000\. Recall algorithm 1 from when we solved Longest Scarf, where
    we learned that an *O*(*mn*) algorithm was too slow with these bounds. Similarly,
    here, an *O*(*nq*) algorithm would be inadequate, as it would not finish within
    the time limit on large test cases.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 丝带的最大长度为100,000，最大涂漆次数为100,000。回想一下我们在解决《最长围巾》问题时使用的算法1，当时我们发现*O*(*mn*)算法在这些边界下运行太慢。类似地，在这里，*O*(*nq*)算法也不合适，因为在大规模测试用例上，它无法在时间限制内完成。
- en: This means that we cannot afford to process each unit that is painted by each
    paint stroke. It would be nice if we could more easily focus on only the *new*
    units that are painted blue by a paint stroke. Then we could go through each paint
    stroke and add up the number of blue units that it contributes.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们不能逐个处理每个涂漆单元。假如我们能更容易地专注于仅由涂漆涂成蓝色的*新*单元就好了。这样我们就可以遍历每个涂漆，计算它所贡献的蓝色单元数量。
- en: Fair enough, but how can we determine the contribution of each paint stroke?
    That’s tricky, because bits and pieces of the next paint stroke may have already
    been painted blue by previous paint strokes.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 说得对，但我们如何确定每次涂漆的贡献呢？这很棘手，因为下一次涂漆的一部分可能已经被前面的涂漆覆盖成了蓝色。
- en: This situation is made much simpler, however, if we sort the paint strokes first.
    Remember from “n log n Time” earlier in this chapter that sorting is extremely
    fast, taking only *O*(*n* log *n*) time. There’s no efficiency concern in using
    sorting, so let’s understand why sorting helps us here.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果我们先对涂漆进行排序，这种情况会变得简单得多。还记得本章早些时候提到的“n log n 时间”吗？排序是极其快速的，仅需*O*(*n* log
    *n*)时间。使用排序没有效率上的问题，所以让我们理解为什么排序在这里能帮助我们。
- en: 'Sorting the paint strokes from the test case in the prior section gives us
    the following list of paint strokes:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 对上一节测试用例中的涂漆进行排序后，我们得到以下涂漆列表：
- en: '[PRE23]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Now that the paint strokes are sorted, we can efficiently process them. As we
    do so, we’ll store the rightmost position of any paint stroke that we’ve processed
    so far. We’ll start this rightmost position off at 0 to indicate that we haven’t
    painted anything.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 现在涂漆已经排序好了，我们可以高效地处理它们。在处理的过程中，我们会存储目前为止已处理的涂漆中最右端的位置。我们从0开始设置这个最右端位置，表示我们尚未涂漆任何地方。
- en: Our first paint stroke paints 14 – 4 = 10 units blue. Now our stored rightmost
    position is 14.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一次涂漆涂了14 – 4 = 10个蓝色单元。现在我们存储的最右端位置是14。
- en: Our second paint stroke paints 12 units blue, yes, but how many of those 12
    does it turn from purple to blue? After all, it overlaps the previous paint stroke,
    so some of these units were blue already. We can calculate the number of new blue
    units by subtracting 14, our stored rightmost position, from 16, the ending position
    of the current paint stroke. This is how we ignore the units already painted blue
    by previous paint strokes. So, there are 16 – 14 = 2 new blue units and 12 blue
    units in total. Crucially, we just figured this out without processing the individual
    units of this paint stroke. Before we continue, don’t forget to update our stored
    rightmost position to 16.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第二次涂漆涂了12个蓝色单元，没错，但其中有多少单元是从紫色变成蓝色的呢？毕竟，它与之前的涂漆有重叠，因此有一些单元已经是蓝色的了。我们可以通过将14（我们存储的最右端位置）从16（当前涂漆的结束位置）中减去，来计算出新的蓝色单元数量。这样，我们就可以忽略之前涂漆过的蓝色单元。所以，新的蓝色单元为16
    – 14 = 2个，总共有12个蓝色单元。关键是，我们在没有处理该涂漆单元的具体细节情况下就解决了这个问题。在继续之前，别忘了更新我们存储的最右端位置为16。
- en: Our third paint stroke is like the second in that it starts prior to our stored
    rightmost position. Unlike the second paint stroke, however, its ending position
    does not extend past our stored rightmost position at all. So, this paint stroke
    adds no new blue units, and our stored rightmost position is still 16\. Again,
    we figured this out without grinding through each of this paint stroke’s positions!
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第三次涂漆和第二次类似，它的起始位置在我们已存储的最右位置之前。然而，不同的是，它的结束位置并没有超过我们已存储的最右位置。因此，这次涂漆不会增加任何新的蓝色单位，我们已存储的最右位置仍然是
    16。再次强调，我们通过不逐个计算每个涂漆位置就得出了这个结论！
- en: Be careful with the fourth paint stroke. It does *not* add 19 – 16 = 3 new blue
    units. We have to treat this paint stroke differently because its starting position
    is to the right of our stored rightmost position. In this case, we don’t use the
    stored rightmost position at all, calculating instead 19 – 18 = 1 new blue unit,
    and 13 blue units in total. We also update our stored rightmost position to 19.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 小心处理第四次涂漆。它*并没有*增加 19 – 16 = 3 个新的蓝色单位。我们必须以不同的方式处理这次涂漆，因为它的起始位置位于我们已存储的最右位置的右侧。在这种情况下，我们根本不使用存储的最右位置，而是计算
    19 – 18 = 1 个新的蓝色单位，总共得到 13 个蓝色单位。同时，我们更新存储的最右位置为 19。
- en: The only question is how we sort the paint strokes in our Python code. We need
    to sort them by their starting position; if multiple paint strokes have the same
    starting position, then we want to sort those by their ending position.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一的问题是如何在 Python 代码中对涂漆进行排序。我们需要按它们的起始位置进行排序；如果多个涂漆的起始位置相同，则需要按它们的结束位置进行排序。
- en: 'That is, we want to take a list like this:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 也就是说，我们希望处理一个像这样的列表：
- en: '[PRE24]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'and produce this:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 并生成如下内容：
- en: '[PRE25]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Happily, as we discovered in “Task 4: Sort Boxes” in [Chapter 6](ch06.xhtml#ch06),
    the list `sort` method works in exactly this way. When given a list of lists,
    `sort` sorts using the first values in each list; when those values are tied,
    the lists are further sorted using the second values. Check it out:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 高兴的是，正如我们在[第6章](ch06.xhtml#ch06)的“任务 4：排序盒子”中发现的那样，`sort` 方法正是这样工作的。当给定一个包含列表的列表时，`sort`
    会使用每个列表中的第一个值进行排序；如果这些值相同，则会根据第二个值进一步排序。请查看：
- en: '[PRE26]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Algorithm: check. Sorting: check. We’re in great shape! Just one more thing
    we’d like to know before we see the code: what will be its big O efficiency? We
    need to read the *q* queries; that takes *O*(*q*) time. Then we need to sort the
    queries; that takes *O*(*q* log *q*) time. Finally, we need to process the queries;
    that takes *O*(*q*) time. The slowest of these is the *O*(*q* log *q*) time for
    the sorting, so that’s our overall big O efficiency.'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 算法：检查。排序：检查。我们准备得很好！在看到代码之前，还有一个问题我们想知道：它的时间复杂度是多少？我们需要读取 *q* 个查询；这需要 *O*(*q*)
    的时间。然后，我们需要对查询进行排序；这需要 *O*(*q* log *q*) 的时间。最后，我们需要处理查询；这需要 *O*(*q*) 的时间。最慢的操作是排序所需的
    *O*(*q* log *q*) 时间，因此这是我们的整体时间复杂度。
- en: Now we have everything we need for a speedy solution. Check it out in [Listing
    10-2](ch10.xhtml#ch10ex02).
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们拥有了快速解决问题所需的一切。在[列表 10-2](ch10.xhtml#ch10ex02)中查看它。
- en: '[PRE27]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '*Listing 10-2: Solving Ribbon Painting*'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: '*列表 10-2：解决 Ribbon Painting 问题*'
- en: We read each paint stroke, appending it as a list of two values to our `strokes`
    list ❶. We then sort all of the paint strokes ❷.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 我们读取每次涂漆，将其作为包含两个值的列表添加到我们的 `strokes` 列表中 ❶。然后，我们对所有涂漆进行排序 ❷。
- en: 'We next need to process each paint stroke from left to right. There are two
    key variables that drive this processing: variable `rightmost_position` stores
    the rightmost position that we have painted so far, and variable `blue` stores
    the number of units that we have painted blue so far.'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要从左到右处理每一次涂漆。有两个关键变量控制着这一过程：变量 `rightmost_position` 存储我们到目前为止涂漆的最右位置，变量
    `blue` 存储我们到目前为止涂漆的蓝色单位数。
- en: To process a paint stroke, we need to know whether it starts before or after
    our stored rightmost position. Let’s think about each of these cases in turn.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 要处理一次涂漆，我们需要知道它是从已存储的最右位置之前开始，还是之后开始。让我们逐一考虑这两种情况。
- en: 'First: what do we do when the paint stroke starts before our stored rightmost
    position ❸? This paint stroke might give us some new blue units, but only if it
    extends past our stored rightmost position. If it does, then the new blue units
    are those between the stored rightmost position and the ending position of the
    paint stroke ❹.'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 首先：当涂漆开始位置在我们已存储的最右位置之前时 ❸，我们该怎么办？这次涂漆可能会给我们一些新的蓝色单位，但只有当它超出我们已存储的最右位置时，才会增加新的蓝色单位。如果是这样，那么新增的蓝色单位就是从存储的最右位置到涂漆结束位置之间的单位
    ❹。
- en: 'Second: what do we do when the paint stroke starts after our stored rightmost
    position ❺? This time, the paint stroke is completely separate from the painting
    we have done so far; this entire paint stroke is a new blue segment. As such,
    the new blue units are those between the ending position and starting position
    of this paint stroke ❻.'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 第二：当涂漆操作从我们存储的最右位置 ❺ 开始时，我们该怎么办？这次，涂漆操作与我们迄今为止的涂漆完全分开；这整个涂漆操作是一个新的蓝色段。因此，新的蓝色单位是从这次涂漆的结束位置到起始位置之间的部分
    ❻。
- en: Notice in each case that we also correctly update our stored rightmost position
    so that we’re ready to process any further paint strokes.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在每个情况下，我们也正确地更新了我们存储的最右位置，以便我们准备好处理任何进一步的涂漆操作。
- en: That’s a wrap! Guided by our big O analysis, we were able to dismiss an algorithm
    whose implementation we knew would be too slow. We then thought about a second
    algorithm—and before implementing it, we knew it would be plenty fast. It’s time
    to submit our code to the judge and bask in our success.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 完成了！在我们的大 O 分析指导下，我们能够淘汰一个我们知道会太慢的算法实现。然后，我们考虑了第二个算法——在实现之前，我们就知道它会足够快。现在是时候将我们的代码提交给评判，享受我们的成功了。
- en: Summary
  id: totrans-267
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter, we learned about big O analysis. Big O is an important efficiency
    building block for further study of algorithm design. You’ll see it everywhere:
    in tutorials, in books, probably in your next job interview!'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们学习了大 O 分析。大 O 是进一步研究算法设计的一个重要效率构建块。你将会在各个地方看到它：教程中、书籍中，也许在你下一次的工作面试中！
- en: We also solved two problems where we needed to design very efficient algorithms.
    Not only were we able to do that, but we were also able to use big O to obtain
    a satisfying understanding of exactly why our code was so efficient.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还解决了两个问题，在这些问题中，我们需要设计非常高效的算法。我们不仅能够做到这一点，还能利用大 O 符号清楚地理解我们的代码为何如此高效。
- en: Chapter Exercises
  id: totrans-270
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 章节练习
- en: Here are some exercises for you to try. For each, use big O to determine whether
    your proposed algorithm is efficient enough to solve the problem within the time
    limit. You might also like to implement algorithms that you know are going to
    be too slow. That would give you extra practice solidifying your Python knowledge
    and confirm that your big O analysis was spot-on!
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些练习供你尝试。对于每个练习，使用大 O 来判断你提出的算法是否足够高效，能够在时间限制内解决问题。你也可以实现那些你知道会太慢的算法，这将帮助你巩固
    Python 知识，并确认你的大 O 分析是否准确！
- en: Some of these problems are quite challenging. There are two reasons. First,
    you might agree based on your work throughout the book that coming up with *any*
    algorithm can be tough. Coming up with a faster algorithm can be even tougher.
    Second, this is the end of our time together, but only the beginning of the study
    of algorithms. I hope that these problems both help you appreciate what you’ve
    accomplished and offer evidence that there’s a lot more beyond this book if you
    want it.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 这些问题有些非常具有挑战性。原因有二。首先，基于你在本书中的工作，你可能会同意，想出*任何*一个算法都很困难。而想出一个更快的算法可能会更难。其次，这是我们共同学习的结束，但算法研究才刚刚开始。如果你想继续深入，这些问题将帮助你既欣赏自己所取得的成就，又能证明在本书之外，还有很多内容等待你去探索。
- en: DMOJ problem `dmopc17c1p1`, Fujo Neko (The problem talks about using fast input/output.
    Don’t ignore that!)
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: DMOJ 问题 `dmopc17c1p1`，Fujo Neko（这个问题讲的是使用快速输入/输出。不要忽视这一点！）
- en: DMOJ problem `coci10c1p2`, Profesor
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: DMOJ 问题 `coci10c1p2`，Profesor
- en: 'DMOJ problem `coci19c4p1`, Pod starim krovovima (Hint: to maximize the number
    of empty glasses, you want to put as much liquid as possible in the biggest glasses.)'
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: DMOJ 问题 `coci19c4p1`，Pod starim krovovima（提示：为了最大化空玻璃杯的数量，你需要将尽可能多的液体倒入最大的玻璃杯中。）
- en: DMOJ problem `dmopc20c1p2`, Victor’s Moral Dilemma
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: DMOJ 问题 `dmopc20c1p2`，Victor的道德困境
- en: DMOJ problem `avocadotrees`, Avocado Trees!
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: DMOJ 问题 `avocadotrees`，鳄梨树！
- en: 'DMOJ problem `coci11c5p2`, Eko (Hint: the maximum number of trees is far fewer
    than the maximum number of heights. Consider each tree from tallest to shortest.)'
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: DMOJ 问题 `coci11c5p2`，Eko（提示：树木的最大数量远小于高度的最大数量。从最高的树开始考虑。）
- en: 'DMOJ problem `wac6p2`, Cheap Christmas Lights (Hint: don’t try flipping a switch
    each second—how would you know which one to flip? Instead, store them up, and
    use them all as soon as you can shut off all the lights that are on.)'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: DMOJ 问题 `wac6p2`，廉价的圣诞灯（提示：不要尝试每秒都切换一次开关——你怎么知道该切换哪个呢？相反，先把它们都存起来，并在能关掉所有亮着的灯时一次性使用它们。）
- en: 'DMOJ problem `ioi98p3`, Party Lamps (Hint: all that matters for each button
    is whether it is pressed an even or odd number of times.)'
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: DMOJ 问题 `ioi98p3`，派对灯（提示：每个按钮的关键是它被按下的次数是偶数次还是奇数次。）
- en: Notes
  id: totrans-281
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注释
- en: Longest Scarf is originally from the DMOPC ’14 March Contest. Ribbon Painting
    is originally from the DMOPC ’20 November Contest.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 最长围巾最初来自 DMOPC ’14 三月竞赛。丝带绘画最初来自 DMOPC ’20 十月竞赛。

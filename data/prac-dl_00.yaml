- en: INTRODUCTION
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引言
- en: '![Image](Images/common.jpg)'
  id: totrans-1
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/common.jpg)'
- en: When I was in high school, I wanted to write a tic-tac-toe program that the
    user would play against a computer. At the time, I was blissfully unaware of how
    real computer scientists approached such a problem. I had only my own thoughts,
    and those were to implement a lot of rules using the crude if-then statements
    and gotos supported by unstructured Applesoft BASIC. It was a lot of rules—a few
    hundred lines’ worth.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在我上高中时，我想写一个井字游戏程序，用户可以和计算机对战。当时，我完全不知道真正的计算机科学家是如何处理这样的问题的。我只有自己的想法，那就是用粗糙的
    if-then 语句和不结构化的 Applesoft BASIC 来实现大量的规则。这是许多规则——几百行代码。
- en: In the end, the program worked well enough, until I found the sequence of moves
    that my rules didn’t cover and was able to win every time. I felt certain that
    there must be a way to teach a computer how to do things by showing it examples
    instead of brute-force code and rules—a way to make the computer learn on its
    own.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，程序运行得足够好，直到我发现了一些我的规则没有覆盖的动作序列，并且能够每次都获胜。我确信一定有一种方法可以通过展示示例来教计算机如何做事情，而不是依赖死板的代码和规则——一种让计算机自我学习的方法。
- en: As an undergraduate student in the later 1980s, I was excited to sign up for
    a course in artificial intelligence. The course finally answered my question about
    how to write a tic-tac-toe playing program, but the computer wasn’t learning;
    it was still just using a clever algorithm. Incidentally, the same course assured
    us that while it was expected that someday a computer would beat the world’s best
    chess player, which happened in 1997, it was impossible for a computer to beat
    the best human at a game like Go. In March 2016, the AlphaGo deep learning program
    did just that.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 上世纪80年代末，作为一名本科生，我非常兴奋地报名参加了人工智能课程。课程最终解答了我关于如何写一个井字游戏程序的问题，但计算机并没有学习；它仍然只是在使用一个巧妙的算法。顺便说一句，同一课程还曾向我们保证，虽然预计有一天计算机会打败世界上最好的国际象棋选手，这一事件在1997年发生了，但计算机永远不可能打败最顶尖的围棋选手。然而，2016年3月，AlphaGo深度学习程序就做到了这一点。
- en: 'In 2003, while working as a consultant for a scientific computing company,
    I was assigned to a project with a major medical device manufacturer. The goal
    was to classify, in real time, intravascular ultrasound images of coronary arteries
    by using *machine learning*: a subfield of artificial intelligence that learns
    from data on its own, developing models that were not explicitly programmed by
    a human. This was what I was waiting for!'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 2003年，当我在一家科学计算公司担任顾问时，我被分配到一个与一家大型医疗设备制造商的项目中。目标是通过使用*机器学习*：一种能够从数据中自我学习、并发展出非人工显式编程模型的人工智能子领域，在实时中对冠状动脉的血管内超声图像进行分类。这正是我所期待的！
- en: I was vaguely aware of machine learning and that there were strange beasts called
    neural networks that could do some interesting things, but for the most part,
    machine learning was simply a small research area and not something the average
    computer science person paid much attention to. However, during the project, I
    fell in love with the idea of training a machine to do something useful without
    explicitly writing a lot of code. I kept learning on my own, even after the project
    ended.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我大致了解机器学习以及有一种叫做神经网络的奇怪存在，它们能够做一些有趣的事情，但大多数时候，机器学习只是一个小小的研究领域，并不是普通计算机科学人员关注的重点。然而，在这个项目中，我爱上了训练机器做有用的事情，而不是显式地写很多代码的想法。即使项目结束后，我依然在自学。
- en: Circa 2010, I was involved with another machine learning project, and the timing
    was perfect. People were just beginning to discuss a new approach to machine learning
    called *deep learning*, which revived the old neural networks. When 2012 rolled
    around, the flood-gates opened. I was fortunate enough to be in the room at the
    ICML 2012 conference in Edinburgh, Scotland when Google presented its initial
    breakthrough deep learning results that responded to cats in YouTube videos. The
    room was crowded. After all, there were a whopping 800 people at the conference.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 大约在2010年，我参与了另一个机器学习项目，时机非常合适。人们开始讨论一种新的机器学习方法，叫做*深度学习*，它重新激活了旧有的神经网络。2012年，局面发生了剧变。我有幸参加了2012年在苏格兰爱丁堡举行的ICML会议，当时谷歌展示了它们初步的深度学习突破，能够识别YouTube视频中的猫。会场非常拥挤，毕竟当时会议有多达800人参加。
- en: 'It’s now 2020, and the machine learning conference I recently went to had over
    13,000 attendees. Machine learning has exploded: it’s not a fad that will disappear.
    Machine learning has profoundly affected our lives and will continue to do so.
    It would be nice to know something about it, to get past the oftentimes hyped-up
    presentations down to the essential core, which is interesting enough, no hype
    needed. That is why this book exists, to help you learn the essentials of machine
    learning. Specifically, we’ll be focusing on the approach known as deep learning.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是2020年，我最近参加的机器学习大会有超过13,000名与会者。机器学习已经爆炸性增长：它不是一个会消失的潮流。机器学习深刻地影响了我们的生活，并将继续如此。了解一些关于机器学习的知识是很有用的，能够突破那些经常被夸大其词的演讲，深入到其本质核心，这本身就很有趣，根本不需要炒作。这也是本书存在的原因，帮助你学习机器学习的基本要素。具体来说，我们将重点介绍一种称为深度学习的方法。
- en: Who Is This Book For?
  id: totrans-9
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本书适合谁？
- en: I wrote this book for readers who have no background in machine learning, but
    who are curious and willing to experiment with things. I’ve kept the math to a
    minimum. My goal is to help you understand core concepts and build intuition you
    can use going forward.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我写这本书是为那些没有机器学习背景的读者，但他们充满好奇心并愿意进行实验的人。我将数学内容保持在最低限度。我的目标是帮助你理解核心概念，并建立你可以在未来使用的直觉。
- en: At the same time, I didn’t want to write a book that simply instructed you on
    *how* to use existing toolkits but was devoid of any real substance as to the
    *why* of things. It’s true that if all you care about is the *how*, you can build
    useful models. But without the *why*, you’ll only be parroting, not understanding,
    let alone eventually moving the field forward with your own contributions.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，我不想写一本仅仅教你如何使用现有工具包的书，而是缺乏关于事物*为什么*的实际内容。确实，如果你只关心*如何*做，你可以构建有用的模型。但没有*为什么*，你只是机械地模仿，而不是理解，更别提通过自己的贡献推动这个领域向前发展了。
- en: As far as assumptions on my part, I assume you have some familiarity with computer
    programming, in any language. The language of choice for machine learning, whether
    you are a student or a major corporation, is Python, so that’s the language we’ll
    use. I’ll also assume you’re familiar with high school math but not calculus.
    A little calculus will creep in anyway, but you should be able to follow the ideas,
    even if the technique is unfamiliar. I’ll also assume you know a bit of statistics
    and basic probability. If you’ve forgotten those topics since high school, don’t
    worry—you’ll find relevant sections in [Chapter 1](ch01.xhtml#ch01) that give
    you enough of a background to follow the narrative.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 至于我的假设，我假设你对计算机编程有所了解，使用任何语言都可以。无论你是学生还是大型公司，机器学习的首选语言是Python，因此我们将使用Python。我还假设你对高中数学有所了解，但不一定懂微积分。虽然书中会稍微涉及一些微积分，但你应该能够跟得上，即使该技术对你来说不熟悉。我还假设你了解一些统计学和基础概率。如果你自高中以来忘记了这些内容，别担心——你将在[第一章](ch01.xhtml#ch01)中找到相关章节，为你提供足够的背景，帮助你跟上叙述。
- en: What Can You Expect to Learn?
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你可以期待学习哪些内容？
- en: 'If you work through this book in its entirety, you can expect to learn about
    the following:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你完整地读完本书，你可以预期学习以下内容：
- en: How to build a good training dataset. This is a dataset that will let your model
    be successful when used “in the wild.”
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何构建一个好的训练数据集。这是一个能够确保你的模型在“真实环境”中成功的 dataset。
- en: 'How to work with two of the leading machine learning toolkits: scikit-learn
    and Keras.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用两个主流的机器学习工具包：scikit-learn和Keras。
- en: How to evaluate the performance of a model once you’ve trained and tested it.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在训练和测试模型后评估其性能。
- en: How to use several classical machine learning models like *k*-Nearest Neighbors,
    Random Forests, or Support Vector Machines.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用几种经典的机器学习模型，比如*k*-最近邻、随机森林或支持向量机。
- en: How neural networks work and are trained.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经网络如何工作以及如何训练。
- en: How to develop models using convolutional neural networks.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用卷积神经网络开发模型。
- en: How to start with a given set of data and develop a successful model from scratch.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何从一组给定的数据出发，构建一个成功的模型。
- en: About This Book
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本书简介
- en: This book is about machine learning. Machine learning is about building models
    that take input data and arrive at some conclusion from that data. That conclusion
    might be a label placing the object into a particular class of objects, like a
    certain kind of dog, or a continuous output value, say the price one should ask
    for a house with the given set of amenities. The key here is that the model learns
    from the data on its own. In effect, the model learns by example.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书讲的是机器学习。机器学习是关于构建模型，这些模型接收输入数据并从这些数据中得出结论。这个结论可能是一个标签，将对象归类到某一特定类别中，比如某种狗，或者是一个连续的输出值，例如根据给定的设施要求为房子定价。这里的关键是模型能够自行从数据中学习。实际上，模型是通过示例来学习的。
- en: You can think of the model as a mathematical function, *y* = *f* (*x*), where
    *y* is the output, the class label, or the continuous value, and *x* is the set
    of *features* representing the unknown input. Features are measurements or information
    about the input that the model can use to learn what output to generate. For example,
    *x* might be a vector representing the length, width, and weight of a fish, where
    each of those measurements is a feature. Our goal is to find *f*, a mapping between
    *x* and *y* that we’ll be able to use on new instances of *x*, for which we do
    not know *y*.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以把模型看作一个数学函数，*y* = *f* (*x*)，其中 *y* 是输出，可能是类别标签或连续值，*x* 是代表未知输入的一组 *特征*。特征是关于输入的测量或信息，模型可以利用这些信息来学习生成什么输出。例如，*x*
    可能是一个向量，表示一条鱼的长度、宽度和重量，其中每个测量值都是一个特征。我们的目标是找到 *f*，即 *x* 和 *y* 之间的映射，我们希望能够在新的
    *x* 实例上使用它，而这些实例的 *y* 是我们所不知道的。
- en: 'The standard way to learn *f* is to give our model (or algorithm) known data,
    and have the model learn the parameters it needs to make *f* a useful mapping.
    This is why it’s called *machine learning*: the machine is learning the parameters
    of the model. We’re not thinking of the rules ourselves and cementing them in
    code. Indeed, for some model types like neural networks, it’s not even clear *what*
    the model has learned, only that the model is now performing at a useful level.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 学习 *f* 的标准方法是给我们的模型（或算法）提供已知数据，并让模型学习它所需的参数，以便使 *f* 成为一个有用的映射。这就是为什么它被称为 *机器学习*：机器正在学习模型的参数。我们并不是自己思考规则并将其固化在代码中。实际上，对于一些模型类型，比如神经网络，甚至无法清楚地知道模型学到了
    *什么*，只知道模型现在在执行上已经达到了有用的水平。
- en: 'There are three main branches to machine learning: *supervised learning*, *unsupervised
    learning*, and *reinforcement learning*. The process we just described falls under
    supervised learning. We supervised the training of the model with a set of known
    *x* and *y* values, the *training set*. We call a dataset like this a *labeled*
    dataset because we know the *y* that goes with each *x*. Unsupervised learning
    attempts to learn the parameters used by the model using only *x*. We won’t discuss
    unsupervised learning here, but you can transfer a lot of our discussion of supervised
    learning if you want to explore that area on your own later.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习有三个主要分支：*监督学习*、*无监督学习* 和 *强化学习*。我们刚才描述的过程属于监督学习。我们通过一组已知的 *x* 和 *y* 值来监督模型的训练，这组数据叫做
    *训练集*。我们称这种数据集为 *标记数据集*，因为我们知道每个 *x* 对应的 *y* 值。无监督学习则试图仅通过 *x* 来学习模型使用的参数。我们这里不讨论无监督学习，但如果你稍后想要自己探索这一领域，可以将我们对监督学习的讨论转移到无监督学习上。
- en: Reinforcement learning trains models to perform tasks, like playing chess or
    Go. The model learns a set of actions to take given the current state of its world.
    This is an important area of machine learning, and it has recently achieved a
    high level of success on tasks previously thought to be solely the domain of humans.
    Sadly, compromises had to be made to make this book manageable, so we’ll ignore
    reinforcement learning altogether.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习训练模型执行任务，比如下棋或围棋。模型学习一组动作，以便根据当前的世界状态采取行动。这是机器学习的一个重要领域，最近在一些以前被认为仅属于人类领域的任务上取得了显著的成功。遗憾的是，为了使这本书更具可读性，我们将完全忽略强化学习的内容。
- en: 'One quick note on terminology. In the media, a lot of what we’re talking about
    in this book is referred to as *artificial intelligence*, or *AI*. While this
    is not wrong, it’s somewhat misleading: machine learning is one subfield of the
    broader field of artificial intelligence. Another term you’ll often hear is *deep
    learning*. This term is a bit nebulous, but for our purposes, we’ll use it to
    mean machine learning with neural networks, in particular, neural networks with
    many layers (hence *deep*). [Figure 1](introduction.xhtml#introfig1) shows the
    relationship between these terms.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 关于术语的一个简短说明。在媒体中，我们在本书中讨论的很多内容被称为*人工智能*，或称为*AI*。虽然这并不错误，但有些误导：机器学习是人工智能这一广泛领域的一个子领域。你还经常会听到另一个术语是*深度学习*。这个术语有点模糊，但在我们这里，我们将其用来指代使用神经网络的机器学习，特别是具有多层的神经网络（因此称为*深度*）。[图
    1](introduction.xhtml#introfig1)展示了这些术语之间的关系。
- en: '![image](Images/00fig01.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/00fig01.jpg)'
- en: '*Figure 1: The relationship between artificial intelligence, machine learning,
    and deep learning*'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 1：人工智能、机器学习和深度学习的关系*'
- en: Of course, within the fields of machine learning and deep learning, there’s
    considerable variety. We’ll encounter a number of models throughout this book.
    We could arrange them in what we’ll call “the tree of machine learning,” pictured
    in [Figure 2](introduction.xhtml#introfig2).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，在机器学习和深度学习领域内，存在着相当大的多样性。在本书中，我们将遇到许多模型。我们可以将它们组织成我们所称的“机器学习树”，如[图 2](introduction.xhtml#introfig2)所示。
- en: '![image](Images/00fig02.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/00fig02.jpg)'
- en: '*Figure 2: The tree of machine learning*'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 2：机器学习的树*'
- en: 'The tree shows the growth from traditional machine learning at the root to
    modern deep learning at the top of the tree. Consider this a preview of what’s
    to come: we’ll look at each of these models in this book.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这棵树展示了从传统机器学习到现代深度学习的成长过程，树根处为传统机器学习，树顶为现代深度学习。把这看作是对未来内容的预览：在本书中，我们将逐一探讨这些模型。
- en: Along those same lines, we’ll end this introduction with a quick synopsis of
    each chapter.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，我们将以每章内容的简要概述来结束本章的介绍。
- en: '**[Chapter 1: Getting Started](ch01.xhtml#ch01)** This chapter tells you how
    to set up our assumed working environment. It also includes sections about vectors,
    matrices, probability, and statistics that you can use as refreshers or for background.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第一章：入门](ch01.xhtml#ch01)** 本章介绍了如何设置我们假设的工作环境。它还包括有关向量、矩阵、概率和统计的内容，可以作为复习资料或背景知识。'
- en: '**[Chapter 2: Using Python](ch02.xhtml#ch02)** This chapter will get you started
    on Python.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第二章：使用 Python](ch02.xhtml#ch02)** 本章将帮助你入门 Python。'
- en: '**[Chapter 3: Using NumPy](ch03.xhtml#ch03)** NumPy is an extension to Python.
    It’s what makes Python useful for machine learning. If you are not familiar with
    it, peruse this chapter.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第三章：使用 NumPy](ch03.xhtml#ch03)** NumPy 是 Python 的一个扩展，它使得 Python 在机器学习中变得非常有用。如果你不熟悉它，可以浏览本章内容。'
- en: '**[Chapter 4: Working with Data](ch04.xhtml#ch04)** Bad datasets lead to bad
    models; we’ll teach you what makes a good one.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第四章：数据处理](ch04.xhtml#ch04)** 不良的数据集会导致糟糕的模型；我们将教你如何构建好的数据集。'
- en: '**[Chapter 5: Building Datasets](ch05.xhtml#ch05)** We’ll build the datasets
    used throughout the book. You’ll also learn how to augment datasets.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第五章：构建数据集](ch05.xhtml#ch05)** 我们将构建本书中使用的数据集。你还将学习如何扩增数据集。'
- en: '**[Chapter 6: Classical Machine Learning](ch06.xhtml#ch06)** To understand
    where you are going, sometimes it’s good to know where you came from. Here we’ll
    cover some of the original machine learning models.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第六章：经典机器学习](ch06.xhtml#ch06)** 为了理解你将要前往的方向，有时了解你来自何处也是有帮助的。在这里，我们将介绍一些最初的机器学习模型。'
- en: '**[Chapter 7: Experiments with Classical Models](ch07.xhtml#ch07)** This chapter
    shows the strengths and weaknesses of the old-school approach to machine learning.
    We’ll refer to these results for comparison purposes throughout the book.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第七章：经典模型的实验](ch07.xhtml#ch07)** 本章展示了老式机器学习方法的优缺点。我们将在全书中引用这些结果进行对比。'
- en: '**[Chapter 8: Introduction to Neural Networks](ch08.xhtml#ch08)** Modern deep
    learning is all about neural networks; we’ll introduce them here.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第八章：神经网络简介](ch08.xhtml#ch08)** 现代深度学习就是围绕神经网络展开的；我们将在这里介绍它们。'
- en: '**[Chapter 9: Training a Neural Network](ch09.xhtml#ch09)** This challenging
    chapter gives you the knowledge you need to understand how neural networks are
    trained. Some basic calculus slipped into this chapter, but don’t panic—it’s discussed
    at a high level to give you intuition, and the notation isn’t as frightening as
    it might seem at first.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第9章：训练神经网络](ch09.xhtml#ch09)** 这一具有挑战性的章节为你提供了理解神经网络训练过程所需的知识。本章中涉及了一些基础的微积分内容，但不用担心——它们是从高层次进行讨论的，目的是帮助你建立直觉，而且这些符号并不像它们乍看上去那样可怕。'
- en: '**[Chapter 10: Experiments with Neural Networks](ch10.xhtml#ch10)** Here we
    run experiments to build intuition and get a feel for actually working with data.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第10章：神经网络实验](ch10.xhtml#ch10)** 在这里，我们通过实验来建立直觉，感受实际操作数据的过程。'
- en: '**[Chapter 11: Evaluating Models](ch11.xhtml#ch11)** To understand the results
    presented in machine learning papers, talks, and lectures, we need to understand
    how to evaluate models. This chapter will take you through the process.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第11章：评估模型](ch11.xhtml#ch11)** 为了理解机器学习论文、演讲和讲座中呈现的结果，我们需要理解如何评估模型。本章将带领你了解这个过程。'
- en: '**[Chapter 12: Introduction to Convolutional Neural Networks](ch12.xhtml#ch12)**
    The deep learning we will focus on in this book is embodied in the idea of a convolutional
    neural network, or CNN. This chapter discusses the basic building blocks of these
    networks.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第12章：卷积神经网络简介](ch12.xhtml#ch12)** 本书将重点讨论的深度学习体现在卷积神经网络（CNN）这一概念中。本章将讨论这些网络的基本构建块。'
- en: '**[Chapter 13: Experiments with Keras and MNIST](ch13.xhtml#ch13)** Here we’ll
    explore how CNNs work by experimenting with the MNIST dataset, the workhorse of
    deep learning.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第13章：使用Keras和MNIST的实验](ch13.xhtml#ch13)** 在这里，我们将通过对MNIST数据集进行实验，探索卷积神经网络（CNN）的工作原理，MNIST是深度学习中的常用数据集。'
- en: '**[Chapter 14: Experiments with CIFAR-10](ch14.xhtml#ch14)** The MNIST dataset,
    useful as it is, is a simple one for CNNs to master. Here we explore another workhorse
    dataset, CIFAR-10, which consists of actual images and will challenge our models.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第14章：使用CIFAR-10的实验](ch14.xhtml#ch14)** 尽管MNIST数据集很有用，但它对CNN来说是一个相对简单的挑战。在这里，我们将探索另一个常用数据集CIFAR-10，它包含实际的图像，将对我们的模型提出更大的挑战。'
- en: '**[Chapter 15: A Case Study: Classifying Audio Samples](ch15.xhtml#ch15)**
    We’ll conclude with a case study. We start with a new dataset, one not in widespread
    use, and work through the process of building a good model for it. This chapter
    uses everything we studied in the book, from building and augmenting data to classical
    models, traditional neural networks, CNNs, and ensembles of models.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第15章：案例研究：音频样本分类](ch15.xhtml#ch15)** 我们将通过一个案例研究来结束。本章从一个新的数据集开始，这个数据集并未广泛使用，并且通过构建一个好的模型来解决问题。这个章节应用了本书中所学的所有内容，从数据构建和增强，到经典模型、传统神经网络、CNN和模型集成。'
- en: '**[Chapter 16: Going Further](ch16.xhtml#ch16)** No book is complete. This
    one won’t even try to be. This chapter points out some of what we’ve neglected
    and helps you sift through the mountains of resources around you related to machine
    learning so you can focus on what you should study next.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第16章：进一步探索](ch16.xhtml#ch16)** 没有一本书是完美的，本书也不会尝试做到这一点。本章指出了我们忽略的一些内容，并帮助你筛选出机器学习领域中海量资源，确保你能够专注于下一步应该学习的内容。'
- en: 'All the code in the book, organized by chapter, can be found here: *[https://nostarch.com/practical-deep-learning-python/](https://nostarch.com/practical-deep-learning-python/)*.
    Let’s now take a look at setting up our operating environment.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的所有代码，按章节组织，可以在这里找到： *[https://nostarch.com/practical-deep-learning-python/](https://nostarch.com/practical-deep-learning-python/)*。接下来，让我们看看如何设置我们的操作环境。

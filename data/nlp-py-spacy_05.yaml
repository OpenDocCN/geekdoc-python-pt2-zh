- en: '**5'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**5**'
- en: WORKING WITH WORD VECTORS**
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用词向量**'
- en: '![Image](../Images/comm1.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/comm1.jpg)'
- en: Word vectors are the series of real numbers that represent the meanings of natural
    language words. As you learned in [Chapter 1](../Text/ch01.xhtml#ch01), they allow
    machines to understand human language. In this chapter, you’ll use word vectors
    to calculate the semantic similarity of different texts, which will allow you
    to, for example, classify those texts based on the topics they cover.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 词向量是表示自然语言单词意义的一系列实数。如同你在[第1章](../Text/ch01.xhtml#ch01)中学到的，它们使机器能够理解人类语言。在本章中，你将使用词向量来计算不同文本的语义相似性，这将使你能够，例如，根据文本所涵盖的主题对这些文本进行分类。
- en: You’ll start by taking a conceptual look at word vectors so you can get an idea
    of how to mathematically calculate the semantic similarity between the words represented
    in the form of vectors. Then you’ll learn how machine learning algorithms generate
    the word vectors implemented in spaCy models. You’ll use spaCy’s *similarity method*,
    which compares the word vectors of container objects to determine the closeness
    of their meanings. You’ll also learn how to use word vectors in practice and perform
    preprocessing steps, such as choosing keywords, to make your operations more efficient.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 你将首先从概念上了解词向量，这样你就能大致了解如何在数学上计算以向量形式表示的单词之间的语义相似性。接着，你将学习机器学习算法如何生成在 spaCy 模型中实现的词向量。你将使用
    spaCy 的 *相似性方法*，该方法通过比较容器对象的词向量来确定它们意义的接近程度。你还将学习如何在实际中使用词向量并执行预处理步骤，例如选择关键词，以提高你的操作效率。
- en: '**Understanding Word Vectors**'
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**理解词向量**'
- en: When building statistical models, we map words to vectors of real numbers that
    reflect the words’ semantic similarity. You can imagine a word vector space as
    a cloud in which the vectors of words with similar meanings are located nearby.
    For instance, the vector representing the word “potato” should be closer to the
    vector of the word “carrot” than to that of the word “crying.” To generate these
    vectors, we must be able to encode the meaning of these words. There are a few
    approaches to encoding meaning, which we’ll outline in this section.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建统计模型时，我们将单词映射到反映单词语义相似性的实数向量。你可以将词向量空间想象成一个云，在这个云中，具有相似意义的词的向量相互靠近。例如，表示“土豆”这个词的向量应该比表示“哭泣”这个词的向量更接近表示“胡萝卜”这个词的向量。为了生成这些词向量，我们必须能够对这些词的意义进行编码。本节将概述几种编码意义的方法。
- en: '***Defining Meaning with Coordinates***'
  id: totrans-7
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***通过坐标定义意义***'
- en: 'One way to generate meaningful word vectors is by assigning an object or category
    from the real world to each coordinate of a word vector. For example, suppose
    you’re generating word vectors for the following words: Rome, Italy, Athens, and
    Greece. The word vectors should mathematically reflect the fact that Rome is the
    capital of Italy and is related to Italy in a way that Athens is not. At the same
    time, they should reflect the fact that Athens and Rome are capital cities, and
    that Greece and Italy are countries. [Table 5-1](../Text/ch05.xhtml#ch05tab01)
    illustrates what this vector space might look like in the form of a matrix.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 生成有意义的词向量的一种方法是将现实世界中的物体或类别分配给每个词向量的坐标。例如，假设你正在为以下词汇生成词向量：罗马、意大利、雅典和希腊。词向量应在数学上反映出罗马是意大利的首都，并且与意大利的关系是雅典所没有的。同时，它们还应该反映出雅典和罗马都是首都城市，而希腊和意大利是国家。[表格
    5-1](../Text/ch05.xhtml#ch05tab01)展示了该词向量空间可能以矩阵形式呈现的样子。
- en: '**Table 5-1:** A Simplified Word Vector Space'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**表格 5-1：** 简化的词向量空间'
- en: '|  | **Country** | **Capital** | **Greek** | **Italian** |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '|  | **国家** | **首都** | **希腊语** | **意大利语** |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Italy | 1 | 0 | 0 | 1 |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| 意大利 | 1 | 0 | 0 | 1 |'
- en: '| Rome | 0 | 1 | 0 | 1 |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| 罗马 | 0 | 1 | 0 | 1 |'
- en: '| Greece | 1 | 0 | 1 | 0 |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| 希腊 | 1 | 0 | 1 | 0 |'
- en: '| Athens | 0 | 1 | 1 | 0 |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| 雅典 | 0 | 1 | 1 | 0 |'
- en: We’ve distributed the meaning of each word between its coordinates in a four-dimensional
    space, representing the categories “Country,” “Capital,” “Greek,” and “Italian.”
    In this simplified example, a coordinate value can be either 1 or 0, indicating
    whether or not a corresponding word belongs to the category.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经将每个词的意义分布在四维空间的坐标上，表示“国家”、“首都”、“希腊语”和“意大利语”这几个类别。在这个简化的例子中，一个坐标值可以是 1 或
    0，表示一个对应的词是否属于某个类别。
- en: 'Once you have a vector space in which vectors of numbers capture the meaning
    of corresponding words, you can use vector arithmetic on this vector space to
    gain insight into a word’s meaning. To find out which country Athens is the capital
    of, you could use the following equation, where each token stands for its corresponding
    vector and X is an unknown vector:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你拥有一个词向量空间，其中数字的向量捕捉了相应单词的意义，你就可以对这个向量空间进行向量运算，以深入理解一个单词的意义。为了找出雅典是哪个国家的首都，你可以使用以下公式，其中每个标记代表其对应的向量，X是一个未知的向量：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This equation expresses an analogy in which X represents the word vector that
    has the same relationship to `Athens` as `Italy` has to `Rome`. To solve for X,
    we can rewrite the equation like this:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这个公式表达了一种类比，其中X代表与`雅典`的关系类似于`意大利`与`罗马`之间关系的词向量。为了解出X，我们可以像这样重新写这个公式：
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We first subtract the vector `Rome` from the vector `Italy` by subtracting the
    corresponding vector elements. Then we add the sum of the resulting vector and
    the vector `Athens`. [Table 5-2](../Text/ch05.xhtml#ch05tab02) summarizes this
    calculation.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先通过减去相应的向量元素，将`罗马`的向量从`意大利`的向量中减去。然后我们将得到的向量和`雅典`的向量相加。[表5-2](../Text/ch05.xhtml#ch05tab02)总结了这个计算过程。
- en: '**Table 5-2:** Performing a Vector Math Operation on a Word Vector Space'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**表5-2：** 在词向量空间上执行向量数学运算'
- en: '|  |  | **Country** | **Capital** | **Greek** | **Italian** |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '|  |  | **国家** | **首都** | **希腊** | **意大利** |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| ― | Italy | 1 | 0 | 0 | 1 |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| ― | 意大利 | 1 | 0 | 0 | 1 |'
- en: '| + | Rome | 0 | 1 | 0 | 1 |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| + | 罗马 | 0 | 1 | 0 | 1 |'
- en: '|  | Athens | 0 | 1 | 1 | 0 |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '|  | 雅典 | 0 | 1 | 1 | 0 |'
- en: '|  | Greece | 1 | 0 | 1 | 0 |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '|  | 希腊 | 1 | 0 | 1 | 0 |'
- en: By subtracting the word vector for Rome from the word vector for Italy and then
    adding the word vector for Athens, we get a vector that is equal to the vector
    `Greece`.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 通过从意大利的词向量中减去罗马的词向量，然后再加上雅典的词向量，我们得到一个等于`希腊`的词向量。
- en: '***Using Dimensions to Represent Meaning***'
  id: totrans-30
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***使用维度表示意义***'
- en: Although the vector space we just created had only four categories, a real-world
    vector space might require tens of thousands. A vector space of this size would
    be impractical for most applications, because it would require a huge word-embedding
    matrix. For example, if you had 10,000 categories and 1,000,000 entities to encode,
    you’d need a 10,000 × 1,000,000 embedding matrix, making operations on it too
    time-consuming. The obvious approach to reducing the size of the embedding matrix
    is to reduce the number of categories in the vector space.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们刚才创建的向量空间只有四个类别，但现实世界中的向量空间可能需要成千上万个类别。如此大的向量空间对于大多数应用来说不切实际，因为它需要一个巨大的词嵌入矩阵。例如，如果你有10,000个类别和1,000,000个实体需要编码，你将需要一个10,000
    × 1,000,000的嵌入矩阵，进行操作时将非常耗时。减少嵌入矩阵大小的明显方法是减少向量空间中的类别数量。
- en: Instead of using coordinates to represent all categories, a real-world implementation
    of a word vector space uses the distance between vectors to quantify and categorize
    semantic similarities. The individual dimensions typically don’t have inherent
    meanings. Instead, they represent locations in the vector space, and the distance
    between vectors indicates the similarity of the corresponding words’ meanings.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现实世界中的词向量空间不是使用坐标来表示所有类别，而是使用向量之间的距离来量化和分类语义相似性。各个维度通常没有固有的意义，而是表示向量空间中的位置，向量之间的距离则表明相应单词意义的相似度。
- en: 'The following is a fragment of the 300-dimensional word vector space extracted
    from the *fastText,* a word vector library, which you can download at *[https://fasttext.cc/docs/en/english-vectors.html](https://fasttext.cc/docs/en/english-vectors.html)*:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是从*fastText*（一个词向量库）提取的300维词向量空间的一个片段，您可以在* [https://fasttext.cc/docs/en/english-vectors.html](https://fasttext.cc/docs/en/english-vectors.html)
    *下载它：
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Each line contains a word represented as a vector of real numbers in multidimensional
    space. Graphically, we can represent a 300-dimensional vector space like this
    one with either a 2D or 3D projection. To prepare such a projection, we can use
    first two or three principal coordinates of a vector, respectively. [Figure 5-1](../Text/ch05.xhtml#ch05fig01)
    shows vectors from a 300-dimensional vector space in a 2D projection.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 每一行包含一个词，以一个多维空间中的实数向量表示。图形上，我们可以用二维或三维投影表示这样一个300维的向量空间。为了准备这样的投影，我们可以分别使用向量的前两或前三个主坐标。[图5-1](../Text/ch05.xhtml#ch05fig01)展示了300维向量空间中向量的二维投影。
- en: '![image](../Images/fig5-1.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![image](../Images/fig5-1.jpg)'
- en: '*Figure 5-1: A fragment of a 2D projection of a multidimensional vector space*'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 5-1：二维投影的多维向量空间片段*'
- en: One interesting detail you might notice here is that the lines connecting Greece
    with Athens and Italy with Rome, respectively, are almost parallel. Their lengths
    also look comparable. In practice, this means that if you have three out of the
    above four vectors, you can calculate an approximate location of the missing one,
    since you know where to shift the vector and how far.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会注意到的一个有趣细节是，分别连接希腊与雅典、意大利与罗马的线几乎是平行的。它们的长度看起来也相当可比。实际上，这意味着，如果你有上述四个向量中的三个，你可以计算出缺失向量的大致位置，因为你知道如何移动向量以及移动的距离。
- en: The vectors in the diagram illustrate a country-capital relation, but they could
    easily have another type of relation, such as male-female, verb tense, and so
    on.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图中的向量展示了国家和首都之间的关系，但它们也可以代表其他类型的关系，例如男女关系、动词时态等。
- en: '***The Similarity Method***'
  id: totrans-40
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***相似度方法***'
- en: In spaCy, every type of container object has a *similarity method* that allows
    you to calculate a semantic similarity estimate between two container objects
    of any type by comparing their word vectors. To calculate the similarity of spans
    and documents, which don’t have their own word vectors, spaCy averages the word
    vectors of the tokens they contain.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在 spaCy 中，每种类型的容器对象都有一个*相似度方法*，该方法允许你通过比较单词向量计算两个容器对象之间的语义相似度估计值，无论它们的类型如何。为了计算跨度和文档的相似度（它们没有自己的单词向量），spaCy
    会对它们所包含的词汇的单词向量进行平均。
- en: '**NOTE**'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*spaCy’s small models (those whose model size indicator is %`sm`) don’t include
    word vectors. You can still use the similarity method with these models to compare
    tokens, spans, and documents, but the results won’t be as accurate.*'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '*spaCy 的小型模型（那些模型大小指示符为 %`sm` 的模型）不包括单词向量。你仍然可以使用这些模型的相似度方法来比较标记、跨度和文档，但结果的准确性较低。*'
- en: You can calculate the semantic similarity of two container objects even if the
    two objects are different. For example, you can compare a Token object with a
    Span object, a Span object with a Doc object, and so on.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 即使两个容器对象不同，你也可以计算它们的语义相似度。例如，你可以将 Token 对象与 Span 对象进行比较，将 Span 对象与 Doc 对象进行比较，等等。
- en: 'The following example computes how similar a Span object is to a Doc object:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例计算了一个 Span 对象与一个 Doc 对象的相似度：
- en: '[PRE3]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This code calculates a semantic similarity estimate between the sentence “I
    want a green apple.” and the phrase “a green apple” derived from this same sentence.
    As you can see, the computed degree of similarity is high enough to consider the
    content of two objects similar (the degree of similarity ranges from 0 to 1).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码计算了句子“I want a green apple.”与从同一句话中提取的短语“a green apple”之间的语义相似度估计值。正如你所看到的，计算出的相似度足够高，可以认为这两个对象的内容相似（相似度的范围是从
    0 到 1）。
- en: 'Not surprisingly, the `similarity()` method returns 1 when you compare an object
    with itself:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 不出所料，当你将一个对象与它自身进行比较时，`similarity()` 方法返回 1：
- en: '[PRE4]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'You can also compare a Doc object with a slice from another Doc object:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以将一个 Doc 对象与另一个 Doc 对象中的一个片段进行比较：
- en: '[PRE5]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Here, we compare the sentence “I like red oranges.” stored in `doc2` with the
    span “a green apple” extracted from `doc`. In this case, the degree of similarity
    is not so high this time. Yes, oranges and apples are both fruits (the similarity
    method recognizes this fact), but the verbs “want” and “like” express different
    states of being.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，我们将存储在 `doc2` 中的句子“I like red oranges.”与从 `doc` 中提取的“a green apple”跨度进行比较。在这种情况下，这次的相似度并不高。是的，橙子和苹果都是水果（相似度方法识别了这一点），但动词“want”和“like”表达的是不同的存在状态。
- en: You can also compare two tokens. In the following example, we compare the Token
    object “oranges” to a Span object containing a single token “apple.”
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以比较两个标记。在以下示例中，我们将 Token 对象“oranges”与包含单个标记“apple”的 Span 对象进行比较。
- en: '[PRE6]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: First, we explicitly convert the Span object containing a single token “oranges”
    to a Token object by referring to the first element in the span. Then we calculate
    how similar it is to the span “apple.”
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们显式地将包含单个标记“oranges”的 Span 对象通过引用跨度中的第一个元素转换为 Token 对象。然后，我们计算它与“apple”跨度的相似度。
- en: The `similarity()` method can recognize words that belong to the same or similar
    categories and that often appear in related contexts, showing a high level of
    similarity for such words.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '`similarity()` 方法能够识别属于相同或相似类别并经常出现在相关上下文中的单词，对这些单词显示出较高的相似度。'
- en: '***Choosing Keywords for Semantic Similarity Calculations***'
  id: totrans-57
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***选择用于语义相似度计算的关键词***'
- en: 'The similarity method will calculate semantic similarity for you, but for the results
    of that calculation to be useful, you need to choose the right keywords to compare.
    To understand why, consider the following text snippet:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 相似度方法将为你计算语义相似度，但为了让该计算结果有用，你需要选择正确的关键字进行比较。为了理解其原因，考虑以下文本片段：
- en: '[PRE7]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We might classify this text in a variety of ways depending on the set of categories
    we want to use. If, for example, we’re searching for texts about highest plants
    on the planet, the phrases “tallest trees” and “in the world” will be the key
    ones. Comparing these phrases with the search phrases “highest plants” and “on
    the planet” should show a high level of the semantic similarity. We can do this
    by extracting noun chunks using a Doc object’s `doc.noun_chunk` property and then
    checking the similarity of those noun chunks and the search phrases using the
    similarity method.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以根据想要使用的类别集以多种方式对这段文本进行分类。例如，如果我们在寻找关于地球上最高植物的文本，“*最高树木*”和“*全球范围内*”将是关键短语。将这些短语与搜索短语“*最高植物*”和“*地球上的*”进行比较，应该会显示出很高的语义相似度。我们可以通过使用
    Doc 对象的 `doc.noun_chunk` 属性提取名词短语，然后使用相似度方法检查这些名词短语与搜索短语的相似度来实现这一点。
- en: 'But if we’re looking for texts about places in the world, “California” will
    be the keyword. Of course, we don’t know in advance which geopolitical name might
    occur in a text: it could be California or, say, Amazonia. But whatever it is,
    it should be semantically similar to a word like “geography,” which we can compare
    with the text’s other nouns (or, even better, with its named entities only). If
    we’re able to determine that there’s a high level of similarity, we can assume
    that the named entity in question represents a geopolitical name. (We might also
    extract the `token.ent_type` attribute of a Token object to do this, as described
    in [Chapter 2](../Text/ch02.xhtml#ch02). But we wouldn’t be able to use named
    entity recognition to check the similarity of words that aren’t named entities,
    say, fruits.)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果我们在寻找关于世界上某个地方的文本，那么“*加利福尼亚*”将是关键字。当然，我们无法预先知道文本中会出现哪个地理政治名称：它可能是加利福尼亚，或者是亚马逊地区。无论是什么，它都应该在语义上类似于“地理学”这样的词，我们可以将其与文本中的其他名词进行比较（或者，更好地，仅与其命名实体进行比较）。如果我们能够确定有很高的相似度，我们就可以假设该命名实体代表一个地理政治名称。（我们也可以提取
    Token 对象的 `token.ent_type` 属性来实现这一点，正如[第 2 章](../Text/ch02.xhtml#ch02)中所描述的。但我们无法使用命名实体识别来检查那些不是命名实体的单词的相似性，比如水果。）
- en: '**Installing Word Vectors**'
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**安装词向量**'
- en: If a spaCy model is installed in your Python environment, you can start using
    word vectors right away. You can also install a third-party word vector package.
    Various statistical models use different word vectors, so the results of your
    operations will differ slightly based on the model you’re using. You can try several
    models to determine which one works better in your particular application.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的 Python 环境中安装了 spaCy 模型，你可以立即开始使用词向量。你还可以安装第三方词向量包。不同的统计模型使用不同的词向量，因此你进行的操作结果会略有不同，具体取决于你使用的模型。你可以尝试几个模型，以确定哪个模型在你的特定应用中表现更好。
- en: '***Taking Advantage of Word Vectors That Come with spaCy Models***'
  id: totrans-64
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***利用 spaCy 模型附带的词向量***'
- en: Word vectors come as part of many spaCy models. For example, `en_vectors_web_lg`
    includes more than one million unique word vectors defined on a 300-dimensional
    vector space. Check out *[https://github.com/explosion/spacy-models/releases/](https://github.com/explosion/spacy-models/releases/)*
    for details on a particular model.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 许多 spaCy 模型都包含词向量。例如，`en_vectors_web_lg` 包含超过一百万个在 300 维向量空间中定义的独特词向量。有关特定模型的详细信息，请查看
    *[https://github.com/explosion/spacy-models/releases/](https://github.com/explosion/spacy-models/releases/)*。
- en: Typically, small models (those whose names end with `sm`) don’t contain word
    vectors. Instead, they come with context-sensitive *tensors*, which still allow
    you to work with the similarity methods to compare tokens, spans, and documents—although
    at the expense of accuracy.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，小型模型（其名称以 `sm` 结尾）不包含词向量。相反，它们包含上下文敏感的 *张量*，这仍然允许你使用相似度方法比较标记、跨度和文档——尽管这样做的准确性较低。
- en: To follow along with the examples given in this chapter, you can use any spaCy
    model, even small ones. But you’ll get more accurate results if you install a
    larger model. For details on how to install a spaCy model, refer to “[Installing
    Statistical Models for spaCy](../Text/ch02.xhtml#lev14)” on [page 16](../Text/ch02.xhtml#page_16).
    Note that you might have more than one model installed in your environment.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 要跟随本章中的示例，你可以使用任何 spaCy 模型，甚至是小型模型。但如果你安装一个较大的模型，结果会更加准确。关于如何安装 spaCy 模型的详细信息，请参考
    “[Installing Statistical Models for spaCy](../Text/ch02.xhtml#lev14)” 章节的 [第16页](../Text/ch02.xhtml#page_16)。请注意，你的环境中可能安装了多个模型。
- en: '***Using Third-Party Word Vectors***'
  id: totrans-68
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***使用第三方词向量***'
- en: You can also use third-party packages of word vectors with spaCy. You can check
    whether a third-party will work better for your application than native word vectors
    available in a spaCy model. For example, you can use a fastText pretrained model
    with English word vectors, which you can download at *[https://fasttext.cc/docs/en/english-vectors.html](https://fasttext.cc/docs/en/english-vectors.html)*.
    The name of a package will identify the size of the package and word vectors,
    and the kind of data used to train the word vectors. For example, *wiki-news-300d-1M.vec.zip*
    indicates that it contains one million 300-dimensional word vectors trained on
    Wikipedia and the *statmt.org* news dataset.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以使用 spaCy 的第三方词向量包。你可以检查一个第三方包是否比 spaCy 模型中提供的原生词向量更适合你的应用。例如，你可以使用一个包含英语词向量的
    fastText 预训练模型，下载地址是 *[https://fasttext.cc/docs/en/english-vectors.html](https://fasttext.cc/docs/en/english-vectors.html)*。包的名称会标识包的大小、词向量的维度以及用于训练词向量的数据类型。例如，*wiki-news-300d-1M.vec.zip*
    表示它包含一百万个 300 维度的词向量，这些向量是在 Wikipedia 和 *statmt.org* 新闻数据集上训练的。
- en: 'After downloading a package, unzip it, and then create a new model from the
    vectors in the package that you can use with spaCy. To do this, navigate to the
    folder where you saved the package, and then use the `init-model` command line
    utility, like this:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 下载包后，解压它，然后从包中的词向量创建一个新的模型，这样你就可以在 spaCy 中使用它。为此，导航到你保存包的文件夹，然后使用 `init-model`
    命令行工具，如下所示：
- en: '[PRE8]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The command converts the vectors taken from the *wiki-news-300d-1M.vec* file
    into spaCy’s format and creates the new model directory */tmp/en_vectors_wiki_lg*
    for them. If everything goes well, you’ll see the following messages:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令将从 *wiki-news-300d-1M.vec* 文件中提取的词向量转换为 spaCy 格式，并为它们创建新的模型目录 */tmp/en_vectors_wiki_lg*。如果一切顺利，你会看到以下信息：
- en: '[PRE9]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Once you’ve created the model, you can load it like a regular spaCy model:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你创建了模型，你可以像使用常规的 spaCy 模型一样加载它：
- en: '[PRE10]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Then you can create a Doc object as you normally would:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你可以像往常一样创建一个 Doc 对象：
- en: '[PRE11]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Unlike a regular spaCy model, a third-party model converted for use in spaCy
    might not support some of spaCy’s operations against text contained in a doc object.
    For example, if you try to shred a doc into sentences using `doc.sents`, you’ll
    get the following error: `ValueError: [E030] Sentence boundaries unset...`'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '与常规的 spaCy 模型不同，为在 spaCy 中使用而转换的第三方模型可能不支持 spaCy 针对 doc 对象中文本进行的一些操作。例如，如果你尝试使用
    `doc.sents` 将 doc 拆分成句子，你会遇到以下错误：`ValueError: [E030] Sentence boundaries unset...`'
- en: '**Comparing spaCy Objects**'
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**比较 spaCy 对象**'
- en: Let’s use word vectors to calculate the similarity of container objects, the
    most common task for which we use word vectors. In the rest of this chapter, we’ll
    explore some scenarios in which you’d want to determine the semantic similarity
    of linguistic units.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用词向量来计算容器对象的相似性，这是使用词向量的最常见任务。在本章的剩余部分，我们将探讨一些你可能需要确定语言单位语义相似性的场景。
- en: '***Using Semantic Similarity for Categorization Tasks***'
  id: totrans-81
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***使用语义相似性进行分类任务***'
- en: 'Determining two objects’ syntactic similarity can help you sort texts into
    categories or pick out only the relevant texts. For example, suppose you’re sorting
    through user comments posted to a website to find all the comments related to
    the word “fruits.” Let’s say you have the following utterances to evaluate:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 确定两个对象的句法相似性可以帮助你将文本分类或挑选出相关的文本。例如，假设你在网站上筛选用户评论，以找出所有与“fruits”相关的评论。假设你有以下需要评估的语句：
- en: '[PRE12]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: You can easily recognize that only the second sentence is directly related to
    fruits because it contains the word “citrus.” But to pick out this sentence programmatically,
    you’ll have to compare the word vector for the word “fruits” with word vectors
    in the sample sentences.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以轻松识别出只有第二句话与水果直接相关，因为它包含了“柑橘”这个词。但要通过编程选择出这个句子，你必须将“水果”这个词的词向量与样本句子中的词向量进行比较。
- en: 'Let’s start with the simplest but least successful way of doing this task:
    comparing “fruits” to each of the sentences. As stated earlier, spaCy determines
    the similarity of two container objects by comparing their corresponding word
    vectors. To compare a single token with an entire sentence, spaCy averages the
    sentence’s word vectors to generate an entirely new vector. The following script
    compares each of the preceding sentence samples with the word “fruits”:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从做这项任务最简单但最不成功的方法开始：将“水果”与每个句子进行比较。如前所述，spaCy通过比较两个容器对象的相应词向量来确定它们的相似度。为了将单个Token与整个句子进行比较，spaCy将句子的词向量进行平均，从而生成一个全新的向量。以下脚本将每个前述句子样本与“水果”这个词进行比较：
- en: '[PRE13]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We first create a Token object for the word “fruits” ➊. Then we apply the pipeline
    to the sentences we’re categorizing, creating a single Doc object to hold all
    of them ➋. We shred the doc into sentences ➌, and then print each of the sentences
    and their semantic similarity to the token “fruits,” which we acquire using the
    token object’s similarity method ➍.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先为“水果”这个词创建一个Token对象 ➊。然后我们将管道应用于我们正在分类的句子，创建一个单一的Doc对象来保存它们 ➋。我们将文档切割成句子
    ➌，然后打印出每个句子及其与“水果”这个Token的语义相似度，这个相似度是通过Token对象的similarity方法获得的 ➍。
- en: 'The output should look something like this (although the actual figures will
    depend on the model you use):'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应该像这样（尽管实际数字将取决于你使用的模型）：
- en: '[PRE14]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The degree of similarity between the word “fruits” and the first sentence is
    very small, indicating that the sentence has nothing to do with fruits. The second
    sentence—the one that includes the word “citrus”—is the most closely related to
    “fruits,” meaning the script correctly identified the relevant sentence.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: “水果”这个词与第一句话的相似度非常小，表明这句话与水果没有关系。第二句话——包含“柑橘”这个词的那一句——与“水果”最为相关，这意味着脚本正确地识别了相关句子。
- en: But notice that the script also identified the third sentence as being somehow
    related to fruits, probably because it includes the word “tree,” and fruits grow
    on trees. It would be naive to think that the similarity measuring algorithm “knows”
    that orange and citrus are fruits. All it knows is that these words (“orange”
    and “citrus”) often share the same context with word “fruit” and therefore they’ve
    been put close to it in the vector space. But the word “tree” can also often be
    found in the same context as the word “fruit.” For example, the phrase “fruit
    tree” is not uncommon. For that reason the level of similarity calculated between
    “fruits” (or “fruit” as its lemma) and “tree” is close to the result we got for
    “citrus” and “fruits.”
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 但请注意，脚本也将第三句话识别为与水果相关，可能是因为它包含了“树”这个词，而水果长在树上。认为相似度计算算法“知道”橙子和柑橘是水果是天真的。它所知道的只是这些词（“橙子”和“柑橘”）通常与“水果”这个词共享相同的上下文，因此它们在向量空间中靠得很近。但“树”这个词也常常出现在与“水果”相关的上下文中。例如，“果树”这个短语并不罕见。因此，计算出的“水果”（或其词元“fruit”）和“树”之间的相似度接近我们为“柑橘”和“水果”得到的结果。
- en: There’s another problem with this approach to categorizing texts. In practice,
    of course, you might sometimes have to deal with texts that are much larger than
    the sample texts used in this section. If the text you’re averaging is very large,
    the most important words might have little to no effect on the syntactic similarity
    value.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这种分类文本的方法还有一个问题。当然，在实际应用中，你可能有时需要处理的文本要比本节中使用的样本文本大得多。如果你正在平均的大文本非常庞大，最重要的词可能对句法相似度值几乎没有影响。
- en: To get more accurate results from the similarity method, we’ll need to perform
    some preparations on a text. Let’s look at how we can improve the script.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 为了从相似度方法中获得更准确的结果，我们需要对文本进行一些准备。让我们看看如何改进脚本。
- en: '***Extracting Nouns as a Preprocessing Step***'
  id: totrans-94
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***提取名词作为预处理步骤***'
- en: A better technique for performing categorization would be to extract the most
    important words and compare only those. Preparing a text for processing in this
    way is called *preprocessing*, and it can help make your NLP operations more successful.
    For example, instead of comparing the word vectors for the entire objects, you
    could try comparing the word vectors for certain parts of speech. In most cases,
    you’ll focus on nouns—whether they act as subjects, direct objects, or indirect
    objects—to recognize the meaning conveyed in the text in which they occur. For
    example, in the sentence “Nearly all wild lions live in Africa,” you’ll probably
    focus on lions, Africa, or lions in Africa. Similarly, in the sentence about fruits,
    we focused on picking out the noun “citrus.” In other cases, you’ll need other
    words, like verbs, to decide what a text is about. Suppose you run an agricultural
    produce business and must classify offers from those who produce, process, and
    sell farm products. You often see sentences like, “We grow vegetables,” or “We
    take tomatoes for processing.” In this example, the verbs are just as important
    as nouns in the utterances in the previous examples.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 一个更好的分类技术是提取最重要的词汇，并仅比较这些词汇。以这种方式准备文本进行处理叫做*预处理*，它可以帮助提高你的NLP操作成功的概率。例如，你可以尝试比较某些词性的词向量，而不是比较整个对象的词向量。在大多数情况下，你会专注于名词——无论它们是作为主语、直接宾语还是间接宾语——以识别它们所在文本中传达的意义。例如，在句子“几乎所有的野生狮子生活在非洲”中，你可能会专注于“狮子”，“非洲”或“非洲的狮子”。类似地，在关于水果的句子中，我们专注于挑选出名词“柑橘”。在其他情况下，你可能需要其他词汇，如动词，来决定文本的主题。例如，假设你经营一家农产品公司，必须对来自生产、加工和销售农产品的报价进行分类。你经常会看到像“我们种植蔬菜”或“我们拿番茄去加工”这样的句子。在这个例子中，动词和之前例句中的名词一样重要。
- en: 'Let’s modify the script on [page 70](../Text/ch05.xhtml#page_70). Instead of
    comparing “fruits” to entire sentences, we’ll compare it to the sentences’ nouns
    only:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们修改[第70页](../Text/ch05.xhtml#page_70)上的脚本。我们将不再将“水果”与整个句子进行比较，而是仅与句子的名词进行比较：
- en: '[PRE15]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We start by defining the token “fruits,” which is then used for a series of
    comparisons ➊. Iterating over the tokens in each sentence ➋, we extract the nouns
    and store them in a Python list ➌. Next, we join the nouns in the list into a
    plain string ➍, and then convert that string into a Doc object ➎. We then compare
    this Doc with the token “fruits” to determine their degree of semantic similarity.
    We store each token’s syntactic similarity value in a Python dictionary ➏, which
    we finally print out.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先定义了“水果”这个词项，然后用它进行一系列的比较 ➊。遍历每个句子中的词项 ➋，我们提取出名词并将其存储在Python列表中 ➌。接下来，我们将列表中的名词连接成一个普通字符串
    ➍，然后将该字符串转换为一个Doc对象 ➎。然后，我们将这个Doc与“水果”词项进行比较，以确定它们的语义相似度。我们将每个词项的句法相似度值存储在一个Python字典中
    ➏，并最终将其打印出来。
- en: 'The script’s output should look something like this:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本的输出应该类似于以下内容：
- en: '[PRE16]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'If you compare these figures with the results of the previous script, you’ll
    notice that this time the level of the similarity with the word “fruits” is higher
    for each sentence. But the overall results look similar: the similarity of the
    first sentence is the lowest, whereas the similarity of the other two are much
    higher.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你将这些数字与前一个脚本的结果进行比较，你会注意到这次每个句子与“水果”一词的相似度更高。但总体结果看起来相似：第一句的相似度最低，而其他两句的相似度要高得多。
- en: '***Try This***'
  id: totrans-102
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***尝试这个***'
- en: In the previous example, comparing “fruits” to nouns only, you improved the
    results of the similarity calculations by taking into account only the words that
    matter most (nouns, in this case). You compared the word “fruits” with all the
    nouns extracted from each sentence, combined. Taking it one step further, you
    could look at how each of these nouns is semantically related to the word “fruits”
    to find out which one shows the highest level of similarity. This can be useful
    in evaluating the overall similarity of the document to the word “fruits.” To
    accomplish this, you need to modify the previous script so it determines the similarity
    between the token “fruits” and each of the nouns in a sentence, finding the noun
    that shows the highest level of similarity.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，只比较“水果”与名词时，你通过只考虑最重要的单词（在本例中是名词）改进了相似度计算的结果。你将“水果”这个词与从每个句子提取的所有名词进行了比较，合并在一起。更进一步，你可以查看这些名词与“水果”一词在语义上的关系，以找出哪个名词的相似度最高。这对于评估文档与“水果”一词的整体相似度非常有用。为了实现这一点，你需要修改之前的脚本，以便计算“水果”与每个句子中的名词之间的相似度，从而找出与之最相似的名词。
- en: '***Extracting and Comparing Named Entities***'
  id: totrans-104
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***提取和比较命名实体***'
- en: 'In some cases, instead of extracting every noun from the texts you’re comparing,
    you might want to extract a certain kind of noun only, such as named entities.
    Let’s say you’re comparing the following texts:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，除了提取你比较的文本中的每个名词外，你可能只想提取某种类型的名词，例如命名实体。假设你正在比较以下文本：
- en: “Google Search, often referred to as simply Google, is the most used search
    engine nowadays. It handles a huge number of searches each day.”
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: “Google Search，通常简称为 Google，是目前使用最广泛的搜索引擎。它每天处理大量搜索。”
- en: “Microsoft Windows is a family of proprietary operating systems developed and
    sold by Microsoft. The company also produces a wide range of other software for
    desktops and servers.”
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: “Microsoft Windows 是一系列由微软开发和销售的专有操作系统。该公司还生产广泛的其他桌面和服务器软件。”
- en: “Titicaca is a large, deep, mountain lake in the Andes. It is known as the highest
    navigable lake in the world.”
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: “Titicaca 是安第斯山脉中的一个大而深的山地湖泊。它被认为是世界上最高的可航行湖泊。”
- en: 'Ideally, your script should recognize that the first two texts are about large
    technology companies, but the third text isn’t. But comparing all the nouns in
    this text wouldn’t be very helpful, because many of them, such as “number” in
    the first sentence, aren’t relevant to the context. The differences between the
    sentences involve the following words: “Google,” “Search,” “Microsoft,” “Windows,”
    “Titicaca,” and “Andes.” spaCy recognizes all of these as named entities, which
    makes it a breeze to find and extract them from a text, as illustrated in the
    following script:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，你的脚本应该能识别出前两段文本是关于大型科技公司的，而第三段则不是。但比较这些文本中的所有名词可能并不十分有用，因为其中许多词汇，比如第一句中的“number”，与上下文无关。句子之间的差异包括以下单词：“Google”、“Search”、“Microsoft”、“Windows”、“Titicaca”和“Andes”。spaCy
    能识别出这些都是命名实体，这使得从文本中提取和识别它们变得非常轻松，下面的脚本演示了这一过程：
- en: '[PRE17]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: We group the Docs with the sample texts into a list to make it possible to iterate
    over them in a loop ➊. We define a Python dictionary to store the keywords for
    each text ➋. In a loop iterating over the Docs ➌, we extract these keywords in
    a separate list for each text, selecting only the words marked as named entities
    ➍. Then we print out the list to see what it contains ➎. Next, we convert this
    list into a plain string ➏ to which we then apply the pipeline, converting it
    to a Doc object ➐. We then append the Doc to the `spans` dictionary defined earlier
    ➑.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将包含样本文本的 Docs 分组到一个列表中，以便在循环中迭代 ➊。我们定义一个 Python 字典来存储每个文本的关键词 ➋。在迭代 Docs 的循环中
    ➌，我们为每个文本提取这些关键词，并将它们保存在一个单独的列表中，只选择标记为命名实体的词汇 ➍。然后我们打印出该列表，查看它包含的内容 ➎。接下来，我们将这个列表转换为一个普通的字符串
    ➏，然后将其应用管道，将其转换为一个 Doc 对象 ➐。然后我们将这个 Doc 添加到之前定义的 `spans` 字典中 ➑。
- en: 'The script should produce the following output:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本应该产生以下输出：
- en: '[PRE18]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Now we can see the words in each text whose vectors we’ll compare.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以看到每个文本中的词汇，它们的向量将被用来进行比较。
- en: 'Next, we call `similarity()` on these spans and print the results:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们在这些 spans 上调用 `similarity()` 并打印结果：
- en: '[PRE19]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'This time the output should look as follows:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这次的输出应如下所示：
- en: '[PRE20]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: These figures indicate that the highest level of similarity exists between the
    first and second texts, which are both about American IT companies. How can word
    vectors “know” about this fact? They probably know because the words “Google”
    and “Microsoft” have been found more often in the same texts of the training text
    corpus rather than in the company of the words “Titicaca” and “Andes.”
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这些图表表明，第一篇和第二篇文本之间的相似度最高，这两篇都是关于美国IT公司的。那么，词向量是如何“知道”这一事实的呢？它们可能知道，因为“Google”和“Microsoft”这两个词在训练文本语料库中经常出现在相同的文本中，而不是与“Titicaca”和“Andes”这些词一起出现。
- en: '**Summary**'
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**总结**'
- en: In this chapter, you worked with word vectors, which are vectors of real numbers
    that represent the meanings of words. These representations let you use math to
    determine the semantic similarity of linguistic units, a useful task for categorizing
    texts.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你使用了词向量，它们是表示单词意义的实数向量。这些表示方式让你可以运用数学来确定语言单元的语义相似度，这对于文本分类任务非常有用。
- en: But the math approach might not work as well when you’re trying to determine
    the similarity of two texts without applying any preliminary steps to those texts.
    By applying preprocessing, you can reduce the text to the words that are most
    important in figuring out what the text is about. In particularly large texts,
    you might pick out the named entities found in it, because they most likely best
    describe the text’s category.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，当你尝试在不对文本进行任何预处理的情况下确定两个文本的相似性时，数学方法可能效果不佳。通过应用预处理，你可以将文本简化为最重要的单词，这些单词有助于判断文本的主题。在特别大的文本中，你可能会挑选出其中的命名实体，因为它们最可能最好地描述文本的类别。

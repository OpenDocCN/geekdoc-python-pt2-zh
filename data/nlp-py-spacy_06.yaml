- en: '**6'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**6'
- en: FINDING PATTERNS AND WALKING DEPENDENCY TREES**
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 查找模式与遍历依赖树**
- en: '![Image](../Images/comm1.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../Images/comm1.jpg)'
- en: If you want your application to categorize a text, extract specific phrases
    from it, or determine how semantically similar it is to another text, it must
    be able to “understand” an utterance submitted by a user and generate a meaningful
    response to it.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你希望你的应用程序能够对文本进行分类、提取特定短语或判断它与另一个文本的语义相似度，它必须能够“理解”用户提交的语句，并生成有意义的回应。
- en: 'You’ve already learned some techniques for performing these tasks. This chapter
    discusses two more approaches: using word sequence patterns to classify and generate
    text, and walking the syntactic dependency tree of an utterance to extract necessary
    pieces of information from it. I’ll introduce you to spaCy’s Matcher tool to find
    patterns. I’ll also discuss when you might still need to rely on context to determine
    the proper processing approach.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经学会了一些执行这些任务的技巧。本章讨论了另外两种方法：使用词序模式来分类和生成文本，以及遍历语法依赖树来从中提取必要的信息。我将向你介绍spaCy的Matcher工具，用于查找模式。我还将讨论在何种情况下你可能仍然需要依赖上下文来决定合适的处理方法。
- en: '**Word Sequence Patterns**'
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**词序模式**'
- en: 'A *word sequence pattern* consists of features of words that impose a certain
    requirement on each word in the sequence. For example, the phrase “I can” will
    match the following word sequence pattern: “pronoun + modal auxiliary verb.” By
    searching for word sequence patterns, you can recognize word sequences with similar
    linguistic features, making it possible to categorize input and handle it properly.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*词序模式*由施加特定要求的单词特征组成，要求序列中的每个单词必须满足某些条件。例如，短语“I can”将匹配以下词序模式：“代词 + 情态助动词”。通过搜索词序模式，你可以识别具有相似语言特征的单词序列，从而使输入能够被正确分类和处理。'
- en: For example, when you receive a question that begins with a word sequence that
    uses the pattern “modal auxiliary verb + proper noun,” such as “Can George,” you
    know that this question is about the ability, possibility, permission, or obligation
    of someone or something that the proper noun refers to.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，当你收到一个以使用“情态助动词 + 专有名词”模式开头的问题时，比如“Can George”，你就知道这个问题是关于专有名词所指代的某人或某物的能力、可能性、许可或义务。
- en: In the following sections, you’ll learn to classify sentences by identifying
    common patterns of linguistic features.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，你将学习通过识别常见的语言特征模式来分类句子。
- en: '***Finding Patterns Based on Linguistic Features***'
  id: totrans-9
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***基于语言特征查找模式***'
- en: We need to find patterns in texts because, in most cases, we won’t be able to
    find even two identical sentences within a text. Typically, a text is composed
    of different sentences, each of which contains different words. It would be impractical
    to write the code to process each sentence in a text.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要在文本中查找模式，因为在大多数情况下，我们甚至无法在文本中找到两个完全相同的句子。通常，一篇文本由不同的句子组成，每个句子包含不同的单词。为每个句子编写处理代码是不可行的。
- en: 'Fortunately, some sentences that look completely different might follow the
    same word sequence patterns. For example, consider the following two sentences:
    “We can overtake them.” and “You must specify it.”. These sentences have no words
    in common. But if you look at the syntactic dependency labels assigned to the
    words in the sentences, a pattern emerges, as shown in the following script:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，一些看起来完全不同的句子可能遵循相同的词序模式。例如，考虑以下两个句子：“We can overtake them.” 和 “You must
    specify it.” 这两个句子没有任何相同的单词。但如果你查看这些句子中单词的语法依赖标签，就会出现一个模式，如以下脚本所示：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Because both sentences have the same number of words, we can iterate over the
    words in both sentences within a single loop ➊. If the dependency label is the
    same for the words that have the same index in both sentences ➋, we print these
    words along with the label assigned to them, as well as a description for each
    label ➌.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 因为这两个句子的单词数量相同，我们可以在一个循环中遍历这两个句子中的单词➊。如果在这两个句子中具有相同索引的单词的依赖标签相同➋，我们就打印这些单词及其对应的标签，并提供每个标签的描述➌。
- en: 'The output should look as follows:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应如下所示：
- en: '[PRE1]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'As you can see, the list of dependency labels is identical for both sentences.
    This means that these sentences follow the same word sequence pattern based on
    the following syntactic dependency labels: “subject + auxiliary + verb + direct
    object.”'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，两个句子的依赖标签列表是相同的。这意味着这两个句子基于以下句法依赖标签遵循相同的单词顺序模式：“主语 + 助动词 + 动词 + 直接宾语”。
- en: 'Also notice that the list of part-of-speech tags (coarse-grained and fined-grained)
    is also identical for these sample sentences. If we replace all references to
    `.dep`_ with `.pos`_ in the previous script, we’ll get the following results:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意，这些示例句子的词性标签（粗粒度和细粒度）列表也是相同的。如果我们在前面的脚本中将所有对`.dep`_的引用替换为`.pos`_，我们将得到以下结果：
- en: '[PRE2]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The sample sentences match not only the syntactic dependency label pattern,
    but also the pattern of part-of-speech tags.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这些示例句子不仅匹配句法依赖标签模式，还匹配词性标签的模式。
- en: '***Try This***'
  id: totrans-20
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***尝试这个***'
- en: In the previous example, we created two Doc objects—one for each sample sentence.
    But in practice, a text usually consists of numerous sentences, which makes a
    Doc-per-sentence approach impractical. Rewrite the script so it creates a single
    Doc object. Then use the `doc.sents` property introduced in [Chapter 2](../Text/ch02.xhtml#ch02)
    to operate on each sentence.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，我们创建了两个Doc对象——每个示例句子一个。但在实际应用中，一篇文本通常包含许多句子，这使得逐句创建Doc对象的方法不太实用。重写脚本，使其只创建一个Doc对象。然后使用[第2章](../Text/ch02.xhtml#ch02)中介绍的`doc.sents`属性对每个句子进行操作。
- en: 'But note that `doc.sents` is a generator object, which means it’s not subscriptable—you
    can’t refer to its items by index. To solve this issue, convert the `doc.sents`
    to a list, as follows:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 但请注意，`doc.sents`是一个生成器对象，这意味着它不可通过下标访问——你无法通过索引来引用它的项。为了解决这个问题，将`doc.sents`转换为列表，如下所示：
- en: '[PRE3]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: And, of course, you can iterate over a `doc.sents` in a `for` loop to obtain
    the `sents` in order, as they’re requested by the loop.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，你可以通过`for`循环遍历`doc.sents`，按顺序获取请求的`sents`。
- en: '***Checking an Utterance for a Pattern***'
  id: totrans-25
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***检查语句是否符合模式***'
- en: In the preceding example, we compared two sample sentences to find a pattern
    based on their shared linguistic features. But in practice, we’ll rarely want
    to compare sentences to one another to determine whether they share a common pattern.
    Instead, it’ll be more useful to check a submitted sentence against the pattern
    we’re already interested in.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，我们比较了两个示例句子，以找出它们共享的语言特征模式。但在实际应用中，我们很少需要比较句子之间是否共享共同的模式。相反，检查提交的句子是否符合我们已经感兴趣的模式会更有用。
- en: 'For example, let’s say we were trying to find utterances in user input that
    express one of the following: ability, possibility, permission, or obligation
    (as opposed to utterances that describe real actions that have occurred, are occurring,
    or occur regularly). For instance, we want to find “I can do it.” but not “I’ve
    done it.”'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们要在用户输入的语句中找到表示以下某一项的语句：能力、可能性、许可或义务（与描述已经发生、正在发生或定期发生的实际行动的语句相对）。例如，我们要找到“我能做到”而不是“我做到了”。
- en: 'To distinguish between utterances, we might check whether an utterance satisfies
    the following pattern: “subject + auxiliary + verb + . . . + direct object . .
    .”. The ellipses indicate that the direct object isn’t necessarily located immediately
    behind the verb, making this pattern a little different from the one in the preceding
    example.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 为了区分不同的语句，我们可能需要检查某个语句是否符合以下模式：“主语 + 助动词 + 动词 + …… + 直接宾语 ……”。省略号表示直接宾语不一定位于动词后面，这使得这个模式与前面示例中的模式略有不同。
- en: 'The following sentence satisfies the pattern: “I might send them a card as
    a reminder.”. In this sentence, the noun “card” is a direct object, and the pronoun
    “them” is an indirect object that separates it from the verb “send.” The pattern
    doesn’t specify a position for the direct object in the sentence; it simply requires
    its presence.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 以下句子符合模式：“I might send them a card as a reminder.”。在这个句子中，名词“card”是直接宾语，代词“them”是间接宾语，它将直接宾语与动词“send”分开。这个模式并没有指定直接宾语在句子中的位置，它仅要求直接宾语的存在。
- en: '[Figure 6-1](../Text/ch06.xhtml#ch06fig01) shows a graphical depiction of this
    design:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '[图6-1](../Text/ch06.xhtml#ch06fig01)展示了这个设计的图形化表示：'
- en: '![image](../Images/fig6-1.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![image](../Images/fig6-1.jpg)'
- en: '*Figure 6-1: Checking submitted utterances against a word sequence pattern
    based on linguistic features*'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '*图6-1：根据语言特征检查提交的语句与词序模式的一致性*'
- en: 'In the following script, we define a function that implements this pattern,
    and then test it on a sample sentence:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下脚本中，我们定义了一个实现此模式的函数，然后在一个示例句子上进行测试：
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In this script, we define the `dep_pattern` function that takes a Doc object
    as parameter ➊. In the function, we iterate over the Doc object’s tokens ➋, searching
    for a “subject + auxiliary + verb” pattern ➌. If we find this pattern, we check
    whether the verb has a direct object among its syntactic children ➍. Finally,
    if we find a direct object, the function returns `True` ➎. Otherwise, it returns
    `False` ➏.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个脚本中，我们定义了`dep_pattern`函数，它以Doc对象作为参数 ➊。在函数中，我们遍历Doc对象的标记 ➋，搜索“主语 + 助动词 +
    动词”模式 ➌。如果找到了这个模式，我们检查动词是否在其句法子节点中有一个直接宾语 ➍。最后，如果找到了直接宾语，函数返回`True` ➎。否则，返回`False`
    ➏。
- en: In the main code, we apply the text-processing pipeline to the sample sentence
    ➐ and send the Doc object to the `dep_pattern` function ➑, outputting `Found`
    if the sample satisfies the pattern implemented in the function or `Not found`
    otherwise.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在主代码中，我们将文本处理管道应用于示例句子 ➐，并将Doc对象传递给`dep_pattern`函数 ➑，如果该示例符合函数中实现的模式，则输出`Found`，否则输出`Not
    found`。
- en: 'Because the sample used in this example satisfies the pattern, the script should
    produce the following output:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 因为本示例中使用的示例符合该模式，脚本应该输出以下结果：
- en: '[PRE5]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: You’ll see some examples of using the `dep_pattern` function in some of the
    following sections.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几个部分中，你将看到一些使用`dep_pattern`函数的示例。
- en: '***Using spaCy’s Matcher to Find Word Sequence Patterns***'
  id: totrans-40
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***使用spaCy的Matcher来查找单词序列模式***'
- en: 'In the previous section, you learned how to find a word sequence pattern in
    a doc by iterating over its tokens and checking their linguistic features. In
    fact, spaCy has a predefined feature for this task called *Matcher*, a tool that
    is specially designed to find sequences of tokens based on pattern rules. For
    example, an implementation of the “subject + auxiliary + verb” pattern with Matcher
    might look like this:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，你学会了如何通过遍历文档的标记并检查它们的语言特征来找到单词序列模式。事实上，spaCy为这个任务预定义了一个功能，叫做*Matcher*，它是一个专门设计用来根据模式规则找到标记序列的工具。例如，使用Matcher实现“主语
    + 助动词 + 动词”模式的代码可能如下所示：
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We create a Matcher instance, passing in the vocabulary object shared with the
    documents the Matcher will work on ➊. Then we define a pattern, specifying the
    dependency labels that a word sequence should match ➋. We add the newly created
    pattern to the Matcher ➌.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建一个Matcher实例，将与Matcher将要处理的文档共享的词汇对象传入 ➊。然后我们定义一个模式，指定一个单词序列应该匹配的依赖标签 ➋。我们将新创建的模式添加到Matcher中
    ➌。
- en: Next, we can apply the Matcher to a sample text and obtain the matching tokens
    in a list ➍. Then we iterate over this list ➎, printing out the start and end
    positions of the pattern tokens in the text ➏.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以将Matcher应用于示例文本，并将匹配的标记以列表形式获取 ➍。然后我们遍历这个列表 ➎，打印出模式标记在文本中的起始和结束位置 ➏。
- en: 'The script should produce the following output:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本应该输出以下结果：
- en: '[PRE7]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Matcher allows you to find a pattern in a text without iterating explicitly
    over the text’s tokens, thus hiding implementation details from you. As a result,
    you can obtain the start and end positions of the words composing a sequence that
    satisfies the specified pattern. This approach can be very useful when you’re
    interested in a sequence of words that immediately follow one another.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: Matcher允许你在文本中找到一个模式，而不需要显式地遍历文本的标记，从而将实现细节隐藏在你背后。因此，你可以获得组成符合指定模式的单词序列的起始和结束位置。当你对紧跟在一起的单词序列感兴趣时，这种方法非常有用。
- en: But often you need a pattern that includes words scattered over the sentence.
    For example, you might need to implement such patterns as the “subject + auxiliary
    + verb + . . . + direct object . . .” pattern we used in “[Checking an Utterance
    for a Pattern](../Text/ch06.xhtml#lev73)” on [page 77](../Text/ch06.xhtml#page_77).
    The problem is that you don’t know in advance how many words can occur between
    the “subject + auxiliary + verb” sequence and the direct object. Matcher doesn’t
    allow you to define such patterns. For this reason, I’ll define patterns manually
    for the remainder of this chapter.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 但通常你需要一个包含分散在句子中的单词的模式。例如，你可能需要实现类似于我们在“[检查话语中的模式](../Text/ch06.xhtml#lev73)”中使用的“主语
    + 助动词 + 动词 + ... + 直接宾语 ...”模式。问题是你无法事先知道“主语 + 助动词 + 动词”序列与直接宾语之间可以有多少个单词。Matcher不允许你定义这样的模式。因此，在本章剩余部分，我将手动定义模式。
- en: '***Applying Several Patterns***'
  id: totrans-49
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***应用多个模式***'
- en: 'You can apply several matching patterns to an utterance to make sure it satisfies
    all your conditions. For example, you might check an utterance against two patterns:
    one that implements a dependency label sequence (as discussed in “[Checking an
    Utterance for a Pattern](../Text/ch06.xhtml#lev73)” on [page 77](../Text/ch06.xhtml#page_77))
    and one that checks against a sequence of part-of-speech tags. This might be helpful,
    if, say, you want to make sure that the direct object in an utterance is a personal
    pronoun. If so, you can start the procedure of determining the noun that gives
    its meaning to the pronoun and is mentioned elsewhere in the discourse.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将多个匹配模式应用于一个话语，以确保它满足所有条件。例如，你可能会将一个话语与两个模式进行比较：一个实现依赖标签序列（如在“[检查话语模式](../Text/ch06.xhtml#lev73)”中讨论的[第77页](../Text/ch06.xhtml#page_77)），另一个则检查词性标签的顺序。如果你想确保话语中的直接宾语是人称代词，这将非常有用。若是这样，你可以开始确定赋予代词意义的名词，并且该名词在对话中有其他提及。
- en: Diagrammatically, this design might look like [Figure 6-2](../Text/ch06.xhtml#ch06fig02).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 从图示上来看，这个设计可能像[图6-2](../Text/ch06.xhtml#ch06fig02)一样。
- en: '![image](../Images/fig6-2.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![image](../Images/fig6-2.jpg)'
- en: '*Figure 6-2: Applying several matching patterns to user input*'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 6-2：将多个匹配模式应用于用户输入*'
- en: 'In addition to using the dependency label sequence defined in “[Checking an
    Utterance for a Pattern](../Text/ch06.xhtml#lev73)”, you can define a new function
    by implementing a pattern based on part-of-speech tags. The part-of-speech tag
    pattern might search the sentence to make sure that the subject and the direct
    object are personal pronouns. This new function might implement the following
    pattern: “personal pronoun + modal auxiliary verb + base form verb + . . . + personal
    pronoun . . .”.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 除了使用在“[检查话语模式](../Text/ch06.xhtml#lev73)”中定义的依赖标签序列外，你还可以通过实现基于词性标签的模式来定义一个新函数。词性标签模式可能会搜索句子，以确保主语和直接宾语是人称代词。这个新函数可能会实现以下模式：“人称代词
    + 情态助动词 + 基本形式动词 + . . . + 人称代词 . . .”。
- en: 'Here is the code:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这是代码：
- en: '[PRE8]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We start by adding the code for the `dep_pattern` function defined in a previous
    script. To create the second pattern, we define the `pos_pattern` function ➊,
    which contains a `for` loop with a series of `if` statements in it ➋. Each `if`
    statement checks whether a certain part of a sentence matches a certain part-of-speech
    tag. When the function detects a mismatch, it returns `False`. Otherwise, after
    all the checks have occurred and no mismatch has been detected, the function returns
    `True` ➌.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先添加之前脚本中定义的`dep_pattern`函数的代码。为了创建第二个模式，我们定义`pos_pattern`函数 ➊，该函数包含一个带有多个`if`语句的`for`循环
    ➋。每个`if`语句检查句子的某个部分是否匹配某个词性标签。当函数检测到不匹配时，它返回`False`。否则，在所有检查完成且未发现不匹配的情况下，函数返回`True`
    ➌。
- en: 'To test the patterns, we apply the pipeline to a sentence, and then check whether
    the sentence matches both patterns ➍. Because the sample used in this example
    matches both patterns, we should see the following output:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试这些模式，我们将管道应用于一个句子，然后检查该句子是否匹配这两个模式 ➍。因为示例中使用的句子匹配了这两个模式，所以我们应该看到以下输出：
- en: '[PRE9]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'But if we replace the sample sentence with this one: “I might send them a card
    as a reminder.”, we should see this output:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，如果我们用这个句子替换示例句子：“I might send them a card as a reminder.”，我们应该看到以下输出：
- en: '[PRE10]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The reason is that the sentence doesn’t match the part-of-speech tag pattern,
    because the direct object “card” isn’t a personal pronoun, even though the sentence
    fully satisfies the conditions of the first pattern.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 原因在于该句子不匹配词性标签模式，因为直接宾语“card”不是人称代词，即使该句子完全满足第一个模式的条件。
- en: '***Creating Patterns Based on Customized Features***'
  id: totrans-63
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***基于定制特征创建模式***'
- en: When creating a word sequence pattern, you might need to enhance the functionality
    of the linguistic features spaCy provides by customizing them for your needs.
    For example, you might want the preceding script to recognize another pattern
    that distinguishes pronouns according to number (whether they’re singular or plural).
    Once again, this could be useful when you need to find the noun in a previous
    utterance to which the pronoun refers.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建词序列模式时，你可能需要通过定制spaCy提供的语言特征来增强其功能，以满足你的需求。例如，你可能希望前面的脚本识别另一个模式，通过数目来区分代词（无论是单数还是复数）。如果你需要查找代词所指的前一句中的名词时，这将非常有用。
- en: 'Although spaCy separates nouns by number, it doesn’t do this for pronouns.
    But the ability to recognize whether a pronoun is plural or singular can be very
    useful in the task of meaning recognition or information extraction. For example,
    consider the following discourse:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管spaCy按数量区分名词，但它并不对代词做这样的区分。然而，识别代词是单数还是复数的能力在意义识别或信息提取的任务中非常有用。例如，考虑以下对话：
- en: '[PRE11]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: If we can establish that the direct object “them” in the second sentence is
    a plural pronoun, we’ll have reason to believe that it refers to the plural noun
    “trucks” in the first sentence. We often use this technique to recognize a pronoun’s
    meaning based on the context.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们能确认第二个句子中的直接宾语“them”是一个复数代词，那么我们就有理由相信它指的是第一个句子中的复数名词“trucks”。我们经常使用这种技术根据上下文来识别代词的含义。
- en: The following script defines a `pron_pattern` function, which finds any direct
    object in the submitted sentence, determines whether that direct object is a personal
    pronoun, and then determines whether the pronoun is singular or plural. The script
    then applies the function to a sample sentence after testing for the two patterns
    defined in “[Checking an Utterance for a Pattern](../Text/ch06.xhtml#lev73)” on
    [page 77](../Text/ch06.xhtml#page_77) and “[Applying Several Patterns](../Text/ch06.xhtml#lev75)”
    on [page 80](../Text/ch06.xhtml#page_80).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 以下脚本定义了一个`pron_pattern`函数，用于找到提交句子中的任何直接宾语，确定该直接宾语是否为个人代词，然后判断该代词是单数还是复数。脚本在测试了“[检查语句模式](../Text/ch06.xhtml#lev73)”第77页和“[应用多个模式](../Text/ch06.xhtml#lev75)”第80页中定义的两个模式之后，应用该函数到示例句子中。
- en: '[PRE12]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We start by adding the `dep_pattern` and `pos_pattern` functions defined in
    “[Checking an Utterance for a Pattern](../Text/ch06.xhtml#lev73)” and “[Applying
    Several Patterns](../Text/ch06.xhtml#lev75)” to the script. In the `pron_pattern`
    function ➊, we define a Python list that includes all the possible plural personal
    pronouns ➋. Next, we define a loop that iterates over the tokens in the submitted
    sentence, looking for a direct object that is a personal pronoun ➌. If we find
    such a token, we check whether it’s in the list of plural personal pronouns ➍.
    If so, the function returns `plural` ➎. Otherwise, it returns `singular` ➏. If
    the function either failed to detect a direct object or found one that isn’t a
    personal pronoun, it returns `Not found` ➐.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先通过在脚本中添加在“[检查语句模式](../Text/ch06.xhtml#lev73)”和“[应用多个模式](../Text/ch06.xhtml#lev75)”中定义的`dep_pattern`和`pos_pattern`函数来开始。在`pron_pattern`函数
    ➊中，我们定义了一个包含所有可能的复数个人代词的Python列表 ➋。接下来，我们定义一个循环，遍历提交句子中的标记，查找作为直接宾语的个人代词 ➌。如果找到这样的标记，我们会检查它是否在复数个人代词的列表中
    ➍。如果是，函数返回`plural` ➎。否则，它返回`singular` ➏。如果函数未能检测到直接宾语，或者找到的代词不是个人代词，它将返回`Not found`
    ➐。
- en: 'For the sentence “We can overtake them.”, we should get the following output:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 对于句子“We can overtake them.”，我们应该得到以下输出：
- en: '[PRE13]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We could use this information to find a corresponding noun for the pronoun in
    the previous sentence.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以利用这些信息找到前一句中代词对应的名词。
- en: '***Choosing Which Patterns to Apply***'
  id: totrans-74
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***选择应用哪些模式***'
- en: Once you define these patterns, you can choose which ones to apply for each
    situation. Notice that even if a sentence fails to fully satisfy the `dep_pattern`
    and `pos_pattern` functions, it might still match the `pron_pattern` function.
    For example, the sentence “I know it.” doesn’t match either the `dep_pattern`
    or `pos_pattern` functions, because it doesn’t have a modal auxiliary verb. But
    it satisfies `pron_pattern` because it contains a personal pronoun that is the
    direct object of the sentence.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦定义了这些模式，你就可以根据不同情况选择应用哪些模式。请注意，即使一个句子未完全满足`dep_pattern`和`pos_pattern`函数，它仍然可能匹配`pron_pattern`函数。例如，句子“I
    know it.”不符合`dep_pattern`或`pos_pattern`函数，因为它没有情态助动词。但它满足`pron_pattern`，因为它包含一个作为直接宾语的个人代词。
- en: 'This loose coupling between the patterns lets you use them with other patterns
    or independently. For example, you might use `dep_pattern`, which checks a sentence
    against the “subject + auxiliary + verb + . . . + direct object . . .” pattern
    in conjunction with, say, a “noun + modal auxiliary verb + base form verb + .
    . . + noun . . .” pattern, if you wanted to be sure that the subject and the direct
    object in the sentence are nouns. These two patterns would match the following
    example:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模式之间的松散耦合使你可以将它们与其他模式一起使用或独立使用。例如，如果你想确保句子的主语和直接宾语都是名词，你可以将`dep_pattern`（检查句子是否符合“主语
    + 助动词 + 动词 + ... + 直接宾语...”模式）与“名词 + 情态助动词 + 基本形式动词 + ... + 名词...”模式结合使用。这两个模式将匹配以下示例：
- en: '[PRE14]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: As you might guess, the ability to combine patterns in different ways allows
    you to handle more scenarios with less code.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所猜测的那样，不同方式组合模式的能力使你可以用更少的代码处理更多的场景。
- en: '***Using Word Sequence Patterns in Chatbots to Generate Statements***'
  id: totrans-79
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***在聊天机器人中使用词序列模式生成陈述***'
- en: As stated earlier, the most challenging tasks in NLP are understanding and generating
    natural language text. A chatbot must understand a user’s input and then generate
    a proper response to it. Word sequence patterns based on linguistic features can
    help you implement these functions.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，NLP中最具挑战性的任务是理解和生成自然语言文本。聊天机器人必须理解用户的输入，然后生成适当的响应。基于语言学特征的词序列模式可以帮助你实现这些功能。
- en: In [Chapter 4](../Text/ch04.xhtml#ch04), you learned how to turn a statement
    into a relevant question to continue a conversation with a user. Using word sequence
    patterns, you could generate other kinds of responses, too, such as relevant statements.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第4章](../Text/ch04.xhtml#ch04)中，你学会了如何将陈述转化为相关问题，以继续与用户的对话。通过使用词序列模式，你还可以生成其他类型的响应，例如相关的陈述。
- en: 'Suppose your chatbot has received the following user input:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你的聊天机器人收到了以下用户输入：
- en: '[PRE15]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The chatbot might react as follows:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 聊天机器人可能会做出如下反应：
- en: '[PRE16]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'You can use the patterns implemented in the previous sections to accomplish
    this text generation task. The list of steps might look like this:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用前面章节中实现的模式来完成这个文本生成任务。步骤列表可能如下所示：
- en: Check the conversational input against the `dep_pattern` and `pos_pattern` functions
    defined previously to find an utterance that follows the “subject + auxiliary
    + verb + . . . + direct object . . .” and “pronoun + modal auxiliary verb + base
    form verb + . . . + pronoun . . .” patterns, respectively.
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将对话输入与之前定义的`dep_pattern`和`pos_pattern`函数进行匹配，分别找到符合“主语 + 助动词 + 动词 + ... + 直接宾语...”和“代词
    + 情态助动词 + 基本形式动词 + ... + 代词...”模式的陈述。
- en: Check the utterance found in step 1 against the `pron_pattern` pattern to determine
    whether the direct object personal pronoun is plural or singular.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查步骤1中找到的陈述是否与`pron_pattern`模式匹配，以确定直接宾语的人称代词是复数还是单数。
- en: Find the noun that gives its meaning to the pronoun by searching for a noun
    that has the same number as the personal pronoun.
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过搜索与人称代词相同数量的名词，找到给人称代词赋予意义的名词。
- en: Replace the pronoun that acts as the direct object in the sentence located in
    step 1 with the noun found in step 3.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将步骤1中句子中作为直接宾语的人称代词替换为步骤3中找到的名词。
- en: Append the word “too” to the end of the generated utterance.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在生成的陈述末尾添加单词“too”。
- en: 'The following script implements these steps. It uses the `dep_pattern`, `pos_pattern`,
    and `pron_pattern` functions defined earlier in this chapter (their code is omitted
    to save space). It also introduces two new functions: `find_noun` and `gen_utterance`.
    For convenience, we’ll walk through the code in three steps: the initial operations
    and the `find_noun` function, which finds the noun that matches the personal pronoun;
    the `gen_utterance` function, which generates a relevant statement from that question;
    and finally, the code that tests an utterance. Here is the first part:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 以下脚本实现了这些步骤。它使用了本章前面定义的`dep_pattern`、`pos_pattern`和`pron_pattern`函数（为了节省空间，省略了它们的代码）。它还引入了两个新函数：`find_noun`和`gen_utterance`。为了方便起见，我们将分三个步骤来讲解代码：初步操作和`find_noun`函数，它用于查找与人称代词匹配的名词；`gen_utterance`函数，它根据该问题生成相关陈述；最后是测试陈述的代码。以下是第一部分：
- en: '[PRE17]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: After inserting the code of the `dep_pattern`, `pos_pattern`, and `pron_pattern`
    functions, we define the `find_noun` function, which takes two parameters ➊. The
    first one contains a list of the sentences from the beginning of the discourse
    up to the sentence that satisfies all the patterns here. In this example, this
    list will include all the sentences from the discourse, because only the last
    sentence satisfies all the patterns ➋. But the noun that gives its meaning to
    the pronoun can be found in one of the previous sentences.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在插入`dep_pattern`、`pos_pattern`和`pron_pattern`函数的代码后，我们定义了`find_noun`函数，该函数接受两个参数
    ➊。第一个参数包含从话语开始到满足所有模式的句子的句子列表。在这个示例中，这个列表将包括话语中的所有句子，因为只有最后一句话满足所有模式 ➋。但是，给代词赋予意义的名词可以在之前的句子中找到。
- en: The second parameter sent to `find_noun` is the number of the direct object
    pronoun in the sentence that satisfies all the patterns ➌. The `pron_pattern`
    function determines this. If the value of this argument is `'plural'`, we define
    a Python list containing fine-grained part-of-speech tags used in spaCy to mark
    plural nouns ➍. If it’s `'singular'`, we create a tag list containing fine-grained
    part-of-speech tags used to mark singular nouns ➎.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 传递给`find_noun`的第二个参数是满足所有模式的句子中直接宾语代词的位置 ➌。`pron_pattern`函数确定了这一点。如果该参数的值为`'plural'`，我们定义一个包含用于标记复数名词的细粒度词性标签的Python列表
    ➍。如果是`'singular'`，我们创建一个标签列表，包含用于标记单数名词的细粒度词性标签 ➎。
- en: In a `for` loop, we iterate over the sentences in reverse order, starting from
    the sentence that is the closest to the sentence containing the pronoun to be
    replaced ➏. We start with the closest sentence, because the noun we’re searching
    for will most likely be there. Here, we use Python’s reversed function that returns
    a reverse iterator over the list. In the inner loop, we iterate over the tokens
    in each sentence ➐, looking for a token whose fine-grained part-of-speech tag
    is in the tag list defined earlier ➑.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在`for`循环中，我们按逆序遍历句子，从包含要替换的代词的句子开始 ➏。我们从最接近的句子开始，因为我们要找的名词很可能就在这里。在这里，我们使用Python的reversed函数，它返回一个列表的反向迭代器。在内层循环中，我们遍历每个句子中的标记
    ➐，寻找其细粒度词性标签是否在之前定义的标签列表中 ➑。
- en: 'Then we define the `gen_utterance` function, which generates our new statement:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们定义了`gen_utterance`函数，它生成我们的新语句：
- en: '[PRE18]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We use a `for` loop to iterate over the tokens in the sentence ➊, looking for
    a direct object that is a personal pronoun ➋. Once we’ve found one, we generate
    a new utterance. We change the original sentence by replacing the personal pronoun
    with the matching noun and appending “too” to the end of it ➌. The function then
    returns this newly generated utterance ➍. If we haven’t found a direct object
    in the form of a personal pronoun, the function returns an error message ➎.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`for`循环遍历句子 ➊ 中的标记，寻找直接宾语为人称代词 ➋。找到后，我们生成一个新的表达式。我们通过将人称代词替换为匹配的名词，并在其末尾加上“too”来修改原句
    ➌。然后，函数返回这个新生成的表达式 ➍。如果没有找到以人称代词形式出现的直接宾语，函数会返回一个错误信息 ➎。
- en: 'Now that we have all the functions in place, we can test them on a sample utterance
    using the following code:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好了所有函数，我们可以使用以下代码对示例表达式进行测试：
- en: '[PRE19]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: After applying the pipeline to the sample discourse ➊, we convert it to the
    list of sentences ➋. Then we iterate over this list ➌, searching for the sentence
    that matches the patterns defined in the `dep_pattern` and `pos_pattern` functions.
    Next, we determine the noun that gives the meaning to the pronoun in the sentence
    found in the previous step, using the `find_noun` function ➍. Finally, we call
    the `get_utterance` function to generate a response utterance ➎.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在将管道应用于示例话语 ➊ 后，我们将其转换为句子列表 ➋。然后我们遍历这个列表 ➌，寻找符合`dep_pattern`和`pos_pattern`函数定义的模式的句子。接着，我们使用`find_noun`函数确定在上一步找到的句子中赋予代词意义的名词
    ➍。最后，我们调用`get_utterance`函数生成响应表达式 ➎。
- en: 'The output of the preceding code should look like this:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码输出应该是这样的：
- en: '[PRE20]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '***Try This***'
  id: totrans-105
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***试试这个***'
- en: Notice that there’s still room for improvement in the preceding code, because
    the original statement included the article “the” in front of the noun “symbols.”
    A better output would include the same article in front of the noun. To generate
    a statement that makes the most sense in this context, expand on the script so
    that it inserts the article “the” in front of the noun, making it “I can recognize
    the symbols too.” For that, you’ll need to check whether the noun is preceded
    by an article, and then add that article.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，前面的代码仍然有改进的空间，因为原始语句在名词“symbols”前面包含了冠词“the”。更好的输出应该在名词前加上相同的冠词。为了生成在此上下文中最有意义的语句，需要扩展脚本，使其在名词前插入冠词“the”，使其变成“我也能识别这些符号”。为此，你需要检查名词前面是否有冠词，然后将该冠词添加进去。
- en: '**Extracting Keywords from Syntactic Dependency Trees**'
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**从句法依赖树中提取关键词**'
- en: Finding a sequence of words in an utterance that satisfies a certain pattern
    allows you to construct a grammatically correct response—either a statement or
    a question, based on the submitted text. But these patterns aren’t always useful
    for extracting the meaning of texts.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在话语中找到符合特定模式的单词序列，可以帮助你构建一个语法正确的回应——无论是陈述句还是疑问句，都基于提交的文本。但是，这些模式并不总是有助于提取文本的含义。
- en: 'For example, in the ticket-booking application in [Chapter 2](../Text/ch02.xhtml#ch02),
    a user might submit a sentence like this:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在[第2章](../Text/ch02.xhtml#ch02)的票务预订应用中，用户可能会提交如下句子：
- en: '[PRE21]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: You could easily find the user’s intended destination by searching for the pattern
    “to + `GPE`” where `GPE` is a named entity for countries, cities, and states.
    This pattern would match phrases like “to London,” “to California,” and so on.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过搜索模式“to + `GPE`”轻松找到用户的目的地，其中`GPE`是指国家、城市和州的命名实体。这个模式可以匹配像“to London”（去伦敦）、“to
    California”（去加利福尼亚）这样的短语。
- en: 'But suppose the user submitted one of the following utterances instead:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 但是假设用户提交了以下其中一句话：
- en: '[PRE22]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'As you can see, the “to + `GPE`” pattern wouldn’t find the destination in either
    example. In both cases, “to” directly refers to “the conference,” not to Berlin.
    You’d need something like “to + . . . + `GPE`” instead. But how would you know
    what’s required—or what’s allowed—between “to” and “`GPE`”? For example, the following
    sentence contains the “to + . . . + `GPE`” pattern but has nothing to do with
    booking a ticket to Berlin:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，“to + `GPE`”模式在这两个例子中都无法找到目的地。在这两个例子中，“to”直接指向的是“the conference”，而不是柏林。你需要使用类似“to
    + . . . + `GPE`”的模式。那么，如何知道在“to”和“`GPE`”之间需要或者允许插入什么呢？例如，下面的句子包含了“to + . . . +
    `GPE`”模式，但与预订前往柏林的机票无关：
- en: '[PRE23]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Often, you need to examine relations between the words in a sentence to obtain
    necessary pieces of information. This is where walking the dependency tree of
    the sentence could help a lot.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，你需要检查句子中单词之间的关系，以获得必要的信息。这就是走访句子的依赖树能提供巨大帮助的地方。
- en: Walking a dependency tree means navigating through it in custom order—not necessarily
    from the first token to the last one. For example, you can stop iterating a dependency
    tree just after the required component is found. Remember that a sentence’s dependency
    tree shows the syntactic relationships between pairs of words. We often represent
    these as arrows connecting the head with the child of a relation. Every word in
    a sentence is involved in at least one of the relations. This guarantees that
    you’ll pass through each word in a sentence when walking through the entire dependency
    tree generated for that sentence if you start from `ROOT`.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 走访依赖树意味着以自定义顺序进行遍历——不一定从第一个标记遍历到最后一个标记。例如，你可以在找到所需组件后立即停止遍历依赖树。记住，句子的依赖树显示了单词对之间的句法关系。我们通常将这些关系表示为箭头，连接一个关系的头词和子词。句子中的每个单词都涉及至少一个关系。这保证了如果从`ROOT`开始遍历整个句子的依赖树，你会通过句子中的每个单词。
- en: In this section, we’ll examine a sentence’s structure to figure out a user’s
    intended meaning.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将通过分析句子的结构来搞清楚用户的意图。
- en: '***Walking a Dependency Tree for Information Extraction***'
  id: totrans-119
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***走访依赖树进行信息提取***'
- en: Let’s return to the ticket-booking application example. To find a user’s intended
    destination, you might need to iterate over the dependency tree of a sentence
    to determine whether “to” is semantically related to “Berlin.” This is easy to
    accomplish if you remember the head/child syntactic relations that compose a dependency
    tree, which was introduced in the “Head and Child” box on [page 25](../Text/ch02.xhtml#page_25).
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到票务预订应用的例子。为了找到用户的预期目的地，你可能需要遍历句子的依赖树，判断“to”是否与“Berlin”在语义上相关。如果你记住组成依赖树的头/子句关系（在[第25页](../Text/ch02.xhtml#page_25)的“头和子句”框中介绍），这将很容易实现。
- en: '[Figure 6-3](../Text/ch06.xhtml#ch06fig03) shows the dependency tree for the
    sentence, “I am going to the conference in Berlin”:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '[图6-3](../Text/ch06.xhtml#ch06fig03)展示了句子“我去柏林参加会议”的依赖树：'
- en: '![image](../Images/fig6-3.jpg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![image](../Images/fig6-3.jpg)'
- en: '*Figure 6-3: A syntactic dependency tree of an utterance*'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '*图6-3：一个话语的句法依赖树*'
- en: The verb “going” is the root of the sentence, meaning it’s not a child of any
    other word. Its child to the immediate right is “to.” If you walk through the
    dependency tree, moving to the child to the immediate right of each word, you’ll
    finally reach “Berlin.” This shows that there’s a semantic connection between
    “to” and “Berlin” in this sentence.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 动词“going”是句子的根，它不是任何其他单词的子节点。它右边的直接子节点是“to”。如果你沿着依赖树遍历，每次移动到当前单词的右子节点，最终你会到达“Berlin”。这表明句子中“to”和“Berlin”之间存在语义联系。
- en: '***Iterating over the Heads of Tokens***'
  id: totrans-125
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***遍历标记的头***'
- en: Now let’s figure out how to express the relation between “to” and “Berlin” in
    the sentence programmatically. One way is to walk the dependency tree from left
    to right, starting from “to,” choosing only the immediate right child of each
    word along the way. If you can go from “to” to “Berlin” this way, you can reasonably
    assume that there’s a semantic connection between the two words.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来分析如何以编程方式表示句子中“to”和“Berlin”之间的关系。一个方法是从左到右遍历依赖树，从“to”开始，每次选择当前单词的直接右子节点。如果你能通过这种方式从“to”到达“Berlin”，那么可以合理地假设这两个词之间存在语义联系。
- en: 'But this approach has a drawback. In some cases, a word might have more than
    one right child. For example, in the sentence “I am going to the conference on
    spaCy, which will be held in Berlin,” the word “conference” has two immediate
    right children: the words “on” and “held.” This forces you to check multiple branches,
    complicating the code.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 但这种方法有一个缺点。在某些情况下，一个单词可能有多个右子节点。例如，在句子“我去参加在柏林举行的spaCy会议”中，单词“conference”有两个直接的右子节点：单词“on”和“held”。这就要求你检查多个分支，增加了代码的复杂性。
- en: 'On the other hand, although a head can have multiple children, each word in
    a sentence has exactly one head. This means you can instead move from right to
    left, starting from “Berlin” and trying to reach “to.” The following script implements
    this process in the `det_destination` function:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，尽管一个头可以有多个子节点，但句子中的每个单词都有且只有一个头。这意味着你也可以从右到左移动，从“Berlin”开始，试图到达“to”。以下脚本在`det_destination`函数中实现了这一过程：
- en: '[PRE24]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: In the `det_destination` function ➊, we iterate over the tokens in the submitted
    utterance, looking for a `GPE` entity ➋. If it’s found, we start a `while` loop
    ➌ that iterates over the head of each token, starting from the token containing
    the `GPE` entity ➍. The loop stops when it reaches either the token containing
    “to” ➎ or the root of the sentence. We can check for the root by comparing a token
    to its head ➏, because the head of the root token always refers to itself. (Alternatively,
    we can check for the `ROOT` tag.)
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在`det_destination`函数 ➊中，我们遍历提交的句子中的所有标记，寻找`GPE`实体 ➋。如果找到了，我们启动一个`while`循环 ➌，遍历每个标记的头，起始位置是包含`GPE`实体的标记
    ➍。当循环到达包含“to”的标记 ➎或句子的根节点时，停止。我们可以通过比较标记与其头来检查是否达到了根节点 ➏，因为根标记的头总是指向它自身。（或者，也可以检查`ROOT`标签。）
- en: To test this function, we apply the pipeline to the sample sentence and then
    invoke the `det_destination` function on it ➐.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试这个功能，我们将管道应用到示例句子上，然后调用`det_destination`函数进行处理 ➐。
- en: 'The script should generate the following output:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本应生成以下输出：
- en: '[PRE25]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'If we change the sample sentence so it doesn’t contain “to” or a `GPE` named
    entity, we should get the following output:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们修改示例句子，使其不包含“to”或`GPE`命名实体，应该会得到如下输出：
- en: '[PRE26]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: We can improve the script so it uses another message for cases when it fails
    to determine the user’s destination.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以改进脚本，使其在无法确定用户目的地的情况下使用另一条消息。
- en: '***Condensing a Text Using Dependency Trees***'
  id: totrans-137
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***使用依存树压缩文本***'
- en: The syntactic dependency tree approach isn’t limited to chatbots, of course.
    You could use it, for example, in report-processing applications. Say, you need
    to develop an application that has to condense retail reports by extracting only
    the most important information from them.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 依存句法树方法不仅限于聊天机器人。你可以在例如报告处理应用中使用它。假设你需要开发一个应用程序，必须通过提取报告中最重要的信息来压缩零售报告。
- en: For example, you might want to select the sentences containing numbers, producing
    a concise summary of the data on sales volume, revenue, and costs. (You learned
    how to extract numbers in [Chapter 4](../Text/ch04.xhtml#ch04).) Then, to make
    your new report more concise, you might shorten the selected sentences.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，你可能想选择包含数字的句子，生成一个关于销售量、收入和成本的简洁数据总结。（你已经在[第4章](../Text/ch04.xhtml#ch04)中学会了如何提取数字。）然后，为了使你的新报告更简洁，你可能会缩短选中的句子。
- en: 'As a quick example, consider the following sentence:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个快速示例，考虑下面的句子：
- en: '[PRE27]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'After processing, it should look like this:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 处理后，它应该看起来像这样：
- en: '[PRE28]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'To accomplish this, you can analyze the dependency trees of sentences by following
    these steps:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 要完成这一任务，你可以通过以下步骤分析句子的依存树：
- en: Extract the entire phrase containing the number (it’s 18.6 in this example)
    by walking the heads of tokens, starting from the token containing the number
    and moving from left to right.
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过从包含数字的标记开始，沿着标记的头部从左到右遍历，提取包含该数字的整个短语（在这个例子中是18.6）。
- en: Walk the dependency tree from the main word of the extracted phrase (the one
    whose head is out of the phrase) to the main verb of the sentence, iterating over
    the heads and picking them up to be used in a new sentence.
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从提取短语的主词（其头部不在短语中）开始，沿着依存树遍历到句子的主要动词，遍历头部并将其收集，用于形成新的句子。
- en: Pick up the main verb’s subject, along with its leftward children, which typically
    include a determiner and possibly some other modifiers.
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取主要动词的主语，并与其左侧的子节点一起处理，这些通常包括限定词以及可能的一些修饰语。
- en: '[Figure 6-4](../Text/ch06.xhtml#ch06fig04) represents this process.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '[图6-4](../Text/ch06.xhtml#ch06fig04)表示这一过程。'
- en: '![image](../Images/fig6-4.jpg)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![image](../Images/fig6-4.jpg)'
- en: '*Figure 6-4: An example of condensing a sentence to include only important
    elements*'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '*图6-4：一个将句子压缩到仅包含重要元素的示例*'
- en: 'Let’s start with the first step, which in this example should extract the phrase
    “18.6 million units sold.”. The following code snippet illustrates how to do this
    programmatically:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从第一步开始，在这个例子中应该提取短语“18.6百万单位销售”。以下代码片段展示了如何以编程方式实现这一过程：
- en: '[PRE29]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: We iterate over the sentence’s tokens, looking for one that represents a number
    ➊. If we find one, we start a `while` loop that iterates over right-hand heads
    ➋, starting from the number token and then appending the text of each head to
    the `phrase` variable to form a new phrase. To make sure the head of the next
    token is to the right of that token, we check whether the token is in the list
    of its head’s left children ➌. Once this condition returns false, we break from
    the `while` loop ➍ and then from the outer `for` loop ➎.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我们遍历句子的标记，寻找表示数字的标记 ➊。如果找到了，我们开始一个`while`循环，遍历右侧的头部 ➋，从数字标记开始，并将每个头部的文本附加到`phrase`变量中，形成一个新短语。为了确保下一个标记的头部在该标记的右侧，我们检查该标记是否在其头部的左子节点列表中
    ➌。一旦这个条件返回假，我们跳出`while`循环 ➍，然后跳出外部`for`循环 ➎。
- en: 'Next, we walk the heads of tokens, starting from the main word of the phrase
    containing the number (“sold” in this example) until we reach the main verb of
    the sentence (“hit” in this example), excluding the adposition (“with” in this
    example). We can implement this as shown in the following listing:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们从包含数字的短语的主词（在这个例子中是“sold”）开始，沿着标记的头部遍历，直到到达句子的主要动词（在这个例子中是“hit”），排除介词（在这个例子中是“with”）。我们可以按照下面的代码实现这一过程：
- en: '[PRE30]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: We walk the heads of tokens ➊ in a `while` loop, appending the text of each
    head to the phrase being formed ➋. After reaching the main verb (marked as `ROOT`)
    ➌, we break from the loop ➍.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在`while`循环中遍历标记的头部 ➊，将每个头部的文本附加到正在形成的短语 ➋。在到达主要动词（标记为`ROOT`） ➌后，我们跳出循环 ➍。
- en: 'Finally, we pick up the subject of the sentence, along with its left children:
    “The” and “product.” In this example, the subject is “sales,” so we pick up the
    following noun chunk: “The product sales.” This can be done with the following
    code:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们提取句子的主语及其左侧的词：“The”和“product”。在这个例子中，主语是“sales”，所以我们提取出以下名词短语：“The product
    sales”。可以使用以下代码来完成这一操作：
- en: '[PRE31]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: We start by iterating over the main verb’s children ➊, searching for the subject
    ➋. Then we prepend the subject’s children and the subject of the phrase ➌. To
    see the resulting phrase, we print it ➍.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先迭代主要动词的子节点 ➊，寻找主语 ➋。然后，我们将主语的子节点和短语的主语加到前面 ➌。要查看结果短语，我们打印出来 ➍。
- en: 'The output should look like this:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应该如下所示：
- en: '[PRE32]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The result is a condensed version of the original sentence.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是原始句子的压缩版本。
- en: '***Try This***'
  id: totrans-163
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***试试这个***'
- en: 'Write a script that condenses financial reports by extracting only those sentences
    that contain phrases referring to an amount of money. Also, the script needs to
    condense the selected sentences so they include only the subject, the main verb,
    the phrase referring to an amount of money, and the tokens you can pick up when
    walking the heads starting from the main word of the money phrase up to the main
    verb of the sentence. For example, given the following sentence:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 编写一个脚本，通过提取仅包含金额相关短语的句子来压缩财务报告。此外，脚本需要将选定的句子进行压缩，使其仅包含主语、主要动词、金额相关短语，以及从金额短语的主词到句子的主要动词之间的所有词汇。例如，给定以下句子：
- en: '[PRE33]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Your script should return this sentence:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 你的脚本应该返回以下句子：
- en: '[PRE34]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: In this example, “million” is the main word in the phrase “$4.26 million.” The
    head of “million” is “of,” which is a child of “revenue,” which, in turn, is a
    child of “earned,” the main verb of the sentence.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，“million”是短语“$4.26 million”中的关键词。 “million”的主词是“of”，它是“revenue”的子词，而“revenue”又是“earned”（句子的主要动词）的子词。
- en: '**Using Context to Improve the Ticket-Booking Chatbot**'
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**利用上下文提升购票聊天机器人功能**'
- en: As you’ve no doubt realized by now, there’s no single solution for all intelligent
    text-processing tasks. For example, the ticket-booking script shown earlier in
    this chapter will only find a destination if the submitted sentence contains the
    word “to.”
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你现在毫无疑问已经意识到的那样，没有一种适用于所有智能文本处理任务的单一解决方案。例如，本章前面展示的购票脚本，只有在提交的句子包含“to”时才会找到目的地。
- en: 'One way to make these scripts more useful is to take context into account to
    determine an appropriate response. Let’s increase the functionality of the ticket-booking
    script so it can handle a wider set of user input, including utterances that don’t
    contain a “to + `GPE`” pair in any combination. For example, look at the following
    utterance:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 使这些脚本更有用的一种方法是考虑上下文来确定适当的响应。让我们增强购票脚本的功能，使其能够处理更广泛的用户输入，包括不包含“to + `GPE`”组合的表达。例如，看看以下的表达：
- en: '[PRE35]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Here, the user has expressed an intention to go to Berlin without “to.” Only
    the `GPE` entity “Berlin” is in the sentence. In such cases, it would be reasonable
    for a chatbot to ask a confirmatory question, such as the following:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，用户表达了前往柏林的意图，但没有使用“to”。句子中仅包含`GPE`实体“Berlin”。在这种情况下，聊天机器人提出确认性问题是合理的，例如：
- en: '[PRE36]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The improved ticket-booking chatbot should produce different outputs based
    on three different situations:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 改进后的购票聊天机器人应该根据三种不同的情况生成不同的输出：
- en: The user expresses a clear intention to book a ticket to a certain destination.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户明确表示有意购买前往某个目的地的机票。
- en: It’s not immediately clear whether the user wants a ticket to the destination
    mentioned.
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户是否想要前往提到的目的地，目前还不清楚。
- en: The user doesn’t mention any destination.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户没有提到任何目的地。
- en: Depending on which category the user input falls under, the chatbot generates
    an appropriate response. [Figure 6-5](../Text/ch06.xhtml#ch06fig05) illustrates
    how to represent this user input handling on a diagram.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 根据用户输入的类别，聊天机器人会生成相应的回答。[图6-5](../Text/ch06.xhtml#ch06fig05)展示了如何在图表中表示这种用户输入处理方式。
- en: '![image](../Images/fig6-5.jpg)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![image](../Images/fig6-5.jpg)'
- en: '*Figure 6-5: An example of user input handling in a ticket-booking application*'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '*图6-5：购票应用中用户输入处理的示例*'
- en: The following script implements this design. For convenience, the code is divided
    into several parts.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 以下脚本实现了这一设计。为了方便，代码分为几个部分。
- en: The first snippet contains the `guess_destination` function, which searches
    a sentence for a `GPE` entity. Also, we’ll need to insert the `dep_destination`
    function defined and discussed in “[Iterating Over the Heads of Tokens](../Text/ch06.xhtml#lev82)”
    on [page 87](../Text/ch06.xhtml#page_87). Recall that this function searches a
    sentence for the “to + `GPE`” pattern. We’ll need the `dep_destination` and `guess_destination`
    functions to handle the first and second scenarios of user input, respectively.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个代码片段包含 `guess_destination` 函数，该函数在句子中搜索 `GPE` 实体。同时，我们还需要插入在 “[迭代标记的头部](../Text/ch06.xhtml#lev82)”
    中定义并讨论的 `dep_destination` 函数，见[第87页](../Text/ch06.xhtml#page_87)。回想一下，这个函数会在句子中搜索
    “to + `GPE`” 模式。我们需要 `dep_destination` 和 `guess_destination` 函数来分别处理用户输入的第一种和第二种场景。
- en: '[PRE37]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: The code in the `guess_destination` function iterates over the tokens in a sentence,
    looking for a `GPE` entity ➊. Once it finds one, the function returns it to the
    calling code ➋. If it fails to find one, the function returns `'Failed to determine'`
    ➌, meaning the sentence doesn’t contain a `GPE` entity.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '`guess_destination` 函数中的代码会遍历句子中的标记，寻找 `GPE` 实体 ➊。一旦找到，函数将其返回给调用代码 ➋。如果没有找到，函数将返回
    `''Failed to determine''` ➌，表示句子中没有 `GPE` 实体。'
- en: In the `gen_function` that follows, we generate a response based on what the
    functions defined in the preceding snippet return.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的 `gen_function` 中，我们根据前面片段中定义的函数返回的内容生成响应。
- en: '[PRE38]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: The code in the `gen_response` function starts by invoking the `det_destination`
    function ➊, which determines whether an utterance contains a “to + `GPE`” pair.
    If one is found, we assume that the user wants a ticket to the destination and
    they need to clarify their departure time ➋.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '`gen_response` 函数中的代码首先调用 `det_destination` 函数 ➊，该函数判断一个话语是否包含 “to + `GPE`”
    组合。如果找到这样的组合，我们假设用户想要前往某个目的地，并且他们需要明确他们的出发时间 ➋。'
- en: If the `det_destination` function hasn’t found a “to + `GPE`” pair in the utterance,
    we invoke the `guess_destination` function ➌. This function tries to find a `GPE`
    entity. If it finds such an entity, it asks the user a confirmatory question about
    whether they want to fly to that destination ➍. Otherwise, if it finds no `GPE`
    entity in the utterance, the script asks the user whether they want to fly somewhere
    ➎.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 `det_destination` 函数没有在话语中找到 “to + `GPE`” 组合，我们会调用 `guess_destination` 函数
    ➌。该函数尝试查找 `GPE` 实体。如果找到了该实体，它会询问用户是否想飞往该目的地 ➍。否则，如果在话语中没有找到 `GPE` 实体，脚本会询问用户是否想飞往某个地方
    ➎。
- en: 'To test the code, we apply the pipeline to a sentence and then send the doc
    to the `gen_response` function we used in the previous listing:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试代码，我们将管道应用于一个句子，然后将文档传递给我们在前面的代码中使用的 `gen_response` 函数：
- en: '[PRE39]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'For the utterance submitted in this example, you should see the following output:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本示例提交的语句，您应该看到以下输出：
- en: '[PRE40]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: You can experiment with the sample utterance to see different output.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以尝试使用示例语句来查看不同的输出。
- en: '**Making a Smarter Chatbot by Finding Proper Modifiers**'
  id: totrans-195
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**通过找到合适的修饰语让聊天机器人更智能**'
- en: 'One way to make your chatbot smarter is to use dependency trees to find modifiers
    for particular words. For example, you might teach your application to recognize
    the adjectives that are applicable to a given noun. Then you could tell the bot,
    “I’d like to read a book,” to which the smart bot could respond like this: “Would
    you like a fiction book?”'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 让聊天机器人更智能的一种方法是使用依赖树来查找特定单词的修饰语。例如，您可以教会您的应用程序识别适用于特定名词的形容词。然后，您可以告诉机器人，“我想读一本书”，智能机器人可能会这样回答：“您想要一本小说书吗？”
- en: 'A *modifier* is an optional element in a phrase or a clause used to change
    the meaning of another element. Removing a modifier doesn’t typically change the
    basic meaning of the sentence, but it does make it less specific. As a quick example,
    consider the following two sentences:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '*修饰语* 是短语或从句中的可选元素，用于改变另一个元素的意思。去掉修饰语通常不会改变句子的基本意思，但会使句子变得不那么具体。举个简单的例子，考虑以下两句话：'
- en: '[PRE41]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: The first sentence doesn’t use modifiers. The second uses the modifier “on Python,”
    making your request more detailed.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 第一句话没有使用修饰语。第二句使用了修饰语“on Python”，使得请求更加详细。
- en: If you want to be specific, you must use modifiers. For example, to generate
    a proper response to a user, you might need to learn which modifiers you can use
    in conjunction with a given noun or verb.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想要更具体，必须使用修饰语。例如，为了生成对用户的适当回应，您可能需要学习哪些修饰语可以与特定的名词或动词一起使用。
- en: 'Consider the following phrase:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下短语：
- en: '[PRE42]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: In this noun phrase, “fruit” is the head, “that” and “exotic” are *premodifiers*—modifiers
    located in front of the word being modified—and “from Africa” is a *postmodifier*
    phrase—a modifier that follows the word it limits or qualifies. [Figure 6-6](../Text/ch06.xhtml#ch06fig06)
    shows the dependency tree for this phrase.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个名词短语中，“fruit”是中心词，“that”和“exotic”是*前修饰词*——位于被修饰单词前的修饰词——而“from Africa”是*后修饰词*短语——一个跟随被限定或修饰单词的修饰词。[图
    6-6](../Text/ch06.xhtml#ch06fig06)展示了该短语的依存树。
- en: '![image](../Images/fig6-6.jpg)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![image](../Images/fig6-6.jpg)'
- en: '*Figure 6-6: An example of premodifiers and postmodifiers*'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 6-6：前修饰词和后修饰词的示例*'
- en: Suppose you want to determine possible adjectival modifiers for the word “fruit.”
    (Adjectival modifiers are always premodifiers.) Also, you want to look at what
    `GPE` entities you can find in the postmodifiers of this same word. This information
    could later help you generate an utterance during a conversation on fruits.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你想确定单词“fruit”的可能形容词修饰词。（形容词修饰词总是前修饰词。）此外，你还想查看在同一个单词的后修饰词中可以找到哪些`GPE`实体。这些信息可能会在以后帮助你在关于水果的对话中生成发言。
- en: 'The following script implements this design:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 以下脚本实现了这个设计：
- en: '[PRE43]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'We start by applying the pipeline to a short text that contains the word “fruit”
    with both premodifiers and postmodifiers ➊. We define two empty lists: `fruit_adjectives`
    ➋ and `fruit_origins` ➌. The first one will hold any adjectival modifiers found
    for the word “fruit.” The second list will hold any `GPE` entities found among
    the postmodifiers of “fruit.”'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先将管道应用于一个包含单词“fruit”的简短文本，该单词具有前修饰词和后修饰词 ➊。我们定义了两个空列表：`fruit_adjectives`
    ➋ 和 `fruit_origins` ➌。第一个列表将保存所有找到的“fruit”的形容词修饰词。第二个列表将保存所有在“fruit”的后修饰词中找到的`GPE`实体。
- en: Next, in a loop iterating over the tokens of the entire text, we look for the
    word “fruit” ➍. Once this word is found, we first determine its adjectival premodifiers
    by picking up its syntactic children to the left and choosing only adjectives
    (determiners and compounds can also be premodifiers). We append the adjectival
    modifiers to the `fruit_adjectives` list ➎.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，在一个遍历整个文本的循环中，我们寻找单词“fruit” ➍。一旦找到该单词，我们首先通过获取它的左侧句法子节点来确定其形容词前修饰词，并仅选择形容词（限定词和复合词也可以是前修饰词）。我们将形容词修饰词附加到`fruit_adjectives`列表
    ➎。
- en: Then we search for postmodifiers by checking the right-hand syntactic children
    of the word “fruit.” In particular, we look for named entities, and then append
    them to the `fruit_origins` list ➏.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们通过检查“fruit”右侧的句法子节点来寻找后修饰词。特别是，我们寻找命名实体，然后将它们附加到`fruit_origins`列表 ➏。
- en: 'The script outputs the following two lists:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本输出以下两个列表：
- en: '[PRE44]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Now your bot “knows” that a fruit can be nice, exotic (or both nice and exotic),
    and might come from Africa.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你的机器人“知道”水果可以是美味的、异国的（或既美味又异国），并且可能来自非洲。
- en: '**Summary**'
  id: totrans-215
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**总结**'
- en: When you need to process an utterance, or even just a phrase, it’s often important
    to look at its structure to determine which general patterns it matches. Using
    spaCy’s linguistic features, you can detect these patterns, allowing your script
    to understand the user’s intention and respond properly.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 当你需要处理一段话，甚至只是一个短语时，通常重要的是要查看其结构，以确定它匹配哪些通用模式。通过使用spaCy的语言学特性，你可以检测到这些模式，从而让你的脚本理解用户的意图并作出适当回应。
- en: Using patterns based on linguistic features works well when you need to recognize
    the general structure of a sentence, which involves the subject, modal auxiliary
    verb, main verb, and direct object. But a real-world application needs to recognize
    more complicated sentence structures and be prepared for a wider set of user input.
    This is where the syntactic dependency tree of a sentence becomes very useful.
    You can walk the dependency tree of a sentence in different ways, extracting necessary
    pieces of information from it. For example, you can use dependency trees to find
    modifiers for particular words, and then use this information later to generate
    intelligent text.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 使用基于语言学特征的模式在你需要识别句子的通用结构时效果很好，这些结构包括主语、情态助动词、主要动词和直接宾语。但一个真实世界的应用程序需要识别更复杂的句子结构，并为更广泛的用户输入做好准备。这就是句子的句法依存树变得非常有用的地方。你可以通过不同的方式遍历句子的依存树，从中提取必要的信息。例如，你可以使用依存树查找特定单词的修饰语，然后利用这些信息生成智能文本。

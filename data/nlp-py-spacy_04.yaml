- en: '**4'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**4'
- en: EXTRACTING AND USING LINGUISTIC FEATURES**
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 提取和使用语言特征**
- en: '![Image](../Images/comm1.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../Images/comm1.jpg)'
- en: In the previous chapters, you learned how to access linguistic features, such
    as part-of-speech tags, syntactic dependencies, and named entities, as part of
    the text processing pipeline. This chapter will show you how to use part-of-speech
    tags and syntactic dependency labels to extract and generate text, allowing you
    to build question-asking chatbots, locate specific phrases in a text, and more.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中，你学习了如何访问语言特征，如词性标注、句法依赖关系和命名实体，作为文本处理管道的一部分。本章将向你展示如何使用词性标注和句法依赖标签来提取和生成文本，帮助你构建提问型聊天机器人、定位文本中的特定短语等。
- en: Almost every NLP application needs to extract specific information from a text
    and generate new text that is relevant to a particular situation. For example,
    a chatbot must be able carry on a conversation with a user, which means it must
    be able to identify specific parts of a user’s text and then generate its own
    appropriate response. Let’s look at how to do all of that using linguistic features.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎每个NLP应用程序都需要从文本中提取特定的信息，并生成与特定情境相关的新文本。例如，一个聊天机器人必须能够与用户进行对话，这意味着它必须能够识别出用户文本中的特定部分，然后生成适当的回应。让我们看看如何使用语言特征做到这一点。
- en: '**Extracting and Generating Text with Part-of-Speech Tags**'
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**使用词性标注提取和生成文本**'
- en: Part-of-speech tags can help you retrieve specific kinds of information from
    a text, and they can also help you generate entirely new sentences based on a
    submitted one. In this section, we’ll introduce you to some new part-of-speech
    tags, write a script that finds phrases describing amounts of money, and transform
    statements into questions. For a list of common part-of-speech tags used in spaCy
    for English models, refer to [Table 2-1](../Text/ch02.xhtml#ch02tab01) on [page
    22](../Text/ch02.xhtml#page_22).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 词性标注可以帮助你从文本中检索特定类型的信息，它们还可以帮助你根据提交的句子生成全新的句子。在这一部分，我们将向你介绍一些新的词性标注，编写一个脚本来查找描述金额的短语，并将陈述句转化为疑问句。有关spaCy中用于英语模型的常见词性标注列表，请参见[表2-1](../Text/ch02.xhtml#ch02tab01)中的[第22页](../Text/ch02.xhtml#page_22)。
- en: '***Numeric, Symbolic, and Punctuation Tags***'
  id: totrans-7
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***数字、符号和标点符号标注***'
- en: 'In addition to part-of-speech tags for nouns, verbs, and other words in a sentence,
    spaCy has tags for symbols, numbers, and punctuation marks. Let’s look at these
    by processing the following sentence:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 除了名词、动词和句子中的其他词的词性标注外，spaCy还有符号、数字和标点符号的标注。让我们通过处理以下句子来看这些标注：
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To begin, let’s extract the coarse-grained part-of-speech features from the
    tokens in the sentence to see how spaCy distinguishes between different part-of-speech
    categories. We can do this with the following script:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们从句子中的标记中提取粗粒度的词性特征，看看spaCy如何区分不同的词性类别。我们可以通过以下脚本实现：
- en: '[PRE1]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We create a Doc object for the submitted sentence and then output the coarse-grained
    part-of-speech tags ➊. We also use the `spacy.explain()` function, which returns
    a description for a given linguistic feature ➋.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为提交的句子创建一个Doc对象，然后输出粗粒度的词性标注➊。我们还使用`spacy.explain()`函数，它会返回给定语言特征的描述➋。
- en: 'The output should look as follows:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应如下所示：
- en: '[PRE2]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Notice that the coarse-grained tagger distinguishes numerals, symbols, and punctuation
    marks as individual categories. As you can see, it even recognizes “million” spelled
    out.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到粗粒度标注器将数字、符号和标点符号区分为独立的类别。如你所见，它甚至能识别出拼写出来的“million”。
- en: 'Now, for the sake of comparison, let’s output both coarse-grained and fine-grained
    part-of-speech tags for this sample sentence along with a description column for
    the fine-grained tags:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了比较，我们将输出该示例句子的粗粒度和细粒度词性标注，并为细粒度标注添加一列描述：
- en: '[PRE3]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The output should look as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应如下所示：
- en: '[PRE4]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The second and third columns contain the coarse-grained and fine-grained part-of-speech
    tags, respectively. The fourth column gives descriptions of the fine-grained tags
    provided in the third column.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 第二列和第三列分别包含粗粒度和细粒度词性标注。第四列给出了第三列中细粒度标注的描述。
- en: The fine-grained tagging divides each category into subcategories. For example,
    the coarse-grained category `SYM` (symbols) has three fine-grained subcategories.
    These are `$` for currency symbols, `#` for the number sign, and `SYM` for all
    the other symbols, such as +, −, ×, ÷, =. This sub-dividing can be useful when
    you need to distinguish between different types of symbols. For example, you might
    be processing articles about math and want your script to recognize symbols commonly
    found in math formulas. Or you might be writing a script that needs to recognize
    currency symbols in financial reports.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 细粒度标签将每个类别细分为子类别。例如，粗粒度类别 `SYM`（符号）有三个细粒度子类别。它们分别是：`$` 代表货币符号，`#` 代表数字符号，`SYM`
    代表其他所有符号，如 +、−、×、÷、=。这种细分在你需要区分不同类型符号时非常有用。例如，你可能在处理数学文章时，想要脚本识别数学公式中常见的符号。或者，你可能在编写一个需要识别财务报告中的货币符号的脚本。
- en: '**NOTE**'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*Because spaCy’s part-of-speech tagger relies on a token’s context to generate
    its label, you might get different labels for tokens used in unusual contexts.*'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '*由于 spaCy 的词性标注器依赖于标记的上下文来生成标签，你可能会遇到不同上下文中使用的标记得到不同标签的情况。*'
- en: Now let’s look at how we can take advantage of these specific part-of-speech
    tags to extract and generate text.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看如何利用这些特定的词性标签来提取和生成文本。
- en: '***Extracting Descriptions of Money***'
  id: totrans-25
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***提取货币描述***'
- en: Suppose you’re developing an application for processing financial reports that
    must extract necessary pieces of information from long, boring texts. In practice,
    financial reports can be quite large, but all you really need are the figures.
    In particular, you’re interested in phrases that refer to an amount of money and
    start with a currency symbol. For example, your script should pick out the phrase
    “$1.5 million” from the previous sample sentence, but not “2017”.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你正在开发一个处理财务报告的应用程序，需要从冗长乏味的文本中提取必要的信息。实际上，财务报告通常很大，但你真正需要的只是其中的数字。特别是，你关心的是那些表示金额且以货币符号开头的短语。例如，你的脚本应该能够从前述示例句子中提取出短语“$1.5
    million”，而不是“2017”。
- en: 'The following script illustrates how you might extract this phrase from the
    sentence, relying on the tokens’ part-of-speech tags only. You can save this script
    to a file and then run it or execute the code from within a Python session:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 以下脚本展示了如何仅依靠词性标签提取句子中的短语。你可以将此脚本保存到文件中，然后运行它，或者在 Python 会话中执行代码：
- en: '[PRE5]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We iterate over the sentence’s tokens ➊, searching for a token whose fine-grained
    part-of-speech tag is `$` ➋. This tag indicates a currency symbol, and it typically
    starts a phrase that refers to an amount of money. Once we find a currency symbol,
    we start composing the phrase by checking whether the tokens that follow the currency
    symbol in the sentence are numbers. To do this, we implement a `while` loop in
    which we pick up the tokens located to the right of the currency symbol and check
    them for the `CD` tag, which is the cardinal number fine-grained part-of-speech-tag
    ➌. When we reach a nonnumeric token, we quit the `while` loop and break the `for`
    loop ➍ that iterates over the sentence’s tokens.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们遍历句子的标记 ➊，寻找一个词性标签为 `$` 的标记 ➋。这个标签表示货币符号，通常用于表示金额的短语开头。一旦找到货币符号，我们就开始构建短语，检查紧随其后的标记是否是数字。为此，我们实现了一个
    `while` 循环，循环中我们获取货币符号右侧的标记，并检查它们是否有 `CD` 标签，这是表示基数的词性标签 ➌。当我们遇到非数字标记时，我们退出 `while`
    循环并跳出遍历句子标记的 `for` 循环 ➍。
- en: 'When we run the script, the output should look as follows:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行脚本时，输出应该如下所示：
- en: '[PRE6]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This is exactly the kind of output we are looking for.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是我们所期望的输出。
- en: Keep in mind that a currency symbol assigned to the `$` fine-grained part-of-speech
    tag might not necessarily be “$”. The part-of-speech tag might label other common
    currency symbols, such as £ and €. For example, the preceding script would recognize
    the phrase “£1.500.000”.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，分配给 `$` 细粒度词性标签的货币符号不一定是“$”。这个词性标签也可能标记其他常见的货币符号，如 £ 和 €。例如，上述脚本会识别“£1,500,000”这个短语。
- en: '***Try This***'
  id: totrans-34
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***尝试这个***'
- en: 'We wrote this script to extract a single phrase referring to an amount of money
    from the submitted sentence. Once the script finds the phrase, it completes its
    execution. But in practice, you might have a sentence that has more than one such
    phrase, as in the following example: “The firm earned $1.5 million in 2017, in
    comparison with $1.2 million in 2016.”'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们编写了这个脚本，用于从提交的句子中提取一个指代金额的短语。一旦脚本找到该短语，它便会完成执行。但在实践中，你可能会遇到一个句子，其中有多个这样的短语，例如以下示例：“公司在2017年赚了150万美元，而2016年赚了120万美元。”
- en: Modify the script so it extracts every phrase that refers to an amount of money
    within a sentence. To accomplish this, remove the `break` statement to prevent
    the loop from ending after it finds the first occurrence of the phrase of interest.
    Then move the code that’s responsible for preparing and printing a found phrase
    (the last two lines of the script) into the loop, so you can invoke these two
    lines for every phrase of interest found in the submitted sentence.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 修改脚本，使其能够提取句子中所有指代金额的短语。为此，删除`break`语句，以防止循环在找到第一个感兴趣的短语后结束。然后，将负责准备和打印找到的短语的代码（脚本中的最后两行）移入循环中，这样你就可以对每个在提交的句子中找到的感兴趣短语调用这两行代码。
- en: '***Turning Statements into Questions***'
  id: totrans-37
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***将陈述转换为问题***'
- en: Suppose your NLP application must be able to generate a question from a submitted
    statement. For example, one way chatbots maintain conversations with the user
    is by asking the user a confirmatory question. When a user says, “I am sure,”
    the chatbot might ask something like, “Are you really sure?” To do this, the chatbot
    must be able to generate a relevant question.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你的自然语言处理应用程序必须能够根据提交的陈述生成问题。例如，聊天机器人与用户保持对话的一种方式是通过向用户提问确认性问题。当用户说“我确定”时，聊天机器人可能会问“你真的确定吗？”要做到这一点，聊天机器人必须能够生成一个相关的问题。
- en: 'Let’s say the user’s submitted sentence is this:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 假设用户提交的句子是这样的：
- en: '[PRE7]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This sentence contains several verbs and pronouns, each with different morphologies.
    To see this more clearly, let’s look at the part-of-speech tags spaCy assigned
    to the tokens in this sentence:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这个句子包含了几个动词和代词，每个都有不同的形态。为了更清楚地看到这一点，我们来看看spaCy为这个句子中的标记分配的词性标注：
- en: '[PRE8]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We print the tokens, their coarse-grained part-of-speech tags, and their fine-grained
    part-of-speech-tags, producing the following output:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们打印出这些标记、它们的粗粒度词性标注和精粒度词性标注，生成如下输出：
- en: '[PRE9]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: From the fine-grained part-of-speech tags, you can distinguish between the morphological
    categories of the verbs and pronouns present in the sentence. For example, the
    fine-grained part-of-speech tag `PRP` marks personal pronouns and `PRP$` marks
    possessive pronouns, allowing you to distinguish between these two types of pronouns
    programmatically. We’ll need this information when working on this example.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 从精细的词性标注中，你可以区分句中动词和代词的形态类别。例如，精细的词性标注`PRP`标记人称代词，`PRP$`标记所有格代词，这使得你能够在程序中区分这两种代词。我们在处理这个示例时会需要这些信息。
- en: 'A confirmatory question to the sentence discussed here might be as follows
    (another statement would require another confirmatory question, of course):'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这里讨论的句子的确认性问题可能如下所示（当然，另一个陈述会需要另一个确认性问题）：
- en: '[PRE10]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'From a human perspective, forming this question from the statement looks pretty
    straightforward: you change the order of some words, alter the pronouns accordingly,
    and add the adverbial modifier “really” to the main verb (the one that comes right
    after the subject). But how can you accomplish all these operations programmatically?'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 从人类的角度来看，从陈述中形成这个问题看起来相当简单：你只需要改变一些词语的顺序，适当地更改代词，并将副词修饰语“really”添加到主谓动词（紧跟在主语后面的那个动词）。但如何在程序中实现所有这些操作呢？
- en: Let’s look at some part-of-speech tags. In the sample sentence, the verbs involved
    in forming the question are “can” and “promise”. The fine-grained part-of-speech
    tags mark the first one, “can”, as a modal auxiliary verb and the second one as
    a verb in the base form. Notice that in the preceding confirmatory question, the
    modal auxiliary verb has switched places with the personal pronoun, a process
    called *inversion*. We’ll have to implement this in the script.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来看看一些词性标注。在这个示例句子中，形成问题所涉及的动词是“can”和“promise”。精细的词性标注将第一个动词“can”标记为情态助动词，而将第二个动词标记为基本形式的动词。注意，在前面的确认性问题中，情态助动词与人称代词交换了位置，这一过程称为*倒装*。我们需要在脚本中实现这一点。
- en: When it comes to the pronouns, the chatbot should follow a pattern common to
    regular conversations. [Table 4-1](../Text/ch04.xhtml#ch04tab01) summarizes the
    use of pronouns in such an application.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 关于代词，聊天机器人应该遵循常见的日常对话模式。[表 4-1](../Text/ch04.xhtml#ch04tab01)总结了此类应用中的代词使用方法。
- en: '**Table 4-1:** The Use of Pronouns in a Chatbot'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**表 4-1:** 聊天机器人中代词的使用'
- en: '|  | **Personal pronouns** | **Possessive pronouns** |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '|  | **人称代词** | **物主代词** |'
- en: '| --- | --- | --- |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| chatbot | I, me | my, mine |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| 聊天机器人 | 我, 我自己 | 我的, 我的东西 |'
- en: '| user | you | your, yours |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 用户 | 你 | 你的, 你的东西 |'
- en: In other words, a chatbot refers to itself as “I” or “me,” and it refers to
    a user as “you.”
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，聊天机器人将自己称为“我”或“我自己”，并将用户称为“你”。
- en: 'The following steps outline what we need to do to generate a question from
    the original statement:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤概述了我们需要做的事情，以从原始陈述中生成一个问题：
- en: Change the order of words in the original sentence from “subject + modal auxiliary
    verb + infinitive verb” to “modal auxiliary verb + subject + infinitive verb.”
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将原句中的单词顺序从“主语 + 情态助动词 + 不定式动词”更改为“情态助动词 + 主语 + 不定式动词”。
- en: Replace the personal pronoun “I” (the sentence’s subject) with “you.”
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将人称代词“I”（句子的主语）替换为“你”。
- en: Replace the possessive pronoun “your” with “my.”
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将物主代词“你的”替换为“我的”。
- en: Place the adverbial modifier “really” before the verb “promise” to emphasize
    the latter.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将副词修饰语“really”放置在动词“promise”之前，以强调后者。
- en: Replace the punctuation mark “.” with “?” at the end of the sentence.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将句末的标点符号“.”替换为“?”。
- en: 'The following script implements these steps:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 以下脚本实现了这些步骤：
- en: '[PRE11]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We perform the first four steps in separate `for` loops. First, we iterate over
    the tokens in the sentence and change the order of the subject and verb to make
    the sentence a question. In this example, we’re looking for the modal auxiliary
    verb (tagged `MD`) that follows a personal pronoun and is followed by an infinitive
    verb ➊. Once we find this sequence of words, we move the modal auxiliary verb
    immediately before the personal pronoun, placing it at the beginning of the sentence
    ➋.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在单独的 `for` 循环中执行前四个步骤。首先，我们遍历句子中的标记，改变主语和动词的顺序，使句子变为一个问题。在这个例子中，我们寻找一个紧跟在人称代词后的情态助动词（标记为
    `MD`），并且后面跟着不定式动词 ➊。找到这一系列词后，我们将情态助动词立即移到人称代词前面，置于句首 ➋。
- en: To compose a new sentence, we use a technique known in Python as *slicing* that
    allows us to extract a subsequence from a sequence object, such as a string or
    a list, by specifying the start and end indices. In this case, we can apply slicing
    to a Doc object to extract a given subsequence of tokens from it. For example,
    `slice doc[2:]` will contain the doc’s tokens starting from the token at index
    2 through the end of the doc, which in this case, is “promise it is worth your
    time.” ➌. Once we move the modal verb to a new position, we exit the `for` loop
    ➍.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 为了组成一个新句子，我们使用在 Python 中称为 *切片* 的技术，它允许我们通过指定起始和结束索引，从序列对象（如字符串或列表）中提取子序列。在这种情况下，我们可以对
    Doc 对象应用切片，以从中提取给定的标记子序列。例如，`slice doc[2:]` 将包含从索引 2 开始到文档末尾的标记，在这个例子中是“保证这值得你花时间。”
    ➌。一旦我们将情态助动词移到新位置，就退出 `for` 循环 ➍。
- en: You might wonder why we don’t just use the personal pronoun and auxiliary modal
    verb’s indices to perform inversion. Because we know the personal pronoun is at
    index 0 and the modal verb is at index 1, why do we have to use a loop that iterates
    over the entire set of tokens to find the modal verb’s position? Won’t the verb
    always follow the subject and so be the second word in the sentence?
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想，为什么我们不直接使用人称代词和情态助动词的索引来进行倒装呢？因为我们知道人称代词位于索引 0，而情态助动词位于索引 1，为什么我们还需要使用一个循环，遍历整个词汇集来找到情态助动词的位置呢？动词不总是紧跟主语，因此应该是句子的第二个单词吗？
- en: The fact is that a sentence doesn’t always start with the subject. For example,
    what if the sentence were “Sure enough, I can promise it is worth your time.”?
    In that case, the script would know to omit the first two words and start processing
    with the subject.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，句子并不总是从主语开始。例如，如果句子是“果然，我可以保证这值得你花时间。”呢？在这种情况下，脚本会知道省略前两个词并从主语开始处理。
- en: As a result of the inversion, we get the new sentence as a string. To make this
    sentence available for further processing, we need to obtain a Doc object for
    it ➎.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 由于倒装，我们得到一个新的句子作为字符串。为了进一步处理这个句子，我们需要为它获取一个 Doc 对象 ➎。
- en: Next, we create a new `for` loop that will replace the personal pronoun “I”
    with the personal pronoun “you.” To do this, we search for personal pronouns (tagged
    `PRP`). If the personal pronoun is “I,” we replace it with “you” ➏. Then we quit
    the `for` loop.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们创建一个新的`for`循环，将个人代词“I”替换为个人代词“you”。为此，我们搜索个人代词（标记为`PRP`）。如果个人代词是“I”，我们将其替换为“you”
    ➏。然后我们退出`for`循环。
- en: We repeat this process to replace the possessive pronoun “your” with “my” by
    searching for the `PRP$` tag ➐. Then, in a new `for` loop, we find a verb in the
    infinitive form and insert the adverbial modifier “really” before it ➑.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们重复这个过程，通过搜索`PRP$`标签 ➐来将所有的物主代词“your”替换成“my”。然后，在一个新的`for`循环中，我们找到一个不定式形式的动词，并在它前面插入副词修饰语“really”
    ➑。
- en: Finally, we replace the sentence’s period with a question mark. This is the
    only step where we don’t need to use a loop. The reason is that in all possible
    sentences, the period and the question mark go at the end of a sentence, so we
    can reliably find them using their indices with `len(doc)-1` ➒.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将句子的句号替换为问号。这是唯一一个不需要使用循环的步骤。原因是，在所有可能的句子中，句号和问号都位于句子的末尾，因此我们可以通过`len(doc)-1`的索引可靠地找到它们
    ➒。
- en: 'When we run this code, we should get the following output:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行这段代码时，我们应该得到以下输出：
- en: '[PRE12]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This script is a good start, but it won’t work with every submitted statement.
    For example, the statement might contain a personal pronoun other than “I,” but
    our script doesn’t explicitly check for that. Also, some sentences don’t contain
    auxiliary verbs, like the sentence “I love eating ice cream.” In those cases,
    we’d have to use the word “do” to form the question instead of a word like “can”
    or “should,” like this: “Do you really love eating ice cream?” But if the sentence
    contains the verb “to be,” as in the sentence “I am sleepy,” we’d have to move
    that verb to the front, like this: “Are you sleepy?”'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这个脚本是一个好的开始，但它并不能处理每一个提交的陈述句。例如，句子中可能包含一个除“I”之外的个人代词，但我们的脚本没有明确检查这一点。此外，有些句子没有助动词，比如句子“I
    love eating ice cream”（我喜欢吃冰淇淋）。在这种情况下，我们必须使用“do”这个词来构成问题，而不是像“can”或“should”这样的词，像这样：“Do
    you really love eating ice cream?” 但如果句子包含动词“to be”，比如“I am sleepy”（我困了），我们必须把动词移到句首，变成这样：“Are
    you sleepy?”
- en: A real implementation of this chatbot would have to be able to choose the appropriate
    option for a submitted sentence. You’ll see a “do” example in “[Deciding What
    Question a Chatbot Should Ask](../Text/ch04.xhtml#lev53)” on [page 56](../Text/ch04.xhtml#page_56).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这个聊天机器人真正的实现必须能够为提交的句子选择合适的选项。你可以在[“决定聊天机器人应该问什么问题”](../Text/ch04.xhtml#lev53)一节中看到一个“做”的例子，位于[第56页](../Text/ch04.xhtml#page_56)。
- en: '***Try This***'
  id: totrans-77
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***尝试这个***'
- en: Examining the script from “[Turning Statements into Questions](../Text/ch04.xhtml#lev49)”,
    you might notice that some blocks of code in it look very similar, containing
    repetitive operations. In every step, you make a replacement in the sentence and
    then re-tokenize it. That means you might try to generalize the code, putting
    repetitive operations in a single function.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 检查[“将陈述句转化为问题”](../Text/ch04.xhtml#lev49)中的脚本时，你可能会注意到其中一些代码块看起来非常相似，包含重复的操作。在每一步中，你都会替换句子中的某个部分，然后重新分词。这意味着你可以尝试将代码进行泛化，把重复的操作放入一个函数中。
- en: Before writing such a function, take some time to understand what parameters
    it will need to take to perform the text-manipulation operations you see in the
    script. In particular, you’ll need to explicitly specify what token you’re searching
    for and what operation you want to perform on it by either replacing it with another
    token or adding a token before it.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写这样的函数之前，花点时间了解它需要接受哪些参数，以便执行你在脚本中看到的文本操作。特别地，你需要明确指定你要搜索的词元和你希望对其执行的操作，方法是将其替换为另一个词元或在它前面添加一个词元。
- en: Once you define this function, you can write the main code that invokes it,
    implementing the same functionality as the original script.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你定义了这个函数，就可以编写调用它的主代码，实现与原脚本相同的功能。
- en: '**Using Syntactic Dependency Labels in Text Processing**'
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**在文本处理中使用句法依赖标签**'
- en: As you learned in “[Extracting and Generating Text with Part-of-Speech Tags](../Text/ch04.xhtml#lev45)”
    on [page 48](../Text/ch04.xhtml#page_48), part-of-speech tags are a powerful tool
    for smart text processing. But in practice, you might need to know more about
    a sentence’s tokens to process it intelligently.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在[“使用词性标签提取和生成文本”](../Text/ch04.xhtml#lev45)一节中学习的那样，词性标签是智能文本处理的强大工具。但在实际操作中，你可能需要了解更多关于句子中的词元信息，以便更智能地处理它。
- en: For example, you might need to know whether a personal pronoun is the subject
    of a sentence or a grammatical object. Sometimes, this task is easy. The personal
    pronouns “I,” “he,” “she,” “they,” and “we” will almost always be the subject.
    When used as an object, “I” turns into “me,” as in “A postman brought me a letter.”
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，你可能需要知道一个人称代词是句子的主语还是语法宾语。有时候，这个任务很简单。人称代词“I”，“he”，“she”，“they”和“we”几乎总是主语。当用作宾语时，“I”变成“me”，比如在句子“A
    postman brought me a letter.”中。
- en: 'But this might not be as clear when it comes to some other personal pronouns,
    such as “you” or “it,” which look the same whether they’re used as subjects or
    objects. Consider the following two sentences: “I know you. You know me.” In the
    first sentence, “you” is the direct object of the verb “know.” In the second sentence,
    “you” is the verb’s subject.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 但当涉及到一些其他人称代词时，比如“you”或“it”，它们作为主语或宾语时看起来是一样的，这一点可能不那么清晰。考虑以下两个句子：“I know you.
    You know me.” 在第一个句子中，“you”是动词“know”的直接宾语。在第二个句子中，“you”是动词的主语。
- en: Let’s solve this problem using syntactic dependency labels and part-of-speech
    tags. Then we’ll apply syntactic dependency labels to build a better version of
    the question-asking chatbot.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用句法依存关系标签和词性标签来解决这个问题。然后我们将应用句法依存关系标签来构建一个更好的问答聊天机器人版本。
- en: '***Distinguishing Subjects from Objects***'
  id: totrans-86
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***区分主语和宾语***'
- en: To programmatically determine the role of a pronoun like “you” or “it” in a
    given sentence, you need to check the dependency label assigned to it. By using
    part-of-speech tags in conjunction with dependency labels, you can get much more
    information about the tokens of a sentence.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 要程序化地确定像“you”或“it”这样的代词在给定句子中的角色，你需要检查分配给它的依存关系标签。通过将词性标签与依存关系标签结合使用，你可以获得更多关于句子中词汇的信息。
- en: 'Let’s return to the sentence in the previous example and look at the results
    of the dependency parsing performed on it:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到前面的句子，并查看对其进行依存解析的结果：
- en: '[PRE13]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We extract the part-of-speech tags, the dependency labels, and the description
    for the dependency labels:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提取词性标签、依存关系标签以及依存关系标签的描述：
- en: '[PRE14]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The second and third columns contain the coarse-grained and fine-grained part-of-speech
    tags, respectively. The fourth column contains the dependency labels, and the
    fifth column contains descriptions for those dependency labels.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 第二列和第三列分别包含粗粒度和细粒度的词性标签。第四列包含依存关系标签，第五列包含这些依存关系标签的描述。
- en: Combining part-of-speech tags and dependency labels can give you a better picture
    of the grammatical role of each token in a sentence—more so than just part-of-speech
    tags or dependency labels alone. For instance, in this example, the part-of-speech
    tag `VBZ` assigned to the token “is” indicates a verb in the third person singular
    present, whereas the dependency label `ccomp`, assigned to the same token, indicates
    that “is” is a *clausal complement* (a dependent clause with an internal subject).
    In this example, “is” is a clausal complement of the verb “promise” with the internal
    subject “it.”
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 将词性标签和依存关系标签结合起来，可以为你提供更清晰的每个词汇在句子中的语法角色，比单独使用词性标签或依存关系标签更有帮助。例如，在这个例子中，分配给词汇“is”的词性标签`VBZ`表示它是第三人称单数现在时动词，而依存关系标签`ccomp`则表示“is”是一个*从句补语*（带有内部主语的依赖从句）。在这个例子中，“is”是动词“promise”的从句补语，内部主语是“it”。
- en: 'To figure out the role of “you” in “I know you. You know me.”, we’d check the
    following list of part-of-speech tags and dependency labels assigned to the tokens:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 为了弄清楚在“I know you. You know me.”中“you”的角色，我们需要查看以下为这些词汇分配的词性标签和依存关系标签：
- en: '[PRE15]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'In both cases, “you” is assigned the same part-of-speech tags: `PRON` and `PRP`
    (coarse-grained and fine-grained, respectively). But the two cases have different
    dependency labels: `dobj` in the first sentence and `nsubj` in the second.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，“you”都被分配了相同的词性标签：`PRON`和`PRP`（粗粒度和细粒度标签，分别）。但这两个情况有不同的依存关系标签：第一个句子中的`dobj`和第二个句子中的`nsubj`。
- en: '***Deciding What Question a Chatbot Should Ask***'
  id: totrans-97
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***决定聊天机器人应该提问什么问题***'
- en: 'Sometimes, you might need to navigate a sentence’s dependency tree to extract
    necessary information. For example, consider the following conversation between
    a chatbot and its user:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，你可能需要浏览句子的依存树以提取必要的信息。例如，考虑以下聊天机器人与用户之间的对话：
- en: '[PRE16]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The chatbot is able to continue the conversation by asking questions. But notice
    that the presence or absence of an adjectival modifier for the noun “apple” plays
    a key role in deciding what type of question it should ask.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 聊天机器人能够通过提问继续对话。但请注意，名词“apple”是否有形容词修饰语在决定它应该提什么类型的问题时起着关键作用。
- en: 'There are two basic types of questions in English: yes/no questions and information
    questions. Yes/no questions, like the one we generated in the example discussed
    in “[Turning Statements into Questions](../Text/ch04.xhtml#lev49)” on [page 51](../Text/ch04.xhtml#page_51),
    can have only two possible answers: yes or no. To form a question of this type,
    you place a modal auxiliary verb before the subject and the main verb after the
    subject. For example: “Could you modify it?”'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 英语中有两种基本的提问类型：是/否问题和信息型问题。是/否问题，比如我们在“[将陈述转为问题](../Text/ch04.xhtml#lev49)”一节中讨论的例子，在[第51页](../Text/ch04.xhtml#page_51)，只有两个可能的答案：是或否。要形成这种类型的问题，可以将情态助动词放在主语前面，主语后面是主要动词。例如：“Could
    you modify it?”
- en: 'Information questions are supposed to be answered with more information than
    just yes or no. They begin with a question word, such as “what,” “where,” “when,”
    “why,” or “how.” After the question word, the process of forming an information
    question is the same as for yes/no questions. For example: “What do you think
    about it?”'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 信息型问题的回答应该提供比简单的“是”或“否”更多的信息。它们以疑问词开头，如“what”，“where”，“when”，“why”或“how”。在疑问词之后，形成信息型问题的过程与是/否问题相同。例如：“What
    do you think about it?”
- en: In the first case in the preceding apple example, the chatbot asks a yes/no
    question. In the second case, when the user modifies the noun “apple” with the
    adjective “green,” the chatbot asks an information question.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面苹果示例中的第一个案例中，聊天机器人询问的是一个是/否问题。在第二个案例中，当用户用形容词“green”修饰名词“apple”时，聊天机器人会询问一个信息型问题。
- en: The flowchart in [Figure 4-1](../Text/ch04.xhtml#ch04fig01) summarizes this
    approach.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[图4-1](../Text/ch04.xhtml#ch04fig01)中的流程图总结了这种方法。'
- en: '![image](../Images/fig4-1.jpg)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![image](../Images/fig4-1.jpg)'
- en: '*Figure 4-1: The presence of a modifier in the input sentence determines what
    question the chatbot asks.*'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '*图4-1：输入句子中是否存在修饰语决定了聊天机器人提问的问题类型。*'
- en: The following script simply analyzes a submitted sentence to decide what kind
    of question to ask and then forms the proper question. We’ll walk through the
    code in separate sections, but you should save the entire program in a single
    file called *question.py*.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 以下脚本只是分析提交的句子以决定提问什么类型的问题，然后形成适当的问题。我们将通过单独的部分来逐步讲解代码，但你应该将整个程序保存为一个名为*question.py*的文件。
- en: 'Begin by importing the `sys` module, which provides functionality for accepting
    a sentence for processing as an argument:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 首先导入`sys`模块，它提供了接受句子作为处理参数的功能：
- en: '[PRE17]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This is an improvement from the previous scripts where we hardcoded the sentence
    to analyze. Now users can submit their own sentences as input.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这是对之前脚本的改进，之前我们是将要分析的句子硬编码在程序中。现在用户可以提交自己的句子作为输入。
- en: 'Next, we define a function that recognizes and extracts any noun chunk that
    is a direct object from a submitted doc. For example, if you submit a doc that
    contains the sentence “I want a green apple.”, it will return the chunk “a green
    apple”:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们定义一个函数，它可以识别并提取提交文档中任何作为直接宾语的名词短语。例如，如果你提交的文档包含句子“I want a green apple.”，它将返回短语“a
    green apple”：
- en: '[PRE18]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We iterate over the tokens in the submitted sentence ➊ and look for the one
    that acts as a direct object by checking whether its dependency tag is `dobj`
    ➋. In the sentence “I want a green apple.”, The direct object is the noun “apple.”
    Once we’ve found the direct object, we need to determine its syntactic children
    ➌, because they form the chunk that we’ll use to decide what kind of question
    to ask. For debugging purposes, we might also want to look at the children of
    the direct object ➍.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们遍历提交的句子中的标记 ➊，并通过检查其依赖标签是否为`dobj` ➋来寻找作为直接宾语的单词。在句子“I want a green apple.”中，直接宾语是名词“apple”。一旦我们找到了直接宾语，就需要确定它的句法子项
    ➌，因为它们组成了我们用来决定应该提问什么类型问题的部分。为了调试目的，我们还可能需要查看直接宾语的子项 ➍。
- en: 'To extract the chunk, we slice the Doc object, calculating the start and the
    end indices of the slice as follows: the start index is the index of the direct
    object minus the number of its syntactic children. As you might guess, this is
    the index of the leftmost child. The end index is the index of the direct object
    plus one, so the last token included in the chunk is the direct object ➎.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提取块，我们对`Doc`对象进行切片，计算切片的起始和结束索引，方法如下：起始索引是直接宾语的索引减去其语法子节点的数量。正如你可能猜到的，这是最左侧子节点的索引。结束索引是直接宾语的索引加一，所以块中包含的最后一个标记是直接宾语
    ➎。
- en: For simplicity, the algorithm implemented in this script assumes that a direct
    object has only leftward children. In fact, this isn’t always the case. For example,
    in the following sentence, “I want to touch a wall painted green.”, we’ll need
    to check the left and right children of the direct object “wall.” Also, because
    “green” is not a direct child of “wall,” we’ll need to walk the dependency tree
    to determine that “green” is a modifier of “wall.” We’ll discuss premodifiers
    and postmodifiers in more depth in [Chapter 6](../Text/ch06.xhtml#ch06).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化，脚本中实现的算法假设直接宾语只有左向的子节点。事实上，情况并非总是如此。例如，在以下句子中，“I want to touch a wall painted
    green.”（我想摸一面涂了绿色的墙。）我们需要检查直接宾语“wall”的左右子节点。此外，因为“green”不是“wall”的直接子节点，我们需要沿着依存树走，确定“green”是“wall”的修饰语。我们将在[第六章](../Text/ch06.xhtml#ch06)中更深入地讨论前修饰语和后修饰语。
- en: 'The following function examines the chunk and decides what kind of question
    the chatbot should ask:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 以下函数检查块并决定聊天机器人应提出什么样的问题：
- en: '[PRE19]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: We initialize the `question_type` variable to a value of `yesno`, which represents
    the yes/no question type ➊. Then, in the submitted chunk, we search for a token
    tagged `amod`, which stands for adjectival modifier ➋. If we find it, we set the
    `question_type` variable to `'info'`, which represents the information question
    type ➌.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将`question_type`变量初始化为`yesno`，表示是/否问题类型 ➊。然后，在提交的块中，我们搜索标记为`amod`的标记，它表示形容词修饰语
    ➋。若找到，我们将`question_type`变量设置为`'info'`，表示信息性问题类型 ➌。
- en: 'Once we’ve determined what question type to use, the following function generates
    a question from the submitted sentence:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们确定了使用哪种问题类型，以下函数会根据提交的句子生成一个问题：
- en: '[PRE20]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: In a sequence of `for` loops, we convert the submitted statement into a question
    by performing inversion and changing the personal pronouns. In this example, because
    there is no modal auxiliary verb in the statement, we add the verb “do” before
    the personal pronoun to form the question. (Remember that this will only work
    with certain sentences; in a more complete implementation, we’d have to programmatically
    figure out which processing approach to take.)
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在一系列`for`循环中，我们通过进行倒装和改变人称代词，将提交的陈述句转化为疑问句。在这个例子中，因为陈述句中没有情态助动词，我们在人称代词前加上动词“do”来构成疑问句。（记住，这只适用于某些句子；在更完整的实现中，我们需要通过编程来确定使用哪种处理方法。）
- en: If `question_type` is set to `info`, we add the word “why” to the beginning
    of the question ➊. If the `question_type` variable is set to `yesno` ➋, we insert
    an adjective to modify the direct object in the question. In this example, we’ve
    hardcoded the adjective for the sake of simplicity. We’ve chosen the adjective
    “red”, ➌ which might sound strange in certain sentences. For example, we can say,
    “Do you want a red orange?” but not “Do you want a red idea?” In a better implementation
    of this chatbot, we could find a way to programmatically determine a suitable
    adjective to modify the direct object. We’ll come back to that topic in [Chapter
    6](../Text/ch06.xhtml#ch06).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`question_type`被设置为`info`，我们在问题的开头加上“why” ➊。如果`question_type`变量设置为`yesno`
    ➋，我们在问题中的直接宾语前插入一个形容词来修饰它。在这个例子中，为了简单起见，我们硬编码了形容词。我们选择了形容词“red” ➌，它在某些句子中可能听起来有些奇怪。例如，我们可以说，“Do
    you want a red orange?”（你想要一个红色的橙子？），但不能说，“Do you want a red idea?”（你想要一个红色的想法？）。在这个聊天机器人的更好实现中，我们可以找到一种方法来编程确定适合的形容词来修饰直接宾语。我们将在[第六章](../Text/ch06.xhtml#ch06)中回到这个话题。
- en: Notice also that the algorithm used here assumes that a submitted sentence ends
    with a punctuation mark, such as “.” or “!”.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 另外需要注意的是，这里使用的算法假设提交的句子以标点符号结束，比如“.” 或 “!”。
- en: 'Now that we’ve defined all the functions, here is the main block of the script:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经定义了所有函数，以下是脚本的主块：
- en: '[PRE21]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: First, we check whether a user has passed a sentence in as a command line argument
    ➊. If a sentence has been submitted, we apply spaCy’s pipeline to it, creating
    a Doc object instance ➋.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们检查用户是否作为命令行参数传递了一个句子➊。若提交了句子，我们会将spaCy的处理管道应用于该句子，创建一个Doc对象实例➋。
- en: We then send the doc to the `find_chunk` function, which should return a noun
    chunk containing a direct object, such as “a green apple”, for further processing
    ➌. If there is no such noun chunk in the submitted sentence ➍, we’ll receive the
    message “The sentence does not contain a direct object.”
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将文档发送给`find_chunk`函数，该函数应该返回一个包含直接宾语的名词短语，例如“一个绿色的苹果”，以便进一步处理➌。如果提交的句子中没有这样的名词短语➍，我们将收到消息“该句子不包含直接宾语”。
- en: Next, we pass the chunk we just extracted to the `determine_question_type` function,
    which determines which question to ask based on the chunk’s structure ➎.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将刚刚提取的短语传递给`determine_question_type`函数，该函数根据短语的结构决定要提出什么问题➎。
- en: Finally, we pass the submitted sentence and the type of question to the `generate_question`
    function, which will generate an appropriate question and return it as a string
    ➏.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将提交的句子和问题类型传递给`generate_question`函数，该函数将生成一个适当的问题并将其作为字符串返回➏。
- en: 'The script’s output depends on the specific sentence submitted. Here are some
    possible variants:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本的输出取决于提交的具体句子。以下是一些可能的变体：
- en: '[PRE22]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: If we submit a sentence that contains an adjectival modifier, such as “green”
    for a direct object like “apple”, the script should generate an information question
    ➊.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们提交一个包含形容词修饰语的句子，例如“绿色”修饰直接宾语“苹果”，脚本应生成一个信息性问题➊。
- en: If the sentence contains a direct object without an adjectival modifier, the
    script should respond with a yes/no question ➋.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 如果句子包含没有形容词修饰语的直接宾语，脚本应返回一个是/否问题➋。
- en: If we submit a sentence with no direct object, the script should recognize this
    at once and ask us to resubmit ➌.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们提交一个没有直接宾语的句子，脚本应立即识别这一点并要求我们重新提交➌。
- en: Finally, if we forget to submit a sentence, the script should respond with an
    appropriate message ➍.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果我们忘记提交句子，脚本应返回一个适当的消息➍。
- en: '***Try This***'
  id: totrans-136
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***试试这个***'
- en: As noted earlier, the script discussed in the preceding section won’t work with
    all sentences. The script adds “do” to form a question, which works only with
    sentences that contain no auxiliary modal verb.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，上节中讨论的脚本并不适用于所有句子。该脚本通过添加“do”来构成问题，但只适用于不含助动词的句子。
- en: Enhance the functionality of this script so it can also work with statements
    containing modal auxiliary verbs. For example, given the following statement,
    “I might want a green apple,” the script should generate “Why might you want a
    green one?” For details on how to turn a statement containing a modal auxiliary
    verb into a question, refer to “[Turning Statements into Questions](../Text/ch04.xhtml#lev49)”
    on [page 51](../Text/ch04.xhtml#page_51).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 增强该脚本的功能，使其能够处理包含情态助动词的陈述句。例如，对于以下陈述句：“我可能想要一个绿色的苹果”，脚本应生成“你为什么可能想要一个绿色的苹果？”有关如何将包含情态助动词的陈述句转化为问题的详细信息，请参考[《将陈述句转化为问题》](../Text/ch04.xhtml#lev49)（见[第51页](../Text/ch04.xhtml#page_51)）。
- en: '**Summary**'
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**总结**'
- en: Linguistic features are at the heart of all NLP tasks. This chapter taught you
    some techniques for smart text processing and text generation with linguistic
    features. You learned how to extract phrases of a certain type (say, those that
    refer to an amount of money), and then wrote a script using dependency labels
    and part-of-speech tags that generated a meaningful response to the sentence submitted
    by a user.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 语言特征是所有NLP任务的核心。本章向你介绍了一些处理文本和生成文本的智能技术，运用了语言特征。你学会了如何提取某种类型的短语（例如，指代金额的短语），然后编写了一个使用依赖标签和词性标签的脚本，生成了对用户提交句子的有意义的回应。
- en: We’ll return to linguistic features in [Chapter 6](../Text/ch06.xhtml#ch06)
    where you’ll implement them in more complex scenarios.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[第6章](../Text/ch06.xhtml#ch06)中重新讨论语言特征，在那里你将把它们应用于更复杂的场景。

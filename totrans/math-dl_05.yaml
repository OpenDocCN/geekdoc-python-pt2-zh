- en: '**5'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**5'
- en: LINEAR ALGEBRA**
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 线性代数**
- en: '![image](Images/common.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/common.jpg)'
- en: Formally, linear algebra is the study of linear equations, in which the highest
    power of the variable is one. However, for our purposes, *linear algebra* refers
    to multidimensional mathematical objects—like vectors and matrices—and operations
    on them. This is how linear algebra is typically applied in deep learning, and
    how data is manipulated in programs that implement deep learning algorithms. By
    making this distinction, we are throwing away a massive amount of fascinating
    mathematics, but as our goal is to understand the mathematics used and applied
    in deep learning, we can hopefully be forgiven.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 从形式上讲，线性代数是研究线性方程的学科，其中变量的最高次幂为一。然而，就我们的目的而言，*线性代数*指的是多维数学对象——如向量和矩阵——以及对它们进行的运算。这就是线性代数在深度学习中的典型应用方式，以及在实现深度学习算法的程序中如何操作数据。通过做出这个区分，我们舍弃了大量令人着迷的数学内容，但由于我们的目标是理解深度学习中使用和应用的数学，希望能够得到谅解。
- en: In this chapter, I’ll introduce the objects used in deep learning, specifically
    scalars, vectors, matrices, and tensors. As we’ll see, all of these objects are
    actually tensors of various orders. We’ll discuss tensors from a mathematical,
    notational perspective and then experiment with them using NumPy. NumPy was explicitly
    designed to add multidimensional arrays to Python, and they are good, though incomplete,
    analogues for the mathematical objects we’ll work with in this chapter.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我将介绍深度学习中使用的对象，特别是标量、向量、矩阵和张量。正如我们所看到的，这些对象实际上都是不同阶数的张量。我们将从数学符号的角度讨论张量，然后使用NumPy进行实验。NumPy显式设计用于将多维数组引入Python，它们是我们将在本章中处理的数学对象的良好（但不完全）类比。
- en: We’ll spend the bulk of the chapter learning how to do arithmetic with tensors,
    which is of fundamental importance in deep learning. Most of the effort in implementing
    highly performant deep learning toolkits involves finding ways to do arithmetic
    with tensors as efficiently as possible.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的重点将是学习如何对张量进行算术运算，这是深度学习中的基础内容。实现高性能深度学习工具包的主要工作涉及寻找尽可能高效地对张量进行算术运算的方法。
- en: Scalars, Vectors, Matrices, and Tensors
  id: totrans-6
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 标量、向量、矩阵和张量
- en: Let’s introduce our cast of characters. I’ll relate them to Python variables
    and NumPy arrays to show how we’ll implement these objects in code. Then I’ll
    present a handy conceptual mapping between tensors and geometry.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来介绍一下这些角色。我将它们与Python变量和NumPy数组进行关联，展示我们如何在代码中实现这些对象。接着，我会呈现一个张量和几何之间的概念性映射。
- en: Scalars
  id: totrans-8
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 标量
- en: 'Even if you’re not familiar with the word, you’ve known what a scalar is since
    the day you first learned to count. A *scalar* is just a number, like 7, 42, or
    π. In expressions, we’ll use *x* to mean a scalar, that is, the ordinary notation
    used for variables. To a computer, a scalar is a simple numeric variable:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 即使你不熟悉这个词，你从第一次学会数数那天起就已经知道什么是标量了。*标量*就是一个数字，如7、42或π。在表达式中，我们将使用* x *来表示标量，也就是用于变量的常规符号。对于计算机来说，标量是一个简单的数值变量：
- en: '>>> s = 66'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> s = 66'
- en: '>>> s'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> s'
- en: '66'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '66'
- en: Vectors
  id: totrans-13
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 向量
- en: A *vector* is a 1D array of numbers. Mathematically, a vector has an orientation,
    either horizontal or vertical. If horizontal, it’s a *row vector*. For example,
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '*向量*是一个一维的数字数组。从数学角度看，向量有一个方向，要么是水平的，要么是垂直的。如果是水平的，它就是一个*行向量*。例如，'
- en: '![Image](Images/05equ01.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/05equ01.jpg)'
- en: is a row vector of three elements or components. Note, we’ll use *x*, a lowercase
    letter in bold, to mean a vector.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 是一个包含三个元素或分量的行向量。请注意，我们将使用**x**，一个小写的粗体字母，表示一个向量。
- en: Mathematically, vectors are usually assumed to be *column vectors*,
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学角度看，向量通常被假定为*列向量*，
- en: '![Image](Images/05equ02.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/05equ02.jpg)'
- en: where ***y*** has four components, making it a four-dimensional (4D) vector.
    Notice that in [Equation 5.1](ch05.xhtml#ch05equ01) we used square brackets, whereas
    in [Equation 5.2](ch05.xhtml#ch05equ02) we used parentheses. Either notation is
    acceptable.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 其中***y***有四个分量，使其成为一个四维（4D）向量。请注意，在[方程式 5.1](ch05.xhtml#ch05equ01)中，我们使用了方括号，而在[方程式
    5.2](ch05.xhtml#ch05equ02)中我们使用了圆括号。两种符号都可以接受。
- en: 'In code, we usually implement vectors as 1D arrays:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码中，我们通常将向量实现为一维数组：
- en: '>>> import numpy as np'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> import numpy as np'
- en: '>>> x = np.array([1,2,3])'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> x = np.array([1,2,3])'
- en: '>>> print(x)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(x)'
- en: '[1 2 3]'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[1 2 3]'
- en: '>>> print(x.reshape((3,1)))'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(x.reshape((3,1)))'
- en: '[[1]'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[[1]'
- en: '[2]'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '[2]'
- en: '[3]]'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '[3]]'
- en: Here, we’ve used reshape to turn the three-element row vector into a column
    vector of three rows and one column.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，我们使用reshape将包含三个元素的行向量转换成一个三行一列的列向量。
- en: The components of a vector are often interpreted as lengths along a set of coordinate
    axes. For example, a three-component vector might be used to represent a point
    in 3D space. In this vector,
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 向量的分量通常被解释为沿着一组坐标轴的长度。例如，一个三分量的向量可以用来表示三维空间中的一个点。在这个向量中，
- en: '***x*** = [*x*, *y*, *z*]'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '***x*** = [*x*, *y*, *z*]'
- en: '*x* could be the length along the x-axis, *y* the length along the y-axis,
    and *z* the length along the z-axis. These are the Cartesian coordinates and serve
    to uniquely identify all points in 3D space.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '*x* 可能是沿 x 轴的长度，*y* 是沿 y 轴的长度，*z* 是沿 z 轴的长度。这些是笛卡尔坐标，用来唯一标识三维空间中的所有点。'
- en: However, in deep learning, and machine learning in general, the components of
    a vector are often unrelated to each other in any strict geometric sense. Rather,
    they’re used to represent *features*, qualities of some sample that the model
    will use to attempt to arrive at a useful output, like a class label, or a regression
    value. That said, the vector representing the collection of features, called the
    *feature vector*, is sometimes thought about geometrically. For example, some
    machine learning models, like *k*-nearest neighbors, interpret the vector as representing
    some coordinate in geometric space.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在深度学习以及机器学习中，向量的分量通常在几何意义上互不相关。相反，它们用于表示*特征*，即模型将用来尝试得到有用输出（如类别标签或回归值）的一些样本的性质。也就是说，表示特征集合的向量，称为*特征向量*，有时会从几何角度进行思考。例如，一些机器学习模型，如*k*近邻算法，将向量解释为几何空间中的某个坐标。
- en: You’ll often hear deep learning people discuss the *feature space* of a problem.
    The feature space refers to the set of possible inputs. The training set for a
    model needs to accurately represent the feature space of the possible inputs the
    model will encounter when used. In this sense, the feature vector is a point,
    a location in this *n*-dimensional space where *n* is the number of features in
    the feature vector.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 你常常会听到深度学习领域的人讨论一个问题的*特征空间*。特征空间是指可能输入的集合。模型的训练集需要准确地代表模型在使用时可能遇到的特征空间。在这个意义上，特征向量是一个点，位于这个*n*维空间中，*n*是特征向量中的特征数量。
- en: Matrices
  id: totrans-35
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 矩阵
- en: 'A *matrix* is a 2D array of numbers:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '*矩阵* 是一个二维的数字数组：'
- en: '![Image](Images/105equ01.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![Image](Images/105equ01.jpg)'
- en: The elements of ***A*** are subscripted by the row number and column number.
    The matrix ***A*** has three rows and four columns, so we say that it’s a 3 ×
    4 matrix, where 3 × 4 is the *order* of the matrix. Notice that ***A*** uses subscripts
    starting with 0\. Math texts often begin with 1, but increasingly, they’re using
    0 so that there isn’t an offset between the math notation and the computer representation
    of the matrix. Note, also, that we’ll use ***A***, an uppercase letter in bold,
    to mean a matrix.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '***A*** 的元素通过行号和列号进行下标表示。矩阵 ***A*** 有三行四列，所以我们说它是一个 3 × 4 的矩阵，其中 3 × 4 是矩阵的*阶*。注意，***A***
    的下标从 0 开始。数学书籍通常从 1 开始，但越来越多的数学书籍使用 0，这样就不会出现数学符号和计算机表示之间的偏差。还要注意，我们将使用***A***，一个粗体大写字母，来表示一个矩阵。'
- en: 'In code, matrices are represented as 2D arrays:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码中，矩阵表示为二维数组：
- en: '>>> A = np.array([[1,2,3],[4,5,6],[7,8,9]])'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> A = np.array([[1,2,3],[4,5,6],[7,8,9]])'
- en: '>>> print(A)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(A)'
- en: '[[1 2 3]'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '[[1 2 3]'
- en: '[4 5 6]'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[4 5 6]'
- en: '[7 8 9]]'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '[7 8 9]]'
- en: '>>> print(np.arange(12).reshape((3,4)))'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(np.arange(12).reshape((3,4)))'
- en: '[[ 0 1 2 3]'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[[ 0 1 2 3]'
- en: '[ 4 5 6 7]'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[ 4 5 6 7]'
- en: '[ 8 9 10 11]]'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '[ 8 9 10 11]]'
- en: To get element *a*[12] of ***A*** in Python, we write A[1,2]. Notice that when
    we printed the arrays, there was an extra [ and ] around them. NumPy uses these
    brackets to indicate that the 2D array can be thought of as a row vector in which
    each element is itself a vector. In Python-speak, this means that a matrix can
    be thought of as a list of sublists in which each sublist is of the same length.
    Of course, this is exactly how we defined A to begin with.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 Python 中获取矩阵 ***A*** 的元素 *a*[12]，我们写 A[1,2]。注意，当我们打印数组时，它们周围多了一个 [ 和 ]。NumPy
    使用这些括号来表示二维数组可以被视为一个行向量，其中每个元素本身就是一个向量。在 Python 术语中，这意味着矩阵可以被看作是一个子列表的列表，其中每个子列表的长度相同。当然，这正是我们最初定义
    A 的方式。
- en: 'We can think of vectors as matrices with a single row or column. A column vector
    with three elements is a 3 × 1 matrix: it has three rows and one column. Similarly,
    a row vector of four elements acts like a 1 × 4 matrix: it has one row and four
    columns. We’ll make use of this observation later.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将向量看作是具有单行或单列的矩阵。例如，一个包含三个元素的列向量是一个3 × 1的矩阵：它有三行一列。类似地，一个包含四个元素的行向量相当于一个1
    × 4的矩阵：它有一行四列。我们稍后会用到这个观察结果。
- en: Tensors
  id: totrans-51
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 张量
- en: 'A scalar has no dimensions, a vector has one, and a matrix has two. As you
    might suspect, we don’t need to stop there. A mathematical object with more than
    two dimensions is colloquially referred to as a *tensor*. When necessary, we’ll
    represent tensors like this: T, as a sans serif capital letter.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 标量没有维度，向量有一维，矩阵有二维。正如你可能猜到的，我们不止于此。一个具有超过两维的数学对象通常被称为*张量*。在必要时，我们会用T表示张量，T是一个无衬线的大写字母。
- en: The number of dimensions a tensor has defines its *order*, which is not to be
    confused with the order of a matrix. A 3D tensor has order 3\. A matrix is a tensor
    of order 2\. A vector is an order-1 tensor, and a scalar is an order-0 tensor.
    When we discuss the flow of data through a deep neural network in [Chapter 9](ch09.xhtml#ch09),
    we’ll see that many toolkits use tensors of order 4 (or more).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 张量的维度数量定义了它的*阶*，这与矩阵的阶不同。一个三维张量的阶是3，一个矩阵是阶为2的张量，一个向量是阶为1的张量，一个标量是阶为0的张量。当我们在[第9章](ch09.xhtml#ch09)讨论深度神经网络中的数据流时，我们会看到许多工具包使用阶为4（或更高）的张量。
- en: 'In Python, NumPy arrays with three or more dimensions are used to implement
    tensors. For example, we can define an order-3 tensor in Python as shown below:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python中，具有三维或更多维的NumPy数组用于实现张量。例如，我们可以如下定义一个阶为3的张量：
- en: '>>> t = np.arange(36).reshape((3,3,4))'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> t = np.arange(36).reshape((3,3,4))'
- en: '>>> print(t)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(t)'
- en: '[[[ 0 1 2 3]'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[[[ 0 1 2 3]'
- en: '[ 4 5 6 7]'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[ 4 5 6 7]'
- en: '[ 8 9 10 11]]'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[ 8 9 10 11]]'
- en: '[[12 13 14 15]'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[[12 13 14 15]'
- en: '[16 17 18 19]'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[16 17 18 19]'
- en: '[20 21 22 23]]'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[20 21 22 23]]'
- en: '[[24 25 26 27]'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[[24 25 26 27]'
- en: '[28 29 30 31]'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[28 29 30 31]'
- en: '[32 33 34 35]]]'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[32 33 34 35]]]'
- en: 'Here, we use np.arange to define t to be a vector of 36 elements holding the
    numbers 0 . . . 35\. Then, we immediately reshape the vector into a tensor of
    3 × 3 × 4 elements (3 × 3 × 4 = 36). One way to think of a 3 × 3 × 4 tensor is
    that it contains a stack of three 3 × 4 images. If we keep this in mind, the following
    statements make sense:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用np.arange定义t为一个包含36个元素的向量，元素值为0到35。然后，我们立即将该向量重塑为一个包含3 × 3 × 4个元素的张量（3
    × 3 × 4 = 36）。一种理解3 × 3 × 4张量的方式是，它包含三张3 × 4的图像。如果我们记住这一点，接下来的陈述就能理解了：
- en: '>>> print(t[0])'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(t[0])'
- en: '[[ 0 1 2 3]'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[[ 0 1 2 3]'
- en: '[ 4 5 6 7]'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[ 4 5 6 7]'
- en: '[ 8 9 10 11]]'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '[ 8 9 10 11]]'
- en: '>>> print(t[0,1])'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(t[0,1])'
- en: '[4 5 6 7]'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[4 5 6 7]'
- en: '>>> print(t[0,1,2])'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(t[0,1,2])'
- en: '6'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '6'
- en: Asking for t[0] will return the first 3 × 4 *image* in the stack. Asking for
    t[0,1], then, should return the second row of the first image, which it does.
    Finally, we get to an individual element of t by asking for the image number (0),
    the row number (1), and the element of that row (2).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 请求t[0]将返回堆栈中的第一张3 × 4*图像*。接着，t[0,1]应该返回第一张图像的第二行，正如它所做的那样。最后，我们通过请求图像编号（0），行编号（1）和该行的元素（2）来得到t的一个单独元素。
- en: 'Assigning the dimensions of a tensor to successively smaller collections of
    something is a handy way to keep the meaning of the dimensions in mind. For example,
    we can define an order-5 tensor like so:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 将张量的维度分配给一个个越来越小的集合，是帮助记住维度含义的一种有效方式。例如，我们可以这样定义一个阶为5的张量：
- en: '>>> w = np.zeros((9,9,9,9,9))'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> w = np.zeros((9,9,9,9,9))'
- en: '>>> w[4,1,2,0,1]'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> w[4,1,2,0,1]'
- en: '0.0'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '0.0'
- en: But, what does asking for w[4,1,2,0,1] mean? The exact meaning depends on the
    application. For example, we might think of w as representing a bookcase. The
    first index selects the shelf, and the second selects the book on the shelf. Then,
    the third index selects the page within the book, and the fourth selects the line
    on the page. The final index selects the word on the line. Therefore, w[4,1,2,0,1]
    is asking for the second word of the first line of the third page of the second
    book on the fifth shelf of the bookcase, understood by reading the indices from
    right to left.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，w[4,1,2,0,1]意味着什么呢？其确切含义取决于应用场景。例如，我们可能将w看作表示一个书架。第一个索引选择书架的层，第二个索引选择书架上的书籍。然后，第三个索引选择书中的页面，第四个索引选择页面上的行。最后一个索引选择行上的单词。因此，w[4,1,2,0,1]是在询问书架第五层上的第二本书的第三页中的第一行的第二个单词，这个含义是从右到左读索引来理解的。
- en: The bookcase analogy does have its limitations. NumPy arrays have fixed dimensions,
    meaning that if w is a bookcase, there are nine shelves, and each shelf has *exactly*
    nine books. Likewise, each book has exactly nine pages, and each page has nine
    lines. Finally, each line has precisely nine words. NumPy arrays ordinarily use
    contiguous memory in the computer, so the size of each dimension is fixed when
    the array is defined. Doing so, and selecting the specific data type, like unsigned
    integer, makes locating an element of the array an indexing operation using a
    simple formula to compute an offset from a base memory address. This is what makes
    NumPy arrays so much faster than Python lists.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 书架类比确实有它的局限性。NumPy 数组有固定的维度，这意味着如果 w 是一个书架，那么它有九个架子，每个架子上有 *恰好* 九本书。同样，每本书有
    *恰好* 九页，每一页有九行。最后，每行恰好有九个单词。NumPy 数组通常使用计算机中的连续内存，因此当数组被定义时，每个维度的大小是固定的。这样做并选择特定的数据类型，比如无符号整数，可以使得定位数组的一个元素变成通过简单公式从基址内存地址计算偏移量的索引操作。这就是为什么
    NumPy 数组比 Python 列表要快得多。
- en: Any tensor of less than order *n* can be represented as an order-*n* tensor
    by supplying the missing dimensions of length one. We saw an example of this above
    when I said that an *m*-component vector could be thought of as a 1 × *m* or an
    *m* × 1 matrix. The order-1 tensor (the vector) is turned into an order-2 tensor
    (matrix) by adding a missing dimension of length one.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 任何小于 *n* 阶的张量都可以通过补充缺失的长度为一的维度来表示为 *n* 阶张量。我们在上面看到过一个例子，当我说一个 *m* 分量的向量可以被视为一个
    1 × *m* 或 *m* × 1 的矩阵时，就是这个情况。通过添加一个缺失的长度为一的维度，1阶张量（向量）被转化为2阶张量（矩阵）。
- en: 'As an extreme example, we can treat a scalar (order-0 tensor) as an order-5
    tensor, like this:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个极端例子，我们可以将一个标量（0阶张量）视为一个5阶张量，像这样：
- en: '>>> t = np.array(42).reshape((1,1,1,1,1))'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> t = np.array(42).reshape((1,1,1,1,1))'
- en: '>>> print(t)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(t)'
- en: '[[[[[42]]]]]'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[[[[[42]]]]]'
- en: '>>> t.shape'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> t.shape'
- en: (1, 1, 1, 1, 1)
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: (1, 1, 1, 1, 1)
- en: '>>> t[0,0,0,0,0]'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> t[0,0,0,0,0]'
- en: '42'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '42'
- en: 'Here, we reshape the scalar 42 into an order-5 tensor (a five-dimensional [5D]
    array) with length one on each axis. Notice that NumPy tells us that the tensor
    t has five dimensions with the [[[[[ and ]]]]] around 42. Asking for the shape
    of t confirms that it is a 5D tensor. Finally, as a tensor, we can get the value
    of the single element it contains by specifying all the dimensions with t[0,0,0,0,0].
    We’ll often use this trick of adding new dimensions of length one. In fact, in
    NumPy, there is a way to do this directly, which you’ll see when using deep learning
    toolkits:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将标量 42 重新塑造为一个 5 阶张量（一个五维 [5D] 数组），每个轴的长度为一。注意，NumPy 告诉我们，张量 t 具有五个维度，周围有
    [[[[[ 和 ]]]]]。请求 t 的形状确认它是一个 5D 张量。最后，作为张量，我们可以通过指定 t[0,0,0,0,0] 来获取它包含的单个元素的值。我们经常会使用这种添加新维度的技巧。实际上，在
    NumPy 中，有一种方法可以直接做到这一点，你会在使用深度学习工具包时看到：
- en: '>>> t = np.array([[1,2,3],[4,5,6]])'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> t = np.array([[1,2,3],[4,5,6]])'
- en: '>>> print(t)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(t)'
- en: '[[1 2 3]'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '[[1 2 3]'
- en: '[4 5 6]]'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '[4 5 6]]'
- en: '>>> w = t[np.newaxis,:,:]'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> w = t[np.newaxis,:,:]'
- en: '>>> w.shape'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> w.shape'
- en: (1, 2, 3)
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: (1, 2, 3)
- en: '>>> print(w)'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(w)'
- en: '[[[1 2 3]'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[[[1 2 3]'
- en: '[4 5 6]]]'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '[4 5 6]]]'
- en: Here, we’ve turned t, an order-2 tensor (a matrix), into an order-3 tensor by
    using np.newaxis to create a new axis of length one. That’s why w.shape returns
    (1,2,3) and not (2,3), as it would for t.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们通过使用 np.newaxis 创建一个新的长度为一的轴，将 t（一个2阶张量，矩阵）转化为一个3阶张量。这就是为什么 w.shape 返回
    (1,2,3) 而不是 (2,3)，如同 t 那样。
- en: 'There are analogues between tensors up to order-3 and geometry that are helpful
    in visualizing the relationships between the different orders:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 张量与几何之间有一些类比，这有助于可视化不同阶张量之间的关系：
- en: '| **Order (dimensions)** | **Tensor name** | **Geometric name** |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| **阶数（维度）** | **张量名称** | **几何名称** |'
- en: '| --- | --- | --- |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 0 | Scalar | Point |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 标量 | 点 |'
- en: '| 1 | Vector | Line |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 向量 | 直线 |'
- en: '| 2 | Matrix | Plane |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 矩阵 | 平面 |'
- en: '| 3 | Tensor | Volume |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 张量 | 体积 |'
- en: Notice, I used *tensor* in its common sense in the table. There seems to be
    no standardized name for an order-3 tensor.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在表格中我使用了 *张量* 这个术语的常见含义。似乎没有统一的名称来表示一个3阶张量。
- en: In this section, we defined the mathematical objects of deep learning in relation
    to multidimensional arrays, since that’s how they are implemented in code. We’ve
    thrown away a lot of mathematics by doing this, but we’ve preserved what we need
    to understand deep learning. Let’s move on now and see how to use tensors in expressions.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，我们将深度学习的数学对象与多维数组相关联，因为它们在代码中的实现方式就是这样。通过这样做，我们丢弃了很多数学内容，但保留了理解深度学习所需的部分。接下来我们继续，看看如何在表达式中使用张量。
- en: Arithmetic with Tensors
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 张量运算
- en: The purpose of this section is to detail operations on tensors, with special
    emphasis on tensors of order-1 (vectors) and order-2 (matrices). We’ll assume
    operations with scalars are well in hand at this point.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的目的是详细说明张量的操作，特别强调1阶张量（向量）和2阶张量（矩阵）。我们假设此时标量的操作已经很熟悉。
- en: We’ll start with what I’m calling *array operations*, by which I mean the element-wise
    operations that toolkits like NumPy perform on arrays of all dimensions. Then
    we’ll move on to operations particular to vectors. This sets the stage for the
    critical topic of matrix multiplication. Finally, we’ll discuss block matrices.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从我称之为*数组操作*的内容开始，这指的是工具包如NumPy在所有维度的数组上执行的逐元素操作。然后我们将进入向量特有的操作。这为矩阵乘法这一关键主题奠定了基础。最后，我们将讨论块矩阵。
- en: Array Operations
  id: totrans-115
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数组操作
- en: The way we’ve used the NumPy toolkit so far has shown us that all the normal
    scalar arithmetic operations translate directly into the world of multidimensional
    arrays. This includes standard operations like addition, subtraction, multiplication,
    division, and exponentiation, as well as the application of functions to an array.
    In all of these cases, the scalar operation is applied element-wise to each element
    of the array. The examples here will set the tone for the rest of this section
    and will also let us explore some NumPy broadcasting rules that we haven’t called
    out yet.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们使用NumPy工具包的方式向我们展示了，所有正常的标量算术运算都可以直接转化为多维数组的运算。这包括标准的加法、减法、乘法、除法和指数运算，以及对数组应用函数。在所有这些情况下，标量操作都是逐元素应用到数组的每个元素上的。这里的示例为本节的其余部分定下了基调，也让我们探索了一些尚未提及的NumPy广播规则。
- en: 'Let’s first define some arrays to work with:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先定义一些数组来操作：
- en: '>>> a = np.array([[1,2,3],[4,5,6]])'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> a = np.array([[1,2,3],[4,5,6]])'
- en: '>>> b = np.array([[7,8,9],[10,11,12]])'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> b = np.array([[7,8,9],[10,11,12]])'
- en: '>>> c = np.array([10,100,1000])'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> c = np.array([10,100,1000])'
- en: '>>> d = np.array([10,11])'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> d = np.array([10,11])'
- en: '>>> print(a)'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(a)'
- en: '[[1 2 3]'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '[[1 2 3]'
- en: '[4 5 6]]'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '[4 5 6]]'
- en: '>>> print(b)'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(b)'
- en: '[[ 7 8 9]'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '[[ 7 8 9]'
- en: '[10 11 12]]'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[10 11 12]]'
- en: '>>> print(c)'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(c)'
- en: '[  10 100 1000]'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '[ 10 100 1000]'
- en: '>>> print(d)'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(d)'
- en: '[10 11]'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '[10 11]'
- en: 'Element-wise arithmetic is straightforward for arrays with dimensions that
    match:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 对于维度匹配的数组，逐元素的算术运算是直接的：
- en: '>>> print(a+b)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(a+b)'
- en: '[[ 8 10 12]'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '[[ 8 10 12]'
- en: '[14 16 18]]'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '[14 16 18]]'
- en: '>>> print(a-b)'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(a-b)'
- en: '[[-6 -6 -6]'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '[[-6 -6 -6]'
- en: '[-6 -6 -6]]'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '[-6 -6 -6]]'
- en: '>>> print(a*b)'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(a*b)'
- en: '[[ 7 16 27]'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '[[ 7 16 27]'
- en: '[40 55 72]]'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '[40 55 72]]'
- en: '>>> print(a/b)'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(a/b)'
- en: '[[0.14285714 0.25       0.33333333]'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '[[0.14285714 0.25 0.33333333]'
- en: '[0.4        0.45454545 0.5       ]]'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '[0.4 0.45454545 0.5 ]]'
- en: '>>> print(b**a)'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(b**a)'
- en: '[[       7       64      729]'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '[[ 7 64 729]'
- en: '[   10000   161051  2985984]]'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '[ 10000 161051 2985984]]'
- en: These results are all easy enough to interpret; NumPy applies the desired operation
    to the corresponding elements of each array. Element-wise multiplication on two
    matrices (a and b) is often known as the *Hadamard product*. (You’ll encounter
    this term from time to time in the deep learning literature.)
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果都足够简单，容易解释；NumPy将所需的操作应用于每个数组的相应元素。对两个矩阵（a 和 b）进行逐元素相乘通常被称为*哈达玛积*。（你在深度学习文献中时常会遇到这个术语。）
- en: The NumPy toolkit extends the idea of element-wise operations into what it calls
    *broadcasting*. When broadcasting, NumPy applies rules, which we’ll see via examples,
    where one array is passed over another to produce a meaningful output.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy工具包将逐元素操作的概念扩展到它所称的*广播*。在广播过程中，NumPy应用一些规则，接下来我们将通过示例看到这些规则，规则是将一个数组应用到另一个数组上，从而生成有意义的输出。
- en: We’ve already encountered a form of broadcasting when operating on an array
    with a scalar. In that case, the scalar value was broadcast to every value of
    the array.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们对一个数组与标量进行操作时，已经遇到过一种形式的广播。在这种情况下，标量值会广播到数组的每个值。
- en: 'For our first example, even though a is a 2 × 3 matrix, NumPy allows operations
    on it with c, a three-component vector, by applying broadcasting:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的第一个示例，尽管a是一个2 × 3的矩阵，NumPy允许通过广播将其与一个包含三个分量的向量c进行操作：
- en: '>>> print(a+c)'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(a+c)'
- en: '[[  11  102 1003]'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '[[ 11 102 1003]'
- en: '[  14  105 1006]]'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '[ 14 105 1006]]'
- en: '>>> print(c*a)'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(c*a)'
- en: '[[  10 200 3000]'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '[[ 10 200 3000]'
- en: '[  40 500 6000]]'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '[ 40 500 6000]]'
- en: '>>> print(a/c)'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(a/c)'
- en: '[[0.1  0.02  0.003]'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '[[0.1 0.02 0.003]'
- en: '[0.4  0.05  0.006]]'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '[0.4 0.05 0.006]]'
- en: Here, the three-component vector, c, has been broadcast over the rows of the
    2 × 3 matrix, a. NumPy recognized that the last dimensions of a and c were both
    three, so the vector could be passed over the matrix to produce the given output.
    When looking at deep learning code, much of which is in Python, you’ll see situations
    like this. At times, some thought is necessary, along with some experimentation
    at the Python prompt, to understand what’s happening.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，三维向量 c 被广播到了 2 × 3 矩阵 a 的行上。NumPy 识别到 a 和 c 的最后一个维度都是三，所以该向量可以广播到矩阵上，得到预期的输出。当你查看深度学习代码时，很多代码都是
    Python 编写的，你会遇到类似的情况。此时，有时需要一些思考，配合在 Python 提示符下的实验，才能理解发生了什么。
- en: 'Can we broadcast d, a two-component vector, over a, a 2 × 3 matrix? If we try
    to do so the same way we broadcast c over a, we’ll fail:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们能否将 d 这个二维向量广播到 a 这个 2 × 3 的矩阵上？如果我们尝试以相同的方式将 c 广播到 a 上，我们会失败：
- en: '>>> print(a+d)'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(a+d)'
- en: 'Traceback (most recent call last):'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 'Traceback (most recent call last):'
- en: File "<stdin>", line 1, in <module>
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 文件 "<stdin>", 第 1 行，位于 <module>
- en: 'ValueError: operands could not be broadcast together with shapes (2,3) (2,)'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 'ValueError: 操作数无法在形状 (2,3) 和 (2,) 上广播。'
- en: 'However, the broadcasting rules for NumPy accommodate dimensions of length
    one. The shape of d is 2; it’s a two-element vector. If we reshape d so that it’s
    a 2D array with shape 2 × 1, we’ll give NumPy what it needs:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，NumPy 的广播规则适用于长度为 1 的维度。d 的形状是 2；它是一个包含两个元素的向量。如果我们将 d 重塑为一个 2D 数组，形状为 2
    × 1，那么我们就给 NumPy 提供了它所需要的格式：
- en: '>>> d = d.reshape((2,1))'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> d = d.reshape((2,1))'
- en: '>>> d.shape'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> d.shape'
- en: (2, 1)
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: (2, 1)
- en: '>>> print(a+d)'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(a+d)'
- en: '[[11 12 13]'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '[[11 12 13]'
- en: '[15 16 17]]'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '[15 16 17]]'
- en: We now see that Numpy has added d across the columns of a.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在看到 Numpy 已经将 d 加到了 a 的列上。
- en: Let’s return to the world of mathematics and look at operations on vectors.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到数学的世界，看看向量上的运算。
- en: Vector Operations
  id: totrans-176
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 向量运算
- en: Vectors are represented in code as a collection of numbers that can be interpreted
    as values along a set of coordinate axes. Here, we’ll define several operations
    that are unique to vectors.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 向量在代码中表示为一组数字，可以解释为沿着一组坐标轴的数值。在这里，我们将定义一些只适用于向量的运算。
- en: Magnitude
  id: totrans-178
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 长度
- en: Geometrically, we can understand vectors as having a direction and a length.
    They’re often drawn as arrows, and we’ll see an example of a vector plot in [Chapter
    6](ch06.xhtml#ch06). People speak of the length of a vector as its *magnitude*.
    Therefore, the first vector operation we’ll consider is calculating its magnitude.
    For a vector, ***x***, with *n* components, the formula for its magnitude is
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在几何上，我们可以将向量理解为具有方向和长度的量。它们通常被画成箭头，我们将在 [第 6 章](ch06.xhtml#ch06) 中看到一个向量图的例子。人们常说向量的长度是它的
    *大小*。因此，我们将首先考虑的向量运算是计算其大小。对于一个具有 *n* 个分量的向量 ***x***，其大小的公式是
- en: '![Image](Images/05equ03.jpg)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![Image](Images/05equ03.jpg)'
- en: In [Equation 5.3](ch05.xhtml#ch05equ03), the double vertical bars around the
    vector represent its magnitude. You’ll often see people use single bars here as
    well. Single bars are also used for absolute value; we usually rely on context
    to tell the difference between the two.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [方程 5.3](ch05.xhtml#ch05equ03) 中，围绕向量的双竖线表示它的大小。你也经常看到有人使用单竖线。单竖线也用于表示绝对值；我们通常依赖上下文来判断这两者之间的区别。
- en: Where did [Equation 5.3](ch05.xhtml#ch05equ03) come from? Consider a vector
    in 2D, ***x*** = (*x*, *y*). If *x* and *y* are lengths along the x-axis and y-axis,
    respectively, we see that *x* and *y* form the sides of a right triangle. The
    length of the hypotenuse of this right triangle is the length of the vector. Therefore,
    according to Pythagoras, and the Babylonians long before him, this length is ![Image](Images/112equ01.jpg),
    which, generalized to *n* dimensions, becomes [Equation 5.3](ch05.xhtml#ch05equ03).
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '[方程 5.3](ch05.xhtml#ch05equ03)从哪里来的？考虑一个二维向量，***x*** = (*x*, *y*)。如果 *x* 和
    *y* 分别是 x 轴和 y 轴上的长度，我们可以看到 *x* 和 *y* 形成了一个直角三角形的两条边。这个直角三角形的斜边长度就是向量的长度。因此，根据毕达哥拉斯定理，以及早在他之前的巴比伦人，这个长度是
    ![Image](Images/112equ01.jpg)，将其推广到 *n* 维后，得到的就是 [方程 5.3](ch05.xhtml#ch05equ03)。'
- en: Unit Vectors
  id: totrans-183
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 单位向量
- en: Now that we can calculate the magnitude of a vector, we can introduce a useful
    form of a vector known as a *unit vector*. If we divide the components of a vector
    by its magnitude, we’re left with a vector that points in the same direction as
    the original vector but has a magnitude of one. This is the unit vector. For a
    vector, ***v***, the unit vector in the same direction is
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以计算向量的大小，接下来我们引入一个有用的向量形式，称为 *单位向量*。如果我们将一个向量的分量除以它的大小，我们就得到一个方向与原向量相同，但大小为一的单位向量。这就是单位向量。对于一个向量
    ***v***，与其方向相同的单位向量是
- en: '![Image](Images/112equ02.jpg)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![Image](Images/112equ02.jpg)'
- en: where the hat over the vector serves to identify it as a unit vector. Let’s
    see a concrete example. Our example vector is ***v*** = (2, –4,3). Therefore,
    the unit vector in the same direction as ***v*** is
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，向量上方的帽子标记表示它是一个单位向量。让我们看一个具体的例子。我们的示例向量是 ***v*** = (2, –4,3)。因此，方向与 ***v***
    相同的单位向量是
- en: '![Image](Images/112equ03.jpg)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![Image](Images/112equ03.jpg)'
- en: 'In code, we calculate the unit vector as the following:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码中，我们通过以下方式计算单位向量：
- en: '>>> v = np.array((2, -4, 3))'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> v = np.array((2, -4, 3))'
- en: '>>> u = v / np.sqrt((v*v).sum())'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> u = v / np.sqrt((v*v).sum())'
- en: '>>> print(u)'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(u)'
- en: '[ 0.37139068 -0.74278135 0.55708601 ]'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '[ 0.37139068 -0.74278135 0.55708601 ]'
- en: Here, we make use of the fact that to square each element of v, we multiply
    it by itself, element-wise, and then add the components together by calling sum
    to get the magnitude squared.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们利用了这样的事实：要平方 v 的每个元素，我们将其与自身逐元素相乘，然后通过调用 sum 将各个分量加在一起，得到平方的大小。
- en: Vector Transpose
  id: totrans-194
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 向量转置
- en: We mentioned earlier that row vectors can be thought of as 1 × *n* matrices,
    while column vectors are *n* × 1 matrices. The act of changing a row vector into
    a column vector and vice versa is known as taking the *transpose*. We’ll see in
    [Chapter 6](ch06.xhtml#ch06) that the transpose also applies to matrices. Notationally,
    we denote the vector transpose of ***y*** as ***y***^⊤. Therefore, we have
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前提到过，行向量可以被看作是 1 × *n* 的矩阵，而列向量是 *n* × 1 的矩阵。将行向量转换为列向量，反之亦然，称为取 *转置*。我们将在[第六章](ch06.xhtml#ch06)中看到转置同样适用于矩阵。在符号表示上，我们用
    ***y***^⊤ 来表示向量 ***y*** 的转置。因此，我们有
- en: '![Image](Images/113equ01.jpg)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![Image](Images/113equ01.jpg)'
- en: Of course, we’re not limited to just three components.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们不仅仅局限于三个分量。
- en: 'In code, we transpose vectors in several ways. As we saw above, we can use
    reshape to reshape the vector into a 1 × *n* or *n* × 1 matrix. We can also call
    the transpose method on the vector, with some care, or use the transpose shorthand.
    Let’s see examples of all of these approaches. First, let’s define a NumPy vector
    and see how reshape turns it into a 3 × 1 column vector and a 1 × 3 row vector,
    as opposed to a plain vector of three elements:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码中，我们可以通过几种方式转置向量。如上所示，我们可以使用 reshape 将向量重塑为 1 × *n* 或 *n* × 1 的矩阵。我们也可以谨慎地调用转置方法，或者使用转置的简写。让我们来看所有这些方法的示例。首先，我们定义一个
    NumPy 向量，看看 reshape 如何将它转换为 3 × 1 的列向量和 1 × 3 的行向量，而不是普通的三元素向量：
- en: '>>> v = np.array([1,2,3])'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> v = np.array([1,2,3])'
- en: '>>> print(v)'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(v)'
- en: '[1 2 3]'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '[1 2 3]'
- en: '>>> print(v.reshape((3,1)))'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(v.reshape((3,1)))'
- en: '[[1]'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '[[1]'
- en: '[2]'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '[2]'
- en: '[3]]'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '[3]]'
- en: '>>> print(v.reshape((1,3)))'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(v.reshape((1,3)))'
- en: '[[1 2 3]]'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '[[1 2 3]]'
- en: Notice the difference between the first print(v) and the last after calling
    reshape((1,3)). The output now has an extra set of brackets around it to indicate
    the leading dimension of one.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，第一次打印 v 和最后一次调用 reshape((1,3)) 后的区别。输出现在多了一组括号，表示它的前导维度为 1。
- en: 'Next, we apply the transpose operation on v:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们对 v 应用转置操作：
- en: '>>> print(v.transpose())'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(v.transpose())'
- en: '[1 2 3]'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '[1 2 3]'
- en: '>>> print(v.T)'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(v.T)'
- en: '[1 2 3]'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '[1 2 3]'
- en: 'Here, we see that calling transpose or T changes nothing about v. This is because
    the shape of v is simply 3, not (1,3) or (3,1). If we explicitly alter v to be
    a 1 × 3 matrix, we see that transpose and T have the desired effect:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，我们看到调用转置或 T 对 v 没有任何变化。这是因为 v 的形状仅为 3，而不是 (1,3) 或 (3,1)。如果我们显式地将 v 改为一个 1
    × 3 的矩阵，我们会看到转置和 T 达到了预期效果：
- en: '>>> v = v.reshape((1,3))'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> v = v.reshape((1,3))'
- en: '>>> print(v.transpose())'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(v.transpose())'
- en: '[[1]'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '[[1]'
- en: '[2]'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '[2]'
- en: '[3]]'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '[3]]'
- en: '>>> print(v.T)'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(v.T)'
- en: '[[1]'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '[[1]'
- en: '[2]'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '[2]'
- en: '[3]]'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '[3]]'
- en: Here, v goes from being a row vector to a column vector, as we expect. The lesson,
    then, is to be careful about the actual dimensionality of vectors in NumPy code.
    Most of the time, we can be sloppy, but sometimes we need to be explicit and care
    about the distinction between plain vectors, row vectors, and column vectors.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，v 从行向量变为列向量，正如我们所期望的那样。那么，教训就是要小心 NumPy 代码中向量的实际维度。大多数时候我们可以不那么严格，但有时我们需要明确区分普通向量、行向量和列向量。
- en: Inner Product
  id: totrans-225
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 内积
- en: Perhaps the most common vector operation is the *inner product*, or, as it is
    frequently called, the *dot product*. Notationally, the inner product between
    two vectors is written as
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 也许最常见的向量操作是*内积*，或者更常称为*点积*。在符号上，两个向量的内积写作
- en: '![Image](Images/05equ04.jpg)![Image](Images/05equ05.jpg)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![Image](Images/05equ04.jpg)![Image](Images/05equ05.jpg)'
- en: 'Here, *θ* is the angle between the two vectors if they’re interpreted geometrically.
    The result of the inner product is a scalar. The 〈***a***, ***b***〉 notation is
    seen frequently, though the ***a*** • ***b*** dot notation seems more common in
    the deep learning literature. The ***a***^⊤***b*** matrix multiplication notation
    explicitly calls out how to calculate the inner product, but we’ll wait until
    we discuss matrix multiplication to explain its meaning. For the present, the
    summation tells us what we need to know: the inner product of two vectors of length
    *n* is the sum of the products of the *n* components.'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*θ* 是两个向量之间的夹角，如果它们在几何上被解释。内积的结果是一个标量。〈***a***, ***b***〉符号常常出现，尽管在深度学习文献中，***a***
    • ***b*** 点积符号似乎更常见。***a***^⊤***b*** 矩阵乘法符号明确说明了如何计算内积，但我们会等到讨论矩阵乘法时再解释它的含义。目前，求和公式告诉我们：两个长度为
    *n* 的向量的内积是 *n* 个分量乘积的和。
- en: 'The inner product of a vector with itself is the magnitude squared:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 向量与自身的内积是其大小的平方：
- en: '***a*** • ***a*** = ||***a***||²'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '***a*** • ***a*** = ||***a***||²'
- en: The inner product is commutative,
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 内积是可交换的，
- en: '***a*** • ***b*** = ***b*** • ***a***'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '***a*** • ***b*** = ***b*** • ***a***'
- en: and distributive,
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 且是分配的，
- en: '***a*** • (***b*** + ***c***) = ***a*** • ***b*** + ***a*** • ***c***'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '***a*** • (***b*** + ***c***) = ***a*** • ***b*** + ***a*** • ***c***'
- en: but not associative, as the output of the first inner product is a scalar, not
    a vector, and multiplying a vector by a scalar is not an inner product.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 但它不是结合律的，因为第一个内积的输出是一个标量，而不是向量，且向量与标量相乘不是内积。
- en: Finally, notice that the inner product is zero when the angle between the vectors
    is 90 degrees; this is because cos *θ* is zero ([Equation 5.5](ch05.xhtml#ch05equ05)).
    This means the two vectors are perpendicular, or *orthogonal*, to each other.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，注意到当两个向量之间的夹角为 90 度时，内积为零；这是因为 cos *θ* 为零（[公式 5.5](ch05.xhtml#ch05equ05)）。这意味着两个向量是垂直的，或者说是*正交*的。
- en: 'Let’s look at some examples of the inner product. First, we’ll be literal and
    implement [Equation 5.4](ch05.xhtml#ch05equ04) explicitly:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一些内积的例子。首先，我们将逐字实现 [公式 5.4](ch05.xhtml#ch05equ04)：
- en: '>>> a = np.array([1,2,3,4])'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> a = np.array([1,2,3,4])'
- en: '>>> b = np.array([5,6,7,8])'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> b = np.array([5,6,7,8])'
- en: '>>> def inner(a,b):'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> def inner(a,b):'
- en: '...   s = 0.0'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '...   s = 0.0'
- en: '...   for i in range(len(a)):'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '...   for i in range(len(a)):'
- en: '...     s += a[i]*b[i]'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '...     s += a[i]*b[i]'
- en: '...   return s'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '...   return s'
- en: '...'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '...'
- en: '>>> inner(a,b)'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> inner(a,b)'
- en: '70.0'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '70.0'
- en: 'However, since a and b are NumPy arrays, we know we can be more efficient:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于 a 和 b 是 NumPy 数组，我们知道我们可以更高效：
- en: '>>> (a*b).sum()'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> (a*b).sum()'
- en: '70'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '70'
- en: 'Or, probably most efficient of all, we’ll let NumPy do it for us by using np.dot:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，可能最有效的方式是，让 NumPy 来为我们处理，使用 np.dot：
- en: '>>> np.dot(a,b)'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> np.dot(a,b)'
- en: '70'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '70'
- en: You’ll see np.dot frequently in deep learning code. It can do more than calculate
    the inner product, as we’ll see below.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习代码中，你会经常看到 np.dot。它不仅仅能计算内积，下面我们会看到更多用法。
- en: '[Equation 5.5](ch05.xhtml#ch05equ05) tells us that the angle between two vectors
    is'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '[公式 5.5](ch05.xhtml#ch05equ05)告诉我们，两个向量之间的夹角是'
- en: '![Image](Images/115equ01.jpg)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![Image](Images/115equ01.jpg)'
- en: In the code, this could be calculated as
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码中，这可以这样计算
- en: '>>> A = np.sqrt(np.dot(a,a))'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> A = np.sqrt(np.dot(a,a))'
- en: '>>> B = np.sqrt(np.dot(b,b))'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> B = np.sqrt(np.dot(b,b))'
- en: '>>> t = np.arccos(np.dot(a,b)/(A*B))'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> t = np.arccos(np.dot(a,b)/(A*B))'
- en: '>>> t*(180/np.pi)'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> t*(180/np.pi)'
- en: '14.335170291600924'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: '14.335170291600924'
- en: This tells us that the angle between ***a*** and ***b*** is approximately 14°
    after converting t from radians.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 这告诉我们，转换 t 为弧度后，***a*** 和 ***b*** 之间的夹角大约是 14°。
- en: 'If we consider vectors in 3D space, we see that the dot product between orthogonal
    vectors is zero, implying that the angle between them is 90°:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们考虑三维空间中的向量，我们会看到，正交向量之间的点积为零，这意味着它们之间的夹角是 90°：
- en: '>>> a = np.array([1,0,0])'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> a = np.array([1,0,0])'
- en: '>>> b = np.array([0,1,0])'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> b = np.array([0,1,0])'
- en: '>>> np.dot(a,b)'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> np.dot(a,b)'
- en: '0'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '0'
- en: '>>> t = np.arccos(0)'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> t = np.arccos(0)'
- en: '>>> t*(180/np.pi)'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> t*(180/np.pi)'
- en: '90.0'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '90.0'
- en: This is true because a is a unit vector along the x-axis, b is a unit vector
    along the y-axis, and we know there’s a right angle between them.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为 ***a*** 是沿 x 轴的单位向量，***b*** 是沿 y 轴的单位向量，并且我们知道它们之间存在直角。
- en: With the inner product in our toolkit, let’s see how we can use it to project
    one vector onto another.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 有了内积作为工具箱中的一部分，让我们看看如何使用它将一个向量投影到另一个向量上。
- en: Projection
  id: totrans-274
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 投影
- en: The projection of one vector onto another calculates the amount of the first
    vector that’s in the direction of the second. The projection of ***a*** onto ***b***
    is
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 一个向量在另一个向量上的投影计算的是第一个向量在第二个向量方向上的分量。***a*** 在 ***b*** 上的投影是
- en: '![Image](Images/116equ01.jpg)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
  zh: '![Image](Images/116equ01.jpg)'
- en: '[Figure 5-1](ch05.xhtml#ch05fig01) shows graphically what projection means
    for 2D vectors.'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 5-1](ch05.xhtml#ch05fig01) 直观地展示了投影在 2D 向量中的意义。'
- en: '![image](Images/05fig01.jpg)'
  id: totrans-278
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/05fig01.jpg)'
- en: '*Figure 5-1: A graphical representation of the projection of **a** onto **b**
    in 2D*'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 5-1：***a*** 在 2D 平面上投影到 ***b*** 的图示表示*'
- en: Projection finds the component of ***a*** in the direction of ***b***. Note
    the projection of ***a*** onto ***b*** is not the same as the projection of ***b***
    onto ***a***.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 投影找出 ***a*** 在 ***b*** 方向上的分量。注意，***a*** 在 ***b*** 上的投影与 ***b*** 在 ***a*** 上的投影并不相同。
- en: Because we use an inner product in the numerator, we can see that the projection
    of a vector onto another vector that’s orthogonal to it is zero. No component
    of the first vector is in the direction of the second. Think again of the x-axis
    and y-axis. The entire reason we use Cartesian coordinates is because the two
    axes, or three in 3D space, are all mutually orthogonal; no part of one is in
    the direction of the others. This lets us specify any point, and the vector from
    the origin to that point, by specifying the components along these axes. We’ll
    see this breaking up of an object into mutually orthogonal components later when
    we discuss eigenvectors and PCA in [Chapter 6](ch06.xhtml#ch06).
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们在分子中使用了内积，我们可以看到一个向量投影到另一个与其正交的向量上的结果为零。第一个向量没有任何分量在第二个向量的方向上。再想想 x 轴和 y
    轴。我们使用笛卡尔坐标系的根本原因是两个坐标轴，或在三维空间中的三个坐标轴，都是互相正交的；其中一个轴没有任何部分在其他轴的方向上。这让我们能够通过指定沿这些轴的分量来确定任意点及从原点到该点的向量。稍后当我们讨论特征向量和主成分分析（PCA）时，会看到这种将物体分解为相互正交分量的过程，详见[第
    6 章](ch06.xhtml#ch06)。
- en: 'In code, calculating the projection is straightforward:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码中，计算投影是直接的：
- en: '>>> a = np.array([1,1])'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> a = np.array([1,1])'
- en: '>>> b = np.array([1,0])'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> b = np.array([1,0])'
- en: '>>> p = (np.dot(a,b)/np.dot(b,b))*b'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> p = (np.dot(a,b)/np.dot(b,b))*b'
- en: '>>> print(p)'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(p)'
- en: '[1\. 0.]'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '[1\. 0.]'
- en: '>>> c = np.array([-1,1])'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> c = np.array([-1,1])'
- en: '>>> p = (np.dot(c,b)/np.dot(b,b))*b'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> p = (np.dot(c,b)/np.dot(b,b))*b'
- en: '>>> print(p)'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(p)'
- en: '[-1\. -0.]'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '[-1\. -0.]'
- en: In the first example, ***a*** points in the direction 45° up from the x-axis,
    while ***b*** points along the x-axis. We’d then expect the projection of ***a***
    to be along the x-axis, which it is (p). In the second example, ***c*** points
    in the direction 135° = 90° + 45° from the x-axis. Therefore, we’d expect the
    component of ***c*** along ***b*** to be along the x-axis but in the opposite
    direction from ***b***, which it is.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一个例子中，***a*** 在 x 轴上方 45° 方向，***b*** 则沿着 x 轴方向。我们可以预期，***a*** 的投影会沿着 x 轴，这正是它所表现的（p）。在第二个例子中，***c***
    在 x 轴上方 135° = 90° + 45° 方向。因此，我们可以预期，***c*** 沿着 ***b*** 的分量将会沿着 x 轴，但与 ***b***
    的方向相反，结果正是如此。
- en: '**NOTE**'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*Projecting **c** along **b** returned a y-axis component of –0. The negative
    sign is a quirk of the IEEE 754 representation used for floating-point numbers.
    The significand (mantissa) of the internal representation is zero, but the sign
    can still be specified, leading to an output of negative zero from time to time.
    For a detailed explanation of computer number formats, including floating-point,
    please see my book,* Numbers and Computers *(Springer-Verlag, 2017).*'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: '*将 ***c*** 沿 ***b*** 投影得到的 y 轴分量为 –0。负号是 IEEE 754 浮点数表示法的特性。内部表示的有效数字（尾数）为零，但符号仍然可以指定，这导致有时输出负零。有关计算机数字格式（包括浮点数）的详细解释，请参阅我的书，*《数字与计算机》*（Springer-Verlag，2017）。*'
- en: Let’s move on now to consider the outer product of two vectors.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们继续讨论两个向量的外积。
- en: Outer Product
  id: totrans-296
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 外积
- en: The inner product of two vectors returned a scalar value. The *outer product*
    of two vectors instead returns a matrix. Note that unlike the inner product, the
    outer product does not require the two vectors to have the same number of components.
    Specifically, for vectors ***a*** of *m* components and ***b*** of *n* components,
    the outer product is the matrix formed by multiplying each element of ***a***
    by each element of ***b***, as shown next.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 两个向量的内积返回一个标量值。两个向量的*外积*则返回一个矩阵。请注意，与内积不同，外积不要求两个向量具有相同数量的分量。具体而言，对于具有*m*个分量的向量***a***和具有*n*个分量的向量***b***，外积是一个矩阵，通过将***a***的每个元素与***b***的每个元素相乘得到，如下所示。
- en: '![Image](Images/118equ01.jpg)'
  id: totrans-298
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/118equ01.jpg)'
- en: The ***ab***^⊤ notation is how to calculate the outer product via matrix multiplication.
    Notice that this notation is not the same as the inner product, ***a***^⊤***b***,
    and that it assumes ***a*** and ***b*** to be column vectors. No operator symbol
    is consistently used for the outer product, primarily because it’s so easily specified
    via matrix multiplication and because it’s less common than the dot product. However,
    ⊗ seems the most commonly used when the outer product is presented with a binary
    operator.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '***ab***^⊤符号表示通过矩阵乘法计算外积。请注意，这个符号与内积***a***^⊤***b***不同，并且它假设***a***和***b***是列向量。外积通常没有一致的操作符，主要是因为它可以通过矩阵乘法轻松地指定，并且比点积更少见。然而，当外积用二元操作符表示时，⊗似乎是最常用的符号。'
- en: 'In code, NumPy has kindly provided an outer product function for us:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码中，NumPy 为我们提供了一个外积函数：
- en: '>>> a = np.array([1,2,3,4])'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> a = np.array([1,2,3,4])'
- en: '>>> b = np.array([5,6,7,8])'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> b = np.array([5,6,7,8])'
- en: '>>> np.dot(a,b)'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> np.dot(a,b)'
- en: '70'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '70'
- en: '>>> np.outer(a,b)'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> np.outer(a,b)'
- en: array([[ 5, 6, 7, 8],
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: array([[ 5, 6, 7, 8],
- en: '[10, 12, 14, 16],'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '[10, 12, 14, 16],'
- en: '[15, 18, 21, 24],'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: '[15, 18, 21, 24],'
- en: '[20, 24, 28, 32]])'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '[20, 24, 28, 32]])'
- en: We used a and b above when discussing the inner product. As expected, np.dot
    gives us a scalar output for ***a***•***b***. However, the np.outer function returns
    a 4 × 4 matrix, where we see that each row is vector b multiplied successively
    by each element of vector a, first 1, then 2, then 3, and finally 4. Therefore,
    each element of a has multiplied each element of b. The resulting matrix is 4
    × 4 because both a and b have four elements.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面讨论内积时，我们使用了a和b。如预期的那样，np.dot为***a***•***b***返回一个标量输出。然而，np.outer函数返回一个4 ×
    4的矩阵，其中我们看到每一行是向量b依次乘以向量a的每个元素，首先是1，然后是2，再是3，最后是4。因此，a的每个元素都与b的每个元素相乘。最终得到的矩阵是4
    × 4，因为a和b都有四个元素。
- en: THE CARTESIAN PRODUCT
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 笛卡尔积
- en: There is a direct analogue between the outer product of two vectors and the
    Cartesian product of two sets, *A* and *B*. The *Cartesian product* is a new set,
    each element of which is one of the possible pairings of elements from *A* and
    *B*. So, if *A*={1,2,3,4} and *B*={5,6,7,8}, the Cartesian product can be written
    as
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 两个向量的外积与两个集合*A*和*B*的笛卡尔积之间有直接的类比。*笛卡尔积*是一个新集合，其中每个元素都是从*A*和*B*中元素的可能配对。因此，如果*A*={1,2,3,4}，*B*={5,6,7,8}，那么笛卡尔积可以写作
- en: '![Image](Images/118equ02.jpg)'
  id: totrans-313
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/118equ02.jpg)'
- en: Here, we see that if we replace each entry with the product of the pair, we
    get the corresponding vector product we saw above with NumPy np.outer. Also, note
    that × is typically used for the Cartesian product when working with sets.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们看到如果将每个元素替换为对应的数对乘积，就能得到我们之前用 NumPy np.outer 得到的向量积。另外，注意在处理集合时，×通常用于表示笛卡尔积。
- en: The ability of the outer product to mix all combinations of its inputs has been
    used in deep learning for neural collaborative filtering and visual question answering
    applications. These functions are performed by advanced networks that make recommendations
    or answer text questions about an image. The outer product appears as a mixing
    of two different embedding vectors. *Embeddings* are the vectors generated by
    lower layers of a network, for example, the next to last fully connected layer
    before the softmax layer’s output of a traditional convolutional neural network
    (CNN). The embedding layer is usually viewed as having learned a new representation
    of the network input. It can be thought of as mapping complex inputs, like images,
    to a reduced space of several hundred to several thousands of dimensions.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 外积能够混合其输入的所有组合，这一特性已在深度学习中用于神经协同过滤和视觉问答应用中。这些功能由高级网络执行，用于推荐或回答有关图像的文本问题。外积表现为两种不同嵌入向量的混合。*嵌入*是由网络低层生成的向量，例如传统卷积神经网络（CNN）中软最大层输出之前的倒数第二个全连接层。嵌入层通常被视为已学习了网络输入的一个新表示。它可以被认为是将复杂的输入（如图像）映射到一个几百到几千维的简化空间。
- en: Cross Product
  id: totrans-316
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 叉积
- en: Our final vector-vector operator is the *cross product*. This operator is only
    defined for 3D space (ℝ³). The cross product of ***a*** and ***b*** is a new vector
    that is perpendicular to the plane containing ***a*** and ***b***. Note, this
    does not imply that ***a*** and ***b*** are themselves perpendicular. The cross
    product is defined as
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的最终向量-向量运算符是*叉积*。这个运算符仅在三维空间（ℝ³）中定义。***a***和***b***的叉积是一个新向量，垂直于包含***a***和***b***的平面。请注意，这并不意味着***a***和***b***本身是垂直的。叉积定义为
- en: '![Image](Images/05equ06.jpg)'
  id: totrans-318
  prefs: []
  type: TYPE_IMG
  zh: '![Image](Images/05equ06.jpg)'
- en: where ![Image](Images/ncap.jpg) is a unit vector and *θ* is the angle between
    ***a*** and ***b***. The direction of ![Image](Images/ncap.jpg) is given by the
    *right-hand rule*. With your right hand, point your index finger in the direction
    of ***a*** and your middle finger in the direction of ***b***. Then, your thumb
    will be pointing in the direction of ![Image](Images/ncap.jpg). [Equation 5.6](ch05.xhtml#ch05equ06)
    gives the actual ℝ³ components of the cross product vector.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 ![Image](Images/ncap.jpg) 是单位向量，*θ* 是 ***a*** 和 ***b*** 之间的角度。![Image](Images/ncap.jpg)
    的方向由*右手定则*给出。用你的右手，伸出食指指向 ***a*** 的方向，中指指向 ***b*** 的方向。然后，大拇指将指向 ![Image](Images/ncap.jpg)
    的方向。[方程 5.6](ch05.xhtml#ch05equ06) 给出了叉积向量在 ℝ³ 中的实际分量。
- en: 'NumPy implements the cross product via np.cross:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy 通过 np.cross 实现叉积：
- en: '>>> a = np.array([1,0,0])'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> a = np.array([1,0,0])'
- en: '>>> b = np.array([0,1,0])'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> b = np.array([0,1,0])'
- en: '>>> print(np.cross(a,b))'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(np.cross(a,b))'
- en: '[0 0 1]'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: '[0 0 1]'
- en: '>>> c = np.array([1,1,0])'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> c = np.array([1,1,0])'
- en: '>>> print(np.cross(a,c))'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> print(np.cross(a,c))'
- en: '[0 0 1]'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: '[0 0 1]'
- en: 'In the first example, a points along the x-axis and b along the y-axis. Therefore,
    we expect the cross product to be perpendicular to these axes, and it is: the
    cross product points along the z-axis. The second example shows that it doesn’t
    matter if a and b are perpendicular to each other. Here, c is at a 45° angle to
    the x-axis, but a and c are still in the xy-plane. Therefore, the cross product
    is still along the z-axis.'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一个示例中，a 指向 x 轴，b 指向 y 轴。因此，我们预计叉积会垂直于这些轴，结果也是如此：叉积指向 z 轴。第二个示例表明，a 和 b 是否垂直并不重要。在这里，c
    与 x 轴成 45° 角，但 a 和 c 仍然在 xy 平面内。因此，叉积仍然沿着 z 轴。
- en: The definition of the cross product involves sin *θ*, while the inner product
    uses cos *θ*. The inner product is zero when the two vectors are orthogonal to
    each other. The cross product, on the other hand, is zero when the two vectors
    are in the same direction and is maximized when the vectors are perpendicular.
    The second NumPy example above works out because the magnitude of c is ![Image](Images/120equ01.jpg)
    and sin ![Image](Images/120equ02.jpg). As a result, the ![Image](Images/120equ01.jpg)
    factors cancel out to leave a magnitude of 1 for the cross product because a is
    a unit vector.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 叉积的定义涉及 sin *θ*，而内积则使用 cos *θ*。当两个向量互相正交时，内积为零。另一方面，当两个向量在同一方向时，叉积为零，当向量垂直时，叉积达到最大值。上面的第二个
    NumPy 示例之所以有效，是因为 c 的大小为 ![Image](Images/120equ01.jpg) 且 sin ![Image](Images/120equ02.jpg)。因此，![Image](Images/120equ01.jpg)因子相互抵消，叉积的大小为
    1，因为 a 是单位向量。
- en: The cross product is widely used in physics and other sciences but is less often
    used in deep learning because of its restriction to 3D space. Nontheless, you
    should be familiar with it if you’re going to tackle the deep learning literature.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 叉积在物理学和其他科学中被广泛使用，但在深度学习中不常用，因为它仅限于三维空间。然而，如果你打算阅读深度学习文献，你应该对它有所了解。
- en: 'This concludes our look at vector-vector operations. Let’s leave the 1D world
    and move on to consider the most important operation for all deep learning: matrix
    multiplication.'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 这就结束了我们对向量-向量操作的讨论。让我们离开一维世界，转而考虑所有深度学习中最重要的操作：矩阵乘法。
- en: Matrix Multiplication
  id: totrans-332
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 矩阵乘法
- en: 'In the previous section, we saw how to multiply two vectors in various ways:
    Hadamard product, inner (dot) product, outer product, and cross product. In this
    section, we’ll investigate multiplication of matrices, recalling that row and
    column vectors are themselves matrices with one row or column.'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，我们看到了如何以不同的方式乘以两个向量：哈达玛积、内积（点积）、外积和叉积。在这一节中，我们将研究矩阵的乘法，回顾一下行向量和列向量本身就是只有一行或一列的矩阵。
- en: Properties of Matrix Multiplication
  id: totrans-334
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 矩阵乘法的性质
- en: We’ll define the matrix product operation shortly, but, before we do, let’s
    look at the properties of matrix multiplication. Let ***A***, ***B***, and ***C***
    be matrices. Then, following the algebra convention of multiplying symbols by
    placing them next to each other,
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在稍后定义矩阵乘积运算，但在此之前，让我们先看一下矩阵乘法的性质。设***A***、***B***和***C***为矩阵。那么，根据代数习惯，符号通过放置在一起进行相乘，
- en: '***(AB)C*** = ***A***(***BC***)'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: '***(AB)C*** = ***A***(***BC***)'
- en: 'meaning matrix multiplication is associative. Second, matrix multiplication
    is distributive:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着矩阵乘法是结合律的。其次，矩阵乘法是分配律的：
- en: '![Image](Images/05equ07.jpg)![Image](Images/05equ08.jpg)'
  id: totrans-338
  prefs: []
  type: TYPE_IMG
  zh: '![Image](Images/05equ07.jpg)![Image](Images/05equ08.jpg)'
- en: 'However, in general, matrix multiplication is *not* commutative:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，通常情况下，矩阵乘法是*不*满足交换律的：
- en: '***AB*** ≠ ***BA***'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: '***AB*** ≠ ***BA***'
- en: As you can see in [Equation 5.8](ch05.xhtml#ch05equ08), matrix multiplication
    over addition from the right produces a different result than matrix multiplication
    over addition from the left, as shown in [Equation 5.7](ch05.xhtml#ch05equ07).
    This explains why we showed both [Equation 5.7](ch05.xhtml#ch05equ07) and [Equation
    5.8](ch05.xhtml#ch05equ08); matrix multiplication can be performed from the left
    or the right, and the result will be different.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在[方程 5.8](ch05.xhtml#ch05equ08)中看到的，右侧的矩阵乘法加法与左侧的矩阵乘法加法会产生不同的结果，如[方程 5.7](ch05.xhtml#ch05equ07)所示。这也解释了为什么我们展示了[方程
    5.7](ch05.xhtml#ch05equ07)和[方程 5.8](ch05.xhtml#ch05equ08)；矩阵乘法可以从左侧或右侧执行，结果会不同。
- en: How to Multiply Two Matrices
  id: totrans-342
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 如何乘以两个矩阵
- en: To calculate ***AB***, knowing that ***A*** must be on the left of ***B***,
    we first need to verify that the matrices are compatible. It’s only possible to
    multiply two matrices if the number of columns in ***A*** is the same as the number
    of rows in ***B***. Therefore, if ***A*** is an *n × m* matrix and ***B*** is
    an *m × k* matrix, then the product, ***AB***, can be found and will be a new
    *n* × *k* matrix.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算***AB***，知道***A***必须在***B***的左边，我们首先需要验证矩阵是否兼容。只有当***A***的列数与***B***的行数相同，才能相乘。因此，如果***A***是一个*n
    × m*矩阵，***B***是一个*m × k*矩阵，那么积***AB***可以计算出来，并且将是一个新的*n* × *k*矩阵。
- en: To calculate the product, we perform a series of inner product multiplications
    between the row vectors of ***A*** and the column vectors of ***B***. [Figure
    5-2](ch05.xhtml#ch05fig02) illustrates the process for a 3 × 3 matrix ***A***
    and a 3 × 2 matrix ***B***.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算积，我们需要在***A***的行向量与***B***的列向量之间执行一系列内积乘法。[图 5-2](ch05.xhtml#ch05fig02)展示了一个3
    × 3矩阵***A***与一个3 × 2矩阵***B***的乘法过程。
- en: '![image](Images/05fig02.jpg)'
  id: totrans-345
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/05fig02.jpg)'
- en: '*Figure 5-2: Multiplying a 3* × *3 matrix by a 3* × *2 matrix*'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 5-2：将3* × *3矩阵与3* × *2矩阵相乘*'
- en: In [Figure 5-2](ch05.xhtml#ch05fig02), the first row of the output matrix is
    found by computing the inner product of the first row of ***A*** with each of
    the columns of ***B***. The first element of the output matrix is shown where
    the first row of ***A*** is multiplied by the first column of ***B***. The remaining
    first row of the output matrix is found by repeating the dot product of the first
    row of ***A*** by the remaining column of ***B***.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [图 5-2](ch05.xhtml#ch05fig02) 中，输出矩阵的第一行是通过计算 ***A*** 的第一行与 ***B*** 的每一列的内积得到的。输出矩阵的第一个元素是通过将
    ***A*** 的第一行与 ***B*** 的第一列相乘得到的。输出矩阵的剩余第一行是通过对 ***A*** 的第一行与 ***B*** 的其余列的点积进行重复计算得到的。
- en: 'Let’s present a worked example with actual numbers for the matrices in [Figure
    5-2](ch05.xhtml#ch05fig02):'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过 [图 5-2](ch05.xhtml#ch05fig02) 中实际的矩阵数字来展示一个例子：
- en: '![Image](Images/121equ01.jpg)'
  id: totrans-349
  prefs: []
  type: TYPE_IMG
  zh: '![Image](Images/121equ01.jpg)'
- en: Notice, ***AB*** is defined, but ***BA*** is not, because we can’t multiply
    a 3 × 2 matrix by a 3 × 3 matrix. The number of columns in ***B*** needs to be
    the same as the number of rows in ***A***.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，***AB*** 是定义的，但 ***BA*** 不是，因为我们不能将一个 3 × 2 的矩阵与一个 3 × 3 的矩阵相乘。***B*** 的列数必须与
    ***A*** 的行数相同。
- en: Another way to think of matrix multiplication is by considering what goes into
    making up each of the output matrix elements. For example, if ***A*** is *n* ×
    *m* and ***B*** is *m* × *p*, we know that the matrix product exists as an *n*
    × *p* matrix, ***C***. We find the output elements by computing
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种理解矩阵乘法的方式是考虑如何构成每个输出矩阵元素。例如，如果 ***A*** 是 *n* × *m* 且 ***B*** 是 *m* × *p*，我们知道矩阵乘积是一个
    *n* × *p* 的矩阵，***C***。我们通过计算得到输出元素：
- en: '![Image](Images/05equ09.jpg)'
  id: totrans-352
  prefs: []
  type: TYPE_IMG
  zh: '![Image](Images/05equ09.jpg)'
- en: for *i* = 0, . . . , *n* − 1 and *j* = 0, . . . , *p* − 1\. In the example above,
    we find *c*[21] by summing the products *a*[20]*b*[01] + *a*[21]*b*[11] + *a*[22]*b*[21],
    which fits [Equation 5.9](ch05.xhtml#ch05equ09) with *i* = 2, *j* = 1 and *k*
    = 0, 1, 2.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 *i* = 0, . . . , *n* − 1 和 *j* = 0, . . . , *p* − 1。在上面的例子中，我们通过求和 *a*[20]*b*[01]
    + *a*[21]*b*[11] + *a*[22]*b*[21] 来得到 *c*[21]，这与 [公式 5.9](ch05.xhtml#ch05equ09)
    相符，其中 *i* = 2，*j* = 1 和 *k* = 0, 1, 2。
- en: '[Equation 5.9](ch05.xhtml#ch05equ09) tells us how to find a single output matrix
    element. If we loop over *i* and *j*, we can find the entire output matrix. This
    implies a straightforward implementation of matrix multiplication:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: '[公式 5.9](ch05.xhtml#ch05equ09) 告诉我们如何找到单个输出矩阵元素。如果我们循环遍历 *i* 和 *j*，我们可以找到整个输出矩阵。这意味着矩阵乘法的直接实现：'
- en: 'def matrixmul(A,B):'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 'def matrixmul(A,B):'
- en: I,K = A.shape
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: I,K = A.shape
- en: J = B.shape[1]
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: J = B.shape[1]
- en: C = np.zeros((I,J), dtype=A.dtype)
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: C = np.zeros((I,J), dtype=A.dtype)
- en: 'for i in range(I):'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 'for i in range(I):'
- en: 'for j in range(J):'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 'for j in range(J):'
- en: 'for k in range(K):'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 'for k in range(K):'
- en: C[i,j] += A[i,k]*B[k,j]
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: C[i,j] += A[i,k]*B[k,j]
- en: return C
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: return C
- en: We’ll assume the arguments, ***A*** and ***B***, are compatible matrices. We
    set the number of rows (I) and columns (J) of the output matrix, ***C***, and
    use them as the loop limits for the elements of ***C***. We create the output
    matrix, C, and give it the same data type as A. Then starts a triple loop. The
    loop over i covers all the rows of the output. The next loop, over j, covers the
    columns of the current row, and the innermost loop, over k, covers the combining
    of elements from A and B, as in [Equation 5.9](ch05.xhtml#ch05equ09). When all
    loops finish, we return the matrix product, C.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设参数 ***A*** 和 ***B*** 是兼容的矩阵。我们设置输出矩阵 ***C*** 的行数 (I) 和列数 (J)，并将它们作为 ***C***
    元素的循环限制。我们创建输出矩阵 C，并使其与 A 具有相同的数据类型。然后开始一个三重循环。对 *i* 的循环遍历输出的所有行。接下来的循环，针对 *j*，遍历当前行的列，最内层的循环，针对
    *k*，遍历 A 和 B 中元素的组合，正如 [公式 5.9](ch05.xhtml#ch05equ09) 中所示。当所有循环完成时，我们返回矩阵乘积 C。
- en: The function matrixmul works. It finds the matrix product. However, in terms
    of implementation, it’s quite naive. Advanced algorithms exist, as do many optimizations
    of the naive approach when using compiled code. As we’ll see below, NumPy supports
    matrix multiplication and internally uses highly optimized compiled code libraries
    that far outstrip the performance of the simple code above.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 函数 matrixmul 可以工作。它找到矩阵乘积。然而，在实现方面，它相当简单。确实存在更先进的算法，并且在使用编译代码时，简单方法的优化也有很多。正如我们将在下面看到的，NumPy
    支持矩阵乘法，并且内部使用高度优化的编译代码库，性能远超上面简单代码的执行。
- en: Matrix Notation for Inner and Outer Products
  id: totrans-366
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 内积和外积的矩阵表示
- en: We are now in a position to understand the matrix notation above for the inner
    product, ***a***^⊤***b***, and the outer product, ***ab***^⊤, of two vectors.
    In the first case, we have a 1 × *n* row vector, because of the transpose, and
    an *n* × 1 column vector. The algorithm says to form the inner product of the
    row vector and the column vector to arrive at an output matrix that is 1 × 1,
    that is, a single scalar number. Notice that there must be *n* components in both
    ***a*** and ***b***.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以理解上面关于内积***a***^⊤***b***和外积***ab***^⊤的矩阵表示了。对于内积的情况，我们有一个1 × *n*的行向量（由于转置），和一个*n*
    × 1的列向量。算法要求我们形成行向量和列向量的内积，得出一个1 × 1的输出矩阵，即一个标量值。注意，***a***和***b***必须都有*n*个分量。
- en: For the outer product, we have an *n* × 1 column vector on the left and a 1
    × *m* row vector on the right. Therefore, we know the output matrix is *n* × *m*.
    If *m* = *n*, we’ll have an output matrix that’s *n* × *n*. A matrix with as many
    rows as it has columns is a *square matrix*. These have special properties, some
    of which we’ll see in [Chapter 6](ch06.xhtml#ch06).
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 对于外积，我们有一个*n* × 1的列向量在左边，一个1 × *m*的行向量在右边。因此，我们知道输出矩阵的形状是*n* × *m*。如果*m* = *n*，我们将得到一个*n*
    × *n*的输出矩阵。一个行数与列数相等的矩阵被称为*方阵*。这些矩阵有一些特殊的性质，其中一些我们将在[第6章](ch06.xhtml#ch06)中看到。
- en: To find the outer product of two vectors by matrix multiplication, we multiply
    each element of the rows of ***a*** by each of the columns of ***b** as a row
    vector*,
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 要通过矩阵乘法找到两个向量的外积，我们将***a***的每一行的每个元素与***b***的每一列相乘，就像一个行向量*。
- en: '![Image](Images/123equ01.jpg)'
  id: totrans-370
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/123equ01.jpg)'
- en: where each column of ***b***^⊤, a single scalar number, is passed down the rows
    of ***a***, thereby forming each possible product between the elements of the
    two vectors.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，***b***^⊤的每一列，一个标量数值，将沿着***a***的行传递，从而形成两个向量之间的每一个可能的乘积。
- en: We’ve seen how to perform matrix multiplication manually. Let’s take a look
    now at how NumPy supports matrix multiplication.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看过如何手动进行矩阵乘法。现在让我们看看NumPy是如何支持矩阵乘法的。
- en: Matrix Multiplication in NumPy
  id: totrans-373
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: NumPy中的矩阵乘法
- en: NumPy provides two different functions that we can use for matrix multiplication.
    The first, we’ve seen already, np.dot, though we’ve only used it so far to compute
    inner products of vectors. The second is np.matmul, which is also called when
    using the @ binary operator available in Python 3.5 and later. Matrix multiplication
    with either function works as we expect. However, NumPy sometimes treats 1D arrays
    differently from row or column vectors.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy提供了两个可以用于矩阵乘法的不同函数。第一个是我们已经见过的np.dot，虽然我们到目前为止仅使用它来计算向量的内积。第二个是np.matmul，当使用Python
    3.5及更高版本中的@二进制运算符时也会调用它。无论使用哪个函数，矩阵乘法都会如我们所预期地工作。然而，NumPy有时会将1D数组与行向量或列向量区分对待。
- en: 'We can use shape to decide if a NumPy array is a 1D array, a row vector, or
    a column vector, as shown in [Listing 5-1](ch05.xhtml#ch05ex01):'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用shape来判断一个NumPy数组是1D数组、行向量还是列向量，如[列出5-1](ch05.xhtml#ch05ex01)所示：
- en: '>>> av = np.array([1,2,3])'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> av = np.array([1,2,3])'
- en: '>>> ar = np.array([[1,2,3]])'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> ar = np.array([[1,2,3]])'
- en: '>>> ac = np.array([[1],[2],[3]])'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> ac = np.array([[1],[2],[3]])'
- en: '>>> av.shape'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> av.shape'
- en: (3,)
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: (3,)
- en: '>>> ar.shape'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> ar.shape'
- en: (1, 3)
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: (1, 3)
- en: '>>> ac.shape'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> ac.shape'
- en: (3, 1)
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: (3, 1)
- en: '*Listing 5-1: NumPy vectors*'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: '*列出5-1：NumPy向量*'
- en: 'Here, we see that a 1D array with three elements, av, has a shape different
    from a row vector with three components, ar, or a column vector of three components,
    ac. However, each of these arrays contains the same three integers: 1, 2, and
    3.'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们看到一个包含三个元素的1D数组av，它的形状与一个包含三个分量的行向量ar或列向量ac不同。然而，这些数组都包含相同的三个整数：1、2和3。
- en: Let’s run an experiment to help us understand how NumPy implements matrix multiplication.
    We’ll test np.dot, but the results are the same if we use np.matmul or the @ operator.
    We need a collection of vectors and matrices to work with. We’ll then apply combinations
    of them to np.dot and consider the output, which may very well be an error if
    the operation is undefined for that combination of arguments.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进行一个实验，帮助我们理解NumPy是如何实现矩阵乘法的。我们将测试np.dot，但如果使用np.matmul或@运算符，结果是相同的。我们需要一些向量和矩阵的集合来进行测试。然后，我们将它们的组合应用到np.dot，并考虑输出，如果该组合的操作未定义，可能会出现错误。
- en: 'Let’s create the arrays, vectors, and matrices we’ll need:'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建我们需要的数组、向量和矩阵：
- en: a1 = np.array([1,2,3])
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: a1 = np.array([1,2,3])
- en: ar = np.array([[1,2,3]])
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: ar = np.array([[1,2,3]])
- en: ac = np.array([[1],[2],[3]])
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: ac = np.array([[1],[2],[3]])
- en: b1 = np.array([1,2,3])
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: b1 = np.array([1,2,3])
- en: br = np.array([[1,2,3]])
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: br = np.array([[1,2,3]])
- en: bc = np.array([[1],[2],[3]])
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: bc = np.array([[1],[2],[3]])
- en: A = np.array([[1,2,3],[4,5,6],[7,8,9]])
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: A = np.array([[1,2,3],[4,5,6],[7,8,9]])
- en: B = np.array([[9,8,7],[6,5,4],[3,2,1]])
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: B = np.array([[9,8,7],[6,5,4],[3,2,1]])
- en: The shape of the objects should be discernible from the definition, if we keep
    the results of [Listing 5-1](ch05.xhtml#ch05ex01) in mind. We’ll also define two
    3 × 3 matrices, A and B.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 对象的形状应该可以从定义中看出，如果我们记得 [清单 5-1](ch05.xhtml#ch05ex01) 的结果。我们还将定义两个 3 × 3 的矩阵
    A 和 B。
- en: 'Next, we’ll define a helper function to wrap the call to NumPy so we can trap
    any errors:'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将定义一个辅助函数来封装对 NumPy 的调用，以便捕获任何错误：
- en: 'def dot(a,b):'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 'def dot(a,b):'
- en: 'try:'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 'try:'
- en: return np.dot(a,b)
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: return np.dot(a,b)
- en: 'except:'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 'except:'
- en: return "fails"
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: return "失败"
- en: This function calls np.dot and returns the word fails if the call doesn’t succeed.
    [Table 5-1](ch05.xhtml#ch05tab01) shows the output of dot for the given combinations
    of the inputs defined above.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数调用 np.dot 并在调用不成功时返回 “失败”。[表 5-1](ch05.xhtml#ch05tab01) 显示了 dot 对上述输入组合的输出。
- en: '[Table 5-1](ch05.xhtml#ch05tab01) illustrates how NumPy sometimes treats 1D
    arrays differently from row or column vectors. See the difference in [Table 5-1](ch05.xhtml#ch05tab01)
    for a1,A versus ar,A and A,ac. The output of A,ac is what we’d expect to see mathematically,
    with the column vector ***a[c]*** multiplied on the left by ***A***.'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: '[表 5-1](ch05.xhtml#ch05tab01) 说明了NumPy有时如何将一维数组与行向量或列向量区分对待。请参见 [表 5-1](ch05.xhtml#ch05tab01)
    中 a1,A 与 ar,A 和 A,ac 的区别。A,ac 的输出是我们在数学上预期看到的结果，其中列向量 ***a[c]*** 被矩阵 ***A*** 从左侧相乘。'
- en: Is there any real difference between np.dot and np.matmul? Yes, some. For 1D
    and 2D arrays, there is no difference. However, there is a difference between
    how each function handles arrays greater than two dimensions, although we won’t
    work with those here. Also, np.dot allows one of its arguments to be a scalar
    and multiplies each element of the other argument by it. Multiplying by a scalar
    with np.matmul throws an error.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: np.dot 和 np.matmul 之间有实际差异吗？有的。对于 1D 和 2D 数组，二者没有区别。然而，当处理大于二维的数组时，每个函数的处理方式不同，虽然我们这里不会使用那些数组。此外，np.dot
    允许其中一个参数是标量，并将另一个参数的每个元素与之相乘。而使用 np.matmul 进行标量乘法会引发错误。
- en: '**Table 5-1:** Results of Applying dot or matmul to Different Types of Arguments'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: '**表 5-1：** 对不同类型的参数应用 dot 或 matmul 的结果'
- en: '| **Arguments** | **Result of np.dot or np.matmul** |'
  id: totrans-408
  prefs: []
  type: TYPE_TB
  zh: '| **参数** | **np.dot 或 np.matmul 的结果** |'
- en: '| --- | --- |'
  id: totrans-409
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| a1,b1 | 14 (scalar) |'
  id: totrans-410
  prefs: []
  type: TYPE_TB
  zh: '| a1,b1 | 14 (标量) |'
- en: '| a1,br | fails |'
  id: totrans-411
  prefs: []
  type: TYPE_TB
  zh: '| a1,br | 失败 |'
- en: '| a1,bc | [14] (1 vector) |'
  id: totrans-412
  prefs: []
  type: TYPE_TB
  zh: '| a1,bc | [14] (1维向量) |'
- en: '| ar,b1 | [14] (1 vector) |'
  id: totrans-413
  prefs: []
  type: TYPE_TB
  zh: '| ar,b1 | [14] (1维向量) |'
- en: '| ar,br | fails |'
  id: totrans-414
  prefs: []
  type: TYPE_TB
  zh: '| ar,br | 失败 |'
- en: '| ar,bc | [14] (1 × 1 matrix) |'
  id: totrans-415
  prefs: []
  type: TYPE_TB
  zh: '| ar,bc | [14] (1 × 1 矩阵) |'
- en: '| ac,b1 | fails |'
  id: totrans-416
  prefs: []
  type: TYPE_TB
  zh: '| ac,b1 | 失败 |'
- en: '| ac,br | ![Image](Images/124equ01.jpg) |'
  id: totrans-417
  prefs: []
  type: TYPE_TB
  zh: '| ac,br | ![Image](Images/124equ01.jpg) |'
- en: '| ac,bc | fails |'
  id: totrans-418
  prefs: []
  type: TYPE_TB
  zh: '| ac,bc | 失败 |'
- en: '| A,a1 | [14 32 50] (3 vector) |'
  id: totrans-419
  prefs: []
  type: TYPE_TB
  zh: '| A,a1 | [14 32 50] (3维向量) |'
- en: '| A,ar | fails |'
  id: totrans-420
  prefs: []
  type: TYPE_TB
  zh: '| A,ar | 失败 |'
- en: '| A,ac | ![Image](Images/124equ02.jpg) |'
  id: totrans-421
  prefs: []
  type: TYPE_TB
  zh: '| A,ac | ![Image](Images/124equ02.jpg) |'
- en: '| a1,A | [30 36 42] (3 vector) |'
  id: totrans-422
  prefs: []
  type: TYPE_TB
  zh: '| a1,A | [30 36 42] (3维向量) |'
- en: '| ar,A | [30 36 42] (1 × 3 matrix) |'
  id: totrans-423
  prefs: []
  type: TYPE_TB
  zh: '| ar,A | [30 36 42] (1 × 3 矩阵) |'
- en: '| ac,A | fails |'
  id: totrans-424
  prefs: []
  type: TYPE_TB
  zh: '| ac,A | 失败 |'
- en: '| A,B | ![Image](Images/124equ03.jpg) |'
  id: totrans-425
  prefs: []
  type: TYPE_TB
  zh: '| A,B | ![Image](Images/124equ03.jpg) |'
- en: Kronecker Product
  id: totrans-426
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 克罗内克积
- en: The final form of matrix multiplication we’ll discuss is the *Kronecker product*
    or *matrix direct product* of two matrices. When computing the matrix product,
    we mixed individual elements of the matrices, multiplying them together. For the
    Kronecker product, we multiply the elements of one matrix by an entire matrix
    to produce an output matrix that is larger than the input matrices. The Kronecker
    product is also a convenient place to introduce the idea of a *block matrix*,
    or a matrix constructed from smaller matrices (the blocks).
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将讨论的矩阵乘法的最终形式是 *克罗内克积* 或 *矩阵直接积*。在计算矩阵乘积时，我们将矩阵的各个元素混合在一起并进行相乘。而对于克罗内克积，我们通过将一个矩阵的元素与另一个矩阵的所有元素相乘，生成一个比输入矩阵大的输出矩阵。克罗内克积也是引入
    *块矩阵* 概念的方便途径，块矩阵是由较小矩阵（块）构成的矩阵。
- en: For example, if we have three matrices
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们有三个矩阵
- en: '![Image](Images/05equ10.jpg)'
  id: totrans-429
  prefs: []
  type: TYPE_IMG
  zh: '![Image](Images/05equ10.jpg)'
- en: we can define a block matrix, ***M***, as the following.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以定义一个块矩阵 ***M***，如下所示。
- en: '![Image](Images/126equ01.jpg)'
  id: totrans-431
  prefs: []
  type: TYPE_IMG
  zh: '![Image](Images/126equ01.jpg)'
- en: where each element of ***M*** is a smaller matrix stacked on top of each other.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 其中每个 ***M*** 的元素是一个堆叠在一起的较小矩阵。
- en: We can most easily define the Kronecker product using a visual example involving
    a block matrix. The Kronecker product of ***A*** and ***B***, typically written
    as ***A*** ⊗ ***B***, is
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过一个涉及块矩阵的可视化示例最容易地定义克罗内克积。***A*** 和 ***B*** 的克罗内克积，通常写作 ***A*** ⊗ ***B***，为：
- en: '![Image](Images/126equ02.jpg)'
  id: totrans-434
  prefs: []
  type: TYPE_IMG
  zh: '![Image](Images/126equ02.jpg)'
- en: for ***A***, an *m* × *n* matrix. This is a block matrix because of ***B***,
    so, when written out completely, the Kronecker product results in a matrix larger
    than either ***A*** or ***B***. Note, unlike matrix multiplication, the Kronecker
    product is defined for arbitrarily sized ***A*** and ***B*** matrices. For example,
    using ***A*** and ***B*** from [Equation 5.10](ch05.xhtml#ch05equ10), the Kronecker
    product is
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 对于***A***，一个*m* × *n*的矩阵。这是一个块矩阵，因为有了***B***，因此完全展开后，克罗内克积会得到一个比***A***或***B***都要大的矩阵。注意，与矩阵乘法不同，克罗内克积适用于任意大小的***A***和***B***矩阵。例如，使用[方程
    5.10](ch05.xhtml#ch05equ10)中的***A***和***B***，克罗内克积是
- en: '![Image](Images/126equ03.jpg)'
  id: totrans-436
  prefs: []
  type: TYPE_IMG
  zh: '![Image](Images/126equ03.jpg)'
- en: Notice above that we used ⊗ for the Kronecker product. This is the convention,
    though the symbol ⊗ is sometimes abused and is used for other things too. We used
    it for the outer product of two vectors, for example. NumPy supports the Kronecker
    product via np.kron.
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到我们在上面使用了⊗表示克罗内克积。这是约定俗成的符号，尽管⊗有时也会被滥用，用于表示其他的运算。比如，我们就用它来表示两个向量的外积。NumPy通过np.kron支持克罗内克积。
- en: Summary
  id: totrans-438
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter, we introduced the mathematical objects used in deep learning:
    scalars, vector, matrices, and tensors. We then explored arithmetic with tensors,
    in particular with vectors and matrices. We saw how to perform operations on these
    objects, both mathematically and in code via NumPy.'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了深度学习中使用的数学对象：标量、向量、矩阵和张量。接着，我们探讨了张量的运算，尤其是与向量和矩阵的运算。我们看到了如何在数学上以及通过NumPy代码对这些对象进行操作。
- en: Our exploration of linear algebra is not complete, however. In the next chapter,
    we’ll dive deeper into matrices and their properties to discuss just a handful
    of the important things that we can do with or know about them.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们对线性代数的探索还没有完成。在下一章，我们将深入研究矩阵及其性质，讨论一些我们可以用或需要了解的关于矩阵的重要内容。

<html><head></head><body><div id="sbo-rt-content"><h2 class="h2" id="ch04"><span epub:type="pagebreak" id="page_51"/><strong><span class="big">4</span><br/>WORKING WITH DATA</strong></h2>&#13;
<div class="imagec"><img src="Images/common.jpg" alt="image" width="189" height="189"/></div>&#13;
<p class="noindents">Developing a proper dataset is the single most important part of building a successful machine learning model. Machine learning models live and die by the phrase “garbage in, garbage out.” As you saw in <a href="ch01.xhtml#ch01">Chapter 1</a>, the model uses the training data to configure itself to the problem. If the training data is not a good representation of the data the model will receive when it is used, we can’t expect our model to perform well. In this chapter, we’ll learn how to create a good dataset that represents the data the model will encounter in the wild.</p>&#13;
<h3 class="h3" id="lev1_25">Classes and Labels</h3>&#13;
<p class="noindent">In this book, we’re exploring <em>classification</em>: we’re building models that put things into discrete categories, or <em>classes</em>, like dog breed, flower type, digit, and so on. To represent classes, we give each input in our training set an identifier called a <em>label</em>. A label could be the string “Border Collie" or, better still, a number like 0 or 1.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_52"/>Models don’t know what their inputs represent. They don’t care whether the input is a picture of a border collie or the value of Google stock. To the model, it’s all numbers. The same is true of labels. Because the label for the input has no intrinsic meaning to the model, we can represent classes however we choose. In practice, class labels are usually integers starting with 0. So, if there are 10 classes, the class labels are 0, 1, 2, …, 9. In <a href="ch05.xhtml#ch05">Chapter 5</a>, we’ll work with a dataset that has 10 classes representing images of different real-world things. We’ll simply map them to the integers as in <a href="ch04.xhtml#ch4tab1">Table 4-1</a>.</p>&#13;
<p class="tabcap" id="ch4tab1"><strong>Table 4-1:</strong> Label Classes with Integers: 0, 1, 2, . . .</p>&#13;
<table class="bordertb">&#13;
<colgroup>&#13;
<col style="width:50%"/>&#13;
<col style="width:50%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr class="borderb">&#13;
<th style="vertical-align: top"><p class="tab"><strong>Label</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>Actual class</strong></p></th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab">0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">airplanes</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">1</p></td>&#13;
<td style="vertical-align: top"><p class="tab">cars</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab">2</p></td>&#13;
<td style="vertical-align: top"><p class="tab">birds</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">3</p></td>&#13;
<td style="vertical-align: top"><p class="tab">cats</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab">4</p></td>&#13;
<td style="vertical-align: top"><p class="tab">deer</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">5</p></td>&#13;
<td style="vertical-align: top"><p class="tab">dogs</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab">6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">frogs</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">7</p></td>&#13;
<td style="vertical-align: top"><p class="tab">horses</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab">8</p></td>&#13;
<td style="vertical-align: top"><p class="tab">ships</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">9</p></td>&#13;
<td style="vertical-align: top"><p class="tab">trucks</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="indent">With that labeling, every training input that is a dog is labeled 5, while every input that is a truck is labeled 9. But what exactly is it that we’re labeling? In the next section, we’ll cover features and feature vectors, the very lifeblood of machine learning.</p>&#13;
<h3 class="h3" id="lev1_26">Features and Feature Vectors</h3>&#13;
<p class="noindent">Machine learning models take <em>features</em> as inputs and deliver, in the case of a classifier, a label as output. So what are these features and where do they come from?</p>&#13;
<p class="indent">For most models, features are numbers. What the numbers represent depends upon the task at hand. If we’re interested in identifying flowers based on measurements of their physical properties, our features are those measurements. If we’re interested in using the dimensions of cells in a medical sample to predict whether a tumor is breast cancer or not, the features are those dimensions. With modern techniques, the features might be the pixels of an image (numbers), or a sound’s frequency (numbers) or even how many foxes were counted by a camera trap over a two-week period (numbers).</p>&#13;
<p class="indent">Features, then, are whatever numbers we want to use as inputs. The goal of training the model is to get it to learn a relationship between <span epub:type="pagebreak" id="page_53"/>the input features and the output label. We assume that a relationship exists between the input features and output label before training the model. If the model fails to train, it might be that there is no relationship to learn.</p>&#13;
<p class="indent">After training, feature vectors with unknown class labels are given to the model, and the model’s output predicts the class label based on the relationships it discovered during training. If the model is repeatedly making poor predictions, one possibility is that the selected features are not sufficiently capturing that relationship. Before we go into what makes a good feature, let’s take a closer look at the features themselves.</p>&#13;
<h4 class="h4" id="lev2_28">Types of Features</h4>&#13;
<p class="noindent">To recap, features are numbers representing something that is measured or known, and <em>feature vectors</em> are sets of these numbers used as inputs to the model. There are different kinds of numbers you could use as features, and as you’ll see, they’re not all created equal. Sometimes you’ll have to manipulate them before you can input them into your model.</p>&#13;
<h5 class="h5">Floating-Point Numbers</h5>&#13;
<p class="noindent">In <a href="ch05.xhtml#ch05">Chapter 5</a>, we’ll be building a historic flower dataset. The features of that dataset are actual measurements of things like a flower’s sepal width and height (in centimeters). A typical measurement might be 2.33 cm. This is a <em>floating-point</em> number—a number with a decimal point, or, if you remember your high school math courses, a <em>real</em> number. Most models want to work with floating-point numbers, so you can just use the measurements as they are. Floating-point numbers are <em>continuous</em>, meaning there are an infinite number of values between one integer and the next, so we have a smooth transition between them. As we’ll see later on, some models expect continuous values.</p>&#13;
<h5 class="h5">Interval Values</h5>&#13;
<p class="noindent">Floating-point numbers don’t work for everything, however. Clearly, flowers cannot have 10.14 petals, though they might have 9, 10, or 11. These numbers are <em>integers</em>: whole numbers without a fractional part or a decimal point. Unlike floating-point numbers, they are <em>discrete</em>, which means they pick out only certain values, leaving gaps in between. Fortunately for us, integers are just special real numbers, so models can use them as they are.</p>&#13;
<p class="indent">In our petal example, the difference between 9, 10, and 11 is meaningful in that 11 is bigger than 10, and 10 is bigger than 9. Not only that, but 11 is bigger than 10 in exactly the same way that 10 is bigger than 9. The difference, or interval, between the values is the same: 1. This value is called an <em>interval</em> value.</p>&#13;
<p class="indent">The pixels in an image are interval values, because they represent the (assumed linear) response of some measurement device, like a camera or an MRI machine, to some physical process like intensity and color of visible light or the number of hydrogen protons in free water in tissue. The key point is that if value <em>x</em> is the next number in the sequence after value <em>y</em>, and <span epub:type="pagebreak" id="page_54"/>value <em>z</em> is the number before value <em>y</em>, then the difference between <em>x</em> and <em>y</em> is the same difference as between <em>y</em> and <em>z</em>.</p>&#13;
<h5 class="h5">Ordinal Values</h5>&#13;
<p class="noindent">Sometimes the interval between the values is not the same. For example, some models include someone’s educational level to predict whether or not they will default on a loan. If we encode someone’s educational level by counting their years of schooling, we could use that safely since the difference between 10 years of schooling and 8 is the same as the difference between 8 years of schooling and 6. However, if we simply assign 1 for “completed high school,” 2 for “has an undergraduate degree,” and 3 for “has a doctorate or other professional degree,” we’d probably be in trouble; while 3 &gt; 2 &gt; 1 is true, whether or not meaningful for our model, the difference between the values represented by 3 and 2 and 2 and 1 is not the same. Features like these are called <em>ordinal</em> because they express an ordering, but the differences between the values are not necessarily always the same.</p>&#13;
<h5 class="h5">Categorical Values</h5>&#13;
<p class="noindent">Sometimes we use numbers as codes. We might encode sex as 0 for male and 1 for female, for example. In this case, 1 is not understood to be greater than 0 or less than 0, so these are not interval or ordinal values. Instead, these are <em>categorical</em> values. They express a category but say nothing about any relationship between the categories.</p>&#13;
<p class="indent">Another common example, perhaps relevant to classifying flowers, is color. We might use 0 for red, 1 for green, and 2 for blue. Again, no relationship exists between 0, 1, or 2 in this case. This doesn’t mean we can’t use categorical features with our models, but it does mean that we usually can’t use them as they are since most types of machine learning models expect at least ordinal, if not interval numbers.</p>&#13;
<p class="indent">We can make categorical values at least ordinal by using the following trick. If we wanted to use a person’s sex as an input, instead of saying 0 for male and 1 for female, we would create a two-element vector, one element for each possibility. The first digit in the vector will indicate whether the input is male by signaling either 0 (meaning they’re not male) or 1 (meaning they are). The second digit will indicate whether or not they are female. We map the categorical values to a binary vector, as shown in <a href="ch04.xhtml#ch4tab2">Table 4-2</a>.</p>&#13;
<p class="tabcap" id="ch4tab2"><strong>Table 4-2:</strong> Representing Categories as Vectors</p>&#13;
<table class="bordertb">&#13;
<colgroup>&#13;
<col style="width:40%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:50%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr class="borderb">&#13;
<td style="vertical-align: top"><p class="tab"><strong>Categorical value</strong></p></td>&#13;
<td style="vertical-align: top"/>&#13;
<td style="vertical-align: top"><p class="tab"><strong>Vector representation</strong></p></td>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab">0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">→</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1 0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">1</p></td>&#13;
<td style="vertical-align: top"><p class="tab">→</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0 1</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_55"/>Here a 0 in the “is male” feature is meaningfully less than a 1 in that feature, which fits the definition of an ordinal value. The price we pay is to expand the number of features in our feature vector, as we need one feature for each of the possible categorical values. With five colors, for example, we would need a five-element vector; with five thousand, a five-thousand-element vector.</p>&#13;
<p class="indent">To use this scheme, the categories must be mutually exclusive, meaning there will be only one 1 in each row. Because there’s always only one nonzero value per row, this approach is sometimes called a <em>one-hot encoding</em>.</p>&#13;
<h4 class="h4" id="lev2_29">Feature Selection and the Curse of Dimensionality</h4>&#13;
<p class="noindent">This section is about <em>feature selection</em>, the process of selecting which features to use in your feature vectors, and why you shouldn’t include features you don’t need. Here’s a good rule of thumb: the feature vector should contain only features that capture aspects of the data that allow the model to generalize to new data.</p>&#13;
<p class="indent">In other words, features should capture aspects of the data that help the model separate the classes. It’s impossible to be more explicit, since the set of best features are always dataset specific, unknowable in advance. But that doesn’t mean we can’t say things that might be helpful in guiding us toward a useful set of features for whatever dataset we’re working with.</p>&#13;
<p class="indent">Like many things in machine learning, selecting features comes with trade-offs. We need enough features to capture all the relevant parts of the data so that the model has something to learn from, but if we have too many features, we fall victim to the <em>curse of dimensionality</em>.</p>&#13;
<p class="indent">To explain what this means, let’s look at an example. Suppose our features are all restricted to the range [0,1). That’s not a typo; we’re using interval notation, where a square bracket means the bound is included in the range, and a parenthesis means the bound is excluded. So here 0 is allowed but 1 isn’t. We’ll also assume our feature vectors are either two-dimensional or three-dimensional. That way, we can plot each feature vector as a point in a 2D or 3D space. Finally, we’ll simulate datasets by selecting feature vectors, 2D or 3D, uniformly at random so that each element of the vector is in [0,1).</p>&#13;
<p class="indent">Let’s fix the number of samples at 100. If we have two features, or a 2D space, we can represent 100 randomly selected 2D vectors as in the top of <a href="ch04.xhtml#ch4fig1">Figure 4-1</a>. Now, if we have three features, or a 3D space, those same 100 features look like the bottom of <a href="ch04.xhtml#ch4fig1">Figure 4-1</a>.</p>&#13;
<div class="image" id="ch4fig1"><span epub:type="pagebreak" id="page_56"/><img src="Images/04fig01.jpg" alt="image" width="680" height="1058"/></div>&#13;
<p class="figcap"><em>Figure 4-1: One hundred random samples in 2D space (top) and in 3D space (bottom)</em></p>&#13;
<p class="indent">Since we’re assuming our feature vectors can come from anywhere in the 2D or 3D space, we want our dataset to sample as much of that space as possible so that it represents the space well. We can get a measure of how <span epub:type="pagebreak" id="page_57"/>well the 100 points are filling the space by splitting each axis into 10 equal sections. Let’s call these sections <em>bins</em>. We’ll end up with 100 bins in the 2D space, because it has two axes (10 × 10), and 1,000 in the 3D space, because it has three axes (10 × 10 × 10). Now, if we count the number of bins occupied by at least one point and divide that number by the total number of bins, we’ll get the fraction of bins that are occupied.</p>&#13;
<p class="indent">Doing this gives us 0.410 (out of a maximum of 1.0) for the 2D space and 0.048 for the 3D space. This means that 100 samples were able to sample about half of the 2D feature space. Not bad! But 100 samples in the 3D feature space sampled only about 5 percent of the space. To fill the 3D space to the same fraction as the 2D space, we’d need about 1,000—or 10 times as many as we have. This general rule applies as the dimensionality increases: a 4D feature space would need about 10,000 samples, while a 10D feature space would need about 10,000,000,000! As the number of features increases, the amount of training data we need to get a representative sampling of the possible feature space increases dramatically, approximately as 10<sup><em>d</em></sup>, where <em>d</em> is the number of dimensions. This is the <em>curse of dimensionality</em>, and it was the bane of machine learning for decades. Fortunately for us, modern deep learning has overcome this curse, but it’s still relevant when working with traditional models like the ones we will explore in <a href="ch06.xhtml#ch06">Chapter 6</a>.</p>&#13;
<p class="indent">For example, a typical color image on your computer might have 1,024 pixels on a side where each pixel requires 3 bytes to specify the color as a mix of red, green, and blue. If we wanted to use this image as input to a model, we’d need a feature vector with <em>d</em> = 1024 × 1024 × 3 = 3,145,728 elements. This means we’d need some 10<sup>3,145,728</sup> samples to populate our feature space. Clearly, this is not possible. We’ll see in <a href="ch12.xhtml#ch12">Chapter 12</a> how to overcome this curse by using a convolutional neural network.</p>&#13;
<p class="indent">Now that we know about classes, features, and feature vectors, let’s describe what it means to have a good dataset.</p>&#13;
<h3 class="h3" id="lev1_27">Features of a Good Dataset</h3>&#13;
<p class="noindent">The dataset is everything. This is no exaggeration, since we build the model from the dataset. The model has parameters—be they the weights and biases of a neural network, the probabilities of each feature occurring in a Naïve Bayes model, or the training data itself in the case of Nearest Neighbors. The parameters are what we use the training data to find out: they encode the knowledge of the model and are learned by the training algorithm.</p>&#13;
<p class="indent">Let’s back up a little bit and define the term <em>dataset</em> as we we’ll use it in this book. Intuitively, we understand what a dataset is, but let’s be more scientific and define it as a collection of pairs of values, {<em>X,Y</em>}, where <em>X</em> is an <em>input</em> to the model and <em>Y</em> is a label. Here <em>X</em> is some set of values that we’ve measured and grouped together, like length and width of flower parts, and <em>Y</em> is the thing we want to teach the model to tell us, such as which flower or which animal the data best represents.</p>&#13;
<p class="indent">For <em>supervised</em> learning, we act as the teacher, and the model acts as the student. We are teaching the student by presenting example after example, <span epub:type="pagebreak" id="page_58"/>saying things like “this is a cat” and “this is a dog,” much as we would teach a small child with a picture book. In this case, the <em>dataset</em> is a collection of examples, and <em>training</em> consists of showing the examples to the model repeatedly, until the model “gets it”—that is, until the parameters of the model are conditioned and adjusted to minimize the error made by the model for this particular dataset. This is the learning part of machine learning.</p>&#13;
<h4 class="h4" id="lev2_30">Interpolation and Extrapolation</h4>&#13;
<p class="noindent"><em>Interpolation</em> is the process of estimating within a certain known range. And <em>extrapolation</em> occurs when we use the data we have to estimate outside the known range. Generally speaking, our models are more accurate when they in some sense interpolate, which means we need a dataset that is a comprehensive representation of the range of values that could be used as inputs to the model.</p>&#13;
<p class="indent">As an example, let’s look at world population, in billions, from 1910 to 1960 (<a href="ch04.xhtml#ch4tab3">Table 4-3</a>). We have data for every 10 years in our known range, 1910 to 1960.</p>&#13;
<p class="tabcap" id="ch4tab3"><strong>Table 4-3:</strong> The World Population by Decade</p>&#13;
<table class="bordertb">&#13;
<colgroup>&#13;
<col style="width:50%"/>&#13;
<col style="width:50%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr class="borderb">&#13;
<th style="vertical-align: top"><p class="tab"><strong>Year</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>Population (billions)</strong></p></th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab">1910</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.750</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">1920</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.860</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab">1930</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2.070</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">1940</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2.300</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab">1950</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2.557</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">1960</p></td>&#13;
<td style="vertical-align: top"><p class="tab">3.042</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="noindent">If we find the “best fitting” line to plot through this data, we can use it as a model to predict values. This is called <em>linear regression</em>, and it allows us to estimate the population for any year we choose. We’ll skip the actual fitting process, which you can do simply with online tools, and jump to the model:</p>&#13;
<p class="center"><em>p</em> = 0.02509<em>y</em> – 46.28</p>&#13;
<p class="noindent">For any year, <em>y</em>, we can get an estimate of the population, <em>p</em>. What was the world population in 1952? We don’t have actual data for 1952 in our table, but using the model, we can estimate it like so:</p>&#13;
<p class="center"><em>p</em> = 0.02509(1952) – 46.28 = 2.696 billion</p>&#13;
<p class="noindent">By checking the actual world population data for 1952, we know that it was 2.637 billion, so our estimate of 2.696 billion was only some 60 million off. The model seems to be pretty good!</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_59"/>In using the model to estimate the world population in 1952, we performed interpolation. We made an estimate for a value that was between data points we had, and the model gave us a good result. Extrapolation, on the other hand, is measuring beyond what is known, outside the range of our data.</p>&#13;
<p class="indent">Let’s use our model to estimate world population in 2000, 40 years after the data we used to build our model ends:</p>&#13;
<p class="center"><em>p</em> = 0.02509(2000) – 46.28 = 3.900 billion</p>&#13;
<p class="noindent">According to the model, it should be close to 3.9 billion, but we know from actual data that the world population in 2000 was 6.089 billion. Our model is off by over 2 billion people. What happened here is that we applied the model to input it wasn’t suited for. If we remain in the range of inputs that the model is “trained” to know about, namely, dates from 1910 through 1960, then the model performs well enough. Once we went beyond the model’s training, however, it fell apart because it assumed knowledge we didn’t possess.</p>&#13;
<p class="indent">When we interpolate, the model will see examples that are similar to the set of examples it saw during training. Perhaps unsurprisingly, it will do better on these examples than when we extrapolate and ask the model to go beyond its training.</p>&#13;
<p class="indent">When it comes to classification, it’s essential we have comprehensive training data. Let’s assume we’re training a model to identify dog breeds. In our dataset, we have hundreds of images of classic black-and-white border collies like the one on the left in <a href="ch04.xhtml#ch4fig2">Figure 4-2</a>. If we then give the model a new image of a classic border collie, we will, hopefully, get back a correct label: “Border Collie.” This is akin to asking the model to interpolate: it’s working with something is has already seen before because the “Border Collie” label in the training data included many examples of classic border collies.</p>&#13;
<div class="image" id="ch4fig2"><img src="Images/04fig02.jpg" alt="image" width="680" height="226"/></div>&#13;
<p class="figcap"><em>Figure 4-2: A border collie with classic markings (left), a border collie with liver-colored markings (middle), an Australian shepherd (right)</em></p>&#13;
<p class="indent">However, not every border collie has the classic border collie markings. Some are marked like the collie in the middle of <a href="ch04.xhtml#ch4fig2">Figure 4-2</a>. Since we didn’t include images like this in the training set, the model must now try to go beyond what it was trained to do and give a correct output label for an instance of a class it was trained on but of a type it was not trained with. It will likely <span epub:type="pagebreak" id="page_60"/>fail, giving a false output like “Australian Shepherd,” a breed similar to a border collie, as seen on the right of <a href="ch04.xhtml#ch4fig2">Figure 4-2</a>.</p>&#13;
<p class="indent">The key concept to remember, however, is that the dataset must cover the full range of variation <em>within</em> the classes the model will see when the model is predicting labels for unknown inputs.</p>&#13;
<h4 class="h4" id="lev2_31">The Parent Distribution</h4>&#13;
<p class="noindent">The dataset must be representative of the classes it’s modeling. Buried in this idea is the assumption that our data has a <em>parent distribution</em>, an unknown data generator that created the particular dataset we’re using.</p>&#13;
<p class="indent">Consider this parallel from philosophy. The ancient Greek philosopher Plato uses the concept of ideals. In his view, there was an ideal chair somewhere “out there,” and all existing chairs were more or less perfect copies of that ideal chair. This is what we mean by the relationship between the dataset we are using, the copy, and the parent distribution, the ideal generator. We want the dataset to be a representation of the ideal.</p>&#13;
<p class="indent">We can think of a dataset as a sample from some unknown process that produces data according to the parent distribution. The type of data it produces—the values and ranges of the features—will follow some unknown, statistical rule. For example, when you roll a die, each of the six values is equally likely in the long run. We call this a <em>uniform parent distribution</em>. If you make a bar graph of the number of times each value appears as you roll the die many times, then you will get a (more or less) horizontal line since each value is equally likely to happen. We see a different distribution when we measure the height of adults. The distribution of heights will have a form with two humps, one around mean male height and the other around mean female height.</p>&#13;
<p class="indent">The parent distribution is what generates this overall shape. The training data, the test data, and the data you give the model to make decisions must all come from the same parent distribution. This is a fundamental assumption models make, and one that shouldn’t seem too surprising to us. Still, sometimes it’s easy to mix things up and train with data from one parent distribution while testing or using the model with data from a different parent distribution. (How to train with one parent distribution and use that model with data from a different distribution is a very active research area at the moment. Search for “domain adaptation.”)</p>&#13;
<h4 class="h4" id="lev2_32">Prior Class Probabilities</h4>&#13;
<p class="noindent">The <em>prior class probability</em> is the probability with which each class in the dataset appears in the wild.</p>&#13;
<p class="indent">In general, we want our dataset to match the prior probabilities of the classes. If class A appears 85 percent of the time and class B only 15 percent of the time, then we want class A to appear 85 percent of the time and class B to appear 15 percent of the time in our training set.</p>&#13;
<p class="indent">There are exceptions, however. Say one of the classes we want the model to learn is rare, showing up only once for every 10,000 inputs. If we make <span epub:type="pagebreak" id="page_61"/>the dataset strictly follow the actual prior probabilities, the model might not see enough examples of the rare class to learn anything helpful about it. And, worse yet, what if the rare class is the class we are most interested in?</p>&#13;
<p class="indent">For example, let’s pretend we’re building a robot that locates four-leaf clovers. We’ll assume that we already know that the input to the model is a clover; we just want to know whether it has three or four leaves. We know that an estimated 1 in every 5,000 clovers is a four-leaf clover. Building a dataset with 5,000 three-leaf clovers for every instance of a four-leaf clover seems reasonable until we realize that a model that simply says every input is a three-leaf clover will be right, on average, 4,999 times out of 5,000! It will be an extremely accurate but completely useless model because it never finds the class we’re interested in.</p>&#13;
<p class="indent">Instead, we might use a 10:1 ratio of three-leaf to four-leaf clovers. Or, when training the model, we might start with an even number of three- and four-leaf clovers, and then, after training for a time, change to a mix that is increasingly closer to the actual prior probability. This trick doesn’t work for all model types, but it does work for neural networks. Why this trick works is poorly understood but, intuitively, we can imagine the network learning first about the visual difference between a three-leaf and four-leaf clover and then learning something about the actual likelihood of encountering a four-leaf clover as the mix changes to be closer to the actual prior probabilities.</p>&#13;
<p class="indent">In reality, the trick is used because it often results in better-performing models. For much of machine learning, especially deep learning, empirical tricks and techniques are well in advance of any theory to back them up. “It just works better; that’s why” is still a valid, though ultimately unsatisfying, answer to many questions about why a particular approach works well.</p>&#13;
<p class="indent">How to work with imbalanced data is something the research community is still actively investigating. Some choose to start with a more balanced ratio of classes; others use data augmentation (see <a href="ch05.xhtml#ch05">Chapter 5</a>) to boost the number of samples from the underrepresented class.</p>&#13;
<h4 class="h4" id="lev2_33">Confusers</h4>&#13;
<p class="noindent">We said that we need to include examples in our dataset that reflect all the natural variation in the classes we want to learn. This is definitely true, but at times it is particularly important to include training samples that are similar to one or more of our classes but really are not examples of that class.</p>&#13;
<p class="indent">Consider two models. The first learns the difference between images of dogs and images of cats. The second learns the difference between images of dogs and images that are not dogs. The first model has it easy. The input is either a dog or a cat, and the model is trained using images of dogs and images of cats. The second model, however, has it rougher. It’s obvious that we need images of dogs for training. But, what should the “not dog” images be? Given the preceding discussion, we should be starting to intuit that we’ll need images that cover the space of images the model will see in the wild.</p>&#13;
<p class="indent">We can take this one step further. If we want to tell the difference between dogs and not dogs, we should be sure to include wolves in the “not a dog” class when training. If we don’t, the model might not learn enough to <span epub:type="pagebreak" id="page_62"/>tell the difference when it encounters a wolf and will return a “dog” classification. If we build the dataset by using hundreds of “not dog” images that are all pictures of penguins and parrots, should we be surprised if the model decides to call a wolf a dog?</p>&#13;
<p class="indent">In general, we need to make sure the dataset includes <em>confusers</em>, or <em>hard negatives</em>—examples that are similar enough to other classes to be mistaken for them, but don’t belong in the class. Confusers give the model a chance to learn the more precise features of a class. Hard negatives are particularly useful when distinguishing between something and everything else, as in “dog” versus “not dog.”</p>&#13;
<h4 class="h4" id="lev2_34">Dataset Size</h4>&#13;
<p class="noindent">So far we’ve talked about what kind of data to include in a dataset, but how much of it do we need? “All of it" is a temptingly cheeky answer. For our model to be as precise as possible, we should use as many examples as possible. But it’s rarely possible to get all of the data.</p>&#13;
<p class="indent">Choosing the size of your dataset means considering a trade-off between accuracy and the time and energy it takes to acquire the data. Acquiring data can be expensive or slow, or, as we saw with our clover example, sometimes the key class of the dataset is rare and seldom encountered. Because labeled data is generally expensive and slow to acquire, we should have some idea of how much we need before we get started.</p>&#13;
<p class="indent">Unfortunately, the truth is that there is no formula that answers the question of how much data is enough data. After a certain point, there are diminishing returns on the benefit of additional data. Moving from 100 examples to 1,000 examples might boost the accuracy of the model dramatically, but moving from 1,000 to 10,000 examples might offer only a small increase in accuracy. The increased accuracy needs to be balanced against the effort and expense of acquiring an additional 9,000 training examples.</p>&#13;
<p class="indent">Another factor to consider is the model itself. Models have a <em>capacity</em>, which determines the complexity they can support relative to the amount of training data available. The capacity of a model is directly related to its number of parameters. A larger model with more parameters will require a lot of training data to be able to find the proper parameter settings. And though it’s often a good idea to have more training examples than model parameters, deep learning can work well when there is less training data than parameters. For example, if the classes are very different from each other—think buildings versus oranges—and it’s easy for us to tell the difference, the model likely will also learn the difference quickly, so we can get away with fewer training examples. On the other hand, if we’re trying to separate wolves from huskies, we might need a lot more data. We will discuss what to do when you don’t have a lot of training data in <a href="ch05.xhtml#ch05">Chapter 5</a>, but none of those tricks are a good substitute for simply getting more data.</p>&#13;
<p class="indent">The only correct answer to the question of how much data is needed is “all of it.” Get as much as is <em>practical</em>, given the constraints of the problem: expense, time, rarity, and so forth.</p>&#13;
<h3 class="h3" id="lev1_28"><span epub:type="pagebreak" id="page_63"/>Data Preparation</h3>&#13;
<p class="noindent">Before we move on to building actual datasets, we’re going to cover two situations you’ll likely encounter before you can feed your dataset to a model: how to scale features, and what to do if a feature value is missing.</p>&#13;
<h4 class="h4" id="lev2_35">Scaling Features</h4>&#13;
<p class="noindent">A feature vector built from a set of different features might have a variety of ranges. One feature might take on a wide range of values, say, –1000 to 1000, while another might be restricted to a range of 0 to 1. Some models will not work well when this happens, as one feature dominates the others because of its range. Also, some model types are happiest when features have a mean value that is close to 0.</p>&#13;
<p class="indent">The solution to these issues is scaling. We’ll assume for the time being that every feature in the feature vector is continuous. We’ll work with a fake dataset consisting of five features and 15 samples. This means that our dataset has 15 samples—feature vectors and their labels—and each of the feature vectors has five elements. We’ll assume there <span epub:type="pagebreak" id="page_64"/>are three classes. The dataset looks like <a href="ch04.xhtml#ch4tab4">Table 4-4</a>.</p>&#13;
<p class="tabcap" id="ch4tab4"><strong>Table 4-4:</strong> A Hypothetical Dataset</p>&#13;
<table class="bordertb">&#13;
<colgroup>&#13;
<col style="width:5%"/>&#13;
<col style="width:15%"/>&#13;
<col style="width:15%"/>&#13;
<col style="width:20%"/>&#13;
<col style="width:20%"/>&#13;
<col style="width:20%"/>&#13;
<col style="width:5%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr class="borderb">&#13;
<th style="vertical-align: top"><p class="tab"><strong>Sample</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong><em>x</em><sub>0</sub></strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong><em>x</em><sub>1</sub></strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong><em>x</em><sub>2</sub></strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong><em>x</em><sub>3</sub></strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong><em>x</em><sub>4</sub></strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>Label</strong></p></th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><em>0</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">6998</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.1361</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.3408</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.00007350</p></td>&#13;
<td style="vertical-align: top"><p class="tab">78596048</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab"><em>1</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">6580</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.4908</p></td>&#13;
<td style="vertical-align: top"><p class="tab">3.0150</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.00004484</p></td>&#13;
<td style="vertical-align: top"><p class="tab">38462706</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><em>2</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">7563</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.9349</p></td>&#13;
<td style="vertical-align: top"><p class="tab">4.3465</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.00001003</p></td>&#13;
<td style="vertical-align: top"><p class="tab">6700340</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab"><em>3</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">8355</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6529</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2.1271</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.00002966</p></td>&#13;
<td style="vertical-align: top"><p class="tab">51430391</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><em>4</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">2393</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.4605</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2.7561</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.00003395</p></td>&#13;
<td style="vertical-align: top"><p class="tab">27284192</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab"><em>5</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">9498</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0244</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2.7887</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.00008880</p></td>&#13;
<td style="vertical-align: top"><p class="tab">78543394</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><em>6</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">4030</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6467</p></td>&#13;
<td style="vertical-align: top"><p class="tab">4.8231</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.00000403</p></td>&#13;
<td style="vertical-align: top"><p class="tab">19101443</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab"><em>7</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">5275</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.3560</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0705</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.00000899</p></td>&#13;
<td style="vertical-align: top"><p class="tab">96029352</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><em>8</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">8094</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.7979</p></td>&#13;
<td style="vertical-align: top"><p class="tab">3.9897</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.00006691</p></td>&#13;
<td style="vertical-align: top"><p class="tab">7307156</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab"><em>9</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">843</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.7892</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.9804</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.00005798</p></td>&#13;
<td style="vertical-align: top"><p class="tab">10179751</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><em>10</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">1221</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.9564</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2.3944</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.00007815</p></td>&#13;
<td style="vertical-align: top"><p class="tab">14241835</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab"><em>11</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">5879</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0329</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2.0085</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.00009564</p></td>&#13;
<td style="vertical-align: top"><p class="tab">34243070</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><em>12</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">923</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.4159</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.7821</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.00002467</p></td>&#13;
<td style="vertical-align: top"><p class="tab">52404615</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab"><em>13</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">5882</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0002</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.5362</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.00005066</p></td>&#13;
<td style="vertical-align: top"><p class="tab">18728752</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><em>14</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">1796</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.7247</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2.3190</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.00001332</p></td>&#13;
<td style="vertical-align: top"><p class="tab">96703562</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="indent">As this is the first dataset covered in the book, let’s go over it thoroughly to introduce some notation and see what is what. The first column in <a href="ch04.xhtml#ch4tab4">Table 4-4</a> is the sample number. The sample is an input, in this case a collection of five features representing a feature vector. Notice that the numbering starts at 0. As we’ll be using Python arrays (NumPy arrays) for data, we’ll start counting at 0 in all cases.</p>&#13;
<p class="indent">The next five columns are the features in each sample, labeled <em>x</em><sub>0</sub> to <em>x</em><sub>4</sub>, again starting indices at 0. The final column is the class label. Since there are three classes, the labels run from 0 through 2. There are five samples from class 0, five from class 1, and five from class 2. Therefore, this is a small but balanced dataset; the prior probability of each class is 33 percent, which should, ideally, be close to the actual prior probability of the classes appearing in the wild.</p>&#13;
<p class="indent">If we had a model, then each row would be its own input. Writing {<em>x</em><sub>0</sub>, <em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>, <em>x</em><sub>3</sub>, <em>x</em><sub>4</sub>} to refer to these is tedious, so instead, when we are referring to a full feature vector, we’ll use an uppercase letter. For example, we’d refer to Sample 2 as <em>X</em><sub>2</sub> for dataset <em>X</em>. We’ll also sometimes use matrices—2D arrays of numbers—that are also labeled with uppercase letters, for clarity. When we want to refer to a single feature, we’ll use a lowercase letter with subscript, for example, <em>x</em><sub>3</sub>.</p>&#13;
<p class="indent">Let’s look at the ranges of the features. The minimum, maximum, and range (the difference between the maximum and minimum) of each feature are shown in <a href="ch04.xhtml#ch4tab5">Table 4-5</a>.</p>&#13;
<p class="tabcap" id="ch4tab5"><strong>Table 4-5:</strong> The Minimum, Maximum, and Range of the Features in <a href="ch04.xhtml#ch4tab4">Table 4-4</a></p>&#13;
<table class="bordertb">&#13;
<colgroup>&#13;
<col style="width:10%"/>&#13;
<col style="width:30%"/>&#13;
<col style="width:30%"/>&#13;
<col style="width:30%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr>&#13;
<th style="vertical-align: top"><p class="tab"><strong>Feature</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>Minimum</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>Maximum</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>Range</strong></p></th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><em>x</em><sub>0</sub></p></td>&#13;
<td style="vertical-align: top"><p class="tab">843.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">9498.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">8655.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab"><em>x</em><sub>1</sub></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0002</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.9564</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.9562</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><em>x</em><sub>2</sub></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0705</p></td>&#13;
<td style="vertical-align: top"><p class="tab">4.8231</p></td>&#13;
<td style="vertical-align: top"><p class="tab">4.7526</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab"><em>x</em><sub>3</sub></p></td>&#13;
<td style="vertical-align: top"><p class="tab">4.03e-06</p></td>&#13;
<td style="vertical-align: top"><p class="tab">9.564e-05</p></td>&#13;
<td style="vertical-align: top"><p class="tab">9.161e-05</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><em>x</em><sub>4</sub></p></td>&#13;
<td style="vertical-align: top"><p class="tab">6700340.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">96703562.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">90003222.0</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="indent">Note the use of computer notation like 9.161e-05. This how computers represent scientific notation: 9.161 × 10<sup><em>–</em>5</sup> = 0.00009161. Notice, also, that each feature covers a very different range. Because of this, we’ll want to scale the features so their ranges are more similar. Scaling is a valid thing to do prior to training a model as long as you scale all new inputs the same way.</p>&#13;
<h5 class="h5">Mean Centering</h5>&#13;
<p class="noindent">The simplest form of scaling is <em>mean centering</em>. This is easy to do: from each feature, simply subtract the mean (average) value of the feature over the entire dataset. The mean over a set of values, <em>x</em><sub><em>i</em></sub> <em>i</em> =  0, 1, 2, … is simply the sum of each value divided by the number of values:</p>&#13;
<div class="imagec"><img src="Images/064equ01.jpg" alt="image" width="102" height="64"/></div>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_65"/>The mean value for feature <em>x</em><sub>0</sub> is 5022, so to center <em>x</em><sub>0</sub>, we replace each value like so:</p>&#13;
<p class="center"><em>x<sub>i</sub></em> ← <em>x<sub>i</sub></em> – 5022, <em>i</em> = 0, 1, 2, . . .</p>&#13;
<p class="noindent">where in this case the <em>i</em> index is across the samples, not the other elements of the feature vector.</p>&#13;
<p class="indent">Repeating the preceding steps for the mean value of all the other features will center the entire dataset. The result is that the mean value of each feature, over the dataset, is now 0, meaning the feature values themselves are all above and below 0. For deep learning, mean centering is often done by subtracting a mean image from each input image.</p>&#13;
<h5 class="h5">Changing the Standard Deviation to 1</h5>&#13;
<p class="noindent">Mean centering helps, but the distribution of values around 0 remains the same as before the mean was subtracted. All we did was shift the data down toward 0. The spread of values around the mean has a formal name: it’s called the <em>standard deviation</em>, and it’s computed as the average difference of the data values and the mean:</p>&#13;
<div class="imagec"><img src="Images/065equ01.jpg" alt="image" width="173" height="63"/></div>&#13;
<p class="noindent">The letter <em>σ</em> (sigma) is the usual name for the standard deviation in mathematics. You don’t need to memorize this formula. It’s there to show us how to calculate a measure of the spread, or range, of the data relative to the mean value of the data.</p>&#13;
<p class="indent">Mean centering changes <span class="middle"><img src="Images/xbar.jpg" alt="Image"/></span> to 0, but it does not change <em>σ</em>. Sometimes we want to go further and, along with mean centering, change the spread of the data so that the ranges are the same, meaning the standard deviation for each feature is 1. Fortunately, doing this is straightforward. We replace each feature value, <em>x</em>, with</p>&#13;
<div class="imagec"><img src="Images/065equ02.jpg" alt="image" width="83" height="43"/></div>&#13;
<p class="noindent">where <span class="middle"><img src="Images/xbar.jpg" alt="Image"/></span> and <em>σ</em> are the mean and standard deviation of each feature across the dataset. For example, the preceding toy dataset can be stored as a 2D NumPy array</p>&#13;
<pre>x = [<br/>&#13;
 [6998, 0.1361, 0.3408, 0.00007350, 78596048],<br/>&#13;
 [6580, 0.4908, 3.0150, 0.00004484, 38462706],<br/>&#13;
 [7563, 0.9349, 4.3465, 0.00001003,  6700340],<br/>&#13;
 [8355, 0.6529, 2.1271, 0.00002966, 51430391],<br/>&#13;
 [2393, 0.4605, 2.7561, 0.00003395, 27284192],<br/>&#13;
 [9498, 0.0244, 2.7887, 0.00008880, 78543394],<br/>&#13;
 [4030, 0.6467, 4.8231, 0.00000403, 19101443],<br/>&#13;
<span epub:type="pagebreak" id="page_66"/> [5275, 0.3560, 0.0705, 0.00000899, 96029352],<br/>&#13;
 [8094, 0.7979, 3.9897, 0.00006691,  7307156],<br/>&#13;
 [ 843, 0.7892, 0.9804, 0.00005798, 10179751],<br/>&#13;
 [1221, 0.9564, 2.3944, 0.00007815, 14241835],<br/>&#13;
 [5879, 0.0329, 2.0085, 0.00009564, 34243070],<br/>&#13;
 [ 923, 0.4159, 1.7821, 0.00002467, 52404615],<br/>&#13;
 [5882, 0.0002, 1.5362, 0.00005066, 18728752],<br/>&#13;
 [1796, 0.7247, 2.3190, 0.00001332, 96703562],<br/>&#13;
]<br/>&#13;
</pre>&#13;
<p class="noindent">so that the entire dataset can be processed in one line of code:</p>&#13;
<pre>x = (x - x.mean(axis=0)) / x.std(axis=0)</pre>&#13;
<p class="indent">This approach is called <em>standardization</em> or <em>normalizing</em>, and you should do it to most datasets, especially when using one of the traditional models discussed in <a href="ch06.xhtml#ch06">Chapter 6</a>. Whenever possible, standardize your dataset so that the features have 0 mean and a standard deviation of 1.</p>&#13;
<p class="indent">If we standardize the preceding dataset, what will it look like? Subtracting, per feature, the mean value of that feature and dividing by the standard deviation gives us a new dataset (<a href="ch04.xhtml#ch4tab6">Table 4-6</a>). Here, we’ve shortened the numbers to four decimal digits for display and have dropped the label.</p>&#13;
<p class="tabcap" id="ch4tab6"><strong>Table 4-6:</strong> The Data in <a href="ch04.xhtml#ch4tab4">Table 4-4</a> Standardized</p>&#13;
<table class="bordertb">&#13;
<colgroup>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:20%"/>&#13;
<col style="width:20%"/>&#13;
<col style="width:20%"/>&#13;
<col style="width:20%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr class="borderb">&#13;
<th style="vertical-align: top"><p class="tab"><strong>Sample</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong><em>x</em><sub>0</sub></strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong><em>x</em><sub>1</sub></strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong><em>x</em><sub>2</sub></strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong><em>x</em><sub>3</sub></strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong><em>x</em><sub>4</sub></strong></p></th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><em>0</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6930</p></td>&#13;
<td style="vertical-align: top"><p class="tab">–1.1259</p></td>&#13;
<td style="vertical-align: top"><p class="tab">–1.5318</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.9525</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.1824</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab"><em>1</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.5464</p></td>&#13;
<td style="vertical-align: top"><p class="tab">–0.0120</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.5051</p></td>&#13;
<td style="vertical-align: top"><p class="tab">–0.0192</p></td>&#13;
<td style="vertical-align: top"><p class="tab">–0.1141</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><em>2</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.8912</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.3826</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.5193</p></td>&#13;
<td style="vertical-align: top"><p class="tab">–1.1996</p></td>&#13;
<td style="vertical-align: top"><p class="tab">–1.1403</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab"><em>3</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.1690</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.4970</p></td>&#13;
<td style="vertical-align: top"><p class="tab">–0.1712</p></td>&#13;
<td style="vertical-align: top"><p class="tab">–0.5340</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.3047</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><em>4</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">–0.9221</p></td>&#13;
<td style="vertical-align: top"><p class="tab">–0.1071</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.3079</p></td>&#13;
<td style="vertical-align: top"><p class="tab">–0.3885</p></td>&#13;
<td style="vertical-align: top"><p class="tab">–0.4753</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab"><em>5</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.5699</p></td>&#13;
<td style="vertical-align: top"><p class="tab">–1.4767</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.3327</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.4714</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.1807</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><em>6</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">–0.3479</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.4775</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.8823</p></td>&#13;
<td style="vertical-align: top"><p class="tab">–1.4031</p></td>&#13;
<td style="vertical-align: top"><p class="tab">–0.7396</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab"><em>7</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0887</p></td>&#13;
<td style="vertical-align: top"><p class="tab">–0.4353</p></td>&#13;
<td style="vertical-align: top"><p class="tab">–1.7377</p></td>&#13;
<td style="vertical-align: top"><p class="tab">–1.2349</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.7456</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><em>8</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.0775</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.9524</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.2475</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.7291</p></td>&#13;
<td style="vertical-align: top"><p class="tab">–1.1207</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab"><em>9</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">–1.4657</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.9250</p></td>&#13;
<td style="vertical-align: top"><p class="tab">–1.0446</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.4262</p></td>&#13;
<td style="vertical-align: top"><p class="tab">–1.0279</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><em>10</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">–1.3332</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.4501</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0323</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.1102</p></td>&#13;
<td style="vertical-align: top"><p class="tab">–0.8966</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab"><em>11</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.3005</p></td>&#13;
<td style="vertical-align: top"><p class="tab">–1.4500</p></td>&#13;
<td style="vertical-align: top"><p class="tab">–0.2615</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.7033</p></td>&#13;
<td style="vertical-align: top"><p class="tab">–0.2505</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><em>12</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">–1.4377</p></td>&#13;
<td style="vertical-align: top"><p class="tab">–0.2472</p></td>&#13;
<td style="vertical-align: top"><p class="tab">–0.4340</p></td>&#13;
<td style="vertical-align: top"><p class="tab">–0.7032</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.3362</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab"><em>13</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.3016</p></td>&#13;
<td style="vertical-align: top"><p class="tab">–1.5527</p></td>&#13;
<td style="vertical-align: top"><p class="tab">–0.6213</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.1780</p></td>&#13;
<td style="vertical-align: top"><p class="tab">–0.7517</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><em>14</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">–1.1315</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.7225</p></td>&#13;
<td style="vertical-align: top"><p class="tab">–0.0250</p></td>&#13;
<td style="vertical-align: top"><p class="tab">–1.0881</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.7674</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="indent">If you compare the two tables, you’ll see that after our manipulations, the features are more similar than they were in the original set. If we look at <em>x</em><sub>3</sub>, we’ll see that the mean of the values is <em>–</em> 1.33<em>e –</em> 16 = <em>–</em>1.33 × 10<sup><em>–</em>16</sup> = <em>–</em>0.000000000000000133, which is virtually 0. Good! This is what we want. If you do the calculations, you’d see that the means of the other features are similarly close to 0. What about the standard deviation? For <em>x</em><sub>3</sub> it’s <span epub:type="pagebreak" id="page_67"/>0.99999999, which is virtually 1—again, this is what we’d like. We’ll use this new, transformed, dataset to train the model.</p>&#13;
<p class="indent">Therefore, we must apply the per feature means and standard deviations, as measured on the training set, to any new inputs we’re giving to the model:</p>&#13;
<div class="imagec"><img src="Images/067equ01.jpg" alt="image" width="179" height="47"/></div>&#13;
<p class="noindent">Here, <em>x</em><sub>new</sub> is the new feature vector we want to apply to the model, and <span class="middle"><img src="Images/067equ02.jpg" alt="Image" width="44" height="18"/></span> and <em>σ</em><sub>train</sub> are the mean and standard deviation, per feature, from the training set.</p>&#13;
<h4 class="h4" id="lev2_36">Missing Features</h4>&#13;
<p class="noindent">Sometimes we don’t have all the features we need for a sample. We might have forgotten to make a measurement, for example. These are <em>missing features</em>, and we need to find a way to correct them, since most models don’t have the ability to accept missing data.</p>&#13;
<p class="indent">One solution is to fill in the missing values with values that are outside of the feature’s range, in the hopes that the model will learn to ignore those values or make more use of other features. Indeed, some more advanced deep learning models intentionally zero some of the input as a form of regularization (we’ll see what that means in later chapters).</p>&#13;
<p class="indent">For now, we’ll learn the second most obvious solution: replacing missing features with the mean value of features over the dataset. Let’s look again at our practice dataset from earlier. This time, we’ll have some missing data to deal with (<a href="ch04.xhtml#ch4tab7">Table 4-7</a>).</p>&#13;
<p class="tabcap" id="ch4tab7"><strong>Table 4-7:</strong> Our Sample Dataset (<a href="ch04.xhtml#ch4tab4">Table 4-4</a>) with Some Holes</p>&#13;
<table class="bordertb">&#13;
<colgroup>&#13;
<col style="width:5%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:20%"/>&#13;
<col style="width:20%"/>&#13;
<col style="width:25%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr class="borderb">&#13;
<th style="vertical-align: top"><p class="tab"><strong>Sample</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong><em>x</em><sub>0</sub></strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong><em>x</em><sub>1</sub></strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong><em>x</em><sub>2</sub></strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong><em>x</em><sub>3</sub></strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong><em>x</em><sub>4</sub></strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>Label</strong></p></th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><em>0</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">6998</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.1361</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.3408</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.00007350</p></td>&#13;
<td style="vertical-align: top"><p class="tab">78596048</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab"><em>1</em></p></td>&#13;
<td style="vertical-align: top"/>&#13;
<td style="vertical-align: top"><p class="tab">0.4908</p></td>&#13;
<td style="vertical-align: top"/>&#13;
<td style="vertical-align: top"><p class="tab">0.00004484</p></td>&#13;
<td style="vertical-align: top"><p class="tab">38462706</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><em>2</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">7563</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.9349</p></td>&#13;
<td style="vertical-align: top"><p class="tab">4.3465</p></td>&#13;
<td style="vertical-align: top"/>&#13;
<td style="vertical-align: top"><p class="tab">6700340</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab"><em>3</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">8355</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6529</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2.1271</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.00002966</p></td>&#13;
<td style="vertical-align: top"><p class="tab">51430391</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><em>4</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">2393</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.4605</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2.7561</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.00003395</p></td>&#13;
<td style="vertical-align: top"><p class="tab">27284192</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab"><em>5</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">9498</p></td>&#13;
<td style="vertical-align: top"/>&#13;
<td style="vertical-align: top"><p class="tab">2.7887</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.00008880</p></td>&#13;
<td style="vertical-align: top"><p class="tab">78543394</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><em>6</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">4030</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6467</p></td>&#13;
<td style="vertical-align: top"><p class="tab">4.8231</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.00000403</p></td>&#13;
<td style="vertical-align: top"/>&#13;
<td style="vertical-align: top"><p class="tab">2</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab"><em>7</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">5275</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.3560</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0705</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.00000899</p></td>&#13;
<td style="vertical-align: top"><p class="tab">96029352</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><em>8</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">8094</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.7979</p></td>&#13;
<td style="vertical-align: top"><p class="tab">3.9897</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.00006691</p></td>&#13;
<td style="vertical-align: top"><p class="tab">7307156</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab"><em>9</em></p></td>&#13;
<td style="vertical-align: top"/>&#13;
<td style="vertical-align: top"/>&#13;
<td style="vertical-align: top"><p class="tab">0.9804</p></td>&#13;
<td style="vertical-align: top"/>&#13;
<td style="vertical-align: top"><p class="tab">10179751</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><em>10</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">1221</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.9564</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2.3944</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.00007815</p></td>&#13;
<td style="vertical-align: top"><p class="tab">14241835</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab"><em>11</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">5879</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0329</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2.0085</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.00009564</p></td>&#13;
<td style="vertical-align: top"><p class="tab">34243070</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><em>12</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">923</p></td>&#13;
<td style="vertical-align: top"/>&#13;
<td style="vertical-align: top"/>&#13;
<td style="vertical-align: top"><p class="tab">0.00002467</p></td>&#13;
<td style="vertical-align: top"/>&#13;
<td style="vertical-align: top"><p class="tab">1</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab"><em>13</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">5882</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0002</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.5362</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.00005066</p></td>&#13;
<td style="vertical-align: top"><p class="tab">18728752</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><em>14</em></p></td>&#13;
<td style="vertical-align: top"><p class="tab">1796</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.7247</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2.3190</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.00001332</p></td>&#13;
<td style="vertical-align: top"><p class="tab">96703562</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="noindent"><span epub:type="pagebreak" id="page_68"/>The blank spaces indicate missing values. The means of each feature, ignoring missing values, are shown in <a href="ch04.xhtml#ch4tab8">Table 4-8</a>.</p>&#13;
<p class="tabcap" id="ch4tab8"><strong>Table 4-8:</strong> The Means for Features in <a href="ch04.xhtml#ch4tab7">Table 4-7</a></p>&#13;
<table class="bordertb">&#13;
<colgroup>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:20%"/>&#13;
<col style="width:20%"/>&#13;
<col style="width:20%"/>&#13;
<col style="width:20%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr class="borderb">&#13;
<th style="vertical-align: top"><p class="tab"><strong><em>x</em><sub>0</sub></strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong><em>x</em><sub>1</sub></strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong><em>x</em><sub>2</sub></strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong><em>x</em><sub>3</sub></strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong><em>x</em><sub>4</sub></strong></p></th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab">5223.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.5158</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2.345</p></td>&#13;
<td style="vertical-align: top"><p class="tab">4.71e-05</p></td>&#13;
<td style="vertical-align: top"><p class="tab">42957735.0</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="noindent">If we replace each missing value with the mean, we’ll get a dataset we can standardize and use to train a model.</p>&#13;
<p class="indent">Of course, real data is better, but the mean is the simplest substitute we can reasonably use. If the dataset is large enough, we might instead generate a histogram of the values of each feature and select the mode—the most common value—but using the mean should work out just fine, especially if your dataset has a lot of samples and the number of missing features is fairly small.</p>&#13;
<h3 class="h3" id="lev1_29">Training, Validation, and Test Data</h3>&#13;
<p class="noindent">Now that we have a dataset—a collection of feature vectors—we’re ready to start training a model, right? Well, actually, no. That’s because we don’t want to use the entire dataset for training. We’ll need to use some of the data for other purposes, and so we need to split it into at least two subsets, although ideally we’d have three. We call these subsets the training data, validation data, and test data.</p>&#13;
<h4 class="h4" id="lev2_37">The Three Subsets</h4>&#13;
<p class="noindent">The <em>training data</em> is the subset we use to train the model. The important thing here is selecting feature vectors that well represent the parent distribution of the data.</p>&#13;
<p class="indent">The <em>test data</em> is the subset used to evaluate how well the trained model is doing. We <em>never</em> use the test data when training the model; that would be cheating, because we’d be testing the model on data it has seen before. Put the test dataset aside, resist the temptation to touch it until the model is complete, and then use it to evaluate the model.</p>&#13;
<p class="indent">The third dataset is the <em>validation data</em>. Not every model needs a validation dataset, but for deep learning models, having one is helpful. We use the validation dataset during training as though it’s test data to get an idea of how well the training is working. It can help us decide things like when to stop training and whether we’re using the proper model.</p>&#13;
<p class="indent">For example, a neural network has some number of layers, each with some number of nodes. We call this the <em>architecture</em> of the model. During training, we can test the performance of the neural network with the validation data to figure out whether we should continue training or stop and try a different architecture. We don’t train the model with the validation set, and we don’t use the validation set to modify model parameters. We also can’t <span epub:type="pagebreak" id="page_69"/>use validation data when reporting actual model performance, since we used results based on the validation data to select the model in the first place. Again, this would make it seem like the model is doing better than it is.</p>&#13;
<p class="indent"><a href="ch04.xhtml#ch4fig3">Figure 4-3</a> illustrates the three subsets and their relationships to one another. On the left is the whole dataset. This is the entire collection of feature vectors and associated labels. On the right are the three subsets. The training data and the validation data work together to train and develop the model, while the test data is held back until the model is ready for it. The size of the cylinders reflects the relative amount of data that should fall into each subset, though in practice the validation and test subsets might be even smaller.</p>&#13;
<div class="image" id="ch4fig3"><img src="Images/04fig03.jpg" alt="image" width="419" height="201"/></div>&#13;
<p class="figcap"><em>Figure 4-3: Relationships among training, validation, and test subsets</em></p>&#13;
<p class="indent">To recap: use the training and validation sets to build the model and the test set to evaluate it.</p>&#13;
<h4 class="h4" id="lev2_38">Partitioning the Dataset</h4>&#13;
<p class="noindent">How much data should go into each dataset?</p>&#13;
<p class="indent">A typical split is 90 percent for training, 5 percent for validation, and 5 percent for testing. For deep learning models, this is fairly standard. If you’re working with a very large dataset, you could go as low as 1 percent each for validation and testing. For classic models, which might not learn as well, we might want to make the test dataset larger to ensure we are able to generalize to a wide variety of possible inputs. In those cases, you might try something like 80 percent for training and 10 percent each for validation and test. If you’re not using validation data, the full 20 percent might go to testing. These larger test sets might be appropriate for multiclass models that have classes with low prior probabilities. Or, since the test set is not used to define the model, you might increase the number of rare classes in the test set. This might be of particular value should missing the rare class be a costly event (think missing a tumor in a medical image).</p>&#13;
<p class="indent">Now that we’ve determined how much data to put into each set, let’s use <code>sklearn</code> to generate a dummy dataset that we can partition:</p>&#13;
<pre>&gt;&gt;&gt; <span class="codestrong1">import numpy as np</span><br/>&#13;
&gt;&gt;&gt; <span class="codestrong1">from sklearn.datasets import make_classification</span><br/>&#13;
&gt;&gt;&gt; <span class="codestrong1">x,y = make_classification(n_samples=10000, weights=(0.9,0.1))</span><br/>&#13;
<span epub:type="pagebreak" id="page_70"/>&gt;&gt;&gt; <span class="codestrong1">x.shape</span><br/>&#13;
    (10000, 20)<br/>&#13;
&gt;&gt;&gt; <span class="codestrong1">len(np.where(y == 0)[0])</span><br/>&#13;
    8969<br/>&#13;
&gt;&gt;&gt; <span class="codestrong1">len(np.where(y == 1)[0])</span><br/>&#13;
    1031</pre>&#13;
<p class="indent">Here, we’ve used two classes and 20 features to generate 10,000 samples. The dataset is imbalanced, with 90 percent of the samples in class 0 and 10 percent in class 1. The output is a 2D array of samples (<code>x</code>) and associated 0 or 1 labels (<code>y</code>). The dataset is generated from multidimensional Gaussians that are the analogs of the normal bell curve in more than one dimension, but that doesn’t matter to us right now. The useful part for us is that we have a collection of feature vectors and labels, so that we can look at ways in which the dataset might be split into subsets.</p>&#13;
<p class="indent">The key to the preceding code is the call to <code>make_classification</code>, which accepts the number of samples requested and the fraction for each class. The <code>np.where</code> calls simply find all the class 0 and class 1 instances so that <code>len</code> can count them.</p>&#13;
<p class="indent">Earlier, we talked about the importance of preserving—or at least approaching—the actual prior probabilities of the different classes in our dataset. If one class makes up 10 percent of real world cases, it would ideally make up 10 percent of our dataset. Now we need to find a way to preserve this prior class probability in the subsets we make for training, validation, and test. There are two main ways to do this: partitioning by class and random sampling.</p>&#13;
<h5 class="h5">Partitioning by Class</h5>&#13;
<p class="noindent">The exact approach, which is suitable when the dataset is small or perhaps when one class is rare, is to determine the number of samples representing each class, and then set aside selected percentages of each, by class, before merging them together. So, if there are 9,000 samples from class 0, and 1,000 samples from class 1, and we want to put 90 percent of the data into training and 5 percent each into validation and test, we would select 8,100 samples, <em>at random</em>, from the class 0 collection and 900 samples, <em>at random</em>, from the class 1 collection to make up the training set. Similarly, we would randomly select 450 of the remaining 900 unused class 0 samples for the validation set along with 50 of the remaining unused class 1 data. The remaining class 0 and class 1 samples become the test set.</p>&#13;
<p class="indent"><a href="ch04.xhtml#ch4lis1">Listing 4-1</a> shows the code to construct the subsets using a 90/5/5 split of the original data.</p>&#13;
<p class="programs" id="ch4lis1">   import numpy as np<br/>&#13;
   from sklearn.datasets import make_classification<br/>&#13;
<br/>&#13;
<span class="ent">❶</span> a,b = make_classification(n_samples=10000, weights=(0.9,0.1))<br/>&#13;
   idx = np.where(b == 0)[0]<br/>&#13;
   x0 = a[idx,:]<br/>&#13;
<span epub:type="pagebreak" id="page_71"/>   y0 = b[idx]<br/>&#13;
   idx = np.where(b == 1)[0]<br/>&#13;
   x1 = a[idx,:]<br/>&#13;
   y1 = b[idx]<br/>&#13;
<br/>&#13;
<span class="ent">❷</span> idx = np.argsort(np.random.random(y0.shape))<br/>&#13;
   y0 = y0[idx]<br/>&#13;
   x0 = x0[idx]<br/>&#13;
   idx = np.argsort(np.random.random(y1.shape))<br/>&#13;
   y1 = y1[idx]<br/>&#13;
   x1 = x1[idx]<br/>&#13;
<br/>&#13;
<span class="ent">❸</span> ntrn0 = int(0.9*x0.shape[0])<br/>&#13;
   ntrn1 = int(0.9*x1.shape[0])<br/>&#13;
   xtrn = np.zeros((int(ntrn0+ntrn1),20))<br/>&#13;
   ytrn = np.zeros(int(ntrn0+ntrn1))<br/>&#13;
   xtrn[:ntrn0] = x0[:ntrn0]<br/>&#13;
   xtrn[ntrn0:] = x1[:ntrn1]<br/>&#13;
   ytrn[:ntrn0] = y0[:ntrn0]<br/>&#13;
   ytrn[ntrn0:] = y1[:ntrn1]<br/>&#13;
<br/>&#13;
<span class="ent">❹</span> n0 = int(x0.shape[0]-ntrn0)<br/>&#13;
   n1 = int(x1.shape[0]-ntrn1)<br/>&#13;
   xval = np.zeros((int(n0/2+n1/2),20))<br/>&#13;
   yval = np.zeros(int(n0/2+n1/2))<br/>&#13;
   xval[:(n0//2)] = x0[ntrn0:(ntrn0+n0//2)]<br/>&#13;
   xval[(n0//2):] = x1[ntrn1:(ntrn1+n1//2)]<br/>&#13;
   yval[:(n0//2)] = y0[ntrn0:(ntrn0+n0//2)]<br/>&#13;
   yval[(n0//2):] = y1[ntrn1:(ntrn1+n1//2)]<br/>&#13;
<br/>&#13;
<span class="ent">❺</span> xtst = np.concatenate((x0[(ntrn0+n0//2):],x1[(ntrn1+n1//2):]))<br/>&#13;
   ytst = np.concatenate((y0[(ntrn0+n0//2):],y1[(ntrn1+n1//2):]))</p>&#13;
<p class="figcap"><em>Listing 4-1: Exact construction of training, validation, and test datasets</em></p>&#13;
<p class="indent">There’s a lot of bookkeeping in this code. First, we create the dummy dataset <span class="ent">❶</span> and split it into class 0 and class 1 collections, stored in <code>x0,y0</code> and <code>x1,y1</code>, respectively. We then randomize the ordering <span class="ent">❷</span>. This will let us pull off the first <em>n</em> samples for the subsets without worrying that we might be introducing a bias because of ordering in the data. Because of how <code>sklearn</code> generates the dummy dataset, this step isn’t required, but it’s always a good idea to ensure randomness in the ordering of samples.</p>&#13;
<p class="indent">We use a trick that’s helpful when reordering samples. Because we store the feature vectors in one array and the labels in another, the NumPy shuffle methods will not work. Instead, we generate a random vector of the same length as our number of samples and then use <code>argsort</code> to return the indices of the vector that would put it in sorted order. Since the values in the vector are random, the ordering of the indices used to sort it will also be random. <span epub:type="pagebreak" id="page_72"/>These indices then reorder the samples and labels so that the each label is still associated with the correct feature vector.</p>&#13;
<p class="indent">Next, we extract the first 90 percent of samples for the two classes and build the training subset with samples in <code>xtrn</code> and labels in <code>ytrn</code> <span class="ent">❸</span>. We do the same for the 5 percent validation set <span class="ent">❹</span> and the remaining 5 percent for the test set <span class="ent">❺</span>.</p>&#13;
<p class="indent">Partitioning by class is tedious, to say the least. We do know, however, that the class 0 to class 1 ratio in each of the subsets is exactly the same.</p>&#13;
<h5 class="h5">Random Sampling</h5>&#13;
<p class="noindent">Must we be so precise? In general, no. The second common method for partitioning the full dataset is via random sampling. If we have enough data—and 10,000 samples is enough data—we can build our subsets by randomizing the full dataset and then extracting the first 90 percent of samples as the training set, the next 5 percent as the validation set, and the last 5 percent as the test set. This is what we show in <a href="ch04.xhtml#ch4lis2">Listing 4-2</a>.</p>&#13;
<p class="programs" id="ch4lis2"><span class="ent">❶</span> x,y = make_classification(n_samples=10000, weights=(0.9,0.1))<br/>&#13;
   idx = np.argsort(np.random.random(y.shape[0]))<br/>&#13;
   x = x[idx]<br/>&#13;
   y = y[idx]<br/>&#13;
<br/>&#13;
<span class="ent">❷</span> ntrn = int(0.9*y.shape[0])<br/>&#13;
   nval = int(0.05*y.shape[0])<br/>&#13;
<br/>&#13;
<span class="ent">❸</span> xtrn = x[:ntrn]<br/>&#13;
   ytrn = y[:ntrn]<br/>&#13;
   xval = x[ntrn:(ntrn+nval)]<br/>&#13;
   yval = y[ntrn:(ntrn+nval)]<br/>&#13;
   xtst = x[(ntrn+nval):]<br/>&#13;
   ytst = y[(ntrn+nval):]</p>&#13;
<p class="figcap"><em>Listing 4-2: Random construction of training, validation, and test datasets</em></p>&#13;
<p class="indent">We randomize the dummy dataset stored in <code>x</code> and <code>y</code> <span class="ent">❶</span>. We need to know how many samples to include in each of the subsets. First, the number of samples for the training set is 90 percent of the total in the dataset <span class="ent">❷</span>, while the number in the validation set is 5 percent of the total. The remainder, also 5 percent, is the test set <span class="ent">❸</span>.</p>&#13;
<p class="indent">This method is so much simpler than the one shown in <a href="ch04.xhtml#ch4lis1">Listing 4-1</a>. What’s the downside of using it? The possible downside is that the mix of classes in each of these subsets might not quite be the fractions we want. For example, imagine we want a training set of 9,000 samples, or 90 percent of the original 10,000 samples, with 8,100 of them from class 0, and 900 of them from class 1. Running the <a href="ch04.xhtml#ch4lis2">Listing 4-2</a> code 10 times gives the splits between class 0 and class 1 in the training set that are shown in <a href="ch04.xhtml#ch4tab9">Table 4-9</a>.</p>&#13;
<p class="tabcap" id="ch4tab9"><span epub:type="pagebreak" id="page_73"/><strong>Table 4-9:</strong> Ten Training Splits Generated by Random Sampling</p>&#13;
<table class="bordertb">&#13;
<colgroup>&#13;
<col style="width:20%"/>&#13;
<col style="width:40%"/>&#13;
<col style="width:40%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr class="borderb">&#13;
<th style="vertical-align: top"><p class="tab"><strong>Run</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>Class 0</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>Class 1</strong></p></th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab">1</p></td>&#13;
<td style="vertical-align: top"><p class="tab">8058 (89.5)</p></td>&#13;
<td style="vertical-align: top"><p class="tab">942 (10.5)</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">2</p></td>&#13;
<td style="vertical-align: top"><p class="tab">8093 (89.9)</p></td>&#13;
<td style="vertical-align: top"><p class="tab">907 (10.1)</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab">3</p></td>&#13;
<td style="vertical-align: top"><p class="tab">8065 (89.6)</p></td>&#13;
<td style="vertical-align: top"><p class="tab">935 (10.4)</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">4</p></td>&#13;
<td style="vertical-align: top"><p class="tab">8081 (89.8)</p></td>&#13;
<td style="vertical-align: top"><p class="tab">919 (10.2)</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab">5</p></td>&#13;
<td style="vertical-align: top"><p class="tab">8045 (89.4)</p></td>&#13;
<td style="vertical-align: top"><p class="tab">955 (10.6)</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">8045 (89.4)</p></td>&#13;
<td style="vertical-align: top"><p class="tab">955 (10.6)</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab">7</p></td>&#13;
<td style="vertical-align: top"><p class="tab">8066 (89.6)</p></td>&#13;
<td style="vertical-align: top"><p class="tab">934 (10.4)</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">8</p></td>&#13;
<td style="vertical-align: top"><p class="tab">8064 (89.6)</p></td>&#13;
<td style="vertical-align: top"><p class="tab">936 (10.4)</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab">9</p></td>&#13;
<td style="vertical-align: top"><p class="tab">8071 (89.7)</p></td>&#13;
<td style="vertical-align: top"><p class="tab">929 (10.3)</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">10</p></td>&#13;
<td style="vertical-align: top"><p class="tab">8063 (89.6)</p></td>&#13;
<td style="vertical-align: top"><p class="tab">937 (10.4)</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="indent">The number of samples in class 1 ranges from as few as 907 samples to as many as 955 samples. As the number of samples of a particular class in the full dataset decreases, the number in the subsets will start to vary more. This is especially true of smaller subsets, like the validation and test sets. Let’s do a separate run, this time looking at the number of samples from each class in the <em>test</em> set (<a href="ch04.xhtml#ch4tab10">Table 4-10</a>).</p>&#13;
<p class="tabcap" id="ch4tab10"><strong>Table 4-10:</strong> Ten Test Splits Generated by Random Sampling</p>&#13;
<table class="bordertb">&#13;
<colgroup>&#13;
<col style="width:20%"/>&#13;
<col style="width:40%"/>&#13;
<col style="width:40%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr class="borderb">&#13;
<th style="vertical-align: top"><p class="tab"><strong>Run</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>Class 0</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>Class 1</strong></p></th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab">1</p></td>&#13;
<td style="vertical-align: top"><p class="tab">446 (89.2)</p></td>&#13;
<td style="vertical-align: top"><p class="tab">54 (10.8)</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">2</p></td>&#13;
<td style="vertical-align: top"><p class="tab">450 (90.0)</p></td>&#13;
<td style="vertical-align: top"><p class="tab">50 (10.0)</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab">3</p></td>&#13;
<td style="vertical-align: top"><p class="tab">444 (88.8)</p></td>&#13;
<td style="vertical-align: top"><p class="tab">56 (11.2)</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">4</p></td>&#13;
<td style="vertical-align: top"><p class="tab">450 (90.0)</p></td>&#13;
<td style="vertical-align: top"><p class="tab">50 (10.0)</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab">5</p></td>&#13;
<td style="vertical-align: top"><p class="tab">451 (90.2)</p></td>&#13;
<td style="vertical-align: top"><p class="tab">49 (9.8)</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">462 (92.4)</p></td>&#13;
<td style="vertical-align: top"><p class="tab">38 (7.6)</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab">7</p></td>&#13;
<td style="vertical-align: top"><p class="tab">441 (88.2)</p></td>&#13;
<td style="vertical-align: top"><p class="tab">59 (11.8)</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">8</p></td>&#13;
<td style="vertical-align: top"><p class="tab">449 (89.8)</p></td>&#13;
<td style="vertical-align: top"><p class="tab">51 (10.2)</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab">9</p></td>&#13;
<td style="vertical-align: top"><p class="tab">449 (89.8)</p></td>&#13;
<td style="vertical-align: top"><p class="tab">51 (10.2)</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">10</p></td>&#13;
<td style="vertical-align: top"><p class="tab">438 (87.6)</p></td>&#13;
<td style="vertical-align: top"><p class="tab">62 (12.4)</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="noindent">In the test set, the number of samples from class 1 ranges from 38 to 62.</p>&#13;
<p class="indent">Will these differences influence how the model learns? Probably not, but they might make the test results look better than they are, as most models struggle to identify the classes that are least common in the training set. The possibility exists of a pathological split that results in having no examples from a particular class, but in practice, it’s not really that likely unless your pseudorandom number generator is particularly poor. Still, it’s worth <span epub:type="pagebreak" id="page_74"/>keeping the possibility in mind. If concerned, use the exact split approach in <a href="ch04.xhtml#ch4lis1">Listing 4-1</a>. In truth, the better solution is, as always, to get more data.</p>&#13;
<p class="indent">Algorithmically, the steps to produce the training, validation, and test splits are as follows:</p>&#13;
<ol>&#13;
<li class="noindent">Randomize the order of the full dataset so that classes are evenly mixed.</li>&#13;
<li class="noindent">Calculate the number of samples in the training (<code>ntrn</code>) and validation (<code>nval</code>) sets by multiplying the number of samples in the full dataset by the desired fraction. The remaining samples will fall into the test set.</li>&#13;
<li class="noindent">Assign the first <code>ntrn</code> samples to the training set.</li>&#13;
<li class="noindent">Assign the next <code>nval</code> samples to the validation set.</li>&#13;
<li class="noindent">Finally, assign the remaining samples to the test set.</li>&#13;
</ol>&#13;
<p class="indent">At all times, ensure that the order of the samples is truly random, and that when reordering the feature vectors, you’re sure to reorder the labels in the exact same sequence. If this is done, this simple splitting process will give a good split unless the dataset is very small or some classes are very rare.</p>&#13;
<p class="indent">We neglected to discuss one consequence of this approach. If the full dataset is small to begin with, partitioning it will make the training set even smaller. In <a href="ch07.xhtml#ch07">Chapter 7</a>, we’ll see a powerful approach to dealing with a small dataset, one that’s used heavily in deep learning. But first, let’s look at a principled way to work with a small dataset to get an idea of how well it will perform on new data.</p>&#13;
<h4 class="h4" id="lev2_39">k-Fold Cross Validation</h4>&#13;
<p class="noindent">Modern deep learning models typically need very large datasets, and therefore, you’re able to use a single training/validation/test split as described previously. More traditional machine learning models, like those in <a href="ch06.xhtml#ch06">Chapter 6</a>, however, often work with datasets that are too small (in general) for deep learning models. If we use a single training/validation/test split on those datasets, we might be holding too much data back for testing, or else have too few samples in the test set to get a meaningful measurement of how well the model is working.</p>&#13;
<p class="indent">One way to address this issue is to use <em>k-fold cross validation</em>, a technique that ensures each sample in the dataset is used at some point for training and testing. Use this technique for small datasets intended for traditional machine learning models. It can also be helpful as a way to decide between different models.</p>&#13;
<p class="indent">To do <em>k</em>-fold cross validation, first partition the full, randomized dataset into <em>k</em> non-overlapping groups, <em>x</em><sub>0</sub>,<em>x</em><sub>1</sub>,<em>x</em><sub>2</sub>,…,<em>x</em><sub><em>k–</em>1</sub>. Your <em>k</em> value is arbitrary, though it typically ranges from 5 to 10. <a href="ch04.xhtml#ch4fig4">Figure 4-4</a>a shows this split, imagining the entire dataset laid out horizontally.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_75"/>We can train a model by holding <em>x</em><sub>0</sub> back as test data and using the other groups, <em>x</em><sub>1</sub>,<em>x</em><sub>2</sub>,…,<em>x</em><sub><em>k–</em>1</sub> as training data. We’ll ignore validation data for the time being; after building the current training data, we can always hold some of it back as validation data if we want. Call this trained model <em>m</em><sub>0</sub>. You can then start over from scratch, this time holding back <em>x</em><sub>1</sub> as test data and training with all the other groups, including <em>x</em><sub>0</sub>. We’ll get a new trained model. Call it <em>m</em><sub>1</sub>. By design, <em>m</em><sub>0</sub> and <em>m</em><sub>1</sub> are the same <em>type</em> of model. What we are interested in here is multiple instances of the same type of model trained with different subsets of the full dataset.</p>&#13;
<p class="indent">Repeat this process for each of the groups, as in <a href="ch04.xhtml#ch4fig4">Figure 4-4</a>b, and we’ll have <em>k</em> models trained with (<em>k –</em> 1)/<em>k</em> of the data each, holding 1/<em>k</em> of the data back for testing. What <em>k</em> should be depends upon how much data is in the full dataset. Larger <em>k</em> means more training data but less test data. If the per model training time is low, tend toward a larger <em>k</em> as this increases the per model training set size.</p>&#13;
<div class="image" id="ch4fig4"><img src="Images/04fig04.jpg" alt="image" width="672" height="455"/></div>&#13;
<p class="figcap"><em>Figure 4-4:</em> k-<em>fold cross validation. Partitioning the dataset into non-overlapping regions</em>, k=<em>7(a). The first three train/test splits using first</em> x<sub>0</sub> <em>for test, then</em> x<sub>1</sub> <em>for test, and so on (b)</em>.</p>&#13;
<p class="indent">Once the <em>k</em> models are trained, you can evaluate them individually and average their metrics to get an idea of how a model trained on the full dataset would behave. See <a href="ch11.xhtml#ch11">Chapter 11</a> to learn about ways to evaluate a model. If using <em>k</em>-fold cross validation to select among two or more models (say, between using <em>k</em>-NN or a Support Vector Machine<sup><a id="Rch04fn1" href="ch04.xhtml#ch04fn1">1</a></sup>), repeat the full training and evaluation process for each type of model and compare their results.</p>&#13;
<p class="noindent"><span epub:type="pagebreak" id="page_76"/>Once we have an idea of how well the model is performing on the averaged evaluation metrics, we can start over again and train the selected model type using <em>all</em> of the dataset for training. This is the advantage of <em>k</em>-fold cross validation: it lets you have your cake and eat it, too.</p>&#13;
<h3 class="h3" id="lev1_30">Look at Your Data</h3>&#13;
<p class="noindent">It’s quite easy to assemble features and feature vectors, and then go ahead and put the training, validation, and test sets together without pausing to <em>look</em> at the data to see if it makes sense. This is especially true with deep learning models using huge collections of images or other multidimensional data. Here are a few problems you’ll want to look out for:</p>&#13;
<p class="block"><strong>Mislabeled data</strong> Assume we’re building a large dataset—one with hundreds of thousands of labeled samples. Further, assume that we’re going to use the dataset to build a model that will be able to tell the difference between dogs and cats. Naturally, we need to feed the model many, many dog images and many, many cat images. No problem, you say; we’ll just collect a lot of images using something like Google Images. Okay, that’ll work. But if you simply set up a script to download image search results matching “dog” and “cat,” you’ll also get a lot of other images that are not of dogs or cats, or images that contain dogs and cats along with other things. The labels won’t be perfect. While it is true that deep learning models can be resistant to such label noise, you want to avoid it whenever possible.</p>&#13;
<p class="block"><strong>Missing or outlier data</strong> Imagine you have a collection of feature vectors, and you have no idea how common it is that features are missing. If a large percentage of a particular feature is missing, that feature will become a hindrance to the model and you should eliminate it. Or, if there are extreme outliers in the data, you might want to remove those samples, especially if you’re going to standardize, since outliers will strongly affect the mean subtracted from the feature values.</p>&#13;
<h4 class="h4" id="lev2_40">Searching for Problems in the Data</h4>&#13;
<p class="noindent">How can we look for these problems in the data? Well, for feature vectors, we can often load the dataset into a spreadsheet, if it isn’t too large. Or we could write a Python script to summarize the data, feature by feature, or bring the data into a statistics program and examine it that way.</p>&#13;
<p class="indent">Typically, when summarizing values statistically, we look at the mean and standard deviation, both defined previously, as well as the largest value and the smallest value. We could also look at the median, which is the value we get when we sort the values from smallest to largest and pick the one in the middle. (If the number of values is even, we’d average the two middle values.) Let’s look at one of the features from our earlier example. After sorting the values from smallest to largest, we can summarize the data in the following way.</p>&#13;
<table class="bordertb">&#13;
<colgroup>&#13;
<col style="width:100%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr class="borderb">&#13;
<td style="vertical-align: top"><p class="tab"><span epub:type="pagebreak" id="page_77"/><strong><em>x</em><sub>2</sub></strong></p></td>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">0.0705</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">0.3408</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">0.9804</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">1.5362</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">1.7821</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">2.0085</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">2.1271</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab"><strong>2.3190</strong></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">2.3944</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">2.7561</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">2.7887</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">3.0150</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">3.9897</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">4.3465</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">4.8231</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<table>&#13;
<colgroup>&#13;
<col style="width:40%"/>&#13;
<col style="width:20%"/>&#13;
<col style="width:40%"/>&#13;
</colgroup>&#13;
<tbody>&#13;
<tr>&#13;
<td><p class="tab">Mean (<span class="middle"><img src="Images/xbar.jpg" alt="Image"/></span>)</p></td>&#13;
<td><p class="tab">=</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2.3519</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p class="tab">Standard deviation (<em>σ</em>)</p></td>&#13;
<td><p class="tab">=</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.3128</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p class="tab">Standard error (SE)</p></td>&#13;
<td><p class="tab">=</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.3390</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p class="tab">Median</p></td>&#13;
<td><p class="tab">=</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2.3190</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p class="tab">Minimum</p></td>&#13;
<td><p class="tab">=</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0705</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p class="tab">Maximum</p></td>&#13;
<td><p class="tab">=</p></td>&#13;
<td style="vertical-align: top"><p class="tab">4.8231</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="indent">We’ve already explored the concepts of mean, minimum, maximum, and standard deviation. The median is there, as well; I’ve highlighted it in the list of features on the left. Notice that after sorting, the median appears in the exact middle of the list. It’s often known as the <em>50th percentile</em>, because the same amount of data is above it as below.</p>&#13;
<p class="indent">There is also a new value listed, the <em>standard error</em>, also called the <em>standard error of the mean</em>. This is the standard deviation divided by the square root of the number of values in the dataset:</p>&#13;
<div class="imagec"><img src="Images/077equ01.jpg" alt="image" width="78" height="43"/></div>&#13;
<p class="noindent">The standard error is a measure of the difference between our mean value, <span class="middle"><img src="Images/xbar.jpg" alt="Image" width="10" height="14"/></span>, and the mean value of the parent distribution. The basic idea is this: if we have more measurements, we’ll have a better idea of the parent distribution that is generating the data, and so the mean value of the measurements will be closer to the mean value of the parent distribution.</p>&#13;
<p class="indent">Notice also that the mean and the median are relatively close to each other. The phrase <em>relatively close</em> has no rigorous mathematical meaning, of course, but we can use it as an ad hoc indicator that the data might be normally distributed, meaning we could reasonably replace the missing values by the mean (or median), as we saw previously.</p>&#13;
<p class="indent">The preceding values were computed easily using NumPy, as seen in <a href="ch04.xhtml#ch4lis3">Listing 4-3</a>.</p>&#13;
<p class="programs" id="ch4lis3">   import numpy as np<br/>&#13;
<br/>&#13;
<span class="ent">❶</span> f = [0.3408,3.0150,4.3465,2.1271,2.7561,<br/>&#13;
        2.7887,4.8231,0.0705,3.9897,0.9804,<br/>&#13;
        2.3944,2.0085,1.7821,1.5362,2.3190]<br/>&#13;
   f = np.array(f)<br/>&#13;
<span epub:type="pagebreak" id="page_78"/>   print<br/>&#13;
   print("mean  = %0.4f" % f.mean())<br/>&#13;
   print("std   = %0.4f" % f.std())<br/>&#13;
<span class="ent">❷</span> print("SE    = %0.4f" % (f.std()/np.sqrt(f.shape[0])))<br/>&#13;
   print("median= %0.4f" % np.median(f))<br/>&#13;
   print("min   = %0.4f" % f.min())<br/>&#13;
   print("max   = %0.4f" % f.max())</p>&#13;
<p class="figcap"><em>Listing 4-3: Calculating basic statistics. See</em> feature_stats.py.</p>&#13;
<p class="indent">After loading NumPy, we manually define the <em>x</em><sub>2</sub> features (<code>f</code>) and turn them into a NumPy array <span class="ent">❶</span>. Once the data is a NumPy array, calculating the desired values is straightforward, as all of them, except the standard error, are simple method or function calls. The standard error is calculated via the preceding formula <span class="ent">❷</span> where the first element of the tuple NumPy returns for the shape is the number of elements in a vector.</p>&#13;
<p class="indent">Numbers are nice, but pictures are often better. You can visualize the data with a <em>box plot</em> in Python. Let’s generate one to view the standardized values of our dataset. Then we’ll discuss what the plot is showing us. The code to create the plot is in <a href="ch04.xhtml#ch4lis4">Listing 4-4</a>.</p>&#13;
<p class="programs" id="ch4lis4">  import numpy as np<br/>&#13;
  import matplotlib.pyplot as plt<br/>&#13;
<br/>&#13;
<span class="ent">❶</span> d = [[ 0.6930, -1.1259, -1.5318,  0.9525,  1.1824],<br/>&#13;
        [ 0.5464, -0.0120,  0.5051, -0.0192, -0.1141],<br/>&#13;
        [ 0.8912,  1.3826,  1.5193, -1.1996, -1.1403],<br/>&#13;
        [ 1.1690,  0.4970, -0.1712, -0.5340,  0.3047],<br/>&#13;
        [-0.9221, -0.1071,  0.3079, -0.3885, -0.4753],<br/>&#13;
        [ 1.5699, -1.4767,  0.3327,  1.4714,  1.1807],<br/>&#13;
        [-0.3479,  0.4775,  1.8823, -1.4031, -0.7396],<br/>&#13;
        [ 0.0887, -0.4353, -1.7377, -1.2349,  1.7456],<br/>&#13;
        [ 1.0775,  0.9524,  1.2475,  0.7291, -1.1207],<br/>&#13;
        [-1.4657,  0.9250, -1.0446,  0.4262, -1.0279],<br/>&#13;
        [-1.3332,  1.4501,  0.0323,  1.1102, -0.8966],<br/>&#13;
        [ 0.3005, -1.4500, -0.2615,  1.7033, -0.2505],<br/>&#13;
        [-1.4377, -0.2472, -0.4340, -0.7032,  0.3362],<br/>&#13;
        [ 0.3016, -1.5527, -0.6213,  0.1780, -0.7517],<br/>&#13;
        [-1.1315,  0.7225, -0.0250, -1.0881,  1.7674]]<br/>&#13;
<span class="ent">❷</span> d = np.array(d)<br/>&#13;
   plt.boxplot(d)<br/>&#13;
   plt.show()</p>&#13;
<p class="figcap"><em>Listing 4-4: A box plot of the standardized toy dataset</em>. See box_plot.py.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_79"/>The values themselves are in <a href="ch04.xhtml#ch4tab6">Table 4-6</a>. We can store the data as a 2D array and make the box plot using <a href="ch04.xhtml#ch4lis4">Listing 4-4</a>. We manually define the array <span class="ent">❶</span> and then plot it <span class="ent">❷</span>. The plot is interactive, so experiment with the environment provided until you feel comfortable with it. The old-school floppy disk icon will store the plot to your disk.</p>&#13;
<p class="indent">The box plot generated by the program is shown in <a href="ch04.xhtml#ch4fig5">Figure 4-5</a>.</p>&#13;
<div class="image" id="ch4fig5"><img src="Images/04fig05.jpg" alt="image" width="673" height="516"/></div>&#13;
<p class="figcap"><em>Figure 4-5: The box plot produced by <a href="ch04.xhtml#ch4lis4">Listing 4-4</a></em></p>&#13;
<p class="indent">How do we interpret the box plot? I’ll show you by examining the box representing the standardized feature <em>x</em><sub>2</sub>, shown in <a href="ch04.xhtml#ch4fig6">Figure 4-6</a>.</p>&#13;
<p class="indent">The lower box line, Q1, marks the end of the first quartile. This means that 25 percent of the data values for a feature are less than this value. The median, Q2, is the 50 percent mark, and therefore is the end of the second quartile. Half the data values are less than this value. The upper box line, Q3, is the 75 percent mark. The remaining 25 percent of the data values are above Q3.</p>&#13;
<div class="image" id="ch4fig6"><span epub:type="pagebreak" id="page_80"/><img src="Images/04fig06.jpg" alt="image" width="673" height="515"/></div>&#13;
<p class="figcap"><em>Figure 4-6: The standardized feature x2 from our dataset</em></p>&#13;
<p class="indent">Two lines above and below the box are also shown. These are the <em>whiskers</em>. (Matplotlib calls them <em>fliers</em>, but this is an unconventional term.) The whiskers are the values at Q1 <em>–</em> 1.5 × IQR and Q3 + 1.5 × IQR. By convention, values outside this range are considered <em>outliers</em>.</p>&#13;
<p class="indent">Looking at outliers can be helpful, because you might realize they’re mistakes in data entry and drop them from the dataset. Whatever you do with the outliers, however, be prepared to justify it should you ever plan on publishing or otherwise presenting results based on the dataset. Similarly, you might be able to drop samples with missing values, but make sure there’s no systematic error causing the missing data, and check that you’re not introducing bias into the data by dropping those samples. In the end, common sense should override slavish adherence to convention.</p>&#13;
<h4 class="h4" id="lev2_41">Cautionary Tales</h4>&#13;
<p class="noindent">So, at the risk of being repetitive, <em>look at your data</em>. The more you work with it, the more you will understand it, and the more effectively you will be able to make reasonable decisions about what goes in and what comes out, and <em>why</em>. Recall that the goal of the dataset is to faithfully and completely capture the parent distribution, or what the data will look like in the wild when the model is used.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_81"/>Two quick anecdotes come to mind. They both illustrate ways models may well learn things we did not intend or even consider.</p>&#13;
<p class="indent">The first was told to me as an undergraduate student in the 1980s. In this story, an early form of neural network was tasked with detecting tank and non-tank images. The neural network seemed to work well in testing, but when used in the field, the detection rate dropped rapidly. The researchers realized that the tank images were taken on a cloudy day, and the non-tank were taken on a sunny day. The recognition system had not learned the difference between tanks and non-tanks at all; instead, it had learned the difference between cloudy and sunny days. The moral of this story is that the training set needs to include <em>all</em> of the conditions the model will see in the wild.</p>&#13;
<p class="indent">The second anecdote is more recent. I heard it in a talk at the Neural Information Processing Systems (NIPS) 2016 conference in Barcelona, Spain, and later found it repeated in the researchers’ paper.<sup><a id="Rch04fn2" href="ch04.xhtml#ch04fn2">2</a></sup> In this case, the authors, who were demonstrating their technique for getting a model to explain its decisions, trained a model that claimed to tell the difference between images of huskies and images of wolves. The model appeared to work rather well, and during the talk, the authors polled the audience composed of machine learning researchers about how believable the model was. Most thought it was a good model. Then, using their technique, the speaker revealed that the network had not learned much, if anything, about the difference between huskies and wolves. Instead, it had learned that the wolf pictures had snow in the background and the husky pictures did not.</p>&#13;
<p class="indent">Think about your data and be on the lookout for unintended consequences. Models are not human. We bring a lot of preconceived notions and unintended biases to the dataset.</p>&#13;
<h3 class="h3" id="lev1_31">Summary</h3>&#13;
<p class="noindent">In this chapter, we described the components of a dataset (classes, labels, features, feature vectors) and then characterized a good dataset, emphasizing the importance of ensuring that the dataset well represents the parent distribution. We then described basic data preparation techniques including how to scale data and one approach for dealing with missing features. After that, we learned how to separate the full dataset into training, validation, and test subsets and how to apply <em>k</em>-fold cross validation, which is especially useful with small datasets. We ended the chapter with tips on how to simply examine the data to make sure it makes sense.</p>&#13;
<p class="indent">In the next chapter, we’ll take what we have learned in this chapter and apply it directly to construct the datasets we will use throughout the remainder of this book.</p>&#13;
<p class="fnote1"><span epub:type="pagebreak" id="page_82"/><a id="ch04fn1" href="ch04.xhtml#Rch04fn1">1.</a> These are examples of classical machine learning models. We’ll learn more about them later in the book.</p>&#13;
<p class="fnote"><a id="ch04fn2" href="ch04.xhtml#Rch04fn2">2.</a> Ribeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin. “Why Should I Trust You?: Explaining the Predictions of Any Classifier.” <em>In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em>, pp. 1135–1144. ACM, 2016.</p>&#13;
</div></body></html>
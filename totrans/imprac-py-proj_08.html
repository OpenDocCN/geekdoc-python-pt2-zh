<html><head></head><body>
<h2 class="h2" id="ch08"><span epub:type="pagebreak" id="page_145"/><strong><span class="big">8</span><br/>COUNTING SYLLABLES FOR HAIKU POETRY</strong></h2>
<div class="image1"><img src="../images/common01.jpg" alt="image"/></div>
<p class="noindent">Poetry may be the supreme form of literature. It is, as Coleridge put it, “the best words in the best order.” The poet must—with great brevity—tell a story, promote an idea, describe a scene, or evoke intensity of feeling, all while obeying strict rules on rhythm and rhyme, style and structure.</p>
<p class="indent">Computers love rules and structure and even have the potential to evoke emotions. In his 1996 book <em>Virtual Muse: Experiments in Computer Poetry</em>, author Charles Hartman describes early attempts to write algorithms that could mimic human poetry. To quote Hartman, “The complexity of poetic interaction, the tricky dance among poet and text and reader, causes a game of hesitation. In this game, a properly programmed computer has a chance to slip in some interesting moves.”</p>
<p class="indent">The early programs Hartman describes could, at best, produce bad beatnik poetry. The goal at the time was to “introduce calculated bits of mechanized anarchy into the language, put the results back into the <span epub:type="pagebreak" id="page_146"/>contingent world where language lives, and see how the dust settles.” As we have touched on in several chapters, context is the weak link in programming things like proper-name anagrams and null ciphers. To write computer poems that pass the “supreme” test of literature, you cannot ignore context.</p>
<p class="indent">Getting a computer to simulate this most human of human endeavors is an intriguing challenge—and certainly not one we can pass up. In this chapter and the next, you’ll teach your computer how to generate a traditional form of Japanese poetry called <em>haiku</em>.</p>
<h3 class="h3" id="lev170"><strong>Japanese Haiku</strong></h3>
<p class="noindent">Haiku consist of three lines of five, seven, and five syllables, respectively. The poems rarely rhyme, and the subject matter usually addresses the natural world—mainly the seasons—either directly or indirectly. If done properly, a haiku can immerse you in the scene, as if evoking a memory.</p>
<p class="indentb">I’ve provided three example haiku here. The first is by the master Buson (1715–1783), the second by the master Issa (1763–1828), and the third by yours truly, based on memories of childhood road trips.</p>
<p class="poem">Standing still at dusk</p>
<p class="poem">Listen . . . in far distances</p>
<p class="poem">The song of froglings!</p>
<p class="poemr"><em>—Buson</em></p>
<p class="poem">Good friend grasshopper</p>
<p class="poem">Will you play the caretaker</p>
<p class="poem">For my little grave?</p>
<p class="poemr"><em>—Issa</em></p>
<p class="poem">Faraway cloudbanks</p>
<p class="poem">That I let myself pretend</p>
<p class="poem">Are distant mountains</p>
<p class="poemr"><em>—Vaughan</em></p>
<p class="indent">Because of its evocative nature, every haiku has a built-in “exploitable gap” for the programmer. This is summed up nicely by Peter Beilenson in his 1955 book <em>Japanese Haiku</em>: “the haiku is not expected to be always a complete or even a clear statement. The reader is supposed to add to the words his own associations and imagery, and thus to become a co-creator of his own pleasure in the poem.” Hartman adds, “The reader’s mind works most actively on sparse materials. We draw the clearest constellations from the fewest stars. So, the nonsense factor is low for a tiny collocation of words that can be imbued with imagistic significance.” To put it simply, it’s harder to mess up a short poem. Readers always assume the poet had a point and will make one up themselves if they can’t find it.</p>
<p class="indent"><span epub:type="pagebreak" id="page_147"/>Despite this advantage, training your computer to write poetry is no mean feat, and you’ll need two whole chapters to get it done. In this chapter, you’ll write a program that counts the number of syllables in words and phrases so that you can honor the syllabic structure of the haiku. In <a href="ch09.xhtml#ch09">Chapter 9</a>, you’ll use a technique called <em>Markov chain analysis</em> to capture the essence of haiku—the elusive evocative component—and transform existing poems into something new and, occasionally, arguably better.</p>
<h3 class="h3a" id="lev171"><strong>Project #15: Counting Syllables</strong></h3>
<p class="noindent">Counting syllables in English is difficult. The problem lies in, as Charles Hartman put it, the quirky spelling and tangled linguistic history of English. For example, a word like <em>aged</em> may be one syllable or two depending on whether it describes a man or a cheese. How can a program count syllables accurately without degenerating into an endless list of special cases?</p>
<p class="indent">The answer is that it can’t, at least not without a “cheat sheet.” Fortunately, these cheat sheets exist, thanks to a branch of science known as <em>natural language processing</em> (<em>NLP</em>), which deals with interactions between the precise and structured language of computers and the nuanced, frequently ambiguous “natural” language used by humans. Example uses for NLP include machine translations, spam detection, comprehension of search engine questions, and predictive text recognition for cell phone users. The biggest impact of NLP is yet to come: the mining of vast volumes of previously unusable, poorly structured data and engaging in seamless conversations with our computer overlords.</p>
<p class="indent">In this chapter, you’ll use an NLP dataset to help count syllables in words or phrases. You’ll also write code that finds words that are missing from this dataset and then helps you build a supporting dictionary. Finally, you’ll write a program to help you check your syllable-counting code. In <a href="ch09.xhtml#ch09">Chapter 9</a>, you’ll use this syllable-counting algorithm as a module in a program that helps you computationally produce the highest achievement in literature: poetry.</p>
<div class="sidebar">
<p class="sidebart"><strong>THE OBJECTIVE</strong></p>
<p class="spara">Write a Python program that counts the number of syllables in an English word or phrase.</p>
</div>
<h3 class="h3" id="lev172"><strong>The Strategy</strong></h3>
<p class="noindent">For you and me, counting syllables is easy. Place the back of your hand just below your chin and start talking. Every time your chin hits your hand you’ve spoken a syllable. Computers don’t have hands or chins, but every vowel sound represents a syllable—and computers can count vowel sounds. It’s not easy, however, as there isn’t a simple rule for doing this. Some vowels in written language are silent, such as the <em>e</em> in <em>like</em>, and some combine to <span epub:type="pagebreak" id="page_148"/>make a single sound, such as the <em>oo</em> in <em>moo</em>. Luckily, the number of words in the English language isn’t infinite. Fairly exhaustive lists are available that include much of the information you need.</p>
<p class="indent">A <em>corpus</em> is a fancy name for a body of text. In <a href="ch09.xhtml#ch09">Chapter 9</a>, you’ll use a <em>training corpus</em>—composed of haiku—that teaches Python how to write new haiku. In this chapter, you’ll use this same corpus to extract syllable counts.</p>
<p class="indent">Your syllable counter should evaluate both phrases and individual words, since you will ultimately use it to count the syllables in entire <em>lines</em> in a haiku. The program will take some text as an input, count the number of syllables in each word, and return the total syllable count. You’ll also have to deal with things like punctuation, whitespace, and missing words.</p>
<p class="indent">The primary steps you need to follow are:</p>
<ol>
<li class="noindent">Download a large corpus with syllable-count information.</li>
<li class="noindent">Compare the syllable-count corpus to the haiku-training corpus and identify all the words missing from the syllable-count corpus.</li>
<li class="noindent">Build a dictionary of the missing words and their syllable counts.</li>
<li class="noindent">Write a program that uses both the syllable-count corpus and the missing-words dictionary to count syllables in the training corpus.</li>
<li class="noindent">Write a program that checks the syllable-counting program against updates of the training corpus.</li>
</ol>
<h4 class="h4" id="lev173"><strong><em>Using a Corpus</em></strong></h4>
<p class="noindent">The Natural Language Toolkit (NLTK) is a popular suite of programs and libraries for working with human language data in Python. It was created in 2001 as part of a computational linguistics course in the Department of Computer and Information Science at the University of Pennsylvania. Development and expansion have continued with the help of dozens of contributors. To learn more, check out the official NLTK website at <em><a href="http://www.nltk.org/">http://www.nltk.org/</a></em>.</p>
<p class="indent">For this project, you will use NLTK to access the Carnegie Mellon University Pronouncing Dictionary (CMUdict). This corpus contains almost 125,000 words mapped to their pronunciations. It is machine readable and useful for tasks such as speech recognition.</p>
<h4 class="h4" id="lev174"><strong><em>Installing NLTK</em></strong></h4>
<p class="noindent">You can find instructions for installing NLTK on Unix, Windows, and macOS at <em><a href="http://www.nltk.org/install.html">http://www.nltk.org/install.html</a></em>. If you are using Windows, I suggest you start by opening Windows Command Prompt or PowerShell and trying to install with <code>pip</code>:</p>
<pre>python -m pip install nltk</pre>
<p class="indent"><span epub:type="pagebreak" id="page_149"/>You can check the installation by opening the Python interactive shell and typing:</p>
<pre>&gt;&gt;&gt; <span class="codestrong1">import nltk</span><br/>&gt;&gt;&gt;</pre>
<p class="indent">If you don’t get an error, you’re good to go. Otherwise, follow the instructions on the website just cited.</p>
<h4 class="h4" id="lev175"><strong><em>Downloading CMUdict</em></strong></h4>
<p class="noindent">To get access to CMUdict (or any of the other NLTK corpora), you have to download it. You can do this using the handy NLTK Downloader. Once you’ve installed NLTK, enter the following into the Python shell:</p>
<pre>&gt;&gt;&gt; <span class="codestrong1">import nltk</span><br/>&gt;&gt;&gt; <span class="codestrong1">nltk.download()</span></pre>
<p class="indent">The NLTK Downloader window (<a href="ch08.xhtml#ch08fig1">Figure 8-1</a>) should now be open. Click the <strong>Corpora</strong> tab near the top, then click <strong>cmudict</strong> in the Identifier column. Next, scroll to the bottom of the window and set the Download Directory; I used the default, <em>C:\nltk_data</em>. Finally, click the <strong>Download</strong> button to load CMUdict.</p>
<div class="image"><a id="ch08fig1"/><img src="../images/f0149-01.jpg" alt="image"/></div>
<p class="figcap"><em>Figure 8-1: The NLTK Downloader window with cmudict selected for download</em></p>
<p class="indent"><span epub:type="pagebreak" id="page_150"/>When CMUdict has finished downloading, exit the Downloader and enter the following into the Python interactive shell:</p>
<pre>&gt;&gt;&gt; <span class="codestrong1">from nltk.corpus import cmudict</span><br/>&gt;&gt;&gt;</pre>
<p class="indent">If you don’t encounter an error, then the corpus has been successfully downloaded.</p>
<h4 class="h4" id="lev176"><strong><em>Counting Sounds Instead of Syllables</em></strong></h4>
<p class="noindent">The CMUdict corpus breaks words into sets of <em>phonemes</em>—perceptually distinct <em>units</em> of sound in a specified language—and marks vowels for lexical stress using numbers (0, 1, and 2). The CMUdict corpus marks every vowel with one, and only one, of these numbers, so you can use the numbers to identify the vowels in a word.</p>
<p class="indent">Looking at words as a set of phonemes will help you sidestep a few problems. For one, CMUdict will not include vowels in the written word that are unpronounced. For example, here’s how CMUdict sees the word <em>scarecrow</em>:</p>
<pre>[['S', 'K', 'AE1', 'R', 'K', 'R', 'OW0']]</pre>
<p class="indent">Each item with a numerical suffix represents a pronounced vowel. Note that the silent <em>e</em> at the end of <em>scare</em> is correctly omitted.</p>
<p class="indent">Second, sometimes multiple and consecutive written vowels are pronounced as just a single phoneme. For example, this is how CMUdict represents <em>house</em>:</p>
<pre>[['HH', 'AW1', 'S']]</pre>
<p class="indent">Note how the corpus treats the written double vowels <em>ou</em> as a single vowel, <code>'AW1'</code>, for pronunciation purposes.</p>
<h4 class="h4" id="lev177"><strong><em>Handling Words with Multiple Pronunciations</em></strong></h4>
<p class="noindent">As I mention in the introduction, some words have multiple distinct pronunciations; <em>aged</em> and <em>learned</em> are just two examples:</p>
<pre>[['EY1', 'JH', 'D'], ['EY1', 'JH', 'IH0', 'D']]<br/>[['L', 'ER1', 'N', 'D'], ['L', 'ER1', 'N', 'IH0', 'D']]</pre>
<p class="indent">Note the nested lists. The corpus recognizes that both words can be pronounced with one or two syllables. This means it will return more than one syllable count for certain words, something you will have to account for in your code.</p>
<h3 class="h3" id="lev178"><span epub:type="pagebreak" id="page_151"/><strong>Managing Missing Words</strong></h3>
<p class="noindent">CMUdict is very useful, but with a corpus, a word is either there or not. It took only seconds to find more than 50 words—like <em>dewdrop</em>, <em>bathwater</em>, <em>dusky</em>, <em>ridgeline</em>, <em>storks</em>, <em>dragonfly</em>, <em>beggar</em>, and <em>archways</em>—missing from CMUdict in a 1,500-word test case. So, one of your strategies should be to check CMUdict for missing words and then address any omissions by making a corpus for your corpus!</p>
<h4 class="h4" id="lev179"><strong><em>The Training Corpus</em></strong></h4>
<p class="noindent">In <a href="ch09.xhtml#ch09">Chapter 9</a>, you’ll use a training corpus of several hundred haiku to “teach” your program how to write new ones. But you can’t count on CMUdict to contain all the words in this corpus because some will be Japanese words, like <em>sake</em>. And as you already saw, even some common English words are missing from CMUdict.</p>
<p class="indent">So the first order of business is to check all the words in the training corpus for membership in CMUdict. To do this, you’ll need to download the training corpus, called <em>train.txt</em>, from <em><a href="https://www.nostarch.com/impracticalpython/">https://www.nostarch.com/impracticalpython/</a></em>. Keep it in the same folder as all the Python programs from this chapter. The file contains slightly under 300 haiku that have been randomly duplicated around 20 times to ensure a robust training set.</p>
<p class="indent">Once you find words that aren’t in CMUdict, you’ll write a script to help you prepare a Python dictionary that uses words as keys and syllable counts as values; then you’ll save this dictionary to a file that can support CMUdict in the syllable-counting program.</p>
<h4 class="h4" id="lev180"><strong><em>The Missing Words Code</em></strong></h4>
<p class="noindent">The code in this section will find words missing from CMUdict, help you prepare a dictionary of the words and their syllable counts, and save the dictionary to a file. You can download the code from <em><a href="https://nostarch.com/impracticalpython/">https://nostarch.com/impracticalpython/</a></em> as <em>missing_words_finder.py</em>.</p>
<h5 class="h5" id="lev181"><strong>Importing Modules, Loading CMUdict, and Defining the main() Function</strong></h5>
<p class="noindent"><a href="ch08.xhtml#ch08list1">Listing 8-1</a> imports modules, loads CMUdict, and defines the <code>main()</code> function that runs the program.</p>
<p class="margin"><em>missing_words_finder.py,</em> part 1</p>
<pre>   import sys<br/>   from string import punctuation<br/><span class="ent">➊</span> import pprint<br/>   import json<br/>   from nltk.corpus import cmudict<br/><br/><span class="ent">➋</span> cmudict = cmudict.dict()  # Carnegie Mellon University Pronouncing Dictionary<br/><br/><span class="ent">➌</span> def main():<br/>    <span class="ent">➍</span> haiku = load_haiku('train.txt')<br/>    <span class="ent">➎</span> exceptions = cmudict_missing(haiku)<br/><span epub:type="pagebreak" id="page_152"/>    <span class="ent">➏</span> build_dict = input("\nManually build an exceptions dictionary (y/n)? \n")<br/>       if build_dict.lower() == 'n':<br/>           sys.exit()<br/>       else:<br/>        <span class="ent">➐</span> missing_words_dict = make_exceptions_dict(exceptions)<br/>           save_exceptions(missing_words_dict)</pre>
<p class="listing" id="ch08list1"><em>Listing 8-1: Imports modules, loads CMUdict, and defines</em> <span class="codeitalic">main()</span></p>
<p class="indent">You start with some familiar imports and a few new ones. The <code>pprint</code> module lets you “pretty print” your dictionary of missing words in an easy-to-read format <span class="ent">➊</span>. You’ll write out this same dictionary as persistent data using JavaScript Object Notation (<code>json</code>), a text-based way for computers to exchange data that works well with Python data structures; it’s part of the standard library, standardized across multiple languages, and the data is secure and human readable. Finish by importing the CMUdict corpus.</p>
<p class="indent">Next, call the <code>cmudict</code> module’s <code>dict()</code> method to turn the corpus into a dictionary with the words as keys and their phonemes as values <span class="ent">➋</span>.</p>
<p class="indent">Define the <code>main()</code> function that will call functions to load the training corpus, find missing words in CMUdict, build a dictionary with the words and their syllable counts, and save the results <span class="ent">➌</span>. You’ll define these functions after defining <code>main()</code>.</p>
<p class="indent">Call the function to load the haiku-training corpus and assign the returned set to a variable named <code>haiku</code> <span class="ent">➍</span>. Then call the function that will find the missing words and return them as a set <span class="ent">➎</span>. Using sets removes duplicate words that you don’t need. The <code>cmudict_missing()</code> function will also display the number of missing words and some other statistics.</p>
<p class="indent">Now, ask the user if they want to manually build a dictionary to address the missing words and assign their input to the <code>build_dict</code> variable <span class="ent">➏</span>. If they want to stop, exit the program; otherwise, call a function to build the dictionary <span class="ent">➐</span> and then another one to save the dictionary. Note that the user isn’t restricted to pressing <code>y</code> if they want to continue, though that’s the prompt.</p>
<h5 class="h5" id="lev182"><strong>Loading the Training Corpus and Finding Missing Words</strong></h5>
<p class="noindent"><a href="ch08.xhtml#ch08list2">Listing 8-2</a> loads and prepares the training corpus, compares its contents to CMUdict, and keeps track of the differences. These tasks are divided between two functions.</p>
<p class="margin"><em>missing_words_finder.py,</em> part 2</p>
<pre><span class="ent">➊</span> def load_haiku(filename):<br/>       """Open and return training corpus of haiku as a set."""<br/>       with open(filename) as in_file:<br/>     <span class="ent">➋</span> haiku = set(in_file.read().replace('-', ' ').split())<br/>     <span class="ent">➌</span> return haiku<br/><br/>   def cmudict_missing(word_set):<br/>       """Find and return words in word set missing from cmudict."""<br/>    <span class="ent">➍</span> exceptions = set()<br/>       for word in word_set:<br/>           word = word.lower().strip(punctuation)<br/>           if word.endswith("'s") or word.endswith("’s"):<br/><span epub:type="pagebreak" id="page_153"/>               word = word[:-2]<br/>        <span class="ent">➎</span> if word not in cmudict:<br/>               exceptions.add(word)<br/>       print("\nexceptions:")<br/>       print(*exceptions, sep='\n')<br/>    <span class="ent">➏</span> print("\nNumber of unique words in haiku corpus = {}"<br/>             .format(len(word_set)))<br/>       print("Number of words in corpus not in cmudict = {}"<br/>             .format(len(exceptions)))<br/>       membership = (1 - (len(exceptions) / len(word_set))) * 100<br/>    <span class="ent">➐</span> print("cmudict membership = {:.1f}{}".format(membership, '%'))<br/>       return exceptions</pre>
<p class="listing" id="ch08list2"><em>Listing 8-2: Defines functions to load the corpus and finds words missing from CMUdict</em></p>
<p class="indent">Define a function to read in the words from the haiku-training corpus <span class="ent">➊</span>. The haiku in <em>train.txt</em> have been duplicated many times, plus the original haiku contain duplicate words, like <em>moon</em>, <em>mountain</em>, and <em>the</em>. There’s no point in evaluating a word more than once, so load the words as a set to remove repeats <span class="ent">➋</span>. You also need to replace hyphens with spaces. Hyphens are popular in haiku, but you need to separate the words on either side in order to check for them in CMUdict. End the function by returning the <code>haiku</code> set <span class="ent">➌</span>.</p>
<p class="indent">It’s now time to find missing words. Define a function, <code>cmudict_missing()</code>, that takes as an argument a sequence—in this case, the set of words returned by the <code>load_haiku()</code> function. Start an empty set called <code>exceptions</code> to hold any missing words <span class="ent">➍</span>. Loop through each word in the haiku set, converting it to lowercase and stripping any leading or trailing punctuation. Note that you don’t want to remove interior punctuation other than hyphens because CMUdict recognizes words like <em>wouldn’t</em>. Possessive words typically aren’t in a corpus, so remove the trailing <em>’s</em>, since this won’t affect the syllable count.</p>
<div class="note">
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>
<p class="notep"><em>Be careful of curly apostrophes (’) produced by word-processing software. These are different from the straight apostrophes (</em><code>'</code><em>) used in simple text editors and shells and may not be recognized by CMUdict. If you add new words to either the training or JSON files, be sure to use a straight apostrophe for contractions or possessive nouns.</em></p>
</div>
<p class="indent">If the word isn’t found in CMUdict, add it to <code>exceptions</code> <span class="ent">➎</span>. Print these words as a check, along with some basic information <span class="ent">➏</span>, like how many unique words, how many missing words, and what percentage of the training corpus are members of CMUdict. Set the percent value precision to one decimal place <span class="ent">➐</span>. End the function by returning the set of exceptions.</p>
<h5 class="h5" id="lev183"><strong>Building a Dictionary of Missing Words</strong></h5>
<p class="noindent"><a href="ch08.xhtml#ch08list3">Listing 8-3</a> continues the <em>missing_words_finder.py</em> code, now supplementing CMUdict by assigning syllable counts to the missing words as values in a Python dictionary. Since the number of missing words should be relatively small, the user can assign the counts manually, so write the code to help them interact with the program.</p>
<p class="margin"><span epub:type="pagebreak" id="page_154"/><em>missing_words_finder.py,</em> part 3</p>
<pre><span class="ent">➊</span> def make_exceptions_dict(exceptions_set):<br/>       """Return dictionary of words &amp; syllable counts from a set of words."""<br/>    <span class="ent">➋</span> missing_words = {}<br/>       print("Input # syllables in word. Mistakes can be corrected at end. \n")<br/>       for word in exceptions_set:<br/>           while True:<br/>            <span class="ent">➌</span> num_sylls = input("Enter number syllables in {}: ".format(word))<br/>            <span class="ent">➍</span> if num_sylls.isdigit():<br/>                   break<br/>               else:<br/>                   print("                 Not a valid answer!", file=sys.stderr)<br/>        <span class="ent">➎</span> missing_words[word] = int(num_sylls)<br/>       print()<br/>    <span class="ent">➏</span> pprint.pprint(missing_words, width=1)<br/><br/>    <span class="ent">➐</span> print("\nMake Changes to Dictionary Before Saving?")<br/>       print("""<br/>       0 - Exit &amp; Save<br/>       1 – Add a Word or Change a Syllable Count<br/>       2 - Remove a Word<br/>       """)<br/><br/>    <span class="ent">➑</span> while True:<br/>           choice = input("\nEnter choice: ")<br/>           if choice == '0':<br/>               break<br/>           elif choice == '1':<br/>               word = input("\nWord to add or change: ")<br/>               missing_words[word] = int(input("Enter number syllables in {}: "<br/>                                               .format(word)))<br/>           elif choice == '2':<br/>               word = input("\nEnter word to delete: ")<br/>            <span class="ent">➒</span> missing_words.pop(word, None)<br/><br/>       print("\nNew words or syllable changes:")<br/>    <span class="ent">➓</span> pprint.pprint(missing_words, width=1)<br/><br/>       return missing_words</pre>
<p class="listing" id="ch08list3"><em>Listing 8-3: Allows the user to manually count syllables and builds a dictionary</em></p>
<p class="indent">Start by defining a function that takes the set of exceptions returned by the <code>cmudict_missing()</code> function as an argument <span class="ent">➊</span>. Immediately assign an empty dictionary to a variable named <code>missing_words</code> <span class="ent">➋</span>. Let the user know that if they make a mistake, they’ll have a chance to fix it later; then, use a <code>for</code> and <code>while</code> loop to go through the set of missing words and present each word to the user, asking for the number of syllables as input. The word will be the dictionary key, and the <code>num_sylls</code> variable will become its value <span class="ent">➌</span>. If the input is a digit <span class="ent">➍</span>, break out of the loop. Otherwise, warn the user and let the <code>while</code> loop request input again. If the input passes, add the value to the dictionary as an integer <span class="ent">➎</span>.</p>
<p class="indent"><span epub:type="pagebreak" id="page_155"/>Use <code>pprint</code> to display each key/value pair on a separate line, as a check. The <code>width</code> parameter acts as a newline argument <span class="ent">➏</span>.</p>
<p class="indent">Give the user the opportunity to make last-minute changes to the <code>missing_words</code> dictionary before saving it as a file <span class="ent">➐</span>. Use triple quotes to present the options menu, followed by a <code>while</code> loop to keep the options active until the user is ready to save <span class="ent">➑</span>. The three options are exiting, which invokes the <code>break</code> command; adding a new word or changing the syllable count for an existing word, which requires the word and syllable count as input; and removing an entry, which uses the dictionary <code>pop()</code> function <span class="ent">➒</span>. Adding the <code>None</code> argument to <code>pop()</code> means the program won’t raise a <code>KeyError</code> if the user enters a word that’s not in the dictionary.</p>
<p class="indent">Finish by giving the user a last look at the dictionary, in the event changes were made <span class="ent">➓</span>, and then return it.</p>
<h5 class="h5" id="lev184"><strong>Saving the Missing Words Dictionary</strong></h5>
<p class="noindent"><em>Persistent data</em> is data that is preserved after a program terminates. To make the <code>missing_words</code> dictionary available for use in the <em>count_syllables.py</em> program you’ll write later in this chapter, you need to save it to a file. <a href="ch08.xhtml#ch08list4">Listing 8-4</a> does just that.</p>
<p class="margin"><em>missing_words_finder.py,</em> part 4</p>
<pre><span class="ent">➊</span> def save_exceptions(missing_words):<br/>       """Save exceptions dictionary as json file."""<br/>    <span class="ent">➋</span> json_string = json.dumps(missing_words)<br/>    <span class="ent">➌</span> f = open('missing_words.json', 'w')<br/>       f.write(json_string)<br/>       f.close()<br/>    <span class="ent">➍</span> print("\nFile saved as missing_words.json")<br/><br/><span class="ent">➎</span> if __name__ == '__main__':<br/>       main()</pre>
<p class="listing" id="ch08list4"><em>Listing 8-4: Saves missing-words dictionary to a file and calls</em> <span class="codeitalic">main()</span></p>
<p class="indent">Use <code>json</code> to save the dictionary. Define a new function that takes the set of missing words as an argument <span class="ent">➊</span>. Assign the <code>missing_words</code> dictionary to a new variable named <code>json_string</code> <span class="ent">➋</span>; then, open a file with a <em>.json</em> extension <span class="ent">➌</span>, write the <code>json</code> variable, and close the file. Display the name of the file as a reminder to the user <span class="ent">➍</span>. End with the code that lets the program be run as a module or in stand-alone mode <span class="ent">➎</span>.</p>
<p class="indent">The <code>json.dumps()</code> method serializes the <code>missing_words</code> dictionary into a string. <em>Serialization</em> is the process of converting data into a more transmittable or storable format. For example:</p>
<pre>&gt;&gt;&gt; <span class="codestrong1">import json</span><br/>&gt;&gt;&gt; <span class="codestrong1">d = {'scarecrow': 2, 'moon': 1, 'sake': 2}</span><br/>&gt;&gt;&gt; <span class="codestrong1">json.dumps(d)</span><br/>'{"sake": 2, "scarecrow": 2, "moon": 1}'</pre>
<p class="indent">Note that the serialized dictionary is bound by single quotes, making it a string.</p>
<p class="indent"><span epub:type="pagebreak" id="page_156"/>I’ve provided a partial output from <em>missing_words_finder.py</em> here. The list of missing words at the top and the manual syllable counts at the bottom have both been shortened for brevity.</p>
<pre><span class="codeitalic1">--snip--</span><br/>froglings<br/>scatters<br/>paperweights<br/>hibiscus<br/>cumulus<br/>nightingales<br/><br/>Number of unique words in haiku corpus = 1523<br/>Number of words in corpus not in cmudict = 58<br/>cmudict membership = 96.2%<br/><br/>Manually build an exceptions dictionary (y/n)?<br/><span class="codestrong1">y</span><br/>Enter number syllables in woodcutter: 3<br/>Enter number syllables in morningglory: 4<br/>Enter number syllables in cumulus: 3<br/><span class="codeitalic1">--snip--</span></pre>
<p class="indent">Don’t worry—you won’t have to assign all the syllable counts. The <em>missing_words.json</em> file is complete and ready for download when you need it.</p>
<div class="note">
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>
<p class="notep"><em>For words that have multiple pronunciations, like</em> jagged <em>or</em> our<em>, you can force the program to use the one you prefer by manually opening the</em> missing_words.json <em>file and adding the key/value pair at any location. I did this with the word</em> sake <em>so that it uses the two-syllable Japanese pronunciation. Because word membership is checked in this file first, it will override the CMUdict value.</em></p>
</div>
<p class="indent">Now that you’ve addressed the holes in CMUdict, you’re ready to write the code that counts syllables. In <a href="ch09.xhtml#ch09">Chapter 9</a>, you’ll use this code as a module in the <em>markov_haiku.py</em> program.</p>
<h3 class="h3" id="lev185"><strong>The Count Syllables Code</strong></h3>
<p class="noindent">This section contains the code for the <em>count_syllables.py</em> program. You’ll also need the <em>missing_words.json</em> file you created in the previous section. You can download both from <em><a href="https://www.nostarch.com/impracticalpython/">https://www.nostarch.com/impracticalpython/</a></em>. Keep them together in the same folder.</p>
<h4 class="h4" id="lev186"><strong><em>Prepping, Loading, and Counting</em></strong></h4>
<p class="noindent"><a href="ch08.xhtml#ch08list5">Listing 8-5</a> imports the necessary modules, loads the CMUdict and missing-words dictionaries, and defines a function that will count the syllables in a given word or phrase.</p>
<p class="margin"><span epub:type="pagebreak" id="page_157"/><em>count_syllables.py,</em> part 1</p>
<pre>   import sys<br/>   from string import punctuation<br/>   import json<br/>   from nltk.corpus import cmudict<br/><br/>   # load dictionary of words in haiku corpus but not in cmudict<br/>   with open('missing_words.json') as f:<br/>       missing_words = json.load(f)<br/><br/><span class="ent">➊</span> cmudict = cmudict.dict()<br/><br/><span class="ent">➋</span> def count_syllables(words):<br/>       """Use corpora to count syllables in English word or phrase."""<br/>       # prep words for cmudict corpus<br/>       words = words.replace('-', ' ')<br/>       words = words.lower().split()<br/>    <span class="ent">➌</span> num_sylls = 0<br/>    <span class="ent">➍</span> for word in words:<br/>           word = word.strip(punctuation)<br/>           if word.endswith("'s") or word.endswith("’s"):<br/>               word = word[:-2]<br/>        <span class="ent">➎</span> if word in missing_words:<br/>               num_sylls += missing_words[word]<br/>           else:<br/>            <span class="ent">➏</span> for phonemes in cmudict[word][0]:<br/>                   for phoneme in phonemes:<br/>                    <span class="ent">➐</span> if phoneme[-1].isdigit():<br/>                           num_sylls += 1<br/><br/>    <span class="ent">➑</span> return num_sylls</pre>
<p class="listing" id="ch08list5"><em>Listing 8-5: Imports modules, loads dictionaries, and counts syllables</em></p>
<p class="indent">After some familiar imports, load the <em>missing_words.json</em> file that contains all the words and syllable counts missing from CMUdict. Using <code>json.load()</code> restores the dictionary that was stored as a string. Next, turn the CMUdict corpus into a dictionary using the <code>dict()</code> method <span class="ent">➊</span>.</p>
<p class="indent">Define a function called <code>count_syllables()</code> to count syllables. It should take both words <em>and</em> phrases, because you’ll ultimately want to pass it lines from a haiku. Prep the words as you did previously in the <em>missing_words_finder.py</em> program <span class="ent">➋</span>.</p>
<p class="indent">Assign a <code>num_sylls</code> variable to hold the syllable count and set it to <code>0</code> <span class="ent">➌</span>. Now start looping through the input words, stripping punctuation and <em>’s</em> from the ends. Note that you can get tripped up by the format of the apostrophe, so two versions are supplied: one with a straight apostrophe and one with a curly apostrophe <span class="ent">➍</span>. Next, check whether the word is a member of the small dictionary of missing words. If the word is found, add the dictionary value for the word to <code>num_sylls</code> <span class="ent">➎</span>. Otherwise, start looking through the phonemes, which represent a value in CMUdict; for each phoneme, look through the strings that make it up <span class="ent">➏</span>. If you find a digit at the end of the string, then you know that phoneme is a vowel. To illustrate using the word <em>aged</em>, only the first string (highlighted in gray here) ends with a digit, so the word contains one vowel:</p>
<pre><span epub:type="pagebreak" id="page_158"/>[['<span class="gray">EY1</span>', 'JH', 'D'], ['EY1', 'JH', 'IH0', 'D']]</pre>
<p class="indent">Note that you use the first value (<code>[0]</code>) in case there are multiple pronunciations; remember that CMUdict represents each pronunciation in a nested list. This may result in the occasional error, as the proper choice will depend on context.</p>
<p class="indent">Check whether the end of the phoneme has a digit, and if it does, add <code>1</code> to <code>num_sylls</code> <span class="ent">➐</span>. Finally, return the total syllable count for the word or phrase <span class="ent">➑</span>.</p>
<h4 class="h4" id="lev187"><strong><em>Defining the main() Function</em></strong></h4>
<p class="noindent">Completing the program, <a href="ch08.xhtml#ch08list6">Listing 8-6</a> defines and runs the <code>main()</code> function. The program will call this function when the program is run in stand-alone mode—for example, to spot-check a word or phrase—but it won’t be called if you import <code>syllable_counter</code> as a module.</p>
<p class="margin"><em>count_syllables.py,</em> part 2</p>
<pre>   def main():<br/>    <span class="ent">➊</span> while True:<br/>           print("Syllable Counter")<br/>        <span class="ent">➋</span> word = input("Enter word or phrase; else press Enter to Exit: ")<br/>        <span class="ent">➌</span> if word == '':<br/>               sys.exit()<br/>        <span class="ent">➍</span> try:<br/>               num_syllables = count_syllables(word)<br/>               print("number of syllables in {} is: {}"<br/>                     .format(word, num_syllables))<br/>               print()<br/>           except KeyError:<br/>               print("Word not found.  Try again.\n", file=sys.stderr)<br/><span class="ent">➎</span> if __name__ == '__main__':<br/>       main()</pre>
<p class="listing" id="ch08list6"><em>Listing 8-6: Defines and calls the</em> <span class="codeitalic">main()</span> <em>function</em></p>
<p class="indent">Define the <code>main()</code> function and then start a <code>while</code> loop <span class="ent">➊</span>. Ask the user to input a word or phrase <span class="ent">➋</span>. If the user presses <small>ENTER</small> with no input, the program exits <span class="ent">➌</span>. Otherwise, start a <code>try</code>-<code>except</code> block so the program won’t crash if a user enters a word not found in either dictionary <span class="ent">➍</span>. An exception should be raised only in stand-alone mode, as you have already prepared the program to run on the haiku-training corpus with no exceptions. Within this block, the <code>count_syllables()</code> function is called and passed the input, and then the results are displayed in the interactive shell. End with the standard code that lets the program run stand-alone or as a module in another program <span class="ent">➎</span>.</p>
<h3 class="h3" id="lev188"><strong>A Program to Check Your Program</strong></h3>
<p class="noindent">You have carefully tailored the syllable-counting program to ensure it will work with the training corpus. As you continue with the haiku program, you may want to add a poem or two to this corpus, but adding new haiku <span epub:type="pagebreak" id="page_159"/>might introduce a new word that isn’t in either the CMUdict or your exceptions dictionary. Before you go back and rebuild the exceptions dictionary, check whether you really need to do so.</p>
<p class="indent"><a href="ch08.xhtml#ch08list7">Listing 8-7</a> will automatically count the syllables in each word in your training corpus and display any word(s) on which it failed. You can download this program from <em><a href="https://www.nostarch.com/impracticalpython/">https://www.nostarch.com/impracticalpython/</a></em> as <em>test_count_syllables_w_full_corpus.py</em>. Keep it in the same folder as <em>count_syllables.py</em>, <em>train.txt</em>, and <em>missing_words.json</em>.</p>
<p class="margin"><em>test_count_syllables_w_full_corpus.py</em></p>
<pre>   import sys<br/>   import count_syllables<br/><br/>   with open('train.txt.') as in_file:<br/>    <span class="ent">➊</span> words = set(in_file.read().split())<br/><br/><span class="ent">➋</span> missing = []<br/><br/><span class="ent">➌</span> for word in words:<br/>       try:<br/>           num_syllables = count_syllables.count_syllables(word)<br/>           ##print(word, num_syllables, end='\n') # uncomment to see word counts<br/>    <span class="ent">➍</span> except KeyError:<br/>           missing.append(word)<br/><br/><span class="ent">➎</span> print("Missing words:", missing, file=sys.stderr)</pre>
<p class="listing" id="ch08list7"><em>Listing 8-7: Attempts to count syllables in words in a training corpus and lists all failures</em></p>
<p class="indent">Open your updated <em>train.txt</em> training corpus and load it as a set to remove duplicates <span class="ent">➊</span>. Start an empty list, called <code>missing</code>, to hold any new words for which syllables can’t be counted <span class="ent">➋</span>. Words in <code>missing</code> won’t be in CMUdict or in your <code>missing_words</code> dictionary.</p>
<p class="indent">Loop through the words in the new training corpus <span class="ent">➌</span> and use a <code>try-except</code> block to handle the <code>KeyError</code> that will be raised if <em>count_syllables.py</em> can’t find the word <span class="ent">➍</span>. Append this word to the <code>missing</code> list and then display the list <span class="ent">➎</span>.</p>
<p class="indent">If the program displays an empty list, then all the words in the new haiku are already present in either CMUdict or <em>missing_words.json</em>, so you don’t need to make any adjustments. Otherwise, you have the choice of manually adding the words to the <em>missing_words.json</em> file or rerunning <em>missing_words_finder.py</em> to rebuild <em>missing_words.json</em>.</p>
<h3 class="h3" id="lev189"><strong>Summary</strong></h3>
<p class="noindent">In this chapter, you’ve learned how to download NLTK and use one of its datasets, the Carnegie Mellon Pronouncing Dictionary (CMUdict). You checked the CMUdict dataset against a training corpus of haiku and built a supporting Python dictionary for any missing words. You saved this Python <span epub:type="pagebreak" id="page_160"/>dictionary as persistent data using JavaScript Object Notation (JSON). Finally, you wrote a program that can count syllables. In <a href="ch09.xhtml#ch09">Chapter 9</a>, you’ll use your syllable-counting program to help you generate novel haiku.</p>
<h3 class="h3" id="lev190"><strong>Further Reading</strong></h3>
<p class="noindent"><em>Virtual Muse: Experiments in Computer Poetry</em> (Wesleyan University Press, 1996) by Charles O. Hartman is an engaging look at the early collaboration between humans and computers to write poetry.</p>
<p class="indent"><em>Natural Language Processing with Python: Analyzing Text with the Natural Language Toolkit</em> (O’Reilly, 2009) by Steven Bird, Ewan Klein, and Edward Loper is an accessible introduction to NLP using Python, with lots of exercises and useful integration with the NLTK website. A new version of the book, updated for Python 3 and NLTK 3, is available online at <em><a href="http://www.nltk.org/book/">http://www.nltk.org/book/</a></em>.</p>
<p class="indent">“The Growing Importance of Natural Language Processing” by Stephen F. DeAngelis is a <em>Wired</em> magazine article on the expanding role of NLP in big data. An online version is available at <em><a href="https://www.wired.com/insights/2014/02/growing-importance-natural-language-processing/">https://www.wired.com/insights/2014/02/growing-importance-natural-language-processing/</a></em>.</p>
<h3 class="h3" id="lev191"><strong>Practice Project: Syllable Counter vs. Dictionary File</strong></h3>
<p class="noindent">Write a Python program that lets you test <em>count_syllables.py</em> (or any other syllable-counting Python code) against a dictionary file. After allowing the user to specify how many words to check, choose the words at random and display a listing of each word and its syllable count on separate lines. The output should look similar to this printout:</p>
<pre>ululation 4<br/>intimated 4<br/>sand 1<br/>worms 1<br/>leatherneck 3<br/>contenting 3<br/>scandals 2<br/>livelihoods 3<br/>intertwining 4<br/>beaming 2<br/>untruthful 3<br/>advice 2<br/>accompanying 5<br/>deathly 2<br/>hallos 2</pre>
<p class="indent">Downloadable dictionary files are listed in <a href="ch02.xhtml#ch02tab1">Table 2-1</a> on <a href="ch02.xhtml#page_20">page 20</a>. You can find a solution in the appendix that can be downloaded from <em><a href="https://www.nostarch.com/impracticalpython/">https://www.nostarch.com/impracticalpython/</a></em> as <em>test_count_syllables_w_dict.py</em>.</p>
</body></html>
- en: '**4'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**4'
- en: STATISTICS**
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 统计学**
- en: '![image](Images/common.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/common.jpg)'
- en: Bad datasets lead to bad models. We’d like to understand our data before we
    build a model, and then use that understanding to create a useful dataset, one
    that leads to models that do what we expect them to do. Knowing basic statistics
    will enable us to do just that.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 糟糕的数据集会导致糟糕的模型。在构建模型之前，我们希望了解我们的数据，然后利用这些理解创建一个有用的数据集，进而生成符合预期的模型。掌握基本的统计学将帮助我们做到这一点。
- en: A *statistic* is any number that’s calculated from a sample and used to characterize
    it in some way. In deep learning, when we talk about samples, we’re usually talking
    about datasets. Maybe the most basic statistic is the arithmetic mean, commonly
    known as the average. The mean of a dataset is a single-number summary of the
    dataset.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '*统计量*是从样本中计算得出的任何数字，并以某种方式用来描述它。在深度学习中，当我们谈论样本时，通常是指数据集。也许最基本的统计量是算术平均数，通常称为平均值。数据集的平均值是数据集的一个单一数字摘要。'
- en: We’ll see many different statistics in this chapter. We’ll begin by learning
    about the types of data and characterizing a dataset with summary statistics.
    Next, we’ll learn about quantiles and plotting data to understand what it contains.
    After that comes a discussion of outliers and missing data. Datasets are seldom
    perfect, so we need to have some way of detecting bad data and dealing with missing
    data. We’ll follow our discussion of imperfect datasets with a discussion of the
    correlation between variables. Then we’ll close the chapter out by discussing
    hypothesis testing, where we attempt to answer questions like “How likely is it
    that the same parent process generated two datasets?” Hypothesis testing is widely
    used in science, including deep learning.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将看到许多不同的统计量。我们将从学习数据类型和用总结性统计量描述数据集开始。接下来，我们将学习分位数并绘制数据以了解其内容。之后将讨论异常值和缺失数据。数据集很少是完美的，因此我们需要有某种方式来检测不良数据并处理缺失数据。我们在讨论不完美的数据集之后，会讨论变量之间的相关性。最后，我们将通过讨论假设检验来结束本章，假设检验帮助我们回答诸如“相同的父进程生成两个数据集的可能性有多大？”这样的问题。假设检验在科学中被广泛应用，包括深度学习。
- en: Types of Data
  id: totrans-6
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据类型
- en: The four types of data are nominal, ordinal, interval, and ratio. Let’s look
    at each in turn.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 四种数据类型是名义数据、顺序数据、间隔数据和比率数据。让我们逐一看一下它们。
- en: Nominal Data
  id: totrans-8
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 名义数据
- en: '*Nominal data*, sometimes called *categorical data*, is data that has no ordering
    between the different values. An example of this is eye color; there is no relationship
    between brown, blue, and green.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '*名义数据*，有时称为*类别数据*，是没有不同值之间顺序关系的数据。一个例子是眼睛颜色；棕色、蓝色和绿色之间没有关系。'
- en: Ordinal Data
  id: totrans-10
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 顺序数据
- en: For *ordinal data*, the data has a ranking or order, though differences aren’t
    meaningful in a mathematical sense. For example, if a questionnaire asks you to
    select from “strongly disagree,” “disagree,” “neutral,” “agree,” and “strongly
    agree,” it’s pretty clear that there is an order. Still, it’s also clear that
    “agree” isn’t three more than “strongly disagree.” All we can say is that “strongly
    disagree” is to the left of “agree” (and “neutral” and “disagree”).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 对于*顺序数据*，数据具有排名或顺序，尽管在数学意义上这些差异并不重要。例如，如果问卷要求你从“强烈反对”、“反对”、“中立”、“同意”和“强烈同意”中选择，显然是有顺序的。不过，仍然可以看出，“同意”并不比“强烈反对”大三倍。我们能说的只是“强烈反对”在“同意”的左侧（以及“中立”和“反对”）。
- en: Another example of ordinal data is education level. If one person has a fourth-grade
    education and another has an eighth-grade education, we can say that the latter
    person is more educated than the former, but we can’t say that the latter person
    is twice as educated, because “twice as educated” has no fixed meaning.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个顺序数据的例子是教育水平。如果一个人的教育水平是四年级，另一个人的教育水平是八年级，我们可以说后者的教育水平高于前者，但我们不能说后者的教育水平是前者的两倍，因为“教育水平是两倍”没有固定的意义。
- en: Interval Data
  id: totrans-13
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 间隔数据
- en: '*Interval data* has meaningful differences. For example, if one cup of water
    is at 40 degrees Fahrenheit and another is at 80 degrees Fahrenheit, we can say
    that there is a 40-degree difference between the two cups of water. We can’t,
    however, say that there is twice as much heat in the second cup, because the zero
    for the Fahrenheit scale is arbitrary. Colloquially, we do say it’s twice as hot,
    but in reality, it isn’t. To see this, think about what happens if we change the
    temperature scale to another scale with an arbitrary, though more sensible, zero:
    the Celsius scale. We see that the first cup is at about 4.4 degrees Celsius,
    and the second is at 26.7 degrees Celsius. Clearly, the second cup doesn’t suddenly
    now have six times the heat of the first.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '*区间数据*具有有意义的差异。例如，如果一杯水的温度是40华氏度，另一杯是80华氏度，我们可以说这两杯水之间的温差是40度。然而，我们不能说第二杯水的热量是第一杯的两倍，因为华氏度的零点是任意的。口语中我们确实会说第二杯更热，但实际上并非如此。要验证这一点，可以想象如果我们将温度量表换成另一个具有任意零点但更合理的量表——摄氏度。我们看到第一杯水的温度大约是4.4°C，第二杯是26.7°C。显然，第二杯水并没有比第一杯多六倍的热量。'
- en: Ratio Data
  id: totrans-15
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 比率数据
- en: Finally, *ratio data* is data where differences are meaningful, and there is
    a true zero point. Height is a ratio value because a height of zero is just that—no
    height at all. Similarly, age is also a ratio value because an age of zero means
    no age at all. If we were to adopt a new age scale and call a person zero when
    they reach, say, voting age, we’d then have an interval scale, not a ratio scale.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，*比率数据*是指差异有意义并且具有真实零点的数据。身高是比率值，因为零身高就是没有身高。同样，年龄也是比率值，因为零岁意味着没有年龄。如果我们采用一个新的年龄量表，并在一个人达到某个年龄段（例如投票年龄）时称其为零，那么我们就得到了一个区间量表，而不是比率量表。
- en: Let’s look at temperature again. We said above that temperature is an interval
    quantity. This isn’t always the case. If we measure temperature in Fahrenheit
    or Celsius, then, yes, it is an interval quantity. However, if we measure temperature
    in Kelvin, the absolute temperature scale, then it becomes a ratio value. Why?
    Because a temperature of 0 Kelvin (or *K*) is just that, no temperature at all.
    If our first cup is at 40°F, 277.59 K, and the second is at 80°F, 299.82 K, then
    we can truthfully say that the second cup is 1.08 times hotter than the first,
    since (277.59)(1.08) ≈ 299.8.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们再来看一下温度。我们之前提到温度是一个区间量。这并非总是如此。如果我们用华氏度或摄氏度来测量温度，那么确实它是一个区间量。然而，如果我们用开尔文度（绝对温标）来测量温度，它就变成了比率值。为什么？因为0开尔文（或*K*）温度就是真正的零温度，意味着没有任何温度。如果我们的第一杯水是40°F，277.59
    K，第二杯是80°F，299.82 K，那么我们可以真实地说第二杯水比第一杯热1.08倍，因为（277.59）（1.08）≈299.8。
- en: '[Figure 4-1](ch04.xhtml#ch04fig01) names the scales and shows their relationships
    to each other.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[图4-1](ch04.xhtml#ch04fig01)标明了各个量表，并展示了它们之间的关系。'
- en: '![image](Images/04fig01.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/04fig01.jpg)'
- en: '*Figure 4-1: The four types of data*'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '*图4-1：四种数据类型*'
- en: Each step in [Figure 4-1](ch04.xhtml#ch04fig01) from left to right adds something
    to the data that the type of data on the left is lacking. For nominal to ordinal,
    we add ordering. For ordinal to interval, we add meaningful differences. Lastly,
    moving from interval to ratio adds a true zero point.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[图4-1](ch04.xhtml#ch04fig01)中的每一步，从左到右，都为数据增加了左边数据类型所缺乏的内容。从名义数据到有序数据，我们增加了排序；从有序数据到区间数据，我们增加了有意义的差异；最后，从区间数据到比率数据增加了一个真正的零点。'
- en: In practical use, as far as statistics are concerned, we should be aware of
    the types of data so we don’t do something meaningless. If we have a questionnaire,
    and the mean value of question A on a 1-to-5 rating scale is 2, while for question
    B it’s 4, we can’t say that B is rated twice as high as A, only that B was rated
    higher than A. What “twice” means in this context is unclear and quite probably
    meaningless.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际应用中，就统计学而言，我们应该了解数据的类型，以免做出没有意义的分析。如果我们有一份问卷，问题A在1到5的评分量表上的平均值为2，而问题B的平均值为4，我们不能说B的评分是A的两倍，只能说B的评分高于A。在这个背景下，“两倍”是什么意思并不明确，很可能是没有意义的。
- en: Interval and ratio data may be continuous (floating-points) or discrete (integers).
    From a deep learning perspective, models typically treat continuous and discrete
    data the same way, and we don’t need to do anything special for discrete data.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 区间数据和比率数据可以是连续的（浮动数值）或离散的（整数）。从深度学习的角度看，模型通常将连续数据和离散数据同等对待，我们不需要对离散数据做任何特殊处理。
- en: Using Nominal Data in Deep Learning
  id: totrans-24
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在深度学习中使用名义数据
- en: If we have a nominal value, say a set of colors, such as red, green, and blue,
    and we want to pass that value into a deep network, we need to change the data
    before we can use it. As we just saw, nominal data has no order, so while it’s
    tempting to assign a value of 1 to red, 2 to green, and 3 to blue, it would be
    wrong to do so, since the network will interpret those numbers as interval data.
    In that case, to the network, blue = 3(red), which is of course nonsense. If we
    want to use nominal data with a deep network, we need to alter it so that the
    interval is meaningful. We do this with *one-hot encoding*.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有一个名义值，比如一组颜色，像红色、绿色和蓝色，我们想将这些值传递到深度网络中，在使用之前我们需要先对数据进行转换。正如我们刚才看到的，名义数据是没有顺序的，所以虽然我们可能会想把红色赋值为1，绿色赋值为2，蓝色赋值为3，但这样做是错误的，因为网络会将这些数字解释为区间数据。在这种情况下，对网络来说，蓝色
    = 3（红色），这显然是无意义的。如果我们想将名义数据与深度网络一起使用，我们需要改变它，使得区间具有实际意义。我们通过*独热编码*来实现这一点。
- en: 'In one-hot encoding, we turn the single nominal variable into a vector, where
    each element of the vector corresponds to one of the nominal values. For the color
    example, the one nominal variable becomes a three-element vector with one element
    representing red, another green, and the last blue. Then, we set the value corresponding
    to the color to one and all the others to zero, like so:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在独热编码中，我们将单一的名义变量转化为一个向量，其中向量的每个元素对应于一个名义值。以颜色为例，单一的名义变量变成了一个三元素向量，一个元素代表红色，另一个代表绿色，最后一个代表蓝色。然后，我们将与颜色对应的值设置为1，其它值设置为0，如下所示：
- en: '| **Value** |  | **Vector** |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| **值** |  | **向量** |'
- en: '| --- | --- | --- |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| red | → | 1 0 0 |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 红色 | → | 1 0 0 |'
- en: '| green | → | 0 1 0 |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| 绿色 | → | 0 1 0 |'
- en: '| blue | → | 0 0 1 |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 蓝色 | → | 0 0 1 |'
- en: Now the vector values are meaningful because either it’s red (1) or it’s not
    (0), green (1) or it’s not (0), or blue (1) or it’s not (0). The interval between
    zero and one has mathematical meaning because the presence of the value, say red,
    is genuinely greater than its absence, and that works the same way for each color.
    The values are now interval, so the network can use them. In some toolkits, like
    Keras, class labels are one-hot encoded before passing them to the model. This
    is done so vector output operates nicely with the one-hot encoded class label
    when computing the loss function.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，向量值变得有意义，因为它要么是红色（1），要么不是（0），要么是绿色（1），要么不是（0），要么是蓝色（1），要么不是（0）。零和一之间的区间具有数学意义，因为某个值的存在，比如红色，确实比它的缺失要“大”，对于每种颜色都一样。现在，这些值是区间型数据，网络可以使用它们。在一些工具包中，如Keras，类标签在传递给模型之前会进行独热编码。这样做是为了确保向量输出能够与独热编码后的类标签在计算损失函数时良好地配合。
- en: Summary Statistics
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 汇总统计
- en: We’re given a dataset. How do we make sense of it? How should we characterize
    it to understand it better before we use it to build a model?
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了一份数据集。我们该如何理解它呢？在使用它来构建模型之前，我们应该如何描述它，以便更好地理解它？
- en: To answer these questions, we need to learn about *summary statistics*. Calculating
    summary statistics should be the first thing you do when handed a new dataset.
    Not looking at your dataset before building a model is like buying a used car
    without checking the tires, taking it for a test drive, and looking under the
    hood.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回答这些问题，我们需要了解*汇总统计*。计算汇总统计应该是你拿到新数据集后的第一件事。没有在构建模型之前查看数据集，就像买了一辆二手车，却没有检查轮胎，试驾一圈，也没看引擎盖下的情况。
- en: 'People have different notions of what makes a good set of summary statistics.
    We’ll focus on the following: means; the median; and measures of variation, including
    variance, standard deviation, and standard error. The range and mode are also
    often mentioned. The *range* is the difference between the maximum and minimum
    of the dataset. The *mode* is the most frequent value in the dataset. We generally
    get a sense of the mode visually from the histogram, as the histogram shows us
    the shape of the distribution of the data.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的人对什么构成良好的汇总统计有不同的看法。我们将重点关注以下几项：均值；中位数；以及变异性度量，包括方差、标准差和标准误差。数据集的范围和众数也是常被提及的。*范围*是数据集中最大值和最小值之间的差异。*众数*是数据集中最频繁出现的值。我们通常通过直方图来视觉上感知众数，因为直方图展示了数据分布的形态。
- en: Means and Median
  id: totrans-37
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 均值与中位数
- en: 'Most of us learned how to calculate the average of a set of numbers in elementary
    school: add the numbers and divide by how many there are. This is the *arithmetic
    mean*, or, more specifically, the *unweighted* arithmetic mean. If the dataset
    consists of a set of values, *{x[0]*, *x*[1], *x*[2], . . . , *x[n–1]*}, then
    the arithmetic mean is the sum of the data divided by the number of elements in
    the dataset (*n*). Notationally, we write this as the following.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/04equ01.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
- en: The ![image](Images/xbar.jpg) is the typical way to denote the mean of a sample.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: '[Equation 4.1](ch04.xhtml#ch04equ01) calculates the unweighted mean. Each value
    is given a weight of 1/*n*, where the sum of all the weights is 1.0\. Sometimes,
    we might want to weight elements of the dataset differently; in other words, not
    all of them should count equally. In that case, we calculate a weighted mean,'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/071equ01.jpg)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
- en: where *w[i]* is the weight given to *x[i]* and Σ*[i]w[i]* = 1\. The weights
    are not part of the dataset; they need to come from somewhere else. The grade
    point average (GPA) used by many universities is an example of a weighted mean.
    The grade for each course is multiplied by the number of course credits, and the
    sum is divided by the total number of credits. Algebraically, this is equivalent
    to multiplying each grade by a weight, *w[i]* = *c[i]*/Σ*[i]**c[i]*, with *c[i]*
    the number of credits for course *i* and Σ*[i]**c[i]* the total number of credits
    for the semester.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: Geometric Mean
  id: totrans-44
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The arithmetic mean is by far the most commonly used mean. However, there are
    others. The *geometric mean* of two positive numbers, *a* and *b*, is the square
    root of their product:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/071equ02.jpg)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
- en: 'In general, the geometric mean of *n* positive numbers is the *n*th root of
    their product:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/071equ03.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
- en: The geometric mean is used in finance to calculate average growth rates. In
    image processing, the geometric mean can be used as a filter to help reduce image
    noise. In deep learning, the geometric mean appears in the *Matthews correlation
    coefficient (MCC)*, one of the metrics we use to evaluate deep learning models.
    The MCC is the geometric mean of two other metrics, the informedness and the markedness.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: Harmonic Mean
  id: totrans-50
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The *harmonic mean* of two numbers, *a* and *b*, is the reciprocal of the arithmetic
    mean of their reciprocals:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/071equ04.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
- en: In general,
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/072equ01.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
- en: 'The harmonic mean shows up in deep learning as the F1 score. This is a frequently
    used metric for evaluating classifiers. The F1 score is the harmonic mean of the
    recall (sensitivity) and the precision:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/072equ02.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
- en: 'Despite its frequent use, it’s not a good idea to use the F1 score to evaluate
    a deep learning model. To see this, consider the definitions of recall and precision:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/072equ03.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
- en: Here, TP is the number of true positives, FN is the number of false negatives,
    and FP is the number of false positives. These values come from the test set used
    to evaluate the model. A fourth number that’s important for classifiers, TN, is
    the number of correctly classified true negatives (assuming a binary classifier).
    The F1 score ignores TN, but to understand how well the model performs, we need
    to consider both positive and negative classifications. Therefore, the F1 score
    is misleading and often too optimistic. Better metrics are the MCC mentioned above
    or Cohen’s κ (kappa), which is similar to MCC and usually tracks it closely.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，TP 是真正阳性（True Positive）的数量，FN 是假阴性（False Negative）的数量，FP 是假阳性（False Positive）的数量。这些值来自于用于评估模型的测试集。分类器的第四个重要数字是
    TN，即真正阴性（True Negative）的数量（假设为二分类器）。F1 分数忽略 TN，但为了了解模型的表现，我们需要考虑正类和负类的分类。因此，F1
    分数具有误导性，通常过于乐观。更好的度量标准是上面提到的 MCC 或 Cohen’s κ（Kappa），它与 MCC 相似，通常会紧密跟踪其变化。
- en: Median
  id: totrans-60
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 中位数
- en: 'Before moving on to measures of variation, there’s one more commonly used summary
    statistic we’ll mention here. It’ll show up again a little later in the chapter
    too. The *median* of a dataset is the middle value. It’s the value where, when
    the dataset is sorted numerically, half the values are below it and half are above
    it. Let’s use this dataset:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续讨论变异度量之前，还有一个常用的总结性统计量我们在这里提到。它稍后会在本章中再次出现。数据集的*中位数*是中间值。它是数据按数值排序后，数据集一半的值位于它之下，一半的值位于它之上的那个值。我们使用这个数据集：
- en: '*X* = {55,63,65,37,74,71,73,87,69,44}'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '*X* = {55,63,65,37,74,71,73,87,69,44}'
- en: If we sort *X*, we get
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们对 *X* 进行排序，我们得到
- en: '{37, 44, 55, 63, 65, 69, 71, 73, 74, 87}'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '{37, 44, 55, 63, 65, 69, 71, 73, 74, 87}'
- en: We immediately see a potential problem. I said we need the middle value when
    the data is sorted. With 10 things in *X*, there is no middle value. The middle
    lies between 65 and 69\. When the number of elements in the data-set is even,
    the median is the arithmetic mean of the two middle numbers. Therefore, the median
    in this case is
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们立刻看到一个潜在问题。我说过，我们需要在数据排序后得到中间值。对于 *X* 中的10个数据，没有真正的中间值。中间值位于65和69之间。当数据集中的元素数量是偶数时，中位数是两个中间数字的算术平均值。因此，在这种情况下，中位数是
- en: '![image](Images/073equ01.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/073equ01.jpg)'
- en: The arithmetic mean of the data is 63.8\. What’s the difference between the
    mean and the median?
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的算术平均值是63.8。均值和中位数之间有什么区别？
- en: By design, the median tells us the value that splits the dataset, so the number
    of samples above equals the number below. It’s the number of samples that matters.
    For the mean, it’s a sum over the actual data values. Therefore, the mean is sensitive
    to the values themselves, while the median is sensitive to the ordering of the
    values.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 从设计上看，中位数告诉我们将数据集分开的值，使得位于其上的样本数等于位于其下的样本数。重要的是样本的数量。对于均值，它是所有数据值的总和。因此，均值对值本身敏感，而中位数则对值的排序敏感。
- en: If we look at *X*, we see that most values are in the 60s and 70s, with one
    low value of 37\. It’s the low value of 37 that drags the mean down relative to
    the median. An excellent example of this effect is income. The current median
    annual family income in the United States is about $62,000\. A recent measure
    of the mean family income in the United States is closer to $72,000\. The difference
    is because of the small portion of the population who make significantly more
    money than everyone else. They pull the overall mean up. For income, then, the
    most meaningful statistic is the median.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们观察 *X*，会看到大多数值位于60到70之间，只有一个较低的值37。正是这个低值37使得均值相对于中位数较低。收入就是这种效应的一个典型例子。美国当前的家庭年收入中位数大约是62,000美元。最近的美国家庭收入均值接近72,000美元。二者之间的差异是因为少部分人群的收入远高于其他人，他们把整体均值拉高了。因此，对于收入而言，最有意义的统计量是中位数。
- en: Consider [Figure 4-2](ch04.xhtml#ch04fig02).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考 [图 4-2](ch04.xhtml#ch04fig02)。
- en: '![image](Images/04fig02.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/04fig02.jpg)'
- en: '*Figure 4-2: The mean (solid) and median (dashed) plotted over the histogram
    of a sample dataset*'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 4-2：均值（实线）和中位数（虚线）在样本数据集直方图上的绘制*'
- en: '[Figure 4-2](ch04.xhtml#ch04fig02) shows the histogram generated from 1,000
    samples of a simulated dataset. Also plotted are the mean (solid line) and median
    (dashed line). The two do not match; the long tail in the histogram drags the
    mean up. If we were to count, 500 samples would fall in the bins below the dashed
    line and 500 in the bins above.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 4-2](ch04.xhtml#ch04fig02)展示了从1,000个模拟数据样本生成的直方图。图中还标出了均值（实线）和中位数（虚线）。两者并不重合；直方图中的长尾将均值拉高。如果我们进行计数，会发现500个样本落在虚线以下的区间，500个样本则落在虚线以上的区间。'
- en: Are there times when the mean and median are the same? Yes. If the data distribution
    is completely symmetric, then the mean and median will be the same. The classic
    example of this situation is the normal distribution. [Figure 3-4](ch03.xhtml#ch03fig04)
    showed a normal distribution where the left-right symmetry was clear. The normal
    distribution is special. We’ll see it again throughout the chapter. For now, remember
    that the closer the distribution of the dataset is to a normal distribution, the
    closer the mean and median will be.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 有没有可能均值和中位数相同的情况？有的。如果数据的分布完全对称，那么均值和中位数将会相同。一个经典的例子就是正态分布。[图 3-4](ch03.xhtml#ch03fig04)展示了一个正态分布，左右对称性非常明显。正态分布是特别的，我们将在本章中再次遇到它。现在要记住的是，数据集的分布越接近正态分布，均值和中位数就越接近。
- en: 'The opposite is also worth remembering: if the dataset’s distribution is far
    from normal, like in [Figure 4-2](ch04.xhtml#ch04fig02), then the median is likely
    the better statistic to consider when summarizing the data.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个值得记住的情况是：如果数据集的分布与正态分布相差较远，如[图 4-2](ch04.xhtml#ch04fig02)所示，那么中位数可能是更好的统计量，适合用来总结数据。
- en: Measures of Variation
  id: totrans-76
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 变异度的度量
- en: A beginning archer shoots 10 arrows at a target. Eight of the beginner’s arrows
    hit the target, two miss completely, and the eight that do hit the target are
    spread uniformly across it. An expert archer shoots 10 arrows at a target. All
    of the expert’s arrows hit within a few centimeters of the center. Think about
    the mean position of the arrows. For the expert, all of the arrows are near the
    center of the target, so we can see that the mean position of the arrows will
    be near the center. For the beginner, none of the arrows are near the center of
    the target, but they are scattered more or less equally to the left and right
    or above and below the center. Because of this, the average position will balance
    out and be near the center of the target as well.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 一名初学者射手向目标射击了10支箭。初学者的8支箭击中了目标，2支箭完全偏离，且那8支命中的箭均匀分布在目标上。另一位专家射手向目标射击了10支箭，所有箭都射中了距离中心几厘米以内的区域。想一想这些箭的均值位置。对于专家射手，所有的箭都集中在目标中心附近，因此均值位置也会靠近中心。对于初学者，虽然没有箭射中目标中心，但它们大致均匀分布在目标的左右或上下。由于这个原因，平均位置将会平衡，并接近目标的中心。
- en: However, the first archer’s arrows are scattered; their location varies greatly.
    The second archer’s arrows, on the other hand, are tightly clustered, and there
    is little variation in their position. One meaningful way to summarize and understand
    a dataset is to quantify its variation. Let’s see how we might do this.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，第一位射手的箭散布得较广，它们的位置变化很大。另一方面，第二位射手的箭聚集得很紧，位置变化很小。总结和理解数据集的一种有意义的方法是量化它的变化。让我们看看如何实现这一点。
- en: Deviation vs. Variance
  id: totrans-79
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 偏差与方差
- en: One way we might measure the variation of a dataset is to find the *range*,
    the difference between the largest and smallest values. However, the range is
    a crude measurement, as it pays no attention to most of the values in the dataset,
    only the extremes. We can do better by calculating the mean of the difference
    between the data values and the mean of the data. The formula is
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们衡量数据集变化的一种方法是找出*极差*，即最大值和最小值之间的差异。然而，极差是一个粗略的度量，因为它忽略了数据集中的大多数值，仅关注极端值。我们可以通过计算数据值与数据均值之间差异的平均值来做得更好。公式如下：
- en: '![image](Images/04equ02.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/04equ02.jpg)'
- en: '[Equation 4.2](ch04.xhtml#ch04equ02) is the *mean deviation*. It’s a natural
    measure and gives just what we want: an idea of how far, on average, each sample
    is from the mean. While there’s nothing wrong with calculating the mean deviation,
    you’ll find that it’s rarely used in practice. One reason has to do with algebra
    and calculus. The absolute value is annoying to deal with mathematically.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead of the natural measure of variation, let’s calculate this one using
    squared differences:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/04equ03.jpg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
- en: '[Equation 4.3](ch04.xhtml#ch04equ03) is known as the *biased sample variance*.
    It’s the mean of the squared difference between each value in the dataset and
    the mean. It’s an alternate way of characterizing the scatter in the dataset.
    Why it’s biased, we’ll discuss in a second. We’ll get into why it’s ![image](Images/ssub-bar.jpg)
    and not *s[n]* shortly after that.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we do, it’s worth noting that you’ll often see a slightly different
    equation:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/04equ04.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
- en: This equation is the *unbiased sample variance*. Using *n* – 1 in place of *n*
    is known as Bessel’s correction. It’s related to the number of degrees of freedom
    in the residuals, where the residuals are what’s left when the mean is subtracted
    from each of the values in the dataset. The sum of the residuals is zero, so if
    there are *n* values in the dataset, knowing *n* – 1 of the residuals allows the
    last residual to be calculated. This gives us the degrees of freedom for the residuals.
    We are “free” to calculate *n* – 1 of them knowing that we’ll get the last one
    from the fact that the residuals sum to zero. Dividing by *n*–1 gives a less biased
    estimate of the variance, assuming ![image](Images/ssub-bar.jpg) is biased in
    some way to begin with.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: Why are we talking about biased variance and unbiased variance? Biased how?
    We should always remember that a dataset is a sample from some parent data-generating
    process, the population. The true population variance (σ²) is the scatter of the
    population around the true population mean (μ). However, we don’t know μ or σ²,
    so instead, we estimate them from the dataset we do have. The mean of the sample
    is ![image](Images/xbar.jpg). That’s our estimate for μ. It’s then natural to
    calculate the mean of the squared deviations around ![image](Images/xbar.jpg)
    and call that our estimate for σ². That’s ![image](Images/ssub-bar.jpg) ([Equation
    4.3](ch04.xhtml#ch04equ03)). The claim, which is true but beyond our scope to
    demonstrate, is that ![image](Images/ssub-bar.jpg) is biased and not the best
    estimate of σ², but if Bessel’s correction is applied, we’ll have a better estimate
    of the population variance. So we should use *s*² ([Equation 4.4](ch04.xhtml#ch04equ04))
    to characterize the variance of the dataset around the mean.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: In summary, we should use ![image](Images/xbar.jpg) and *s*² to quantify the
    variance of the data-set. Now, why is it *s*²? The square root of the variance
    is the *standard deviation* denoted as σ for the population and *s* for the estimate
    of σ calculated from the dataset. Most often, we want to work with the standard
    deviation. Writing square roots becomes tiresome, so convention has adopted the
    σ or *s* notation for the standard deviation and uses the squared form when discussing
    the variance.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，我们应该使用![image](Images/xbar.jpg)和 *s*² 来量化数据集的方差。那么，为什么是 *s*² 呢？方差的平方根是
    *标准差*，对于总体来说用σ表示，针对从数据集中计算出的σ估计值用 *s* 表示。我们通常需要处理的是标准差。写平方根会很麻烦，因此约定俗成地用σ或 *s*
    表示标准差，讨论方差时则使用其平方形式。
- en: And, because life isn’t already ambiguous enough, you’ll often see σ used for
    *s*, and [Equation 4.3](ch04.xhtml#ch04equ03) used when it really should be [Equation
    4.4](ch04.xhtml#ch04equ04). Some toolkits, including our beloved NumPy, make it
    easy to use the wrong formula.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 而且，由于生活本身已经足够模糊，你经常会看到σ被用作 *s*，以及[方程式4.3](ch04.xhtml#ch04equ03)被使用，而实际上它应该使用[方程式4.4](ch04.xhtml#ch04equ04)。一些工具包，包括我们亲爱的NumPy，便于使用错误的公式。
- en: 'However, as the number of samples in our dataset increases, the difference
    between the biased and unbiased variance decreases because dividing by *n* or
    *n* – 1 matters less and less. A few lines of code illustrate this:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，随着数据集中样本数量的增加，偏差方差和无偏方差之间的差异逐渐减小，因为除以 *n* 或 *n* – 1 的影响变得越来越小。以下几行代码展示了这一点：
- en: '[PRE0]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Here, a sample with only 10 values (`a`) shows a difference in the biased and
    unbiased variance in the third decimal. If we increase our dataset size from 10
    to 10,000, we get
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，一个只有10个值的样本（`a`）显示了偏差方差和无偏方差在第三位小数上的差异。如果我们将数据集的大小从10增加到10,000，我们会得到
- en: '[PRE1]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The difference between the biased and unbiased estimate of the variance is now
    in the fifth decimal. Therefore, for the large datasets we typically work with
    in deep learning, it matters little in practice whether we use *s[n]* or *s* for
    the standard deviation.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，偏差方差和无偏方差估计之间的差异已经在第五位小数。因此，对于我们通常在深度学习中使用的大数据集来说，实际上无论是使用 *s[n]* 还是 *s*
    作为标准差都没多大区别。
- en: '**MEDIAN ABSOLUTE DEVIATION**'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '**中位数绝对偏差**'
- en: 'The standard deviation is based on the mean. The mean, as we saw above, is
    sensitive to extreme values, and the standard deviation is doubly so because we
    square the deviation from the mean for each sample. A measure of variability that
    is insensitive to extreme values in the dataset is the *median absolute deviation
    (MAD)*. The MAD is defined as the median of the absolute values of the difference
    between the data and the median:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 标准差基于均值。如上所述，均值对极端值敏感，而标准差更为敏感，因为我们对每个样本的偏差进行平方处理。一个对数据集中极端值不敏感的变异性度量是 *中位数绝对偏差（MAD）*。MAD定义为数据与中位数之间差异的绝对值的中位数：
- en: MAD = median(|*X[i]* – median(*X*)|)
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: MAD = 中位数(|*X[i]* – 中位数(*X*)|)
- en: 'Procedurally, first calculate the median of the data, then subtract it from
    each data value, making the result positive, and report the median of that set.
    The implementation is straightforward:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 按步骤操作，首先计算数据的中位数，然后将其从每个数据值中减去，使结果为正，并报告该数据集的中位数。实现方法非常直接：
- en: '[PRE2]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The MAD is not often used, but its insensitivity to extreme values in the dataset
    argues toward more frequent use, especially for outlier detection.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: MAD不常使用，但它对数据集中极端值的不敏感使得它在异常值检测中具有更频繁使用的价值。
- en: Standard Error vs. Standard Deviation
  id: totrans-103
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 标准误差与标准差
- en: 'We have one more measure of variance to discuss: the *standard error of the
    mean (SEM)*. The SEM is often simply called the *standard error (SE)*. We need
    to go back to the population to understand what the SE is and when to use it.
    If we select a sample from the population, a dataset, we can calculate the mean
    of the sample, ![image](Images/xbar.jpg). If we choose repeated samples and calculate
    those sample means, we’ll generate a dataset of means of the samples from the
    population. This might sound familiar; it’s the process we used to illustrate
    the central limit theorem in [Chapter 3](ch03.xhtml#ch03). The standard deviation
    of the set of means is the standard error.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还有一个方差的度量需要讨论：*均值的标准误差（SEM）*。SEM通常简称为*标准误差（SE）*。为了理解SE是什么以及何时使用它，我们需要回到总体。如果我们从总体中选择一个样本，一个数据集，我们可以计算该样本的均值，
    ![image](Images/xbar.jpg)。如果我们选择多个样本并计算这些样本的均值，我们将生成一个包含来自总体样本均值的数据集。这听起来可能有些熟悉；它就是我们在[第3章](ch03.xhtml#ch03)中用来说明中心极限定理的过程。均值集合的标准差就是标准误差。
- en: The formula for the standard error from the standard deviation is straightforward,
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/077equ01.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
- en: and is nothing more than a scaling of the sample standard deviation by the square
    root of the number of samples.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: When should we use the standard deviation, and when should we use the standard
    error? Use the standard deviation to learn about the distribution of the samples
    around the mean. Use the standard error to say something about how good an estimate
    of the population mean a sample mean is. In a sense, the standard error is related
    to both the central limit theorem, as that affects the standard deviation of the
    means of multiple samples from the parent population, and the law of large numbers,
    since a larger dataset is more likely to give a better estimate of the population
    mean.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: From a deep learning point of view, we might use the standard deviation to describe
    the dataset used to train a model. If we train and test several models, remembering
    the stochastic nature of deep network initialization, we can calculate a mean
    over the models for some metric, say the accuracy. In that case, we might want
    to report the mean accuracy plus or minus the standard error. As we train more
    models and gain confidence that the mean accuracy represents the sort of accuracy
    the model architecture can provide, we should expect that the error in the mean
    accuracy over the models will decrease.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: To recap, in this section, we discussed different summary statistics, values
    we can use to start to understand a dataset. These include the various means (arithmetic,
    geometric, and harmonic), the median, the standard deviation, and, when appropriate,
    the standard error. For now, let’s see how we can use plots to help understand
    a dataset.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: Quantiles and Box Plots
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To calculate the median, we need to find the middle value, the number splitting
    the dataset into two halves. Mathematically, we say that the median divides the
    dataset into two quantiles.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: A *quantile* splits the dataset into fixed-sized groups where the fixed size
    is the number of data values in the quantile. Since the median splits the dataset
    into two equally sized groups, it’s a *2-quantile*. Sometimes you’ll see the median
    referred to as the *50th percentile*, meaning 50 percent of the data values are
    less than this value. By similar reasoning, then, the 95th percentile is the value
    that 95 percent of the dataset is less than. Researchers often calculate 4-quantiles
    and refer to them as *quartiles*, since they split the dataset into four groups
    such that 25 percent of the data values are in the first quartile, 50 percent
    are in the first and second, and 75 percent are in the first, second, and third,
    with the final 25 percent in the fourth quartile.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s work through an example to understand what we mean by quantiles. The
    example uses a synthetic exam dataset representing 1,000 test scores. See the
    file *exams.npy*. We’ll use NumPy to calculate the quartile values for us and
    then plot a histogram of the dataset with the quartile values marked. First, let’s
    calculate the quartile positions:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This code, along with code to generate the plot, is in the file *quantiles.py*.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: First we load the synthetic exam data and keep the first exam scores (`p`).
    Note, we make `p` an integer array so we can use `np.bincount` later to make the
    histogram. (That code is not shown above.) We then use NumPy’s `np.quantile` function
    to calculate the quartile values. This function takes the source array and an
    array of quantile values in the range [0, 1]. The values are fractions of the
    distance from the minimum value of the array to its maximum. So, asking for the
    0.5 quantile is asking for the value that is half the distance between the minimum
    of `p` and its maximum such that the number of values in each set is equal.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: To get quartiles, we ask for the 0.25, 0.5, and 0.75 quantiles to get the values
    such that 25 percent, 50 percent, and 75 percent of the elements of `p` are less
    than the values. We also ask for the 0.0 and 1.0 quantiles, the minimum and maximum
    of `p`. We do this for convenience when we count the number of elements in each
    range. Note, we could have instead used the `np.percentile` function. It returns
    the same values as `np.quantile` but uses percentage values instead of fractions.
    In that case, the second argument would have been `[0,25,50,75,100]`.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: The returned quartile values are in `q`. We print them to get
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Here, 18 is the minimum, 100 is the maximum, and the three cutoff values for
    the quartiles are 56.75, 68, and 78\. Note that the cutoff for the second quartile
    is the median, 68.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: The remaining code counts the number of values in `p` in each range. With 1,000
    values, we’d expect to have 250 in each range, but because the math doesn’t always
    fall along existing data values, we get instead
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: meaning 250 elements of `p` are less than 56.75, 237 are in [56.75, 68], and
    so forth.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: The code above uses a clever counting trick worth explaining. We want to count
    the number of values in `p` in some range. We can’t use NumPy’s `np.where` function,
    as it doesn’t like the compound conditional statement. However, if we use an expression
    like `10 <= p`, we’ll be given an array the same size as `p` where each element
    is either `True` if the condition is true for that element or `False` if it is
    not. Therefore, asking for `10 <= p` and `p < 90` will return two Boolean arrays.
    To get the elements where both conditions are true, we need to logically AND them
    together (`&`). This gives us a final array the same size and shape as `p`, where
    all `True` elements represent values in `p` in [10, 90). To get the count, we
    apply the `sum` method that for a Boolean array treats `True` as one and `False`
    as zero.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 4-3](ch04.xhtml#ch04fig03) shows the histogram of the exam data with
    the quartiles marked.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/04fig03.jpg)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4-3: A histogram of 1,000 exam scores with the quartiles marked*'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: The example above shows yet again how useful a histogram is for visualizing
    and understanding data. We should use histograms whenever possible to help understand
    what’s going on with a dataset. [Figure 4-3](ch04.xhtml#ch04fig03) superimposes
    the quartile values on the histogram. This helps us understand what the quartiles
    are and their relationship to the data values, but this is not a typical presentation
    style. More typical, and useful because it can show multiple features of a dataset,
    is the *box plot*. Let’s use it now for the exam scores above, but this time we’ll
    also include the two other sets of exam scores we ignored previously.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: We’ll show a box plot first, and then explain it. To see the box plot for the
    three exams in the *exams.npy* file, use
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: where we’re loading the full set of exam scores and then using the Matplotlib
    `boxplot` function.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: Take a look at the output, shown in [Figure 4-4](ch04.xhtml#ch04fig04).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/04fig04.jpg)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4-4: Box plots for the three exams (top), and the box plot for the
    first exam with the components marked (bottom)*'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: The top chart in [Figure 4-4](ch04.xhtml#ch04fig04) shows the box plot for the
    three sets of exam scores in *|*exams.npy|. The first of these is plotted again
    on the bottom of [Figure 4-4](ch04.xhtml#ch04fig04), along with labels describing
    the parts of the plot.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: A box plot shows us a visual summary of the data. The box in the bottom chart
    in [Figure 4-4](ch04.xhtml#ch04fig04) illustrates the range between the cutoffs
    for the first quartile (Q1) and the third quartile (Q3). The numerical difference
    between Q3 and Q1 is known as the *interquartile range (IQR)*. The larger the
    IQR, the more spread out the data is around the median. Notice that the score
    is on the y-axis this time. We could have easily made the plot horizontal, but
    vertical is the default. The median (Q2) is marked near the middle of the box.
    The mean is not shown in a box plot.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: The box plot includes two additional lines, the *whiskers*, though Matplotlib
    calls them *fliers*. As indicated, they are 1.5 times the IQR above Q3 or below
    Q1\. Finally, there are some circles labeled “possible outliers.” By convention,
    values outside of the whiskers are considered *possible outliers*, meaning they
    might represent erroneous data, either entered incorrectly by hand or, more likely
    these days, received from faulty sensors. For example, bright or dead pixels on
    a CCD camera might be considered outliers. When evaluating a potential dataset,
    we should be sensitive to outliers and use our best judgment about what to do
    with them. Usually, there are only a few, and we can drop the samples from the
    dataset without harm. However, it’s also possible that the outliers are actually
    real and are highly indicative of a particular class. If that’s the case, we want
    to keep them in the dataset in the hopes that the model will use them effectively.
    Experience, intuition, and common sense must guide us here.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s interpret the top chart in [Figure 4-4](ch04.xhtml#ch04fig04) showing
    the three sets of exam scores. The top of the whiskers is at 100 each time, which
    makes sense: a 100 is a perfect score, and there were 100s in the dataset. Notice
    that the box portion of the plot is not centered vertically in the whiskers. Recalling
    that 50 percent of the data values are between Q1 and Q3, with 25 percent above
    and below Q2 in the box, we see that the data is not rigorously normal; its distribution
    deviates from a normal curve. A glance back to the histogram in [Figure 4-3](ch04.xhtml#ch04fig03)
    confirms this for the first exam. Similarly, we see the second and third exams
    deviate from normality as well. So, a box plot can tell us how similar the distribution
    of the dataset is to a normal distribution. When we discuss hypothesis testing
    below, we’ll want to know if the data is normally distributed or not.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: What about possible outliers, the values below Q1 – 1.5 × IQR? We know the dataset
    represents test scores, so common sense tells us that these are not outliers but
    valid scores by particularly confused (or lazy) students. If the dataset contained
    values above 100 or below zero, those would be fair game to label outliers.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes dropping samples with outliers is the right thing to do. However,
    if the outlier is caused by missing data, cutting the sample might not be an option.
    Let’s take a look at what we might do with missing data, and why we should generally
    avoid it like the plague.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: Missing Data
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Missing data is just that, data we don’t have. If the dataset consists of samples
    representing feature vectors, missing data shows up as one or more features in
    a sample that were not measured for some reason. Often, missing data is encoded
    in some way. If the value is only positive, a missing feature might be marked
    with a –1 or, historically, –999\. If the feature is given to us as a string,
    the string might be empty. For floating-point values, a not a number (NaN) might
    be used. NumPy makes it easy for us to check for NaNs in an array by using `np.isnan`:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Notice that direct comparison to `np.nan` with either `==` or `is` doesn’t work;
    only testing with `np.isnan` works.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: Detecting missing data is dataset-specific. Assuming we’ve convinced ourselves
    there is missing data, how do we handle it?
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s generate a small dataset with missing values and use our existing statistics
    knowledge to see how to handle them. The code for the following is in `missing.py`.
    First, we generate a dataset of 1,000 samples, each with four features:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The dataset is in `x`. We fix the random number seed to get a reproducible result.
    The first feature is uniformly distributed. The second is normally distributed,
    while the third follows a beta distribution and the fourth a lognormal distribution.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: 'At the moment, `x` has no missing values. Let’s add some by making random elements
    NaNs:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The dataset now has NaNs across 5 percent of its values.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: If a few samples in a large dataset have missing data, we can remove them from
    the dataset with little worry. However, if 5 percent of the samples have missing
    data, we probably don’t want to lose that much data. More worrisome still, what
    if there’s a correlation between the missing data and a particular class? Throwing
    the samples away might bias the dataset in some way that’ll make the model less
    useful.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: So, what can we do? We just spent many pages learning how to summarize a dataset
    with basic descriptive statistics. Can we use those? Of course. We can look at
    the distributions of the features, ignoring the missing values, and use those
    distributions to decide how we might want to replace the missing data. Naively,
    we’d use the mean of the data we do have, but looking at the distribution may
    or may not push us toward the median instead, depending on how far the distribution
    is from normal. This sounds like a job for a box plot. Fortunately for us, Matplotlib’s
    `boxplot` function is smart; it ignores the NaNs. Therefore, making the box plot
    is a straightforward call to `boxplot(x)`.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 4-5](ch04.xhtml#ch04fig05) shows us the dataset with the NaNs ignored.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/04fig05.jpg)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4-5: Box plot of the dataset ignoring missing values*'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: The boxes in [Figure 4-5](ch04.xhtml#ch04fig05) make sense for the distributions
    of the features. Feature 1 is uniformly distributed, so we expect a symmetric
    box around the mean/median. (These are the same for the uniform distribution.)
    Feature 2 is normally distributed, so we get a similar box structure as Feature
    1, but, with only 1,000 samples, some asymmetry is evident. The beta distribution
    of Feature 3 is skewed toward the top of its range, which we see in the box plot.
    Finally, the lognormal distribution of Feature 4 should be skewed toward lower
    values, with a long tail visible as the many “outliers” above the whiskers, an
    object lesson against mindlessly calling such values outliers.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: 'Because we have features that are highly not normally distributed, we’ll update
    missing values with the median instead of the mean. The code is straightforward:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Here, `i` first holds the indices of Feature 1 that are not NaNs. We use these
    to calculate the median (`m`). Next, we set `i` to the indices that are NaNs and
    replace them with the median. We can do the same for the other features, updating
    the entire dataset so we no longer have missing values.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: 'Did we cause much of a change from the earlier distributions? No, because we
    only updated 5 percent of the values. For example, for Feature 3, based on the
    beta distribution, the mean and standard deviations change like so:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The moral of the story is that if there’s enough missing data that the dataset
    might become biased by dropping it, the safest thing to do is replace the missing
    data with the mean or median. To decide whether to use the mean or median, consult
    descriptive statistics, a box plot, or a histogram.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, if the dataset is labeled, as a deep learning dataset would be,
    the process described above needs to be completed with the mean or median of samples
    grouped by each class. Otherwise, the calculated value might be inappropriate
    for the class.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: With missing data eliminated, deep learning models can be trained on the dataset.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: Correlation
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: At times, there is an association between the features in a dataset. If one
    goes up, the other might go up as well, though not necessarily in a simple linear
    way. Or, the other might go down—a negative association. The proper word for this
    type of association is *correlation*. A statistic that measures correlation is
    a handy way to understand how the features in a dataset are related.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: For example, it isn’t hard to see that the pixels of most images are highly
    correlated. This means if we select a pixel at random and then an adjacent pixel,
    there’s a good chance the second pixel will be similar to the first pixel. Images
    where this is not true look to us like random noise.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: In traditional machine learning, highly correlated features were undesirable,
    as they didn’t add any new information and only served to confuse the models.
    The entire art of feature selection was developed, in part, to remove this effect.
    For modern deep learning, where the network itself learns a new representation
    of the input data, it’s less critical to have uncorrelated inputs. This is, in
    part, why images work as inputs to deep networks when they usually fail to work
    at all with older machine learning models.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: Whether the learning is traditional or modern, as part of summarizing and exploring
    a dataset, correlations among the features are worth examining and understanding.
    In this section, we’ll discuss two types of correlations. Each type returns a
    single number that measures the strength of the correlation between two features
    in the dataset.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: Pearson Correlation
  id: totrans-172
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The *Pearson correlation coefficient* returns a number, *r* ϵ [–1, +1], that
    indicates the strength of the *linear* correlation between two features. By *linear*
    we mean how strongly we can describe the correlation between the features by a
    line. If the correlation is such that one feature goes up exactly as the other
    feature goes up, the correlation coefficient is +1\. Conversely, if the second
    feature goes down exactly as the other goes up, the correlation is –1\. A correlation
    of zero means there is no association between the two features; they are (possibly)
    independent.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: I slipped the word *possibly* in the sentence above because there are situations
    where a nonlinear dependence between two features might lead to a zero Pearson
    correlation coefficient. These situations are not common, however, and for our
    purposes, we can claim a correlation coefficient near zero indicates the two features
    are independent. The closer the correlation coefficient is to zero, either positive
    or negative, the weaker the correlation between the features.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: The Pearson correlation is defined using the means of the two features or the
    means of products of the two features. The inputs are two features, two columns
    of the dataset. We’ll call these inputs *X* and *Y*, where the capital letter
    refers to a vector of data values. Note, since these are two features from the
    dataset, *X[i]* is paired with *Y[i]*, meaning they both come from the same feature
    vector.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: The formula for the Pearson correlation coefficient is
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/04equ05.jpg)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
- en: 'We’ve introduced a new, but commonly used, notation. The mean of *X* is the
    *expectation* of *X*, denoted as E(*X*). Therefore, in [Equation 4.5](ch04.xhtml#ch04equ05),
    we see the mean of *X*, E(*X*), and the mean of *Y*, E(*Y*). As we might suspect,
    E(*XY*) is the mean of the product of *X* and *Y*, element by element. Similarly,
    E(*X*²) is the mean of the product of *X* with itself, and E(*X*)² is the square
    of the mean of *X*. With this notation in hand, we can easily write our own function
    to calculate the Pearson correlation of two vectors of features:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The `pearson` function directly implements [Equation 4.5](ch04.xhtml#ch04equ05).
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: Let’s set up a scenario where we can use `pearson` and compare it to what NumPy
    and SciPy provide. The code that follows, including the definition of `pearson`
    above, is in the file *correlation.py*.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: First, we’ll create three correlated vectors, `x`, `y`, and `z`. We imagine
    that these are features from a dataset so that `x[0]` is paired with `y[0]` and
    `z[0]`. The code we need is
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Notice that we’re again fixing the NumPy pseudorandom seed to make the output
    reproducible. The first feature, `x`, is a noisy line from zero to one. The second,
    `y`, tracks `x` but is also noisy because of the multiplication by a random value
    in [0, 1). Finally, `z` is negatively correlated to `x` because of the –0.1 coefficient.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: The top chart in [Figure 4-6](ch04.xhtml#ch04fig06) plots the three feature
    values sequentially to see how they track each other. The bottom chart shows the
    three as paired points, with one value on the x-axis and the other on the y-axis.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/04fig06.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4-6: Three features in sequence to show how they track (top), and a
    scatter plot of the features as pairs (bottom)*'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: 'The NumPy function to calculate the Pearson correlation is `np.corrcoef`. Unlike
    our version, this function returns a matrix showing the correlations between all
    pairs of variables passed to it. For example, using our `pearson` function, we
    get the following as the correlation coefficients between `x`, `y`, and `z`:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'NumPy returns the following, with `x`, `y`, and `z` stacked as a single 3 ×
    100 array:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The diagonal corresponds to the correlation with each feature and itself, which
    is naturally perfect and therefore 1.0\. The correlation between `x` and `y` is
    in element 0,1 and matches our `pearson` function value. Similarly, the correlation
    between `x` and `z` is in element 0,2, and the correlation between `y` and `z`
    is in element 1,2\. Notice also that the matrix is symmetric, which we expect
    because corr(*X, Y*) = corr(*Y, X*).
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: SciPy’s correlation function is `stats.pearsonr`, which acts like ours but returns
    a *p*-value along with the *r* value. We’ll discuss *p*-values more later in the
    chapter. We use the returned *p*-value as the probability of an uncorrelated system
    producing the calculated correlation value. For our example features, the *p*-value
    is virtually identical to zero, implying there’s no reasonable likelihood that
    an uncorrelated system produced the features.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: 'We stated earlier that for images, nearby pixels are usually highly correlated.
    Let’s see if this is actually true for a sample image. We’ll use the China image
    included with `sklearn` and treat specific rows of the green band as the paired
    vectors. We’ll calculate the correlation coefficient for two adjacent rows, a
    row further away, and a random vector:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Comparing row 230 and row 231 shows that they are highly positively correlated.
    Comparing rows 230 and 400 shows a weaker and, in this case, negative correlation.
    Finally, as we might expect, correlation with a random vector gives a value approaching
    zero.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: The Pearson correlation coefficient is so widely used that you’ll often see
    it referred to as merely *the correlation coefficient*. Let’s now take a look
    at a second correlation function and see how it differs from the Pearson coefficient.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: Spearman Correlation
  id: totrans-198
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The second correlation measure we’ll explore is the *Spearman correlation coefficient*,
    ρ ϵ [–1, +1]. It’s a measure based on the ranks of the feature values instead
    of the values themselves.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: To rank *X*, we replace each value in *X* with the index to that value in the
    sorted version of *X*. If *X* is
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: then the ranks are
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: because when *X* is sorted, 86 goes in the eighth place (counting from zero),
    and 3 goes first.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: The Pearson correlation looks for a linear relationship, whereas the Spearman
    looks for any monotonic association between the inputs.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: If we have the ranks for the feature values, then the Spearman coefficient is
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/04equ06.jpg)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
- en: where *n* is the number of samples and *d* = rank(*X*) – rank(*Y*) is the difference
    of the rank of the paired *X* and *Y* values. Note how [Equation 4.6](ch04.xhtml#ch04equ06)
    is only valid if the rankings are unique (that is, there are no repeated values
    in *X* or *Y*).
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: To calculate *d* in [Equation 4.6](ch04.xhtml#ch04equ06), we need to rank *X*
    and *Y* and use the difference of the ranks. The Spearman correlation is the Pearson
    correlation of the ranks.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: 'The example above points the way to an implementation of the Spearman correlation:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: To get the ranks, we need to first sort *X* (`t`). Then, for each value in *X*
    (`x`), we find where it occurs in `t` via `np.where` and take the first element,
    the first match. After building the `rx` list, we make it a floating-point NumPy
    array. We do the same for *Y* to get `ry`. With the ranks, `d` is set to their
    difference, and [Equation 4.6](ch04.xhtml#ch04equ06) is used to return the Spearman
    ρ value.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: Please note that this version of the Spearman correlation is limited by [Equation
    4.6](ch04.xhtml#ch04equ06) and should be used when there are no duplicate values
    in *X* or *Y*. Our example in this section uses random floating-point values,
    so the probability of an exact duplicate is quite low.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll compare our `spearman` implementation to the SciPy version, `stats .spearmanr`.
    Like the SciPy version of the Pearson correlation, `stats.spearmanr` returns a
    *p*-value. We’ll ignore it. Let’s see how our function compares:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: We have complete agreement with the SciPy function out to the last bit or so
    of the floating-point value.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: 'It’s important to remember the fundamental difference between the Pearson and
    Spearman correlations. For example, consider the correlation between a linear
    ramp and the sigmoid function:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Here, `ramp` increases linearly from –20 to 20 and `sig` follows a sigmoid shape
    (“S” curve). The Pearson correlation will be on the high side, since both are
    increasing as *x* becomes more positive, but the association is not purely linear.
    Running the example gives
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: indicating a Pearson correlation of 0.9 but a perfect Spearman correlation of
    1.0, since for every increase in `ramp` there is an increase in `sig` and *only*
    an increase. The Spearman correlation has captured the nonlinear relationship
    between the arguments, while the Pearson correlation has only hinted at it. If
    we’re analyzing a dataset intended for a classical machine learning algorithm,
    the Spearman correlation might help us decide which features to keep and which
    to discard.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: This concludes our examination of statistics for describing and understanding
    data. Let’s now learn how to use hypothesis testing to interpret experimental
    results and answer questions like “Are these two sets of data samples from the
    same parent distribution?”
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: Hypothesis Testing
  id: totrans-223
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We have two independent sets of 50 students studying cell biology. We have no
    reason to believe the groups differ in any significant way, as students from the
    larger population were assigned randomly. Group 1 attended the lectures and, in
    addition, worked through a structured set of computer exercises. Group 2 only
    attended the lectures. Both groups took the same final examination, leading to
    the test scores given in [Table 4-1](ch04.xhtml#ch04tab01). We want to know if
    asking the students to work through the computer exercises made a difference in
    their final test scores.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 4-1:** Group 1 and Group 2 Test Scores'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: '| **Group 1** | 81 80 85 87 83 87 87 90 79 83 88 75 87 92 78 80 83 91 82 88
    89 92 97 82 79 82 82 85 89 91 83 85 77 81 90 87 82 84 86 79 84 85 90 84 90 85
    85 78 94 100 |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
- en: '| **Group 2** | 92 82 78 74 86 69 83 67 85 82 81 91 79 82 82 88 80 63 85 86
    77 94 85 75 77 89 86 71 82 82 80 88 72 91 90 92 95 87 71 83 94 90 78 60 76 88
    91 83 85 73 |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
- en: '[Figure 4-7](ch04.xhtml#ch04fig07) shows a box plot of [Table 4-1](ch04.xhtml#ch04tab01).'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: To understand if there is a significant change in final test scores between
    the two groups, we need to test some hypotheses. The method we’ll use to test
    the hypotheses is known as *hypothesis testing*, and it’s a critical piece of
    modern science.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/04fig07.jpg)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4-7: Box plot for the data in [Table 4-1](ch04.xhtml#ch04tab01)*'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: 'Hypothesis testing is a broad topic, too extensive for us to provide more than
    a minimal introduction here. As this is a book on deep learning, we’ll focus on
    the scenario a deep learning researcher is likely to encounter. We’ll consider
    only two hypothesis tests: the t-test for unpaired samples of differing variance
    (a parametric test) and the Mann-Whitney U (a nonparametric test). As we progress,
    we’ll understand what these tests are and why we’re restricting ourselves to them,
    as well as the meaning of *parametric* and *nonparametric*.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: To be successful with hypothesis testing, we need to know what we mean by *hypothesis*,
    so we’ll address that first, along with our rationale for limiting the types of
    hypothesis testing we’ll consider. With the hypothesis concept in hand, we’ll
    discuss the t-test and the Mann-Whitney U test in turn, using the data in [Table
    4-1](ch04.xhtml#ch04tab01) as our example. Let’s get started.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: Hypotheses
  id: totrans-234
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To understand if two sets of data are from the same parent distribution or not,
    we might look at summary statistics. [Figure 4-7](ch04.xhtml#ch04fig07) shows
    us the box plot for Group 1 and Group 2\. It appears that the two groups have
    different means and standard deviations. How do we know? The box plot shows us
    the location of the medians, and the whiskers tell us something about the variance.
    Both of these together hint that the means will be different because the medians
    are different, and both sets of data are reasonably symmetric around the median.
    The space between the whiskers hints at the standard deviation. So, let’s make
    hypotheses using the means of the datasets.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: In hypothesis testing, we have two hypotheses. The first, known as the *null
    hypothesis* (*H*[0]), is that the two sets of data *are* from the same parent
    distribution, that there is nothing special to differentiate them. The second
    hypothesis, the *alternative hypothesis* (*H[a]*), is that the two groups are
    not from the same distribution. Since we’ll be using the means, *H*[0] is saying
    that the means, really the means of the parent population that generated the data,
    are the same. Similarly, if we reject *H*[0], we are implicitly accepting *H[a]*
    and claiming we have evidence that the means are different. We don’t have the
    true population means, so we’ll use the sample means and standard deviations instead.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: Hypothesis testing doesn’t tell us definitively whether *H*[0] is true. Instead,
    it gives us evidence in favor of rejecting or accepting the null hypothesis. It’s
    critical to remember this.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: We’re testing two independent samples to see if we should think of them as coming
    from the same parent distribution. There are other ways to use hypothesis testing,
    but we rarely encounter them in deep learning. For the task at hand, we need the
    sample means and the sample standard deviations. Our tests will ask the question,
    “Is there a meaningful difference in the means of these two sets?”
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: We’re only interested in detecting whether the two groups of data are from the
    same parent distribution, so another simplification we’ll make is that all of
    our tests will be *two-sided*, or *two-tailed*. When we use a test, like the t-test
    we’ll describe next, we’re comparing our calculated test statistic (the t-value)
    to the distribution of the test statistic and asking questions about how likely
    our calculated t-value is. If we want to know about the test statistic being above
    or below some fraction of that distribution, we’re making a two-sided test. If
    instead we want to know about the likelihood of the test statistic being above
    a particular value without caring about it being below, or vice versa, then we’re
    making a one-sided test.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s lay out our assumptions and approach:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: We have two independent sets of data we wish to compare.
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We’re making no assumption as to whether the standard deviations of the data
    are the same.
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Our null hypothesis is that the means of the parent distributions of the datasets
    are the same, *H*[0] : μ[1] = μ[2]. We’ll use the sample means ![image](Images/094equ01a.jpg)
    and sample standard deviations (*s*[1], *s*[2]) to help us decide to accept or
    reject *H*[0].'
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Hypothesis tests assume that the data is *independent and identically distributed
    (i.i.d.)*. We interpret this as a statement that the data is a fair random sample.
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: With these assumptions understood, let’s start with the t-test, the most widely
    used hypothesis test.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: The t-test
  id: totrans-246
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The *t-test* depends on *t*, the test statistic. This statistic is compared
    to the t-distribution and used to generate a *p*-value, a probability we’ll use
    to reach a conclusion about *H*[0]. There’s a rich history behind the t-test and
    the related z-test that we’ll ignore here. I encourage you to dive more deeply
    into hypothesis testing when you have the chance or, at a minimum, review thoughtful
    articles about the proper way to do a hypothesis test and interpret its results.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: The t-test is a *parametric* test. This means there are assumptions about the
    data and the distribution of the data. Specifically, the t-test assumes, beyond
    the data being i.i.d., that the distribution (histogram) of the data is normal.
    We’ve stated before that many physical processes do seem to follow a normal distribution,
    so there’s reason to think that data from actual measurements might do so.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: There are many ways to test if a dataset is normally distributed, but we’ll
    ignore them, as there’s some debate about the utility of such tests. Instead,
    I’ll (somewhat recklessly) suggest you use the t-test and the Mann-Whitney U test
    together to help make your decision about accepting or rejecting *H*[0]. Using
    both tests might lead to a situation where they disagree, where one test says
    there’s evidence against the null hypothesis and the other says there isn’t. In
    general, if the nonparametric test is claiming evidence against *H*[0], then one
    should probably accept that evidence regardless of the t-test result. If the t-test
    result is against *H*[0], but the Mann-Whitney U test isn’t, and you think the
    data is normal, then you might also accept the t-test result.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: The t-test has different versions. We explicitly stated above that we’ll use
    a version designed for datasets of differing size and variance. The specific version
    of the t-test we’ll use is *Welch’s t-test*, which doesn’t assume the variance
    of the two datasets is the same.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: The t-score for Welch’s t-test is
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/095equ01.jpg)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
- en: where *n*[1] and *n*[2] are the size of the two groups.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: The t-score, and an associated value known as the *degrees of freedom*, which
    is similar to but also different from the degrees of freedom mentioned above,
    generates the appropriate t-distribution curve. To get a *p*-value, we calculate
    the area under the curve, both above and below (positive and negative t-score),
    and return it. Since the integral of a probability distribution is 1, the total
    area under the tails from the positive and negative t-score value to positive
    and negative infinity will be the *p*-value. We’ll use the degrees of freedom
    below to help us calculate confidence intervals.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: What does the *p*-value tell us? It tells us the probability of seeing the difference
    between the two means we see, or larger, *if* the null hypothesis is true. Typically,
    if this probability is below some threshold we’ve chosen, we reject the null hypothesis
    and say we have evidence that the two groups have different means—that they come
    from different parent distributions. When we reject *H*[0], we say that the difference
    is *statistically significant*. The threshold for accepting/rejecting *H*[0] is
    called α, usually with α = 0.05 as a typical, if problematic, value. We’ll discuss
    why 0.05 is problematic below.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: 'The point to remember is that the *p*-value assumes the null hypothesis is
    true. It tells us the likelihood of a true *H*[0] giving us at least the difference
    we see, or greater, between the groups. If the *p*-value is small, that has two
    possible meanings: (1) the null hypothesis is false, or (2) a random sampling
    error has given us samples that fall outside what we might expect. Since the *p*-value
    assumes *H*[0] is true, a small *p*-value helps us believe less and less in (2)
    and boosts our confidence that (1) might be correct. However, the *p*-value alone
    cannot confirm (1); other knowledge needs to come into play.'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: 'I mentioned that using α = 0.05 is problematic. The main reason it’s problematic
    is that it’s too generous; it leads to too many rejections of a true null hypothesis.
    According to James Berger and Thomas Sellke in their article “Testing a Point
    Null Hypothesis: The Irreconcilability of *P* Values and Evidence” (*Journal of
    the American Statistical Association*, 1987), when α = 0.05, about 30 percent
    of true null hypotheses will be rejected. When we use something like α ≤ 0.001,
    the chance of falsely rejecting a true null hypothesis goes down to less than
    3 percent. The moral of the story is that *p* < 0.05 is not magic and, frankly,
    is unconvincing for a single study. Look for highly significant *p*-values of
    at least 0.001 or, preferably, much smaller. At *p*  = 0.05, all you have is a
    suggestion, and you should repeat the experiment. If repeated experiments all
    have a *p*-value around 0.05, then rejecting the null hypothesis begins to make
    sense.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: Confidence Intervals
  id: totrans-258
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Along with a *p*-value, you’ll often see *confidence intervals (CIs)*. The confidence
    interval gives bounds within which we believe the true population difference in
    the means will lie, with a given confidence for repeated samples of the two datasets
    we’re comparing. Typically, we report 95 percent confidence intervals. Our hypothesis
    tests check for equality of means by asking if the difference of the sample means
    is zero or not. Therefore, any CI that includes zero signals to us that we cannot
    reject the null hypothesis.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: For Welch’s t-test, the degrees of freedom is
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/04equ07.jpg)'
  id: totrans-261
  prefs: []
  type: TYPE_IMG
- en: which we can use to calculate confidence intervals,
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/04equ08.jpg)'
  id: totrans-263
  prefs: []
  type: TYPE_IMG
- en: where *t*[1–α/2,*df*] is the critical value, and the t-value for the given confidence
    level (α) and the degrees of freedom, *df*, come from [Equation 4.7](ch04.xhtml#ch04equ07).
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: 'How should we interpret the 95 percent confidence interval? There is a population
    value: the true difference between the group means. The 95 percent confidence
    interval is such that if we could draw repeated samples from the distribution
    that produced the two datasets, 95 percent of the calculated confidence intervals
    would contain the true difference between the means. It is *not* the range that
    includes the true difference in the means at 95 percent certainty.'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: Beyond checking if zero is in the CI, the CI is useful because its width tells
    us something about the magnitude of the effect. Here, the effect is related to
    the difference between the means. We may have a statistically significant difference
    based on the *p*-value, but the effect might be practically meaningless. The CI
    will be narrow when the effect is large because small CIs imply a narrow range
    encompassing the true effect. We’ll see shortly how, when possible, to calculate
    another useful measure of effect.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: Finally, a *p*-value less than α also will have a *CI*[α] that does not include
    *H*[0]. In other words, what the *p*-value tells us and what the confidence interval
    tells us track–they will not contradict each other.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: Effect Size
  id: totrans-268
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: It’s one thing to have a statistically significant *p*-value. It’s another for
    the difference represented by that *p*-value to be meaningful in the real world.
    A popular measure of the size of an effect, the *effect size*, is *Cohen’s d*.
    For us, since we’re using Welch’s t-test, Cohen’s *d* is found by calculating
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/04equ09.jpg)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
- en: Cohen’s *d* is usually interpreted subjectively, though we should report the
    numeric value as well. Subjectively, the size of the effect could be
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: '| ***d*** | **Effect** |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
- en: '| 0.2 | Small |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
- en: '| 0.5 | Medium |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
- en: '| 0.8 | Large |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
- en: Cohen’s *d* makes sense. The difference between the means is a natural way to
    think about the effect. Scaling it by the mean variance puts it in a consistent
    range. From [Equation 4.9](ch04.xhtml#ch04equ09), we see that a *p*-value corresponding
    to a statistically significant result might lead to a small effect that isn’t
    of any true practical importance.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating the Test Scores
  id: totrans-278
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Let’s put all of the above together to apply the t-test to our test data from
    [Table 4-1](ch04.xhtml#ch04tab01). You’ll find the code in the file *hypothesis.py*.
    We generate the data-sets first:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Once again, we’re using a fixed NumPy pseudorandom number seed for repeatability.
    We make `a` a sample from a normal distribution with a mean of 85 and a standard
    deviation of 6.0\. We select `b` from a normal distribution with a mean of 82
    and a standard deviation of 7.0\. For both, we cap any values over 100 to 100\.
    These are test scores, after all, without extra credit.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: 'We apply the t-test next:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: We get *(t* = 2.40234, *p* = 0.01852). The *t* is the statistic, and *p* is
    the computed *p*-value. It’s 0.019, which is less than 0.05 but only by a factor
    of two. We have a weak result telling us we might want to reject the null hypothesis
    and believe that the two groups, `a` and `b`, come from different distributions.
    Of course, we know they do because we generated them, but it’s nice to see the
    test pointing in the right direction.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: Notice that the function we import from SciPy is `ttest_ind`. This is the function
    to use for independent samples, which are not paired. Also, notice that we added
    `equal_var=False` to the call. This is how to use Welch’s t-test, which doesn’t
    assume that the variance between the two datasets is equal. We know they’re not
    equal, since `a` uses a standard deviation of 6.0 while `b` uses 7.0.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: 'To get the confidence intervals, we’ll write a CI function, since NumPy and
    SciPy don’t include one. The function directly implements [Equations 4.7](ch04.xhtml#ch04equ07)
    and [4.8](ch04.xhtml#ch04equ08):'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The critical *t* value is given by calling `stats.t.ppf`, passing in the α/2
    value and the proper degrees of freedom, *df*. The critical *t* value is the 97.5
    percent percentile value, for α = 0.05, which is what the *percent point function
    (ppf)* returns. We divide by two to cover the tails of the t-distribution.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: 'For our test example, the confidence interval is [0.56105, 5.95895]. Notice
    how this does not include zero, so the CI also indicates a statistically significant
    result. However, the range is rather large, so this is not a particularly robust
    result. The CI range can be difficult to interpret on its own, so, finally, let’s
    calculate Cohen’s *d* to see if it makes sense given the width of the confidence
    interval. In code, we implement [Equation 4.9](ch04.xhtml#ch04equ09):'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: We get *d* = 0.48047, corresponding to a medium effect size.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: The Mann-Whitney U Test
  id: totrans-292
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The t-test assumes the distribution of the source data is normal. If the data
    is not normally distributed, we should instead use a *nonparametric test*. Nonparametric
    tests make no assumptions about the underlying distribution of the data. The *Mann-Whitney
    U test*, sometimes called the *Wilcoxon rank-sum test*, is a nonparametric test
    to help decide if two different sets of data come from the same parent distribution.
    The Mann-Whitney U test does not rely directly on the values of the data, but
    instead uses the data’s ranking.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: 'The null hypothesis for this test is the following: the probability that a
    randomly selected value from Group 1 is larger than a randomly selected value
    from Group 2 is 0.5\. Let’s think a bit about that. If the data is from the same
    parent distribution, then we should expect any randomly selected pair of values
    from the two groups to show no preference as to which is larger than the other.'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: The alternative hypothesis is that the probability of a randomly selected value
    from Group 1 being larger than a randomly selected value from Group 2 is not 0.5\.
    Notice, there is no statement as to the probability being greater or less than
    0.5, only that it isn’t 0.5; thus, the Mann-Whitney U test, as we’ll use it, is
    two-sided.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: The null hypothesis for the Mann-Whitney U test is not the same as the null
    hypothesis for the t-test. For the t-test, we’re asking whether the means between
    the two groups are the same. (Really, we’re asking if the difference in the means
    is zero.) However, if two sets of data *are* from different parent distributions,
    both null hypotheses are false, so we can use the Mann-Whitney U test in place
    of the t-test, especially when the underlying data is not normally distributed.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: To generate *U*, the Mann-Whitney statistic, we first pool both sets of data
    and rank them. Ties are replaced with the mean between the tie value rank and
    the next rank value. We also keep track of the source group so we can separate
    the list of ranks again. The ranks, by group, are summed to give *R*[1] and *R*[2]
    (using the ranks from the pooled data). We calculate two values,
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/100equ01.jpg)'
  id: totrans-298
  prefs: []
  type: TYPE_IMG
- en: with the smaller called *U*, the test statistic. It’s possible to generate a
    *p*-value from *U*, keeping in mind all the discussion above about the meaning
    and use of *p*-values. As before, *n*[1] and *n*[2] are the number of samples
    in the two groups. The Mann-Whitney U test requires the smaller of these two numbers
    to be at least 21 samples. If you don’t have that many, the results may not be
    reliable when using the SciPy `mannwhitneyu` function.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: We can run the Mann-Whitney U test on our test data from [Table 4-1](ch04.xhtml#ch04tab01),
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: with `a` and `b` as we used above for the t-test. This gives us *(U* = 997.00000,
    *p* = 0.04058). The *p*-value is barely below the minimum threshold of 0.05.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: The means of `a` and `b` are 85 and 82, respectively. What happens to the *p*-values
    if we make the mean value of `b` 83 or 81? Changing the mean of `b` means changing
    the first argument to `np.random.normal`. Doing this gives us [Table 4-2](ch04.xhtml#ch04tab02),
    where I’ve included all results for completeness.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 4-2:** Mann-Whitney U Test and t-test Results for the Simulated Test
    Scores with Different Means (*n*[1]=*n*[2]=50)'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: '| **Means** | **Mann-Whitney U** | **t-test** |'
  id: totrans-305
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  id: totrans-306
  prefs: []
  type: TYPE_TB
- en: '| 85 vs. 83 | (*U*=1104.50000, *p*=0.15839) | (*t*=1.66543, *p*=0.09959) |'
  id: totrans-307
  prefs: []
  type: TYPE_TB
- en: '| 85 vs. 82 | (*U*=997.00000, *p*=0.04058) | (*t*=2.40234, *p*=0.01852) |'
  id: totrans-308
  prefs: []
  type: TYPE_TB
- en: '| 85 vs. 81 | (*U*=883.50000, *p*=0.00575) | (*t*=3.13925, *p*=0.00234) |'
  id: totrans-309
  prefs: []
  type: TYPE_TB
- en: '[Table 4-2](ch04.xhtml#ch04tab02) should make sense to us. When the means are
    close, it’s harder to tell them apart, so we expect larger *p*-values. Recall
    how we have only 50 samples in each group. As the difference between the means
    increases, the *p*-values go down. A difference of three in the means leads to
    barely significant *p*-values. When the difference is larger still, the *p*-values
    become truly significant—again, as we expect.'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: 'The analysis above begs the question: for a small difference in the means between
    the two groups, how do the *p*-values change as a function of the sample size?'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 4-8](ch04.xhtml#ch04fig08) shows the *p*-value (mean ± standard error)
    over 25 runs for both the Mann-Whitney U test and the t-test as a function of
    sample size for the case where the means are 85 and 84.'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/04fig08.jpg)'
  id: totrans-313
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4-8: Mean p-value as a function of sample size for a difference in
    the sample means of one, ![image](Images/101equ01.jpg)*'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: Small datasets make it difficult to differentiate between cases when the difference
    in the means is small. We also see that larger sample sizes reveal the difference,
    regardless of the test. It is interesting that in [Figure 4-8](ch04.xhtml#ch04fig08),
    the Mann-Whitney U *p*-value is less than that of the t-test even though the underlying
    data is normally distributed. Conventional wisdom states that it’s usually the
    other way around.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 4-8](ch04.xhtml#ch04fig08) is an object lesson in the power of large-sample
    tests to detect real differences. When the sample size is large enough, a weak
    difference becomes significant. However, we need to balance this with the effect
    size. When we have 1,000 samples in each group, we have a statistically significant
    *p*-value, but we also have a Cohen’s *d* of about 0.13, signaling a weak effect.
    A large sample study might find a significant effect that is so weak as to be
    practically meaningless.'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-317
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This chapter touched on the key aspects of statistics you’ll encounter during
    your sojourn through the world of deep learning. Specifically, we learned about
    different types of data and how to ensure the data is useful for building models.
    We then learned about summary statistics and saw examples that used them to help
    us understand a dataset. Understanding our data is key to successful deep learning.
    We investigated the different types of means, learned about measures of variation,
    and saw the utility of visualizing the data via box plots.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: Missing data is a bane of deep learning. In this chapter, we investigated how
    to compensate for missing data. Next, we discussed correlation, how to detect
    and measure the relationships between elements of a dataset. Finally, we introduced
    hypothesis testing. Restricting ourselves to the most likely scenario we’ll encounter
    in deep learning, we learned how to apply both the t-test and the Mann-Whitney
    U test. Hypothesis testing introduced us to the *p*-value. We saw examples of
    it and discussed how to interpret it correctly.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter we’ll leave statistics behind and dive headfirst into the
    world of linear algebra. Linear algebra is how we implement neural networks.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL

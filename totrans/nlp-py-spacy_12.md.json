["```py\nnlp.meta['version']\n```", "```py\nHave you heard of rhinos? Are you familiar with rhinos? What could you tell me about rhinos?\n```", "```py\ndoc = nlp(u\"Have you heard of rhinos?\")\n\nfor t in doc:\n\n  if t.dep_ == 'pobj' and (t.pos_ == 'NOUN' or t.pos_ == 'PROPN'):\n\n    phrase = (' '.join([child.text for child in t.lefts]) + ' ' + t.text).lstrip()\n\n    break\n```", "```py\ndoc = nlp(u\"Tell me about the color of the sky.\")\n\nfor t in doc:\n\n  if t.dep_ == 'pobj' and (t.pos_ == 'NOUN' or t.pos_ == 'PROPN'):\n\n    phrase = (' '.join([child.text for child in t.lefts]) + ' ' + t.text).lstrip()\n\n    if bool([prep for prep in t.rights if prep.dep_ == 'prep']): \n\n      prep = list(t.rights)[0]\n\n      pobj = list(prep.children)[0] \n\n      phrase = phrase + ' ' + prep.text + ' ' + pobj.text\n\n    break\n```", "```py\nDo you know what an elephant eats? Tell me how dolphins sleep. What is an API?\n```", "```py\ndoc = nlp(u\"Do you know what an elephant eats?\")\n\nfor t in reversed(doc):\n\n  if t.dep_ == 'nsubj' and (t.pos_ == 'NOUN' or t.pos_ == 'PROPN'):\n\n    phrase = t.text + ' ' + t.head.text\n\n    break\n\n```", "```py\nHow to feed a cat?\n```", "```py\ndoc = nlp(u\"How to feed a cat?\")\n\nfor t in reversed(doc):\n\n  if t.dep_ == 'dobj' and (t.pos_ == 'NOUN' or t.pos_ == 'PROPN'):\n\n    phrase = t.head.lemma_ + 'ing' + ' ' + t.text\n\n    break\n\n```", "```py\npip install wikipedia\n```", "```py\n   import spacy\n\n   import wikipedia\n\n   nlp = spacy.load('en')\n\n   doc = nlp(u\"What do you know about rhinos?\")\n\n   for t in doc:\n\n     if t.dep_ == 'pobj' and (t.pos_ == 'NOUN' or t.pos_ == 'PROPN'):\n\n ➊ phrase = (' '.join([child.text for child in t.lefts]) + ' ' + t.text).\n\n       lstrip()\n\n       break\n\n➋ wiki_resp = wikipedia.page(phrase)\n\n   print(\"Article title: \", wiki_resp.title)\n\n   print(\"Article url: \", wiki_resp.url)\n\n   print(\"Article summary: \", wikipedia.summary(phrase, sentences=1))\n```", "```py\nArticle title:  Rhinoceros\n\nArticle url:  https://en.wikipedia.org/wiki/Rhinoceros\n\nArticle summary:  A rhinoceros (, from Greek  rhinokero–s, meaning 'nose-horned', from  rhis,\n\nmeaning 'nose', and  keras, meaning 'horn'), commonly abbreviated to rhino, is one of ...\n```", "```py\npip install clarifai --upgrade\n```", "```py\n   from clarifai.rest import ClarifaiApp, client, Image\n\n   app = ClarifaiApp(api_key='YOUR_API_KEY')\n\n➊ model = app.public_models.general_model\n\n   filename = '/your_path/grape.jpg'\n\n➋ image = Image(file_obj=open(filename, 'rb'))\n\n   response = model.predict([image])\n\n➌ concepts = response['outputs'][0]['data']['concepts']\n\n   for concept in concepts:\n\n     print(concept['name'], concept['value'])\n```", "```py\nno person 0.9968359470367432\n\nwine 0.9812138080596924\n\nfruit 0.9805494546890259\n\njuicy 0.9788177013397217\n\nhealth 0.9755384922027588\n\ngrow 0.9669009447097778\n\ngrape 0.9660607576370239\n\n...\n```", "```py\nimport spacy\n\nimport wikipedia\n\nfrom telegram.ext import Updater, CommandHandler, MessageHandler, Filters\n\nfrom clarifai.rest import ClarifaiApp, Image\n```", "```py\ndef keyphrase(doc): \n\n  for t in doc:\n\n    if t.dep_ == 'pobj' and (t.pos_ == 'NOUN' or t.pos_ == 'PROPN'):\n\n      return (' '.join([child.text for child in t.lefts]) + ' ' + t.text).\n\n      lstrip()\n\n  for t in reversed(doc):\n\n    if t.dep_ == 'nsubj' and (t.pos_ == 'NOUN' or t.pos_ == 'PROPN'):\n\n      return t.text + ' ' + t.head.text\n\n  for t in reversed(doc):\n\n    if t.dep_ == 'dobj' and (t.pos_ == 'NOUN' or t.pos_ == 'PROPN'):\n\n      return t.head.text + 'ing' + ' ' + t.text \n\n  return False\n```", "```py\ndef photo_tags(filename):\n\n  app = ClarifaiApp(api_key=CLARIFAI_API_KEY)\n\n  model = app.public_models.general_model\n\n  image = Image(file_obj=open(filename, 'rb'))\n\n  response = model.predict([image])\n\n  concepts = response['outputs'][0]['data']['concepts']\n\n  for concept in concepts:\n\n    if concept['name'] == 'food':\n\n      food_model = app.public_models.food_model\n\n      result = food_model.predict([image])\n\n      first_concept = result['outputs'][0]['data']['concepts'][0]['name']\n\n      return first_concept\n\n  return response['outputs'][0]['data']['concepts'][1]['name']\n```", "```py\ndef wiki(concept):\n\n  nlp = spacy.load('en')\n\n  wiki_resp = wikipedia.page(concept)\n\n  doc = nlp(wiki_resp.content)\n\n  if len(concept.split()) == 1:\n\n    for sent in doc.sents:\n\n      for t in sent:\n\n        if t.text == concept and t.dep_ == 'dobj':\n\n          return sent.text\n\n  return list(doc.sents)[0].text\n```", "```py\ndef start(update, context):\n\n    update.message.reply_text('Hi! This is a conversational bot. Ask me something.')\n```", "```py\ndef text_msg(update, context):\n\n  msg = update.message.text\n\n  nlp = spacy.load('en')\n\n  doc = nlp(msg)\n\n  concept = keyphrase(doc)\n\n  if concept != False:\n\n    update.message.reply_text(wiki(concept))\n\n  else: \n\n    update.message.reply_text('Please rephrase your question.')\n```", "```py\ndef photo(update, context):\n\n  photo_file = update.message.photo[-1].get_file()\n\n  filename = '{}.jpg'.format(photo_file.file_id)\n\n  photo_file.download(filename) \n\n  concept = photo_tags(filename)\n\n  update.message.reply_text(wiki(concept))\n```", "```py\ndef main():\n\n    updater = Updater(\"YOUR_TOKEN\", use_context=True)\n\n    disp = updater.dispatcher\n\n    disp.add_handler(CommandHandler(\"start\", start))\n\n    disp.add_handler(MessageHandler(Filters.text, text_msg))\n\n    disp.add_handler(MessageHandler(Filters.photo, photo))\n\n    updater.start_polling()\n\n    updater.idle()\n\nif __name__ == '__main__':\n\n    main()\n```"]
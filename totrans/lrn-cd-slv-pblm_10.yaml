- en: '10'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: BIG O AND PROGRAM EFFICIENCY
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/common.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In the first seven chapters of this book, we focused on writing programs that
    were correct: for any valid input, we wanted our program to produce the desired
    output. In addition to correct code, though, we generally want efficient code,
    code that runs quickly even in the face of huge amounts of input. You may have
    received the occasional time limit exceeded error when working through the first
    seven chapters, but our first formal foray into program efficiency wasn’t until
    [Chapter 8](ch08.xhtml#ch08), when we solved Email Addresses. We saw there that
    sometimes we need to make our programs more efficient so that they can finish
    within a given time limit.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’ll first learn how programmers think and communicate about
    program efficiency. Then, we’ll study two problems where we’ll need to write efficient
    code: determining the most desired piece of a scarf and painting a ribbon.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For each problem, we’ll see that our initial ideas lead to an algorithm that
    would not be efficient enough. But we’ll keep at it until we design a faster algorithm
    for the same problem, one that’s dramatically more efficient than before. This
    exemplifies a common workflow for programmers: first, come up with a correct algorithm;
    then, only if needed, make it faster.'
  prefs: []
  type: TYPE_NORMAL
- en: The Problem with Timing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Each competitive programming problem that we solve in this book has a time limit
    on how long our program will be allowed to run. (I began including time limits
    in the problem descriptions of [Chapter 8](ch08.xhtml#ch08), when we started running
    into programming problems where efficiency is a serious concern.) If our program
    exceeds the time limit, then the judge terminates our program with a time limit
    exceeded error. A time limit is designed to prevent solutions that are too slow
    from passing the test cases. For example, perhaps we come up with a complete-search
    solution but the author of the problem has worked out a solution that’s much faster.
    That faster solution may be a variation of complete search, as it was when we
    solved the Cow Baseball problem in [Chapter 9](ch09.xhtml#ch09), or it may be
    a different approach entirely. Regardless, the time limit may be set such that
    our complete-search solution will not finish in time. As such, in addition to
    being correct, we may need our programs to be fast.
  prefs: []
  type: TYPE_NORMAL
- en: We can run a program to explore whether it is efficient enough. For example,
    think back to “Efficiency of Searching a List” in [Chapter 8](ch08.xhtml#ch08)
    when we tried to solve Email Addresses using a list. We ran code that used bigger
    and bigger lists to get a sense of the amount of time taken by list operations.
    This kind of testing can give us some understanding of the efficiency of our programs.
    If our program is too slow, according to the time limit for the problem, then
    we know that we need to optimize the current code or find a wholly new approach.
  prefs: []
  type: TYPE_NORMAL
- en: The amount of time taken by a program depends on the computer it is being run
    on. We don’t know what kind of computer the judge is using, but running the program
    on our own computer is still informative because the judge is probably using a
    computer that’s at least as fast as ours. Say that we run our program on our laptop
    and it takes 30 seconds on some small test case. If the problem time limit is
    three seconds, we can be confident that our program is simply not fast enough.
  prefs: []
  type: TYPE_NORMAL
- en: An exclusive focus on time limits, however, is limiting. Think about our first
    solution to Cow Baseball in [Chapter 9](ch09.xhtml#ch09). We didn’t need to run
    that code to determine how slow it would be. That’s because we were able to characterize
    the program in terms of the amount of work that it would do if we did run it.
    For example, in “Efficiency of Our Program” on [page 253](ch09.xhtml#ch09lev2sec16),
    we said that for *n* cows, our program processes *n*³ triples of cows. Notice
    that our focus here is not on the number of seconds our program would take to
    run, but on how much work it does in terms of the amount of input *n*.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are significant advantages to this kind of analysis compared to running
    our programs and recording execution times. Here are five:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Execution time depends on the computer** Timing our program tells us only
    how long our program takes on one computer. That’s very specific information,
    and it gives us little in the way of understanding what to expect when the program
    is run on other computers. When working through the book, you may have also noticed
    that the time taken by a program varies from run to run, even on the same computer.
    For example, you might run a program on a test case and find that it takes three
    seconds; you might then run it again, on the same test case, and find that it
    takes two-and-a-half seconds or three-and-a-half seconds. The reason for this
    difference is that your operating system is managing your computing resources,
    shunting them around to different tasks as needed. The decisions that your operating
    system makes influence the runtime of your program.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Execution time depends on the test case** Timing our program on a test case
    tells us only how long our program takes on that test case. Suppose that our program
    takes three seconds to run on a small test case. That may seem fast, but here’s
    the truth about small test cases: every reasonable solution for a problem will
    quickly be able to solve those. If I ask you to tell me the number of unique email
    addresses among 10 email addresses, or the number of triples of cows among 10
    cows, you can quickly do it with the first correct idea that you have. What’s
    interesting, then, are large test cases. They are the ones where algorithmic ingenuity
    pays off. How long will our program take on a large test case or on a huge test
    case? We don’t know. We’d have to run our program on those test cases, too. Even
    if we did that, there could be specific kinds of test cases that trigger poorer
    performance. We may be led to believe that our program is faster than it is.'
  prefs: []
  type: TYPE_NORMAL
- en: '**The program requires implementation** We can’t time something that we don’t
    implement. Suppose that we’re thinking about a problem and come up with an idea
    for how to solve it. Is it fast? Although we could implement it to find out, it
    would be nice to know, in advance, whether or not the idea is likely to lead to
    a fast program. You would not implement a program that you knew, at the outset,
    would be incorrect. It would similarly be nice to know, at the outset, that a
    program would be too slow.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Timing doesn’t explain slowness** If we find that our program is too slow,
    then our next task is to design a faster one. However, simply timing a program
    gives us no insight into why our program is slow. It just is. Further, if we manage
    to think up a possible improvement to our program, we’d need to implement it to
    see whether or not it helps.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Execution time is not easily communicated** For many of the reasons listed,
    it’s difficult to use execution time to talk to other people about the efficiency
    of algorithms. Execution time is too specific: it depends on the computer, operating
    system, test case, programming language, and particular implementation that’s
    used. We’d have to provide all of this information to others interested in the
    efficiency of our algorithm.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Not to worry: computer scientists have devised a notation that addresses these
    shortcomings of timing. It’s independent of the computer, independent of test
    case, and independent of a particular implementation. It signals why a slow program
    is slow. It’s easily communicated. It’s called *big O*, and it’s coming right
    up.'
  prefs: []
  type: TYPE_NORMAL
- en: Big O
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Big O is a notation that computer scientists use to concisely describe the efficiency
    of algorithms. The key concept here is the *efficiency class*, which tells you
    how fast an algorithm is or, equivalently, how much work it does. The faster an
    algorithm, the less work it does; the slower an algorithm, the more work it does.
    Each algorithm belongs to an efficiency class; the efficiency class tells you
    how much work that algorithm does relative to the amount of input that it must
    process. To understand big O, we need to understand these efficiency classes.
    We’re now going to study seven of the most common ones. We’ll see those that do
    the least amount of work, the ones you’ll hope your algorithms fit into. We’ll
    also see those that do considerably more work, the ones whose algorithms will
    probably give you time limit exceeded errors.
  prefs: []
  type: TYPE_NORMAL
- en: Constant Time
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The most desirable algorithms are those that don’t do more work as the amount
    of input increases. No matter the problem instance, such an algorithm takes about
    the same number of steps. These are called *constant-time* algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is hard to believe, right? An algorithm that does about the same amount
    of work, no matter what? Indeed, solving a problem with such an algorithm is rare.
    But when you can do it, rejoice: you can’t do any better than that.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ve managed to solve a few problems in this book using constant-time algorithms.
    Think back to the Telemarketers problem in [Chapter 2](ch02.xhtml#ch02), where
    we had to determine whether the provided phone number belongs to a telemarketer.
    I’ve reproduced our solution from [Listing 2-2](ch02.xhtml#ch02ex02) here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Our solution does the same amount of work no matter what the four digits of
    the phone number are. The code starts by reading the input. Then it makes some
    comparisons with `num1`, `num2`, `num3`, and `num4`. If the phone number belongs
    to a telemarketer, we output something; if it doesn’t belong to a telemarketer,
    we output something else. There’s no input that can make our program do more work
    than this.
  prefs: []
  type: TYPE_NORMAL
- en: 'Earlier in [Chapter 2](ch02.xhtml#ch02), we solved Winning Team. Did we solve
    that one in constant time, too? We did! Here’s the solution from [Listing 2-1](ch02.xhtml#ch02ex01):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: We read the input, compute the total points for the Apples, compute the total
    points for the Bananas, compare those totals, and output a message. It doesn’t
    matter how many points the Apples or Bananas have—our program always does the
    same amount of work.
  prefs: []
  type: TYPE_NORMAL
- en: Hold on—what if the Apples scored zillions and zillions of three-point shots?
    Surely, it takes longer for the computer to work with ginormous numbers than small
    numbers like 10 or 50? While that’s true, we don’t have to worry about that here.
    The problem description states that each team scores at most 100 of each type
    of play. We’re therefore working with small numbers, and it’s fair to say that
    the computer can read or operate on these numbers in a constant number of steps.
    In general, you can think of numbers up to a few billion as “small.”
  prefs: []
  type: TYPE_NORMAL
- en: In big O notation, we say that a constant-time algorithm is *O*(1). The 1 doesn’t
    mean that you’re stuck performing only one step in a constant-time algorithm.
    If you perform a fixed number of steps, like 10 or even 10,000, it’s still constant
    time. But don’t write *O*(10) or *O*(10000)—all constant-time algorithms are denoted
    *O*(1).
  prefs: []
  type: TYPE_NORMAL
- en: Linear Time
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Most algorithms are not constant-time algorithms. Instead, they do an amount
    of work that depends on the amount of input. For example, they do more work to
    process 1,000 values than they do to process 10 values. What distinguishes these
    algorithms from each other is the relationship between the amount of input and
    the amount of work that the algorithm does.
  prefs: []
  type: TYPE_NORMAL
- en: A *linear-time* algorithm is one with a linear relationship between the amount
    of input and the amount of work done. Suppose we run a linear-time algorithm on
    an input with 50 values, and then we run it again on an input with 100 values.
    The algorithm will do about twice as much work on the 100 values compared with
    on the 50 values.
  prefs: []
  type: TYPE_NORMAL
- en: 'For an example, let’s look at the Three Cups problem from [Chapter 3](ch03.xhtml#ch03).
    We solved that problem in [Listing 3-1](ch03.xhtml#ch03ex01), and I’ve reproduced
    our solution here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: There’s a `for` loop ❶, and the amount of work that it does depends linearly
    on the amount of input. If there are five swaps to process, then the loop iterates
    five times. If there are 10 swaps to process, then the loop iterates 10 times.
    Each iteration of the loop performs a constant number of comparisons and may change
    what `ball_location` refers to. Therefore, the amount of work that this algorithm
    does is directly proportional to the number of swaps.
  prefs: []
  type: TYPE_NORMAL
- en: We typically use *n* to refer to the amount of input provided to a problem.
    Here, *n* is the number of swaps. If there are 5 swaps that we need to perform,
    then *n* is 5; if there are 10 swaps that we need to perform, then *n* is 10.
  prefs: []
  type: TYPE_NORMAL
- en: If there are *n* swaps, then our program does about *n* work. That’s because
    the `for` loop performs *n* iterations, each of which performs a constant number
    of steps. We don’t care how many steps it performs on each iteration, as long
    as it’s a constant number. Whether the algorithm performs a total of *n* steps
    or 10*n* steps or 10,000*n* steps, it’s a linear-time algorithm. In big O notation,
    we say that this algorithm is *O*(*n*).
  prefs: []
  type: TYPE_NORMAL
- en: When using big O notation, we don’t include numbers in front of *n*. For example,
    an algorithm that takes 10*n* steps is written *O*(*n*), not *O*(10*n*). This
    helps us focus on the fact that the algorithm is linear time and away from the
    specifics of the linear relationship.
  prefs: []
  type: TYPE_NORMAL
- en: What if an algorithm takes 2*n* + 8 steps—what kind of algorithm is this? This
    is still linear time! The reason is that the linear term (2*n*) will come to dominate
    the constant term (8) as soon as *n* is big enough. For example, if *n* is 5,000,
    then 8*n* is 40,000\. The number 8 is so small compared to 40,000 that we may
    as well ignore it. In big O notation, we ignore everything except the dominant
    terms.
  prefs: []
  type: TYPE_NORMAL
- en: Many Python operations take constant time to do their work. For example, appending
    to a list, adding to a dictionary, or indexing a sequence or dictionary all take
    constant time.
  prefs: []
  type: TYPE_NORMAL
- en: But some Python operations take linear time to do their work. Be careful to
    count them as linear time and not constant time. For example, using the Python
    `input` function to read a long string takes linear time, because Python has to
    read each character on the line of input. Any operation that examines each character
    of a string or value in a list takes linear time as well.
  prefs: []
  type: TYPE_NORMAL
- en: If an algorithm reads *n* values and processes each value in a constant number
    of steps, then it is a linear-time algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'We don’t need to go far to see another linear-time algorithm—our solution to
    Occupied Spaces in [Chapter 3](ch03.xhtml#ch03) is another such example. I’ve
    reproduced our solution from [Listing 3-3](ch03.xhtml#ch03ex03) here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We let *n* be the number of parking spaces. The pattern is the same as for
    Three Cups: we read the input and then perform a constant number of steps for
    each parking space.'
  prefs: []
  type: TYPE_NORMAL
- en: '**CONCEPT CHECK**'
  prefs: []
  type: TYPE_NORMAL
- en: In [Listing 1-1](ch01.xhtml#ch01ex01), we solved the Word Count problem. Here’s
    the code for that solution.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: What is the big O efficiency of our algorithm?
  prefs: []
  type: TYPE_NORMAL
- en: A. *O*(1)
  prefs: []
  type: TYPE_NORMAL
- en: B. *O*(*n*)
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: B. It’s tempting to think that this algorithm is *O*(1). After all,
    there’s no loop anywhere, and it looks like the algorithm is performing just three
    steps: read the input, call `count` to count the number of words, and output the
    number of words.'
  prefs: []
  type: TYPE_NORMAL
- en: But this algorithm is *O*(*n*), where *n* is the number of characters in the
    input. It takes linear time for the `input` function to read the input, because
    it has to read the input character by character. Using the `count` method also
    takes linear time, because it has to process each character of the string to find
    matches. So this algorithm performs a linear amount of work to read the input
    and a linear amount of work to count the words. That’s a linear amount of work
    overall.
  prefs: []
  type: TYPE_NORMAL
- en: '**CONCEPT CHECK**'
  prefs: []
  type: TYPE_NORMAL
- en: 'In [Listing 1-2](ch01.xhtml#ch01ex02), we solved the Cone Volume problem. I’ve
    reproduced that solution here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: What is the big O efficiency of our algorithm? (Recall that the maximum value
    for the radius and height is 100.)
  prefs: []
  type: TYPE_NORMAL
- en: A. *O*(1)
  prefs: []
  type: TYPE_NORMAL
- en: B. *O*(*n*)
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: A. We’re dealing with small numbers here, so reading them from the
    input takes constant time. Calculating the volume takes constant time, too: it’s
    just a few mathematical operations. All we’re doing here, then, is a few constant-time
    steps. That’s a constant amount of work overall.'
  prefs: []
  type: TYPE_NORMAL
- en: '**CONCEPT CHECK**'
  prefs: []
  type: TYPE_NORMAL
- en: 'In [Listing 3-4](ch03.xhtml#ch03ex04), we solved the Data Plan problem. I’ve
    reproduced that solution here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: What is the big O efficiency of our algorithm?
  prefs: []
  type: TYPE_NORMAL
- en: A. *O*(1)
  prefs: []
  type: TYPE_NORMAL
- en: B. *O*(*n*)
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: B. The pattern for this algorithm is similar to that of our solution
    to Three Cups or Occupied Spaces, except that it interleaves reading the input
    with processing it. We let *n* be the number of monthly megabyte values. The program
    performs a constant number of steps for each of these *n* input values. This is
    therefore an *O*(*n*) algorithm.'
  prefs: []
  type: TYPE_NORMAL
- en: Quadratic Time
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: So far we’ve discussed constant-time algorithms (those that don’t do more work
    as the amount of input increases) and linear-time algorithms (those that do more
    work linearly as the amount of input increases). Like a linear-time algorithm,
    a *quadratic-time* algorithm does more work as the amount of input increases;
    for example, it does more work to process 1,000 values than 10 values. Whereas
    we can get away with using a linear-time algorithm on relatively large amounts
    of input, we’ll be restricted to much smaller amounts of input on quadratic-time
    algorithms. We’ll see why next.
  prefs: []
  type: TYPE_NORMAL
- en: Typical Form
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'A typical linear-time algorithm looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'In contrast, a typical quadratic-time algorithm looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: For an input of *n* values, how many values does each algorithm process? The
    linear-time algorithm processes *n* values, one on each iteration of the `for`
    loop. The quadratic-time algorithm, in contrast, processes *n* values *on each
    iteration* of the outer `for` loop.
  prefs: []
  type: TYPE_NORMAL
- en: On the first iteration of the outer `for` loop, *n* values are processed (one
    on each iteration of the inner `for` loop); on the second iteration of the outer
    `for` loop, *n* more values are processed (one on each iteration of the inner
    `for` loop); and so on. As the outer `for` loop iterates *n* times, the total
    number of values that are processed is *n* * *n*, or *n*². Two nested loops, each
    of which depends on *n*, gives rise to a quadratic-time algorithm. In big O notation,
    we say that a quadratic-time algorithm is *O*(*n*²).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s compare the amount of work done by linear-time and quadratic-time algorithms.
    Suppose that we’re processing an input of 1,000 values, meaning that *n* is 1,000\.
    A linear-time algorithm that takes *n* steps would take 1,000 steps. A quadratic-time
    algorithm that takes *n*² steps would take 1,000² = 1,000,000 steps. A million
    is way more than a thousand. But who cares: computers are really, really fast,
    right? Well, yes, and for an input of 1,000 values, we’re probably okay if we
    use a quadratic-time algorithm. In “Efficiency of Our Program” on [page 253](ch09.xhtml#ch09lev2sec16),
    I gave a conservative rule claiming that we can perform about five million steps
    per second. A million steps, then, should be doable in all but the strictest time
    limits.'
  prefs: []
  type: TYPE_NORMAL
- en: But any optimism for a quadratic-time algorithm is short-lived. Watch what happens
    if we crank the number of input values up from 1,000 to 10,000\. The linear-time
    algorithm takes only 10,000 steps. The quadratic-algorithm takes 10,000² = 100,000,000
    steps. Hmmm . . . if we’re using a quadratic-time algorithm, now our computer
    isn’t looking so fast. While the linear-time algorithm still runs in milliseconds,
    the quadratic-time algorithm will take at least a few seconds. Time limit exceeded
    there, no question.
  prefs: []
  type: TYPE_NORMAL
- en: '**CONCEPT CHECK**'
  prefs: []
  type: TYPE_NORMAL
- en: What is the big O efficiency of the following algorithm?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: A. *O*(1)
  prefs: []
  type: TYPE_NORMAL
- en: B. *O*(*n*)
  prefs: []
  type: TYPE_NORMAL
- en: C. *O*(*n*^(*2*))
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: B. There are two nested loops here, so your first instinct might be
    to claim that this is a quadratic-time algorithm. Be careful, though, because
    the outer `for` loop iterates only 10 times, independent of the value of *n*.
    The total number of steps in this algorithm, therefore, is *10n*. There’s no *n*^(*2*)
    here; *10n* is linear, just like *n*. So, this is a linear-time algorithm, not
    a quadratic-time algorithm. We’d write its efficiency as *O*(*n*).'
  prefs: []
  type: TYPE_NORMAL
- en: '**CONCEPT CHECK**'
  prefs: []
  type: TYPE_NORMAL
- en: What is the big O efficiency of the following algorithm?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: A. *O*(1)
  prefs: []
  type: TYPE_NORMAL
- en: B. *O*(*n*)
  prefs: []
  type: TYPE_NORMAL
- en: C. *O*(*n*^(*2*))
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: B. We have two loops here, and they both depend on *n*. Isn’t this
    quadratic time, then?'
  prefs: []
  type: TYPE_NORMAL
- en: No! These two loops are sequential, not nested. The first loop takes *n* steps,
    and the second also takes *n* steps, for a total of *2n* steps. This is therefore
    a linear-time algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Alternate Form
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'When you see two nested loops where each depends on *n*, it’s a good bet that
    you’re looking at a quadratic-time algorithm. But it’s possible for a quadratic-time
    algorithm to arise even in the absence of such nested loops. We can find such
    an example in our first solution to the Email Addresses problem, [Listing 8-2](ch08.xhtml#ch08ex02).
    I’ve reproduced that solution here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: We’ll let *n* be the maximum number of email addresses that we see in our 10
    test cases. The outer `for` loop iterates 10 times; the inner `for` loop iterates
    at most *n* times. We’re therefore processing at most 10*n* email addresses, which
    is linear in *n*.
  prefs: []
  type: TYPE_NORMAL
- en: Cleaning an email address ❶ takes a constant number of steps, so we don’t need
    to worry about that. But this is still *not* a linear-time algorithm, because
    each iteration of the inner `for` loop takes more than a constant number of steps.
    Specifically, checking whether an email address is already in our list ❷ takes
    work proportional to the number of email addresses already in the list, because
    Python has to search through the list. That’s a linear-time operation on its own!
    So we’re processing 10*n* email addresses, each of which requires *n* work, for
    a total of 10*n*², or quadratic-time, work. This quadratic-time performance is
    precisely why we received a time limit exceeded error with this code, leading
    us to use a set rather than a list.
  prefs: []
  type: TYPE_NORMAL
- en: Cubic Time
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: If one loop can lead to linear time, and two nested loops can lead to quadratic
    time, then what about three nested loops? Three nested loops, each of which depends
    on *n*, leads to a *cubic-time* algorithm. In big O notation, we say that a cubic-time
    algorithm is *O*(*n*³).
  prefs: []
  type: TYPE_NORMAL
- en: 'If you thought quadratic-time algorithms were slow, wait till you see how slow
    cubic-time algorithms are. Suppose that *n* is 1,000\. We already know that a
    linear-time algorithm will take about 1,000 steps and that a quadratic-time algorithm
    will take about 1,000² = 1,000,000 steps. A cubic-time algorithm will take 1,000³
    = 1,000,000,000 steps. A billion steps! But it gets worse. For example, if *n*
    is 10,000, which is still a small amount of input, then a cubic-time algorithm
    will take 1,000,000,000,000 (that’s one trillion) steps. One trillion steps would
    take many minutes of computing time. No joke: a cubic-time algorithm is almost
    never good enough.'
  prefs: []
  type: TYPE_NORMAL
- en: 'It certainly wasn’t good enough when we tried to use a cubic-time algorithm
    to solve Cow Baseball in [Listing 9-5](ch09.xhtml#ch09ex05). I’ve reproduced that
    solution here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'You’ll see the telltale of cubic time in this code: three nested loops ❶ ❷
    ❸, each of which depends on the amount of input. As you’ll recall, the time limit
    for that problem was four seconds, and we could have up to 1,000 cows. A cubic-time
    algorithm, processing a billion triples, is way too slow.'
  prefs: []
  type: TYPE_NORMAL
- en: Multiple Variables
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In [Chapter 5](ch05.xhtml#ch05), we solved the Baker Bonus problem. I’ve reproduced
    our solution from [Listing 5-6](ch05.xhtml#ch05ex06) here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: What is the big O efficiency of this algorithm? There are some nested loops
    in here, so a first guess is that this algorithm is *O*(*n*²). But what is *n*?
  prefs: []
  type: TYPE_NORMAL
- en: 'In the problems we’ve discussed to this point in the chapter, we used the single
    variable *n* to represent the amount of input: *n* could be the number of swaps
    or the number of parking spaces or the number of email addresses or the number
    of cows. But in the Baker Bonus problem, we’re dealing with two-dimensional input,
    so we need *two* variables to represent its amount. We’ll call the first variable
    *d*, the number of days; we’ll call the second *f*, the number of franchisees.
    More formally, because there are multiple test cases per input, we’ll let *d*
    be the maximum number of days and *f* the maximum number of franchisees. We need
    to give the big O efficiency in terms of *both d* and *f*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Our algorithm consists of three major components: reading the input, calculating
    the number of bonuses from the rows, and calculating the number of bonuses from
    the columns. Let’s take a look at each of these.'
  prefs: []
  type: TYPE_NORMAL
- en: To read the input ❶, we perform *d* iterations of the outer loop. On each of
    these iterations we read a row and call `split`, which takes about *f* steps.
    We take another *f* steps to loop through the values and convert them to integers.
    In total, then, each of the *d* iterations performs a number of steps proportional
    to *f*. Reading the input therefore takes *O*(*df*) time.
  prefs: []
  type: TYPE_NORMAL
- en: Now for the row bonuses ❷. The outer loop here loops *d* times. Each of these
    iterations calls `sum`, which takes *f* steps because it has to add up *f* values.
    Like reading the input, then, this part of the algorithm is *O*(*df*).
  prefs: []
  type: TYPE_NORMAL
- en: Finally, let’s look at the code for the column bonuses ❸. The outer loop loops
    *f* times. Each of those iterations leads to the inner loop iterating *d* times.
    The total here, again, is *O*(*df*).
  prefs: []
  type: TYPE_NORMAL
- en: Each component of this algorithm is *O*(*df*). Adding three *O*(*df*) components
    together yields an *O*(*df*) algorithm overall.
  prefs: []
  type: TYPE_NORMAL
- en: '**CONCEPT CHECK**'
  prefs: []
  type: TYPE_NORMAL
- en: What is the big O efficiency of the following algorithm?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: A. *O*(1)
  prefs: []
  type: TYPE_NORMAL
- en: B. *O*(*n*)
  prefs: []
  type: TYPE_NORMAL
- en: C. *O*(*n*^(*2*))
  prefs: []
  type: TYPE_NORMAL
- en: D. *O*(*m*+*n*)
  prefs: []
  type: TYPE_NORMAL
- en: E. *O*(*mn*)
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: D. The first loop depends on *m*, and the second depends on *n*. The
    loops are sequential, not nested, so their work is added rather than multiplied.'
  prefs: []
  type: TYPE_NORMAL
- en: Log Time
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In “Efficiency of Our Program” on [page 255](ch09.xhtml#ch09lev2sec18), we discussed
    the difference between linear search and binary search. A linear search finds
    a value in a list by searching the list from beginning to end. That’s an *O*(*n*)
    algorithm. It works whether or not the list is sorted. A binary search, by contrast,
    works only on a sorted list. But if you have a sorted list, then binary search
    is blazingly fast.
  prefs: []
  type: TYPE_NORMAL
- en: Binary search works by comparing the value we’re searching for to the value
    at the middle of the list. If the value at the middle of the list is larger than
    the value we’re searching for, we continue searching in the left half of the list.
    If the value at the middle of the list is smaller than the value we’re searching
    for, we continue searching in the right half of the list. We keep doing this,
    ignoring half of the list each time, until we find the value that we’re looking
    for.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose we use binary search to find a value in a list of 512 values. How many
    steps does it take? Well, after one step, we’ve ignored half the list, so we’re
    left with about 512 / 2 = 256 values. (It doesn’t matter whether our value is
    larger than half of the values in the list or smaller than half the values in
    the list; in each case, we ignore one half of the list.) After two steps, we’re
    left with 256 / 2 = 128 values. After three steps, we’re left with 128 / 2 = 64
    values. Continuing, after four steps we have 32 values, after five steps we have
    16 values, after six steps we have 8 values, after seven steps we have 4 values,
    after eight steps we have 2 values, and after nine steps we have only 1 value.
  prefs: []
  type: TYPE_NORMAL
- en: 'Nine steps—that’s it! That’s way better than taking up to 512 steps using linear
    search. Binary search does far less work than a linear-time algorithm. But what
    kind of algorithm is it? It’s not constant time: while it takes very few steps,
    the number of steps does increase a little as the amount of input increases.'
  prefs: []
  type: TYPE_NORMAL
- en: Binary search is an example of a *logarithmic-time* or *log-time* algorithm.
    In big O notation, we say that a logarithmic-time algorithm is *O*(log *n*).
  prefs: []
  type: TYPE_NORMAL
- en: Logarithmic-time refers to the logarithm function in mathematics. Given a number,
    this function tells you the number of times you have to divide that number by
    a base to get to 1 or less. The base we typically use in computer science is 2,
    so we’re looking for the number of times you have to divide a number by 2 to get
    to 1 or less. For example, it takes 9 divisions by 2 to take 512 down to 1\. We
    write this as log[2] 512 = 9.
  prefs: []
  type: TYPE_NORMAL
- en: The logarithm function is the inverse of the exponential function, the latter
    of which may be more familiar to you. Another way to calculate log[2] 512 is to
    find the power *p* so that 2*^p* = 512\. Since 2⁹ = 512, we confirm that log[2]
    512 = 9.
  prefs: []
  type: TYPE_NORMAL
- en: It’s shocking how slowly the logarithm function grows. For example, consider
    a list of one million values. How many steps would binary search take to search
    that? It takes log[2] 1,000,000 steps, which is only about 20\. Logarithmic-time
    is much closer to constant-time than it is to linear-time. It’s a huge win any
    time you can replace a linear-time algorithm by a logarithmic-time one.
  prefs: []
  type: TYPE_NORMAL
- en: n log n Time
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In [Chapter 5](ch05.xhtml#ch05), we solved the Village Neighborhood problem.
    I’ve reproduced our solution from [Listing 5-1](ch05.xhtml#ch05ex01) here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Looks like a linear-time algorithm, eh? I mean, there’s a linear-time loop to
    read the input ❶ and another linear-time loop to find the minimum size ❸. Is this
    code *O*(*n*), then?
  prefs: []
  type: TYPE_NORMAL
- en: It’s too early to tell! The reason is that we haven’t yet taken into account
    that we sort the positions ❷. We can’t just ignore that; we need to know about
    the efficiency of sorting. As we’ll see, sorting is slower than linear time. So,
    since sorting is the slowest step here, whatever the efficiency is of sorting
    will be the efficiency overall.
  prefs: []
  type: TYPE_NORMAL
- en: 'Programmers and computer scientists have devised many sorting algorithms, and
    these algorithms can roughly be divided into two groups. The first group consists
    of algorithms that take *O*(*n*²) time. The three most famous of these sorting
    algorithms are bubble sort, selection sort, and insertion sort. You can learn
    more about these sorting algorithms on your own if you like, but we won’t need
    to know anything about them to continue here. All we have to keep in mind is that
    *O*(*n*²) can be quite slow. For example, to sort a list of 10,000 values, an
    *O*(*n*²) sorting algorithm would take about 10,000² = 100,000,000 steps. As we
    know, this would take any computer at least a few seconds. That’s pretty disappointing:
    sorting 10,000 values feels like something computers should be able to do almost
    instantly.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Enter the second group of sorting algorithms. This group consists of algorithms
    that take only *O*(*n* log *n*) time. There are two famous sorting algorithms
    in this group: quick sort and merge sort. Again, you’re free to look them up if
    you like, but we don’t need the details here.'
  prefs: []
  type: TYPE_NORMAL
- en: What does *O*(*n* log *n*) mean? Don’t let the notation confuse you. It’s just
    the multiplication of *n* by log *n*. Let’s try this out on a list of 10,000 values.
    Here, we have 10,000 * log 10,000 steps, which is only about 132,877\. This is
    a very small number of steps, especially compared to the 100,000,000 steps taken
    by the *O*(*n*²) sorting algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can ask the question we really care about: what sorting algorithm is
    Python using when we ask it to sort a list? Answer: an *O*(*n* log *n*) one! (It’s
    called Timsort. If you’d like to learn more, start with merge sort, because Timsort
    is a souped-up merge sort.) No slow *O*(*n*²) sorting here. In general, sorting
    is so fast—so close to linear time—that we can use it without affecting our efficiency
    too much.'
  prefs: []
  type: TYPE_NORMAL
- en: Returning to Village Neighborhood, now we see that its efficiency is not *O*(*n*)
    but, because of the sort, *O*(*n* log *n*). In practice, an *O*(*n* log *n*) algorithm
    only does a little more work than an *O*(*n*) algorithm and far less than an *O*(*n*²)
    algorithm. If your goal is to design an *O*(*n*) algorithm, designing one that’s
    *O*(*n* log *n*) is probably good enough.
  prefs: []
  type: TYPE_NORMAL
- en: Handling Function Calls
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Starting in [Chapter 6](ch06.xhtml#ch06), we wrote our own functions to help
    us design larger programs. In our big O analysis, we need to be careful to include
    the work done when we call these functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s revisit the Card Game problem from [Chapter 6](ch06.xhtml#ch06). We solved
    it in [Listing 6-1](ch06.xhtml#ch06ex01), and part of our solution involved calling
    our `no_high` function. I’ve reproduced that solution here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: We’ll use *n* to represent the number of cards. The `no_high` function ❶ takes
    a list and uses `in` on it, so we might conclude that it is *O*(*n*) time. (`in`
    may have to search the whole list to find what it’s looking for, after all.) However,
    we only ever call `no_high` with lists of constant size—maximum four cards—so
    we can treat each call of `no_high` as *O*(1) time.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we understand the efficiency of `no_high`, we can determine the big
    O efficiency of the complete program. We begin with a loop that takes *O*(*n*)
    time to read the cards ❷. We then enter another loop that iterates *n* times ❸.
    Each iteration takes just a constant number of steps, possibly including a call
    of `no_high` that takes a constant number of steps. This loop, then, takes *O*(*n*)
    time. The program therefore consists of two *O*(*n*) pieces, so it is *O*(*n*)
    overall.
  prefs: []
  type: TYPE_NORMAL
- en: Be careful to accurately judge the amount of work performed when a function
    is called. As you just saw with `no_high`, this may involve looking at both the
    function itself and the context in which it is called.
  prefs: []
  type: TYPE_NORMAL
- en: '**CONCEPT CHECK**'
  prefs: []
  type: TYPE_NORMAL
- en: What is the big O efficiency of the following algorithm?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: A. *O*(1)
  prefs: []
  type: TYPE_NORMAL
- en: B. *O*(*n*)
  prefs: []
  type: TYPE_NORMAL
- en: C. *O*(*n*^(*2*))
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: C. The loop in the main program iterates *n* times. On each iteration,
    we call function `f`, which itself has a loop that iterates *n* times.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The algorithms that do the least work are *O*(1), followed by *O*(log *n*),
    followed by *O*(*n*), followed by *O*(*n* log *n*). Have you solved a problem
    using one of these four? If so, you’re probably done. If not, then depending on
    the time limit, you may have more work to do.
  prefs: []
  type: TYPE_NORMAL
- en: We’re now going to look at two problems where a straightforward solution will
    not be efficient enough—it won’t run within the time limit. Using what we just
    learned about big O, we’ll be able to predict this inefficiency even without implementing
    the code! We’ll then work on a faster solution and implement it to solve the problem
    within the time limit.
  prefs: []
  type: TYPE_NORMAL
- en: 'Problem #24: Longest Scarf'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this problem, we’ll determine the longest desired scarf that we can produce
    by cutting an initial scarf. After reading the following description, pause: how
    would you solve it? Can you come up with multiple algorithms whose efficiency
    you’d like to investigate?'
  prefs: []
  type: TYPE_NORMAL
- en: This is DMOJ problem `dmopc20c2p2`.
  prefs: []
  type: TYPE_NORMAL
- en: The Challenge
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: You have a scarf whose length is *n* feet, and each foot has a specific color.
  prefs: []
  type: TYPE_NORMAL
- en: You also have *m* relatives. Each relative indicates what their desired scarf
    looks like by specifying the color of its first foot and last foot.
  prefs: []
  type: TYPE_NORMAL
- en: Your goal is to cut your original scarf in such a way as to produce the longest
    desired scarf for one of your relatives.
  prefs: []
  type: TYPE_NORMAL
- en: Input
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The input consists of the following lines:'
  prefs: []
  type: TYPE_NORMAL
- en: A line containing the integer scarf length *n* and integer number of relatives
    *m*, separated by a space. *n* and *m* are each between 1 and 100,000.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A line containing *n* integers separated by spaces. Each integer specifies the
    color of one foot of scarf in order from the first foot to the last foot. Each
    integer is between 1 and 1,000,000.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*m* lines, one per relative, containing two integers separated by a space.
    These numbers describe the relative’s desired scarf: the first integer is the
    desired color of the first foot, and the second integer is the desired color of
    the last foot.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Output
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Output the length of the longest desired scarf that can be produced by cutting
    your original scarf.
  prefs: []
  type: TYPE_NORMAL
- en: The time limit for solving the test cases is 0.4 seconds.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring a Test Case
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s make sure we know exactly what is being asked by working through a small
    test case. Here it is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: We have a scarf that’s 6 feet long and three relatives. The color of each foot
    of the scarf is 18, 4, 4, 2, 1, and 2\. What’s the longest desired scarf we can
    make?
  prefs: []
  type: TYPE_NORMAL
- en: 'The first relative wants a scarf whose first foot is color 1 and whose last
    foot is color 2\. The best we can do is give this relative a 2-foot scarf: the
    2 feet (colors 1 and 2) at the end of the scarf.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The second relative wants a scarf whose first foot is color 4 and whose last
    foot is color 2\. We can give them a 5-foot scarf: 4, 4, 2, 1, 2.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The third relative wants a scarf whose first foot is color 18 and whose last
    foot is color 4\. We can give them a 3-foot scarf: 18, 4, 4.'
  prefs: []
  type: TYPE_NORMAL
- en: The maximum length of a desired scarf that we can make is 5, so that’s the answer
    for this test case.
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm 1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The way we just processed that test case might immediately suggest to you an
    algorithm that we can use to solve this problem. Namely, we should be able to
    go through the relatives and figure out the maximum length of a desired scarf
    for each one. For example, the maximum length for the first relative might be
    2, so we remember that. The maximum length for the second relative might be 5\.
    That’s longer than 2, so we remember the 5\. The maximum length for the third
    relative might be 3\. This isn’t greater than 5—no change here. If this reminds
    you of a complete-search algorithm ([Chapter 9](ch09.xhtml#ch09)): good, because
    it is one!'
  prefs: []
  type: TYPE_NORMAL
- en: There are *m* relatives. If we knew how long it would take us to process each
    relative, then we’d be able to work out the big O efficiency we’d be dealing with.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an idea: for each relative, let’s find the leftmost index of the color
    of the first foot and the rightmost index of the color of the last foot. Once
    we had these indices, then no matter how long the scarf, we could use these indices
    to quickly determine the length of the longest desired scarf for this relative.
    For example, if the leftmost index of the color of the first foot is 100 and the
    rightmost index of the color of the last foot is 110, then their longest desired
    scarf is 110 – 100 + 1 = 11.'
  prefs: []
  type: TYPE_NORMAL
- en: Depending on how we try to find these indices, we might be lucky and find them
    quickly. For example, we might scan from the left for the leftmost index of the
    color of the first foot and scan from the right for the rightmost index of the
    color of the last foot. Then, if the color of the first foot is near the beginning
    of the scarf and the color of the last foot is near the end, we’ll discover these
    indices very quickly.
  prefs: []
  type: TYPE_NORMAL
- en: We might not be lucky, though. Finding one or both of the indices could take
    up to *n* steps. For example, suppose that a relative wants a scarf whose first
    foot is a color that shows up right at the end of the scarf or that doesn’t show
    up in the scarf at all. We will have to check the entire *n* feet of the scarf,
    one foot at a time, to figure this out.
  prefs: []
  type: TYPE_NORMAL
- en: So, about *n* steps per relative. That’s linear time, and we know that linear
    time is fast. Are we good? No, because in this case the linear-time work is far
    more menacing than it may appear. Remember that we’d be doing this *O*(*n*) work
    for each of the *m* relatives. We therefore have an *O*(*mn*) algorithm overall.
    *m* and *n* can be as big as 100,000\. So, *mn* can be as big as 100,000 *** 100,000
    = 10,000,000,000\. That’s 10 billion! Given that we can do about five million
    operations per second and that our time limit is 0.4 seconds . . . yeah, we’re
    not even close. There’s no need to implement this algorithm. We’re certain that
    it will time out on large test cases. We may as well move on and spend our time
    implementing something else. (If you’re nevertheless curious about the code, please
    see the online resources associated with the book. Just remember that without
    even looking at the code, we already figured out that it would be too slow. The
    power of big O analysis is in helping us understand whether an algorithm is doomed
    even before we implement it.)
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm 2
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We’re going to have to somehow process each of the relatives—there’s no getting
    around that. What we’ll focus on optimizing, then, is the amount of work that
    we do per relative. Unfortunately, processing a relative in the way we did in
    the previous section may cause us to check over a huge portion of the scarf. It’s
    this searching through the scarf, once per relative, that’s crushing us. We need
    to get that searching under control.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose that we could look through the scarf only once, up-front, before we
    knew anything about what the relatives wanted. We could remember two things about
    each color in the scarf: its leftmost index and its rightmost index. Then, no
    matter what each relative wants, we could figure out the maximum length of their
    desired scarf using the left and right indices that we had already stored.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, assume we have this scarf:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'We would store the following information for it:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Color** | **Leftmost index** | **Rightmost index** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 4 | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 3 | 5 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 1 | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| 18 | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: Suppose that a relative wants a scarf whose first foot is color 1 and whose
    last foot is color 2\. We look up the leftmost index for color 1, which is 4,
    and the rightmost index for color 2, which is 5\. We then calculate 5 – 4 + 1
    = 2, and that’s the length of the longest desired scarf for this relative.
  prefs: []
  type: TYPE_NORMAL
- en: 'Amazing: no matter how long the scarf, we can just do a quick calculation for
    each relative. No more running through the scarf over and over. The only tricky
    thing here is how to calculate all the leftmost and rightmost indices for the
    colors and to do so by looking through the scarf only once.'
  prefs: []
  type: TYPE_NORMAL
- en: The code is presented in [Listing 10-1](ch10.xhtml#ch10ex01). Try to figure
    out how the `leftmost_index` and `rightmost_index` dictionaries are constructed
    before you continue reading my explanation that follows.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 10-1: Solving Longest Scarf, algorithm 2*'
  prefs: []
  type: TYPE_NORMAL
- en: 'This solution uses two dictionaries: one to keep track of the leftmost index
    for each color ❶ and one to keep track of the rightmost index for each color ❷.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As promised, we look at each foot of the scarf just once ❸. Here’s how we keep
    the `leftmost_index` and `rightmost_index` dictionaries up-to-date:'
  prefs: []
  type: TYPE_NORMAL
- en: If the color of the current foot has never been seen before ❹, then the current
    index serves as both the leftmost and rightmost index for this color.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Otherwise, the color of the current foot has been seen before ❺. We don’t want
    to update the leftmost index for this color, because the current index is to the
    right of the old one. We *do* want to update the rightmost index, though, because
    we have found an index to the right of the old one.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now for the payoff: for each relative, we can simply look up the leftmost and
    rightmost indices from these dictionaries ❻. The maximum length of the desired
    scarf is the rightmost index of the color of the last foot, minus the leftmost
    index of the color of the first foot, plus one.'
  prefs: []
  type: TYPE_NORMAL
- en: As I’ll argue now, this algorithm is far better than algorithm 1\. Reading the
    scarf takes *O*(*n*) time, as does processing the scarf ’s feet. That’s *O*(*n*)
    time so far. We then take a constant number of steps to process each relative
    (not *n* steps like before!), so that’s *O*(*m*) time. In total, we have an *O*(*m*
    + *n*) algorithm, rather than an *O*(*mn*) algorithm. Given that *m* and *n* can
    be at most 100,000, we’re doing only about 100,000 + 100,000 = 200,000 steps,
    easily done within the time limit. You can submit our code to the judge to prove
    it!
  prefs: []
  type: TYPE_NORMAL
- en: 'Problem #25: Ribbon Painting'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Here’s another problem where the first algorithm that we might come up with
    is too slow. We won’t waste much time on that algorithm, though, because our big
    O analysis will tell us all we need to know before we consider implementing the
    code. We’ll then spend our time designing a faster algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: This is DMOJ problem `dmopc17c4p1`.
  prefs: []
  type: TYPE_NORMAL
- en: The Challenge
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: You have a purple ribbon whose length is *n* units. The first unit goes from
    position 0 up to but not including position 1, the second unit goes from position
    1 up to but not including position 2, and so on. You then carry out *q* paint
    strokes, each of which colors a segment of the ribbon blue.
  prefs: []
  type: TYPE_NORMAL
- en: Your goal is to determine the number of units of the ribbon that are still purple
    and the number of units of the ribbon that are now blue.
  prefs: []
  type: TYPE_NORMAL
- en: Input
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The input consists of the following lines:'
  prefs: []
  type: TYPE_NORMAL
- en: A line containing the integer ribbon length *n* and integer number of paint
    strokes *q*, separated by a space. *n* and *q* are each between 1 and 100,000.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*q* lines, one per paint stroke, containing two integers separated by a space.
    The first integer gives the starting position of the paint stroke; the second
    gives the ending position of the paint stroke. The starting position is guaranteed
    to be less than the ending position; each integer is between 0 and *n*. The paint
    stroke goes from the starting position up to but not including the ending position.
    As a quick example here, if a paint stroke has a starting position of 5 and an
    ending position of 12, then the stroke paints the ribbon from position 5 up to
    but not including position 12.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Output
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Output the number of units of the ribbon that are still purple, a space, and
    the number of units of the ribbon that are now blue.
  prefs: []
  type: TYPE_NORMAL
- en: The time limit for solving the test cases is 2 seconds.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring a Test Case
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s look at a small test case. This test case will not only ensure that we’ve
    interpreted the problem correctly but also highlight the perils of a naive algorithm.
    Here it is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Our ribbon’s length is 20, and there are four paint strokes. How much of the
    ribbon do our paint strokes turn blue?
  prefs: []
  type: TYPE_NORMAL
- en: The first paint stroke paints one unit blue, the one that starts at position
    18.
  prefs: []
  type: TYPE_NORMAL
- en: The second paint stroke paints the units of ribbon starting at positions 4,
    5, 6, 7, and so on, all the way up to position 15\. That’s 12 units painted blue
    by this stroke, and 13 blue units in total.
  prefs: []
  type: TYPE_NORMAL
- en: The third paint stroke paints 10 units blue. But all of those units are already
    blue from the second paint stroke! It would be a colossal waste of time indeed
    if we spent time “painting” anything with this paint stroke. Whatever algorithm
    we come up with better not fall into this time-wasting trap.
  prefs: []
  type: TYPE_NORMAL
- en: 'The fourth paint stroke paints 7 units blue. But again: all of these units
    are already blue!'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we’re done painting, and we have 13 blue units. There are 20 – 13 = 7 remaining
    purple units, so the correct output for this test case is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Solving the Problem
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The maximum length of the ribbon is 100,000, and the maximum number of paint
    strokes is 100,000\. Recall algorithm 1 from when we solved Longest Scarf, where
    we learned that an *O*(*mn*) algorithm was too slow with these bounds. Similarly,
    here, an *O*(*nq*) algorithm would be inadequate, as it would not finish within
    the time limit on large test cases.
  prefs: []
  type: TYPE_NORMAL
- en: This means that we cannot afford to process each unit that is painted by each
    paint stroke. It would be nice if we could more easily focus on only the *new*
    units that are painted blue by a paint stroke. Then we could go through each paint
    stroke and add up the number of blue units that it contributes.
  prefs: []
  type: TYPE_NORMAL
- en: Fair enough, but how can we determine the contribution of each paint stroke?
    That’s tricky, because bits and pieces of the next paint stroke may have already
    been painted blue by previous paint strokes.
  prefs: []
  type: TYPE_NORMAL
- en: This situation is made much simpler, however, if we sort the paint strokes first.
    Remember from “n log n Time” earlier in this chapter that sorting is extremely
    fast, taking only *O*(*n* log *n*) time. There’s no efficiency concern in using
    sorting, so let’s understand why sorting helps us here.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sorting the paint strokes from the test case in the prior section gives us
    the following list of paint strokes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Now that the paint strokes are sorted, we can efficiently process them. As we
    do so, we’ll store the rightmost position of any paint stroke that we’ve processed
    so far. We’ll start this rightmost position off at 0 to indicate that we haven’t
    painted anything.
  prefs: []
  type: TYPE_NORMAL
- en: Our first paint stroke paints 14 – 4 = 10 units blue. Now our stored rightmost
    position is 14.
  prefs: []
  type: TYPE_NORMAL
- en: Our second paint stroke paints 12 units blue, yes, but how many of those 12
    does it turn from purple to blue? After all, it overlaps the previous paint stroke,
    so some of these units were blue already. We can calculate the number of new blue
    units by subtracting 14, our stored rightmost position, from 16, the ending position
    of the current paint stroke. This is how we ignore the units already painted blue
    by previous paint strokes. So, there are 16 – 14 = 2 new blue units and 12 blue
    units in total. Crucially, we just figured this out without processing the individual
    units of this paint stroke. Before we continue, don’t forget to update our stored
    rightmost position to 16.
  prefs: []
  type: TYPE_NORMAL
- en: Our third paint stroke is like the second in that it starts prior to our stored
    rightmost position. Unlike the second paint stroke, however, its ending position
    does not extend past our stored rightmost position at all. So, this paint stroke
    adds no new blue units, and our stored rightmost position is still 16\. Again,
    we figured this out without grinding through each of this paint stroke’s positions!
  prefs: []
  type: TYPE_NORMAL
- en: Be careful with the fourth paint stroke. It does *not* add 19 – 16 = 3 new blue
    units. We have to treat this paint stroke differently because its starting position
    is to the right of our stored rightmost position. In this case, we don’t use the
    stored rightmost position at all, calculating instead 19 – 18 = 1 new blue unit,
    and 13 blue units in total. We also update our stored rightmost position to 19.
  prefs: []
  type: TYPE_NORMAL
- en: The only question is how we sort the paint strokes in our Python code. We need
    to sort them by their starting position; if multiple paint strokes have the same
    starting position, then we want to sort those by their ending position.
  prefs: []
  type: TYPE_NORMAL
- en: 'That is, we want to take a list like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'and produce this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Happily, as we discovered in “Task 4: Sort Boxes” in [Chapter 6](ch06.xhtml#ch06),
    the list `sort` method works in exactly this way. When given a list of lists,
    `sort` sorts using the first values in each list; when those values are tied,
    the lists are further sorted using the second values. Check it out:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Algorithm: check. Sorting: check. We’re in great shape! Just one more thing
    we’d like to know before we see the code: what will be its big O efficiency? We
    need to read the *q* queries; that takes *O*(*q*) time. Then we need to sort the
    queries; that takes *O*(*q* log *q*) time. Finally, we need to process the queries;
    that takes *O*(*q*) time. The slowest of these is the *O*(*q* log *q*) time for
    the sorting, so that’s our overall big O efficiency.'
  prefs: []
  type: TYPE_NORMAL
- en: Now we have everything we need for a speedy solution. Check it out in [Listing
    10-2](ch10.xhtml#ch10ex02).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 10-2: Solving Ribbon Painting*'
  prefs: []
  type: TYPE_NORMAL
- en: We read each paint stroke, appending it as a list of two values to our `strokes`
    list ❶. We then sort all of the paint strokes ❷.
  prefs: []
  type: TYPE_NORMAL
- en: 'We next need to process each paint stroke from left to right. There are two
    key variables that drive this processing: variable `rightmost_position` stores
    the rightmost position that we have painted so far, and variable `blue` stores
    the number of units that we have painted blue so far.'
  prefs: []
  type: TYPE_NORMAL
- en: To process a paint stroke, we need to know whether it starts before or after
    our stored rightmost position. Let’s think about each of these cases in turn.
  prefs: []
  type: TYPE_NORMAL
- en: 'First: what do we do when the paint stroke starts before our stored rightmost
    position ❸? This paint stroke might give us some new blue units, but only if it
    extends past our stored rightmost position. If it does, then the new blue units
    are those between the stored rightmost position and the ending position of the
    paint stroke ❹.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Second: what do we do when the paint stroke starts after our stored rightmost
    position ❺? This time, the paint stroke is completely separate from the painting
    we have done so far; this entire paint stroke is a new blue segment. As such,
    the new blue units are those between the ending position and starting position
    of this paint stroke ❻.'
  prefs: []
  type: TYPE_NORMAL
- en: Notice in each case that we also correctly update our stored rightmost position
    so that we’re ready to process any further paint strokes.
  prefs: []
  type: TYPE_NORMAL
- en: That’s a wrap! Guided by our big O analysis, we were able to dismiss an algorithm
    whose implementation we knew would be too slow. We then thought about a second
    algorithm—and before implementing it, we knew it would be plenty fast. It’s time
    to submit our code to the judge and bask in our success.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this chapter, we learned about big O analysis. Big O is an important efficiency
    building block for further study of algorithm design. You’ll see it everywhere:
    in tutorials, in books, probably in your next job interview!'
  prefs: []
  type: TYPE_NORMAL
- en: We also solved two problems where we needed to design very efficient algorithms.
    Not only were we able to do that, but we were also able to use big O to obtain
    a satisfying understanding of exactly why our code was so efficient.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter Exercises
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Here are some exercises for you to try. For each, use big O to determine whether
    your proposed algorithm is efficient enough to solve the problem within the time
    limit. You might also like to implement algorithms that you know are going to
    be too slow. That would give you extra practice solidifying your Python knowledge
    and confirm that your big O analysis was spot-on!
  prefs: []
  type: TYPE_NORMAL
- en: Some of these problems are quite challenging. There are two reasons. First,
    you might agree based on your work throughout the book that coming up with *any*
    algorithm can be tough. Coming up with a faster algorithm can be even tougher.
    Second, this is the end of our time together, but only the beginning of the study
    of algorithms. I hope that these problems both help you appreciate what you’ve
    accomplished and offer evidence that there’s a lot more beyond this book if you
    want it.
  prefs: []
  type: TYPE_NORMAL
- en: DMOJ problem `dmopc17c1p1`, Fujo Neko (The problem talks about using fast input/output.
    Don’t ignore that!)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: DMOJ problem `coci10c1p2`, Profesor
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'DMOJ problem `coci19c4p1`, Pod starim krovovima (Hint: to maximize the number
    of empty glasses, you want to put as much liquid as possible in the biggest glasses.)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: DMOJ problem `dmopc20c1p2`, Victor’s Moral Dilemma
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: DMOJ problem `avocadotrees`, Avocado Trees!
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'DMOJ problem `coci11c5p2`, Eko (Hint: the maximum number of trees is far fewer
    than the maximum number of heights. Consider each tree from tallest to shortest.)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'DMOJ problem `wac6p2`, Cheap Christmas Lights (Hint: don’t try flipping a switch
    each second—how would you know which one to flip? Instead, store them up, and
    use them all as soon as you can shut off all the lights that are on.)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'DMOJ problem `ioi98p3`, Party Lamps (Hint: all that matters for each button
    is whether it is pressed an even or odd number of times.)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Notes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Longest Scarf is originally from the DMOPC ’14 March Contest. Ribbon Painting
    is originally from the DMOPC ’20 November Contest.
  prefs: []
  type: TYPE_NORMAL

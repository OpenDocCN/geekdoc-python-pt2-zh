- en: '12'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '12'
- en: Machine Learning for Data Analysis
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 数据分析中的机器学习
- en: '![](image_fi/book_art/chapterart.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](image_fi/book_art/chapterart.png)'
- en: '*Machine learning* is a method of data analysis where applications leverage
    existing data to discover patterns and make decisions, without being explicitly
    programmed to do so. In other words, the applications learn for themselves, independent
    of human interference. A robust data analysis technique, machine learning is used
    in many fields, including but not limited to classification, clustering, predictive
    analytics, learning associations, anomaly detection, image analysis, and natural
    language processing.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '*机器学习*是一种数据分析方法，应用程序利用现有数据发现模式并做出决策，而无需显式编程。换句话说，应用程序能够自主学习，无需人工干预。作为一种强大的数据分析技术，机器学习在许多领域得到应用，包括但不限于分类、聚类、预测分析、学习关联、异常检测、图像分析和自然语言处理。'
- en: This chapter provides an overview of some fundamental machine learning concepts,
    then explores two machine learning examples in depth. First we’ll perform a sentiment
    analysis, developing a model to predict the number of stars (from one to five)
    associated with a product review. After that, we’ll develop another model to predict
    changes in the price of a stock.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章概述了一些基本的机器学习概念，然后深入探讨了两个机器学习实例。首先，我们将进行情感分析，开发一个模型来预测与产品评论相关的星级评分（从一到五颗星）。之后，我们将开发另一个模型来预测股票价格的变化。
- en: Why Machine Learning?
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么选择机器学习？
- en: Machine learning lets computers perform tasks that would be difficult, if not
    impossible, using conventional programming techniques. For instance, imagine you
    need to build an image-processing application that can distinguish between different
    types of animals based on submitted photos. In this hypothetical scenario, you
    already have a code library that can identify the edges of an object (such as
    an animal) in an image. In this way, you can transform the animal shown in a photo
    into a characteristic set of lines. But how can you programmatically distinguish
    between the lines representing two different animals—say, a cat and a dog?
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习让计算机能够完成一些使用传统编程技术很难甚至不可能完成的任务。例如，假设你需要构建一个图像处理应用程序，能够根据提交的照片区分不同种类的动物。在这个假设的场景中，你已经有了一个代码库，可以识别图像中物体（比如动物）的边缘。通过这种方式，你可以将照片中的动物转换为一组特征性的线条。但是，如何才能程序化地区分两种不同动物的线条——比如一只猫和一只狗呢？
- en: A traditional programming approach would be to manually craft rules that map
    every characteristic line combination to an animal. Unfortunately, this solution
    would require a huge amount of code, and it could completely fail when a new photo
    is submitted whose edges don’t fit one of the manually defined rules. In contrast,
    applications built on machine learning algorithms don’t rely on predefined logic
    but instead hinge on the application’s ability to automatically learn from previously
    seen data. Thus, a machine learning–based photo-tagging application would look
    for patterns in the line combinations derived from previous photos and then make
    predictions about the animals in new photos based on probability statistics.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的编程方法是手动编写规则，将每一种特征线条组合映射到一个动物上。不幸的是，这个方法需要大量的代码，并且在提交一张新照片时，如果该照片的边缘不符合任何手动定义的规则，系统可能完全失效。相比之下，基于机器学习算法的应用程序并不依赖预定义的逻辑，而是依靠应用程序从之前见过的数据中自动学习。因此，基于机器学习的照片标记应用程序会寻找从之前照片中提取的线条组合中的模式，然后根据概率统计对新照片中的动物进行预测。
- en: Types of Machine Learning
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习的类型
- en: Data scientists distinguish between several types of machine learning. The two
    most common are supervised learning and unsupervised learning. In this chapter
    we’ll primarily be concerned with supervised learning, but this section provides
    a brief overview of both types.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家区分了几种不同类型的机器学习。其中最常见的是监督学习和无监督学习。在本章中，我们主要关注监督学习，但本节将简要概述这两种类型。
- en: Supervised Learning
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 监督学习
- en: '*Supervised learning* uses a labeled dataset (referred to as a *training set*)
    to teach a model to yield the desired output when given new, previously unseen
    data. Technically, supervised learning is the technique of inferring a function
    that maps an input to an output based on the training set. You’ve already seen
    an example of supervised learning in Chapter 3, where we used a set of example
    product reviews to train a model to predict whether new product reviews were positive
    or negative.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '*有监督学习*使用标记数据集（称为*训练集*）来教会模型在给定新的、先前未见过的数据时，产生期望的输出。从技术上讲，有监督学习是一种推断函数的技术，该函数基于训练集将输入映射到输出。您在第3章中已经看到了一个有监督学习的例子，我们使用一组示例产品评论训练模型，预测新的产品评论是正面还是负面。'
- en: The input data for a supervised learning algorithm can represent characteristics
    of real-world objects or events. For example, you might use the characteristics
    of homes for sale (square footage, number of bedrooms and bathrooms, and so on)
    as input for an algorithm designed to predict home values. These values would
    be the output of the algorithm. You’d train the algorithm with a collection of
    input-output pairs, consisting of the characteristics of various homes and their
    associated values, then feed it the characteristics of new homes and receive those
    new homes’ estimated values as output.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 有监督学习算法的输入数据可以表示现实世界对象或事件的特征。例如，您可能会使用待售房屋的特征（如面积、卧室和浴室的数量等）作为预测房价的算法的输入。这些房价将是算法的输出。您会用一组输入-输出对来训练该算法，这些输入-输出对由不同房屋的特征及其相关房价组成，然后将新房屋的特征输入给它，并将这些新房屋的估计房价作为输出。
- en: 'Other supervised learning algorithms are designed to work not with characteristics
    but with *observational data*: data gathered through observing an activity or
    behavior. As an example, consider a time series produced by the sensors monitoring
    noise levels at an airport. This observational noise level data might be submitted
    to a machine learning algorithm, along with information such as the time of day
    and day of the week, so that the algorithm can learn to predict the noise levels
    in the coming hours. In this example, the times and days of the week are the input,
    and the noise levels are the output. In other words, the algorithm would be designed
    to predict future observational data.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 其他有监督学习算法设计用来处理的不是特征，而是*观察数据*：通过观察某种活动或行为收集的数据。例如，考虑一个由监控机场噪音水平的传感器生成的时间序列。这些观察到的噪音水平数据可能会提交给一个机器学习算法，同时提供诸如时间和星期几等信息，以便算法能够学习预测未来几个小时的噪音水平。在这个例子中，时间和星期几是输入，噪音水平是输出。换句话说，该算法将被设计用来预测未来的观察数据。
- en: Both the home value predictions and the noise level predictions are examples
    of *regression*, a common supervised learning technique for predicting continuous
    values. The other common supervised learning technique is *classification*, where
    the model assigns one of a finite number of class labels to each input. Distinguishing
    between favorable and unfavorable product reviews is an example of classification,
    as are other *sentiment analysis* applications, where text fragments are identified
    as being either positive or negative. We’ll explore an example of sentiment analysis
    later in this chapter.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 房价预测和噪音水平预测都是*回归*的例子，回归是一种常见的有监督学习技术，用于预测连续值。另一种常见的有监督学习技术是*分类*，它使模型为每个输入分配有限个类别标签中的一个。区分有利和不利的产品评论就是分类的一个例子，其他*情感分析*应用也是如此，其中文本片段被识别为正面或负面。我们将在本章后面探讨一个情感分析的例子。
- en: Unsupervised Learning
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 无监督学习
- en: '*Unsupervised learning* is a machine learning technique in which there’s no
    training stage. You only give the application input data, without any corresponding
    output values to learn from. In that sense, unsupervised machine learning models
    have to work on their own, discovering hidden patterns in the input data.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '*无监督学习*是一种机器学习技术，其中没有训练阶段。您只需提供输入数据，而没有任何相应的输出值供其学习。从这个意义上讲，无监督机器学习模型必须独立工作，发现输入数据中的隐藏模式。'
- en: A great example of unsupervised learning is *association analysis*, where a
    machine learning application identifies items within a set that have an affinity
    for each other. In Chapter 11, you performed an association analysis on a set
    of transaction data, identifying items commonly purchased together. You used the
    Apriori algorithm, which doesn’t require example output data to learn from; instead,
    it takes all the transaction data as an input and searches the transactions for
    frequent itemsets, thus representing learning with no training.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 非监督学习的一个很好的例子是*关联分析*，在这种学习方式中，机器学习应用会识别数据集中彼此之间有亲和力的项目。在第11章中，你对一组交易数据进行了关联分析，识别出了经常一起购买的商品。你使用了Apriori算法，该算法不需要示例输出数据进行学习；它将所有交易数据作为输入，搜索交易中的频繁项集，从而实现无监督学习。
- en: How Machine Learning Works
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习如何工作
- en: 'A typical machine learning pipeline relies on three major components:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的机器学习流程依赖于三个主要组件：
- en: Data to learn from
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习数据
- en: A statistical model to apply to the data
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用于数据的统计模型
- en: New, previously unseen data to process
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要处理的新数据
- en: The following sections take a closer look at each of these components.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 以下部分将更详细地介绍这些组件。
- en: Data to Learn From
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 学习数据
- en: Machine learning is based on the idea that computer systems can learn, so any
    machine learning algorithm requires data to learn from. As we’ve already discussed,
    the nature of this data varies depending on whether the machine learning model
    is supervised or unsupervised. In the case of supervised machine learning, the
    data to learn from takes the form of input-output pairs that train the model to
    later predict outputs based on new inputs. In unsupervised learning, on the other
    hand, the model receives only input data, which it mines for patterns in order
    to produce output.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习基于计算机系统能够学习的理念，因此任何机器学习算法都需要数据来进行学习。正如我们之前讨论的那样，这些数据的性质取决于机器学习模型是监督学习还是非监督学习。在监督学习中，学习的数据以输入-输出对的形式出现，这样可以训练模型根据新的输入预测输出。而在非监督学习中，模型只接收输入数据，通过挖掘其中的模式来生成输出。
- en: 'While all machine learning applications require data to learn from, the requisite
    format of this data may vary from algorithm to algorithm. Many algorithms learn
    from a dataset organized as a table, in which the rows represent various instances,
    such as perhaps individual objects or particular moments in time, and the columns
    represent attributes pertaining to those instances. A classic example is the Iris
    dataset ([https://archive.ics.uci.edu/ml/datasets/Iris](https://archive.ics.uci.edu/ml/datasets/Iris)).
    It has 150 rows, each of which contains observations about a different specimen
    of iris. Here are the first four rows of the dataset:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然所有机器学习应用都需要数据来进行学习，但这些数据的格式可能因算法而异。许多算法从组织成表格的数据集进行学习，其中行代表不同的实例，比如可能是单个对象或特定时间点，而列则代表与这些实例相关的属性。一个经典的例子是鸢尾花数据集（[https://archive.ics.uci.edu/ml/datasets/Iris](https://archive.ics.uci.edu/ml/datasets/Iris)）。它有150行，每一行包含关于不同鸢尾花标本的观察数据。以下是该数据集的前四行：
- en: '[PRE0]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The first four columns represent different attributes, or features, of the
    specimens. The fifth column contains a label for each instance: the iris’s exact
    species name. If you trained a classification model with this dataset, you’d use
    the values in the first four columns as the independent variables, or input, while
    the fifth column would be the dependent variable, or output. After learning from
    this data, ideally the model would be able to classify new iris specimens by species.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 前四列代表不同的属性或特征，描述的是标本的不同特征。第五列包含每个实例的标签：鸢尾花的具体物种名称。如果你用这个数据集训练一个分类模型，你将把前四列的值作为自变量或输入，而第五列则作为因变量或输出。通过从这些数据中学习，理想情况下，模型能够根据物种分类新的鸢尾花标本。
- en: 'Other machine learning algorithms learn from non-tabular data. For example,
    the Apriori algorithm used for association analysis, which we discussed in the
    previous chapter, takes a set of transactions (or baskets) of different sizes
    as input data. Here’s a simple example of such a transaction set:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 其他机器学习算法则从非表格数据中学习。例如，我们在上一章中讨论过的用于关联分析的Apriori算法，它将不同大小的交易（或购物篮）作为输入数据。下面是一个简单的交易集示例：
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Beyond the question of how the machine learning data is structured, the type
    of data used also varies from algorithm to algorithm. As the previous examples
    illustrate, some machine learning algorithms work with numeric or textual data.
    There are also algorithms designed to work with photo, video, or audio data.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 除了机器学习数据如何结构化的问题外，所使用的数据类型也因算法而异。正如前面的例子所示，一些机器学习算法处理的是数值或文本数据。也有一些算法是专门设计来处理照片、视频或音频数据的。
- en: A Statistical Model
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 统计模型
- en: 'Whatever data format the machine learning algorithm requires, the input data
    must be transformed in such a way that it can be analyzed to produce outputs.
    This is where a *statistical model* comes into play: statistics are used to create
    a representation of the data so the algorithm can identify relationships between
    variables, discover insights, make predictions about new data, generate recommendations,
    and so on. Statistical models lie at the heart of any machine learning algorithm.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 无论机器学习算法需要什么样的数据格式，输入数据必须以某种方式进行转换，以便能够分析并生成输出。这时*统计模型*就派上用场了：统计数据被用来创建数据的表示形式，这样算法就能识别变量之间的关系、发现洞察、对新数据进行预测、生成推荐等等。统计模型是任何机器学习算法的核心。
- en: 'For example, the Apriori algorithm uses the support metric as a statistical
    model to find frequent itemsets. (As discussed in Chapter 11, support is the percentage
    of transactions that include an itemset.) In particular, the algorithm identifies
    every possible itemset and calculates the corresponding support metric, then selects
    only those itemsets with a sufficiently high support. Here’s a simple example
    illustrating how the algorithm works behind the scenes:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，Apriori算法使用支持度度量作为统计模型来寻找频繁项集。（如第11章所讨论，支持度是包含某个项集的交易的百分比。）具体来说，算法识别所有可能的项集并计算相应的支持度度量，然后仅选择支持度足够高的项集。以下是一个简单的示例，说明算法背后的工作原理：
- en: '[PRE2]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This example shows only two-item itemsets. In fact, after calculating the support
    for every possible two-item itemset, the Apriori algorithm moves on to analyzing
    every three-item itemset, four-item itemset, and so on. Then the algorithm uses
    the support values for the itemsets of all sizes to generate a list of frequent
    itemsets.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子只展示了两项集合。实际上，在计算每个可能的两项集合的支持度之后，Apriori算法会继续分析每个三项集合、四项集合，依此类推。然后，算法使用所有大小项集的支持度值来生成频繁项集的列表。
- en: Previously Unseen Data
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 之前未见过的数据
- en: In supervised machine learning, once you’ve trained a model on example data,
    you can apply it to new, previously unseen data. Before doing so, however, you
    might want to evaluate the model, which is why it’s common practice to split the
    initial dataset into training and testing sets. The former is the data the model
    learns from, and the latter becomes previously unseen data for testing purposes.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在监督学习中，一旦你在示例数据上训练好模型，就可以将其应用于新的、之前未见过的数据。然而，在这样做之前，你可能需要评估模型，这就是为什么通常做法是将初始数据集拆分为训练集和测试集。前者是模型学习的数据，后者则是用于测试目的的之前未见过的数据。
- en: The testing data still has both input and output, but only the input is shown
    to the model. Then the real output is compared to the output suggested by the
    model to assess the accuracy of its predictions. Once you’ve made sure the model’s
    accuracy is acceptable, you can use fresh input data to do predictive analysis.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 测试数据仍然包含输入和输出，但模型只看到输入数据。然后，将实际输出与模型预测的输出进行比较，以评估其预测的准确性。一旦确保模型的准确性达到可接受的水平，你就可以使用新的输入数据进行预测分析。
- en: In the case of unsupervised learning, there is no distinction between data to
    learn from and previously unseen data. All the data is essentially previously
    unseen, and the model tries to learn from it by analyzing its underlying features.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在无监督学习的情况下，数据没有区分“用于学习的数据”和“之前未见过的数据”。所有数据本质上都是之前未见过的，模型通过分析其潜在特征来尝试从中学习。
- en: 'A Sentiment Analysis Example: Classifying Product Reviews'
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 情感分析示例：对产品评论进行分类
- en: Now that we’ve reviewed the basics of machine learning, you’re ready to conduct
    a sample sentiment analysis. As explained previously, this natural language processing
    technique allows you to programmatically determine whether a piece of writing
    is positive or negative. (More categories, such as neutral, very positive, or
    very negative, are also possibilities in some applications.) In essence, sentiment
    analysis is a form of classification, a supervised machine learning technique
    that sorts data into discrete categories.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经复习了机器学习的基础知识，您可以进行样本情感分析了。如前所述，这种自然语言处理技术允许您以编程方式确定一篇文章是积极的还是消极的。 （在某些应用中，还有更多类别，如中立、非常积极或非常消极。）实质上，情感分析是一种分类形式，是一种监督的机器学习技术，将数据排序为离散类别。
- en: In Chapter 3, you used scikit-learn to perform a basic sentiment analysis on
    a set of product reviews from Amazon. You trained a model to identify whether
    reviews were good or bad. In this section, you’ll expand on the work you did in
    that chapter. You’ll obtain an actual set of product reviews directly from Amazon
    and use it to train a classification model. The goal of the model is to predict
    the star ratings of reviews, on a one to five scale. Thus, the model will sort
    reviews into five possible categories, rather than just two.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在第三章中，您使用scikit-learn对来自亚马逊的一组产品评论执行了基本的情感分析。您训练了一个模型来识别评论是好是坏。在本节中，您将扩展该章节中的工作。您将直接从亚马逊获取一组实际的产品评论，并用它来训练分类模型。该模型的目标是预测评论的星级评分，即一到五级。因此，模型将评论排序为五种可能的类别，而不仅仅是两种。
- en: Obtaining Product Reviews
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 获取产品评论
- en: 'The first step in building the model is to download a set of actual product
    reviews from Amazon. One easy way to do this is to use Amazon Reviews Exporter,
    a Google Chrome browser extension that downloads an Amazon product’s reviews as
    a CSV file. You can install this extension in your Chrome browser with one click
    from this page: [https://chrome.google.com/webstore/detail/amazon-reviews-exporter-c/njlppnciolcibljfdobcefcngiampidm](https://chrome.google.com/webstore/detail/amazon-reviews-exporter-c/njlppnciolcibljfdobcefcngiampidm).'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建模型的第一步是从亚马逊下载一组实际的产品评论。一个简单的方法是使用亚马逊评论导出器，这是一个Google Chrome浏览器扩展程序，可以将亚马逊产品的评论下载为CSV文件。您可以从这个页面用一键安装这个扩展程序到您的Chrome浏览器：[https://chrome.google.com/webstore/detail/amazon-reviews-exporter-c/njlppnciolcibljfdobcefcngiampidm](https://chrome.google.com/webstore/detail/amazon-reviews-exporter-c/njlppnciolcibljfdobcefcngiampidm)。
- en: With the extension installed, open an Amazon product page in Chrome. For this
    example, we’ll use the Amazon page for No Starch Press’s *Python Crash Course*
    by Eric Matthes (https://www.amazon.com/Python-Crash-Course-2nd-Edition/dp/1593279280),
    which at the time of this writing has 445 reviews. To download the book’s reviews,
    find and click the Amazon Reviews Exporter button in your Chrome toolbar.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 安装了该扩展程序后，在Chrome中打开亚马逊产品页面。在这个示例中，我们将使用No Starch Press的 *Python Crash Course*
    由Eric Matthes的亚马逊页面 (https://www.amazon.com/Python-Crash-Course-2nd-Edition/dp/1593279280)，目前有445条评论。要下载这本书的评论，请找到并点击Chrome工具栏中的亚马逊评论导出器按钮。
- en: 'Once you have the reviews in a CSV file, you can read them into a pandas DataFrame
    as follows:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您将评论保存为CSV文件，您可以按以下方式将其读入pandas DataFrame中：
- en: '[PRE3]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Before proceeding, you might want to look at the total number of reviews and
    the first few reviews loaded in the DataFrame:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，您可能想查看评论的总数以及DataFrame中加载的前几条评论：
- en: '[PRE4]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The output should look something like this:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应该看起来像这样：
- en: '[PRE5]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This view shows only the `title` and `rating` fields for each record. We’ll
    treat the review titles as the independent variable in the model (that is, the
    input) and the ratings as the dependent variable (the output). Notice that we’re
    ignoring the full text of each review and focusing just on the titles. This seems
    reasonable for the purposes of training a model for sentiment classification,
    since the title typically represents a summary of the reviewer’s feelings about
    the product. By contrast, the full review text often includes other nonemotional
    information, like a description of the book’s contents.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这个视图仅显示每条记录的`title`和`rating`字段。我们将评论标题视为模型中的独立变量（即输入），评分作为依赖变量（输出）。请注意，我们忽略了每条评论的完整文本，仅关注标题。对于训练情感分类模型来说，这似乎是合理的，因为标题通常代表评论者对产品感受的总结。相比之下，完整的评论文本通常包含其他非情感信息，例如书籍内容的描述。
- en: Cleansing the Data
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 清洗数据
- en: Before you can process real-world data, it almost always requires cleansing.
    In this particular example, you’ll need to filter out reviews that aren’t written
    in English. For that, you’ll need a way to programmatically determine the language
    of each review. There are several Python libraries with language-detection capabilities;
    we’ll use google_trans_new.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在你处理真实世界数据之前，几乎总是需要进行数据清洗。在这个具体的例子中，你需要过滤掉不是用英语写的评论。为此，你需要一种方法来编程地确定每个评论的语言。有几个具有语言检测功能的Python库；我们将使用google_trans_new。
- en: Installing google_trans_new
  id: totrans-56
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 安装google_trans_new
- en: 'Use `pip` to install the google_trans_new library, as follows:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`pip`安装google_trans_new库，如下所示：
- en: '[PRE6]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Before going any further, make sure google_trans_new has fixed the known bug
    that raises a `JSONDecodeError` exception during language detection. For that,
    run the following test in a Python session:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，确保google_trans_new已修复已知的bug，该bug会在语言检测过程中抛出`JSONDecodeError`异常。为此，请在Python会话中运行以下测试：
- en: '[PRE7]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'If this test runs without an error, you’re ready to proceed. If it raises a
    `JSONDecodeError` exception, you’ll need to make some small changes to the library’s
    source code in *google_trans_new.py*. Locate the file with `pip`:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这个测试没有报错，你可以继续进行。如果它抛出了`JSONDecodeError`异常，你需要对库的源代码中的*google_trans_new.py*做一些小修改。用`pip`定位该文件：
- en: '[PRE8]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The command will show some basic information about the library, including the
    location of its source code on your local machine. Go to that location, and open
    *google_trans_new.py* in a text editor. Then find lines 151 and 233, which will
    look like this:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令将显示有关库的一些基本信息，包括其源代码在你本地机器上的位置。前往该位置，用文本编辑器打开*google_trans_new.py*。然后找到第151行和第233行，它们看起来像这样：
- en: '[PRE9]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'and change them to:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将它们更改为：
- en: '[PRE10]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Save the changes, restart your Python session, and rerun the test. It should
    now correctly identify *good* as an English-language word:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 保存更改，重新启动你的Python会话，然后重新运行测试。现在它应该能够正确识别*good*为英语单词：
- en: '[PRE11]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Removing Non-English Reviews
  id: totrans-69
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 移除非英语评论
- en: 'Now you’re ready to detect the language of each review and filter out the reviews
    that aren’t in English. In the following code, you use the `google_translator`
    module from google_trans_new to determine the language of each review title, and
    you store the language in a new column of the DataFrame. It may take a while to
    detect the language of a large number of samples, so be patient when you run the
    code:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你已经准备好检测每个评论的语言并过滤掉不是用英语写的评论。在以下代码中，你使用google_trans_new中的`google_translator`模块来确定每个评论标题的语言，并将语言存储在DataFrame的新列中。检测大量样本的语言可能需要一些时间，所以在运行代码时要耐心：
- en: '[PRE12]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'You first create a `google_translator` object, then use a lambda expression
    to apply the object’s `detect()` method to each review title. You save the results
    to a new column called `lang`. Here you print that column, along with `title`
    and `rating`:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 你首先创建一个`google_translator`对象，然后使用lambda表达式将对象的`detect()`方法应用于每个评论标题。你将结果保存到名为`lang`的新列中。在这里，你打印该列，以及`title`和`rating`：
- en: '[PRE13]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The output will look similar to the following:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将类似于以下内容：
- en: '[PRE14]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Your next step is to filter the dataset, keeping only those reviews that are
    written in English:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 你的下一步是过滤数据集，仅保留用英语写的评论：
- en: '[PRE15]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This operation should reduce the total number of rows in the dataset. To verify
    that it worked, count the number of rows in the updated DataFrame:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 该操作应减少数据集中的总行数。为了验证它是否有效，请计算更新后的DataFrame中的行数：
- en: '[PRE16]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The row count should be less than it was originally because all the non-English
    reviews have been removed.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 行数应该比原来少，因为所有非英语评论已经被移除。
- en: Splitting and Transforming the Data
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 拆分和转换数据
- en: Before you go any further, you need to split the reviews into a training set
    for developing the model and a testing set for evaluating its accuracy. You also
    need to transform the natural language of the review titles into numerical data
    that the model can understand. As you saw in “Transforming Text into Numerical
    Feature Vectors” in Chapter 3, the bag of words (BoW) technique can be used for
    that purpose; to review how it works, refer back to that section.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，你需要将评论分为用于训练模型的训练集和用于评估准确性的测试集。你还需要将评论标题的自然语言转换为模型可以理解的数字数据。正如你在第3章的“将文本转换为数字特征向量”中所看到的，词袋（BoW）技术可以用于此目的；要回顾其工作原理，请参考该章节。
- en: 'The following code uses scikit-learn to both split and transform the data.
    The code follows the same format used in Chapter 3:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码使用scikit-learn进行数据的拆分和转换。代码遵循第3章中使用的相同格式：
- en: '[PRE17]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'To recap, scikit-learn’s `train_test_split()` function randomly splits the
    data into a training set and a testing set ❶, and the library’s `CountVectorizer`
    class has methods for transforming text data into numerical feature vectors ❷.
    The code generates the following structures, implementing the training and testing
    sets as NumPy arrays and their corresponding feature vectors as SciPy sparse matrices:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，scikit-learn的`train_test_split()`函数将数据随机拆分为训练集和测试集❶，该库的`CountVectorizer`类有方法将文本数据转换为数值特征向量❷。代码生成以下结构，将训练集和测试集实现为NumPy数组，并将其相应的特征向量实现为SciPy稀疏矩阵：
- en: '`reviews_train` An array containing the review titles chosen for training'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`reviews_train` 一个包含用于训练的评论标题的数组'
- en: '`reviews_test` An array containing the review titles chosen for testing'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`reviews_test` 一个包含用于测试的评论标题的数组'
- en: '`y_train` An array containing the star ratings corresponding to the reviews
    in `reviews_train`'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`y_train` 一个包含与`reviews_train`中的评论对应的星级评分的数组'
- en: '`y_test` An array containing the star ratings corresponding to the reviews
    in `reviews_test`'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`y_test` 一个包含与`reviews_test`中的评论对应的星级评分的数组'
- en: '`x_train` A matrix containing the set of feature vectors for the review titles
    found in the `reviews_train` array'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`x_train` 一个包含`reviews_train`数组中评论标题对应的特征向量的矩阵'
- en: '`x_test` A matrix containing the set of feature vectors for the review titles
    found in the `reviews_test` array'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`x_test` 一个包含`reviews_test`数组中评论标题对应的特征向量的矩阵'
- en: 'We’re most interested in `x_train` and `x_test`, the numerical feature vectors
    scikit-learn has generated from the review titles using the BoW technique. Each
    of these matrices should include one row per review headline, with this row representing
    the headline’s numerical feature vector. To check the number of rows in the matrix
    generated from the `reviews_train` array, use:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最关心的是`x_train`和`x_test`，这些是scikit-learn从评论标题使用BoW技术生成的数值特征向量。这些矩阵中的每一行都代表一个评论标题的数值特征向量。要检查由`reviews_train`数组生成的矩阵的行数，可以使用：
- en: '[PRE18]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The resulting number should be 80 percent of the total number of English-language
    reviews, since you split the data into training and testing sets using the 80/20
    pattern. The `x_test` matrix should contain the other 20 percent of the feature
    vectors, which you can verify with:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 结果数字应该是英语评论总数的80%，因为你按80/20的模式将数据分为训练集和测试集。`x_test`矩阵应该包含其余20%的特征向量，你可以通过以下方式验证：
- en: '[PRE19]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'You might also want to check the length of the feature vectors in the training
    matrix:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能还想检查训练矩阵中特征向量的长度：
- en: '[PRE20]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'You print the length of just the first row in the matrix, but each row’s length
    is the same. The result may look as follows:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 你打印的是矩阵中第一行的长度，但每一行的长度是相同的。结果可能如下所示：
- en: '[PRE21]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: This means that 442 unique words occur in the training set’s review titles.
    This collection of words is called the *vocabulary dictionary* of the dataset.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着训练集中的评论标题中出现了442个独特的词汇。这个词汇集合被称为数据集的*词汇字典*。
- en: 'If you’re curious, here’s how to print the entire matrix:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你感兴趣的话，下面是如何打印整个矩阵：
- en: '[PRE22]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The result will look something like this:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 结果大概会是这样：
- en: '[PRE23]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Each column of the matrix corresponds to one of the words in the dataset’s
    vocabulary dictionary, and the numbers tell you how many times each word appears
    in any given review title. As you can see, the matrix consists mostly of zeros.
    This is to be expected: the average review title in the example set consists of
    just 5 to 10 words, but the vocabulary dictionary of the entire set consists of
    442 words, meaning that in a typical row, only 5 to 10 elements out of 442 will
    be set to 1 or higher. Nevertheless, this representation of the example data is
    exactly what you need to train a classification model for sentiment analysis.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵的每一列对应数据集词汇字典中的一个词，数字表示该词在任何给定评论标题中出现的次数。如你所见，矩阵大多数情况下是零。这是预期的：示例集中平均的评论标题只有5到10个词，但整个数据集的词汇字典包含442个词，意味着在一个典型的行中，只有5到10个元素会被设置为1或更高。不过，这种示例数据的表示方式正是你训练情感分析分类模型所需要的。
- en: Training the Model
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练模型
- en: 'Now you’re ready to train your model. In particular, you need to train a *classifier*,
    a machine learning model that sorts data into categories, so that it can predict
    the number of stars of a review. For that, you can use scikit-learn’s `LogisticRegression`
    classifier:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经准备好训练模型了。特别地，你需要训练一个*分类器*，这是一种将数据分到不同类别的机器学习模型，以便它能预测评论的星级。为此，你可以使用scikit-learn的`LogisticRegression`分类器：
- en: '[PRE24]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: You import the `LogisticRegression` class and create a `classifier` object.
    Then you train the classifier by passing it the `x_train` matrix (the feature
    vectors of the review titles in the training set) and the `y_train` array (the
    corresponding star ratings).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 你导入`LogisticRegression`类并创建一个`classifier`对象。然后，通过传递`x_train`矩阵（训练集中的评论标题的特征向量）和`y_train`数组（相应的星级评分）来训练分类器。
- en: Evaluating the Model
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 评估模型
- en: 'Now that the model has been trained, you can use the `x_test` matrix to evaluate
    its accuracy, comparing the model’s predicted ratings to the actual ratings in
    the `y_test` array. In Chapter 3, you used the `classifier` object’s `score()`
    method to evaluate its accuracy. Here you’ll use a different evaluation method,
    one that allows for more precision:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，模型已经训练完成，你可以使用`x_test`矩阵来评估它的准确性，将模型的预测评分与`y_test`数组中的实际评分进行比较。在第3章中，你使用了`classifier`对象的`score()`方法来评估其准确性。这里你将使用另一种评估方法，这种方法允许更精确的分析：
- en: '[PRE25]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'You use the classifier’s `predict()` method to predict ratings based on the
    `x_test` feature vectors ❶. Then you test for equivalency between the model’s
    predictions and the actual star ratings ❸. The result of this comparison is a
    Boolean array, where `True` and `False` indicate accurate and inaccurate predictions.
    By taking the arithmetic mean of the array ❷, you get an overall accuracy rating
    for the model. (For the purposes of calculating the mean, each `True` is treated
    as a `1` and each `False` as a `0`.) Printing the result should give you something
    like:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 你使用分类器的`predict()`方法根据`x_test`特征向量❶来预测评分。然后，你测试模型的预测值与实际星级评分之间的等价性❸。这种比较的结果是一个布尔数组，其中`True`和`False`表示准确和不准确的预测。通过对数组❷取算术平均，你可以得到模型的总体准确率。（在计算均值时，每个`True`视为`1`，每个`False`视为`0`。）打印结果应该类似于：
- en: '[PRE26]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'This indicates that the model is 68 percent accurate, meaning that on average
    approximately 7 out of 10 predictions are correct. To get a more fine-grained
    understanding of the model’s accuracy, however, you need to use other scikit-learn
    features to examine more specific metrics. For example, you can study the model’s
    *confusion matrix*, a grid that compares predicted classifications with actual
    classifications. A confusion matrix can help reveal the model’s accuracy within
    each individual class, as well as show whether the model is likely to confuse
    two classes (mislabel one class as another). You can create the confusion matrix
    for your classification model as follows:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这表示模型的准确率为68%，意味着平均每10次预测中大约有7次是正确的。然而，为了更细致地了解模型的准确性，你需要使用其他scikit-learn功能来检查更具体的指标。例如，你可以研究模型的*混淆矩阵*，这是一张将预测分类与实际分类进行比较的网格。混淆矩阵有助于揭示模型在每个单独类别中的准确性，还能显示模型是否容易将两个类别混淆（即将一个类别错误标记为另一个类别）。你可以通过以下方式为你的分类模型创建混淆矩阵：
- en: '[PRE27]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'You import scikit-learn’s `metrics` module, then use the `confusion_matrix()`
    method to generate the matrix. You pass the method the actual ratings of the test
    set (`y_test`), the ratings predicted by your model (`predicted`), and the labels
    corresponding to those ratings. The matrix will look something like this:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 你导入scikit-learn的`metrics`模块，然后使用`confusion_matrix()`方法生成矩阵。你将测试集的实际评分（`y_test`）、模型预测的评分（`predicted`）和对应的标签传递给该方法。矩阵大致如下所示：
- en: '[PRE28]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Here, the rows correspond to actual ratings, and the columns correspond to predicted
    ratings. For example, looking at the numbers in the first row tells you the test
    set contained eight actual one-star ratings, one of which was predicted to be
    a four-star rating and seven of which were predicted to be five-star ratings.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，行对应实际的评分，列对应预测的评分。例如，查看第一行中的数字可以告诉你，测试集包含八个实际的1星评分，其中一个被预测为4星，七个被预测为5星。
- en: The main diagonal of the confusion matrix (top left to bottom right) shows the
    number of correct predictions for each rating level. Examining this diagonal,
    you can see that the model made 54 correct predictions for five-star reviews and
    only 1 correct prediction for four-star reviews. No one-, two-, or three-star
    reviews were correctly identified. Overall, out of a test set of 81 reviews, 55
    were correctly predicted.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵的主对角线（从左上到右下）显示了每个评分级别的正确预测数量。通过检查这条对角线，你可以看到模型为五星级评论做出了54个正确预测，而为四星级评论做出了1个正确预测。没有正确识别出一星、二星或三星级评论。总体而言，在81条测试集评论中，模型正确预测了55条。
- en: 'This outcome raises a number of questions. For one, why does the model only
    work well for five-star reviews? The problem could be that the example dataset
    has only five-star reviews in sufficient quantity. To check if this is the case,
    you might count the rows in each rating group:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 这个结果引发了几个问题。例如，为什么模型仅对五星级评论表现良好？问题可能出在示例数据集中，只有五星级评论的数量足够。为了验证这一点，你可以统计每个评分组中的行数：
- en: '[PRE29]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'You group the original DataFrame containing both the training and testing data
    by the `rating` column and use the `size()` method to get the number of entries
    in each group. The output might look something like this:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 你通过`rating`列对包含训练和测试数据的原始DataFrame进行分组，并使用`size()`方法获取每个组中的条目数。输出结果可能如下所示：
- en: '[PRE30]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'As you can see, this count confirms our hypothesis: there are far more five-star
    reviews than any other rating, suggesting the model didn’t have enough data to
    effectively learn the features of reviews with four stars or lower.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这个统计结果验证了我们的假设：五星级评价远多于其他评分，这表明模型没有足够的数据有效地学习到四星级或更低星级评论的特征。
- en: 'To further explore the accuracy of the model, you might also want to look at
    its main classification metrics, comparing the `y_test` and `predicted` arrays.
    You can do this with the help of the `classification_report()` function found
    in scikit-learn’s `metrics` module:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步探索模型的准确性，你可能还想查看其主要的分类指标，比较`y_test`和`predicted`数组。你可以借助scikit-learn的`metrics`模块中的`classification_report()`函数来实现：
- en: '[PRE31]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The generated report will look something like this:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的报告大致如下所示：
- en: '[PRE32]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: This report shows the summary of the main classification metrics for each class
    of reviews. Here, we’ll focus on support and recall; for more information about
    the other metrics in the report, see [https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 该报告显示了每个评论类别的主要分类指标总结。在这里，我们将重点关注支持度和召回率；关于报告中其他指标的更多信息，请参见[https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report)。
- en: The support metric shows the number of reviews for each class of ratings. In
    particular, it reveals that the reviews are distributed extremely unevenly across
    rating groups, with the test set exhibiting the same tendency as the entire dataset.
    Of the total of 81 reviews, there are 57 five-star reviews and only 2 two-star
    reviews.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 支持度指标显示了每个评分类别的评论数量。特别地，它揭示了评论在评分组之间分布极为不均，测试集表现出与整个数据集相同的趋势。在总共81条评论中，有57条五星级评论，只有2条二星级评论。
- en: Recall shows the ratio of correctly predicted reviews to all the reviews with
    a certain rating. For example, the recall metric for five-star reviews is 0.95,
    meaning the model was 95 percent accurate at predicting five-star reviews, while
    the same metric for four-star reviews is just 0.14\. Since the reviews with the
    other ratings don’t have any correct predictions, the weighted average recall
    for the whole test set is shown to be 0.68 at the bottom of the report. This is
    the same accuracy rating you got near the start of this section.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 召回率显示了正确预测的评论数量与某个评分级别的所有评论数量的比率。例如，五星级评论的召回率为0.95，意味着模型预测五星级评论的准确率为95％，而四星级评论的召回率仅为0.14。由于其他评分的评论没有任何正确预测，因此整个测试集的加权平均召回率为0.68，这也是你在本节开始时得到的准确率。
- en: Taking into consideration all these points, you can reasonably conclude that
    the problem is that the example set you’re using has a highly unequal number of
    reviews in each rating group.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到所有这些因素，你可以合理地得出结论，问题在于你使用的示例集在每个评分组中的评论数量极度不均衡。
- en: Predicting Stock Trends
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预测股票趋势
- en: 'To further explore how machine learning can be applied to data analysis, next
    we’ll create a model for predicting stock market trends. For simplicity, we’ll
    create another classification model: one that predicts whether the price of a
    stock tomorrow will be higher, lower, or the same as it is today. A more sophisticated
    model might instead use regression to predict the actual price of a stock from
    day to day.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步探索机器学习如何应用于数据分析，接下来我们将创建一个用于预测股市趋势的模型。为了简化起见，我们将创建另一个分类模型：该模型预测明天股票的价格是上涨、下跌还是保持不变。一个更复杂的模型可能会使用回归分析来预测股票的实际价格变化。
- en: 'Compared to this chapter’s sentiment analysis example, our stock prediction
    model (and indeed, many models that involve nontextual data) raises a new question:
    how do we decide what data to use as the model’s features, or inputs? For the
    sentiment analysis model, you used the feature vectors generated from the text
    of the review headlines via the BoW technique. The content of such a vector firmly
    depends on the content of the corresponding text. In this sense, the content of
    the vector is predefined, being formed from the features extracted from the corresponding
    text in accordance with a certain rule.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 与本章的情感分析示例相比，我们的股票预测模型（实际上，许多涉及非文本数据的模型）提出了一个新问题：我们如何决定使用哪些数据作为模型的特征或输入？在情感分析模型中，你使用了通过BoW技术从评论标题文本中生成的特征向量。这种向量的内容牢牢依赖于相应文本的内容。从这个意义上讲，向量的内容是预定义的，是根据某种规则从相应文本中提取的特征形成的。
- en: By contrast, when your model involves nontextual data such as stock prices,
    it’s often up to you to decide on, and perhaps even calculate, the set of features
    to be used as the input data for the model. Percentage change in price since the
    previous day, average price over the past week, and total trading volume over
    the two preceding days? Perhaps. Percentage change in price since two days ago,
    average price over the past month, and change in volume since yesterday? Could
    be. Financial analysts use all sorts of metrics such as these, in different combinations,
    as input data for their stock prediction models.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，当你的模型涉及非文本数据（如股票价格）时，通常由你来决定，甚至可能需要计算，作为模型输入数据的特征集合。与前一天相比的价格百分比变化、过去一周的平均价格、前两天的总交易量？可能会是。与两天前相比的价格百分比变化、过去一个月的平均价格、昨天以来的交易量变化？也有可能。金融分析师使用各种这样的指标，并通过不同的组合，作为股票预测模型的输入数据。
- en: In Chapter 10, you learned how to derive metrics from stock market data by calculating
    percentage changes over time, rolling window averages, and the like. We’ll revisit
    some of these techniques later in this section to generate the features for our
    prediction model. But first, we need to obtain some data.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在第10章中，你学会了如何通过计算股市数据的百分比变化、滚动窗口平均值等来得出指标。在本节中，我们将回顾这些技术，生成用于预测模型的特征。但首先，我们需要获取一些数据。
- en: Getting Data
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 获取数据
- en: 'To train your model, you’ll need a year’s worth of data for an individual stock.
    For the purpose of this example, we’ll use Apple (AAPL). Here, you use the yfinance
    library to obtain the company’s stock data for the last year:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练你的模型，你需要获取一年的个股数据。为了这个示例，我们将使用苹果公司（AAPL）。在这里，你将使用yfinance库来获取该公司过去一年的股市数据：
- en: '[PRE33]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: You’ll use the resulting `hist` DataFrame to derive metrics about the stock,
    such as the day-to-day percentage change of the price, and feed those metrics
    to your model. However, you can reasonably assume that there are also external
    factors (that is, information that can’t be derived from the stock data itself)
    that influence Apple’s stock price. For example, the overall performance of the
    wider stock market might affect the performance of an individual stock. Thus,
    it would be interesting to also take into account data about a broader stock market
    index as part of your model.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 你将使用生成的`hist` DataFrame来推导关于股票的指标，例如日常价格变动百分比，并将这些指标输入到模型中。然而，你可以合理假设，也有一些外部因素（即不能从股票数据本身推导出的信息）影响着苹果股票的价格。例如，整体股市表现可能会影响个别股票的表现。因此，将更广泛的股市指数数据作为模型的一部分来考虑，可能会更有趣。
- en: 'One of the most well-known stock market indexes is the S&P 500\. It measures
    the stock performance of 500 large companies. As you saw in Chapter 4, you can
    obtain S&P 500 data in Python via the pandas-datareader library. Here you use
    the library’s `get_data_stooq()` method to retrieve one year’s worth of S&P 500
    data from the Stooq website:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 最著名的股市指数之一是标准普尔500指数。它衡量500家大型公司的股票表现。正如你在第4章中看到的，你可以通过 pandas-datareader 库在
    Python 中获取标准普尔500指数的数据。在这里，你使用该库的 `get_data_stooq()` 方法从 Stooq 网站获取一年的标准普尔500数据：
- en: '[PRE34]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Using Python’s `datetime` module, you define the start and end dates of your
    query relative to the current date ❶. Then you call the `get_data_stooq()` method,
    using `'^SPX'` to request S&P 500 data, and store the result in the `index_data`
    DataFrame ❷.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Python 的 `datetime` 模块，你定义相对于当前日期的查询开始和结束日期 ❶。然后你调用 `get_data_stooq()` 方法，使用
    `'^SPX'` 请求标准普尔500指数数据，并将结果存储在 `index_data` DataFrame 中 ❷。
- en: 'Now that you have both Apple stock figures and S&P 500 index figures for the
    same one-year time period, you can combine the data into a single DataFrame:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你已经有了苹果股票和标准普尔500指数的相同时间段的一年的数据，你可以将这些数据合并为一个单一的 DataFrame：
- en: '[PRE35]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The DataFrames being joined have columns with the same names. To avoid overlap,
    you use the `rsuffix` parameter. It instructs the `join()` method to add the suffix
    `'_idx'` to all the column names from the `index_data` DataFrame.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 连接的 DataFrame 中有列名相同的列。为了避免重叠，你使用 `rsuffix` 参数。它指示 `join()` 方法将后缀 `'_idx'` 添加到
    `index_data` DataFrame 中所有列的名称上。
- en: 'For our purposes, you’ll only be interested in the daily closing prices and
    trading volumes for both Apple and the S&P 500\. Here you filter the DataFrame
    to just those columns:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的目的，你只关心苹果和标准普尔500指数的每日收盘价和交易量。在这里，你将 DataFrame 过滤，只保留这些列：
- en: '[PRE36]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'If you now print the `df` DataFrame, you should see something like this:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你现在打印 `df` DataFrame，你应该看到类似下面的内容：
- en: '[PRE37]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: The DataFrame contains a continuous multivariate time series. The next step
    is to derive features from the data that can be used as input for the machine
    learning model.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 该 DataFrame 包含一个连续的多变量时间序列。下一步是从数据中提取特征，这些特征可以作为机器学习模型的输入。
- en: Deriving Features from Continuous Data
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从连续数据中提取特征
- en: 'You want to train your model on information about the changes in price and
    volume from day to day. As you learned in Chapter 10, you calculate percentage
    changes in continuous time series data by shifting data points in time, bringing
    past data points in line with present data points for the purposes of comparison.
    In the following code, you use `shift(1)` to calculate the percentage change of
    each DataFrame column from one day to the next, saving the results in a new batch
    of columns:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 你希望根据每天的价格和交易量变化来训练模型。正如你在第10章中学到的，通过将数据点向时间上移，你可以计算连续时间序列数据中的百分比变化，将过去的数据点与当前数据点对齐以进行比较。在下面的代码中，你使用
    `shift(1)` 来计算每列 DataFrame 中的百分比变化，并将结果保存在一组新的列中：
- en: '[PRE38]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'For each of the four columns, you divide each data point by the data point
    from the day before, then take the natural logarithm of the result. Remember,
    the natural logarithm provides a close approximation of the percentage change.
    You end up with several new columns:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每一列数据，你需要将每个数据点除以前一天的对应数据点，然后取结果的自然对数。记住，自然对数能较好地近似百分比变化。最终，你将得到几列新的数据：
- en: '`priceRise` The percentage change of Apple’s stock price from one day to the
    next'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`priceRise` 苹果股票价格从一天到另一天的百分比变化'
- en: '`volumeRise` The percentage change of Apple’s trading volume from one day to
    the next'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`volumeRise` 苹果交易量从一天到另一天的百分比变化'
- en: '`priceRise_idx` The percentage change of the S&P 500 index price from one day
    to the next'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`priceRise_idx` 标准普尔500指数价格从一天到另一天的百分比变化'
- en: '`volumeRise_idx` The percentage change of trading volume for the S&P 500 from
    one day to the next'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`volumeRise_idx` 标准普尔500指数交易量从一天到另一天的百分比变化'
- en: 'You can now filter the DataFrame again to only include the new columns:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在可以再次过滤 DataFrame，仅保留新生成的列：
- en: '[PRE39]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The contents of the DataFrame will now look similar to the following:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrame 的内容现在看起来会类似于以下内容：
- en: '[PRE40]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: These columns will become the features, or independent variables, for the model.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 这些列将成为模型的特征，或者独立变量。
- en: Generating the Output Variable
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 生成输出变量
- en: 'The next step is to generate the output variable (also called the target or
    dependent variable) for the existing dataset. This variable should convey what
    happens with the stock’s price on the next day: does it go up, go down, or stay
    the same? You can find this out by looking at the next day’s `priceRise` column,
    which you access through `df[''priceRise''].shift(-1)`. The negative shift moves
    future values backward in time. Based on this shift, you can generate a new column
    with a `-1` if the price goes down, a `0` if the price stays the same, or a `1`
    if the price goes up. Here’s how:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是为现有数据集生成输出变量（也称为目标或因变量）。这个变量应该反映股票第二天的价格变化：是上涨、下跌还是保持不变？你可以通过查看第二天的`priceRise`列来得知，使用`df['priceRise'].shift(-1)`可以获取该列。负向移动将未来的值向后移。基于这种偏移，你可以生成一个新列，若价格下跌则为`-1`，若价格不变则为`0`，若价格上涨则为`1`。操作如下：
- en: '[PRE41]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The algorithm implemented here assumes the following:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这里实现的算法假设以下几点：
- en: A price increase of more than 1 percent in relation to the next day is regarded
    as a rise (`1`).
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 相较于第二天的价格，若价格上涨超过1％，则视为上涨（`1`）。
- en: A price decrease by more than 1 percent in relation to the next day is regarded
    as a fall (`-1`).
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 相较于第二天的价格，若价格下降超过1％，则视为下跌（`-1`）。
- en: The rest is regarded as stagnation (`0`).
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 剩余部分视为停滞（`0`）。
- en: To implement the algorithm, you define a `conditions` list that checks the data
    according to points 1 and 2 ❶ as well as a `choices` list with the values `1`
    and `-1` to indicate a rise or fall in price ❷. Then you feed the two lists to
    NumPy’s `select()` function ❸, which builds an array by selecting values from
    `choices` based on the values in `conditions`. If neither condition is satisfied,
    a default value of `0` is assigned, satisfying point 3\. You store the array in
    a new DataFrame column, `Pred`, that you can use as the output for training and
    testing your model. Essentially, `-1`, `0`, and `1` are now the possible classes
    that the model can choose from when classifying new data.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现该算法，你定义了一个`conditions`列表，用于根据第1点和第2点❶检查数据，同时定义一个`choices`列表，包含`1`和`-1`的值，用于表示价格的上涨或下跌❷。然后，你将这两个列表传递给NumPy的`select()`函数❸，该函数根据`conditions`中的值从`choices`中选择相应的值，构建一个数组。如果没有满足条件的情况，将分配一个默认值`0`，以满足第3点的要求。你将该数组存储在一个新的DataFrame列`Pred`中，可以将其作为训练和测试模型的输出。实际上，`-1`、`0`和`1`现在是模型在对新数据进行分类时可以选择的可能类别。
- en: Training and Evaluating the Model
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练与评估模型
- en: 'To train your model, scikit-learn requires that you present the input and output
    data in separate NumPy arrays. You generate the arrays from the `df` DataFrame
    here:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 要训练你的模型，scikit-learn要求你将输入和输出数据分别呈现为独立的NumPy数组。你可以从这里的`df`数据框生成这些数组：
- en: '[PRE42]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The `features` array now contains the four independent variables (the input),
    and the `target` array contains the one dependent variable (the output). Next,
    you can split the data into training and testing sets and train the model:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，`features`数组包含了四个自变量（输入），`target`数组包含了一个因变量（输出）。接下来，你可以将数据分为训练集和测试集，并训练模型：
- en: '[PRE43]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Just as you did in the sentiment analysis example earlier in the chapter, you
    use scikit-learn’s `train_test_split()` function to divide the dataset according
    to the 80/20 pattern, and you use the `LogisticRegression` classifier to train
    the model. Next, you pass the testing portion of the dataset to the classifier’s
    `score()` method to evaluate its accuracy:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 就像你在本章早些时候的情感分析示例中做的那样，你使用scikit-learn的`train_test_split()`函数按80/20的比例划分数据集，并使用`LogisticRegression`分类器来训练模型。接下来，你将数据集的测试部分传递给分类器的`score()`方法来评估其准确性：
- en: '[PRE44]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The result might look as follows:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 结果可能如下所示：
- en: '[PRE45]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: This indicates the model accurately predicted the next day’s trajectory of Apple
    stock about 62 percent of the time. Of course, you may get a different figure.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明模型大约62%的时间准确地预测了苹果股票第二天的走势。当然，你也可能得到不同的结果。
- en: Summary
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter you learned how some data analysis tasks, such as classification,
    can be accomplished with machine learning, a method that enables computer systems
    to learn from historical data or past experience. In particular, you looked at
    how machine learning algorithms can be used for the NLP task of sentiment analysis.
    You converted text data from Amazon product reviews into machine-readable numerical
    feature vectors, then trained a model to classify reviews according to their star
    ratings. You also learned how to generate features based on numerical stock market
    data, and you used those features to train a model to predict changes in a stock’s
    price.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，你学习了如何使用机器学习来完成一些数据分析任务，例如分类，这是一种使计算机系统能够从历史数据或过去经验中学习的方法。特别地，你了解了如何将机器学习算法应用于自然语言处理任务中的情感分析。你将来自亚马逊产品评论的文本数据转化为机器可读的数值特征向量，然后训练模型根据评论的星级评分进行分类。你还学会了如何基于数值股市数据生成特征，并利用这些特征训练模型来预测股票价格的变化。
- en: There are many possibilities for combining machine learning, statistical methods,
    public APIs, and the capabilities of data structures available in Python. This
    book has shown you some of those possibilities, covering a variety of topics,
    and hopefully has given you the inspiration to find many new innovative solutions.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 结合机器学习、统计方法、公共API和Python中可用的数据结构的可能性有很多。本书展示了其中的一些可能性，涵盖了各种主题，并希望能够激发你找到许多新的创新解决方案。

<html><head></head><body><div id="sbo-rt-content"><h2 class="h2" id="ch02"><span epub:type="pagebreak" id="page_17"/><strong><span class="big">2</span><br/>PROBABILITY</strong></h2>&#13;
<div class="imagec"><img src="Images/common.jpg" alt="image" width="189" height="189"/></div>&#13;
<p class="noindents">Probability affects every aspect of our lives, but in reality, we’re all pretty bad at it, as some of the examples in this chapter demonstrate. We need to study probability to get it right. And we need to get it right because deep learning deals extensively with ideas from probability theory. Probability appears everywhere, from the outputs of neural networks to how often different classes appear in the wild to the distributions used to initialize deep networks.</p>&#13;
<p class="indent">This chapter aims to expose you to the sorts of probability-related ideas and terms you’ll frequently encounter in deep learning. We’ll start with basic ideas about probability and introduce the notion of a random variable. We’ll then jump to the rules of probability. These sections cover the basics that will put us in a position to talk about <em>joint and marginal probabilities</em>. You’ll encounter those terms over and over again as you explore deep learning. Once you understand how to use joint and marginal probabilities, I’ll explain the first of the two chain rules discussed in this book. The second is in <a href="ch06.xhtml#ch06">Chapter 6</a> on differential calculus. We’ll continue our study of probability in <a href="ch03.xhtml#ch03">Chapter 3</a>.</p>&#13;
<h3 class="h3" id="ch02lev1_1"><span epub:type="pagebreak" id="page_18"/>Basic Concepts</h3>&#13;
<p class="noindent">A <em>probability</em> is a number between zero and one that measures how likely something is to happen. If there’s no chance the something will happen, its probability is zero. If it’s absolutely certain that it will happen, its probability is one. We’ll usually express probabilities this way, though in everyday use, people seem to dislike saying things like, “The chance of rain tomorrow is 0.25.” Instead, we say, “The chance of rain tomorrow is 25 percent.” In everyday speech, we convert the fractional probability to a percentage. We’ll do the same in this chapter.</p>&#13;
<p class="indent">The previous paragraph used multiple words associated with probability: <em>likely</em>, <em>chance</em>, and <em>certainty</em>. This is fine in casual use, and even somewhat in deep learning, but when we need to be explicit, we’ll stick with <em>probability</em> and express it numerically in the range zero to one, [0, 1]. The square brackets mean the upper and lower limit are included. If the limit isn’t included in the range, a normal parenthesis is used. For example, the NumPy function <code>np.random.random()</code> returns a pseudorandom floating-point number in the range [0, 1). So, it might return exactly zero, but it will never return exactly one.</p>&#13;
<p class="indent">Next, I’ll introduce the foundational concepts of sample space, events, and random variables. I’ll close with some examples of how humans are bad at probability.</p>&#13;
<h4 class="h4" id="ch02lev2_1">Sample Space and Events</h4>&#13;
<p class="noindent">Put succinctly, a <em>sample space</em> is a discrete set or continuous range that represents all the possible outcomes of an event. An <em>event</em> is something that happens. Usually, it’s the outcome of some physical process, like the flipping of a coin or the roll of a die. All the possible events we’ve grouped together are the sample space we’re working with. Each event is a <em>sample</em> from the sample space, and the sample space represents <em>all</em> the possible events. Let’s look at a few examples.</p>&#13;
<p class="indent">The possible outcomes of a coin flip are heads (H) or tails (T); thus, the sample space for a coin flip is the set {H, T}. The sample space for the roll of a standard die is the set {1, 2, 3, 4, 5, 6} because, discounting the die perching itself on its edge, one of the six faces of the cube will be on top when the die stops moving. These are examples of discrete sample spaces. In deep learning, most sample spaces are continuous and they consist of floating-point numbers, not integers or elements of a set. For example, if a feature input to a neural network can take on any value in the range [0, 1], then [0, 1] is the sample space for that feature.</p>&#13;
<p class="indent">We can ask about the likelihood of certain events happening. For a coin, we can ask, what’s the likelihood the coin will land heads up when flipped? Intuitively, assuming the coin isn’t weighted so that one side is more likely to show up than the other, we say the likelihood of heads is 50 percent. The probability of getting heads is then 0.5 (50 percent as a percentage). We see that the probability of getting tails is also 0.5. Finally, since heads and tails are the only possible outcomes, we see that the sum of the probabilities over <span epub:type="pagebreak" id="page_19"/>all possible results is 0.5 + 0.5 = 1.0. Probabilities <em>always</em> sum to 1.0 over all possible values of the sample space.</p>&#13;
<p class="indent">What’s the probability of rolling a four with a six-sided die? Again, there is no reason to favor one face over another, and only one of the six faces has four dots, so the probability is one out of six, 1/6 ≈ 0.166666 . . . or about 17 percent.</p>&#13;
<h4 class="h4" id="ch02lev2_2">Random Variables</h4>&#13;
<p class="noindent">Let’s denote the outcome of a coin flip by a variable, <em>X</em>. <em>X</em> is what’s called a <em>random variable</em>, a variable that takes on values from its sample space with a certain probability. Because here the sample space is discrete, <em>X</em> is a <em>discrete random variable</em>, which we denote with an uppercase letter. For the coin, the probability of <em>X</em> being heads equals the probability of <em>X</em> being tails, both 0.5. To write this formally, we use</p>&#13;
<p class="center"><em>P</em>(<em>X</em> = heads) = <em>P</em>(<em>X</em> = tails) = 0.5</p>&#13;
<p class="noindent">where <em>P</em> is universally used to indicate the probability of the event in parentheses for the specified random variable. A <em>continuous random variable</em> is a random variable from a continuous sample space, denoted with a lowercase letter, like <em>x</em>. We usually talk about the probability of the random variable being in some range of the sample space, not a particular real number. For example, if we use the NumPy <code>random</code> function to return a value in [0, 1), we can ask: What’s the probability that it will return a value in the range [0, 0.25)? Since any number is as likely to be returned as any other, we say that the probability of being in that range is 0.25 or 25 percent.</p>&#13;
<h4 class="h4" id="ch02lev2_3">Humans Are Bad at Probability</h4>&#13;
<p class="noindent">We’ll dive into the math of probability in the next section. But before then, let’s look at two examples involving probability that show how bad humans can be at it. Both of these examples have stumped experts, not because the experts are somehow lacking, but because our intuitions about probability are often entirely incorrect, and even experts are thoroughly human.</p>&#13;
<h5 class="h5" id="ch02lev3_1">The Monty Hall Dilemma</h5>&#13;
<p class="noindent">This problem is a particular favorite of mine, as it confuses even mathematicians with advanced degrees. The dilemma is taken from an old American game show called <em>Let’s Make a Deal</em>. The original host of the show, Monty Hall, would select a member of the audience and show that person three large closed doors labeled 1, 2, and 3. Behind one of the doors was a new car. Behind the remaining two doors were joke prizes, such as a live goat.</p>&#13;
<p class="indent">The contestant was asked to pick a door. Then, Hall would ask that one of the doors the contestant <em>didn’t</em> pick be opened, naturally one that didn’t have a car behind it. After the audience stopped laughing at whatever joke prize was behind that door, Hall would ask the contestant if they wanted to <span epub:type="pagebreak" id="page_20"/>keep the originally selected door, or if they would rather change their selection to the remaining door. The dilemma is simply that: do they keep their original guess, or do they switch to the remaining door?</p>&#13;
<p class="indent">If you want to think about it for a while, please do. Put the book down, walk around, get out a pencil and some paper, make notes, then, when you have a solution (or give up), read on. . . .</p>&#13;
<p class="indent">Here’s the right answer: change doors. If you do, you’ll win the car 2/3 of the time. If you don’t, you’ll only win the car 1/3 of the time, as that’s the probability of selecting the correct door initially: one correct choice out of three.</p>&#13;
<p class="indent">When Marilyn vos Savant presented this problem in her <em>Parade</em> magazine column in 1990 and stated that the correct solution is to change doors, she was flooded with letters, many from mathematicians, some angry, insisting she was wrong. She wasn’t. One way to see that she was right is to use a computer program to simulate the game. We won’t develop the code for one here, but it isn’t too hard. If you write one and run it, you’ll see the probability of winning when changing doors converges on 2/3 as the number of simulated games increases. However, we can also use common sense and basic ideas about probability to see the solution.</p>&#13;
<p class="indent">First, if we don’t change doors, we know we have a 1/3 probability of winning the car. Now, consider what can happen when we change doors. If we change doors, the only way we can <em>lose</em> is if we happened to select the correct door in the first place. Why? Suppose we initially chose one of the joke prize doors instead. Hall, who knows full well which door the car is behind, will never open the door with the car. Since we selected one of the joke doors already, he’s forced to choose the remaining joke door and open it for us, thereby ensuring the car is behind the only remaining door. If we switch doors, we win. Since there are two doors without the car, our chance of selecting the wrong door initially is 2/3. However, we just saw that if we choose the wrong door initially and switch when given the opportunity, we’ll win the car. Therefore, we have a 2/3 chance of winning the car by changing our guess. The 1/3 probability of losing by changing our initial guess is, of course, the case where we initially selected the correct door.</p>&#13;
<h5 class="h5" id="ch02lev3_2">Cancer or Not?</h5>&#13;
<p class="noindent">This example is found in several popular books about probability and statistics (for instance, <em>More Damned Lies and Statistics</em>, by Joel Best [UC Press, 2004], and <em>The Drunkard’s Walk</em>, by Leonard Mlodinow [Pantheon, 2008]). It’s based on an actual study. The task is to determine the probability that a woman in her 40s has breast cancer if she has a positive mammogram. Note that the numbers that follow might have been accurate when the study was conducted, but they may not be valid now. Please consider them only as an example.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_21"/>We are told the following:</p>&#13;
<ol>&#13;
<li class="noindent">The probability that a randomly selected woman in her 40s has breast cancer is 0.8 percent (8 out of 1,000).</li>&#13;
<li class="noindent">The probability that a woman with breast cancer will have a positive mammogram is 90 percent.</li>&#13;
<li class="noindent">The probability that a woman <em>without</em> breast cancer will have a positive mammogram is 7 percent.</li>&#13;
</ol>&#13;
<p class="indent">A woman comes to the clinic and is screened. The mammogram is positive. What’s the probability, based on what we’ve been told, that she actually has breast cancer?</p>&#13;
<p class="indent">From #1 above, we know that if we select 1,000 women in their 40s at random, 8 of them will have breast cancer (on average). Therefore, of those 8, 90 percent of them (#2 above) will have a positive mammogram. This means 7 women with cancer will have a positive mammogram because 8 × 0.9 = 7.2. This leaves 992 of the original 1,000 who don’t have breast cancer. From #3 above, 992 × 0.07 = 69.4, so 69 women without breast cancer will also have a positive mammogram, giving a total of 7 + 69 = 76 positive mammograms, of which 7 are actual cancer and 69 are false-positive results. Therefore, the probability that a positive mammogram indicates cancer is 7 out of 76 or 7/76 = 0.092—about 9 percent.</p>&#13;
<p class="indent">The median estimate that doctors presented with this problem gave was a probability of cancer of around 70 percent, with over one-third giving an estimate of 90 percent. Probabilities are hard for humans, even for those with a lot of training. The doctors’ mistake wasn’t properly accounting for the probability of a randomly selected woman in her 40s having breast cancer. We’ll see in <a href="ch03.xhtml#ch03">Chapter 3</a> how to calculate this result using Bayes’ theorem, which does take this probability into account.</p>&#13;
<p class="indent">For now, let’s switch from intuition to mathematical formality.</p>&#13;
<h3 class="h3" id="ch02lev1_2">The Rules of Probability</h3>&#13;
<p class="noindent">Let’s get started with the basic rules of probability. These are foundational rules that we’ll need for the remainder of the chapter and beyond. We’ll learn about the probability of events, the sum rule for probabilities, and what we mean by a conditional probability. After that, the product rule will let us tackle the birthday paradox. In the birthday paradox, we’ll see how to calculate the minimum number of people to have together in a room such that the probability of at least two of them sharing a birthday exceeds 50 percent. The answer is fewer than you might think.</p>&#13;
<h4 class="h4" id="ch02lev2_4">Probability of an Event</h4>&#13;
<p class="noindent">We mentioned earlier that the sum of all the probabilities for a sample space is one. This means that the chance of any event from the sample space is <span epub:type="pagebreak" id="page_22"/>always less than or equal to one, since the event came from the sample space, and the sample space encompasses all possible events. This implies, for any event <em>A</em>,</p>&#13;
<div class="imagec" id="ch02equ01"><img src="Images/02equ01.jpg" alt="image" width="405" height="22"/></div>&#13;
<p class="noindent">and, for all events <em>A<sub>i</sub></em> in the sample space,</p>&#13;
<div class="imagec" id="ch02equ02"><img src="Images/02equ02.jpg" alt="image" width="403" height="43"/></div>&#13;
<p class="noindent">where ∑ (sigma) means to sum over the expression on the right for each of the <em>i</em>’s. Think of a <code>for</code> loop in Python with the expression on the right as the body of the loop.</p>&#13;
<p class="indent">If we roll a six-sided die, we intuitively (and correctly) understand that the probability of getting any value is the same: one out of six possibilities, or 1/6. Therefore, <a href="ch02.xhtml#ch02equ01">Equation 2.1</a> tells us that <em>P</em>(1), the probability of rolling a one, is between zero and one. This is true since <img src="Images/022equ01.jpg" alt="image" width="113" height="26"/>. Furthermore, <a href="ch02.xhtml#ch02equ02">Equation 2.2</a> tells us that the sum of the probabilities of all events in the sample space must be one. This is also true for the six-sided die, since <img src="Images/022equ02.jpg" alt="image" width="412" height="26"/> and <img src="Images/022equ03.jpg" alt="image" width="228" height="26"/>.</p>&#13;
<p class="indent">If the probability of an event happening is <em>P(A)</em>, then the probability that event <em>A does not</em> happen is</p>&#13;
<div class="imagec" id="ch02equ03"><img src="Images/02equ03.jpg" alt="image" width="421" height="24"/></div>&#13;
<p class="noindent">with <img src="Images/022equ04.jpg" alt="image" width="41" height="24"/> read as “not <em>A</em>.” <img src="Images/022equ04.jpg" alt="image" width="41" height="24"/> is known as the <em>complement</em> of <em>A</em>. You’ll sometimes see <img src="Images/022equ04.jpg" alt="image" width="41" height="24"/> written as <em>P</em>(¬<em>A</em>) using ¬, the logical symbol for “not.”</p>&#13;
<p class="indent"><a href="ch02.xhtml#ch02equ03">Equation 2.3</a> comes from <a href="ch02.xhtml#ch02equ01">Equation 2.1</a> and <a href="ch02.xhtml#ch02equ02">Equation 2.2</a> because the probability of an event is less than one and the probability of any event from the sample space happening is one, so the probability of events that aren’t <em>A</em> happening must be one minus the probability of event <em>A</em> happening.</p>&#13;
<p class="indent">For example, when rolling a die, the probability of getting a value in [1, 6] is one, but the probability of getting a four is 1/6. So, the chance of <em>not</em> rolling a four is all the probability that remains when the chance of rolling a four is removed,</p>&#13;
<div class="imagec"><img src="Images/022equ05.jpg" alt="image" width="374" height="44"/></div>&#13;
<p class="noindent">meaning we have an 83 percent chance of not rolling a four.</p>&#13;
<p class="indent">What if we roll two dice and sum them? The sample space is the set of integers from 2 through 12. However, each sum is not equally likely in this case, a situation that’s at the core of the casino game craps, for example. We calculate the probabilities of each sum by enumerating all the ways they can happen. By counting the ways events can happen and dividing by the total number of events, we can determine the probability. <a href="ch02.xhtml#ch02tab01">Table 2-1</a> shows all the possible ways to generate each sum.</p>&#13;
<p class="tabcap" id="ch02tab01"><span epub:type="pagebreak" id="page_23"/><strong>Table 2-1:</strong> The Number of Combinations of Two Dice Leading to Different Sums</p>&#13;
<table class="borderta">&#13;
<colgroup>&#13;
<col style="width:10%"/>&#13;
<col style="width:30%"/>&#13;
<col style="width:30%"/>&#13;
<col style="width:30%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr class="borderb">&#13;
<th style="vertical-align: top"><p class="tab"><strong>Sum</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>Combinations</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>Count</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>Probability</strong></p></th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab">2</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1 + 1</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0278</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">3</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1 + 2, 2 + 1</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0556</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab">4</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1 + 3, 2 + 2, 3 + 1</p></td>&#13;
<td style="vertical-align: top"><p class="tab">3</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0833</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">5</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1 + 4, 2 + 3, 3 + 2, 4 + 1</p></td>&#13;
<td style="vertical-align: top"><p class="tab">4</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.1111</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab">6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1 + 5, 2 + 4, 3 + 3, 4 + 2, 5 + 1</p></td>&#13;
<td style="vertical-align: top"><p class="tab">5</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.1389</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">7</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1 + 6, 2 + 5, 3 + 4, 4 + 3, 5 + 2, 6 + 1</p></td>&#13;
<td style="vertical-align: top"><p class="tab">6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.1667</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab">8</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2 + 6, 3 + 5, 4 + 4, 5 + 3, 6 + 2</p></td>&#13;
<td style="vertical-align: top"><p class="tab">5</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.1389</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">9</p></td>&#13;
<td style="vertical-align: top"><p class="tab">3 + 6, 4 + 5, 5 + 4, 6 + 3</p></td>&#13;
<td style="vertical-align: top"><p class="tab">4</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.1111</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab">10</p></td>&#13;
<td style="vertical-align: top"><p class="tab">4 + 6, 5 + 5, 6 + 4</p></td>&#13;
<td style="vertical-align: top"><p class="tab">3</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0833</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">11</p></td>&#13;
<td style="vertical-align: top"><p class="tab">5 + 6, 6 + 5</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0556</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td class="borderb" style="vertical-align: top"><p class="tab">12</p></td>&#13;
<td class="borderb" style="vertical-align: top"><p class="tab">6 + 6</p></td>&#13;
<td class="borderb" style="vertical-align: top"><p class="tab">1</p></td>&#13;
<td class="borderb" style="vertical-align: top"><p class="tab">0.0278</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab"/></td>&#13;
<td style="vertical-align: top"><p class="tab"/></td>&#13;
<td style="vertical-align: top"><p class="tab">36</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.0000</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="indent">In <a href="ch02.xhtml#ch02tab01">Table 2-1</a>, there are 36 possible combinations of the two dice. We see that the most likely sum is 7, since six combinations add to 7. The least likely are 2 and 12; there’s only one way to get either. If there are six ways to get a sum of 7, then the probability of a 7 is “6 out of 36,” or 6/36 ≈ 0.1667. We’ll return to <a href="ch02.xhtml#ch02tab01">Table 2-1</a> later in the next chapter when we discuss probability distributions and Bayes’ theorem. <a href="ch02.xhtml#ch02tab01">Table 2-1</a> illustrates a general rule: if we can enumerate the sample space, then we can calculate the probabilities of specific events.</p>&#13;
<p class="indent">As a final example, if you flip three coins simultaneously, what is the probability of getting no heads, one head, two heads, or three heads? We can enumerate the possible outcomes and see. We get the following:</p>&#13;
<table class="borderta">&#13;
<colgroup>&#13;
<col style="width:10%"/>&#13;
<col style="width:30%"/>&#13;
<col style="width:30%"/>&#13;
<col style="width:30%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr class="borderb">&#13;
<th style="vertical-align: top"><p class="tab"><strong>Heads</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>Combinations</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>Count</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>Probability</strong></p></th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">TTT</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.125</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">1</p></td>&#13;
<td style="vertical-align: top"><p class="tab">HTT, THT, TTH</p></td>&#13;
<td style="vertical-align: top"><p class="tab">3</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.375</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">2</p></td>&#13;
<td style="vertical-align: top"><p class="tab">HHT, HTH, THH</p></td>&#13;
<td style="vertical-align: top"><p class="tab">3</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.375</p></td>&#13;
</tr>&#13;
<tr class="borderb">&#13;
<td style="vertical-align: top"><p class="tab">3</p></td>&#13;
<td style="vertical-align: top"><p class="tab">HHH</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.125</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab"/></td>&#13;
<td style="vertical-align: top"><p class="tab"/></td>&#13;
<td style="vertical-align: top"><p class="tab">8</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.000</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="indent">From this table, we claim that the probability of getting one or two heads in three coin flips is the same: 37.5 percent. Let’s test this with a bit of code:</p>&#13;
<pre>import numpy as np<br/>&#13;
N = 1000000<br/>&#13;
M = 3<br/>&#13;
heads = np.zeros(M+1)<br/>&#13;
for i in range(N):<br/>&#13;
    flips = np.random.randint(0,2,M)<br/>&#13;
    h, _ = np.bincount(flips, minlength=2)<br/>&#13;
    heads[h] += 1<br/>&#13;
<span epub:type="pagebreak" id="page_24"/>prob = heads / N<br/>&#13;
print("Probabilities: %s" % np.array2string(prob))</pre>&#13;
<p class="indent">The code runs 1,000,000 tests (<code>N</code>) simulating the flip of three coins (<code>M</code>). The number of times each test ends up with 0, 1, 2, or 3 heads is stored in <code>heads</code>. Each test selects three values in [0, 1] (<code>flips</code>) and counts how many heads (a zero) show up. We use <code>np.bincount</code> for this and throw away the number of tails. The number of heads is then tallied, and the next set of flips happens.</p>&#13;
<p class="indent">When all <code>N</code> simulations are complete, we convert the number of heads to probabilities by dividing by the number of simulations run (<code>prob</code>). Finally, we print the corresponding probabilities. For zero, one, two, or three heads, a single run returned the following:</p>&#13;
<pre>&#13;
Probabilities: [0.125236, 0.3751, 0.37505, 0.124614]&#13;
</pre>&#13;
<p class="indent">These are quite close to the probabilities we calculated above, so we have confidence that we’re correct.</p>&#13;
<h4 class="h4" id="ch02lev2_5">Sum Rule</h4>&#13;
<p class="noindent">We’ll start with a definition: two events <em>A</em> and <em>B</em> are said to be <em>mutually exclusive</em> if they can’t both happen; either one or the other happens. For example, a coin flip is either heads or tails; it can’t be heads <em>and</em> tails. Mutually exclusive events mean if event <em>A</em> happens, event <em>B</em> is excluded, and vice versa. Additionally, if the probabilities of two events happening are completely unrelated, meaning the probability of <em>A</em> is unaffected by whether <em>B</em> has happened, we say the two events are <em>independent</em>.</p>&#13;
<p class="indent">The sum rule is concerned with the probability of more than one mutually exclusive event happening. It tells us the probability of either event happening. For example, what’s the probability of rolling a four or a five with a standard die? We know the probability of rolling a four is 1/6, as is the probability of rolling a five. Since the events are mutually exclusive, we can intuit that the probability of getting a four <em>or</em> a five is their sum, since four and five as outcomes are both parts of the sample space, and either one or the other happens or neither happens. So, we get the following:</p>&#13;
<div class="imagec" id="ch02equ04"><img src="Images/02equ04.jpg" alt="image" width="674" height="22"/></div>&#13;
<p class="indent">Here ∪ means “or” or “union.” You’ll see ∪ often. For a standard die, the probability of rolling a four or a five is <img src="Images/024equ01.jpg" alt="image" width="89" height="26"/>, or about 33 percent.</p>&#13;
<p class="indent">The sample space of two coin flips is {HH, HT, TH, TT}; therefore, this is the probability of getting two heads or two tails:</p>&#13;
<div class="imagec"><img src="Images/024equ02.jpg" alt="image" width="419" height="43"/></div>&#13;
<p class="indent">There’s more to the sum rule, but before we can see it, we need to consider the product rule.</p>&#13;
<h4 class="h4" id="ch02lev2_6"><span epub:type="pagebreak" id="page_25"/>Product Rule</h4>&#13;
<p class="noindent">The sum rule tells us about the probability of events <em>A</em> or <em>B</em> happening. The product rule tells us the probability of events <em>A and B</em>:</p>&#13;
<div class="imagec" id="ch02equ05"><img src="Images/02equ05.jpg" alt="image" width="506" height="21"/></div>&#13;
<p class="noindent">Here ∩ means “and” or “intersection.”</p>&#13;
<p class="indent">If events <em>A</em> and <em>B</em> are mutually exclusive, we will immediately see that <em>P</em>(<em>A</em> ∩ <em>B</em>) = 0 because if event <em>A</em> happens with probability <em>P</em>(<em>A</em>), then event <em>B</em>’s probability is <em>P</em>(<em>B</em>) = 0, and their product is also zero. The same is true if event <em>B</em> happens; then <em>P</em>(<em>A</em>) = 0.</p>&#13;
<p class="indent">Not all events are mutually exclusive, of course. For example, assume 80 percent of the people in the world have brown eyes and 50 percent are female. What’s the probability of a randomly selected person being a female with brown eyes? Let’s use the product rule,</p>&#13;
<p class="center"><em>P</em>(female, brown-eyed) = <em>P</em>(female)<em>P</em>(brown-eyed) = 0.5(0.8) = 0.4</p>&#13;
<p class="noindent">to see there is a 40 percent chance of a randomly selected person being a brown-eyed female.</p>&#13;
<p class="indent">The product rule makes sense if we think about it a bit. Calculating the fraction of people, which is the probability, who are female won’t change the fraction of those females who are brown-eyed. One event, being female, has no impact on the other event, being brown-eyed.</p>&#13;
<p class="indent">The product rule isn’t limited to only two events. Consider the following. According to insurance companies, the probability of being struck by lightning in any given year, if you live in the US, is about 1/1,222,000, or 0.000082 percent. What’s the probability of being a brown-eyed female and being struck by lightning in any given year, assuming you live in the US? Again, we can use the product rule:</p>&#13;
<div class="imagec"><img src="Images/025equ01.jpg" alt="image" width="667" height="111"/></div>&#13;
<p class="noindent">The population of the United States is about 331,000,000, of which 0.000033 percent are brown-eyed females who’ll be struck by lightning this year: 109 people, by our calculation above. According to the US National Weather Service, about 270 people will be struck by lightning in a given year. As we saw above, 40 percent of those people will be brown-eyed females, which yields 270(0.4) = 108. So, our calculation is entirely believable.</p>&#13;
<h4 class="h4" id="ch02lev2_7">Sum Rule Revisited</h4>&#13;
<p class="noindent">We stated above that there’s more to the sum rule. Let’s see now what we were missing above. <a href="ch02.xhtml#ch02equ04">Equation 2.4</a> gives us the sum rule for mutually exclusive events <em>A</em> and <em>B</em>. What if the events aren’t mutually exclusive? In that case, the sum rule needs to be modified:</p>&#13;
<span epub:type="pagebreak" id="page_26"/>&#13;
<div class="imagec" id="ch02equ06"><img src="Images/02equ06.jpg" alt="image" width="521" height="21"/></div>&#13;
<p class="noindent">Let’s look at an example.</p>&#13;
<p class="indent">An archaeologist has discovered a small cache of 20 ancient coins. He notes that 12 of the coins are Roman and 8 are Greek. He also notes that 6 of the Roman coins and 3 of the Greek coins are silver. The remaining coins are bronze. What’s the probability of selecting a silver or Roman coin from the cache?</p>&#13;
<p class="indent">If we believe that silver and Roman are mutually exclusive, we’d be tempted to say the following:</p>&#13;
<div class="imagec"><img src="Images/026equ01.jpg" alt="image" width="427" height="90"/></div>&#13;
<p class="indent">However, the sum of the two probabilities is <img src="Images/026equ02.jpg" alt="image" width="84" height="26"/>, and we <em>can’t</em> have a probability greater than one. Something is amiss.</p>&#13;
<p class="indent">The problem is that there are Roman coins in the cache that are made of silver. We counted them twice—once in <em>P</em> (silver) and again in <em>P</em>(Roman)—so now we need to subtract them from the overall sum. There are six silver Roman coins. So, the probability of being a silver Roman coin is <em>P</em>(silver and Roman)<img src="Images/026equ03.jpg" alt="image" width="35" height="25"/>. Subtracting that part, we see that the probability of picking a silver coin or a Roman coin is 75 percent:</p>&#13;
<div class="imagec"><img src="Images/026equ04.jpg" alt="image" width="609" height="156"/></div>&#13;
<p class="indent">As with the sum rule, there’s more to the product rule, and we’ll get to that shortly. But first, let’s use the product rule to see if we can solve the birthday paradox.</p>&#13;
<h4 class="h4" id="ch02lev2_8">The Birthday Paradox</h4>&#13;
<p class="noindent">On average, how many people do we need together in a room to have a higher than 50 percent chance that two of them share the same birthday? This problem is known as the <em>birthday paradox</em>. Let’s see if we can use our knowledge of the product rule for probability to see what the solution is.</p>&#13;
<p class="indent">We’ll ignore leap years and state that there are 365 days in a year. Intuitively, we see that the probability of randomly selected people sharing a birthday is one day (the shared birthday) out of 365 possible birthdays in a year. The sample space is 365 days, and the shared birthday is the one day in common. So, we get the following:</p>&#13;
<span epub:type="pagebreak" id="page_27"/>&#13;
<div class="imagec"><img src="Images/027equ01.jpg" alt="image" width="334" height="44"/></div>&#13;
<p class="noindent">They either share a birthday or they don’t: 1 – 1/365 = 365/365 – 1/365 = 364/365. So we get the following:</p>&#13;
<div class="imagec"><img src="Images/027equ02.jpg" alt="image" width="488" height="43"/></div>&#13;
<p class="noindent">Of the 365 days in a year, there is one possible match, leaving 364 days that don’t match.</p>&#13;
<p class="indent">A 0.3 percent chance of randomly selected people sharing a birthday is pretty low. It means if you randomly choose pairs of people and ask if they share a birthday, on average you’ll get three matches in a thousand—not terribly likely.</p>&#13;
<p class="indent">For our calculation, we’ll look at things the other way. We’re looking for the number of people we need together so that the probability of <em>no</em> two people sharing a birthday is below 50 percent.</p>&#13;
<p class="indent">We know the probability that two randomly selected people <em>don’t</em> share a birthday: <img src="Images/027equ03.jpg" alt="image" width="26" height="26"/>. Therefore, if we select two pairs of people at random, the probability that both pairs do not share a birthday is the following:</p>&#13;
<div class="imagec"><img src="Images/027equ04.jpg" alt="image" width="557" height="134"/></div>&#13;
<p class="noindent">Here, we’re using the product rule. Similarly, with three people, <em>(A</em>, <em>B</em>, <em>C</em>), we can form three different pairs, <em>(A</em>, <em>B</em>), (<em>A</em>, <em>C</em>), and (<em>B</em>, <em>C</em>), so we calculate the following:</p>&#13;
<div class="imagec"><img src="Images/027equ05.jpg" alt="image" width="423" height="45"/></div>&#13;
<p class="noindent">For <em>n</em> comparisons, here’s the probability that none share a birthday:</p>&#13;
<div class="imagec" id="ch02equ07"><img src="Images/02equ07.jpg" alt="image" width="497" height="48"/></div>&#13;
<p class="indent">Our task is to find the minimum number of comparisons, <em>n</em>, leading to a probability of no shared birthday &lt; 50 percent, where <em>n</em> is a function of the number of people in the room, <em>m</em>. Why less than 50 percent? Because if we find an <em>n</em> leading to a less than 50 percent probability that there is no <span epub:type="pagebreak" id="page_28"/>shared birthday, the probability that there <em>is</em> a shared birthday must then be &gt; 50 percent.</p>&#13;
<p class="indent">If you pick three people at random, there are three pairs of people to check to see if they share a birthday. If you have four people, there are six pairs. So, the larger the group of people, the more pairs there are. Can we find a rule that maps the number of people, <em>m</em>, to the number of pairs to compare, <em>n</em>? If we have that, we can find the smallest <em>m</em> leading to an <em>n</em> where the probability of <a href="ch02.xhtml#ch02equ07">Equation 2.7</a> is &lt; 50 percent.</p>&#13;
<p class="indent">When we have a set of <em>m</em> unique objects, like people in a room, and we select pairs of them, how many different pairs can we select? In other words, how many combinations of <em>m</em> things are there when taken two at a time? The formula to calculate the number of combinations of <em>m</em> things taken <em>k</em> at a time is this:</p>&#13;
<div class="imagec"><img src="Images/028equ01.jpg" alt="image" width="247" height="49"/></div>&#13;
<p class="noindent">You’ll sometimes hear this referred to as “<em>m</em> choose <em>k</em>,” where, for us, <em>k</em> = 2. Let’s find the number of comparisons we need, <em>n</em>, and use the number of combinations of things taken two at a time to find an <em>m</em> leading to at least <em>n</em> comparisons.</p>&#13;
<p class="indent">A straightforward loop in Python locates the <em>n</em> we need:</p>&#13;
<pre>for n in range(300):<br/>&#13;
    if ((364/365)**n &lt; 0.5):<br/>&#13;
        print(n)<br/>&#13;
        break</pre>&#13;
<p class="noindent">We’re told <em>n</em> = 253. So, we need to make, on average, 253 comparisons, 253 pairs of people, to have a greater than 50 percent chance that one of those pairs shares a birthday. The final step is to find how many combinations of <em>m</em> people taken two at a time are at least 253. A bit of brute force trial and error tells us this:</p>&#13;
<div class="imagec"><img src="Images/028equ02.jpg" alt="image" width="165" height="230"/></div>&#13;
<p class="noindent">We need <em>m</em> = 23 people on average to have a higher than 50 percent chance at least two of them share a birthday. All thanks to the product rule.</p>&#13;
<p class="indent">Is our result reliable or just sleight of hand? Some code can tell us. First, let’s verify via simulation that the probability of randomly picking two people who share a birthday is 0.3 percent:</p>&#13;
<pre><span epub:type="pagebreak" id="page_29"/>match = 0<br/>&#13;
for i in range(100000):<br/>&#13;
    a = np.random.randint(0,364)<br/>&#13;
    b = np.random.randint(0,364)<br/>&#13;
    if (a == b):<br/>&#13;
        match += 1<br/>&#13;
print("Probability of a random match = %0.6f" % (match/100000,))</pre>&#13;
<p class="indent">The code simulates 100,000 random pairs of people, where the random integer in [0, 364] represents the person’s birthday. If the two random birthdays match, <code>match</code> is incremented. After all simulations run, we print the probability. A run of this code produced the following, making our assertion of a 0.3 percent chance believable:</p>&#13;
<pre>&#13;
Probability of a random match = 0.003100&#13;
</pre>&#13;
<p class="indent">What about the number of people to get a &gt; 50 percent chance of sharing a birthday? Here, we have two loops. The first is over the number of people in the room (<code>m</code>), and the second is over the number of simulations for that many people in the room (<code>n</code>). In code, that looks like this:</p>&#13;
<pre>for m in range(2,31):<br/>&#13;
    matches = 0<br/>&#13;
    for n in range(100000):<br/>&#13;
        match = 0<br/>&#13;
        b = np.random.randint(0,364,m)<br/>&#13;
        for i in range(m):<br/>&#13;
            for j in range(m):<br/>&#13;
                if (i != j) and (b[i] == b[j]):<br/>&#13;
                    match += 1<br/>&#13;
        if (match != 0):<br/>&#13;
            matches += 1<br/>&#13;
    print("%2d %0.6f" % (m, matches/100000))</pre>&#13;
<p class="indent">We let <code>m</code> range over 2 to 30 people. For each set of <code>m</code> people, we run 100,000 simulations. For each simulation, we pick a set of birthdays for each person in the room (<code>b</code>) and then compare each person with every other person to see if there’s a matching birthday. If there is, we increment <code>match</code>. If we had at least one match, we increment <code>matches</code> and move to the next simulation. Finally, when all of the simulations for the current number of people in the room are complete, we print the probability of at least a single match.</p>&#13;
<p class="indent">If we run the code and plot the output, we get <a href="ch02.xhtml#ch02fig01">Figure 2-1</a>, where the dashed line is 50 percent. The first point above the dashed line is 23 people, precisely as we calculated.</p>&#13;
<span epub:type="pagebreak" id="page_30"/>&#13;
<div class="image" id="ch02fig01"><img src="Images/02fig01.jpg" alt="image" width="694" height="522"/></div>&#13;
<p class="figcap"><em>Figure 2-1: The probability of a shared birthday as a function of the number of people in a room</em></p>&#13;
<p class="indent">It’s always satisfying to see the simulation line up with the math.</p>&#13;
<h4 class="h4" id="ch02lev2_9">Conditional Probability</h4>&#13;
<p class="noindent">Consider a bag of 10 marbles: 8 red and 2 blue. We know if we pick a marble at random from the bag, we have a 2 out of 10, or 20 percent, chance of picking a blue marble. Say we pick a blue marble. After admiring its pretty shade of blue, we put it back in the bag, shake the bag, and pull out another marble. What’s our chance of picking a blue marble a second time? Again, there are 2 blue marbles and 10 total, so it’s still 20 percent.</p>&#13;
<p class="indent">If the fact that event <em>A</em> happened (here, picking a blue marble that we then returned to the bag) hasn’t affected the probability of a future event <em>B</em>, the two are independent events. Our chance of picking a blue marble a second time is in no way affected by the fact that we previously chose a blue marble. The same is true for a coin flip. The fact that we’ve landed heads up four times in a row has nothing to do with the probability of getting tails on the next flip, assuming it’s a fair coin, i.e., it’s not weighted on one side or two-headed (or two-tailed).</p>&#13;
<p class="indent">Now, consider an alternate scenario. We still have a bag with eight red and two blue marbles. We pick a marble—say it’s red this time—and because we like the color, we keep the marble and put it aside. Now, we pick another marble from the bag. What’s the probability of picking another red marble? Here, things have changed. There are nine marbles now, and seven of them are red. So, our chance of picking a second red marble is now 7 of 9, or <span epub:type="pagebreak" id="page_31"/>78 percent. The possibility of choosing a red marble initially was 8 of 10, or 80 percent. The fact that event <em>A</em> happened, picking a red marble we then kept, has altered the probability of a second event. The two events are no longer independent. The probability of the second event was changed by the first event happening. Notationally, we write <em>P</em><em>(B</em>|<em>A</em>) to mean the probability of event <em>B given</em> event <em>A</em> has happened. This is a <em>conditional probability</em> because it’s conditional on event <em>A</em> happening.</p>&#13;
<p class="indent">Here’s where we update the product rule. The version in <a href="ch02.xhtml#ch02equ05">Equation 2.5</a> assumes that the two events are independent, like being female and having brown eyes. If we have a dependent situation, the rule becomes</p>&#13;
<div class="imagec" id="ch02equ08"><img src="Images/02equ08.jpg" alt="image" width="465" height="21"/></div>&#13;
<p class="noindent">meaning the probability of the two events both happening is the product of the probability of one given the other has happened and the probability of the other.</p>&#13;
<p class="indent">Looking back at our marble example above, we calculated the probability of picking a red marble after already picking and keeping a red marble to be 7 of 9, or about 78 percent. That’s <em>P</em><em>(B</em>|<em>A</em>). For <em>P(A</em>), we need the probability of picking a red marble initially, which we said was 80 percent. Therefore, the probability of picking a red marble that we keep, <em>A</em>, and picking a red marble on a second draw, <em>B</em>, is 62 percent:</p>&#13;
<div class="imagec"><img src="Images/031equ01.jpg" alt="image" width="235" height="134"/></div>&#13;
<p class="indent">If two events are mutually exclusive, <em>P</em><em>(B</em>|<em>A</em>) = <em>P</em>(<em>A</em>|<em>B</em>) = 0. If events <em>A</em> and <em>B</em> are independent, then <em>P</em>(<em>A</em>|<em>B</em>) = <em>P</em>(<em>A</em>) and <em>P</em>(<em>B</em>|<em>A</em>) = <em>P</em>(<em>B</em>) because the conditional event happening or not has no influence on the later event.</p>&#13;
<p class="indent">Finally, note that typically <em>P</em><em>(B</em>|<em>A</em>) ≠ <em>P</em>(<em>A</em>|<em>B</em>), and confusing the two conditional probabilities is a common and often serious error. As we’ll see in <a href="ch03.xhtml#ch03">Chapter 3</a>, something called Bayes’ theorem gives the proper relationship between the conditional probabilities. We’ll encounter conditional probability again when discussing the chain rule for probability.</p>&#13;
<h4 class="h4" id="ch02lev2_10">Total Probability</h4>&#13;
<p class="noindent">If our sample space is separated into disjoint regions, <em>B<sub>i</sub></em> (<em>B</em><sub>1</sub>, <em>B</em><sub>2</sub>, etc.) so that the totality of the sample space is covered by the collection of <em>B<sub>i</sub></em>s and the <em>B</em><sub>i</sub>s don’t overlap, we can calculate the probability of an event over all the partitions as the following:</p>&#13;
<div class="imagec"><img src="Images/031equ02.jpg" alt="image" width="221" height="43"/></div>&#13;
<p class="noindent"><span epub:type="pagebreak" id="page_32"/>Here <em>P</em><em>(A</em>|<em>B<sub>i</sub></em>) is the probability of <em>A</em> given partition <em>B<sub>i</sub></em> and <em>P</em>(<em>B<sub>i</sub></em>) is the probability of partition <em>B<sub>i</sub></em>, which is the amount of the sample space that <em>B<sub>i</sub></em> represents. In this view, <em>P</em><em>(A</em>) is the <em>total probability</em> of <em>A</em> over the partitions, <em>B<sub>i</sub></em>. Let’s see an example of how to use this law.</p>&#13;
<p class="indent">You have three cities, Kish, Kesh, and Kuara, and their populations are 2,000, 1,000, and 3,000, respectively. Additionally, the percentages of people with blue eyes in these cities are 12 percent, 3 percent, and 21 percent, respectively. We want to know the probability that a randomly selected person from among the cities has blue eyes. The cities’ populations affect things, as the probability of having blue eyes varies by city and the cities vary in population. To find <em>P</em>(blue), we use the total probability:</p>&#13;
<div class="imagec"><img src="Images/032equ01.jpg" alt="image" width="310" height="115"/></div>&#13;
<p class="noindent">Here <em>P</em>(blue|Kish) is the probability of having blue eyes given you live in Kish, and <em>P</em> (Kish) is the probability of living in Kish, and so on.</p>&#13;
<p class="indent">We know the necessary quantities to find the total probability. The probability of blue eyes per city is given above, and the probability of living in each city is found from its population and the total population of the three cities:</p>&#13;
<div class="imagec"><img src="Images/032equ02.jpg" alt="image" width="249" height="176"/></div>&#13;
<p>Therefore, <em>P</em>(blue) is</p>&#13;
<div class="imagec"><img src="Images/032equ03.jpg" alt="image" width="460" height="45"/></div>&#13;
<p class="noindent">meaning there is a 15 percent chance a randomly selected inhabitant of the three cities will have blue eyes. Note the sum of the probabilities for selecting the cities: <em>P</em>(Kish) + <em>P</em>(Kesh) + <em>P</em>(Kuara) = 1. This must be the case for the partitioning of the total sample space, all the inhabitants of the cities, to be covered by the partitioning into cities.</p>&#13;
<h3 class="h3" id="ch02lev1_3">Joint and Marginal Probability</h3>&#13;
<p class="noindent">The <em>joint probability</em> of two variables, <em>P</em><em>(X</em> = <em>x</em>, <em>Y</em> = <em>y</em>), is the probability that random variable <em>X</em> will have the value <em>x</em> at the same time random variable <span epub:type="pagebreak" id="page_33"/><em>Y</em> is <em>y</em>. We’ve already seen an example of a joint probability. When we use “and” when calculating a probability, we’re calculating a joint probability. A joint probability is the probability of multiple conditions being true at the same time, which is “and.” The <em>marginal probability</em> is what we get when we calculate the probability of one or more of those conditions without caring about the value of the others; in other words, the probability of a subset of the random variables in the “and.”</p>&#13;
<p class="indent">In this section, we’ll examine joint and marginal probabilities using simple tables. We’ll then introduce the chain rule for probability. This rule lets us break down a joint probability into the product of smaller joint probabilities and conditional probabilities.</p>&#13;
<h4 class="h4" id="ch02lev2_11">Joint Probability Tables</h4>&#13;
<p class="noindent">According to Colour Blind Awareness (<em><a href="http://www.colourblindawareness.org/">http://www.colourblindawareness.org/</a></em>), approximately 1 in 12 men and 1 in 200 women are color-blind. The difference comes from the fact that the affected gene is on the X chromosome, requiring a woman to inherit the recessive gene from both her mother and father. A man need only inherit the gene from one parent.</p>&#13;
<p class="indent">Pretend we survey 1,000 people. We can count the number of people who are male and color-blind, female and color-blind, male and not color-blind, and female and not color-blind. We do this and arrange the data in a table like so:</p>&#13;
<table class="borderta">&#13;
<colgroup>&#13;
<col style="width:25%"/>&#13;
<col style="width:25%"/>&#13;
<col style="width:25%"/>&#13;
<col style="width:25%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr class="borderb">&#13;
<th class="borderr"/>&#13;
<th style="vertical-align: top"><p class="tab"><strong>Color-blind</strong></p></th>&#13;
<th class="borderr" style="vertical-align: top"><p class="tab"><strong>Not color-blind</strong></p></th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td class="borderr" style="vertical-align: top"><p class="tab"><strong>Male</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">42</p></td>&#13;
<td class="borderr" style="vertical-align: top"><p class="tab">456</p></td>&#13;
<td style="vertical-align: top"><p class="tab">498</p></td>&#13;
</tr>&#13;
<tr class="borderb">&#13;
<td class="borderr" style="vertical-align: top"><p class="tab"><strong>Female</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">3</p></td>&#13;
<td class="borderr" style="vertical-align: top"><p class="tab">499</p></td>&#13;
<td style="vertical-align: top"><p class="tab">502</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td class="borderr" style="vertical-align: top"><p class="tab"/></td>&#13;
<td style="vertical-align: top"><p class="tab">45</p></td>&#13;
<td class="borderr" style="vertical-align: top"><p class="tab">955</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1000</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="noindent">Tables like these are known as <em>contingency tables</em>. The tallied data is in the center 2 × 2 numerical portion of the table. The rightmost column is the sum across the rows, and the final row is the sum of the columns. The sum of the final row or column is in the last cell and, by necessity, sums to the 1,000 people we surveyed.</p>&#13;
<p class="indent">We can turn the contingency table into a table of probabilities by dividing each cell by 1,000, the number of people surveyed. Doing this gives us the following:</p>&#13;
<table class="borderta">&#13;
<colgroup>&#13;
<col style="width:25%"/>&#13;
<col style="width:25%"/>&#13;
<col style="width:25%"/>&#13;
<col style="width:25%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr class="borderb">&#13;
<th class="borderr"/>&#13;
<th style="vertical-align: top"><p class="tab"><strong>Color-blind</strong></p></th>&#13;
<th class="borderr" style="vertical-align: top"><p class="tab"><strong>Not color-blind</strong></p></th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td class="borderr" style="vertical-align: top"><p class="tab"><strong>Male</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.042</p></td>&#13;
<td class="borderr" style="vertical-align: top"><p class="tab">0.456</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.498</p></td>&#13;
</tr>&#13;
<tr class="borderb">&#13;
<td class="borderr" style="vertical-align: top"><p class="tab"><strong>Female</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.003</p></td>&#13;
<td class="borderr" style="vertical-align: top"><p class="tab">0.499</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.502</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td class="borderr" style="vertical-align: top"><p class="tab"/></td>&#13;
<td style="vertical-align: top"><p class="tab">0.045</p></td>&#13;
<td class="borderr" style="vertical-align: top"><p class="tab">0.955</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.000</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_34"/>The table is now a joint probability table. With it, we can look up the probability of being male and color-blind. Notationally, we write</p>&#13;
<p class="center"><em>P</em>(sex = male, color-blind = yes) = 0.042</p>&#13;
<p class="noindent">and, similarly, we see that</p>&#13;
<p class="center"><em>P</em>(sex = female, color-blind = no) = 0.499</p>&#13;
<p class="indent">Using the joint probability table, we can predict what we would expect to measure given a random sample of people. For example, if we have a sample of 20,000 people, then, based on our table, we’ll expect to find about 20000(0.042) = 840 color-blind men and about 20000(0.003) = 60 color-blind women.</p>&#13;
<p class="indent">What if we wanted to know the probability of being color-blind regardless of sex? For that, we sum the probabilities along the color-blind column and see that there is a 4.5 percent chance that a randomly selected person is color-blind. Likewise, summing along the row gives us an estimated probability of being female as 50.2 percent. We do need to bear in mind that our table was built from a sample of only 1,000 people. You might guess that if we had instead sampled 100,000 people, our split between male and female would be closer to 50/50, and you’d be right.</p>&#13;
<p class="indent">Calculating the probability of being color-blind or female from the joint probability table is calculating a marginal probability. In the first case, we summed along the column to remove the effect of sex, whereas in the second case, we summed along the row to remove the effect of color-blindness.</p>&#13;
<p class="indent">Mathematically, we get the marginal probabilities by summing across the variables we don’t want. If we have a joint probability table for two variables, like the example above, we get the marginal probabilities by summing:</p>&#13;
<div class="imagec"><img src="Images/034equ01.jpg" alt="image" width="279" height="111"/></div>&#13;
<p class="indent">Using the table above, we can write</p>&#13;
<div class="imagec"><img src="Images/034equ02.jpg" alt="image" width="470" height="68"/></div>&#13;
<p class="noindent">where we sum across sex to remove its effect. Now, let’s explore another table, one with three variables.</p>&#13;
<p class="indent">Sometime during the night of April 14, 1912, the RMS <em>Titanic</em> sank in the North Atlantic on its maiden voyage from England to New York City. Based on a sample of 887 people who were on board the <em>Titanic</em>, we can generate <a href="ch02.xhtml#ch02tab02">Table 2-2</a> showing the joint probability for three variables: survival, sex, and cabin class.</p>&#13;
<p class="tabcap" id="ch02tab02"><span epub:type="pagebreak" id="page_35"/><strong>Table 2-2:</strong> Joint Probability Table for <em>Titanic</em> Passengers</p>&#13;
<table class="bordertb">&#13;
<colgroup>&#13;
<col style="width:20%"/>&#13;
<col style="width:20%"/>&#13;
<col style="width:20%"/>&#13;
<col style="width:20%"/>&#13;
<col style="width:20%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr class="borderb">&#13;
<th class="borderr" style="vertical-align: top"><p class="tab"/></th>&#13;
<th class="borderr" style="vertical-align: top"><p class="tab"/></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>Cabin1</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>Cabin2</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>Cabin3</strong></p></th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td class="borderr" rowspan="2" style="vertical-align: top"><p class="tab"><strong>Dead</strong></p></td>&#13;
<td class="borderr" style="vertical-align: top"><p class="tab"><strong>Male</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.087</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.103</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.334</p></td>&#13;
</tr>&#13;
<tr class="borderb">&#13;
<td class="borderr" style="vertical-align: top"><p class="tab"><strong>Female</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.003</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.007</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.081</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td class="borderr" rowspan="2" style="vertical-align: top"><p class="tab"><strong>Alive</strong></p></td>&#13;
<td class="borderr" style="vertical-align: top"><p class="tab"><strong>Male</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.051</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.019</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.053</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td class="borderr" style="vertical-align: top"><p class="tab"><strong>Female</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.103</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.079</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.081</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="indent">Let’s use <a href="ch02.xhtml#ch02tab02">Table 2-2</a> to calculate some probabilities. Note, we’ll use the values in <a href="ch02.xhtml#ch02tab02">Table 2-2</a>, which are accurate to three decimals. As a result, the overall numbers will be slightly off from the probabilities we’d calculate from the counts, but doing this makes the link between the table and the equations more concrete.</p>&#13;
<p class="indent">First, we can read directly from the table for specific triplets of survived, sex, and cabin class. Here’s an example:</p>&#13;
<p class="center"><em>P</em>(dead, male, cabin3) = 0.334</p>&#13;
<p class="noindent">This means the probability of a randomly selected passenger being a man who was in a third-class cabin and didn’t survive is 33 percent. What about men in first class? That’s in the table too:</p>&#13;
<p class="center"><em>P</em>(dead, male, cabin1) = 0.087</p>&#13;
<p class="noindent">This means that a selected passenger has a 9 percent chance of being a man in first class who died. We can see that class differences, in cabins and society, mattered quite a bit.</p>&#13;
<p class="indent">Let’s use the table to calculate some other joint and marginal probabilities. First, what’s the probability of not surviving? To find it, we need to sum over sex and cabin:</p>&#13;
<div class="imagec" id="ch02equ09"><img src="Images/02equ09.jpg" alt="image" width="603" height="157"/></div>&#13;
<p class="noindent">Here we’ve introduced a shorthand notation for male/female (<em>M</em>/<em>F</em>) and cabin class (1, 2, 3).</p>&#13;
<p class="indent">Let’s calculate the probability of not surviving <em>given</em> the passenger was male, <em>P</em>(dead|<em>M</em>). To do this, we look back to <a href="ch02.xhtml#ch02equ08">Equation 2.8</a>, remembering that the “and” implies a joint probability. We rewrite <a href="ch02.xhtml#ch02equ08">Equation 2.8</a> to solve for <em>P</em>(<em>B</em>|<em>A</em>):</p>&#13;
<div class="imagec"><img src="Images/035equ01.jpg" alt="image" width="163" height="50"/></div>&#13;
<p class="noindent"><span epub:type="pagebreak" id="page_36"/>This is sometimes used to define the conditional probability in the first place. Note, <em>P</em><em>(A</em>, <em>B</em>) means <em>P</em>(<em>A</em> and <em>B</em>)—both are joint probabilities. Using this form, the probability of not surviving given the passenger is male is</p>&#13;
<div class="imagec"><img src="Images/036equ01.jpg" alt="image" width="233" height="50"/></div>&#13;
<p class="noindent">where <em>P</em>(dead, <em>M</em>) is the joint probability of being dead and male, and <em>P</em>(<em>M</em>) is the probability of being male.</p>&#13;
<p class="indent">We need to be careful when thinking about the probabilities. <em>P</em>(dead, <em>M</em>) is not the probability of not surviving if the passenger is male. Instead, it’s the probability of a randomly selected passenger being a male who didn’t survive. What we want is <em>P</em>(dead|<em>M</em>), which is the probability of not surviving given a passenger was male.</p>&#13;
<p class="indent">To get <em>P</em>(dead, <em>M</em>), we need to sum over cabin class:</p>&#13;
<div class="imagec" id="ch02equ10"><img src="Images/02equ10.jpg" alt="image" width="643" height="110"/></div>&#13;
<p class="noindent">To get <em>P</em>(<em>M</em>), we sum over survival and cabin class:</p>&#13;
<div class="imagec" id="ch02equ11"><img src="Images/02equ11.jpg" alt="image" width="594" height="157"/></div>&#13;
<p class="noindent">To finally calculate <em>P</em>(dead|<em>M</em>):</p>&#13;
<div class="imagec"><img src="Images/036equ02.jpg" alt="image" width="390" height="50"/></div>&#13;
<p class="noindent">This tells us that 81 percent of the male passengers didn’t survive.</p>&#13;
<p class="indent">A similar calculation, shown below, tells us the probability of being female and surviving:</p>&#13;
<div class="imagec"><img src="Images/036equ03.jpg" alt="image" width="370" height="50"/></div>&#13;
<p class="noindent">We see that women were far more likely to survive than men. Here’s one instance where the phrase “women and children first” was actually the case. I leave it as an exercise for you to calculate the individual probabilities in <em>P</em>(alive|<em>F</em>).</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_37"/>We’ve calculated <em>P</em>(dead, <em>M</em>), the probability of being a male who did not survive; <em>P</em>(<em>M</em>), the probability of being male; and <em>P</em>(dead|<em>M</em>), the probability of not surviving given being a male. Let’s do one more calculation based on <a href="ch02.xhtml#ch02tab02">Table 2-2</a>. Let’s find <em>P</em>(dead or <em>M</em>), the probability of not surviving, or being male.</p>&#13;
<p class="indent"><a href="ch02.xhtml#ch02equ06">Equation 2.6</a> tells us that this is the probability:</p>&#13;
<div class="imagec"><img src="Images/037equ01.jpg" alt="image" width="420" height="110"/></div>&#13;
<p class="indent">If we look at <a href="ch02.xhtml#ch02equ09">Equation 2.9</a> and <a href="ch02.xhtml#ch02equ11">Equation 2.11</a>, we see that both have the same terms, the very terms summed in <a href="ch02.xhtml#ch02equ10">Equation 2.10</a>. This is why we must subtract <em>P</em>(dead, <em>M</em>) from the calculation of <em>P</em>(dead or <em>M</em>) to avoid double-counting.</p>&#13;
<p class="indent">To summarize, then:</p>&#13;
<ul>&#13;
<li class="noindent">The joint probability is the probability of two or more random variables having a specific set of values. The joint probability is often represented as a table.</li>&#13;
<li class="noindent">The marginal probability for a random variable is found by summing over all the possible values of the other random variables.</li>&#13;
</ul>&#13;
<p class="indent">The product rule with a conditional probability tells us how to calculate the joint probability given a conditional probability and an unconditional probability when we have two random variables. Let’s now see how to use the chain rule for probability to generalize that idea.</p>&#13;
<h4 class="h4" id="ch02lev2_12">Chain Rule for Probability</h4>&#13;
<p class="noindent"><a href="ch02.xhtml#ch02equ08">Equation 2.8</a> tells us how to calculate the joint probability for two random variables in terms of the conditional probability. By using the <em>chain rule for probability</em>, we can expand <a href="ch02.xhtml#ch02equ08">Equation 2.8</a> and calculate the joint probability for more than two random variables.</p>&#13;
<p class="indent">In its generic form, the chain rule for the joint probability of <em>n</em> random variables is as follows:</p>&#13;
<div class="imagec" id="ch02equ12"><img src="Images/02equ12.jpg" alt="image" width="525" height="63"/></div>&#13;
<p class="noindent">Here ⋂ is used to indicate “and” for joint probabilities. <a href="ch02.xhtml#ch02equ12">Equation 2.12</a> looks impressive, but it’s not hard to follow, as we’ll see with a few examples. I need to use ⋂ in the equation for the joint part of the conditional probabilities, but in the examples, I’ll use a comma, and you’ll see the pattern quickly enough.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_38"/>Here’s how the chain rule breaks up a joint probability with three random variables:</p>&#13;
<div class="imagec"><img src="Images/038equ01.jpg" alt="image" width="299" height="68"/></div>&#13;
<p class="indent">The first line says the probability of <em>X</em>, <em>Y</em>, and <em>Z</em> is the product of the probability of <em>X</em> given <em>Y</em> and <em>Z</em> and the probability of <em>Y</em> and <em>Z</em>. This is <a href="ch02.xhtml#ch02equ08">Equation 2.8</a> with <em>X</em> for <em>B</em> and <em>Y</em>, <em>Z</em> for <em>A</em>. The second line applies the chain rule to <em>P</em>(<em>Y</em>, <em>Z</em>) to get <em>P</em>(<em>Y</em>|<em>Z</em>)<em>P</em>(<em>Z</em>). The rule can be applied in sequence, like a chain, hence the name.</p>&#13;
<p class="indent">What about a joint probability with four random variables? We get the following:</p>&#13;
<div class="imagec"><img src="Images/038equ02.jpg" alt="image" width="450" height="115"/></div>&#13;
<p class="indent">Let’s work through an example that uses the chain rule. Say we’re very social and have 50 people at our party. Four of the 50 people have been to Boston in the fall. We pick three people at random. What’s the probability that <em>none</em> of them have been to Boston in the fall?</p>&#13;
<p class="indent">We’ll use <em>A<sub>i</sub></em> to indicate the event of a person who has not been to Boston in the fall. Therefore, what we want to find is <em>P</em>(<em>A</em><sub>3</sub>, <em>A</em><sub>2</sub>, <em>A</em><sub>1</sub>), the probability of three people all of whom have not been to Boston in the fall. The chain rule lets us break this probability up like so:</p>&#13;
<div class="imagec"><img src="Images/038equ04.jpg" alt="image" width="399" height="22"/></div>&#13;
<p class="indent">We can work with the right-hand side of this equation intuitively. Look at <em>P</em>(<em>A</em><sub>1</sub>). This is the probability of picking a random person in the room who has not been to Boston in the fall. Four of the people have, so 46 have not, and we see that <em>P</em>(<em>A</em><sub>1</sub>) = 46/50. Once we have a person picked, we need to know the probability of selecting a second person from the remaining 49, that’s <em>P</em>(<em>A</em><sub>2</sub>|<em>A</em><sub>1</sub>) = 45/49. There are only 49 people left, and we haven’t selected one of the four who has been to Boston in the fall. Finally, we have two people selected, so there are 48 people in the room, 44 of whom have not been to Boston in the fall. This means <em>P</em>(<em>A</em><sub>3</sub>|<em>A</em><sub>2</sub>, <em>A</em><sub>1</sub>) = 44/48.</p>&#13;
<p class="indent">We are now ready to answer our initial question. The probability of selecting three people from the room with none of them having been to Boston in the fall is as follows:</p>&#13;
<div class="imagec"><img src="Images/038equ03.jpg" alt="image" width="399" height="134"/></div>&#13;
<p class="noindent"><span epub:type="pagebreak" id="page_39"/>That’s slightly more than 77 percent.</p>&#13;
<p class="indent">We can check if our calculation is reasonable by simulating many draws of three people. This is the code we need:</p>&#13;
<pre>nb = 0<br/>&#13;
N = 100000<br/>&#13;
for i in range(N):<br/>&#13;
    s = np.random.randint(0,50,3)<br/>&#13;
    fail = False<br/>&#13;
    for t in range(3):<br/>&#13;
        if (s[t] &lt; 4):<br/>&#13;
            fail = True<br/>&#13;
    if (not fail):<br/>&#13;
        nb += 1<br/>&#13;
print("No Boston in the fall = %0.4f" % (nb/N,))</pre>&#13;
<p class="indent">We’ll run 100,000 simulations. Every time we select three people out of 50 who haven’t been to Boston in the fall, we’ll increment <code>nb</code>. We simulate selecting three people by choosing three random integers in the range [0, 50) and putting them in <code>s</code>. Then, we look at each of the three integers, asking if any are less than four. If any are, we say we selected a person who has been to Boston and set <code>fail</code> to <code>True</code>. If none of the three integers are less than four, we were successful with this simulation. When done, we print the fraction of simulations that did sample three people who never went to Boston in the fall.</p>&#13;
<p class="indent">Running this code produced</p>&#13;
<pre>&#13;
No Boston in the fall = 0.7780&#13;
</pre>&#13;
<p class="noindent">which is close enough to our calculated value to give us confidence that we found the correct answer.</p>&#13;
<h3 class="h3" id="ch02lev1_4">Summary</h3>&#13;
<p class="noindent">This chapter introduced the fundamentals of probability. We explored basic concepts of probability, including sample spaces and random variables. We followed with some examples of how poor humans can be at probability. After that, we considered the rules of probability, with examples. The rules led us to joint and marginal probabilities and finally to the chain rule for probabilities.</p>&#13;
<p class="indent">The next chapter continues our tour of probability, starting with probability distributions and how to sample from them and ending with Bayes’ theorem, which shows us correct way to compare conditional probabilities.<span epub:type="pagebreak" id="page_40"/></p>&#13;
</div></body></html>
- en: '3'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Group Comparisons
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/book_art/chapterart.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In this chapter, we’ll discuss how to make intelligent comparisons between
    groups, using examples from business scenarios. We’ll start small by looking at
    one group alone. We’ll see which descriptive statistics most succinctly describe
    it, draw plots that capture its essence, and compare various samples from it.
    We’ll then be ready to reason about samples from two groups. We’ll conclude by
    looking at statistical significance tests: the t-test and the Mann-Whitney U test.'
  prefs: []
  type: TYPE_NORMAL
- en: Reading Population Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s start by reading in some data. This data records measurements of 1,034
    professional baseball players, including their height, weight, and age at the
    time of measurement. You can download this data directly from [https://bradfordtuckfield.com/mlb.csv](https://bradfordtuckfield.com/mlb.csv).
    Its original source is the Statistics Online Computational Resource (SOCR) website
    ([https://web.archive.org/web/20220629205951/https://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights](https://web.archive.org/web/20220629205951/https://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights)).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'In this snippet, we import pandas and use its `read_csv()` method to read in
    our data. This is all simple data ingestion, just as we did in Chapters 1 and
    2. After you run this snippet, you should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The last line of the output shows the *shape* of the data, the number of rows
    and columns in the dataset. We can see that our data has 1,034 rows and 6 columns.
    We have one row for each person who was measured, and one column for each fact
    recorded about each person. These 1,034 people are collectively called our *population*,
    which, in the world of statistics, means any set of similar items that are being
    studied to answer a particular question.
  prefs: []
  type: TYPE_NORMAL
- en: Summary Statistics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Doing exploratory analysis every time we get a new dataset is useful. One thing
    we can do is run `print(mlb.describe())` to see our summary statistics all at
    once:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Plotting the data early and often is also a good idea in any data analysis
    effort. We’ll create a box plot with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Here, we import Matplotlib to create plots. We use its `boxplot()` command to
    create a box plot of all the heights in our population. You can see the results
    in [Figure 3-1](#figure3-1).
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/502888c03/f03001.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3-1: A box plot showing the distribution of heights of our Major League
    Baseball (MLB) population'
  prefs: []
  type: TYPE_NORMAL
- en: This box plot is similar to the box plots we looked at in Chapter 1. Remember
    that box plots show the range and distribution of data. Here, we can see that
    the minimum value of height in the data is around 67, and the maximum is around
    83\. The median (the horizontal line in the middle of the box) is around 74 inches.
    We can see that Matplotlib regards several of the points as outliers, and that’s
    why they’re drawn as circles beyond the range of the vertical lines extending
    from the top and bottom of the box. Box plots provide a simple way to explore
    our population and understand it better.
  prefs: []
  type: TYPE_NORMAL
- en: Random Samples
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In many common scenarios, we’re interested in studying a population, but we
    don’t have access to the full population, so we study a small part, or *sample*,
    instead. For example, medical researchers may want to create a drug that can cure
    a disease for all women over 50 years old. The researchers don’t have a way to
    contact all women in the world who are over 50, so instead they recruit a sample
    of that full population, maybe a few hundred people. They study the effect of
    their drug on this sample. They hope that their sample resembles the full population,
    so that if the drug works on the sample, it will also work on the full population.
  prefs: []
  type: TYPE_NORMAL
- en: Recruiting a sample is something you should do carefully, to make sure the sample
    resembles the full population as much as possible. For example, if you recruit
    participants at an Olympic training facility, your sample will contain people
    who are healthier than average, so you may create a drug that works for extremely
    healthy people but not for the general population. If you recruit participants
    at a Polish community festival, you might create a drug that works for Eastern
    Europeans but not for others. The best way to collect a sample that resembles
    the full population is to take a random sample. By selecting randomly from a full
    population, you expect to have equal likelihood of selecting each different type
    of person.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at samples of our baseball player population, which we can create
    in Python as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Here, we use the convenient pandas `sample()` method. This method randomly selects
    30 baseball players for both of our samples, `sample1` and `sample2`. Setting
    the `random_state` parameter is not necessary. But we set it here because it ensures
    that you’ll get the same results as we do when you run the same code.
  prefs: []
  type: TYPE_NORMAL
- en: You may wonder why we select 30 samples and not 20 or 40 or some other number.
    In fact, we could easily select any other number of samples by changing `n=30`
    to `n=20` or `n=40` or anything else we prefer. When we choose a large `n` for
    our random sample, we expect the sample to closely resemble the full population.
    But sometimes recruiting participants can be challenging, so we want to choose
    a small `n` to avoid the difficulty of recruiting. In the world of statistics,
    choosing *n* = 30 is a common convention; when we choose samples that have at
    least size 30, we feel reasonably confident that our samples are big enough to
    make our statistical calculations give us good results.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s also create a third sample, which we’ll define manually as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We know that `sample1` and `sample2` are random samples from our baseball player
    population, since we created them using `sample()`. But it’s not yet clear where
    the measurements in `sample3` came from. Later, you’ll learn how to use statistical
    tests to reason about whether `sample3` is likely to be a random sample from our
    population of baseball players, or whether it is more likely to be associated
    with a different population, like basketball players or another group. Keep thinking
    about `sample3`, because reasoning about where `sample3` came from (and in general,
    whether two given samples come from the same population) will be the central goal
    of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at a plot of these samples to see whether they resemble each other
    and the full population:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we use the same box plot code we used before, but instead of plotting
    only one dataset, we plot four datasets: the distribution of heights of the full
    population and the distribution of heights of all three samples separately. We
    can see the results in [Figure 3-2](#figure3-2).'
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/502888c03/f03002.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3-2: Box plots of our full MLB population (far left), two samples from
    the population (middle), and a mystery sample that may or may not be from our
    population (right)'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can see that none of these box plots are quite identical, but they definitely
    bear some resemblance to one another. We see some similar median values and 75th
    percentile values, as well as some similar maxima. The similarity in the first
    three box plots should match your intuition: when we take large enough random
    samples from a population, the samples should resemble the population and should
    resemble one another. We can also check simple summary statistics related to each
    sample, like the mean:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Here, we check the mean height in all our samples. The mean height for `sample1`
    is 73.8, while the mean height for `sample2` is 74.4, and the mean height for
    `sample3` is 75.4\. These means are relatively close to the mean height of the
    full population, 73.7\. In this context, the mean height of the full population
    has a special name; it’s called the population’s *expected value*. If we take
    a random sample from our population, we expect that the mean height of our sample
    will be about the same as the population’s expected value for height, 73.7\. At
    least two of our samples are random samples from the population, and we see that
    their means are indeed close to our expected value.
  prefs: []
  type: TYPE_NORMAL
- en: When we look at the box plot of `sample3`, we can see that it doesn’t seem to
    resemble the other three box plots as much as they resemble each other. We may
    interpret this as evidence that it isn’t a random sample from our population of
    baseball players. On the other hand, it doesn’t look different enough from the
    population or other samples that we can be immediately certain that it isn’t a
    random sample from our population. We need to learn more before we can feel certain
    about whether `sample3` is a random draw from our population or whether it comes
    from some other population.
  prefs: []
  type: TYPE_NORMAL
- en: 'So far, we’ve used vague and impressionistic language to talk about our samples:
    they *resemble* each other, and they have means that are *relatively close* or
    *about the same* as our expectations. If we want to make concrete, evidence-based
    decisions, we need to be more precise. In the next section, we’ll explore quantitative
    methods that statisticians have developed for reasoning about the differences
    between groups, including some easy-to-use tests that help us decide whether two
    groups come from the same population.'
  prefs: []
  type: TYPE_NORMAL
- en: Differences Between Sample Data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We saw a difference of about 0.6 inches between `sample1` and `sample2` and
    a difference of more than 1.6 inches between `sample1` and `sample3`. Here’s the
    important question we would like to answer: Do we believe that `sample3` is a
    random sample from the same population as `sample1` and `sample2`? We need a method
    more reliable than intuition to say, for example, that a difference of 0.6 inches
    between sample means is plausible or probable, while a difference of 1.6 inches
    between sample means makes it implausible that the samples come from the same
    population. How big of a difference between sample means would make it implausible
    that two samples come from the same population?'
  prefs: []
  type: TYPE_NORMAL
- en: To answer this question, we need to understand the size differences we should
    expect between random samples from our population. So far, we’ve looked at only
    two random samples from our population. Instead of trying to generalize based
    on only two samples, let’s look at a large collection of samples and see how much
    they tend to differ from one another. This will help us understand which variations
    are plausible and which variations are implausible.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s some code to get a collection of 2,000 sample means and their differences:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'In this snippet, we create the `alldifferences` variable as an empty list.
    Then we create a loop that goes through 1,000 iterations. In each iteration, we
    create two new samples and append the difference between their sample means to
    our `alldifferences` list. The final result is a completely filled-in `alldifferences`,
    a list of 1,000 differences between randomly selected samples. After running this
    snippet, you should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: You can see that the first two samples we checked have means that are about
    0.83 inches apart. The second pair of samples has means that are about 0.3 inches
    apart. The sixth pair of samples has means that are almost a full inch apart from
    each other (about –0.97 inches), while the fifth pair of samples has means that
    are nearly identical, only about 0.07 inches apart. Looking at these 10 numbers,
    we can see that 0.6 is not an implausible difference between two samples from
    our population, since several of our first 10 differences are greater in magnitude
    than 0.6\. However, none of the differences we’ve seen so far are greater than
    1 inch in magnitude, so 1.6 inches is starting to seem more implausible.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can see a fuller representation of our 1,000 differences by drawing a plot
    of the `alldifferences` list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Here, we import the seaborn package because it can make beautiful plots. We
    use its `distplot()` method to plot the differences we find. You can see the results
    in [Figure 3-3](#figure3-3).
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/502888c03/f03003.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3-3: A histogram showing the distribution of differences between mean
    heights of random samples, creating an approximate bell curve pattern'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this histogram, each bar represents a relative frequency; it represents
    how likely each observation is compared to other observations. There’s a high
    bar at the point marked 0 on the x-axis. This indicates a relatively high number
    of differences in our `alldifferences` list that are very close to 0\. A much
    lower bar appears at *x* = 1\. This indicates relatively few cases in which the
    difference between the sample means is about 1\. The full shape of the plot should
    make solid intuitive sense: it’s rare for our random samples to be very different
    from each other, because they’re samples from the same population and we expect
    their means to be roughly the same.'
  prefs: []
  type: TYPE_NORMAL
- en: The shape that the bars make in [Figure 3-3](#figure3-3) resembles a bell. You
    can see that we’ve drawn a line over the bars that shows this general bell shape.
    The curve that this plot approximates is called a *bell curve*. Approximate bell
    curves are found in many situations. One powerful theoretical result in statistics
    is called the *central limit theorem*, and it states that under a certain set
    of common conditions, differences between means of samples will be distributed
    in a shape that’s approximately a bell curve. The technical conditions that make
    this theorem true are that the random samples are independent and *identically
    distributed* (that is, random draws from the same population) and that the population
    has a finite expected value and a finite variance. The fact that we see approximate
    bell curves in so many domains provides evidence that these technical conditions
    are often met.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we know the shape and size of the bell curve in [Figure 3-3](#figure3-3),
    we can reason more accurately about difficult statistical questions. Let’s return
    to the question of `sample3`. Given what we know so far, do we believe that `sample3`
    is a random sample from our population of baseball players? We saw that the difference
    between the mean of `sample3` and the mean of `sample1` is about 1.6 inches. When
    we look at [Figure 3-3](#figure3-3), we can see that the bell curve is extremely
    low there, close to 0\. This means that random samples from our population only
    rarely differ by as much as 1.6 inches. This makes it seem relatively implausible
    that `sample3` is a random sample from our baseball player population. We can
    find out how implausible it is by checking exactly how many of our differences
    have magnitude greater than or equal to 1.6 inches:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: In this snippet, we create `largedifferences`, a list that contains all elements
    of `alldifferences` with magnitude greater than or equal to 1.6\. We then check
    the length of the `largedifferences` list. We find that the list has only eight
    elements, meaning random samples from our `mlb` population have means that differ
    by 1.6 or more only about 8 in 1,000 times, or 0.8 percent of the time. This value,
    0.8 percent or 0.008, is a calculated likelihood. We can think of it as our best
    estimate of the probability that the mean heights of two random samples from the
    `mlb` population differ by 1.6 inches or more. This probability is often called
    a *p-value*, where *p* is short for *probability*.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we assume that `sample3` is a random sample from our `mlb` population, we
    have to believe that this rare difference, something whose extremity occurs less
    than 1 percent of the time, has happened naturally. The low likelihood of this
    event may convince us to reject the idea that `sample3` comes from the same population
    as `sample1`. In other words, the low *p*-value causes us to reject the notion
    that these two groups come from the same population. The lower the *p*-value,
    the more confident we feel about rejecting the notion that the groups come from
    the same population, because low *p*-values require us to believe in more and
    more unlikely coincidences. By contrast, consider how common it is that differences
    between sample means from our population are 0.6 inches or more:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Here, we create `smalldifferences`, a list containing every element of `alldifferences`
    that has magnitude greater than or equal to 0.6 inches. We can see that differences
    of this magnitude occur about 31.4 percent of the time. In this case, we would
    say that our *p*-value is 0.314\. If `sample1` and `sample2` come from the same
    population, we would have to believe that this size of difference, which occurs
    about 31 percent of the time, occurred in our case. It’s not hard to believe that
    something with 31 percent probability occurred, so we conclude that the difference
    between `sample1` and `sample2` is plausible; we’re willing to accept that, though
    not identical, they’re random samples from the same population.
  prefs: []
  type: TYPE_NORMAL
- en: The *p*-values we’ve calculated here have led us to accept the notion that `sample1`
    and `sample2` come from the same population, and to reject the notion that `sample1`
    and `sample3` come from the same population. You can see how important the size
    of a *p*-value is in our efforts to compare groups.
  prefs: []
  type: TYPE_NORMAL
- en: Performing Hypothesis Testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We’ve outlined all the ingredients needed for a method of statistical reasoning
    called *hypothesis testing*. We can formalize this method of reasoning in more
    scientific terms. We’re trying to determine whether `sample3` is a random sample
    from the same population as `sample1`. In scientific terms, we can say that we’re
    considering two separate hypotheses:'
  prefs: []
  type: TYPE_NORMAL
- en: Hypothesis 0 `sample1` and `sample3` are random samples from the same population.
  prefs: []
  type: TYPE_NORMAL
- en: Hypothesis 1 `sample1` and `sample3` are not random samples from the same population.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the common statistical parlance, we call Hypothesis 0 the *null hypothesis*,
    and we call Hypothesis 1 the *alternative hypothesis*. The null hypothesis asserts
    that both samples are randomly drawn from one population (our baseball player
    dataset), with just one mean and one standard deviation. The alternative hypothesis
    asserts that the samples are randomly drawn from two totally different populations,
    each with its own mean, its own standard deviation, and all of its own unique
    characteristics. The way we choose between these two hypotheses is by following
    the same reasoning we followed previously:'
  prefs: []
  type: TYPE_NORMAL
- en: Assume that Hypothesis 0, the null hypothesis, is true.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Find how likely we are to observe sample means that differ by as much as our
    observed sample means, assuming that Hypothesis 0 is true. The likelihood of this
    occurring is called the *p*-value.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the *p*-value is small enough, we reject Hypothesis 0, and we’re therefore
    willing to accept Hypothesis 1.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Notice that step 3 is stated vaguely: it doesn’t specify how small the *p*-value
    should be to justify rejecting the null hypothesis. The reason for this vagueness
    is that there’s no mathematically dictated choice for how small the *p*-value
    needs to be. We can choose whatever level of smallness we think is appropriate
    to justify rejecting Hypothesis 0, based on our own judgment and intuitions. The
    *p*-value size that we believe justifies rejecting Hypothesis 0 is called the
    *significance level*.'
  prefs: []
  type: TYPE_NORMAL
- en: The most common significance level used in empirical research is 5 percent,
    meaning that we consider the rejection of the null hypothesis justified if *p*
    < 0.05\. In the case of `sample1` and `sample3`, we can justify rejecting Hypothesis
    0 at a significance level as low as 1 percent, because we found *p* < 0.01\. When
    we find a *p*-value that’s less than our chosen significance level, we say that
    the difference between our groups is *statistically significant*. The recommended
    practice is to choose the significance level that we want to use before we do
    any calculations; that way, we avoid the temptation to choose a significance level
    that confirms whichever hypothesis we want to be confirmed.
  prefs: []
  type: TYPE_NORMAL
- en: The t-Test
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We don’t have to go through the whole process of calculating means, creating
    a histogram, and manually calculating *p*-values every time we want to do hypothesis
    testing. Statisticians have discovered succinct equations that define how likely
    two groups are to come from the same population. They’ve created a relatively
    simple test called a *t-test* that does the process of hypothesis testing quickly
    and painlessly, without requiring a `for` loop or a histogram. We can do a t-test
    to test our Hypothesis 0 and Hypothesis 1\. We’ll check whether `sample1` and
    `sample2` come from the same population as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we import the `scipy.stats` module. The SciPy package that this module
    is a part of is a popular Python library that includes, among other things, many
    statistical tests that could be useful as you get more advanced in statistics
    and data science. After importing this module, we use its `ttest_ind` command
    to check for differences between our samples. Its output is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Here, the *p*-value is relatively high (about 0.283), certainly higher than
    a 0.05 significance threshold. (It differs a little from the 0.314 *p*-value we
    calculated earlier because that *p*-value calculation method was an approximate
    method, and this one is more mathematically exact.) This high *p*-value indicates
    that it is plausible that these are samples from the same population. This is
    not surprising because we know that they are from the same population (we created
    them ourselves). In this case, we decide not to reject our null hypothesis, and
    we accept (until any other evidence convinces us otherwise) that `sample1` and
    `sample2` come from the same population. You can also run `scipy.stats.ttest_ind(sample1['height'],sample3)`
    to compare `sample1` and `sample3`, and if you do, you’ll find a low *p*-value
    (less than 0.05), which justifies rejecting the null hypothesis that `sample1`
    and `sample3` come from the same population.
  prefs: []
  type: TYPE_NORMAL
- en: 'Several types of t-tests exist, as well as other hypothesis tests besides the
    t-test. The `ttest_ind` command we’ve used so far has an `_ind` suffix to indicate
    that it’s meant to be used for independent samples. Here, *independent* means
    just what we would expect: no meaningful, consistent relationship exists between
    the individuals in one sample and the individuals in the other—the samples consist
    of different people who were randomly selected.'
  prefs: []
  type: TYPE_NORMAL
- en: If we have *related* rather than independent samples, we can use another command,
    `scipy.stats.ttest_rel`, which performs another type of t-test that is mathematically
    a little different from `ttest_ind`. The `ttest_rel` command would be appropriate
    when observations in different samples have a meaningful relationship to each
    other—for example, if they’re two different exam scores for the same student,
    or two different medical test results for the same patient.
  prefs: []
  type: TYPE_NORMAL
- en: Another type of t-test, the *Welch’s t-test*, is designed for comparing samples
    when we don’t want to assume that the samples have equal variance. You can implement
    Welch’s t-test in Python by adding `equal_var=False` to the t-test command.
  prefs: []
  type: TYPE_NORMAL
- en: 'The t-test is a *parametric test*, meaning that it relies on assumptions about
    the distribution of the data in our population. The t-test relies on several technical
    assumptions: first, that the groups being compared should have sample means that
    follow a bell curve; second, that the variances of the groups being compared should
    be identical (unless using Welch’s t-test); and third, that the two groups are
    independent of each other. If these assumptions are not met, the t-test is not
    completely accurate, though it’s rarely too far from the truth even if the assumptions
    are not met.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In some cases, we’d prefer to perform hypothesis testing with a test that didn’t
    make these strong assumptions that may not be true. If so, we can rely on a body
    of knowledge called *nonparametric statistics*, which provides tools for hypothesis
    testing and other statistical reasoning that make fewer assumptions about the
    distribution of our data (for example, we don’t need to work with populations
    whose sample means follow bell curves). One hypothesis test from nonparametric
    statistics is called the *Mann-Whitney U test* (or the *Wilcoxon rank-sum test*),
    and we can implement it easily in Python as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: This test requires only one line, since the SciPy package includes an implementation
    of the Mann-Whitney U test. Just like the t-test, all we need to input is the
    data we’re comparing, and the code will output a *p*-value. If you want to have
    a deep understanding of the various kinds of hypothesis tests and exactly when
    to use them, you should read some advanced theoretical statistics textbooks. For
    now, the simple independent sample t-test we’ve used is quite robust and should
    work in most practical scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Nuances of Hypothesis Testing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Hypothesis testing using a null hypothesis and a t-test is common enough to
    be called *popular*, but it’s not as beloved as most popular things are. Students
    tend to dislike it because it’s not intuitive to most people, and it requires
    some tortured reasoning to understand. Teachers sometimes dislike it because their
    students dislike it and struggle to learn it. Many methodological researchers
    find it irritating because it’s so common at all levels for people to misunderstand
    and misinterpret t-tests, *p*-values, and hypothesis tests in general. The antipathy
    toward hypothesis testing has even led some respected scientific journals to ban
    it from their publications, although this has been rare.
  prefs: []
  type: TYPE_NORMAL
- en: Most of the negative feelings toward hypothesis testing are the result of misunderstanding.
    Researchers misunderstand some nuances of hypothesis testing and misuse it, and
    then mistakes in research result, which methodological sticklers resent. Since
    these misunderstandings are common even among professionals, it’s worthwhile to
    mention some of them here and try to explain nuances that will help you avoid
    some of these same mistakes.
  prefs: []
  type: TYPE_NORMAL
- en: 'One important point to remember is what a *p*-value tells you: it tells you
    the likelihood of observing data, after assuming a null hypothesis to be true.
    People often think or wish it told them the converse: the likelihood of a hypothesis’s
    truth, given some observed data. Always remember that a *p*-value should not be
    interpreted directly as a probability of a hypothesis being true. So, when we
    see that the *p*-value for comparing the heights of `sample1` and `sample3` is
    *p* = 0.008, we can’t say, “These samples have only a 0.8 percent probability
    of coming from the same population,” nor can we say, “The null hypothesis has
    a 0.8 percent probability of being true.” We can say only, “If the null hypothesis
    is true, something with 0.8 percent probability occurred.” This enables us to
    decide whether to reject the null hypothesis, but it doesn’t enable us to say
    exactly how likely either hypothesis is to be true.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Another important nuance is the difference between accepting a hypothesis and
    failing to reject it. Hypothesis testing has only two possible outcomes: either
    we reject a null hypothesis, or we decide not to reject the null hypothesis. Failing
    to reject something is not quite the same as wholeheartedly accepting it, and
    just because a *p*-value is not below a significance threshold does not mean that
    two groups are certainly the same. Just because one t-test fails to lead to a
    rejection of the null hypothesis does not mean that the null hypothesis is certainly
    true.'
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, just because one *p*-value seems to justify a rejection of a null
    hypothesis does not mean that the null hypothesis is certainly false. This is
    especially true when we have limited data; difficult, noisy measurements; or a
    reason to doubt our measurements. Hypothesis testing does not let us take uncertain
    data and have perfect certainty about hypotheses. Rather, it provides one piece
    of evidence that we have to understand properly and then weigh together with a
    great deal of other evidence.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another important concept to remember is the Anna Karenina principle. Leo Tolstoy
    wrote in *Anna Karenina* that “all happy families are alike; each unhappy family
    is unhappy in its own way.” Statistics has an analogous principle: all acceptances
    of the null hypothesis are alike, but each rejection of the null hypothesis happens
    for a different reason. The null hypothesis states that two samples are random
    draws from the same population. If we reject the null hypothesis, any one or more
    of a number of things could be true: our two samples could be random draws from
    different populations, or both could be samples from the same population but not
    randomly selected, or a source of sampling bias could be present, or blind luck
    might be occurring. Just because we are confident about rejecting the null hypothesis
    doesn’t mean we can be confident about which part of the null hypothesis is incorrect.
    As empirical researchers like to say, “Further research is needed.”'
  prefs: []
  type: TYPE_NORMAL
- en: A final nuance to remember is the difference between *statistical significance*
    and *practical significance*. It’s possible for one sample of athletes to have
    mean height 73.11 and another sample of athletes to have mean height 73.12, and
    for these two means to have a statistically significant difference according to
    a t-test. We can justifiably conclude that these two groups are not random samples
    from the same population and treat them differently because of their different
    mean height. However, even if this difference of 0.01 inches is statistically
    significant, it’s not clear that this difference has practical significance. Members
    of these two groups should be able to wear the same clothes, sit on the same seats
    on airplanes, and reach the same high cupboards (on average). We have no reason
    to suppose that one group would be better than the other group at baseball in
    any practically important sense. In this case, we might wish to ignore the results
    of a t-test, since even though a statistically detectable difference exists, it’s
    not a difference that has any practical consequence. Practical significance is
    always an important thing to consider during the process of hypothesis testing.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve discussed hypothesis testing and its thorny theoretical nuances,
    let’s turn to a practical business example.
  prefs: []
  type: TYPE_NORMAL
- en: Comparing Groups in a Practical Context
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'So far, this chapter has focused on statistical theory. But for data scientists,
    theoretical considerations always take place within a practical context. Let’s
    switch from our baseball example to a marketing example. Suppose you’re running
    a company that manufactures computers. To keep in touch with customers and increase
    sales, your company maintains email lists: interested customers can sign up for
    a topic they’re interested in and receive periodic emails from your company related
    to that topic. For now, you have only two email lists: the desktop list and the
    laptop list, designed for customers who are interested in your desktop computers
    and your laptop computers, respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Until now, desktops and laptops have been the only products your company makes.
    But soon you’ll be releasing a new set of products that have been in development
    for several years: top-of-the-line web servers. It’s a natural product line for
    your company, since you already manufacture computer hardware and already have
    many tech clients who need server infrastructure. But since this product line
    is new, almost no one knows about it. Your marketing team is planning to email
    the subscribers on your email lists to tell them about your great new products
    and hopefully get started on the right foot with high sales of the new servers.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The marketing team members want to make this email campaign as effective as
    possible. They have a discussion with you about the campaign strategy. They could
    design one email and send it to every person on both email lists, or they could
    design one email message for the desktop subscribers and a different email message
    for the laptop subscribers. The experts on your marketing team know a lot about
    targeting: for example, they know that the email messages that extroverts react
    to most positively are different from the email messages that introverts react
    to most positively. Other personal characteristics—including age, income, and
    culture—also have strong effects on responses to advertising.'
  prefs: []
  type: TYPE_NORMAL
- en: We need to know whether the desktop subscribers have different characteristics
    than the laptop subscribers. If the two groups are essentially the same, we can
    save the marketing team members some time and have them send the same email to
    everyone. If the two groups are significantly different in ways we understand,
    we can craft better messages that appeal to each group and improve sales numbers.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can start our investigation by reading in our data. We’ll read in two fabricated
    datasets (not based on real people or products, just created to illustrate the
    points in the chapter). You can download these two datasets from [https://bradfordtuckfield.com/desktop.csv](https://bradfordtuckfield.com/desktop.csv)
    and [https://bradfordtuckfield.com/laptop.csv](https://bradfordtuckfield.com/laptop.csv),
    and then read them into Python as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'You can run `print(desktop.head())` and `print(laptop.head())` to see the first
    five rows of each dataset. You’ll notice that both datasets have four columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '`userid` Contains a unique number identifying a particular user'
  prefs: []
  type: TYPE_NORMAL
- en: '`spending` Contains a record of how much that user has spent at your company’s
    website'
  prefs: []
  type: TYPE_NORMAL
- en: '`age` Holds the user’s age, which you may have recorded during a separate survey'
  prefs: []
  type: TYPE_NORMAL
- en: '`visits` Holds the number of times the user has visited pages on your website'
  prefs: []
  type: TYPE_NORMAL
- en: Our goal is to determine whether the users described in the `desktop` dataframe
    and the users described in the `laptop` dataframe differ significantly from each
    other. Let’s draw some plots and see whether any immediately apparent differences
    exist.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can start with a plot of the amounts that subscribers to each list have
    spent on our company’s products. We’ll create a box plot with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Here, we import Matplotlib to create plots. We use its `boxplot()` command with
    data from `desktop`’s spending column and `laptop`’s spending column. You can
    see the results in [Figure 3-4](#figure3-4).
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/502888c03/f03004.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3-4: Box plots showing the spending levels of subscribers to the desktop
    email list (left) and subscribers of the laptop email list (right)'
  prefs: []
  type: TYPE_NORMAL
- en: We can learn a few things by looking at these box plots. Both groups have minima
    at 0\. Laptop subscribers have a higher 25th percentile, 50th percentile, and
    75th percentile, as well as a high outlier that is higher than any observations
    in the desktop subscriber group. On the other hand, the distributions don’t seem
    terribly different either; desktop subscribers don’t seem totally different from
    laptop subscribers. We have groups that are different, but not too different.
    We should look more closely and see if some more precise quantitative metrics
    will help us judge how different they are.
  prefs: []
  type: TYPE_NORMAL
- en: 'Besides plotting, we can do simple calculations that get summary statistics
    for our data. In the following snippet, we’ll get some of these descriptive statistics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'In this snippet, we check the mean age of desktop subscribers and laptop subscribers.
    The results reveal that the mean desktop subscriber is about 35.8 years old, and
    the mean laptop subscriber is about 38.7 years old. We can conclude that these
    groups are different, in the sense that they’re not identical. But it’s not clear
    whether the groups are different enough that we should tell our marketing group
    to create two separate emails instead of one. To make that judgment, we need to
    use our hypothesis-testing framework. We can specify our null hypothesis and alternative
    hypothesis as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Hypothesis 0 The two email lists are random samples from the same population.
  prefs: []
  type: TYPE_NORMAL
- en: Hypothesis 1 The two email lists are not random samples from the same population.
  prefs: []
  type: TYPE_NORMAL
- en: Hypothesis 0, our null hypothesis, is describing a world in which there’s a
    population of people who are interested in computers, both laptops and desktops.
    People from this population sign up for your company’s email lists occasionally.
    But when they sign up for a list, they choose completely at random which of your
    two lists they sign up for. In this world, your lists have superficial differences,
    but they are truly two random samples from the same population and don’t differ
    in any essential ways that would warrant different treatment by your company.
  prefs: []
  type: TYPE_NORMAL
- en: Hypothesis 1, the alternative hypothesis, describes a world in which the null
    hypothesis is not true. This would mean that your subscribers’ membership on different
    email lists is the result at least partially of underlying differences in people
    who like desktops and people who like laptops. If Hypothesis 0 is true, it would
    be reasonable to send the same marketing email to both groups. If Hypothesis 1
    is true, sending different marketing emails to each group makes more sense. A
    business decision now depends on the result of a statistical test.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s run our t-test and see whether our two subscriber groups actually differ
    from each other. First, we should specify a significance level. Let’s use the
    5 percent significance level that’s common in research. We can run our t-test
    with only one line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: When you look at the results from our t-test, you can see that our *p*-value
    is about 0.04\. Since we use the common 5 percent significance level, this *p*-value
    is low enough for us to conclude that the desktop and laptop groups are not random
    draws from the same population, so we can reject the null hypothesis. It appears
    that desktop and laptop email subscribers are at least slightly different in a
    detectable way.
  prefs: []
  type: TYPE_NORMAL
- en: 'After finding these differences, we can talk to our company’s marketing team
    and collectively make a decision about whether to design different email campaigns
    for the different groups. Suppose that the team decides to do so. We can feel
    proud of ourselves that our statistical analysis has led to a practical decision
    that we feel is justified. We didn’t only analyze data; we used the data to make
    a decision. This is common in data science: we use our data analysis for data-driven
    decision-making to improve business outcomes.'
  prefs: []
  type: TYPE_NORMAL
- en: 'But what next? We have come so far in this chapter only to make one decision:
    a yes/no decision to send different emails to both of our subscriber lists. The
    next set of questions we need to ask is about how our emails to each group should
    differ: What should their content be, how should we design them, and how will
    we know whether we’re doing it right? In the next chapter, we’ll talk about A/B
    testing, a powerful framework for answering these difficult questions.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, we talked about populations and samples, as well as how samples
    that come from the same population should resemble each other. We introduced hypothesis
    testing, including the t-test, an easy, useful tool for detecting whether two
    groups are likely to be random draws from the same population. We discussed some
    business scenarios where the t-test would be useful, including a marketing scenario
    and a decision about whether to send different emails to different email lists.
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter will build on the tools we introduced here. Instead of just
    comparing groups, we’ll discuss how to run experiments and then use group comparison
    tools to check for the differences between our experimental treatments.
  prefs: []
  type: TYPE_NORMAL

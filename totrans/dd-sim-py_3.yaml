- en: Part III
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: DATA AND FLOW
  prefs: []
  type: TYPE_NORMAL
- en: '9'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Collections and Iteration
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/chapterart.png)'
  prefs: []
  type: TYPE_IMG
- en: Looping through an array is one of the most elementary algorithms in programming.
    Often, it’s one of the first things a new developer does after “Hello, world!”
    The very principle of starting indices at zero was probably the first paradigm
    shift you encountered while learning to code. Yet, this is Python; loops and containers
    here operate on a whole different level.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, I’ll cover Python loops and then explore the various collections
    Python offers for storing and organizing data. Next, I’ll define the concepts
    of iterables and iterators and start putting them to work in the context of loops.
    Then, I’ll provide an overview of several iteration tools. Finally, I’ll implement
    my own iterable class.
  prefs: []
  type: TYPE_NORMAL
- en: Grab a mug of your favorite beverage, and let’s go!
  prefs: []
  type: TYPE_NORMAL
- en: Loops
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Python has two types of loops: `while` and `for`. As you’ll see in this chapter,
    they are not meant to be interchangeable. Rather each has unique purposes.'
  prefs: []
  type: TYPE_NORMAL
- en: while Loops
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `while` loop is the most traditional of the loops. As long as the expression
    in its header evaluates to `True`, the suite of the loop is executed. For example,
    the following loop keeps prompting the user to enter a valid number until they
    do so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-1: *get_number.py:1a*'
  prefs: []
  type: TYPE_NORMAL
- en: As long as the value of `number` is `None`, the suite of the `while` loop keeps
    repeating. I request input from the user with `input()` and attempt to convert
    it to an integer with `int()`. However, if the user has typed in anything other
    than a valid integer, a `ValueError` will be raised, and no new value will be
    assigned to `number`. Thus, the loop will repeat.
  prefs: []
  type: TYPE_NORMAL
- en: As soon as the user enters a valid integer, the loop exits and the number is
    printed to the screen.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an example output of this program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'If I want to provide a mechanism for quitting instead of entering a number,
    I could use the `break` keyword to exit the loop manually. Here, I allow the user
    to quit by entering a *q* instead of a number:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-2: *get_number.py:1b*'
  prefs: []
  type: TYPE_NORMAL
- en: I get the raw input first and check for the string value `'q'`. If I find it,
    I escape the loop manually with `break`. Otherwise, I attempt to convert the input
    to an integer as before.
  prefs: []
  type: TYPE_NORMAL
- en: 'There’s one problem with this approach, as seen in the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The last line of output isn’t right. I want the program to quit right away instead.
  prefs: []
  type: TYPE_NORMAL
- en: 'To fix this, I use a little-known feature of loops in Python: the `else` clause.
    When a Python loop finishes normally, the `else` suite is run; however, it is
    *not* run if the loop is aborted with a `break`, `return`, or raised exception.'
  prefs: []
  type: TYPE_NORMAL
- en: 'By moving my final print statement to the `else` clause of the loop, I ensure
    it only runs if a valid number is entered:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-3: *get_number.py:1c*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Running this code demonstrates the new behavior:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Upon encountering a *q*, the loop exits immediately, without executing the last
    `print()` statement.
  prefs: []
  type: TYPE_NORMAL
- en: for Loops
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For the majority of this chapter, I’ll focus on the mechanics of the `for` loop.
    For now, it will suffice for you to understand that the purpose of a `for` loop
    is to traverse through, or *iterate over*, a collection of values.
  prefs: []
  type: TYPE_NORMAL
- en: Like `while`, the `for` loop has an `else` clause that is only executed when
    the loop finishes normally, and not when it is manually aborted with `break`,
    `return`, or a raised exception.
  prefs: []
  type: TYPE_NORMAL
- en: 'A simplistic example will be enough for now:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-4: *print_list.py*'
  prefs: []
  type: TYPE_NORMAL
- en: I define a list of strings, which I assign to `numbers`. Then, I loop through
    each value in `numbers` and print each out to the terminal. When I’m done, I announce
    that fact with another message.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: For the rest of this chapter, I’ll unpack everything happening behind the scenes
    here, which is surprisingly vast. You will learn how to utilize iteration to its
    fullest potential in your code.
  prefs: []
  type: TYPE_NORMAL
- en: Collections
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A *collection* is a container object containing one or more *items* organized
    in some fashion. Each item is bound to a value; the values themselves are not
    contained within the collection object. There are five fundamental types of collections
    in Python, each with multiple variations: `tuple`, `list`, `deque`, `set`, and
    `dict` (dictionary).'
  prefs: []
  type: TYPE_NORMAL
- en: Once you understand how each collection behaves, using collections effectively
    is simply a matter of memorizing their methods; in lieu of that, most Python developers
    rely on the documentation. In a pinch, you can also run `help(``collection``)`
    in a Python interactive shell, where `collection` is the collection you want more
    information about.
  prefs: []
  type: TYPE_NORMAL
- en: Tuples
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As you know from Chapter 3 and the usages since, a *tuple* is a *sequence* (an
    array-like collection) that is *immutable*, meaning that once it is created, its
    items cannot be added, removed, or reordered.
  prefs: []
  type: TYPE_NORMAL
- en: 'Conventionally, tuples are used for heterogeneously typed, sequentially ordered
    data, such as when you need to keep different but associated values together.
    For example, here’s a tuple containing a customer name, a coffee order, and an
    order size, in ounces:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-5: *order_tuple.py:1*'
  prefs: []
  type: TYPE_NORMAL
- en: You define a tuple as a comma-separated sequence of values, enclosed in parentheses.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because the contents of a tuple are *ordered*, you can access individual items
    by index, or *subscript*, specified in square brackets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-6: *order_tuple.py:2*'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you need a tuple with a single item, leave a trailing comma after the item,
    like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This is primarily useful when one of your functions is expected to return a
    tuple, but you don’t know in advance how many elements you’ll need to return in
    that tuple.
  prefs: []
  type: TYPE_NORMAL
- en: Since tuples are immutable, they don’t offer any built-in methods for adding,
    changing, or removing items. You define a tuple once, in its entirety, up front,
    and then you access the items it contains.
  prefs: []
  type: TYPE_NORMAL
- en: Named Tuples
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `collections` module provides a strange little variant of the tuple called
    the *named tuple*, which allows you to define a tuple-like collection with named
    fields. Like a normal tuple, a named tuple is an immutable collection. Its primary
    use is adding keys to the values, while still retaining its subscriptable behavior:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-7: *coffeeorder_namedtuple.py*'
  prefs: []
  type: TYPE_NORMAL
- en: 'I define a new `namedtuple` with the type name `CoffeeOrder` ❶, which I also
    bind to the name `CoffeeOrder`. I name three fields in that named tuple: `item`,
    `addons`, and `to_go` ❷.'
  prefs: []
  type: TYPE_NORMAL
- en: Next, I create a new instance of the named tuple by passing the values to the
    `CoffeeOrder` initializer, and I bind the instance to `order`. I can access the
    values within `order` by field name ❸ or by subscript ❹.
  prefs: []
  type: TYPE_NORMAL
- en: In practice, most Pythonistas prefer dictionaries or classes to named tuples,
    but all three have their place.
  prefs: []
  type: TYPE_NORMAL
- en: Lists
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Lists* are sequence collections that are *mutable*, meaning items can be added,
    removed, and reordered. Conventionally, lists are used for homogeneously typed,
    sequentially ordered data, such as this list of specials at the fictional Uncomment
    Café:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-8: *specials_list.py:1*'
  prefs: []
  type: TYPE_NORMAL
- en: 'You define a list as a comma-separated sequence, enclosed in square brackets.
    As with tuples, you can access individual items via their index, specified in
    square brackets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-9: *specials_list.py:2*'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can use lists as arrays, stacks, or queues. Here are a few of the most
    commonly used methods on `list`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-10: *specials_list.py:3*'
  prefs: []
  type: TYPE_NORMAL
- en: I use `pop()` to return and remove items from the list. If I don’t pass an index
    to `pop()`, the last item is removed by default.
  prefs: []
  type: TYPE_NORMAL
- en: 'If I pass an index as an argument to `pop()`, the indicated item is removed
    instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-11: *specials_list.py:4*'
  prefs: []
  type: TYPE_NORMAL
- en: 'I can also add new items to the end of the list, using `append()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-12: *specials_list.py:5*'
  prefs: []
  type: TYPE_NORMAL
- en: The new item, `"cold brew"`, is passed to `append()`, and it is added at the
    end of the list.
  prefs: []
  type: TYPE_NORMAL
- en: 'If I want to add an item somewhere else in the list, I can use `insert()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-13: *specials_list.py:6*'
  prefs: []
  type: TYPE_NORMAL
- en: The first argument is a target index, `1`, and the new item, `"americano"`,
    is the second argument.
  prefs: []
  type: TYPE_NORMAL
- en: These are the three most common methods for modifying lists. Python has more,
    many of which are quite interesting. As I’ve mentioned, the official documentation
    is your best resource for learning all the available methods.
  prefs: []
  type: TYPE_NORMAL
- en: Deques
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `collections` module provides another sequence, *deque* (pronounced “deck”),
    which is optimized for accessing the first and last items. This makes it a good
    option to use as a stack or queue when performance especially matters.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, I’ll use `deque` to track the people waiting in line at the
    Uncomment Café:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-14: *customers_deque.py:1*'
  prefs: []
  type: TYPE_NORMAL
- en: After I import `deque` from `collections`, I create a new `deque`, which I bind
    to `customers`. I pass a list of two customers as the list’s initial value, although
    I could have omitted this and started with an empty deque instead.
  prefs: []
  type: TYPE_NORMAL
- en: 'Simon enters the café and gets in line, so I add him to the end of the `deque`
    with `append()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-15: *customers_deque.py:2*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, the barista helps the next person in line, so I return and remove the
    first customer, Daniel, from the front (“left”) of the line, using `popleft()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-16: *customers_deque.py:3*'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are once again two people in line. James slips in front of everyone else
    (how rude!), so I append him to the “left” of the `deque` with `appendleft()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-17: *customers_deque.py:4*'
  prefs: []
  type: TYPE_NORMAL
- en: 'But that’s okay by Simon, because the last person in line wins a free drink.
    I return and remove the last item from the deque:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-18: *customers_deque.py:5*'
  prefs: []
  type: TYPE_NORMAL
- en: 'After all this, the deque only has James and Denis:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-19: *customers_deque.py:6*'
  prefs: []
  type: TYPE_NORMAL
- en: Sets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A *set* is a built-in, mutable, *unordered* collection, in which all items are
    guaranteed to be unique. If you try to add an item that already exists in the
    set, the new duplicate will be discarded. You’ll primarily use a set for fast
    inclusion checks and various operations relating to set theory (math), especially
    in large data sets.
  prefs: []
  type: TYPE_NORMAL
- en: Every value stored in a set must be *hashable*, which the Python documentation
    defines as having “a hash value that never changes during its lifetime.” Hashable
    objects implement the special method `__hash__()`. All the built-in immutable
    types are hashable, since they never change value throughout their lifetime. However,
    many mutable types are not hashable.
  prefs: []
  type: TYPE_NORMAL
- en: 'I’ll use a set to run a raffle at the Uncomment Café, where each customer can
    only enter once:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-20: *raffle_set.py:1*'
  prefs: []
  type: TYPE_NORMAL
- en: I first define the set as a comma-separated sequence of values, surrounded by
    curly braces (`{}`). In this case, I provide three initial values.
  prefs: []
  type: TYPE_NORMAL
- en: 'As customers come in, I add their names to the set with `add()`. If their name
    is already in the set, such as in the case of Denis, it won’t be added another
    time if I try to add it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-21: *raffle_set.py:2*'
  prefs: []
  type: TYPE_NORMAL
- en: The `print` statement shows the current items in the set. Just remember that
    sets are *unordered*, so there is no guarantee of the order in which the items
    will appear.
  prefs: []
  type: TYPE_NORMAL
- en: 'I can remove items from the set using `discard()`. Since Simon won something
    earlier, I’ll remove his name:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-22: *raffle_set.py:3*'
  prefs: []
  type: TYPE_NORMAL
- en: I could have also used `remove()` to remove a value, but that raises a `KeyError`
    if the specified value is not in the set; `discard()` never raises an error.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, I return and remove an arbitrary item from the set with `pop()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-23: *raffle_set.py:4*'
  prefs: []
  type: TYPE_NORMAL
- en: Be aware, *arbitrary* does not mean *random*! The `pop()` method always returns
    and removes whichever item happens to be in the first position in the set. Because
    `set` is unordered and Python makes no guarantees about the internal sequence
    of the items, you cannot trust `set` for reliable randomness.
  prefs: []
  type: TYPE_NORMAL
- en: frozenset
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The immutable twin to `set` is `frozenset`, which works in much the same manner.
    They differ in the same way that `list` and `tuple` do: once created, a `frozenset`
    cannot have items added or removed.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To demonstrate this, I’ll create a `frozenset` for storing all previous prizewinners
    and use that as part of the next raffle:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-24: *raffle_frozenset.py:1*'
  prefs: []
  type: TYPE_NORMAL
- en: A `frozenset` is specified by passing a set literal (shown here), an existing
    set, or another linear collection to the `frozenset()` initializer. After I initially
    define `prev_winners`, I cannot change the contents of the `frozenset`—it’s immutable.
    The regular set, `raffle`, can still be modified.
  prefs: []
  type: TYPE_NORMAL
- en: One of the most exciting features of `set` and `frozenset` is that they both
    support *set mathematics*. You can use math and logic operators for finding the
    union (`|`), intersection (`&`), difference (`-`), and symmetric difference (`^`).
    It’s also useful for testing if one set is a subset (`<` or `<=`) or superset
    (`>` or `>=`) of the other. The documentation also outlines several other functions
    for combining and comparing sets of either type.
  prefs: []
  type: TYPE_NORMAL
- en: 'In my example, I’ll remove all the previous winners (`prev_winners`) from the
    `raffle` set using the `-=` operator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-25: *raffle_frozenset.py:2*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Then I can `pop()` an arbitrary item off of `raffle` to find my winner:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-26: *raffle_frozenset.py:3*'
  prefs: []
  type: TYPE_NORMAL
- en: Yay for Kyle! He wins a three-day, one-night trip to Antarctica, courtesy of
    Frozen Set Airlines. (Bundle up, buddy.)
  prefs: []
  type: TYPE_NORMAL
- en: Dictionaries
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A *dictionary* (type `dict`) is a mutable collection that stores data in *key-value*
    pairs, instead of in linear fashion. This associative manner of storage is known
    as *mapping*. Keys can be virtually any type, as long as that type is hashable.
    It’s easiest to remember that hashable types are virtually always immutable.
  prefs: []
  type: TYPE_NORMAL
- en: The value in the pair can be anything. Looking up a value by key is particularly
    fast, regardless of the amount of data in the dictionary. (In other languages,
    this type of collection is referred to as a *hashmap*; in CPython, the dictionary
    is implemented as a hash table.)
  prefs: []
  type: TYPE_NORMAL
- en: 'I’ll use a dictionary to store the menu at the Uncomment Café:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-27: *menu_dict.py:1*'
  prefs: []
  type: TYPE_NORMAL
- en: I create the dictionary as a sequence of comma-separated key-value pairs, wrapped
    in curly braces, with a colon (`:`) separating the key and value in each pair.
    In this case, the key is a string that is the name of the drink, and the value
    is a floating-point number representing the price.
  prefs: []
  type: TYPE_NORMAL
- en: 'I access individual items by key, specified in square brackets (`[ ]`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-28: *menu_dict.py:2*'
  prefs: []
  type: TYPE_NORMAL
- en: If the key being accessed is not in the dictionary, a `KeyError` is raised.
  prefs: []
  type: TYPE_NORMAL
- en: 'I can add or modify items by assigning a value to a key specified in square
    brackets. Here, I’ll add the `"americano"` key to the menu, with a price value
    of `2.49`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-29: *menu_dict.py:3*'
  prefs: []
  type: TYPE_NORMAL
- en: 'For whatever reason, the Americano isn’t terribly popular at the café, so I
    wind up removing it from the dictionary, using the `del` operator on the key:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-30: *menu_dict.py:4*'
  prefs: []
  type: TYPE_NORMAL
- en: Once again, if the key specified in the square brackets were not in the dictionary,
    a `KeyError` would be raised.
  prefs: []
  type: TYPE_NORMAL
- en: Check or Except?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There’s a bit of debate about whether one should check for a key in a dictionary
    directly with the `in` operator or use a `try` statement with a `KeyError` instead.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the EAFP (“Easier to Ask Forgiveness than Permission”) approach, using
    `try`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-31: *checkout_dict_eafp.py*'
  prefs: []
  type: TYPE_NORMAL
- en: Within a `try` statement, I try to access the value in the dictionary `menu`
    associated with the key `order` ❶. If the key is invalid, a `KeyError` will be
    raised and I will catch it in the `except` clause. I can then take the appropriate
    action.
  prefs: []
  type: TYPE_NORMAL
- en: This approach is better suited to instances where invalid keys are an *exceptional*
    situation (thus, “exceptions”). Typically, an `except` clause is a more expensive
    operation in terms of performance, but it’s an expense that is completely justified
    for handling errors and other exceptional situations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the LBYL (“Look Before You Leap”) approach, using the `in` operator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-32: *checkout_dict_lbyl.py*'
  prefs: []
  type: TYPE_NORMAL
- en: In this approach, I check whether `order` is a key in the `menu` dictionary
    before I do anything ❶. If it’s there, I can safely access the value associated
    with the key ❷. This approach may be preferable if you expect to frequently check
    for invalid keys, since either outcome is reasonably likely. Failure is more the
    *rule* than the *exception*, so it’s better for both scenarios to have roughly
    the same performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'The LBYL approach is generally frowned upon when an invalid key is an exceptional
    situation, because it has to look in the dictionary for a valid key twice: once
    when checking and once when accessing. By contrast, the EAFP approach only has
    to access a valid key once, since it handles the possible `KeyError`.'
  prefs: []
  type: TYPE_NORMAL
- en: As with all issues of performance, you can’t know for sure until you profile
    the code. You can rely on the assumptions herein, unless you specifically need
    the logic structure of one approach or the other. However, if performance is critical,
    profile the code (see Chapter 19).
  prefs: []
  type: TYPE_NORMAL
- en: Dictionary Variants
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Python has a `collections` module that offers a few variations on the built-in
    `dict`. Here are the three most common variations, along with their unique behavior:'
  prefs: []
  type: TYPE_NORMAL
- en: '`defaultdict` allows you to specify a callable that produces a default value.
    If you attempt to access the value on an undefined key, a new key-value pair will
    be defined, using this default value.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`OrderedDict` has extra functionality for tracking and managing the order of
    key-value pairs. Since Python 3.7, the built-in `dict` also officially preserves
    insertion order, but `OrderedDict` is specifically *optimized* for reordering
    and has additional behaviors for it.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Counter` is designed specifically for counting hashable objects; the object
    is the key, and the count is an integer value. Other languages call this type
    of collection a *multiset*.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You should only use one of these specialized dictionary types if you actually
    need its behavior, so I won’t go into more detail here. Each is optimized for
    a specific use case and is not likely to have optimal performance in other scenarios.
    The official documentation is your best bet if you need further details: [https://docs.python.org/3/library/collections.html](https://docs.python.org/3/library/collections.html).'
  prefs: []
  type: TYPE_NORMAL
- en: Unpacking Collections
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'All collections can be *unpacked* into multiple variables, meaning each item
    is assigned to its own name. For example, I can unpack a deque of three customers
    into three separate variables. I first create the deque of customers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-33: *unpack_customers.py:1a*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, to unpack the deque. I place a comma-separated list of names to unpack
    into, in order, on the left side of an assignment operator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-34: *unpack_customers.py:2a*'
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, you’ll see this left-hand part wrapped in parentheses, but using
    parentheses isn’t required when unpacking a linear collection like this. (I’ll
    demonstrate where parentheses fit into unpacking a dictionary in the next section.)
    I place the collection I’m unpacking on the right side of the assignment operator.
  prefs: []
  type: TYPE_NORMAL
- en: 'There’s one major limitation to unpacking: you have to know how many values
    you’re unpacking! To demonstrate this, I’ll go back and add one more customer
    to the deque with the `append()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-35: *unpack_customers.py:1b*'
  prefs: []
  type: TYPE_NORMAL
- en: 'If I were to specify too many or too few names on the left, a `ValueError`
    would be raised. Since my deque contains four values, trying to unpack into three
    names fails:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-36: *unpack_customers.py:2b*'
  prefs: []
  type: TYPE_NORMAL
- en: 'To fix this, I could specify a fourth name on the left. However, for this example,
    I want to ignore the fourth value. I can ignore any item by unpacking it into
    an underscore:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-37: *unpack_customers.py:2c*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The underscore (`_`), when used as a name, conventionally indicates that the
    value should be ignored. I can use the underscore as many times as I need, such
    as if I want to ignore the last two values in the collection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-38: *unpack_customers.py:2d*'
  prefs: []
  type: TYPE_NORMAL
- en: Only the first two values in `customers` will be unpacked, and the second two
    will be effectively ignored.
  prefs: []
  type: TYPE_NORMAL
- en: 'By the way, if you ever need to unpack a collection that only contains one
    value, leave a trailing comma after the name you’re unpacking into:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Starred Expressions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If you have no idea how many additional values there are in the collection,
    you can capture multiple unpacked values using a *starred expression*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-39: *unpack_customers.py:2e*'
  prefs: []
  type: TYPE_NORMAL
- en: The first two values are unpacked into `first` and `second`, and the remainder
    (if any) are packed into a list assigned to `rest`. As long as the collection
    being unpacked has at least two values, one for each of the nonstarred names on
    the left, this will work. If there are only two values in the collection, `rest`
    will be an empty list.
  prefs: []
  type: TYPE_NORMAL
- en: You can use starred expressions anywhere in the unpacking list, including the
    beginning. Here’s an example where I unpack the `first` and `last` values individually
    and pack all the rest into a list named `middle:`
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-40: *unpack_customers.py:3*'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can even use starred expressions to ignore multiple values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-41: *unpack_customers.py:4*'
  prefs: []
  type: TYPE_NORMAL
- en: By preceding the underscore with an asterisk, I capture multiple values but
    ignore them, instead of packing them into a list. In this scenario, I unpack the
    last two values in the collection.
  prefs: []
  type: TYPE_NORMAL
- en: You can only have one starred expression per unpacking statement, because starred
    expressions are *greedy*—consuming as many values as they’re allowed. Python unpacks
    values into all the other names before evaluating the starred expression. Using
    multiple starred expressions in the same statement makes no sense, since it’s
    impossible to tell where one stops and another starts.
  prefs: []
  type: TYPE_NORMAL
- en: Unpacking Dictionaries
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Dictionaries can be unpacked like any other built-in type of collection. By
    default, only the keys are unpacked, as seen when I unpack the dictionary representing
    the café menu.
  prefs: []
  type: TYPE_NORMAL
- en: 'I start by defining my dictionary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-42: *unpack_menu.py:1*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, I unpack the dictionary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-43: *unpack_menu.py:2a*'
  prefs: []
  type: TYPE_NORMAL
- en: 'If I want the values instead, I must unpack using a *dictionary view*, which
    provides access to the keys and/or values in a dictionary. In this case, I use
    the `values()` dictionary view:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-44: *unpack_menu.py:2b*'
  prefs: []
  type: TYPE_NORMAL
- en: 'I can unpack the keys and values together by unpacking from the `items()` dictionary
    view. This returns each key-value pair as a tuple:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-45: *unpack_menu.py:2c*'
  prefs: []
  type: TYPE_NORMAL
- en: 'I can also unpack each of the key-value tuples in the same statement by using
    parentheses around a pair of names a tuple will be unpacked into:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-46: *unpack_menu.py:3*'
  prefs: []
  type: TYPE_NORMAL
- en: For brevity, I chose to only unpack the first two items in the `menu` dictionary
    and ignore the rest. I unpack the first tuple from `menu.items()` into the pair
    `(a_name, a_price)`, so the first item of the tuple is stored in `a_name` and
    the second item is stored in `a_price`. The same thing happens with the second
    key-value pair in the dictionary.
  prefs: []
  type: TYPE_NORMAL
- en: You can use this unpacking strategy with parentheses to unpack two-dimensional
    collections, such as a list of tuples or a tuple of sets.
  prefs: []
  type: TYPE_NORMAL
- en: Structural Pattern Matching on Collections
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Starting from Python 3.10, it is possible to perform structural pattern matching
    on tuples, lists, and dictionaries.
  prefs: []
  type: TYPE_NORMAL
- en: 'In patterns, tuples and lists are interchangeable. They are both matched against
    sequence patterns*. Sequence patterns* use the same syntax as unpacking, including
    the ability to use starred expressions. For example, I could match on the first
    and last elements of a sequence and ignore everything in the middle:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-47: *match_coffee_sequence.py*'
  prefs: []
  type: TYPE_NORMAL
- en: Sequence patterns are the same, whether enclosed in parentheses or square brackets.
    The list `order` is compared against each pattern. For each, the first and last
    items are checked, and the rest of the items are captured via wildcard as `drink`.
    Within each case, I join together the elements in `drink` to determine what to
    fill the chosen vessel with.
  prefs: []
  type: TYPE_NORMAL
- en: 'I could also pattern match against specific values in a dictionary, using a
    *mapping pattern*. Here’s almost the same example, reworked to used a dictionary
    instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-48: *match_coffee_dictionary.py:1a*'
  prefs: []
  type: TYPE_NORMAL
- en: Mapping patterns are wrapped in curly braces. Only the keys I specify in the
    pattern are checked, while any other keys are ignored. In this version, I check
    the `'size'` and `'serve'` keys, as well as the value associated with the key
    `'drink'`, which I capture as `drink`.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you run this version of the code, versus the previous one, you’ll notice
    that I’m leaving the `''notes''` off (for example, `''no whip''`). To fix that,
    I could capture all remaining keys via wildcard instead, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-49: *match_coffee_dictionary.py:1b*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Although I chose to demonstrate capturing with a wildcard in a mapping pattern,
    it is worth noting that I can still directly access the subject, `order`, from
    within any of the cases. In this particular example, I could have just as easily
    written the code like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-50: *match_coffee_dictionary.py:1c*'
  prefs: []
  type: TYPE_NORMAL
- en: As before, any keys omitted from each mapping pattern are ignored for purposes
    of pattern matching.
  prefs: []
  type: TYPE_NORMAL
- en: Accessing by Index or Key
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Many collections are *subscriptable*, meaning individual items can be accessed
    via an index specified in square brackets. You’ve already seen this with lists:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-51: *subscript_specials.py:1a*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Subscriptable collection classes implement the special methods `__getitem__()`,
    `__setitem__()`, and `__delitem__()`, where each accepts a single-integer argument.
    You can see this in action by using the special methods directly, instead of the
    square-bracket notation from a moment ago. This code is functionally identical
    to the above:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-52: *subscript_specials.py:1b*'
  prefs: []
  type: TYPE_NORMAL
- en: These same special methods are implemented by the `dict` class, except that
    they accept a *key* as the sole argument. Because dictionaries don’t have a formal
    “index,” they are not considered subscriptable collections.
  prefs: []
  type: TYPE_NORMAL
- en: Slice Notation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Slice notation* allows you to access specific items or ranges of items in
    a list or tuple. Of the five fundamental types of collections, only `tuple` and
    `list` can be sliced. Neither `set` nor `dict` is subscriptable, so slice notation
    won’t work on them. While `deque` is subscriptable, it cannot be sliced using
    slice notation, because of how it is implemented.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To take a *slice* of a list or tuple, you use square brackets around the slice
    notation, which generally consists of three parts, separated by colons:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: The *inclusive* index of the first item you want to include in the slice is
    `start`. The *exclusive* index, `stop`, is *just past* where the slice stops.
    The `step` part allows you to skip over items and even reverse the order.
  prefs: []
  type: TYPE_NORMAL
- en: 'You aren’t required to specify all three arguments, but be mindful of the colons.
    If you want a slice, as opposed to a single element accessed by index, you must
    *always* include the colon separating `start` and `stop`, even if you don’t specify
    one or the other: (`[``start``:``stop``]`, `[``start``:]`, `[:``stop``]`).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, if you define `step`, you must precede it with its own colon: (`[:``stop``:``step``]`,
    `[::``step``]`, `[``start``::``step``]`).'
  prefs: []
  type: TYPE_NORMAL
- en: 'That’s rather theoretical, so here are some practical examples, using a list
    of coffee orders:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-53: *slice_orders.py:1*'
  prefs: []
  type: TYPE_NORMAL
- en: Start and Stop
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'By specifying the start and stop for a slice, I can specify a range:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-54: *slice_orders.py:2*'
  prefs: []
  type: TYPE_NORMAL
- en: The slice starts at index `3` and ends just before `6`, so it includes the items
    at indices `3`, `4`, and `5`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61] after_third = orders[4:] print(after_third)  # print [''cappuccino'',
    ''americano'', ''mocha latte''] [PRE62] next_two = orders[:2] print(next_two)  #
    prints [''caramel macchiato'', ''drip''] [PRE63] print(orders[-1])  # prints ''mocha
    latte'' [PRE64] last_three = orders[-3:] print(last_three)  # prints [''cappuccino'',
    ''americano'', ''mocha latte''] [PRE65] last_two_but_one = orders[-3:-1] print(last_two_but_one)  #
    prints [''cappuccino'', ''americano''] [PRE66] every_other = orders[1::2] print(every_other)  #
    prints [''drip'', ''drip'', ''americano''] [PRE67] reverse = orders[::-1] [PRE68]
    every_other_reverse = orders[-2::-2] print(every_other_reverse)  # prints [''americano'',
    ''drip'', ''drip''] [PRE69] three_to_five_reverse = orders[3:6:-1]  # WRONG! Returns
    empty list. print(three_to_five_reverse)            # prints [] [PRE70] three_to_five_reverse
    = orders[**5:2**:-1] print(three_to_five_reverse)  # prints [''americano'', ''cappuccino'',
    ''drip''] [PRE71] order_copy = orders[:] [PRE72] my_slice = slice(3, 5, 2)  #
    same as [3:5:2] print(my_slice) [PRE73] islice(`collection`, `start`, `stop`,
    `step`) [PRE74] from itertools import islice  menu = {''drip'': 1.95, ''cappuccino'':
    2.95, ''americano'': 2.49}  menu = dict(islice( ❶ menu.items(), 0, 3, 2))  # same
    as [0:3:2] print(menu) [PRE75] {''drip'': 1.95, ''americano'': 2.49} [PRE76] orders
    = [     "caramel macchiato",     "drip",     "pumpkin spice latte",     "drip",     "cappuccino",     "americano",     "mocha
    cappuccino", ] [PRE77] if "mocha cappuccino" in orders:     print("open chocolate
    syrup bottle") [PRE78] if "drip" not in orders:     print("shut off percolator")
    [PRE79] customers = [''Glen'', ''Todd'', ''Newman''] print(len(customers))  #
    prints 3 [PRE80] customers = []  if ❶ customers:  # if not empty...     print("There
    are customers.") else:     print("Quiet day.")  print(bool(customers)) [PRE81]
    Quiet day. False [PRE82] orders_per_day = [56, 41, 49, 22, 71, 43, 18] average_orders
    = sum(orders_per_day) // len(orders_per_day) print(average_orders) [PRE83] 42
    [PRE84] specials = ["pumpkin spice latte", "caramel macchiato", "mocha cappuccino"]
    [PRE85] first_iterator = specials.__iter__() second_iterator = specials.__iter__()
    print(type(first_iterator)) [PRE86] <class ''list_iterator''> [PRE87] item = first_iterator.__next__()
    print(item) [PRE88] pumpkin spice latte [PRE89] item = first_iterator.__next__()
    print(item) [PRE90] caramel macchiato [PRE91] item = second_iterator.__next__()
    print(item) [PRE92] pumpkin spice latte [PRE93] item = first_iterator.__next__()
    print(item) [PRE94] mocha cappuccino [PRE95] item = first_iterator.__next__()  #
    raises StopIteration [PRE96] first_iterator = **iter(specials)** second_iterator
    = **iter(specials)** print(type(first_iterator))  # prints <class ''list_iterator''>  item
    = **next(first_iterator)** print(item)                  # prints "pumpkin spice
    latte"  item = **next(first_iterator)** print(item)                  # prints
    "caramel macchiato"  item = **next(second_iterator)** print(item)                  #
    prints "pumpkin spice latte"  item = **next(first_iterator)** print(item)                  #
    prints "mocha cappuccino"  item = **next(first_iterator)**  # raises StopIteration
    [PRE97] specials = ["pumpkin spice latte", "caramel macchiato", "mocha cappuccino"]
    ❶ iterator = iter(specials)  while True:     try:         item = ❷ next(iterator)   ❸
    except StopIteration:         break     else:         print(item) [PRE98] specials
    = ["pumpkin spice latte", "caramel macchiato", "mocha cappuccino"]  for item in
    specials:     print(item) [PRE99] customers = [''Newman'', ''Daniel'', ''Simon'',
    ''James'', ''William'',              ''Kyle'', ''Jason'', ''Devin'', ''Todd'',
    ''Glen'', ''Denis'']  for customer in customers:     # Take order     # Make drink     print(f"Order
    for { ❶ customer}!") [PRE100] Order for Newman! Order for Daniel! Order for Simon!
    `# --snip--` [PRE101] customers = [     (''Newman'', ''tea''),     (''Daniel'',
    ''lemongrass tea''),     (''Simon'', ''chai latte''),     (''James'', ''medium
    roast drip, milk, 2 sugar substitutes''),     (''William'', ''french press''),     (''Kyle'',
    ''mocha cappuccino''),     (''Jason'', ''pumpkin spice latte''),     (''Devin'',
    ''double-shot espresso''),     (''Todd'', ''dark roast drip''),     (''Glen'',
    ''americano, no sugar, heavy cream''),     (''Denis'', ''cold brew'') ]  for ❶
    customer, drink in customers:     print(f"Making {drink}...")     print(f"Order
    for {customer}!") [PRE102] Making tea... Order for Newman! Making lemongrass tea...
    Order for Daniel! Making chai latte... Order for Simon! `# --snip--` [PRE103]
    for _, drink in ❶ sorted(customers, ❷ key=lambda x: ❸ x[1]):     print(f"{drink}")
    [PRE104] americano, no sugar, heavy cream chai latte cold brew `# --snip--` [PRE105]
    for number, ❶ (customer, drink) in enumerate(customers, start=1):     print(f"#{number}.
    {customer}: {drink}") [PRE106] #1\. Newman: tea #2\. Daniel: lemongrass tea #3\.
    Simon: chai latte `# --snip--` [PRE107] from collections import deque  customers
    = deque([  (''Newman'', ''tea''),     (''Daniel'', ''lemongrass tea''),     (''Simon'',
    ''chai latte''),     (''James'', ''medium roast drip, milk, 2 sugar substitutes''),     (''William'',
    ''french press''),     (''Kyle'', ''mocha cappuccino''),     (''Jason'', ''pumpkin
    spice latte''),     (''Devin'', ''double-shot espresso''),     (''Todd'', ''dark
    roast drip''),     (''Glen'', ''americano, no sugar, heavy cream''),     (''Denis'',
    ''cold brew'') ]) [PRE108] for customer, drink in customers:     print(f"Making
    {drink}...")     print(f"Order for {customer}!")     customers.popleft()  # RuntimeError
    [PRE109] for customer, drink in ❶ customers**.copy()**:     print(f"Making {drink}...")     print(f"Order
    for {customer}!")   ❷ customers.popleft()  **print(customers)  # prints deque([])**
    [PRE110] **while customers:**   ❶ **customer, drink =** ❷ **customers.popleft()**  print(f"Making
    {drink}...")     print(f"Order for {customer}!") [PRE111] orders = ["pumpkin spice
    latte", "caramel macchiato", "mocha cappuccino"] [PRE112] for order in orders:     #
    ... do whatever ...     orders.append(order)  # creates infinite loop!  print(orders)
    [PRE113] **new_orders = orders[:]** for order in orders:     # ... do whatever
    ...     **new_orders.**append(order) **orders = new_orders**  print(orders) [PRE114]
    samples = [''Costa Rica'', ''Kenya'', ''Vietnam'', ''Brazil''] guests = [''Denis'',
    ''William'', ''Todd'', ''Daniel'', ''Glen''] [PRE115] for sample in samples:     for
    guest in guests:         print(f"Give sample of {sample} coffee to {guest}.")
    [PRE116] Give sample of Costa Rica coffee to Denis. Give sample of Costa Rica
    coffee to William. Give sample of Costa Rica coffee to Todd. Give sample of Costa
    Rica coffee to Daniel. Give sample of Costa Rica coffee to Glen. Give sample of
    Kenya coffee to Denis. Give sample of Kenya coffee to William. `# --snip--` [PRE117]
    **from itertools import product  # Put this line at top of module**  **for** ❶
    **sample, guest in** ❷ **product(samples, guests):**     print(f"Give sample of
    {sample} coffee to {guest}.") [PRE118] orders = [''cold brew'', ''lemongrass tea'',
    ''chai latte'', ''medium drip'',           ''french press'', ''mocha cappuccino'',
    ''pumpkin spice latte'',           ''double-shot espresso'', ''dark roast drip'',
    ''americano'']  drip_orders = ❶ list( ❷ filter( ❸ lambda s: ''drip'' in s, ❹ orders))  print(f''There
    are { ❺ len(drip_orders)} orders for drip coffee.'') [PRE119] orders = [''cold
    brew'', ''lemongrass tea'', ''chai latte'', ''medium drip'',           ''french
    press'', ''mocha cappuccino'', ''pumpkin spice latte'',           ''double-shot
    espresso'', ''dark roast drip'', ''americano''] [PRE120] def brew(order):     print(f"Making
    {order}...")     return order [PRE121] for order in map(brew, orders):     print(f"One
    {order} is ready!") [PRE122] from operator import add  cost = [5.95, 4.95, 5.45,
    3.45, 2.95] tip = [0.25, 1.00, 2.00, 0.15, 0.00]  for total in map(add, cost,
    tip):     print(f''{total:.02f}'') [PRE123] 6.20 5.95 7.45 3.60 2.95 [PRE124]
    regulars = [''William'', ''Devin'', ''Kyle'', ''Simon'', ''Newman''] usuals =
    [''french press'', ''double-shot espresso'', ''mocha cappuccino'',           ''chai
    latte'', ''tea'', ''drip'']  usual_orders = ❶ dict( ❷ zip( ❸ regulars, ❹ usuals))
    [PRE125] print(usual_orders[''Devin''])  # prints ''double-shot espresso'' [PRE126]
    class CafeQueue:      def __init__(self):         self._queue = []         self._orders
    = {}         self._togo = {} [PRE127]  def __iter__(self):         return CafeQueueIterator(self)
    [PRE128]  def add_customer(self, customer, *orders, to_go=True):         self._queue.append(customer)         self._orders[customer]
    = tuple(orders)         self._togo[customer] = to_go [PRE129]  def __len__(self):         return
    len(self._queue) [PRE130]  def __contains__(self, customer):         return (customer
    in self._queue) [PRE131] class CafeQueueIterator:      def __init__(self, ❶ cafe_queue):         self._cafe
    = cafe_queue         self._position = 0 [PRE132]  def __next__(self):         try:             customer
    = self._cafe._queue[self._position]       ❶ except IndexError:           ❷ raise
    StopIteration          orders = self._cafe._orders[customer]         togo = self._cafe._togo[customer]   ❸
    self._position += 1        ❹ return (customer, orders, togo) [PRE133]  def __iter__(self):         return
    self [PRE134] queue = CafeQueue() queue.add_customer(''Newman'', ''tea'', ''tea'',
    ''tea'', ''tea'', to_go=False) queue.add_customer(''James'', ''medium roast drip,
    milk, 2 sugar substitutes'') queue.add_customer(''Glen'', ''americano, no sugar,
    heavy cream'') queue.add_customer(''Jason'', ''pumpkin spice latte'', to_go=False)
    [PRE135] print(len(queue))       # prints 4 print(''Glen'' in queue)  # prints
    True print(''Kyle'' in queue)  # prints False [PRE136] def brew(order):     print(f"(Making
    {order}...)")     return order [PRE137] for customer, orders, to_go in queue:    ❶
    for order in orders: brew(order)     if to_go:         print(f"Order for {customer}!")     else:         print(f"(Takes
    order to {customer})") [PRE138]`  [PRE139]` # 10 Generators and Comprehensions  ![](Images/chapterart.png)  In
    the previous chapter, we escaped all the headaches of traditional index-based
    loops. However, we haven’t yet completely escaped the nested loop.    The solution
    is to employ *generator expressions*, which allow you to rewrite the entire logic
    of a loop in a single statement. You can even create lists in this manner, with
    the much-loved *list comprehensions*. Before I get there, I’ll introduce *generators*,
    which provide a more compact alternative to custom iterable classes in many situations.
    You’ll also encounter the oft-overshadowed cousin of the generator, the humble
    *simple coroutine*, which provides an iterative solution for inputs.    ## Lazy
    Evaluation and Eager Iterables    The features I cover in this chapter all build
    on the principles of iterators, and many utilize the concept of *lazy evaluation,*
    which describes a process in which an iterator does not provide the next value
    until it is requested. This behavior, paired with the fact that iterators do not
    care how many items are possible in their iterable, provides the power behind
    generator objects.    While *iterators* are lazy, the definition of an iterable
    is not! Understanding this distinction is important when you’re writing code that
    works with large amounts of data. Incorrectly defining an iterable can lock your
    program in an infinite loop. In some cases, you can even chew through all available
    system memory and raise a `MemoryError` or even crash your machine. (I crashed
    my system twice while writing this chapter.)    For example, collection literals
    are incredibly *eager*, in that they evaluate all of their items upon creation.
    Programmer Kyle Keen demonstrates this phenomenon with the following example,
    which I’ve restructured slightly for clarity:    [PRE140]    Listing 10-1: *sleepy.py:1a*    Python
    eagerly evaluates each of the expressions in the list literal before assigning
    it to `sleepy`, which means it calls the two `time.sleep()` functions.    This
    behavior can mean that collections have the potential to become a performance
    bottleneck when working with a lot of data or particularly complex expressions.    Thus,
    you must choose your approaches carefully! One of the best ways to handle large
    amounts of data is to use either generators or *generator expressions*, which
    I’ll cover shortly.    ## Infinite Iterators    Lazy evaluation makes it possible
    to have *infinite iterators*, which provide values on demand without ever being
    exhausted. This behavior is very important to some features I cover in this chapter.    The
    `itertools` module offers three infinite iterators:    *   `count()` counts from
    the given numeric value, `start`, adding the optional `step` value each time.
    So, `count(5, 2)` would produce the values `5`, `7`, `9`, `11`, and so on, forever.
    *   `cycle()` cycles through each item in the given iterable, infinitely. Therefore,
    `cycle([1,2,3])` would produce `1`, `2`, `3`, `1`, `2`, `3`, on and on, forever.
    *   `repeat()` repeats the given value, either endlessly or up to an optionally
    specified number of times. Therefore, `repeat(42)` would produce the value `42`
    forever, while `repeat(42, 10)` would produce the value `42` up to `10` times.    However,
    as I mentioned earlier, the very behavior that makes infinite iterators useful
    also makes them dangerous: they have no brakes! When passed to a `for` loop that
    has no `break` statement, the loop becomes infinite. When unpacked with a starred
    expression or used to create a collection, the Python interpreter locks up or
    even crashes the system. Use infinite iterators with caution!    ## Generators    A
    powerful alternative to the iterator class is the *generator function*, which
    looks like an ordinary function, except for its use of a special `yield` keyword.
    When a generator function is called directly, it returns a *generator iterator*
    (also known as a *generator object*) that encapsulates the logic from the suite
    of the generator function.    On each iteration, the generator iterator will run
    up to (and including) a `yield` statement, and then it will wait for another call
    to the special method `__next__()`, which Python implicitly creates behind the
    scenes. You will recall from Chapter 9 that `__next__()` is the special method
    responsible for providing the next value in an iterator; it is called anytime
    an iterator object is passed to the `next()` function or used in a `for` loop.
    Once a generator iterator receives the call to `__next__()`, it will continue
    running until it hits another `yield`.    For example, I can use a generator to
    generate license plate numbers:    [PRE141]    Listing 10-2: *license_generator.py:1*    I
    declare the `gen_license_plates()` generator function like any other function.    To
    generate all the possible combinations of letters, I use the `itertool.product`
    iterable. The predefined string `string.ascii_uppercase`, which I’m locally renaming
    to `alphabet`, will provide the values for each letter within an iterable collection
    (a string).    I iterate over all the possible combinations of three letters by
    initializing a `product` iterator ❶ that iterates over the `alphabet` string three
    times, concatenated. I join the three letters into a single string ❷.    Before
    I iterate over the numbers, I ensure that `letters` is not equal to the string
    `''GOV''`. If it is, the generator will skip that iteration of letter combinations,
    as I imagine in this scenario that `''GOV''` is reserved for government vehicles
    only.    Finally, I iterate over all possible numbers, `000 to 999` ❸.    The
    line that makes this function a generator is the `yield` statement. Every time
    this line is reached in the program execution, the value is returned, and then
    the generator waits for another call to `__next__()`. When `__next__()` is called
    again, the generator resumes exactly where it left off, thereby producing and
    yielding the next value.    I must call my generator function to create the generator
    iterator I want to use, which I’ll bind to a name:    [PRE142]    Listing 10-3:
    *license_generator.py:2*    The name `license_plates` is now bound to the generator
    iterator created by `gen_license_plates()`. This is the object with the `__next__()`
    method.    I can treat `license_plates` the same as any iterator. For example,
    I’ll loop through all possible license plates, although this will take a long
    time to execute:    [PRE143]    Listing 10-4: *license_generator.py:3a*    That
    outputs the following (redacted):    [PRE144]    Most real-world scenarios wouldn’t
    want all the possible numbers at once. Here’s a more practical usage:    [PRE145]    Listing
    10-5: *license_generator.py:3b*    I define a function, `new_registration()`,
    which handles all of the logic for a new license plate registration. If the name
    is not already in the system, it retrieves the next plate from the iterator `license_plates`
    ❶ and stores it in the `registrations` dictionary, with the given `owner` as the
    key. Then, it returns the plate number for convenience. If the name is already
    in the system, it will return `None`.    To make the example a little more interesting,
    I’m manually fast-forwarding through a few thousand license plates:    [PRE146]    Listing
    10-6: *license_generator.py:4*    Now, I’ll put the `new_registration()` function
    to use:    [PRE147]    Listing 10-7: *license_plates.py:5*    I use the `new_registration()`
    function to register myself at this fictional DMV, and then I store the returned
    license plate number in `my_plate`, which I print out. I also directly check the
    `registrations` dictionary, to see what license plate was registered to me.    The
    output of this program is as follows:    [PRE148]    ### Generators vs. Iterator
    Classes    Recall that a `__next__()` method in an iterator class will raise the
    `StopIteration` exception to announce that there are no more items to iterate
    over. Generators don’t require that exception to be explicitly raised; what’s
    more, since Python 3.5, they don’t even allow it. When the generator function
    terminates, either by reaching its end or explicitly with a `return` statement,
    `StopIteration` is raised automatically, behind the scenes.    #### As an Iterator
    Class    To demonstrate this, I’ll write an iterator class that randomly generates
    traffic on a freeway. Once it’s working, I’ll rewrite it as a generator function.    I’ll
    start by defining a couple of lists of possibilities:    [PRE149]    Listing 10-8:
    *traffic_generator_class.py:1*    Next, I create a `Traffic` class for my iterator:    [PRE150]    Listing
    10-9: *traffic_generator_class.py:3*    I don’t need an initializer, since I have
    no instance attributes. I make this class an iterable by defining the `__iter__()`
    special method, which returns `self`.    I also need to define `__next__()` for
    this class to be an iterator:    [PRE151]    Listing 10-10: *traffic_generator_class.py:4*    In
    the `__next__()` special method, I randomly select a vehicle from the global `vehicles`
    list, using `random.choice()`. If I select the item `None` from that list, I raise
    the `StopIteration` exception to indicate an end (gap) in the stream of traffic.
    Otherwise, I select a random color from the global `colors` list, and then I return
    a formatted string containing the vehicle and color.    I can use my `Traffic`
    iterator as follows:    [PRE152]    Listing 10-11: *traffic_generator_class.py:5*    I
    iterate over each vehicle, print out its description, and keep count of how many
    vehicles have passed. Once `StopIteration` is raised by `Traffic()`, the loop
    ends and the final `print()` statement is run. One example output of this code
    is as follows:    [PRE153]    That works fine, but the iterator class has a lot
    of extra boilerplate. Instead, I can write the iterator as a generator function,
    which I’ll do next.    #### As a Generator Function    As before, I’ll reuse the
    lists from the previous example to define a couple of lists containing possibilities:    [PRE154]    Listing
    10-12: *traffic_generator.py:1*    Now, I’ll define the `traffic()` generator
    function:    [PRE155]    Listing 10-13: *traffic_generator.py:2*    I declare
    this generator function like any other function, although I must structure it
    to run continuously, the same as if I were going to `print()` each item. I accomplish
    this with an infinite loop. As soon as the function returns, either implicitly
    by reaching its end (which is not possible in this case) or via a `return` statement,
    the iterator will raise `StopIteration` behind the scenes.    Since I don’t know
    how much traffic is going to be randomly generated, I want this generator function
    to run indefinitely, until it selects a `None` value from `vehicles`. Then, instead
    of raising `StopIteration`, I exit the function with `return` to indicate that
    iteration is finished. Since Python 3.5, raising `StopIteration` within a generator
    function will raise a `RuntimeError` instead.    The usage is the same as before,
    except that I’m now iterating over the generator, not the iterator class:    [PRE156]    Listing
    10-14: *traffic_generator.py:3*    The output is effectively the same as before
    (although remember, it’s random):    [PRE157]    ### Closing Generators    Generators,
    like any iterators, can be infinite. However, when you’re done with an iterator,
    you should close it, since leaving it sitting idle in memory for the rest of your
    program would be a waste of resources.    To demonstrate this, here’s my traffic
    generator, rewritten to be infinite. I start by using the lists I wrote for the
    earlier example:    [PRE158]    Listing 10-15: *traffic_infinite_generator.py:1*    Here’s
    my rewritten traffic generator function, which is the same as [Listing 10-13](#listing10-13),
    except that I’ve dropped the `return` logic:    [PRE159]    Listing 10-16: *traffic_infinite_generator.py:2a*    Since
    the function can never reach its end and has no `return` statement, the generator
    is an infinite iterator.    I can use this generator in whatever way I want. For
    example, I could write a function for a car wash that uses the generator but limits
    how many vehicles can be washed:    [PRE160]    Listing 10-17: *traffic_infinite_generator.py:3*    I
    would pass a `traffic` iterator to the `car_wash()` function, along with an integer
    value bound to `limit` representing how many vehicles can be washed. The function
    iterates over traffic, washing each car, and keeping count.    Once the limit
    has been reached (or surpassed), I don’t want to keep the `traffic` iterable around
    anymore, especially as it may have been instantiated right in the argument list,
    so I close it. This causes `GeneratorExit` to be raised within the generator,
    which in turn causes `StopIteration` to be raised—ending the loop, and thus, the
    function.    Now that I’ve written the generator and the function using it, here’s
    how I put the two together:    [PRE161]    Listing 10-18: *traffic_infinite_generator.py:4a*    A
    new iterator is created from the `traffic()` generator function and passed right
    to the `car_wash()` function. When the function is finished, it also closes the
    iterator. It can now be cleaned up by the garbage collector.    A new iterator
    can still be created from the `traffic()` generator function, but the old iterator
    is exhausted.    I can create a generator iterator instead and use it in `car_wash()`,
    which ultimately closes it:    [PRE162]    Listing 10-19: *traffic_infinite_generator.py:4b*    Since
    the `car_wash()` function closes the iterator `queue`, I can no longer pass it
    to `next()` to get a result, as you can see if I add this erroneous line:    [PRE163]    Leaving
    out the error, running that code produces something like the following redacted
    output:    [PRE164]    ### Behavior on Close    Rather than exiting quietly, I
    can have the generator do something else when it is closed explicitly. I accomplish
    this by catching the `GeneratorExit` exception:    [PRE165]    Listing 10-20:
    *traffic_infinite_generator.py:2b*    I wrap my `yield` statement in a `try` clause.
    When `traffic.close()` is called, `GeneratorExit` is raised at the `yield` statement
    the generator is waiting at. I can catch this exception and do whatever I like,
    such as print out a message. Most important is that I must re-raise the `GeneratorExit`
    exception, or else the generator will never actually close!    Without making
    any changes to the usage of this generator (Listings 10-17 and 10-19), running
    the code shows this new behavior at work:    [PRE166]    ### Throwing Exceptions    One
    seldom-used feature of generators is the `throw()` method, which can be used to
    put the generator into some sort of exceptional state, especially when that requires
    some special behavior beyond the run-of-the-mill `close()`.    For example, if
    you’re using a generator to retrieve values from a thermometer device over a network
    connection, and if the connection is lost, a default value (say, `0`) is returned
    from the query instead. You don’t want to log that default value, since it’s wrong!
    Instead, you’ll want the generator to return the constant `NaN` for that iteration.    You
    could write a different function that detects that the network connection is lost,
    which would retrieve from trying to query the disconnected device. Then, you can
    cause the generator to raise an exception at the `yield` statement it’s idling
    at by using the `throw()` method. Your generator can catch that exception and
    yield `NaN`.    This is similar to how `close()` will raise `GeneratorExit`; in
    fact, `close()` is functionally identical to `throw(GeneratorExit)`.    As amazingly
    useful as that sounds, there aren’t as many real-world use cases for `throw()`.
    The thermometer example is one of the few valid such scenarios, but even that
    would likely be solved better by having the generator call the function for checking
    the network connection.    I’ve had to write a fairly contrived example using
    my `traffic()` generator to demonstrate this behavior. I’m catching `ValueError`
    to allow skipping a vehicle; that is the exception that I will raise at the `yield`
    statement with the `throw()` method in the usage later.    [PRE167]    Listing
    10-21: *traffic_generator_throw.py:1*    When the `ValueError` exception is raised
    at the `yield` statement, it will be caught ❶ and the generator will announce
    that the current vehicle is being skipped ❷, before moving to the next iteration
    of its infinite loop ❸.    This would really only be conceivably useful if I abstracted
    out the logic of washing a car into its own function. That function can raise
    exceptions:    [PRE168]    Listing 10-22: *traffic_generator_throw.py:2*    The
    `wash_vehicle()` function checks that it’s not being asked to wash a semi. If
    it is, a `ValueError` is raised.    I’ll write a function, `car_wash()`, which
    will handle passing each vehicle from `traffic()` to `wash_vehicle()`:    [PRE169]    Listing
    10-23: *traffic_generator_throw.py:3*    In the context of the `car_wash()` function,
    I catch all exceptions thrown from my call to `wash_vehicle()`. This catch-all
    is completely acceptable because I’m re-raising the caught exception within the
    generator, using `traffic.throw()` ❶. That way, the logic of which exceptions
    can be raised and how they are handled is handled solely by the `wash_vehicle()`
    function and the `traffic` generator. If any exception is passed to `traffic.throw()`
    that is not explicitly handled by the generator, that exception will be raised
    and left uncaught at the `yield` statement, so there is no implicit error silencing.    If
    there’s no exception from calling `car_wash()`, I increment my count of vehicles
    washed. If an exception was caught, I don’t want to increment, since I don’t want
    to count the skipped semis in the number of vehicles washed.    Finally, I create
    a `traffic()` generator and pass it to the `car_wash()` function:    [PRE170]    Listing
    10-24: *traffic_generator_throw.py:4*    Running that code produces something
    like the following:    [PRE171]    You can see that 10 vehicles are washed and
    all the semis are skipped. It works exactly as designed.    As I said, this was
    a contrived example. There’s probably little reason to have the *generator* handle
    the `ValueError` exception, when I could have handled it in the `car_wash()` function
    instead. While I cannot guarantee that there is never a use for `throw()`, if
    you think you need it, you’re often overlooking a simpler way of handling the
    problem.    ## yield from    When using a generator, you are not limited to yielding
    data from the current generator iterator. You can temporarily hand off control
    to other iterables, generators, or coroutines, by using `yield from`.    In my
    traffic generator, I want to add a small chance of a biker gang being generated.
    I start by writing a generator specifically for a biker gang. As with prior examples,
    I’m reusing those same lists:    [PRE172]    Listing 10-25: *traffic_bikers_generator.py:1*    Here’s
    my new `biker_gang()` generator function:    [PRE173]    Listing 10-26: *traffic_bikers_generator.py:2*    The
    `biker_gang()` generator will use the `random.randint()` function to select a
    random number between 2 and 10 and generate a biker gang of that size. For each
    bike in the gang, a random color is selected ❶ and a motorcycle of the selected
    color is yielded ❷.    To use it, I add three lines to my original infinite `traffic()`
    generator from [Listing 10-16](#listing10-16):    [PRE174]    Listing 10-27: *traffic_bikers_generator.py:3*    I
    use `random.randint()` to determine whether to generate a biker gang, at a 1-in-50
    probability. To generate the biker gang, I use `yield from` to hand off execution
    flow to the `biker_gang()` generator ❶. The `traffic()` generator will stay paused
    at this position until the `biker_gang()` generator is finished, at which point,
    control is passed back to this generator and it resumes.    Once `biker_gang()`
    is done, I skip to the next iteration of the infinite loop with `continue` to
    generate another vehicle ❷.    The usage of the `traffic()` generator is pretty
    much the same as before:    [PRE175]    Listing 10-28: *traffic_bikers_generator.py:4*    Running
    this code will (probably) show the new biker gang–generation logic at work. Here’s
    an example output (redacted):    [PRE176]    You are not limited to passing off
    control to other generators. You can use `yield from` to iterate over any iterable
    object, whether it be a collection, an iterator class, or a generator object.
    Once the iterable is exhausted, control reverts back to the calling generator.    ##
    Generator Expressions    A *generator expression* is an iterator that wraps the
    entire logic of a generator into a single expression. Generator expressions are
    lazy, so you can use them to work with large amounts of data without locking up
    your program.    To demonstrate how to create and use generator expressions, I’ll
    rebuild my earlier license plate generator. I’ll write a generator function containing
    a single `for` loop. Later, I’ll transform this into a generator expression.    This
    loop generates all the possible license plate numbers consisting of the letters
    *ABC* and three following digits:    [PRE177]    Listing 10-29: *license_plates.py:1a*    The
    iterable `range(1000)` produces all the integers from `0` to `999`. The loop iterates
    through those values, assigning the current value of each iteration to `num`.
    Within the loop, I create the license plate number with f-strings, using string
    formatting to pad `num` with leading `0`s as necessary, to ensure there are always
    three digits.    I want to print the values to test. Since this is also an iterator
    object, it is best to print the values it produces from its usage, instead of
    from within the iterator itself. I print from the generator like this:    [PRE178]    Listing
    10-30: *license_plates.py:2a*    Running this code prints the following (redacted):    [PRE179]    Because
    this generator function is so simple, containing only one loop, it is an ideal
    case for a generator expression. I’ll rewrite as follows:    [PRE180]    Listing
    10-31: *license_plates.py:1b*    The generator expression is enclosed in the outer
    parentheses and is bound to the name `license_plates`. The generator expression
    itself is essentially an inversion of the loop syntax.    Within the generator
    expression, the logic from the suite of the loop earlier ([Listing 10-30](#listing10-30))
    is declared first, where I define an expression that will be evaluated on each
    iteration. I create a string composed of the letters *ABC* and the number from
    the current iteration, left-padded with zeroes to three digits. Similar to a `return`
    in a lambda, the `yield` in the generator expression is implied.    Next, I declare
    the loop itself. As before, I iterate over a `range()` iterable, using the name
    `number` for the value on each iteration.    The revised usage here prints out
    all the possible license plates:    [PRE181]    Listing 10-32: *license_plates.py:2b*    ###
    Generator Objects Are Lazy    Remember, all generator objects are lazy, whether
    they were produced by generator functions or generator expressions. This means
    generator objects produce values on demand, and not a moment sooner.    Recall
    the modified version of Kyle Keen’s eager-evaluation demonstration from [Listing
    10-1](#listing10-1). I can replicate that same essential logic in a generator
    expression, and you can see this lazy evaluation at work:    [PRE182]    Listing
    10-33: *sleepy.py:1b*    Unlike the list—whose very *definition* caused the program
    to sleep for three seconds before continuing, because every item was being evaluated
    at definition—this code runs instantly, because it defers evaluation of its values
    until they’re needed. Defining the generator expression itself does not execute
    `time.sleep()`.    Even when I manually iterate over the first value in `sleepy`,
    there is no delay:    [PRE183]    Listing 10-34: *sleepy.py:2*    Because `time.sleep(0)`
    is called on the first iteration of the generator expression, `next(sleepy)` returns
    instantly. Subsequent calls to `next(sleepy)` would cause the program to sleep,
    but that won’t happen until I request it.    There’s one critical exception to
    the lazy evaluation of generator expressions: the expression in the leftmost `for`
    statement is evaluated immediately. For example, consider what would happen if
    you were to write this:    [PRE184]    Listing 10-35: *sleepy.py:1c*    That version
    of the generator expression has none of the desired lazy evaluation behavior,
    as the list `[1, 2, 3, 4, 5]` in the `for` loop is evaluated immediately when
    the generator expression is first encountered. This is by design, so any errors
    in the loop’s expression will be raised with a traceback to the generator expression’s
    declaration, rather than the first *usage* of the generator expression. However,
    because the list here evaluates instantly, we don’t actually see a delay.    ###
    Generator Expressions with Multiple Loops    Generator expressions can support
    more than one loop at a time, replicating the logic of a nested loop. You list
    the loops in order, from outermost to innermost.    I’ll rewrite my license plate
    generator expression to generate all possible combinations of letters and numbers,
    starting with `AAA 000` and ending with `ZZZ 999`. There are 17,576,000 possible
    results for this, so this is fast only because generator expressions are lazy;
    the values are not created until they’re requested.    [PRE185]    Listing 10-36:
    *license_plates.py:1c*    The generator expression, which is wrapped in parentheses
    and bound to `license_plates`, spans three lines here for readability. I could
    have written it as a single line, but once a generator expression starts involving
    multiple loops, it’s usually best to split it over multiple lines.    In my generator
    expression, I’m employing two loops. For the first (and outermost) loop, I iterate
    over all the possible combinations of three letters via `itertools.product` ❷,
    as I did in [Listing 10-2](#listing10-2). The product `iterator` produces a tuple
    of values on each iteration, which I must concatenate together into a string using
    `"".join()` ❶ when creating the formatted string.    For the second (or inner)
    loop, I iterate over all possible numbers between `000` and `999`, as before ❸.    On
    each iteration, I use an f-string to generate the license plate.    The result
    is an iterator bound to `license_plates` that can lazily generate all the possible
    license plate numbers. The next license plate is not created until it’s requested.    I
    can use the `license_plates` generator expression the same as I would a generator
    object. Its usage is no different from what you saw in [Listing 10-5](#listing10-5)
    through [Listing 10-7](#listing10-7):    [PRE186]    Listing 10-37: *license_plates.py:2c*    The
    output of this program is as follows:    [PRE187]    ### Conditionals in Generator
    Expressions    As you may notice, this produced license plates starting with the
    letters *GOV*. I need to integrate that conditional from [Listing 10-2](#listing10-2)
    to check for that reserved combination of letters, which I’ll do next.    I can
    add a conditional to my generator expression from [Listing 10-36](#listing10-36),
    to incorporate this limitation:    [PRE188]    Listing 10-38: *license_plates.py:1d*    I’ve
    added the conditional: if the value of the tuple `letters` is *not* `(''G'', ''O'',
    ''V'')`, the value will be used. Otherwise, the iteration will be skipped (an
    implicit `continue`).    Order matters here! The loops and conditionals are evaluated
    from top to bottom, as if they were nested. If I’d checked for `(''G'', ''O'',
    ''V'')` further down, `continue` would be implicitly called on a thousand separate
    iterations, but since it *precedes* the second loop, the numbers are never iterated
    over on `(''G'', ''O'', ''V'')` at all; the generator expression continues on
    the first loop.    This syntax can be a bit pesky to keep straight at first. I
    like to think of it as a nested loop, where the `yield` line at the end has been
    yanked out and stuck on the front. The equivalent generator function, written
    with a single nested loop, would look like this:    [PRE189]    The last line
    moves to the front, and you drop the `yield` keyword, since that’s implied in
    generator expressions. You also drop the colons from the end of each of the other
    lines. This way of writing generator expressions is helpful for making sure your
    logic is sound.    Running the code again produces the following:    [PRE190]    As
    you can see, the conditional is working. Instead of `GOV 888`, the result is now
    `GOW 888`.    You can also use `if-else` in the context of a generator expression,
    but there is one catch: the placement is different from with just an `if`! This
    subtlety catches a lot of Python developers unawares, even the experienced ones.    Let
    me show you what I mean. Here’s a generator expression with an `if`, which produces
    all the integers less than 100 that are divisible by 3:    [PRE191]    Listing
    10-39: *divis_by_three.py:1a*    That works, but now, I want to print out `"redacted"`
    for every number that *isn’t* divisible by 3\. You might logically try the following
    (as I did while writing this chapter, and it failed):    [PRE192]    Listing 10-40:
    *divis_by_three.py:1b*    Running that produces this:    [PRE193]    Eep! The
    reason for this error becomes clear if you convert the generator expression to
    a generator function, using the technique I described earlier in this chapter:    [PRE194]    That
    syntax is outright nonsense. The generator expression itself does not support
    the `else` clause—in fact, every compound statement may only have one clause in
    a generator expression. However, the generator expression does support a *ternary
    expression*, which is a compact conditional expression:    [PRE195]    Ternary
    expressions follow the form `a` `if` `expression` `else` `b`. The ternary expression
    evaluates to value `a` if `expression` evaluates to `True`—or to `b`, otherwise.
    These sorts of expressions can show up anywhere, from assignment to return statements.
    However, their use is discouraged in most situations, as they are hard to read.
    Ternary expressions are mainly only used in lambdas and generator expressions,
    where full-size conditional statements are out of the question.    I can convert
    that generator function logic back into a generator expression:    [PRE196]    Listing
    10-41: *divis_by_three.py:1c*    That version evaluates correctly. Hooray! However,
    if I were to revert to using an `if` and dropping the `else` statement, I’d be
    back to having problems:    [PRE197]    Listing 10-42: *divis_by_three.py:1d*    Running
    that gives me this:    [PRE198]    If I convert that back to generator function
    logic, the problem becomes evident again:    [PRE199]    Without an `else`, that’s
    not a ternary expression, so I have to go back to the normal `if` statement:    [PRE200]    That
    can be converted back to a generator expression that works:    [PRE201]    Listing
    10-43: *divis_by_three.py:1e (same as 1a)*    This can be a bit infuriating to
    remember offhand. I recommend you write your logic as a generator function first
    and then convert it to a generator expression.    ### Nested Generator Expressions    One
    inefficiency in my use of the current version of the license plate generator expression
    is that I’m joining the string together on every iteration. My generator expression
    in [Listing 10-38](#listing10-38) joined each combination of letters once, instead
    of once for every combination of letters *and* numbers. What’s more, in my conditional,
    the code would look cleaner and be more maintainable if I had a nice, clean string
    to work with, instead of the tuple being produced by `product()`.    Unlike generator
    functions, generator expressions are limited to nested single-clause compound
    statements, and thus, a single top-level loop. I can overcome this by *nesting*
    one generator expression inside the other. This is effectively the same as writing
    two separate generator expressions and having one use the other.    Here’s how
    I’d use this technique in my license plate generator code:    [PRE202]    Listing
    10-44: *license_plates.py:1e*    The inner nested generator expression handles
    iterating over the results of `product()`, joining the three letters into a single
    string. In the outer generator expression, I iterate over the inner expression
    to get the string containing the next combination of letters. Then, before I iterate
    over the numbers, I ensure that `letters` is not equal to the string `''GOV''`.
    If it is, the generator expression will skip that iteration of letter combinations.    This
    approach improves the readability of my code. Instead of having to add cruft to
    the f-string by calling `join()` inside of it, I can directly include `{letters}`
    ❶.    While this is the cleanest approach to license plate generation I’ve used
    *so far*, I wouldn’t use the above code in production, because I’ve arguably reached
    the practical limit of readability for generator expressions. When things get
    this complicated, you should just reach for ordinary generator functions. The
    generator function in [Listing 10-2](#listing10-2) is much more readable and maintainable
    than the equivalent generator expression in [Listing 10-44](#listing10-44).    ##
    List Comprehensions    If you wrap a generator expression in square brackets (`[
    ])` instead of parentheses, you create a *list comprehension*, which uses the
    enclosed generator expression to populate the list. This is the most common and
    perhaps the most popular usage of generator expressions.    However, since I’m
    declaring an *iterable*, I’m losing the lazy evaluation inherent in the generator
    expression. List comprehensions are eager because list definitions are eager.
    For that reason, I’d likely never write the license plate generator expression
    as a list comprehension; it would take several seconds to finish, and that doesn’t
    make for a pleasant user experience. Make sure you only use a list comprehension
    when you actually need a list object: that is, when you need to store the values
    in a collection for later processing or use. Otherwise, use a generator expression.    List
    comprehensions are preferable to `filter()` for purposes of readability, as they’re
    easier to write and debug, and they look cleaner. I can rewrite the coffee `filter()`
    example from Chapter 9 (Listing 9-96) as a list comprehension:    [PRE203]    Listing
    10-45: *orders_comprehension.py*    Remember, a list comprehension is just a type
    of generator expression. I iterate over every item `order` in the iterable `orders`
    ❷. If the string `''drip''` can be found in the current `order`, then I’ll add
    that item to `drip_orders` ❸. I don’t need to do anything with `order` besides
    adding it to the list, so I lead the generator expression with a bare `order`
    ❶.    Functionally, this code is the same as before, but this version with the
    list comprehension is *much* cleaner! `filter()` has its uses, but most of the
    time, you’ll find that generator expressions or list comprehensions will serve
    your purposes better.    ## Set Comprehensions    Just as you can create a list
    comprehension by enclosing a generator expression in square brackets, so also
    can you create a *set comprehension* by enclosing in curly braces (`{ }`). This
    will use the generator expression to populate a *set*.    There aren’t any surprises
    here, so I’ll keep the example very basic. This set comprehension will find all
    the possible remainders from dividing 100 by an odd number less than 100\. Sets
    will exclude any duplicates, making the results easier to comprehend:    [PRE204]    Listing
    10-46: *odd_remainders.py*    For every other integer `divisor` between `1` and
    `99` inclusive, I find the remainder of dividing `100` by the `divisor`, using
    the modulo operator. The result is added to the set.    Running that code gives
    me this:    [PRE205]    Set comprehensions really do work the same as list comprehensions,
    except for which collection is created. Sets are unordered and contain no duplicates.    ##
    Dictionary Comprehensions    A dictionary comprehension follows almost the same
    structure as a set comprehension, but it requires colons. Both a set comprehension
    and a dictionary comprehension are enclosed in curly braces (`{ }`), like their
    respective collection literals. A dictionary comprehension additionally uses a
    colon (`:`) to separate key-value pairs, and this is what distinguishes it from
    a set comprehension.    For example, if I wanted a dictionary comprehension that
    uses an integer between 1 and 100 as the key and the square of that number as
    the value, I would write this:    [PRE206]    Listing 10-47: *squares_dictionary_comprehension.py*    The
    key expression, on the left side of the colon, is evaluated before the value expression,
    on the right. I use the same loop for creating both key and value.    Be aware,
    like with list and set comprehensions, dictionary comprehensions are eager. The
    program will evaluate the dictionary comprehension until the `range()` iterable
    I’m using is exhausted.    Here’s the output:    [PRE207]    That’s all there
    is to it! Again, besides the colon, everything is the same as in any other generator
    expression.    ## Hazards of Generator Expressions    Generator expressions, along
    with the different types of comprehension, can be addictive, partly because one
    feels really smart when crafting them. There’s something about powerful one-liners
    that gets programmers very excited. We really like being clever with our code.    However,
    I must caution against going too crazy with generator expressions. As The Zen
    of Python reminds us:    > Beautiful is better than ugly. >  > … >  > Simple is
    better than complex. >  > Complex is better than complicated. >  > … >  > Sparse
    is better than dense. >  > Readability counts.    Generator expressions can be
    beautiful—but they can also become dense, unreadable messes when used unwisely.
    List comprehensions are especially vulnerable to abuse. I’ll lay out some examples
    of where list comprehensions and generator expressions aren’t suitable.    ###
    They Quickly Become Unreadable    The following example appeared in a survey by
    Open edX. In the original, each list comprehension was on a single line. For the
    sake of reproducing it legibly, without giving my typesetter fits, I’ve taken
    the liberty of splitting each of the three list comprehensions across multiple
    lines. Unfortunately, it really doesn’t do much to improve things:    [PRE208]    Can
    you tell what’s going on? You probably could if you read it for a while, but why
    would you want to? The code is as clear as mud, and sure enough, it was rated
    as the most unreadable example in the survey.    List comprehensions and generator
    expressions are powerful, but it doesn’t take much for them to become unreadable
    like this. Since generator expressions essentially “flip” the order of statements,
    so the loop comes after the statement that relates to it, it is harder to comprehend
    the logic in this format. The above would be better written in the context of
    a traditional loop.    My colleague “grym” from Libera.Chat IRC shared an even
    more abhorrent example of how easily abused list comprehensions are:    [PRE209]    Don’t
    ask me what it does. None of us wanted to figure it out. My soul burns just reading
    it.    ### They Don’t Replace Loops    Since generator expressions and comprehensions
    are so neat and compact, it might be tempting to write clever one-liners in place
    of garden variety `for` loops. Resist this temptation! Generator expressions are
    suited for creating lazy iterators, while list comprehensions should only be employed
    when you actually need to create a list.    The reason for this is best understood
    by studying an example. Imagine you were reading through someone else’s code and
    you encountered this:    [PRE210]    The first thing that stands out is that,
    although a list comprehension is meant to create a list value, that value is not
    being stored anywhere. Anytime a value is implicitly discarded like this, it should
    be a warning that the pattern is being abused.    Second, you can’t tell at a
    glance whether the data in `some_list` is being mutated directly. This is a case
    of a list comprehension being used inappropriately, in place of a loop. It’s somewhat
    unreadable, as it obfuscates the behavior of the code, and it also makes debugging
    difficult.    This is one case where the author should have stuck with loops,
    which would have looked like this:    [PRE211]    In this form, it’s not so unexpected
    that the values in `some_list` are being mutated, although it’s still bad practice
    for a function to have side effects like this. Most importantly, debugging is
    easier.    ### They Can Be Hard to Debug    The nature of a generator expression
    or comprehension is that you’re packing everything into one gigantic statement.
    The benefit of this is that you eliminate a bunch of intermediate steps. The drawback
    is . . . you eliminate a bunch of intermediate steps.    Think about debugging
    in a typical loop. You can step through it, one iteration at a time, using your
    debugger to observe the state of each variable as you go. You can also use error
    handling to deal with unusual edge cases.    None of that can help you in a generator
    expression, where either everything works or nothing works. You can try to parse
    through the errors and output to figure out what you did wrong, but I assure you,
    it’s a confusing experience.    You can avoid some of this madness by avoiding
    generator expressions or list comprehensions on your first version of the code.
    Write the logic the obvious way, using traditional loops, iterator tools, or normal
    generators (coming up). Once you know it’s working, *then and only then* should
    you collapse the logic into a generator expression, and *only* if you can do so
    without eschewing all your error handling (`try` statements).    This may sound
    like a lot of extra work, but I follow this exact pattern in competitive code
    golfing, especially when I’m up against the clock. My understanding of generator
    expressions is usually my main advantage against less-experienced competitors,
    but I *always* write the standard loop or generator first; I cannot afford to
    waste time debugging bad logic in a generator expression.    ### When to Use Generator
    Expressions    It’s difficult to set a hard-and-fast rule on when generator expressions
    should be used. As always, the important factor is readability. Most of my preceding
    examples split the generator expression across multiple lines, but they’re primarily
    intended to be written on one line. If doing so results in code that is difficult
    to visually parse, think twice about using generator expressions at all.    In
    a way, a generator expression is to an iterator as a lambda is to a function,
    in that it’s particularly useful for defining a one-off iterator right where you’ll
    use it. You can even omit the extra parentheses around a generator expression
    when it’s the sole argument. A generator expression, like a lambda, is best suited
    for simple, one-off logic that would benefit from being declared right where it’s
    used.    When the purpose of this one-off iterator is to populate a list, a list
    comprehension would be used. The same is true of set comprehensions and dictionary
    comprehensions for their respective collections.    Generators are preferred over
    generator expressions whenever you’re working with more complicated logic. Because
    a generator expression follows the same syntactic structure as an ordinary function,
    it isn’t prone to becoming unreadable in the same way generator expressions are.    ##
    Simple Coroutines    The *coroutine* is a type of generator that *consumes* data
    on demand, instead of producing data, and it waits patiently until it receives
    it. For example, you could write a coroutine to maintain a running average temperature;
    you can periodically send a new temperature to the coroutine, and it will immediately
    recalculate the average with each new value.    There are two kinds of coroutines.
    What I’m covering here is the *simple coroutine*. Later, when I cover concurrency,
    I’ll introduce the *native coroutine* (also known as the *asynchronous coroutine*),
    which employs and further builds on these concepts.    For the rest of this chapter,
    when I refer to *coroutines*, assume I’m talking about simple coroutines.    Because
    coroutines are generators, you can use `close()` and `throw()` with them. Control
    can be handed off to another coroutine, using `yield from`. Only `next()` will
    not work here, since you are sending values, rather than retrieving them; instead,
    you use `send()`.    For example, I want to count the number of vehicles (from
    the earlier `traffic()` generator) of a particular color in an iterative fashion.
    Here’s a coroutine that does that:    [PRE212]    Listing 10-48: *traffic_colors_coroutine.py:1a*    The
    `color_counter()` coroutine function accepts a single argument: a string for the
    color of the vehicle being counted. This argument will be passed when the generator
    iterator is created.    I want this coroutine to receive data until I explicitly
    close it, so I use an infinite loop. The key difference between a generator and
    a coroutine is the location where the yield statement appears. Here, the `yield`
    expression is being *assigned* to something—specifically, to the name `vehicle`
    ❶. The data sent to the coroutine is assigned to `vehicle`, which I can then process
    by checking whether the color matches and incrementing the count of vehicles that
    match. Finally, I print out the current count.    As I mentioned, I’ll reuse the
    infinite traffic generator from earlier to create the data:    [PRE213]    Listing
    10-49: *traffic_colors_coroutine.py:2*    The usage of my `color_counter()` coroutine
    is not too different from that of a generator, but there are a few key differences:    [PRE214]    Listing
    10-50: *traffic_colors_coroutine.py:3*    Before I can use the coroutine, I have
    to create a coroutine object (actually, a generator iterator) from the coroutine
    function. I bind this object to `counter`.    I send data to a coroutine by using
    its `send()` method. However, before a coroutine can receive data, it must be
    *primed* by passing `None` to `send()`:    [PRE215]    Listing 10-51: *traffic_colors_coroutine.py:4a*    Priming
    causes the coroutine to run up to its first `yield` statement. Without priming,
    whatever value is first sent is lost, as it’s the `yield` statement that receives
    the value sent in.    Alternatively, I could prime like this:    [PRE216]    Listing
    10-52: *traffic_colors_coroutine.py:4b*    It doesn’t matter which you use. I
    prefer the technique in [Listing 10-51](#listing10-51), because it makes it clear
    I’m priming a coroutine, rather than working with any old generator.    After
    priming, I can use the coroutine:    [PRE217]    Listing 10-53: *traffic_colors_coroutine.py:5a*    I
    iterate over the `traffic()` generator, sending each value to the coroutine `counter`
    by using the `send()` method. The coroutine processes the data and prints out
    the current count of red vehicles.    In the context of my loop, once I’ve iterated
    through a hundred vehicles, I manually close the coroutine and break out of the
    loop.    Running this code produces the following redacted output:    [PRE218]    ###
    Returning Values from a Coroutine    In real projects, one very rarely wants to
    print the results and be done. For most coroutines to be useful, you need some
    way to retrieve the data being produced.    To do this with my color counter,
    I’ll change one line in my coroutine and drop the `print()` statement I no longer
    want, like this:    [PRE219]    Listing 10-54: *traffic_colors_coroutine.py:1b*    I
    place the name `matches` after the `yield` keyword to indicate that I want to
    yield the value bound to that variable. Because a coroutine instance is really
    a special kind of generator iterator, it can both accept and return values with
    the `yield` statement. In this case, on each iteration, a new value is accepted
    and assigned to `vehicle`, and then the current value of `matches` is yielded.    The
    usage is very similar; it requires just a simple change:    [PRE220]    Listing
    10-55: *traffic_colors_coroutine.py:5b*    Every time a value is sent via `counter.send()`,
    a value is also returned and assigned to `matches`. I print out this value after
    the loop is done, instead of seeing a running count.    The new output is now
    one line, such as this:    [PRE221]    ### Sequence of Behavior    The order in
    which things happen in coroutines can be a little difficult to anticipate. To
    understand this, here is an oversimplified coroutine that only outputs its input:    [PRE222]    Listing
    10-56: *coroutine_sequence.py*    Here’s the sequence of behavior when using a
    generator as both a generator and a coroutine like this:    1.  The coroutine
    is primed with `co.send(None)` ❺, advancing it to the first `yield` statement
    ❷ and yielding the initial value of `ret` (`None`). This value is printed out
    external to the coroutine ❻. 2.  The first input to the coroutine (`0`) is accepted
    from `co.send()` ❽ and stored in `recv` ❶. 3.  The value of `recv` (`0`) is printed
    out ❸ and then stored in `ret` ❹. 4.  The coroutine advances to the next `yield`
    ❷. 5.  The current value of `ret` (`0`) is yielded ❷, stored in `current` ❼, and
    printed in the `for` loop ❾. The `for` loop advances. 6.  The next input (`1`)
    is accepted from `co.send()` ❽ and stored in `recv` ❶. 7.  The new value of `recv`
    (`1`) is printed out ❷ and then stored in `ret`. 8.  The coroutine advances to
    the next `yield`. 9.  The current value of `ret` (`1`) is yielded ❷, stored in
    `current` ❼, and printed in the `for` loop ❾. The `for` loop advances. 10.  And
    so on and so forth.    In simpler terms, the coroutine will always `yield` a value
    before it accepts a new value from `send()`. This is because the right side of
    the assignment expression is evaluated before the left side. The behavior is consistent
    with the rest of Python, even though it may feel a bit surprising in this context
    before you’re used to it.    ## What About Async?    Some Python developers insist
    that simple coroutines have no place in modern Python code, that they’ve been
    entirely replaced by *native coroutines*—also known as *async coroutines*. This
    may be the case, but the difference in usage is nontrivial. Native coroutines
    have a number of advantages, but they have to be called differently. (I’ll cover
    `asyncio` and native coroutines in Chapter 16.)    ## Wrapping Up    In this chapter,
    I’ve covered the various forms of generator objects—generator expressions, comprehensions,
    and simple coroutines—and introduced infinite iterators.    Generators and coroutines
    make it possible to utilize lazy evaluation in your iterative code, wherein values
    are only evaluated on demand. When these features are utilized correctly, your
    code can process large amounts of data without hanging or crashing.    I’ll build
    on many of these features in Chapter 16, when I introduce asynchrony.    # 11
    Text IO and Context Managers  ![](Images/chapterart.png)  I find that a project
    doesn’t feel *real* until I start working with files. Text-based files, the most
    common way to store data, are the key to retaining state between program runs.    While
    it’s perfectly simple to open a text file in Python, there are many silent subtleties
    that are often overlooked until they bite you in the rear. Many developers make
    do with some idiosyncratic combination of techniques that appear to work but are
    far removed from the beauty and simplicity of idiomatic Python.    In this chapter,
    I’ll break down the two central components involved in working with text files:
    *streams* and *path-like objects*. I’ll cover the myriad ways of opening, reading
    from, and writing to files, discuss how to work with the filesystem, and wrap
    up with a whirlwind tour of some common file formats.    ## Standard Input and
    Output    So far, we’ve taken functions like `print()` and `input()` for granted.
    They’re practically always the first functions a developer learns in a language,
    but they’re also an essential starting point for a true understanding of text
    input and output. Let’s take a deeper look.    ### Revisiting print()    As you’ve
    seen throughout this book, the `print()` function takes a string argument and
    prints it on the screen. That is simple enough, but the functionality of `print()`
    does not end there. You can use `print()` to quickly and flexibly output multiple
    values in a number of ways, and as you’ll see in a later section, you can even
    use it to write to files.    #### Standard Streams    To fully understand the
    potential of `print()`, you must understand streams. When you use `print()`, you
    send the string to the *standard output stream*, a special communication channel
    provided by your operating system. The standard output stream behaves like a queue:
    you push data, usually strings, to the stream, and these strings can be picked
    up in order by other programs or processes, notably the terminal. Your system
    sends all strings provided to `print()` to the standard output stream, by default.    Your
    system also has a *standard error stream* to display error messages. Normal output
    is sent to the standard output stream, and error-related output is sent to the
    standard error stream.    So far in this book, when I’ve wanted to print an error
    message, I’ve used an ordinary `print()` call, the same as for a normal message:    [PRE223]    Listing
    11-1: *print_error.py:1a*    This is fine as long as the user only needs the error
    output to appear in the terminal. However, say the user wants to use the terminal
    to pipe all program output into files, so that normal output goes into one file
    and error output goes into the other. Here’s an example in bash:    [PRE224]    The
    user would expect *output.txt* to contain `Normal message` and *error.txt* to
    contain `Scary error occurred`. However, because `print()` sends messages to the
    standard output stream by default, both messages got exported to *output.txt*.
    Meanwhile, *error.txt* is completely empty.    To send the error text to the standard
    error stream instead, I have to specify it by using the `file=` keyword argument
    on `print()`:    [PRE225]    Listing 11-2: *print_error.py:1b*    I first import
    the `sys` module, which gives me access to `sys.stderr`, a handle to the standard
    error stream. I send the error message to the standard error stream by specifying
    the argument `file=sys.stderr` in my second `print()` call. The normal message
    still goes to standard output, as the default argument is `file=sys.stdout`.    Revising
    the shell session from before, the usage is the same, but you can see the outputs
    are now sent where they’re expected to be:    [PRE226]    The ordinary message
    has been piped to the file *output.txt*, and the error message has been piped
    to the file *error.txt*. This is the standard expected behavior for output from
    command-line programs being used in this manner.    As the parameter name `file=`
    suggests, the `print()` function is not limited to the standard streams. In fact,
    as you’ll see in a moment, it is quite well suited to writing text to files.    ####
    Flush    One important fact to know is that standard streams are implemented as
    *buffers*: data can be pushed to a buffer, which behaves like a queue. That data
    will wait there until it is picked up by the terminal, or whatever process or
    program is intended to display it. In the case of standard output and standard
    error, text is pushed to the stream buffer, and then the buffer is *flushed* when
    its contents are all printed to the terminal. Flushing doesn’t always happen when
    you expect, for a plethora of reasons (all beyond the scope of this book). On
    occasion, you will send a message with `print()` and then wonder why it hasn’t
    printed to the terminal yet.    Usually, it’s best to let the system decide when
    to flush the standard streams, instead of forcing it yourself. However, in some
    cases, you may want to force it. For example, you may want to add something to
    the end of a line already displayed on the terminal.    Here’s a simple progress
    indicator that does exactly that. I’ll use `time.sleep()` to indicate that some
    time-consuming process is happening, like a download. I want to ensure the user
    knows the program hasn’t crashed, so I display a “Downloading . . . ” message,
    adding another dot every tenth of a second:    [PRE227]    Listing 11-3: *progress_indicator.py*    The
    `end=` keyword argument on `print()` prevents a new line from being printed. I’ll
    come back to this later. The important piece for the example is the `flush=` keyword
    argument. If I’d omitted that, the user wouldn’t have seen anything until the
    loop had finished, because the buffer would have waited for the newline character
    before writing out to the terminal. However, by forcing the buffer to flush, the
    line on the terminal updates on each loop iteration.    If you need all your `print()`
    calls to flush every time by default, you can run Python in *unbuffered mode*,
    by passing the `-u` flag to the Python interpreter when you invoke your program,
    as in `python3 -u -m mypackage`.    #### Printing Multiple Values    The `print()`
    function can accept any number of ordered arguments, and each will be converted
    into strings using each value’s `__str__()` special method. This is a sort of
    quick and dirty alternative to formatting with f-strings.    For example, I might
    want to store an address in multiple pieces and then be able to print out the
    whole thing. I’ll initialize the individual values:    [PRE228]    Listing 11-4:
    *address_print.py:1*    I could use formatted strings to put the address together:    [PRE229]    Listing
    11-5: *address_print.py:2a*    While this works, I can do the same thing without
    the f-string, resulting in a simpler `print()` statement:    [PRE230]    Listing
    11-6: *address_print.py:2b*    The `print()` statement converts each argument
    to a string and then concatenates the pieces together, with a space between each
    piece (by default). In either case, the output is the same:    [PRE231]    The
    benefits of this `print()` statement without f-strings are readability and efficiency.
    Since the final output is nothing more than all the pieces concatenated together
    with spaces, and since I have no need to store the whole string in a single value
    in memory, the f-string is overkill.    Here’s another example of the `print()`
    function’s innate concatenating abilities. I can quickly generate a table of property
    values from a dictionary. First, here’s that dictionary:    [PRE232]    Listing
    11-7: *market_table_print.py:1*    I want to print out a table, with the street,
    number, and formatted property value, separating each column with a tab character
    (`\t`). I’ll use an f-string first, just so you can see why I wouldn’t use that
    approach:    [PRE233]    Listing 11-8: *market_table_print.py:2a*    While this
    produces the desired output (which I’ll show in a moment), the f-string adds an
    unnecessary layer of complexity. Since I’m separating each column with a tab character,
    I can once again make better use of `print()` instead:    [PRE234]    Listing
    11-9: *market_table_print.py:2b*    The `sep=` argument allows me to define what
    string should be used between each of the values. This `sep` string is a space
    by default, as in [Listing 11-6](#listing11-6), but here, I’m using a tab character
    (`\t`) as a separator instead.    I prefer this solution because it’s much more
    readable. I still use an f-string to format `value` to display the desired comma
    separator, lest I get uglier output like `$144121`. The values bound to `street`
    and `address` do not need any special treatment.    Here’s the output, which is
    the same for either version of the code:    [PRE235]    Another advantage of this
    approach is that if I decide I want to separate columns with spaces and a vertical
    bar character, I only need to change the `sep=` argument:    [PRE236]    Listing
    11-10: *market_table_print.py:2c*    If I had used f-strings, I would have needed
    to change the character I was using for each separation.    Here’s the new output:    [PRE237]    The
    `print()` function also has an `end=` parameter, to determine what to append to
    the end of the output. By default, this is a newline character (`\n`), but you
    can change this in the same manner as `sep=`.    One common use is to set `end=\r`,
    which will cause the next printed line to overwrite the previous line. This is
    especially useful in status updates, such as progress messages.    ### Revisiting
    input()    The `input()` function allows you to receive user input from the terminal,
    that is, from the *standard input stream*. Unlike with `print()`, the `input()`
    function has no extra features here, but it is useful to have a formal familiarity
    with `input()` moving forward.    The sole argument accepted by `input()` is `prompt`,
    an optional string that is printed to standard output without adding a trailing
    newline character. The value passed to `prompt=` is usually a message that informs
    the user what they’re supposed to input. This argument can be any value that can
    be converted to a string via its `__str__()` method, the same as in the ordered
    arguments passed to `print()`.    Here’s a basic prompt for an MLS number, perhaps
    intended as part of a property search program:    [PRE238]    Listing 11-11: *search_input.py*    Running
    this prompts the user for an `MLS` number and then reports that it’s searching
    for a property with that number:    [PRE239]    There is absolutely nothing more
    to using `input()`.    ## Streams    To work with any data file, you need to obtain
    a *stream*, also called a *file object* or *file-like object*, which offers methods
    for reading from and writing to that particular file in memory. There are two
    kinds of streams. *Binary streams*, which form the foundation of all streams,
    work with data in binary (1s and 0s). *Text streams* handle the encoding and decoding
    of text from binary.    Streams can work with more than just traditional files,
    such as your run-of-the-mill *.txt* files, Word documents, or what have you. The
    objects for the standard output (`sys.stdout`), standard error (`sys.stderr`),
    and standard input (`sys.stdin`) that you’ve already been using are, in fact,
    streams. Everything you know about the standard streams is the same on any stream.    For
    this chapter, I’ll focus exclusively on text streams. I’ll dig into binary data
    and binary streams in Chapter 12.    You can create a stream that works with a
    file by using the built-in `open()` function. There is a *lot* to using this function,
    but I’ll start with the most simplistic usage.    The code in this entire section
    will assume every file is in the same directory as the Python module opening it.
    If the file is somewhere else on the machine, you’ll need a path, which is a separate
    topic I’ll explore later in this chapter.    To read a file named *213AnywhereAve.txt*
    (the contents of which are identical to the output coming up), I’ll create a stream
    to work with it. Python beautifully handles creating the stream to the file in
    the background, so I only need to use the `open()` function:    [PRE240]    Listing
    11-12: *read_house_open.py:1a*    The `open()` function returns a stream object—specifically,
    a `TextIOWrapper` object—that works with the contents of the *213AnywhereAve.txt*
    file. I bind this stream object to `house`.    Next, I read the entire contents
    of the file by calling the `read()` method on `house` and passing the string it
    returns directly to `print()`.    Once I’m done working with the file, I *must*
    close it, and I do that on the last line. It’s important not to leave file closing
    to the garbage collector, as that is neither guaranteed to work nor portable across
    all Python implementations. What’s more, when writing to a file, Python is not
    guaranteed to finish making changes to the file until `close()` is called. This
    means that if you forget to close before your program ends, your changes may be
    lost in part or in whole.    Assuming the *213AnywhereAve.txt* file exists in
    the same directory as this Python module, this code will output the entire contents
    of the file to the screen:    [PRE241]    You can only read from this particular
    stream. Writing to a file requires me to open it differently, which I’ll return
    to shortly.    ## Context Manager Basics    A *context manager* is a type of object
    that automatically handles its own cleanup tasks when program execution leaves
    a certain section of code, or *context*. This context is provided by a Python
    `with` statement. (This is the last of Python’s compound statements, alongside
    familiar friends such as `if`, `try`, and `def`,to name a few.) To really understand
    how this works, I’ll unpack the underlying logic and build up to the use of context
    managers.    There’s one remaining problem in [Listing 11-12](#listing11-12).
    As it stands, the example is pretty safe, as `house.read()` isn’t going to fail
    unless I’m unable to open the file. In reality, though, I’d do more after opening
    than just printing out the contents of the file. I may process the data in any
    number of ways, store it in a collection, or search it for something in particular.
    There’s lots of room for errors and exceptions. With this approach, if I successfully
    open the file but experience any sort of exception while reading from or working
    with that file—say, a `KeyError` if I tried to read it into a dictionary—the `close()`
    method would never get called.    To get around this, I can wrap the `close()`
    call in the `finally` clause of a `try` statement:    [PRE242]    Listing 11-13:
    *read_house_open.py:1b*    If the file *213AnywhereAve.txt* does not exist, it
    will raise a `FileNotFoundError` exception. If I’m able to open it successfully,
    I can try to `read()` from the `house` stream. I’m not catching any exceptions,
    so they’ll automatically bubble up from this `try` statement. Because the `close()`
    call is in the `finally` clause, it will be called whether there’s an error or
    not.    In practice, though, always remembering to call `close()` is utterly impractical,
    not to mention a royal pain. If you forget, or if the program terminates before
    you can call `close()`, all sorts of pesky bugs can result.    Thankfully, all
    stream objects are context managers, so they can clean up after themselves with
    a `with` statement, encapsulating that entire `try`-`finally` logic ([Listing
    11-13](#listing11-13)) into a single statement:    [PRE243]    Listing 11-14:
    *read_house_open.py:1c*    This opens the *213AnywhereAve.txt* file, binds the
    stream to `house`, and then runs the line of code for reading and printing from
    that file. There’s no need for a manual call to `house.close()`, because the `with`
    statement handles that automatically in the background.    I’ll dig into the mechanics
    of `with` more later on, but as it is the canonical way of working with (most)
    streams, I’ll use it exclusively from here on out.    ## File Modes    The `open()`
    function optionally accepts a second argument: *mode=*, which should be a string
    dictating how the file should be opened, which in turn defines what operations
    may be performed on the stream object—reading, writing, and so on. If you don’t
    pass a `mode=` argument, Python uses `mode=''r''`, which opens the file for reading
    only.    There are eight different file modes for text-based files (see [Table
    11-1](#table11-1)), and the behavior of each is a little different. The base modes
    are as follows:    *   `r` opens the file for *reading*. *   `w` opens the file
    for *writing*; it truncates (erases) the file contents first. *   `a` opens the
    file for *append* writing (that is, writing to the end of the existing file).
    *   `x` *creates* a new file and opens it for writing; the file must not already
    exist.    Adding the addition (`+`) flag adds either reading or writing, whichever
    is missing from the mode. The most important usage is the mode `r+`, which allows
    you to both read from and write to the file *without* the contents being erased
    first.    The behavior of each mode can feel a bit unexpected at times. [Table
    11-1](#table11-1), which is based in part on a Stack Overflow answer by industryworker3595112
    (see [https://stackoverflow.com/a/30931305/472647/](https://stackoverflow.com/a/30931305/472647/)),
    breaks down the functionalities of the modes.      Table 11-1: File Modes       |
    **Functionalities** | **Modes** | | --- | --- | |  | **`r`** | **`r+`** | **`w`**
    | **`w+`** | **`a`** | **`a+`** | **`x`** | **`x+`** | | Allow read | ✓ | ✓ |  |
    ✓ |  | ✓ |  | ✓ | | Allow write |  | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | | Can create
    new file |  |  | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | | Can open existing file | ✓ | ✓ | ✓
    | ✓ | ✓ | ✓ |  |  | | Erase file contents first |  |  | ✓ | ✓ |  |  |  |  | |
    Allow seek | ✓ | ✓ | ✓ | ✓ |  | ✓* | ✓ | ✓ | | Initial position at start | ✓ |
    ✓ | ✓ | ✓ |  |  | ✓ | ✓ | | Initial position at end |  |  |  |  | ✓ | ✓ |  |  |  *Only
    allows seek on read  In a stream, the *position* dictates where you read to and
    write from within the file. The `seek()` method allows you to change this position,
    if the mode supports it. By default, the position will be at either the start
    or the end of the file. I’ll cover this in depth in a later section.    You can
    also use the `mode=` parameter to switch between *text mode* (`t`), which is the
    default, and *binary mode* (`b`). In Chapter 12, I’ll work exclusively in binary
    mode. For now, at least be aware of which mode you’re opening a file in. For example,
    the argument `mode=''r+t''` opens the file in read-write text mode, and it is
    the same as `mode=''r+''`. By contrast, `mode=''r+b''` opens the file in read-write
    binary mode. For this entire chapter, I’ll only use the default text mode.    When
    you’re opening a file in read mode (`r` or `r+`), the file *must* already exist.
    If it doesn’t, the `open()` function will raise `FileNotFoundError`.    Create
    mode (`x` or `x+`) expects precisely the opposite: the file *must not* already
    exist. If it does, the `open()` function will raise `FileExistsError`.    Write
    mode (`w` or `w+`) and append mode (`a` or `a+`) have neither of these problems.
    If the file exists, it will be opened; if it doesn’t, it will be created.    If
    you attempt to write to a stream opened only for reading (`r`) or read from a
    stream opened only for writing (`w`, `a`, or `x`), that read or write operation
    will raise the `io.UnsupportedOperation` error.    If you want to check in advance
    which operations a stream supports, use the `readable()`, `writable()`, or `seekable()`
    methods on the stream. For example:    [PRE244]    Listing 11-15: *check_stream_capabilities.py*    ##
    Reading Files    To read from a file, you first acquire a stream, opening it in
    one of the readable modes (`''r''`, `''r+''`, `''w+''`, `''a+''`, or `''x+''`).
    From there, you can read in one of four ways: `read()`, `readline()`, `readlines()`,
    or iteration.    For all of the examples in this section, I’ll read from the following
    text file:    [PRE245]    Listing 11-16: *78SomewhereRd.txt*    ### The read()
    Method    I can use the `read()` method to read the complete contents of the `78SomewhereRd.txt`
    file like this:    [PRE246]    Listing 11-17: *read_house.py:1a*    After acquiring
    the stream `house`, which I opened in read mode, I call the `read()` method to
    read the entire file in as a single string, which I bind to `contents`. Each of
    the lines in the *78SomewhereRd.txt* file ends with a newline character (`\n`),
    and those are retained in the string. If I print `contents` as a raw string via
    `repr()`, you can see the literal newline characters:    [PRE247]    This line
    of code outputs the following (redacted for brevity):    [PRE248]    (Remember,
    those literal `\n` characters are only there because I printed the raw string.
    A normal print of contents would recognize the newline characters and create new
    lines accordingly.)    By default, `read()` will read characters until the end
    of the file is encountered. You can alter this behavior with the `size=` argument,
    which takes a maximum number of characters to read. For example, to read a maximum
    of 20 characters from the file (and less if the end of the file is encountered
    first), I would do the following:    [PRE249]    Listing 11-18: *read_house.py:1b*    This
    would output the following:    [PRE250]    ### The readline() Method    The `readline()`
    method behaves exactly like `read()`, except that it reads only up to and including
    a newline (`\n`), instead of just the end of the file. I can use this to read
    the first two lines of the file. As before, I’m using `repr()` to show the raw
    strings, as I want to actually *see* the newline characters for the sake of the
    example:    [PRE251]    Listing 11-19: *readline_house.py*    The `house` stream
    remembers my position in the file, so after each call to `readline()`, the stream
    position is set to the beginning of the next line. Running this code outputs the
    first two lines, which I print as raw strings so I can see the literal newline
    characters:    [PRE252]    The `readline()` method also has a `size=` positional
    argument, which works like `read(size=)`, except that it will stop at the first
    newline it encounters if the size is greater than the line’s length.    ### The
    readlines() Method    I can read all the lines in the file at once as a list of
    strings, using `readlines()`:    [PRE253]    Listing 11-20: *readlines_house.py*    Each
    individual line is stored in a string, and all the strings are stored in the list
    `lines`. Once I’ve read all of the lines, I’ll print each one out, removing the
    trailing newline character from each string by using the `strip()` method on the
    string object. This removes any leading and trailing whitespace characters, including
    newlines.    Running that code outputs this:    [PRE254]    The `readlines()`
    method has a `hint=` parameter, which is similar to the `size=` parameter on `read()`.
    The critical difference is that `readlines()` *always* reads entire lines. If
    the number of characters specified in `hint=` is short of the next newline, `readlines()`
    will still read up to (and including) that next newline.    ### Reading with Iteration    Streams
    themselves are iterators—they implement the `__iter__()` and `__next__()` special
    methods. This means I can iterate over a stream directly!    [PRE255]    Listing
    11-21: *iterate_house.py*    The output is the same as in the last example, but
    this iterative approach doesn’t have the overhead of creating a list I’ll only
    throw away after printing.    If you’re only reading a file once, direct iteration
    over the stream is usually going to be the cleaner and (probably) more efficient
    solution.    On the other hand, if you need to access the contents of a file more
    than once in your program’s execution, you’ll almost always want to read the data
    into memory—that is, to read it from the stream and store it in a typical Python
    collection or other value. It’s always faster to read from a value in memory than
    from a file!    ## Stream Position    After every read and write operation, your
    position in the stream will change. You can use the `tell()` and `seek()` methods
    to work with the stream position.    The `tell()` method returns your current
    stream position as a positive integer, representing the number of characters from
    the start of the file.    The `seek()` method allows you to move back and forth
    within a stream, character by character. When working with text streams, it accepts
    one argument: a positive integer representing a new position to move to, represented
    by the number of characters from the beginning. This method works on any stream,
    as long as it isn’t opened in append mode (`''a''` or `''a+''`).    The most common
    use is to jump to the beginning of the file with `seek(0)`. To demonstrate that,
    I’ll print out the first line of the *78SomewhereRd.txt* file three times:    [PRE256]    Listing
    11-22: *iterate_house.py*    After opening the file, I loop three times. On each
    iteration of the loop, I print out the current line, with the newline removed
    with `strip()`. Then, I reposition the stream at the beginning of the file, before
    the next loop iteration.    The output is as follows:    [PRE257]    Additionally,
    you can skip to the end of the stream with `seek(0, 2)`, meaning you’re moving
    `0` positions away from the end of the file (a `whence` of `2`). When doing this,
    you must provide `0` as the first argument and `2` as the second argument; nothing
    else works for this.    The `seek()` method can also be used to skip to other
    stream positions, not just the start or the end. A trivial demonstration of this
    would be to skip one character each time I read the opening line:    [PRE258]    Listing
    11-23: *iterate_house_mangle.py*    Instead of passing `0` to `seek()`, I’m passing
    `n`, the iteration count from the loop, before reading the line. On each iteration,
    the first line is printed again, but with one less character at the beginning:    [PRE259]    That’s
    an interesting example, though it’s not very useful. Don’t worry—I’ll employ `seek()`
    in a more practical fashion in some upcoming examples.    ## Writing Files    The
    first thing to remember about writing to a stream is that you’re always *overwriting*,
    never *inserting*! This doesn’t matter when you’re appending to the end of a file,
    but in all other cases, it can cause confusion and undesired results.    When
    modifying a file, read the contents into memory, modify the file there, and then
    write it out again, to reduce the chances of obliterating data because of a bug.
    You can write out the new data either in place or to a temporary file that you
    move into place. I’ll introduce the latter technique later on in this chapter,
    when I discuss the `pathlib` module. For now, I’ll just overwrite files in place.
    Either technique will prevent a lot of annoying and destructive bugs.    There
    are three ways to write to a stream: the `write()` method, the `writelines()`
    method, and the `print()` function. Before using any of these, you must be certain
    your stream is open in a writable file mode (anything except `''r''`) and know
    your current stream position! All file modes but one have an initial stream position
    at the beginning of the file. The exception is the append mode (`''a''` and `''a+''`),
    which has an initial position at the end of the file. As you read from and write
    to the stream, that position will change.    ### The write() Method    The `write()`
    method writes the given string to the file, starting at the current stream position,
    and it returns an integer representing how many characters it wrote to the file.
    Remember, though, it overwrites any data that’s in the way, from the stream position
    until the end of the new data. To prevent accidental data loss, read the file
    into memory, modify the data there, and then write it back out to the same file.    That
    property description in *78SomewhereRd.txt* isn’t very appealing. I’ll write a
    program to improve the description and write the updated real estate listing to
    the file:    [PRE260]    Listing 11-24: *improve_real_estate_listing.py:1a*    First,
    I open the file in read-write mode. Instead of directly modifying the file contents
    via the stream, I’ll read the file’s data into memory as a string, binding it
    to `contents`. I’ll revise the description by working on this string, rather than
    with the stream itself:    [PRE261]    Listing 11-25: *improve_real_estate_listing.py:2a*    I
    use the `replace()` string method to replace the unappealing words and phrases
    with more attractive ones.    Once I’m happy with the new version of my string,
    I can write it out to the file:    [PRE262]    Listing 11-26: *improve_real_estate_listing.py:3a*    I
    position myself at the start of the file, since I want to overwrite everything
    there, using `real_estate_listing.seek(0)`. Then, I write the new contents of
    the file. Any of the old contents that are in the way are overwritten.    The
    last remaining trouble is that the new contents are shorter than the old contents,
    so some old data will be left hanging out at the end of the file. After `write()`,
    the stream position is at the end of the new data I just wrote, so I can clean
    up the leftovers from the old data with this:    [PRE263]    Listing 11-27: *improve_real_estate_listing.py:4*    By
    default, the `truncate()` method erases everything from the current stream position
    through to the end of the file. It does this by truncating (or shortening) the
    file to a given number of bytes, which can be passed as an argument. If no explicit
    size is passed in, `truncate()` uses the value provided by the `tell()` method,
    which corresponds to the current stream position.    Once the flow leaves the
    `with` statement, the stream is flushed and closed, ensuring the changes to the
    file are written.    That program doesn’t output anything on the command line.
    If I open the *78SomewhereRd.txt* file, I can see the new description:    [PRE264]    ###
    The writelines() Method    Just as `readlines()` stores the contents of the file
    as a list of strings, `writelines()` writes out a list of strings to a file. That
    is all it does. The `writelines()` method doesn’t insert newline characters at
    the end of each string in the list provided to it. The sole difference between
    `write()` and `writelines()` is that the latter accepts a list of strings, instead
    of just a single string, and returns nothing.    I can modify the file using `writelines()`.
    For this example, I restored the *78SomewhereRd.txt* file to what it was in [Listing
    11-16](#listing11-16).    [PRE265]    Listing 11-28: *improve_real_estate_listing.py:1b*    I
    open the file *78SomewhereRd.txt* as before, but this time, I read the contents
    in with `real_estate_listing.readlines()`, which returns a list of strings I bind
    to the name `contents`.    Next, I make my changes to the description by modifying
    that list of strings. Once again, I’m not working with the stream here at all,
    but rather with the list of strings containing the data I read from the stream.    [PRE266]    Listing
    11-29: *improve_real_estate_listing.py:2b*    I iterate over each line in `contents`,
    make the necessary substitutions, and store the modified lines in a new list,
    `new_contents`. I’ll be the first to admit that this implementation is much less
    efficient than the version using `write()`, but this technique becomes useful
    when you’re working with many lines that need to be individually processed.    Finally,
    I can write out the new file contents using `writelines()`:    [PRE267]    Listing
    11-30: *improve_real_estate_listing.py:3b-4*    I pass the list of strings to
    `writelines()`. Because the newline character was retained at the end of each
    line as it was read in by `readlines()`, those same newline characters are being
    written out. If I had removed them, however, I would have had to add them back
    in manually before calling `writelines()`.    The output is the same for the example
    in the previous section.    ### Writing Files with print()    You know that `print()`
    outputs data using the `sys.stdout` stream by default, but you can override this
    by passing a stream to the `file=` argument. One particular use for this is to
    conditionally output either to the terminal or to a file. The simple formatting
    features on `print()` make it an excellent alternative to `write()`, in some cases.    The
    rules of usage are identical to `write()` and `writelines()`: you must have a
    stream that is writable, and you must be mindful of the stream position.    To
    demonstrate this, I’ll rewrite the real estate listings table produced by [Listing
    11-14](#listing11-14) to output to a file, instead of the standard output. I’ll
    reuse the `nearby_properties` dictionary from [Listing 11-7](#listing11-7):    [PRE268]    Listing
    11-31: *print_file_real_estate_listing.py:1*    Here’s my revised code for generating
    the real estate listings table:    [PRE269]    Listing 11-32: *print_file_real_estate_listings.py:2*    I
    open the file *listings.txt* in write mode, since I want to either create or completely
    replace that file when this code runs. The loop iterating over `nearby_properties`
    and the call to `print()` are both essentially unchanged from before. The difference
    here is that I pass the `real_estate_listings` stream to the `file=` parameter
    of `print()`.    The output is the same as before, but it is written to the *listings.txt*
    file instead of being printed to the terminal:    [PRE270]    ### Line Separators    If
    you have any experience with writing portable code, you may remember that in Windows
    operating systems, lines are separated with both the carriage return and the newline
    (`\r\n`), while only the newline (`\n`) is used in UNIX systems. This difference
    can be a royal pain when working with files in many languages.    On the other
    hand, Python streams abstract this difference out behind the scenes. When writing
    to a stream in text mode using `print()`, `write()`, or `writelines()`, you only
    ever use the *universal newline*—which is the newline character (`\n`)—as your
    line separator. Python will always substitute the system-appropriate line separator.    In
    the same way, when reading from files using `read()`, `readline()`, or `readlines()`,
    you only need to work with the newline character as the line separator.    ##
    Context Manager Details    So far in this chapter, I’ve used a context manager
    via the `with` statement every time I’ve opened a file, to idiomatically ensure
    streams are closed as soon as they’re no longer needed.    Like many of Python’s
    compound statements, `with` statements utilize certain special methods to work
    with objects. This means `with` is not limited to streams: it can be made to handle
    virtually any situation that calls for ``try-finally logic. To demonstrate this,
    I’ll unpack precisely how the `with` statement interfaces with streams, and then
    I’ll apply that knowledge to a custom class.``   [PRE271] VAR = EXPR VAR.__enter__()
    try:     BLOCK finally:     VAR.__exit__() [PRE272] real_estate_listing = open("213AnywhereAve.txt")
    try:     print(real_estate_listing.read()) finally:     real_estate_listing.close()
    [PRE273] real_estate_listing = open("213AnywhereAve.txt") **real_estate_listing.__enter__()**
    try:     print(real_estate_listing.read()) finally:     **real_estate_listing.__exit__()**
    [PRE274] **with** open("213AnywhereAve.txt") **as real_estate_listing:**     print(real_estate_listing.read())
    [PRE275] with open(''213AnywhereAve.txt'', ''r'') as left, open(''18SomewhereLn.txt'',
    ''r'') as right:     # work with the streams left and right however you want [PRE276]
    class House:     def __init__(self, address, house_key, **rooms):         self.address
    = address         self.__house_key = house_key         self.__locked = True         self._rooms
    = dict()         for room, desc in rooms.items():             self._rooms[room.replace("_",
    " ").lower()] = desc      def unlock_house(self, house_key):         if self.__house_key
    == house_key:             self.__locked = False             print("House unlocked.")         else:             raise
    RuntimeError("Wrong key! Could not unlock house.")      def explore(self, room):         if
    self.__locked:             raise RuntimeError("Cannot explore a locked house.")          try:             return
    f"The {room.lower()} is {self._rooms[room.lower()]}."         except KeyError
    as e:             raise KeyError(f"No room {room}") from e      def lock_house(self):         self.__locked
    = True         print("House locked!") [PRE277] class HouseShowing:      def __init__(self,
    house, house_key):         self.house = house         self.house_key = house_key
    [PRE278]  def __enter__(self):         self.house.unlock_house(self.house_key)         return
    self [PRE279]  def show(self, room):         print(self.house.explore(room)) [PRE280]  def
    __exit__(self, exc_type, exc_val, exc_tb):       ❶ if exc_type:             print("Sorry
    about that.")       ❷ self.house.lock_house() [PRE281] house = House("123 Anywhere
    Street", house_key=1803,               living_room="spacious",               office="bright",               bedroom="cozy",               bathroom="small",               kitchen="modern")
    [PRE282] with HouseShowing(house, house_key=9999) as showing:     showing.show("Living
    Room")     showing.show("bedroom")     showing.show("porch") [PRE283] Traceback
    (most recent call last):   File "context_class.py", line 57, in <module>     with
    HouseShowing(house, 9999) as showing:   File "context_class.py", line 38, in __enter__     self.house.unlock_house(self.house_key)   File
    "context_class.py", line 15, in unlock_house     raise RuntimeError("Wrong key!
    Could not unlock house.") RuntimeError: Wrong key! Could not unlock house. [PRE284]
    with HouseShowing(house, house_key=**1803**) as showing:     showing.show("Living
    Room")     showing.show("bedroom")     showing.show("porch") [PRE285] House unlocked.
    The living room is spacious. The bedroom is cozy. Sorry about that. House locked!
    Traceback (most recent call last):   File "context_class.py", line 22, in explore     return
    f"The {room.lower()} is {self._rooms[room.lower()]}." KeyError: ''porch''  The
    above exception was the direct cause of the following exception:  Traceback (most
    recent call last):   File "context_class.py", line 60, in <module>     showing.show("porch")   File
    "context_class.py", line 42, in show     print(self.house.explore(room))  File
    "context_class.py", line 24, in explore     raise KeyError(f"No room {room}")
    from e KeyError: ''No room porch'' [PRE286] with HouseShowing(house, 1803) as
    showing:     showing.show("Living Room")     showing.show("bedroom")     showing.show(**"kitchen"**)
    [PRE287] House unlocked. The living room is spacious. The bedroom is cozy. The
    kitchen is modern. House locked! [PRE288] from pathlib import PurePath path =
    PurePath(''../some_file.txt'')  with open(path, ''r'') as file:     print(file.read())  #
    this is okay (assuming file exists)  # create empty file if none exists path.touch()            #
    fails on Pure paths! [PRE289] from pathlib import **Path** path = **Path**(''../some_file.txt'')  with
    open(path, ''r'') as file:     print(file.read())  # this is okay (assuming file
    exists)  # create empty file if none exists path.touch()            **# okay on
    Path!** [PRE290] /path/to/file.txt [PRE291] import pathlib   def path_parts(path):     print(f"{path}\n")      print(f"Drive:
    {path.drive}")     print(f"Root: {path.root}")     print(f"Anchor: {path.anchor}\n")      print(f"Parent:
    {path.parent}\n")     for i, parent in enumerate(path.parents):         print(f"Parents
    [{i}]: {parent}")      print(f"Name: {path.name}")     print(f"Suffix: {path.suffix}")     for
    i, suffix in enumerate(path.suffixes):         print(f"Suffixes [{i}]: {suffix}")     print(f"Stem:
    {path.stem}\n")      print("-------------------\n") [PRE292] path_parts(pathlib.PureWindowsPath(''C:/Windows/System/python37.dll''))
    [PRE293] C:\Windows\System\python37.dll  Drive: C: Root: \ Anchor: C:\  Parent:
    C:\Windows\System  Parents [0]: C:\Windows\System Parents [1]: C:\Windows Parents
    [2]: C:\ Name: python37.dll Suffix: .dll Suffixes [0]: .dll Stem: python37 [PRE294]
    path_parts(pathlib.PurePosixPath(''/usr/lib/x86_64-linux-gnu/libpython3.7m.so.1''))
    [PRE295] /usr/lib/x86_64-linux-gnu/libpython3.7m.so.1  Drive:  Root: / Anchor:
    /  Parent: /usr/lib/x86_64-linux-gnu  Parents [0]: /usr/lib/x86_64-linux-gnu Parents
    [1]: /usr/lib Parents [2]: /usr Parents [3]: / Name: libpython3.7m.so.1 Suffix:
    .1 Suffixes [0]: .7m Suffixes [1]: .so Suffixes [2]: .1 Stem: libpython3.7m.so
    [PRE296] from pathlib import PosixPath  path = PosixPath(''/home/jason/.bash_history'')
    [PRE297] with path.open(''r'') as file:     for line in file:         continue     print(line.strip())
    [PRE298] w3m nostarch.com [PRE299] from pathlib import PosixPath  path = **PosixPath.joinpath(PosixPath.home(),
    ''.bash_history'')** [PRE300] w3m nostarch.com [PRE301] from pathlib import PosixPath  path
    = PosixPath.home() **/** ''.bash_history'' [PRE302] from pathlib import PosixPath  path
    = **PosixPath(''~/.bash_history'').expanduser()** [PRE303] $ magic_program /home/jason/My_Nextcloud/DeadSimplePython/Status.txt
    [PRE304] $ magic_program DeadSimplePython/Status.txt [PRE305] from pathlib import
    Path print(Path.cwd()) [PRE306] from pathlib import Path path = Path(''../settings.ini'')
    [PRE307] from pathlib import Path path = Path(''../settings.ini'').resolve() [PRE308]
    omission-git/ ├── LICENSE.md ├── omission/ │   ├── __init__.py │   ├── __main__.py
    │   ├── app.py │   ├── common/ │   ├── data/ │   ├── interface/ │   ├── game/
    │   │   ├── __init__.py │   │   └── content_loader.py │   ├── resources/ │   │   ├──
    audio/ │   │   ├── content/ │   │       └── content.txt │   │   ├── font/ │   │   └──
    icons/ │   └── tests/ ├── omission.py ├── pylintrc ├── README.md └── .gitignore
    [PRE309] from pathlib import Path  path = Path(''../resources/content/content.txt'')  with
    path.open() as file:     data = file.read() [PRE310] print(Path.cwd())  # prints
    ''/home/jason/Code/omission-git'' [PRE311] from pathlib import Path  path = Path(''**omission/**resources/content/content.txt'')  with
    path.open() as file:     data = file.read() [PRE312] from pathlib import Path  path
    = Path(**__file__**)**.resolve()** **path = path.parents[1] / Path(''**resources/content/content.txt**'')**  with
    path.open() as file:     data = file.read() [PRE313] from pathlib import Path  path
    = Path(''78SomewhereRd.txt'')  with path.open(''r'') as real_estate_listing:     contents
    = real_estate_listing.read()     contents = contents.replace(''Tiny'', ''Cozy'')     contents
    = contents.replace(''Needs repairs'', ''Full of potential'')     contents = contents.replace(''Small'',
    ''Compact'')     contents = contents.replace(''old storage shed'', ''detached
    workshop'')     contents = contents.replace(''Built on ancient burial ground.'',                                 ''Unique
    atmosphere.'') [PRE314] tmp_path = path.with_name(path.name + ''.tmp'')  with
    tmp_path.open(''w'') as file:     file.write(contents) [PRE315] tmp_path.replace(path)  #
    move the new file into place of the old one [PRE316] **import json**  nearby_properties
    = {     "N. Anywhere Ave.":  {         123: 156_852,         124: 157_923,         126:
    163_812,         127: 144_121,         128: 166_356     },     "N. Everywhere
    St.":     {         4567: 175_753,         4568: 166_212,         4569: 185_123     }
    } [PRE317] with open(''nearby.json'', ''w'') as jsonfile:     json.dump(nearby_properties,
    jsonfile) [PRE318] {     "N. Anywhere Ave.": {         "123": 156852,         "124":
    157923,         "126": 163812,         "127": 144121,         "128": 166356     },     "N.
    Everywhere St.": {         "4567": 175753,         "4568": 166212,  "4569": 185123     }
    } [PRE319] import json  with open(''nearby.json'', ''r'') as jsonfile:     nearby_from_file
    = json.load(jsonfile) [PRE320] for k1, v1 in nearby_from_file.items():     print(repr(k1))     for
    k2, v2 in v1.items():         print(f''{k2!r}: {v2!r}'') [PRE321] ''N. Anywhere
    Ave.'' ''123'': 156852 ''124'': 157923 ''126'': 163812 ''127'': 144121 ''128'':
    166356 ''N. Everywhere St.'' ''4567'': 175753 ''4568'': 166212 ''4569'': 185123
    [PRE322]`  [PRE323]*# 12 Binary and Serialization  ![](Images/chapterart.png)  01100010
    01101001 01101110 01100001 01110010 01111001\. This is the language of computers,
    the delight of hackers, and the subject of that one computer science joke you
    have memorized. If a programming language wants a chance to gain the admiration
    of elite developers, it must allow working with *binary*.    For the programmers
    who haven’t encountered binary yet, I’ll start by breaking down the fundamentals,
    particularly as Python sees them, and the different ways of expressing binary
    data and performing bitwise operations. With that foundation in place, I’ll cover
    how to read and write files in binary, and I’ll wrap up with a whirlwind tour
    of some of the most common binary file formats.    ## Binary Notation and Bitwise    For
    those who are new to the fine art of bit twiddling, I’ll breeze through it now.
    Even if you already know how to do bitwise manipulation, I recommend hanging in
    there for the next few pages for a review—and perhaps some little surprises.    ###
    Number Systems Refresher    *Binary* is a number system with only two digits—`0`
    and `1`—which correspond to the open and closed position (respectively) of gates
    on circuit boards. This is the foundation of all computer programming. Typically,
    this binary is abstracted out for better human comprehension through CPU instructions
    and data types, and then further toward human language through various programming
    constructs. Although you won’t usually need to think much about binary, there
    are times when manipulating it directly is the most effective way to solve a problem.    In
    Python, when writing a numeric literal in binary, you prefix it with `0b` to differentiate
    it from run-of-the-mill decimal (base-10) numbers. For example, while `11` is
    the decimal value “eleven,” `0b11` is the binary value for “three.”    A binary
    *bit* is a single digit. A *byte* is usually made up of eight bits, although uncommonly,
    this can vary. Within a byte, place values typically ascend from right to left,
    as with decimal numbers. You can compose any number by switching on (`1`) or off
    (`0`) the bits at different positions. In a byte, the rightmost place has a value
    of `1`, and each subsequent place has double the preceding value. The value of
    each place is demonstrated in [Table 12-1](#table12-1).      Table 12-1: Place
    Values of Bits       | 128 | 64 | 32 | 16 | 8 | 4 | 2 | 1 |    So, the byte `0b01011010`
    would be equivalent to `64 + 16 + 8 + 2`, or `90`. The computer interprets particular
    bytes differently, depending on the data type—something determined by the code,
    rather than stored in the binary data. From a low-level perspective, the same
    sequence of bits could represent the integer `90`, the ASCII character `''Z''`,
    a part of a floating-point number, a bytecode instruction . . . the possibilities
    are endless. Thankfully, you don’t need to worry about how the computer handles
    this interpretation. Trust the language for that.    #### Hexadecimal    You can
    also represent numeric literals in the *hexadecimal*, or base-16 number system,
    which is so named because there are 16 unique digits for the decimal values `0`
    through `15`. The first 10 use the ordinary digits `0` through `9` and the letters
    `A` through `F` as digits for values `10` through `15`, respectively. The decimal
    value `16` cannot be represented with a single digit in hexadecimal; it is instead
    represented by `10` in this system. In Python, as in most programming languages,
    you prefix hexadecimal literals with `0x` to differentiate them from decimal numbers.
    `0x15` would represent decimal value `21`, because `0x10` (`16`) + `0x05` (`5`)
    = `0x15` (`21`).    When manually composing larger numbers in any number system,
    mentally or on paper, it’s useful to think of each *place value* as the base value
    raised to the place number (starting from zero). For example, the decimal number
    `4972` could be thought of as `2 + 70 + 900 + 4000`, which can further be broken
    down as `(2 * 10`⁰`) + (7 * 10`¹`) + (9 * 10`²`) + (4 * 10`³`).`    [Table 12-2](#table12-2)
    demonstrates this with base 10 (decimal), base 2 (binary), and base 16 (hexadecimal).      Table
    12-2: Place Values in Various Number Systems       | **Number system** | **Place
    values** | | --- | --- | |  | `10000 (n`⁴`)` | `1000 (n`³`)` | `100 (n`²`)` |
    `10 (n`¹`)` | `1 (n`⁰`)` | | **Decimal** | `10`⁴ `(10000)` | `10`³ `(1000)` |
    `10`² `(100)` | `10`¹ `(10)` | `10`⁰ `(1)` | | **Binary** | `2`⁴ `(16)` | `2`³
    `(8)` | `2`² `(4)` | `2`¹ `(2)` | `2`⁰ `(1)` | | **Hexadecimal** | `16`⁴ `(65536)`
    | `16`³ `(4096)` | `16`² `(256)` | `16`¹ `(16)` | `16`⁰ `(1)` |    You can use
    this principle to convert a decimal value to another system, such as hexadecimal.
    For example, if I wanted to convert the decimal value 2630, I’d first determine
    the highest place value needed with the formula `⌊log`[16]`2630⌋`, which gives
    me `2`. Then, I’d perform the conversion as shown in [Table 12-3](#table12-3).      Table
    12-3: Converting Decimal to Hexadecimal       | **Value to convert** | `2630`
    | `70` | `6` | | **Place value** | `⌊``2630``/16`²`⌋ = 0xA (10)` | `⌊``70``/16`¹`⌋
    = 0x4` | `⌊``6``/16`⁰`⌋ = 0x6` | | **Current hexadecimal value** | `0x``A``00`
    | `0xA``4``0` | `0xA4``6` | | **Calculate remaining value** | `2630 % 16`² `=`
    `70` | `70 % 16`¹ `=` `6` | `6 % 16`⁰ `= 0` |    The decimal value `2630` has
    the hexadecimal value `0xA46`.    Hexadecimal is useful in the context of binary
    because you can exactly express each possible value of a byte (eight bits) in
    two digits, from `0x00` (`0`) to `0xFF` (`255`). Hexadecimal is a more succinct
    way of representing binary: `0b10101010` can be written as `0xAA`.    #### Hexadecimal
    Humor    Hexadecimal employs the first six letters of the Latin alphabet as digits,
    and among developers, this has led to a traditional brand of puns known as *hexspeak*.
    Hexadecimal numbers such as 0xDEADBEEF and 0xC0FFEE have valid numeric values
    and are visually recognizable; the former has traditionally been used on some
    ancient IBM systems for uninitialized memory, because it was easy to spot amidst
    the wall of hexadecimal that was a core dump.    In the same way, you can sometimes
    mark special data in your binary. This can make your binary files a little easier
    to read and debug manually, and besides, it’s fun! Just be mindful that normal
    data may coincidentally show up in hexspeak, too—for example, a normal integer
    value that happens to read as 0xDEADBEEF—so use it with caution.    #### Octal    The
    third most common number system for representing binary data is *octal*, or base-8\.
    Octal literals are prefixed with `0o` (zero, followed by a lowercase letter *o*).
    Octal uses digits for decimal values `0` through `7`, but it writes `8` as `0o10`.
    Thus, decimal values `9` and `10` would be `0o11` and `0o12`, respectively.    [Table
    12-4](#table12-4) shows that place value table again, this time including octal.      Table
    12-4: Place Values in Various Number Systems       | **Number systems** | **Place
    values** | | --- | --- | |  | `10000 (n`⁴`)` | `1000 (n`³`)` | `100 (n`²`)` |
    `10 (n`¹`)` | `1 (n`⁰`)` | | **Decimal** | `10`⁴ `(10000)` | `10`³ `(1000)` |
    `10`² `(100)` | `10`¹ `(10)` | `10`⁰ `(1)` | | **Binary** | `2`⁴ `(16)` | `2`³
    `(8)` | `2`² `(4)` | `2`¹ `(2)` | `2`⁰ `(1)` | | **Octal** | `8`⁴ `(4096)` | `8`³
    `(512)` | `8`² `(64)` | `8`¹ `(8)` | `8`⁰ `(1)` | | **Hexadecimal** | `16`⁴ `(65536)`
    | `16`³ `(4096)` | `16`² `(256)` | `16`¹ `(16)` | `16`⁰ `(1)` |    Every 8-bit
    byte can be represented by three octal digits, with the highest value (`0xFF`)
    being `0o377`. Although octal doesn’t map to bytes as cleanly or obviously as
    hexadecimal, it is still useful in some scenarios because it’s more compact than
    binary but doesn’t require six extra digits like hexadecimal. Octal is used for
    UNIX file permissions, and it simplifies specifying individual parts of some UTF-8
    characters and some assembly op codes. If you have trouble picturing these use
    cases, you probably don’t need octal. You could go through your entire career
    without needing it! Regardless, it is helpful to know about it for the rare cases
    when you might need it.    #### Number Systems on Integers    It’s important to
    remember that binary, octal, decimal, and hexadecimal are all *number systems*;
    that is, they’re different ways of representing the same *whole number*, or *integer*.
    The decimal number `12` can be represented as `0b1100`, `0xc`, or `0o14`, but
    binding any of these literals to a name in Python will still store an integer
    with the decimal value `12`.    Consider the following:    [PRE324]py    Listing
    12-1: print_integer.py:1a    By default, printing an integer always shows the
    value in decimal. I can instead show the value in another number system by using
    one of the built-in functions for that purpose: `bin()`, `oct()`, or `hex()`:    [PRE325]py    Listing
    12-2: print_integer.py:1b    Regardless of how you display it, the actual value
    bound to `chapter` is unchanged.    #### Two’s Complement    In binary on most
    computers, negative numbers are represented as the *two’s complement* of the positive
    number. This technique is preferred over simply using a single bit to indicate
    positive or negative, as it allows you to store one additional value in the byte.    For
    example, the positive number `42` would be `0b00101010` in binary. To get `-42`,
    I’d find the two’s complement by inverting each of the bits (giving me `0b11010101`)
    and then adding `0b1`, ultimately producing `0b11010110` (you carry the `1`: `0b01`
    + `0b01` = `0b10`).    To convert a negative number back to a positive, you only
    need to repeat the process. Starting with `-42`, or `0b11010110`, I invert each
    of the bits, giving me `0b00101001`. Then, I add `0b1`, producing `0b00101010`,
    which is positive `42`.    Python *almost* uses two’s complement—it actually does
    something more complex, as you’ll see in a later section—so it instead shows negative
    binary numbers by placing a negative sign on the binary representation of the
    positive form of the number, as seen below:    [PRE326]py    Listing 12-3: negative_binary.py:1    As
    a bit wrangler myself, this may be the only thing I dislike about Python, although
    I understand its purpose.    Thankfully, it is possible to see the (approximate)
    two’s complement notation by using a *bitmask*, a binary value that uses strategically
    placed `1`s to keep certain bits in a value and throw away the rest. In this case,
    I want the first eight bits of the value (one byte), so I take the bitwise `AND`
    the value with a bitmask of eight `1`s:    [PRE327]py    Listing 12-4: negative_binary.py:2    That
    shows exactly what I’d expect: the eight-bit-long two’s complement representation
    of `-42`.    #### Byte Order    In this section, I’m not referring to Python at
    all, but rather to the computer memory *underneath* everything. We’re all the
    way down to silicon right now.    Most data is made up of multiple bytes, but
    the sequence the bytes appear in depends on the *byte order* used by your platform:
    either *big-endian* or *little-endian*.    Byte order has everything to do with
    how the computer stores data in memory. Each one-byte-wide slot in memory has
    a numeric address, typically represented in hexadecimal. Memory addresses are
    consecutive. Let’s consider a value, say `0xAABBCCDD` (`2,864,434,397` in decimal),
    that is composed of four bytes: `0xAA`, `0xBB`, `0xCC`, and `0xDD`. This value
    can be stored in a four-byte-wide chunk of memory, with each byte having an address.
    For example, the computer might decide to store that data in the memory at addresses
    `0xABCDEF01`, `0xABCDEF02`, `0xABCDEF03`, and `0xABCDEF04`, as shown in [Table
    12-5](#table12-5).      Table 12-5: An Empty Four-Byte Chunk of Memory with Addresses       |
    **Address** | `0xABCDEF01` | `0xABCDEF02` | `0xABCDEF03` | `0xABCDEF04` | | ---
    | --- | --- | --- | --- | | **Value** |  |  |  |  |    Now here’s the challenge:
    in what order do we store those bytes? Your first instinct might be to store them
    as you’d write them on paper, like in [Table 12-6](#table12-6).      Table 12-6:
    Data Stored in Memory in Big-Endian Byte Order       | **Address** | `0xABCDEF01`
    | `0xABCDEF02` | `0xABCDEF03` | `0xABCDEF04` | Whole value | | --- | --- | ---
    | --- | --- | --- | | **Hex value** | `0xAA` | `0xBB` | `0xCC` | `0xDD` | `= 0xAABBCCDD`
    | | **Equivalent** | `2852126720` | `+ 12255232` | `+ 52224` | `+ 221` | `= 2864434397`
    |    We call this byte order *big-endian*, because the value representing the
    largest part of the value is stored in the lowest, or leftmost, address. The big-endian
    byte order is often the easiest to reason about, because it orders bytes from
    left to right, just like how you’d write it on paper.    In contrast, on little-endian
    systems, the bytes are reversed, as shown in [Table 12-7](#table12-7).      Table
    12-7: Data Stored in Memory in Little-Endian Byte Order       | **Address** |
    `0xABCDEF01` | `0xABCDEF02` | `0xABCDEF03` | `0xABCDEF04` | Whole value | | ---
    | --- | --- | --- | --- | --- | | **Hex value** | `0xDD` | `0xCC` | `0xBB` | `0xAA`
    | `= 0xDDCCBBAA` | | **Equivalent** | `221` | `+ 52224` | `+ 12255232` | `+ 2852126720`
    | `= 2864434397` |    As the name *little-endian* suggests, the byte representing
    the smallest part of the number is stored in the lowest memory address.    Endianness
    only affects primitive data types, like integers and floating-point numbers. It
    will not affect collections, such as strings, which are just arrays of individual
    characters.    Although little-endian byte order sounds confusing, it makes a
    few little technical optimizations possible on the hardware. Most modern computers,
    including all Intel and AMD processors, use little-endian.    In most programming
    languages, we conventionally write binary numbers in big-endian. It’s the byte
    order used when you display an integer in binary in Python with `bin()`.    Often,
    the only time you need to be concerned about byte order is when your binary data
    is going to leave your program, such as when writing it to a file or sending it
    over a network.    ### Python Integers and Binary    Like in most programming
    languages, binary and hexadecimal literals are integers in Python. However, one
    implementation detail behind Python integers bleeds into the binary logic of the
    language: *integers are effectively infinite*.    In Python 2, the `int` type
    had a fixed size of 32 bits, or four bytes. Python 2 also had the `long` type,
    which had an unlimited size. In Python 3, the `long` type was adopted as the new
    `int`, so all integers now have a theoretically infinite size.    This behavior
    has one critical consequence for binary: two’s complement notation must effectively
    lead with an infinite number of `1` bits. This is why Python uses the rather unconventional
    negative binary notation. There’s no rational way to express an infinite number
    of `1`s! It also means you can’t directly type a binary literal for a negative
    integer. Instead, you have to use the negation operator (`-`) before the binary
    literal of the *positive* integer and trust Python to figure things out.    Since
    Python uses that negative binary notation, the negative binary form of a number
    reads the same as the positive binary form. The two’s complement notation would
    only be accurate if you could see the infinite leading `1` bits. This has a weird
    consequence elsewhere, as you’ll see shortly.    ### Bitwise Operations    You
    can work directly with binary data using the *bitwise operators*, which perform
    operations on individual bits. There are six bitwise operators, and Python offers
    all of them, although a couple behave a bit differently than you’d ordinarily
    expect.    The *Bitwise And* operator (`&`) produces a new binary value, where
    each bit is `1` if the corresponding bits in the left and right operands are both
    `1`. For example, `0b1101 & 0b1010` produces `0b1000`, because only the leftmost
    bit is `1` in both operands:    [PRE328]py    The *Bitwise Or* operator (`|`)
    produces a value where each bit is `1` if either the left or the right operand
    is `1` (or if both are). For example, `0b1101 | 0b1010` produces `0b1111`, because
    each of the four bits is on in at least one of the operands.    [PRE329]py    The
    *Bitwise Exclusive Or* operator (`^`), also known as a *Bitwise XOR*, sets a bit
    to `1` if it is on in either operand, but not in both. For example, `0b1101 ^
    0b1010` produces `0b0111`; the first bit is on in both operands, so it is off
    here, but the other three bits are on in only one operand, so they’re included.    [PRE330]py    The
    *Bitwise Inversion* operator (`~`), also known as the *Bitwise Not*, flips each
    bit in the operand given, such that `0b0101` would become (approximately) `0b1010`.    [PRE331]py    However,
    since in Python, integers are infinite, the new value would have infinite leading
    `1` bits. Therefore, the real result of `~0b0101` is actually `0b111...1010`.    [PRE332]py    Since
    infinite `1`s are hard to print, Python shows the result in negative binary notation—placing
    a negative sign at the front and subtracting `1` to get around the two’s complement.
    Remember, this convention is what allows Python to display a negative number as
    the negative binary form of the positive number. Unfortunately, it makes it a
    bit harder to read the results of normal bit twiddling.    Whenever this gets
    in your way, you can print the bitmasked form:    [PRE333]py    Listing 12-5:
    bitwise_inversion.py    Remember that the first value is *internally* correct,
    as it has the infinite leading `1`s that make it a negative Python integer. The
    second only *looks* correct, but it lacks those leading `1`s, so it’s actually
    wrong.    The last two bitwise operators are the *Left Shift* ([PRE334]py   [PRE335]`py
    [PRE336]'
  prefs: []
  type: TYPE_NORMAL

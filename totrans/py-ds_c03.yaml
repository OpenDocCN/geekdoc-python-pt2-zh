- en: '3'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '3'
- en: Python Data Science Libraries
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: Python 数据科学库
- en: '![](image_fi/book_art/chapterart.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](image_fi/book_art/chapterart.png)'
- en: 'Python provides access to a robust ecosystem of third-party libraries that
    you’ll find useful for data analysis and manipulation. This chapter introduces
    you to three of the more popular data science libraries: NumPy, pandas, and scikit-learn.
    As you’ll see, many data analysis applications use these libraries extensively,
    either explicitly or implicitly.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: Python 提供了访问一个强大的第三方库生态系统，这些库对于数据分析和处理非常有用。本章将向你介绍三种较为流行的数据科学库：NumPy、pandas
    和 scikit-learn。正如你所见，许多数据分析应用程序都广泛使用这些库，无论是显式使用还是隐式使用。
- en: NumPy
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: NumPy
- en: NumPy, or the Numeric Python library, is useful for working with *arrays*, which
    are data structures that store values of the same data type. Many other Python
    libraries that perform numerical computations rely on NumPy.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy，或称为数值 Python 库，对于处理*数组*非常有用，数组是一种存储相同数据类型值的数据结构。许多执行数值计算的 Python 库都依赖于
    NumPy。
- en: The NumPy array, a grid of elements of the same type, is the key component of
    the NumPy library. The elements in a NumPy array are indexed by a tuple of nonnegative
    integers. NumPy arrays are similar to Python lists except that they require less
    memory and are usually faster because they use optimized, precompiled C code.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy 数组是 NumPy 库的关键组成部分，它是一个元素类型相同的网格。NumPy 数组中的元素由一组非负整数元组进行索引。NumPy 数组类似于
    Python 列表，不同之处在于它们需要更少的内存，并且通常更快，因为它们使用了优化过的预编译 C 代码。
- en: NumPy arrays support *element-wise operations*, which allow you to perform basic
    arithmetic on entire arrays using compact and readable code. An element-wise operation
    is an operation on two arrays of the same dimensions that produces another array
    of the same dimensions, where each element *i*, *j* is the result of a calculation
    performed on elements *i*, *j* of the original two arrays. [Figure 3-1](#figure3-1)
    illustrates an element-wise operation performed against two NumPy arrays.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy 数组支持*元素级操作*，这使你可以使用简洁且易读的代码对整个数组执行基本的算术运算。元素级操作是对两个具有相同维度的数组执行操作，结果是一个相同维度的新数组，其中每个元素*i*，*j*
    是对原始两个数组的元素*i*，*j* 进行计算后的结果。[图 3-1](#figure3-1) 展示了对两个 NumPy 数组执行元素级操作的示意图。
- en: '![A two-by-two array with numbers 0, 1, 2, and 3 is added to a two-by-two array
    with numbers 3, 2, 1, and 0\. The result is a two-by-two array with numbers 3,
    3, 3, and 3.](image_fi/502208c03/f03001.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![一个包含数字 0、1、2、3 的 2x2 数组与一个包含数字 3、2、1、0 的 2x2 数组相加，结果是一个包含数字 3、3、3、3 的 2x2
    数组。](image_fi/502208c03/f03001.png)'
- en: 'Figure 3-1: Adding two NumPy arrays'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3-1：添加两个 NumPy 数组
- en: As you can see, the resulting array has the same dimensions as the original
    two arrays, and each new element is the sum of the corresponding elements in the
    original arrays.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，结果数组具有与原始两个数组相同的维度，每个新元素是原始数组中对应元素的和。
- en: Installing NumPy
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装 NumPy
- en: 'NumPy is a third-party library, meaning it’s not part of Python’s standard
    library. The simplest way to install it is with this command:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy 是一个第三方库，这意味着它不是 Python 标准库的一部分。最简单的安装方法是使用以下命令：
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Python considers NumPy a module, so you’ll need to import it into your script
    before you can use it.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Python 将 NumPy 视为一个模块，因此你需要在脚本中导入它才能使用。
- en: Creating a NumPy Array
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建 NumPy 数组
- en: 'You can create a NumPy array from the data in one or more Python lists. Suppose
    you have a list for each employee at a company containing that employee’s base
    salary payments over the past three months. You can use code like the following
    to get all the salary information into one data structure:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过一个或多个 Python 列表中的数据创建 NumPy 数组。假设你为每个员工创建一个列表，包含该员工过去三个月的基本薪资支付。你可以使用如下代码将所有薪资信息放入一个数据结构中：
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You start by importing the NumPy library ❶. Then you define a set of lists,
    where each list contains the base salary data of an employee over the past three
    months ❷. Finally, you combine these lists into a NumPy array ❸. The array looks
    like this:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过导入 NumPy 库 ❶ 开始。然后定义一组列表，每个列表包含员工过去三个月的基本薪资数据 ❷。最后，将这些列表合并为一个 NumPy 数组
    ❸。数组看起来是这样的：
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This is a 2D array. It has two axes, which are indexed by integers, starting
    with 0\. Axis 0 runs vertically downward across the array’s rows, while axis 1
    runs horizontally across the columns.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个二维数组。它有两个轴，轴的索引是整数，从 0 开始。轴 0 垂直向下运行，跨越数组的行，而轴 1 水平运行，跨越数组的列。
- en: 'You can follow the same process to create an array containing the employees’
    monthly bonuses:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以按照相同的步骤创建一个包含员工月度奖金的数组：
- en: '[PRE3]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Performing Element-Wise Operations
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 执行逐元素操作
- en: 'It’s easy to perform element-wise operations on multiple NumPy arrays of the
    same dimensions. For example, you can add the `base_salary` and `bonus` arrays
    together to determine the total amount paid each month to each employee:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 对多个维度相同的 NumPy 数组执行逐元素操作非常简单。例如，您可以将 `base_salary` 和 `bonus` 数组合并在一起，以确定每个月支付给每个员工的总金额：
- en: '[PRE4]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'As you can see, the addition operation is a one-liner ❶. The resulting dataset
    is a NumPy array too, in which each element is the sum of the corresponding elements
    in the `base_salary` and `bonus` arrays:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，添加操作是一行代码❶。结果数据集也是一个 NumPy 数组，其中每个元素是 `base_salary` 和 `bonus` 数组中对应元素的和：
- en: '[PRE5]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Using NumPy Statistical Functions
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 NumPy 统计函数
- en: NumPy’s statistical functions allow you to analyze the contents of an array.
    For example, you can find the maximum value of an entire array or the maximum
    value of an array along a given axis.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy 的统计函数允许您分析数组的内容。例如，您可以查找整个数组的最大值，或者沿着给定的轴查找数组的最大值。
- en: 'Let’s say you want to find the maximum value in the `salary_bonus` array you
    created in the previous section. You can do this with the NumPy array’s `max()`
    function:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您想要查找上节中创建的 `salary_bonus` 数组中的最大值。您可以使用 NumPy 数组的 `max()` 函数来实现：
- en: '[PRE6]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The function returns the maximum amount paid in the past three months to any
    employee in the dataset:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数返回数据集中过去三个月内支付给任何员工的最高金额：
- en: '[PRE7]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'NumPy can also find the maximum value of an array along a given axis. If you
    want to determine the maximum amount paid to each employee in the past three months,
    you can use NumPy’s `amax()` function, as shown here:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy 还可以沿着给定的轴查找数组的最大值。如果您想确定过去三个月支付给每个员工的最高金额，您可以使用 NumPy 的 `amax()` 函数，如下所示：
- en: '[PRE8]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'By specifying `axis = 1`, you instruct `amax()` to search horizontally across
    the columns for a maximum in the `salary_bonus` array, thus applying the function
    across each row. This calculates the maximum monthly amount paid to each employee
    in the past three months:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 通过指定 `axis = 1`，您指示 `amax()` 函数横向遍历列，查找 `salary_bonus` 数组中的最大值，从而对每一行应用该函数。这将计算过去三个月内每个月支付给每个员工的最高金额：
- en: '[PRE9]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Similarly, you can calculate the maximum amount paid each month to any employee
    by changing the `axis` parameter to `0`:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，您可以通过将 `axis` 参数设置为 `0` 来计算每个月支付给任何员工的最高金额：
- en: '[PRE10]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The results are as follows:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '[PRE11]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: pandas
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: pandas
- en: 'The pandas library is the de facto standard for data-oriented Python applications.
    (In case you’re wondering, the name is somehow derived from Python Data Analysis
    Library.) The library includes two data structures: the *Series*, which is 1D,
    and the *DataFrame*, which is 2D. While the DataFrame is the primary pandas data
    structure, a DataFrame is actually a collection of Series objects. Therefore,
    it’s important to understand Series as well as DataFrames.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: pandas 库是数据导向 Python 应用程序的事实标准。（如果您在想，名字源自 Python 数据分析库。）该库包含两种数据结构：*Series*（一维）和
    *DataFrame*（二维）。虽然 DataFrame 是 pandas 的主要数据结构，但 DataFrame 实际上是多个 Series 对象的集合。因此，理解
    Series 和 DataFrame 都很重要。
- en: pandas Installation
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: pandas 安装
- en: 'The standard Python distribution does not ship with the pandas module. You
    can install pandas with this command:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 标准的 Python 发行版并不包含 pandas 模块。您可以使用以下命令安装 pandas：
- en: '[PRE12]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The `pip` command also resolves the library’s dependencies, installing the NumPy,
    pytz, and python-dateutil packages implicitly.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '`pip` 命令还会解决库的依赖关系，隐式地安装 NumPy、pytz 和 python-dateutil 包。'
- en: Just like with NumPy, you’ll need to import the pandas module into your script
    before you can use it.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 就像使用 NumPy 一样，您需要先将 pandas 模块导入到脚本中，才能使用它。
- en: pandas Series
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: pandas Series
- en: A pandas Series is a 1D labeled array. By default, elements in a Series are
    labeled with integers according to their position, like in a Python list. However,
    you can specify custom labels instead. These labels need not be unique, but they
    must be of a hashable type, such as integers, floats, strings, or tuples.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: pandas Series 是一个一维标记数组。默认情况下，Series 中的元素根据其位置用整数标记，就像 Python 列表中的元素一样。然而，您也可以指定自定义标签。这些标签不必唯一，但必须是可哈希类型，如整数、浮动、字符串或元组。
- en: The elements of a Series can be of any type (integers, strings, floats, Python
    objects, and so on), but a Series works best if all its elements are of the same
    type. Ultimately, a Series may become one column in a larger DataFrame, and it’s
    unlikely you’ll want to store different kinds of data in the same column.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: Series 的元素可以是任何类型（整数、字符串、浮点数、Python 对象等），但如果 Series 中的所有元素类型相同，它的工作效果最好。最终，Series
    可能成为一个更大 DataFrame 中的一列，而且你不太可能希望将不同类型的数据存储在同一列中。
- en: Creating a Series
  id: totrans-52
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 创建一个 Series
- en: 'There are several ways to create a Series. In most cases, you feed it some
    kind of 1D dataset. Here’s how you create a Series from a Python list:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 创建 Series 有多种方式。在大多数情况下，你会传入某种 1D 数据集。以下是如何从 Python 列表创建 Series：
- en: '[PRE13]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: You start by importing the pandas library and aliasing it as `pd` ❶. Then you
    create a list of items to be used as the data for the Series ❷. Finally, you create
    the Series, passing the list in to the `Series` constructor method ❸.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 你首先导入 pandas 库并将其别名为 `pd` ❶。然后，你创建一个用于 Series 数据的项列表 ❷。最后，你创建 Series，并将该列表传入
    `Series` 构造方法 ❸。
- en: 'This gives you a single list with numeric indices set by default, starting
    from 0:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，你就得到了一个默认从 0 开始的数字索引的单一列表：
- en: '[PRE14]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The `dtype` attribute indicates the type of the underlying data for the given
    Series. By default, pandas uses the data type `object` to store strings.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '`dtype` 属性指示给定 Series 的底层数据类型。默认情况下，pandas 使用 `object` 数据类型来存储字符串。'
- en: 'You can create a Series with user-defined indices as follows:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以按如下方式创建一个具有用户定义索引的 Series：
- en: '[PRE15]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This time the data in the `emps_names` Series object appears as follows:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这时 `emps_names` Series 对象中的数据如下所示：
- en: '[PRE16]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Accessing Data in a Series
  id: totrans-63
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 访问 Series 中的数据
- en: 'To access an element in a Series, specify the Series name followed by the element’s
    index within square brackets, as shown here:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问 Series 中的元素，指定 Series 名称并在方括号内跟上元素的索引，如下所示：
- en: '[PRE17]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This outputs the element corresponding to index 9001:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这将输出对应索引 9001 的元素：
- en: '[PRE18]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Alternatively, you can use the `loc` property of the Series object:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，你可以使用 Series 对象的 `loc` 属性：
- en: '[PRE19]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Although you’re using custom indices in this Series object, you can still access
    its elements by position (that is, use integer location–based indexing) via the
    `iloc` property. Here, for example, you print the first element in the Series:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在这个 Series 对象中使用了自定义索引，但你仍然可以通过位置（即使用基于整数位置的索引）来访问它的元素，通过 `iloc` 属性。例如，在这里，你可以打印
    Series 中的第一个元素：
- en: '[PRE20]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'You can access multiple elements by their indices with a slice operation, as
    discussed in Chapter 2:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过切片操作按索引访问多个元素，正如第 2 章所讨论的那样：
- en: '[PRE21]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'This produces the following output:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生如下输出：
- en: '[PRE22]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Notice that slicing with `loc` includes the right endpoint (in this case, index
    9002), whereas usually Python slice syntax does not.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，使用 `loc` 切片时包括右端点（在此案例中是索引 9002），而通常 Python 的切片语法是不包括右端点的。
- en: 'You can also use slicing to define the range of elements by position rather
    than by index. For instance, the preceding results could instead be generated
    by the following code:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以使用切片操作根据位置而非索引来定义元素的范围。例如，前面的结果可以通过以下代码生成：
- en: '[PRE23]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'or simply as follows:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 或者简单地如下：
- en: '[PRE24]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'As you can see, unlike slicing with `loc`, slicing with `[]` or `iloc` works
    the same as usual Python slicing: the start position is included but the stop
    is not. Thus, `[0:2]` leaves out the element in position 2 and returns only the
    first two elements.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，和 `loc` 切片不同，使用 `[]` 或 `iloc` 切片与普通的 Python 切片相同：起始位置包括，但停止位置不包括。因此，`[0:2]`
    会跳过位置 2 的元素，只返回前两个元素。
- en: Combining Series into a DataFrame
  id: totrans-82
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 将多个 Series 合并为 DataFrame
- en: 'Multiple Series can be combined to form a DataFrame. Let’s try this by creating
    another Series and combining it with the `emps_names` Series:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 多个 Series 可以结合成一个 DataFrame。我们可以通过创建另一个 Series，并将其与 `emps_names` Series 合并，来尝试这一点：
- en: '[PRE25]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'To create the new Series, you call the `Series()` constructor ❶, passing the
    following arguments: the list to be converted to a Series, the indices of the
    Series, and the name of the Series.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建新的 Series，你需要调用 `Series()` 构造函数 ❶，并传入以下参数：要转换为 Series 的列表、Series 的索引以及 Series
    的名称。
- en: You need to name Series before concatenating them into a DataFrame, because
    their names will become the names of the corresponding DataFrame columns. Since
    you didn’t name the `emps_names` Series when you created it earlier, you name
    it here by setting its `name` property to `'names'` ❷. After that, you can concatenate
    it with the `emps_emails` Series ❸. You specify `axis=1` in order to concatenate
    along the columns.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在将多个 Series 合并成 DataFrame 之前，你需要先为它们命名，因为它们的名称将成为相应 DataFrame 列的名称。由于你在之前创建
    `emps_names` Series 时没有命名它，所以在此处通过设置它的 `name` 属性为 `'names'` ❷ 来命名。之后，你可以将它与 `emps_emails`
    Series ❸ 合并。你需要指定 `axis=1`，以便沿着列方向进行合并。
- en: 'The resulting DataFrame looks like this:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的 DataFrame 如下所示：
- en: '[PRE26]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: pandas DataFrames
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: pandas DataFrame
- en: A pandas DataFrame is a 2D labeled data structure with columns that can be of
    different types. A DataFrame can be thought of as a dictionary-like container
    for Series objects, where each key in the dictionary is a column label and each
    value is a Series.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: pandas DataFrame 是一个二维标签化的数据结构，具有不同类型的列。可以将 DataFrame 看作是一个类似字典的容器，其中每个字典的键是列标签，每个值是一个
    Series。
- en: If you are familiar with relational databases, you’ll notice that a pandas DataFrame
    is similar to a regular SQL table. [Figure 3-2](#figure3-2) illustrates an example
    of a pandas DataFrame.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你熟悉关系型数据库，你会发现 pandas DataFrame 类似于普通的 SQL 表。[图 3-2](#figure3-2) 展示了一个 pandas
    DataFrame 的示例。
- en: '![A DataFrame with rows of stock market data. The leftmost column, with row
    numbers from 0 to 4, is highlighted as the index.](image_fi/502208c03/f03002.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![一张包含股票市场数据行的 DataFrame，最左侧列的行号从 0 到 4，作为索引进行了高亮显示。](image_fi/502208c03/f03002.png)'
- en: 'Figure 3-2: An example of a pandas DataFrame'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3-2：一个 pandas DataFrame 的示例
- en: Notice that the DataFrame includes an index column. Like with Series, pandas
    uses zero-based numeric indexing for DataFrames by default. However, you can replace
    the default index with one or more existing columns. [Figure 3-3](#figure3-3)
    shows the same DataFrame but with the Date column set as the index.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，DataFrame 包含一个索引列。与 Series 一样，pandas 默认使用基于零的数字索引。但你可以用一个或多个现有列替代默认的索引。[图
    3-3](#figure3-3) 显示了相同的 DataFrame，但将 Date 列设置为索引。
- en: '![The same DataFrame as in the previous figure, but instead of row numbers,
    the Date column is highlighted as the index.](image_fi/502208c03/f03003.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![与前一张图相同的 DataFrame，不过这次是将 Date 列作为索引而不是行号进行了高亮显示。](image_fi/502208c03/f03003.png)'
- en: 'Figure 3-3: A pandas DataFrame that uses a column as the index'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3-3：一个使用列作为索引的 pandas DataFrame
- en: In this particular example, the index is a column of type `date`. In fact, pandas
    allows you to have DataFrame indexes of any type. The most commonly used index
    types are integers and strings. However, you are not limited to using only simple
    types. You might define an index of a sequence type, such as List or Tuple, or
    even use an object type that is not built into Python; this could be a third-party
    type or even your own object type.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个特定的示例中，索引是一个 `date` 类型的列。事实上，pandas 允许你使用任何类型作为 DataFrame 的索引。最常用的索引类型是整数和字符串。然而，你并不限于使用简单类型。你可以定义一个序列类型的索引，比如
    List 或 Tuple，甚至使用不是 Python 内置的对象类型；这可以是第三方类型，甚至是你自己的对象类型。
- en: Creating a pandas DataFrame
  id: totrans-98
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 创建 pandas DataFrame
- en: You’ve seen how you can create a pandas DataFrame by combining multiple Series
    objects. You can also create a DataFrame by loading data from a database, a CSV
    file, an API request, or another external source using one of the pandas library’s
    *reader* methods. Readers allow you to read different types of data, like JSON
    and Excel, into a DataFrame.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经看到可以通过将多个 Series 对象合并来创建 pandas DataFrame。你还可以通过从数据库、CSV 文件、API 请求或其他外部源加载数据来创建
    DataFrame，方法是使用 pandas 库的 *reader* 方法。Reader 方法允许你将不同类型的数据，如 JSON 和 Excel，读取到
    DataFrame 中。
- en: 'Consider the DataFrame shown in [Figure 3-2](#figure3-2). It might have been
    created as the result of a request to the Yahoo Finance API via the yfinance library.
    To create the DataFrame for yourself, first install yfinance with `pip` as follows:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑图 [3-2](#figure3-2) 所示的 DataFrame。它可能是通过 yfinance 库向 Yahoo Finance API 发起请求的结果。要自己创建该
    DataFrame，首先使用 `pip` 安装 yfinance，方法如下：
- en: '[PRE27]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Then request the stock data, as shown here:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 然后请求股票数据，如下所示：
- en: '[PRE28]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: In this script, you send a request to the API for stock price data for a given
    ticker ❶ and use yfinance’s `history()` method to specify that you want data for
    a five-day period ❷. The resulting data, stored in the variable `hist`, is already
    in the form of a pandas DataFrame. You don’t need to create the DataFrame explicitly;
    yfinance does this for you behind the scenes. After obtaining the DataFrame, you
    remove some of its columns ❸ and switch to numeric indexing ❹, yielding the structure
    that was shown in [Figure 3-2](#figure3-2).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个脚本中，你向 API 发送请求，获取给定股票代码的股票价格数据❶，并使用 yfinance 的 `history()` 方法指定你希望获取五天的数据❷。结果数据存储在变量
    `hist` 中，已经是 pandas DataFrame 的形式。你不需要显式地创建 DataFrame；yfinance 会在后台为你处理。获取 DataFrame
    后，你删除其中一些列❸，并切换为数字索引❹，得到如 [图 3-2](#figure3-2) 所示的结构。
- en: 'To set the index to the Date column, as was shown in [Figure 3-3](#figure3-3),
    you’ll need to execute the following line of code:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 要将索引设置为 Date 列，如 [图 3-3](#figure3-3) 所示，你需要执行以下代码行：
- en: '[PRE29]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Let’s now try converting a JSON document to a pandas object. The sample dataset
    used here contains the monthly salary data of three employees identified by their
    IDs in the `Empno` column:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们尝试将一个 JSON 文档转换为 pandas 对象。此处使用的示例数据集包含三名员工的每月薪资数据，每名员工通过其在 `Empno` 列中的
    ID 进行标识：
- en: '[PRE30]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: You use the pandas `read_json()` reader method to pass a JSON string into a
    DataFrame ❷. For simplicity, this example uses a JSON string converted from a
    list by `json.dumps()` ❶. Alternatively, you could pass a `path` object into the
    reader that points to a JSON file of interest or a URL to an HTTP API that publishes
    data in JSON format. Finally, you set the `Empno` column as the DataFrame index
    ❸, thus replacing the default numeric index.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 你使用 pandas 的 `read_json()` 读取方法将 JSON 字符串传递给 DataFrame❷。为了简单起见，本示例使用通过 `json.dumps()`
    从列表转换的 JSON 字符串❶。或者，你可以将一个 `path` 对象传递给读取器，该对象指向一个 JSON 文件，或者指向发布 JSON 格式数据的 HTTP
    API 的 URL。最后，你将 `Empno` 列设置为 DataFrame 索引❸，从而替换掉默认的数字索引。
- en: 'The resulting DataFrame will look like this:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 结果的 DataFrame 看起来是这样的：
- en: '[PRE31]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Another common practice is to create pandas DataFrames from the standard Python
    data structures introduced in the previous chapter. For example, here’s how to
    create a DataFrame from a list of lists:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种常见的做法是从上一章介绍的标准 Python 数据结构中创建 pandas DataFrame。例如，以下是如何从一个列表的列表中创建 DataFrame：
- en: '[PRE32]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'First, you initialize a list of lists with the data to be sent to the DataFrame
    ❶. Each nested list will become a row in the DataFrame. Then you explicitly create
    the DataFrame, defining the columns to be used ❷. Next, you use a dictionary,
    `column_types`, to change the data types set for the columns by default ❸. This
    step is optional, but it can be crucial if you’re planning to join the DataFrame
    to another one. This is because you can join two DataFrames only on columns of
    the same data type. Finally, you set the `Empno` column as the DataFrame index
    ❹. The resulting DataFrame will look like this:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你初始化一个包含待发送数据的列表列表❶。每个嵌套列表将成为 DataFrame 中的一行。然后，你显式地创建 DataFrame，定义要使用的列❷。接下来，你使用一个字典
    `column_types` 来更改列的默认数据类型❸。这一步是可选的，但如果你计划将 DataFrame 与另一个 DataFrame 合并，这一步是至关重要的。因为你只能在相同数据类型的列上合并两个
    DataFrame。最后，你将 `Empno` 列设置为 DataFrame 索引❹。结果的 DataFrame 看起来是这样的：
- en: '[PRE33]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Notice that the `emps` and `salary` DataFrames both use `Empno` as the index
    column to uniquely identify each row. In both cases, you set this column as the
    DataFrame index to simplify the process of merging the two DataFrames into a single
    one, which we’ll discuss in the next section.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`emps` 和 `salary` DataFrame 都使用 `Empno` 作为索引列，以唯一标识每一行。在这两种情况下，你都将该列设置为
    DataFrame 索引，以简化将两个 DataFrame 合并成一个 DataFrame 的过程，我们将在下一节中讨论。
- en: Combining DataFrames
  id: totrans-117
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 合并 DataFrame
- en: 'pandas allows you to merge (or join) DataFrames together, in the same way that
    you can join different tables in a relational database. This lets you gather together
    data for analysis. DataFrames support database-style join operations through two
    methods: `merge()` and `join()`. Although these methods come with some different
    parameters, you can more or less use them interchangeably.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: pandas 允许你合并（或连接）DataFrame，就像你在关系数据库中连接不同的表一样。这使得你可以将数据聚合在一起进行分析。DataFrame 支持通过两种方法：`merge()`
    和 `join()` 进行数据库风格的连接操作。尽管这两种方法有一些不同的参数，但你可以在大多数情况下互换使用它们。
- en: To begin, let’s join the `emps` and `salary` DataFrames defined in the previous
    section. This is an example of a *one-to-one join* since one row in one DataFrame
    is associated with a single row in the other DataFrame. [Figure 3-4](#figure3-4)
    illustrates how this works.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们连接上一节中定义的 `emps` 和 `salary` DataFrame。这是一个 *一对一连接* 的例子，因为一个 DataFrame
    中的一行与另一个 DataFrame 中的单独一行相关联。[图 3-4](#figure3-4) 说明了这是如何工作的。
- en: '![A row  from the emps  DataFrame  combines with a row from the salary  DataFrame  to
    form a row in the emps_salary  DataFrame . A key icon s hows  the  column shared
    between emps and salary.](image_fi/502208c03/f03004-r.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![emps DataFrame 中的一行与 salary DataFrame 中的一行结合，形成 emps_salary DataFrame 中的一行。一个关键图标显示了
    emps 和 salary 共享的列。](image_fi/502208c03/f03004-r.png)'
- en: 'Figure 3-4: Joining two DataFrames connected with a one-to-one relationship'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3-4：连接两个具有一对一关系的 DataFrame
- en: Here we see an entry from the `emps` DataFrame and one from the `salary` DataFrame.
    The entries share the same index value, `9001`, so they can be joined into a single
    entry in the new `emps_salary` DataFrame. In relational database terminology,
    the columns through which tables are related are known as *key columns*. Although
    pandas uses the term *index* for such columns, [Figure 3-4](#figure3-4) uses the
    key icon for visual association.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们可以看到 `emps` DataFrame 和 `salary` DataFrame 中的一个条目。它们共享相同的索引值 `9001`，因此可以合并成一个新的
    `emps_salary` DataFrame 中的单个条目。在关系型数据库术语中，通过这些列关联的表被称为 *关键列*。尽管 pandas 使用 *index*
    来表示这些列，[图 3-4](#figure3-4) 使用关键图标来做视觉关联。
- en: 'With the help of the `join()` method, the implementation is quite straightforward:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 借助 `join()` 方法，实施起来非常简单：
- en: '[PRE34]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The `join()` method is designed to easily join DataFrames based on their indexes.
    In this particular example, you didn’t even need to provide any additional parameters
    to join these two DataFrames; joining them index-on-index is the default behavior.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '`join()` 方法旨在基于索引轻松地连接 DataFrame。在这个具体的例子中，你甚至不需要提供任何额外的参数来连接这两个 DataFrame；按索引连接是默认行为。'
- en: 'The resulting dataset looks as follows:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 结果数据集如下所示：
- en: '[PRE35]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'In practice, you may need to join two DataFrames even if one of them has rows
    with no matches in the other DataFrame. Suppose you have one more row in the `emps`
    DataFrame and that there is no corresponding row in the `salary` DataFrame:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际操作中，即使其中一个 DataFrame 中的某些行在另一个 DataFrame 中没有匹配的行，你可能仍然需要连接这两个 DataFrame。假设你在
    `emps` DataFrame 中有多出的一行，而在 `salary` DataFrame 中没有相应的行：
- en: '[PRE36]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Here you create a pandas Series object and then add it to the `emps` DataFrame
    using the `append()` method. This is a common way to add new rows to a DataFrame.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你创建一个 pandas Series 对象，并使用 `append()` 方法将其添加到 `emps` DataFrame 中。这是向 DataFrame
    添加新行的常见方法。
- en: 'The updated `emps` DataFrame will be as follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 更新后的 `emps` DataFrame 如下所示：
- en: '[PRE37]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'If you now apply the join operation again:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你现在再次应用连接操作：
- en: '[PRE38]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'the result is the following DataFrame:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是如下的 DataFrame：
- en: '[PRE39]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Note that the row added to the `emps` DataFrame appears in the resulting dataset
    even though it doesn’t have a related row in the `salary` DataFrame. The `NaN`
    entry in the Salary field of the last row denotes that the salary value is missing.
    In some cases you may want to allow incomplete rows like this, but in other cases
    you may want to exclude the rows that don’t have a related row in the other DataFrame.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，添加到 `emps` DataFrame 中的那一行出现在结果数据集中，尽管它在 `salary` DataFrame 中没有相关联的行。最后一行中的
    `Salary` 字段中的 `NaN` 条目表示该工资值缺失。在某些情况下，你可能希望允许像这样的不完整行，但在其他情况下，你可能希望排除那些在另一个 DataFrame
    中没有相关行的行。
- en: 'By default, the `join()` method uses the index of the calling DataFrame in
    the resulting joined DataFrame, thus performing a *left join*. In this example,
    the calling DataFrame is `emps`. It’s considered to be the left DataFrame in the
    join operation, and therefore all the rows from it are included in the resulting
    dataset. You can change this default behavior by passing the `how` parameter in
    to the `join()` method. This parameter takes the following values:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，`join()` 方法在结果的连接 DataFrame 中使用调用 DataFrame 的索引，从而执行 *左连接*。在这个例子中，调用 DataFrame
    是 `emps`，它被视为连接操作中的左侧 DataFrame，因此它的所有行都会包含在结果数据集中。你可以通过传递 `how` 参数到 `join()`
    方法来改变这一默认行为。这个参数可以取以下值：
- en: '`left` Uses the index of the calling DataFrame (or another column if the `on`
    parameter is specified), returning all rows from the calling (left) DataFrame
    and only the matching rows from the other (right) DataFrame'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`left` 使用调用 DataFrame 的索引（或者如果指定了 `on` 参数，则为其他列），返回调用（左侧）DataFrame 中的所有行以及来自另一个（右侧）DataFrame
    的匹配行。'
- en: '`right` Uses the other (right) DataFrame’s index, returning all rows from that
    DataFrame and only the matching rows from the calling (left) DataFrame'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`right` 使用另一个（右侧）DataFrame 的索引，返回该 DataFrame 中的所有行以及调用（左侧）DataFrame 中的匹配行。'
- en: '`outer` Forms the combination of the calling DataFrame’s index (or another
    column if the `on` parameter is specified) and the other DataFrame’s index, returning
    all rows from both DataFrames'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`outer` 形成调用 DataFrame 的索引（或者如果指定了 `on` 参数，则为其他列）与另一个 DataFrame 的索引的组合，返回两个
    DataFrame 中的所有行。'
- en: '`inner` Forms the intersection of the calling DataFrame’s index (or another
    column if the `on` parameter is specified) with the other DataFrame’s index, returning
    only those rows whose indexes appear in both DataFrames'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`inner` 形成调用的 DataFrame 的索引（或者如果指定了 `on` 参数，则为其他列）与另一个 DataFrame 的索引的交集，只返回在两个
    DataFrame 中都出现的那些行。'
- en: '[Figure 3-5](#figure3-5) illustrates each type of join.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 3-5](#figure3-5) 展示了每种连接类型。'
- en: '![A diagram shows how left, right, inner, and outer joins handle rows that
    don’t have a match in the other DataFrame.](image_fi/502208c03/f03005.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![一张图示显示了 left、right、inner 和 outer 连接如何处理在另一个 DataFrame 中没有匹配的行。](image_fi/502208c03/f03005.png)'
- en: 'Figure 3-5: The results of the different types of joins'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3-5：不同类型连接的结果。
- en: 'If you want the resulting DataFrame to include only those rows from `emps`
    that have a related row in the `salary` DataFrame, set the `how` parameter of
    `join()` to `inner`:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你希望结果 DataFrame 仅包含 `emps` 中那些在 `salary` DataFrame 中有相关行的行，可以将 `join()` 的
    `how` 参数设置为 `inner`：
- en: '[PRE40]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The resulting DataFrame looks like this:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 结果 DataFrame 看起来是这样的：
- en: '[PRE41]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Another way to get this result is to pass `right` in as the `how` parameter.
    In this case, `join()` returns all the rows from the `salary` DataFrame, attaching
    to them the fields of the matched rows from the `emps` DataFrame. It’s important
    to realize, however, that a right join will not be equal to an inner join in many
    other cases. For example, if you add a row to the `salary` DataFrame with no match
    in the `emps` DataFrame, the right join will include this row along with the rows
    that have matches in `emps`.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 获取此结果的另一种方法是将 `right` 作为 `how` 参数传递。在这种情况下，`join()` 会返回所有来自 `salary` DataFrame
    的行，并将来自 `emps` DataFrame 的匹配行的字段附加到这些行上。然而，重要的是要意识到，右连接在许多其他情况下与内连接并不相等。例如，如果你向
    `salary` DataFrame 添加一行，并且该行在 `emps` DataFrame 中没有匹配项，则右连接会包括这行以及与 `emps` 中匹配的行。
- en: One-to-Many Joins
  id: totrans-151
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 一对多连接
- en: 'In a *one-to-many join*, a row from one DataFrame can match multiple rows from
    the other DataFrame. Consider the situation where each salesperson in the `emps`
    DataFrame has processed a number of orders. This might be reflected in an `orders`
    DataFrame as follows:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *一对多连接* 中，来自一个 DataFrame 的一行可以与来自另一个 DataFrame 的多行匹配。考虑这样一种情况：`emps` DataFrame
    中的每个销售人员处理了若干订单。这可以在 `orders` DataFrame 中反映如下：
- en: '[PRE42]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Here’s how the `orders` DataFrame will look:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 `orders` DataFrame 的样子：
- en: '[PRE43]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Now that you have a DataFrame of orders, you can combine it with the DataFrame
    of employees defined previously. This is a one-to-many join since one employee
    from the `emps` DataFrame can be associated with multiple rows in the `orders`
    DataFrame:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经有了一个订单的 DataFrame，可以将它与之前定义的员工 DataFrame 结合。这是一个一对多连接，因为 `emps` DataFrame
    中的一名员工可以与 `orders` DataFrame 中的多行关联：
- en: '[PRE44]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: In this code, you use the `merge()` method to define a one-to-many join, combining
    the data from the `emps` and `orders` DataFrames. The `merge()` method allows
    you to specify the columns to join on in both DataFrames, using `left_on` to specify
    the column in the calling DataFrame and `right_on` for the column in the other
    DataFrame. With `join()`, you can only specify the column to join on for the calling
    DataFrame. For the other DataFrame, `join()` uses the index column.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在这段代码中，你使用 `merge()` 方法定义一对多连接，将 `emps` 和 `orders` DataFrame 中的数据合并。`merge()`
    方法允许你指定在两个 DataFrame 中进行连接的列，使用 `left_on` 来指定调用 DataFrame 中的列，使用 `right_on` 来指定另一个
    DataFrame 中的列。使用 `join()` 时，你只能为调用 DataFrame 指定连接的列。对于另一个 DataFrame，`join()` 使用索引列。
- en: 'In this example, you use the inner type of join to include only related rows
    from both DataFrames. The resulting dataset looks as follows:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，你使用了内连接类型，只包括两个 DataFrame 中相关的行。结果数据集如下所示：
- en: '[PRE45]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[Figure 3-6](#figure3-6) illustrates how this one-to-many join works.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '[图3-6](#figure3-6)展示了这种一对多连接是如何工作的。'
- en: '![A row  in  the emps  DataFrame  combines with three rows  in  the o rders  DataFrame  to
    form three rows in the emps_orders  DataFrame . A key icon shows the column shared
    between emps and orders.](image_fi/502208c03/f03006.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![emps DataFrame中的一行与orders DataFrame中的三行结合，形成emps_orders DataFrame中的三行。一个关键图标显示了emps和orders之间共享的列。](image_fi/502208c03/f03006.png)'
- en: 'Figure 3-6: Joining two DataFrames connected with a one-to-many relationship'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 图3-6：连接具有一对多关系的两个DataFrame
- en: As you can see, the one-to-many join in the figure includes one row for each
    row in the dataset on the *many* side of the join. Since you’re using the inner
    type of join, no other rows will be included. In the case of a left or outer join,
    however, the join would also include those rows from the dataset on the *one*
    side of the join that have no matches on the *many* side.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，图中的一对多连接在连接的*多*方每一行都对应数据集中的一行。由于你使用的是内连接类型，其他行将不会被包含。然而，在左连接或外连接的情况下，连接还会包含那些在*一*方数据集中没有与*多*方匹配的行。
- en: 'Apart from one-to-many and one-to-one joins, there are also *many-to-many joins*.
    As an example of this relationship, consider two datasets: one that lists books
    and the other that lists authors. Every record in the authors dataset can be linked
    to one or more records in the books dataset, and every record in the books dataset
    can be linked to one or more author records. We’ll discuss this type of relationship
    in Chapter 7, which covers concatenating, merging, and joining datasets in greater
    detail.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 除了一对多和一对一连接，还有*多对多连接*。以这种关系为例，考虑两个数据集：一个列出书籍，另一个列出作者。作者数据集中的每条记录可以与书籍数据集中的一条或多条记录关联，而书籍数据集中的每条记录也可以与一个或多个作者记录关联。我们将在第7章中讨论这种类型的关系，届时将更详细地讲解如何连接、合并和连接数据集。
- en: Aggregating Data with groupby()
  id: totrans-166
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用groupby()聚合数据
- en: The pandas `groupby()` function lets you aggregate data over multiple rows of
    a DataFrame. For example, it can find the sum of a column or get the mean of a
    subset of the values in a column.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: pandas的`groupby()`函数可以让你在DataFrame的多行数据中进行聚合。例如，它可以求出某一列的总和，或计算某一列中某一部分值的平均值。
- en: 'Imagine that you need to calculate an average total for the orders processed
    by each employee in the `orders` DataFrame you created earlier. You can use the
    `groupby()` function as follows:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你需要计算`orders` DataFrame中每个员工处理的订单的平均总额。你可以像下面这样使用`groupby()`函数：
- en: '[PRE46]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '`groupby()` returns a GroupBy object that supports several aggregate functions.
    In this particular example, you use `mean()` to calculate an average total for
    the group of orders associated with an employee. To achieve this, you group the
    rows in the `orders` DataFrame by the `Empno` column and then apply the `mean()`
    operation to the `Total` column. The generated dataset is a Series object:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '`groupby()`返回一个支持多种聚合函数的GroupBy对象。在这个具体的例子中，你使用`mean()`来计算与员工相关联的订单组的平均总额。为此，你首先根据`Empno`列对`orders`
    DataFrame中的行进行分组，然后对`Total`列应用`mean()`操作。生成的数据集是一个Series对象：'
- en: '[PRE47]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Now suppose you want to sum up the totals of the orders within the groups.
    This is where the `sum()` function of the GroupBy object comes in handy:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 现在假设你想要对每组的订单总数进行求和。这时，GroupBy对象的`sum()`函数就派上用场了：
- en: '[PRE48]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The data in the generated Series object will be as follows:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的Series对象中的数据如下：
- en: '[PRE49]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: scikit-learn
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: scikit-learn
- en: scikit-learn is a Python package designed for machine learning applications.
    Together with NumPy and pandas, it’s another core component in the Python data
    science ecosystem. scikit-learn provides efficient, easy-to-use tools that can
    be applied to common machine learning problems, including exploratory and predictive
    data analysis. We’ll take a deeper dive into machine learning at the end of the
    book. For now, this section offers a taste of how Python can be applied in the
    field of machine learning, particularly for predictive data analysis.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn是一个专为机器学习应用设计的Python包。与NumPy和pandas一起，它是Python数据科学生态系统中的另一个核心组件。scikit-learn提供了高效、易于使用的工具，可应用于常见的机器学习问题，包括探索性和预测性数据分析。我们将在本书的最后部分深入探讨机器学习。目前，本节只是简单介绍Python在机器学习领域，特别是在预测数据分析中的应用。
- en: 'Predictive data analysis is an area of machine learning that relies on classification
    and regression algorithms. Both classification and regression use past data to
    make predictions about new data, but classification sorts data into discrete categories,
    while regression can output a continuous range of numerical values. In this section,
    we’ll look at an example of classification implemented with scikit-learn. We’ll
    build a predictive model that can analyze customer product reviews and sort them
    into two classes: positive reviews and negative reviews. The model will learn
    from already classified samples how to predict the class of other samples. Once
    we have trained the model, we’ll show it some new reviews for classification as
    either positive or negative.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 预测性数据分析是机器学习的一个领域，依赖于分类和回归算法。分类和回归都使用过去的数据来预测新数据，但分类将数据分入离散的类别，而回归可以输出一个连续的数值范围。在本节中，我们将通过一个使用
    scikit-learn 实现的分类示例来进行讲解。我们将构建一个预测模型，分析客户产品评论，并将其分为两类：正面评论和负面评论。该模型将从已经分类的样本中学习如何预测其他样本的类别。一旦我们训练好模型，就会展示一些新的评论，进行正面或负面的分类。
- en: Installing scikit-learn
  id: totrans-179
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装 scikit-learn
- en: 'Like NumPy and pandas, scikit-learn is a third-party Python library. You can
    install it as follows:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 与 NumPy 和 pandas 一样，scikit-learn 是一个第三方 Python 库。你可以按照以下方式安装它：
- en: '[PRE50]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: The scikit-learn package has many submodules, each with its own specific functionality.
    It’s therefore common to only import the submodule needed for a particular task
    (say, `sklearn.model_selection`) rather than the entire module.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn 包含多个子模块，每个子模块都有其特定功能。因此，通常会根据具体任务导入所需的子模块（比如 `sklearn.model_selection`），而不是导入整个模块。
- en: Obtaining a Sample Dataset
  id: totrans-183
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 获取示例数据集
- en: In order to be accurate, a predictive model should be trained on a large number
    of labeled samples, so your first step toward building a model that can classify
    product reviews is to obtain a set of reviews that are already labeled either
    positive or negative. This saves you from having to gather reviews yourself and
    manually label them.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保准确性，预测模型应在大量标注样本上进行训练。因此，构建一个能够分类产品评论的模型的第一步是获取一组已经标注为正面或负面的评论。这可以避免你自己收集评论并手动标注它们。
- en: There are several online sources for labeled datasets. One of the best is UC
    Irvine’s Machine Learning Repository, at [https://archive.ics.uci.edu/ml/index.php](https://archive.ics.uci.edu/ml/index.php).
    Search the repository using the term “customer product reviews” and you’ll find
    a link to the Sentiment Labelled Sentences Data Set (or alternatively, just point
    your browser to [https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences)).
    Download and unpack the *sentiment labelled sentences.zip* file from the dataset’s
    web page.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 有多个在线资源提供标注数据集，其中最好的之一是 UC Irvine 的机器学习资源库，网址为[https://archive.ics.uci.edu/ml/index.php](https://archive.ics.uci.edu/ml/index.php)。使用“customer
    product reviews”搜索该资源库，你会找到指向情感标注句子数据集的链接（或者，你也可以直接将浏览器指向[https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences)）。从数据集的网页下载并解压*sentiment
    labelled sentences.zip*文件。
- en: The *.zip* file contains reviews from IMDb, Amazon, and Yelp, in three different
    *.txt* files. The reviews are labeled with positive or negative sentiment (`1`
    or `0`, respectively); there are 500 positive and 500 negative reviews from each
    source, for a total of 3,000 labeled reviews in the entire dataset. For simplicity,
    we’ll use the instances from Amazon only. They can be found in the *amazon_cells_labelled.txt*
    file.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '*.zip* 文件包含来自 IMDb、Amazon 和 Yelp 的评论，存储在三个不同的 *.txt* 文件中。这些评论已经根据情感（分别为 `1`
    或 `0`）进行了标注；每个来源有 500 条正面评论和 500 条负面评论，总共有 3000 条标注评论。为了简化，我们将仅使用来自 Amazon 的实例。它们可以在
    *amazon_cells_labelled.txt* 文件中找到。'
- en: Loading the Sample Dataset into a pandas DataFrame
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将示例数据集加载到 pandas DataFrame 中
- en: 'To simplify further computations, you need to load the reviews from the text
    file into a more manageable data structure. You can read the data from *amazon_cells_labelled.txt*
    into a pandas DataFrame as follows:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化后续计算，你需要将评论从文本文件加载到一个更易于处理的数据结构中。你可以按如下方式将数据从 *amazon_cells_labelled.txt*
    读取到 pandas DataFrame 中：
- en: '[PRE51]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Here, you use the pandas `read_csv()` reader method to load the data into a
    DataFrame. You specify two columns: the first one to hold reviews ❶ and the second
    for the corresponding sentiment scores ❷. Since tabs separate the reviews from
    their corresponding sentiment scores in the original file, you specify `\t` as
    the separator ❸.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你使用 pandas 的 `read_csv()` 读取方法将数据加载到 DataFrame 中。你指定了两列：第一列存储评论 ❶，第二列存储相应的情感得分
    ❷。由于原始文件中评论和情感得分之间是通过制表符分隔的，你指定 `\t` 作为分隔符 ❸。
- en: Splitting the Sample Dataset into a Training Set and a Test Set
  id: totrans-191
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将样本数据集拆分为训练集和测试集
- en: 'Now that you’ve imported your dataset, the next step is to split it into two
    parts: one to train the predictive model and one to test its accuracy. scikit-learn
    lets you do this with just a few lines of code:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经导入了数据集，接下来的步骤是将数据集拆分为两部分：一部分用于训练预测模型，另一部分用于测试模型的准确性。scikit-learn 允许你只需几行代码就能完成这一步：
- en: '[PRE52]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: You split your dataset using the `train_test_split()` function from the `sklearn.model_selection`
    module. The reviews and their corresponding sentiments (the sentiment scores)
    are passed in to the function as NumPy arrays obtained via the `values` property
    of the corresponding Series objects extracted from the DataFrame. You pass the
    `test_size` parameter ❶ to control how the dataset is split. The value `0.2` means
    20 percent of the reviews will be randomly assigned to the test set. Thus, you
    follow the 80/20 pattern; the remaining 80 percent of reviews will make up the
    training set. The `random_state` parameter ❷ initializes the internal random number
    generator needed to randomly split up the data.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 你使用来自 `sklearn.model_selection` 模块的 `train_test_split()` 函数来拆分数据集。评论及其对应的情感（情感得分）作为通过
    `values` 属性从 DataFrame 提取的相应 Series 对象获得的 NumPy 数组传入函数。你传入 `test_size` 参数 ❶ 来控制数据集的拆分方式。值
    `0.2` 表示 20% 的评论将被随机分配到测试集。因此，你遵循 80/20 的模式；剩余的 80% 评论将组成训练集。`random_state` 参数
    ❷ 初始化内部随机数生成器，用于随机拆分数据。
- en: Transforming Text into Numerical Feature Vectors
  id: totrans-195
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将文本转换为数值特征向量
- en: 'To train and test your model, you need a way to represent the text data numerically.
    This is where the *bag of words (BoW)* model comes in. This model represents a
    text as the set (bag) of its words in order to generate numerical data about the
    text. The most typical numerical feature generated from the BoW model is word
    frequency, the number of times each word occurs in the text. This simple example
    shows how the BoW model transforms a text into a numerical feature vector based
    on word frequency:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 要训练和测试你的模型，你需要一种将文本数据转化为数值的方式。这时，*词袋模型（BoW）* 就派上用场了。该模型通过将文本表示为单词的集合（词袋），以生成有关文本的数值数据。BoW
    模型生成的最典型的数值特征是词频，即每个单词在文本中出现的次数。这个简单的示例展示了 BoW 模型如何根据词频将文本转化为数值特征向量：
- en: '[PRE53]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: You can use scikit-learn’s `CountVectorizer()` function to create a BoW matrix
    for text data. `CountVectorizer()` converts text data into numerical feature vectors
    (*n*-dimensional vectors of numerical features representing some object) and performs
    tokenization (separating a text into individual words and punctuation symbols)
    using either the default tokenizer or a custom one. A custom tokenizer can be
    implemented with a natural language processing tool like spaCy, introduced in
    the previous chapter. In this example, we’ll use the default option to keep things
    simple.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 scikit-learn 的 `CountVectorizer()` 函数来为文本数据创建一个词袋（BoW）矩阵。`CountVectorizer()`
    将文本数据转换为数值特征向量（表示某个对象的 *n* 维数值特征向量），并使用默认的分词器或自定义分词器进行分词（将文本拆分为单独的单词和标点符号）。自定义分词器可以使用像
    spaCy 这样的自然语言处理工具实现，spaCy 在上一章中有介绍。在这个示例中，我们将使用默认选项，以保持简单。
- en: 'Here’s how to convert the reviews into feature vectors:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是将评论转换为特征向量的方法：
- en: '[PRE54]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: First, you create a `vectorizer` object. Then, you apply the vectorizer’s `fit()`
    method to build the vocabulary of tokens found in the `reviews` dataset, which
    contains all reviews from both the training and test sets. After that, you use
    the `transform()` method of the `vectorizer` object to transform the text data
    in the training and test sets into numerical feature vectors.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你创建一个 `vectorizer` 对象。然后，应用 `vectorizer` 的 `fit()` 方法来构建 `reviews` 数据集中发现的词汇表，`reviews`
    数据集包含训练集和测试集中的所有评论。之后，你使用 `vectorizer` 对象的 `transform()` 方法，将训练集和测试集中的文本数据转换为数值特征向量。
- en: Training and Evaluating the Model
  id: totrans-202
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练和评估模型
- en: Now that you have the training and test sets in the form of numerical vectors,
    you’re ready to train and test the model. You’ll first train scikit-learn’s `LogisticRegression()`
    classifier to predict the sentiment of a review. *Logistic regression* is a basic
    yet popular algorithm for solving classification problems.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经拥有了以数值向量形式表示的训练集和测试集，你可以开始训练和测试模型了。首先，你将训练 scikit-learn 的 `LogisticRegression()`
    分类器来预测评论的情感。*逻辑回归*是一种基础但流行的解决分类问题的算法。
- en: 'Here, you create a `LogisticRegression()` classifier, then use its `fit()`
    method to train the model according to the given training data:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你创建一个 `LogisticRegression()` 分类器，然后使用它的 `fit()` 方法根据给定的训练数据来训练模型：
- en: '[PRE55]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Now you must evaluate how accurately the model can make predictions on new
    data. You’ll need a set of labeled data for this, which is why it’s common to
    split a labeled dataset into a training set and a test set, as you did earlier.
    Here, you evaluate the model using the test set:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你必须评估模型在新数据上的预测准确性。你需要一组标注数据，因此通常会将一个标注数据集分为训练集和测试集，就像你之前所做的那样。在这里，你使用测试集来评估模型：
- en: '[PRE56]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'The accuracy rating typically appears as follows:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率通常如下所示：
- en: '[PRE57]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: This means that the model is 81 percent accurate. If you experiment with the
    `random_state` parameter in the `train_test_split()` function, you may get a slightly
    different value because the instances for the training and test sets are chosen
    randomly from the original set.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着模型的准确率为 81%。如果你尝试调整 `train_test_split()` 函数中的 `random_state` 参数，可能会得到稍微不同的值，因为训练集和测试集中的实例是从原始数据集中随机选择的。
- en: Making Predictions on New Data
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 对新数据进行预测
- en: 'Now that you’ve trained and tested your model, it’s ready to analyze new, unlabeled
    data. This will give you a more complete picture of how well the model is working.
    Try it out by feeding your model some new sample reviews:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经训练并测试了模型，它可以开始分析新的、未标记的数据了。这将帮助你更全面地了解模型的表现。试试看，给模型提供一些新的示例评论：
- en: '[PRE58]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'You start by creating a list of new reviews, then you transform that new text
    into numerical feature vectors. Finally, you predict class sentiments for the
    new samples. The sentiments are returned as a list:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要创建一个新的评论列表，然后将这些新文本转换为数值特征向量。最后，你为这些新样本预测类别情感。情感结果将作为一个列表返回：
- en: '[PRE59]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Remember, `0` indicates a negative review and `1` indicates a positive review.
    As you can see, the model has worked for these sample reviews, showing that the
    first one is negative and the other two are positive.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，`0` 表示负面评论，`1` 表示正面评论。正如你所见，模型已经对这些示例评论起作用，显示第一个是负面的，而后两个是正面的。
- en: Summary
  id: totrans-217
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: This chapter introduced you to some of the most popular third-party Python libraries
    for data science applications. First we explored the NumPy library and its multidimensional
    array objects, then we looked at the pandas library and its Series and DataFrame
    data structures. You learned to create NumPy arrays, pandas Series, and pandas
    DataFrame objects from built-in Python structures such as lists and from data
    sources stored in standard formats such as JSON. You also saw how to access and
    manipulate data in those objects. Finally, you used scikit-learn, a popular machine
    learning Python library, to build a predictive model for classification.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了一些最流行的第三方 Python 库，用于数据科学应用。首先，我们探索了 NumPy 库及其多维数组对象，接着了解了 pandas 库及其 Series
    和 DataFrame 数据结构。你学会了如何从 Python 内建结构（如列表）以及存储在标准格式（如 JSON）中的数据源创建 NumPy 数组、pandas
    Series 和 pandas DataFrame 对象。你还了解了如何访问和操作这些对象中的数据。最后，你使用了 scikit-learn 这个流行的机器学习
    Python 库，构建了一个分类预测模型。

<html><head></head><body>
<div id="sbo-rt-content"><h2 class="h2" id="ch06"><span epub:type="pagebreak" id="page_75"/><strong><span class="big">6</span><br/>FINDING PATTERNS AND WALKING DEPENDENCY TREES</strong></h2>&#13;
<div class="image1"><img src="../Images/comm1.jpg" alt="Image" width="191" height="191"/></div>&#13;
<p class="noindents">If you want your application to categorize a text, extract specific phrases from it, or determine how semantically similar it is to another text, it must be able to “understand” an utterance submitted by a user and generate a meaningful response to it.</p>&#13;
<p class="indent">You’ve already learned some techniques for performing these tasks. This chapter discusses two more approaches: using word sequence patterns to classify and generate text, and walking the syntactic dependency tree of an utterance to extract necessary pieces of information from it. I’ll introduce you to spaCy’s Matcher tool to find patterns. I’ll also discuss when you might still need to rely on context to determine the proper processing approach.</p>&#13;
<h3 class="h3" id="lev70"><span epub:type="pagebreak" id="page_76"/><strong>Word Sequence Patterns</strong></h3>&#13;
<p class="noindent">A <em>word sequence pattern</em> consists of features of words that impose a certain requirement on each word in the sequence. For example, the phrase “I can” will match the following word sequence pattern: “pronoun + modal auxiliary verb.” By searching for word sequence patterns, you can recognize word sequences with similar linguistic features, making it possible to categorize input and handle it properly.</p>&#13;
<p class="indent">For example, when you receive a question that begins with a word sequence that uses the pattern “modal auxiliary verb + proper noun,” such as “Can George,” you know that this question is about the ability, possibility, permission, or obligation of someone or something that the proper noun refers to.</p>&#13;
<p class="indent">In the following sections, you’ll learn to classify sentences by identifying common patterns of linguistic features.</p>&#13;
<h4 class="h4" id="lev71"><strong><em>Finding Patterns Based on Linguistic Features</em></strong></h4>&#13;
<p class="noindent">We need to find patterns in texts because, in most cases, we won’t be able to find even two identical sentences within a text. Typically, a text is composed of different sentences, each of which contains different words. It would be impractical to write the code to process each sentence in a text.</p>&#13;
<p class="indent">Fortunately, some sentences that look completely different might follow the same word sequence patterns. For example, consider the following two sentences: “We can overtake them.” and “You must specify it.”. These sentences have no words in common. But if you look at the syntactic dependency labels assigned to the words in the sentences, a pattern emerges, as shown in the following script:</p>&#13;
<pre>   import spacy<br/>&#13;
   nlp = spacy.load('en')<br/>&#13;
   doc1 = nlp(u'We can overtake them.')<br/>&#13;
   doc2 = nlp(u'You must specify it.')<br/>&#13;
<span class="ent">➊</span> for i in range(len(doc1)-1): <br/>&#13;
   <span class="ent">➋</span> if doc1[i].dep_ == doc2[i].dep_:<br/>&#13;
     <span class="ent">➌</span> print(doc1[i].text, doc2[i].text, doc1[i].dep_, spacy.explain(doc1[i].dep_))</pre>&#13;
<p class="indent">Because both sentences have the same number of words, we can iterate over the words in both sentences within a single loop <span class="ent">➊</span>. If the dependency label is the same for the words that have the same index in both sentences <span class="ent">➋</span>, we print these words along with the label assigned to them, as well as a description for each label <span class="ent">➌</span>.</p>&#13;
<p class="indent">The output should look as follows:</p>&#13;
<pre>We       You     nsubj  nominal subject<br/>&#13;
can      must    aux    auxiliary<br/>&#13;
overtake specify ROOT   None<br/>&#13;
them     it      dobj   direct object</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_77"/>As you can see, the list of dependency labels is identical for both sentences. This means that these sentences follow the same word sequence pattern based on the following syntactic dependency labels: “subject + auxiliary + verb + direct object.”</p>&#13;
<p class="indent">Also notice that the list of part-of-speech tags (coarse-grained and fined-grained) is also identical for these sample sentences. If we replace all references to <code>.dep</code>_ with <code>.pos</code>_ in the previous script, we’ll get the following results:</p>&#13;
<pre>We       You     PRON  pronoun<br/>&#13;
can      must    VERB  verb<br/>&#13;
overtake specify VERB  verb<br/>&#13;
them     it      PRON  pronoun</pre>&#13;
<p class="indent">The sample sentences match not only the syntactic dependency label pattern, but also the pattern of part-of-speech tags.</p>&#13;
<h4 class="h4" id="lev72"><strong><em>Try This</em></strong></h4>&#13;
<p class="noindent">In the previous example, we created two Doc objects—one for each sample sentence. But in practice, a text usually consists of numerous sentences, which makes a Doc-per-sentence approach impractical. Rewrite the script so it creates a single Doc object. Then use the <code>doc.sents</code> property introduced in <a href="../Text/ch02.xhtml#ch02">Chapter 2</a> to operate on each sentence.</p>&#13;
<p class="indent">But note that <code>doc.sents</code> is a generator object, which means it’s not subscriptable—you can’t refer to its items by index. To solve this issue, convert the <code>doc.sents</code> to a list, as follows:</p>&#13;
<pre>sents = list(doc.sents)</pre>&#13;
<p class="indent">And, of course, you can iterate over a <code>doc.sents</code> in a <code>for</code> loop to obtain the <code>sents</code> in order, as they’re requested by the loop.</p>&#13;
<h4 class="h4" id="lev73"><strong><em>Checking an Utterance for a Pattern</em></strong></h4>&#13;
<p class="noindent">In the preceding example, we compared two sample sentences to find a pattern based on their shared linguistic features. But in practice, we’ll rarely want to compare sentences to one another to determine whether they share a common pattern. Instead, it’ll be more useful to check a submitted sentence against the pattern we’re already interested in.</p>&#13;
<p class="indent">For example, let’s say we were trying to find utterances in user input that express one of the following: ability, possibility, permission, or obligation (as opposed to utterances that describe real actions that have occurred, are occurring, or occur regularly). For instance, we want to find “I can do it.” but not “I’ve done it.”</p>&#13;
<p class="indent">To distinguish between utterances, we might check whether an utterance satisfies the following pattern: “subject + auxiliary + verb + . . . + direct <span epub:type="pagebreak" id="page_78"/>object . . .”. The ellipses indicate that the direct object isn’t necessarily located immediately behind the verb, making this pattern a little different from the one in the preceding example.</p>&#13;
<p class="indent">The following sentence satisfies the pattern: “I might send them a card as a reminder.”. In this sentence, the noun “card” is a direct object, and the pronoun “them” is an indirect object that separates it from the verb “send.” The pattern doesn’t specify a position for the direct object in the sentence; it simply requires its presence.</p>&#13;
<p class="indent"><a href="../Text/ch06.xhtml#ch06fig01">Figure 6-1</a> shows a graphical depiction of this design:</p>&#13;
<div class="image"><a id="ch06fig01"/><img src="../Images/fig6-1.jpg" alt="image" width="531" height="140"/></div>&#13;
<p class="figcap"><em>Figure 6-1: Checking submitted utterances against a word sequence pattern based on linguistic features</em></p>&#13;
<p class="indent">In the following script, we define a function that implements this pattern, and then test it on a sample sentence:</p>&#13;
<pre>   import spacy<br/>&#13;
   nlp = spacy.load('en')<br/>&#13;
<span class="ent">➊</span> def dep_pattern(doc):<br/>&#13;
  <span class="ent">➋</span> for i in range(len(doc)-1):<br/>&#13;
    <span class="ent">➌</span> if doc[i].dep_ == 'nsubj' and doc[i+1].dep_ == 'aux' and<br/>&#13;
       doc[i+2].dep_ == 'ROOT':<br/>&#13;
      <span class="ent">➍</span> for tok in doc[i+2].children:<br/>&#13;
             if tok.dep_ == 'dobj':<br/>&#13;
          <span class="ent">➎</span> return True<br/>&#13;
  <span class="ent">➏</span> return False<br/>&#13;
<span class="ent">➐</span> doc = nlp(u'We can overtake them.')<br/>&#13;
   if <span class="ent">➑</span>dep_pattern(doc):<br/>&#13;
     print('Found')<br/>&#13;
   else:<br/>&#13;
     print('Not found')</pre>&#13;
<p class="indent">In this script, we define the <code>dep_pattern</code> function that takes a Doc object as parameter <span class="ent">➊</span>. In the function, we iterate over the Doc object’s tokens <span class="ent">➋</span>, searching for a “subject + auxiliary + verb” pattern <span class="ent">➌</span>. If we find this pattern, we check whether the verb has a direct object among its syntactic children <span class="ent">➍</span>. Finally, if we find a direct object, the function returns <code>True</code> <span class="ent">➎</span>. Otherwise, it returns <code>False</code> <span class="ent">➏</span>.</p>&#13;
<p class="indent">In the main code, we apply the text-processing pipeline to the sample sentence <span class="ent">➐</span> and send the Doc object to the <code>dep_pattern</code> function <span class="ent">➑</span>, outputting <code>Found</code> if the sample satisfies the pattern implemented in the function or <code>Not found</code> otherwise.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_79"/>Because the sample used in this example satisfies the pattern, the script should produce the following output:</p>&#13;
<pre>Found</pre>&#13;
<p class="indent">You’ll see some examples of using the <code>dep_pattern</code> function in some of the following sections.</p>&#13;
<h4 class="h4" id="lev74"><strong><em>Using spaCy’s Matcher to Find Word Sequence Patterns</em></strong></h4>&#13;
<p class="noindent">In the previous section, you learned how to find a word sequence pattern in a doc by iterating over its tokens and checking their linguistic features. In fact, spaCy has a predefined feature for this task called <em>Matcher</em>, a tool that is specially designed to find sequences of tokens based on pattern rules. For example, an implementation of the “subject + auxiliary + verb” pattern with Matcher might look like this:</p>&#13;
<pre>   import spacy<br/>&#13;
   from spacy.matcher import Matcher<br/>&#13;
   nlp = spacy.load("en")<br/>&#13;
<span class="ent">➊</span> matcher = Matcher(nlp.vocab)<br/>&#13;
<span class="ent">➋</span> pattern = [{"DEP": "nsubj"}, {"DEP": "aux"}, {"DEP": "ROOT"}]<br/>&#13;
<span class="ent">➌</span> matcher.add("NsubjAuxRoot", None, pattern)<br/>&#13;
   doc = nlp(u"We can overtake them.")<br/>&#13;
<span class="ent">➍</span> matches = matcher(doc)<br/>&#13;
<span class="ent">➎</span> for match_id, start, end in matches:<br/>&#13;
       span = doc[start:end]<br/>&#13;
    <span class="ent">➏</span> print("Span: ", span.text)<br/>&#13;
       print("The positions in the doc are: ", start, "-", end)</pre>&#13;
<p class="indent">We create a Matcher instance, passing in the vocabulary object shared with the documents the Matcher will work on <span class="ent">➊</span>. Then we define a pattern, specifying the dependency labels that a word sequence should match <span class="ent">➋</span>. We add the newly created pattern to the Matcher <span class="ent">➌</span>.</p>&#13;
<p class="indent">Next, we can apply the Matcher to a sample text and obtain the matching tokens in a list <span class="ent">➍</span>. Then we iterate over this list <span class="ent">➎</span>, printing out the start and end positions of the pattern tokens in the text <span class="ent">➏</span>.</p>&#13;
<p class="indent">The script should produce the following output:</p>&#13;
<pre>Span: We can overtake<br/>&#13;
The positions in the doc are: 0 - 3</pre>&#13;
<p class="indent">Matcher allows you to find a pattern in a text without iterating explicitly over the text’s tokens, thus hiding implementation details from you. As a result, you can obtain the start and end positions of the words composing a sequence that satisfies the specified pattern. This approach can be very useful when you’re interested in a sequence of words that immediately follow one another.</p>&#13;
<p class="indent">But often you need a pattern that includes words scattered over the sentence. For example, you might need to implement such patterns as <span epub:type="pagebreak" id="page_80"/>the “subject + auxiliary + verb + . . . + direct object . . .” pattern we used in “<a href="../Text/ch06.xhtml#lev73">Checking an Utterance for a Pattern</a>” on <a href="../Text/ch06.xhtml#page_77">page 77</a>. The problem is that you don’t know in advance how many words can occur between the “subject + auxiliary + verb” sequence and the direct object. Matcher doesn’t allow you to define such patterns. For this reason, I’ll define patterns manually for the remainder of this chapter.</p>&#13;
<h4 class="h4" id="lev75"><strong><em>Applying Several Patterns</em></strong></h4>&#13;
<p class="noindent">You can apply several matching patterns to an utterance to make sure it satisfies all your conditions. For example, you might check an utterance against two patterns: one that implements a dependency label sequence (as discussed in “<a href="../Text/ch06.xhtml#lev73">Checking an Utterance for a Pattern</a>” on <a href="../Text/ch06.xhtml#page_77">page 77</a>) and one that checks against a sequence of part-of-speech tags. This might be helpful, if, say, you want to make sure that the direct object in an utterance is a personal pronoun. If so, you can start the procedure of determining the noun that gives its meaning to the pronoun and is mentioned elsewhere in the discourse.</p>&#13;
<p class="indent">Diagrammatically, this design might look like <a href="../Text/ch06.xhtml#ch06fig02">Figure 6-2</a>.</p>&#13;
<div class="image"><a id="ch06fig02"/><img src="../Images/fig6-2.jpg" alt="image" width="537" height="319"/></div>&#13;
<p class="figcap"><em>Figure 6-2: Applying several matching patterns to user input</em></p>&#13;
<p class="indent">In addition to using the dependency label sequence defined in “<a href="../Text/ch06.xhtml#lev73">Checking an Utterance for a Pattern</a>”, you can define a new function by implementing a pattern based on part-of-speech tags. The part-of-speech tag pattern might search the sentence to make sure that the subject and the direct object are personal pronouns. This new function might implement the following pattern: “personal pronoun + modal auxiliary verb + base form verb + . . . + personal pronoun . . .”.</p>&#13;
<p class="indent">Here is the code:</p>&#13;
<pre>import spacy<br/>&#13;
nlp = spacy.load('en')<br/>&#13;
#Insert the dep_pattern function from a previous listing here<br/>&#13;
#...<br/>&#13;
<span epub:type="pagebreak" id="page_81"/><span class="ent">➊</span> def pos_pattern(doc):<br/>&#13;
  <span class="ent">➋</span> for token in doc:<br/>&#13;
       if token.dep_ == 'nsubj' and token.tag_ != 'PRP':<br/>&#13;
         return False<br/>&#13;
       if token.dep_ == 'aux' and token.tag_ != 'MD':<br/>&#13;
         return False<br/>&#13;
       if token.dep_ == 'ROOT' and token.tag_ != 'VB':<br/>&#13;
         return False<br/>&#13;
       if token.dep_ == 'dobj' and token.tag_ != 'PRP':<br/>&#13;
         return False<br/>&#13;
  <span class="ent">➌</span> return True<br/>&#13;
   #Testing code<br/>&#13;
   doc = nlp(u'We can overtake them.')<br/>&#13;
<span class="ent">➍</span> if dep_pattern(doc) and pos_pattern(doc):<br/>&#13;
       print('Found')<br/>&#13;
   else:<br/>&#13;
       print('Not found')</pre>&#13;
<p class="indent">We start by adding the code for the <code>dep_pattern</code> function defined in a previous script. To create the second pattern, we define the <code>pos_pattern</code> function <span class="ent">➊</span>, which contains a <code>for</code> loop with a series of <code>if</code> statements in it <span class="ent">➋</span>. Each <code>if</code> statement checks whether a certain part of a sentence matches a certain part-of-speech tag. When the function detects a mismatch, it returns <code>False</code>. Otherwise, after all the checks have occurred and no mismatch has been detected, the function returns <code>True</code> <span class="ent">➌</span>.</p>&#13;
<p class="indent">To test the patterns, we apply the pipeline to a sentence, and then check whether the sentence matches both patterns <span class="ent">➍</span>. Because the sample used in this example matches both patterns, we should see the following output:</p>&#13;
<pre>Found</pre>&#13;
<p class="indent">But if we replace the sample sentence with this one: “I might send them a card as a reminder.”, we should see this output:</p>&#13;
<pre>Not found</pre>&#13;
<p class="indent">The reason is that the sentence doesn’t match the part-of-speech tag pattern, because the direct object “card” isn’t a personal pronoun, even though the sentence fully satisfies the conditions of the first pattern.</p>&#13;
<h4 class="h4" id="lev76"><strong><em>Creating Patterns Based on Customized Features</em></strong></h4>&#13;
<p class="noindent">When creating a word sequence pattern, you might need to enhance the functionality of the linguistic features spaCy provides by customizing them for your needs. For example, you might want the preceding script to recognize another pattern that distinguishes pronouns according to number (whether they’re singular or plural). Once again, this could be useful when you need to find the noun in a previous utterance to which the pronoun refers.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_82"/>Although spaCy separates nouns by number, it doesn’t do this for pronouns. But the ability to recognize whether a pronoun is plural or singular can be very useful in the task of meaning recognition or information extraction. For example, consider the following discourse:</p>&#13;
<pre>The trucks are traveling slowly. We can overtake them.</pre>&#13;
<p class="indent">If we can establish that the direct object “them” in the second sentence is a plural pronoun, we’ll have reason to believe that it refers to the plural noun “trucks” in the first sentence. We often use this technique to recognize a pronoun’s meaning based on the context.</p>&#13;
<p class="indent">The following script defines a <code>pron_pattern</code> function, which finds any direct object in the submitted sentence, determines whether that direct object is a personal pronoun, and then determines whether the pronoun is singular or plural. The script then applies the function to a sample sentence after testing for the two patterns defined in “<a href="../Text/ch06.xhtml#lev73">Checking an Utterance for a Pattern</a>” on <a href="../Text/ch06.xhtml#page_77">page 77</a> and “<a href="../Text/ch06.xhtml#lev75">Applying Several Patterns</a>” on <a href="../Text/ch06.xhtml#page_80">page 80</a>.</p>&#13;
<pre>   import spacy<br/>&#13;
   nlp = spacy.load('en')<br/>&#13;
   #Insert the dep_pattern and pos_pattern functions from the previous<br/>&#13;
   listings here<br/>&#13;
   #...<br/>&#13;
<span class="ent">➊</span> def pron_pattern(doc):<br/>&#13;
  <span class="ent">➋</span> plural = ['we','us','they','them']<br/>&#13;
     for token in doc:<br/>&#13;
    <span class="ent">➌</span> if token.dep_ == 'dobj' and token.tag_ == 'PRP':<br/>&#13;
      <span class="ent">➍</span> if token.text in plural:<br/>&#13;
        <span class="ent">➎</span> return 'plural'<br/>&#13;
         else:<br/>&#13;
        <span class="ent">➏</span> return 'singular'<br/>&#13;
  <span class="ent">➐</span> return 'not found'<br/>&#13;
   doc = nlp(u'We can overtake them.')<br/>&#13;
   if dep_pattern(doc) and pos_pattern(doc):<br/>&#13;
       print('Found:', 'the pronoun in position of direct object is',<br/>&#13;
       pron_pattern(doc))<br/>&#13;
   else:<br/>&#13;
       print('Not found')</pre>&#13;
<p class="indent">We start by adding the <code>dep_pattern</code> and <code>pos_pattern</code> functions defined in “<a href="../Text/ch06.xhtml#lev73">Checking an Utterance for a Pattern</a>” and “<a href="../Text/ch06.xhtml#lev75">Applying Several Patterns</a>” to the script. In the <code>pron_pattern</code> function <span class="ent">➊</span>, we define a Python list that includes all the possible plural personal pronouns <span class="ent">➋</span>. Next, we define a loop that iterates over the tokens in the submitted sentence, looking for a direct object that is a personal pronoun <span class="ent">➌</span>. If we find such a token, we check whether it’s in the list of plural personal pronouns <span class="ent">➍</span>. If so, the function returns <code>plural</code> <span class="ent">➎</span>. Otherwise, it returns <code>singular</code> <span class="ent">➏</span>. If the function either failed to detect a direct object or found one that isn’t a personal pronoun, it returns <code>Not found</code> <span class="ent">➐</span>.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_83"/>For the sentence “We can overtake them.”, we should get the following output:</p>&#13;
<pre>Found: the pronoun in position of direct object is plural</pre>&#13;
<p class="indent">We could use this information to find a corresponding noun for the pronoun in the previous sentence.</p>&#13;
<h4 class="h4" id="lev77"><strong><em>Choosing Which Patterns to Apply</em></strong></h4>&#13;
<p class="noindent">Once you define these patterns, you can choose which ones to apply for each situation. Notice that even if a sentence fails to fully satisfy the <code>dep_pattern</code> and <code>pos_pattern</code> functions, it might still match the <code>pron_pattern</code> function. For example, the sentence “I know it.” doesn’t match either the <code>dep_pattern</code> or <code>pos_pattern</code> functions, because it doesn’t have a modal auxiliary verb. But it satisfies <code>pron_pattern</code> because it contains a personal pronoun that is the direct object of the sentence.</p>&#13;
<p class="indent">This loose coupling between the patterns lets you use them with other patterns or independently. For example, you might use <code>dep_pattern</code>, which checks a sentence against the “subject + auxiliary + verb + . . . + direct object . . .” pattern in conjunction with, say, a “noun + modal auxiliary verb + base form verb + . . . + noun . . .” pattern, if you wanted to be sure that the subject and the direct object in the sentence are nouns. These two patterns would match the following example:</p>&#13;
<pre>Developers might follow this rule.</pre>&#13;
<p class="indent">As you might guess, the ability to combine patterns in different ways allows you to handle more scenarios with less code.</p>&#13;
<h4 class="h4" id="lev78"><strong><em>Using Word Sequence Patterns in Chatbots to Generate Statements</em></strong></h4>&#13;
<p class="noindent">As stated earlier, the most challenging tasks in NLP are understanding and generating natural language text. A chatbot must understand a user’s input and then generate a proper response to it. Word sequence patterns based on linguistic features can help you implement these functions.</p>&#13;
<p class="indent">In <a href="../Text/ch04.xhtml#ch04">Chapter 4</a>, you learned how to turn a statement into a relevant question to continue a conversation with a user. Using word sequence patterns, you could generate other kinds of responses, too, such as relevant statements.</p>&#13;
<p class="indent">Suppose your chatbot has received the following user input:</p>&#13;
<pre>The symbols are clearly distinguishable. I can recognize them promptly.</pre>&#13;
<p class="indent">The chatbot might react as follows:</p>&#13;
<pre>I can recognize symbols promptly too.</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_84"/>You can use the patterns implemented in the previous sections to accomplish this text generation task. The list of steps might look like this:</p>&#13;
<ol>&#13;
<li class="noindent">Check the conversational input against the <code>dep_pattern</code> and <code>pos_pattern</code> functions defined previously to find an utterance that follows the “subject + auxiliary + verb + . . . + direct object . . .” and “pronoun + modal auxiliary verb + base form verb + . . . + pronoun . . .” patterns, respectively.</li>&#13;
<li class="noindent">Check the utterance found in step 1 against the <code>pron_pattern</code> pattern to determine whether the direct object personal pronoun is plural or singular.</li>&#13;
<li class="noindent">Find the noun that gives its meaning to the pronoun by searching for a noun that has the same number as the personal pronoun.</li>&#13;
<li class="noindent">Replace the pronoun that acts as the direct object in the sentence located in step 1 with the noun found in step 3.</li>&#13;
<li class="noindent">Append the word “too” to the end of the generated utterance.</li>&#13;
</ol>&#13;
<p class="indent">The following script implements these steps. It uses the <code>dep_pattern</code>, <code>pos_pattern</code>, and <code>pron_pattern</code> functions defined earlier in this chapter (their code is omitted to save space). It also introduces two new functions: <code>find_noun</code> and <code>gen_utterance</code>. For convenience, we’ll walk through the code in three steps: the initial operations and the <code>find_noun</code> function, which finds the noun that matches the personal pronoun; the <code>gen_utterance</code> function, which generates a relevant statement from that question; and finally, the code that tests an utterance. Here is the first part:</p>&#13;
<pre>   import spacy<br/>&#13;
   nlp = spacy.load('en')<br/>&#13;
   #Insert the dep_pattern, pos_pattern and pron_pattern functions from the <br/>&#13;
   previous listings here<br/>&#13;
   #...<br/>&#13;
<span class="ent">➊</span> def find_noun(<span class="ent">➋</span>sents, <span class="ent">➌</span>num):<br/>&#13;
     if num == 'plural':<br/>&#13;
    <span class="ent">➍</span> taglist = ['NNS','NNPS']<br/>&#13;
     if num == 'singular':<br/>&#13;
    <span class="ent">➎</span> taglist = ['NN','NNP']<br/>&#13;
  <span class="ent">➏</span> for sent in reversed(sents):<br/>&#13;
    <span class="ent">➐</span> for token in sent:<br/>&#13;
      <span class="ent">➑</span> if token.tag_ in taglist:<br/>&#13;
           return token.text<br/>&#13;
     return 'Noun not found'</pre>&#13;
<p class="indent">After inserting the code of the <code>dep_pattern</code>, <code>pos_pattern</code>, and <code>pron_pattern</code> functions, we define the <code>find_noun</code> function, which takes two parameters <span class="ent">➊</span>. The first one contains a list of the sentences from the beginning of the discourse up to the sentence that satisfies all the patterns here. In this example, this list will include all the sentences from the discourse, because only the last sentence satisfies all the patterns <span class="ent">➋</span>. But the noun that gives its meaning to the pronoun can be found in one of the previous sentences.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_85"/>The second parameter sent to <code>find_noun</code> is the number of the direct object pronoun in the sentence that satisfies all the patterns <span class="ent">➌</span>. The <code>pron_pattern</code> function determines this. If the value of this argument is <code>'plural'</code>, we define a Python list containing fine-grained part-of-speech tags used in spaCy to mark plural nouns <span class="ent">➍</span>. If it’s <code>'singular'</code>, we create a tag list containing fine-grained part-of-speech tags used to mark singular nouns <span class="ent">➎</span>.</p>&#13;
<p class="indent">In a <code>for</code> loop, we iterate over the sentences in reverse order, starting from the sentence that is the closest to the sentence containing the pronoun to be replaced <span class="ent">➏</span>. We start with the closest sentence, because the noun we’re searching for will most likely be there. Here, we use Python’s reversed function that returns a reverse iterator over the list. In the inner loop, we iterate over the tokens in each sentence <span class="ent">➐</span>, looking for a token whose fine-grained part-of-speech tag is in the tag list defined earlier <span class="ent">➑</span>.</p>&#13;
<p class="indent">Then we define the <code>gen_utterance</code> function, which generates our new statement:</p>&#13;
<pre>   def gen_utterance(doc, noun):<br/>&#13;
     sent = ''<br/>&#13;
  <span class="ent">➊</span> for i,token in enumerate(doc):<br/>&#13;
    <span class="ent">➋</span> if token.dep_ == 'dobj' and token.tag_ == 'PRP':<br/>&#13;
      <span class="ent">➌</span> sent = doc[:i].text + ' ' + noun + ' ' + doc[i+1:len(doc)-2].text + 'too.'<br/>&#13;
      <span class="ent">➍</span> return sent<br/>&#13;
   <span class="ent">➎</span> return 'Failed to generate an utterance'</pre>&#13;
<p class="indent">We use a <code>for</code> loop to iterate over the tokens in the sentence <span class="ent">➊</span>, looking for a direct object that is a personal pronoun <span class="ent">➋</span>. Once we’ve found one, we generate a new utterance. We change the original sentence by replacing the personal pronoun with the matching noun and appending “too” to the end of it <span class="ent">➌</span>. The function then returns this newly generated utterance <span class="ent">➍</span>. If we haven’t found a direct object in the form of a personal pronoun, the function returns an error message <span class="ent">➎</span>.</p>&#13;
<p class="indent">Now that we have all the functions in place, we can test them on a sample utterance using the following code:</p>&#13;
<pre><span class="ent">➊</span> doc = nlp(u'The symbols are clearly distinguishable. I can recognize them <br/>&#13;
   promptly.')<br/>&#13;
<span class="ent">➋</span> sents = list(doc.sents)<br/>&#13;
   response = ''<br/>&#13;
   noun = ''<br/>&#13;
<span class="ent">➌</span> for i, sent in enumerate(sents): <br/>&#13;
     if dep_pattern(sent) and pos_pattern(sent):<br/>&#13;
  <span class="ent">➍</span> noun = find_noun(sents[:i], pron_pattern(sent))<br/>&#13;
       if noun != 'Noun not found':<br/>&#13;
    <span class="ent">➎</span> response = gen_utterance(sents[i],noun)<br/>&#13;
       break<br/>&#13;
print(response)</pre>&#13;
<p class="indent">After applying the pipeline to the sample discourse <span class="ent">➊</span>, we convert it to the list of sentences <span class="ent">➋</span>. Then we iterate over this list <span class="ent">➌</span>, searching for the sentence that matches the patterns defined in the <code>dep_pattern</code> and <code>pos_pattern</code> functions. Next, we determine the noun that gives the <span epub:type="pagebreak" id="page_86"/>meaning to the pronoun in the sentence found in the previous step, using the<code> find_noun</code> function <span class="ent">➍</span>. Finally, we call the <code>get_utterance</code> function to generate a response utterance <span class="ent">➎</span>.</p>&#13;
<p class="indent">The output of the preceding code should look like this:</p>&#13;
<pre>I can recognize symbols too.</pre>&#13;
<h4 class="h4" id="lev79"><strong><em>Try This</em></strong></h4>&#13;
<p class="noindent">Notice that there’s still room for improvement in the preceding code, because the original statement included the article “the” in front of the noun “symbols.” A better output would include the same article in front of the noun. To generate a statement that makes the most sense in this context, expand on the script so that it inserts the article “the” in front of the noun, making it “I can recognize the symbols too.” For that, you’ll need to check whether the noun is preceded by an article, and then add that article.</p>&#13;
<h3 class="h3" id="lev80"><strong>Extracting Keywords from Syntactic Dependency Trees</strong></h3>&#13;
<p class="noindent">Finding a sequence of words in an utterance that satisfies a certain pattern allows you to construct a grammatically correct response—either a statement or a question, based on the submitted text. But these patterns aren’t always useful for extracting the meaning of texts.</p>&#13;
<p class="indent">For example, in the ticket-booking application in <a href="../Text/ch02.xhtml#ch02">Chapter 2</a>, a user might submit a sentence like this:</p>&#13;
<pre>I need an air ticket to Berlin.</pre>&#13;
<p class="indent">You could easily find the user’s intended destination by searching for the pattern “to + <code>GPE</code>” where <code>GPE</code> is a named entity for countries, cities, and states. This pattern would match phrases like “to London,” “to California,” and so on.</p>&#13;
<p class="indent">But suppose the user submitted one of the following utterances instead:</p>&#13;
<pre>I am going to the conference in Berlin. I need an air ticket. <br/>&#13;
I am going to the conference, which will be held in Berlin. I would like to<br/>&#13;
book an air ticket.</pre>&#13;
<p class="indent">As you can see, the “to + <code>GPE</code>” pattern wouldn’t find the destination in either example. In both cases, “to” directly refers to “the conference,” not to Berlin. You’d need something like “to + . . . + <code>GPE</code>” instead. But how would you know what’s required—or what’s allowed—between “to” and “<code>GPE</code>”? For example, the following sentence contains the “to + . . . + <code>GPE</code>” pattern but has nothing to do with booking a ticket to Berlin:</p>&#13;
<pre>I want to book a ticket on a direct flight without landing in Berlin.</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_87"/>Often, you need to examine relations between the words in a sentence to obtain necessary pieces of information. This is where walking the dependency tree of the sentence could help a lot.</p>&#13;
<p class="indent">Walking a dependency tree means navigating through it in custom order—not necessarily from the first token to the last one. For example, you can stop iterating a dependency tree just after the required component is found. Remember that a sentence’s dependency tree shows the syntactic relationships between pairs of words. We often represent these as arrows connecting the head with the child of a relation. Every word in a sentence is involved in at least one of the relations. This guarantees that you’ll pass through each word in a sentence when walking through the entire dependency tree generated for that sentence if you start from <code>ROOT</code>.</p>&#13;
<p class="indent">In this section, we’ll examine a sentence’s structure to figure out a user’s intended meaning.</p>&#13;
<h4 class="h4" id="lev81"><strong><em>Walking a Dependency Tree for Information Extraction</em></strong></h4>&#13;
<p class="noindent">Let’s return to the ticket-booking application example. To find a user’s intended destination, you might need to iterate over the dependency tree of a sentence to determine whether “to” is semantically related to “Berlin.” This is easy to accomplish if you remember the head/child syntactic relations that compose a dependency tree, which was introduced in the “Head and Child” box on <a href="../Text/ch02.xhtml#page_25">page 25</a>.</p>&#13;
<p class="indent"><a href="../Text/ch06.xhtml#ch06fig03">Figure 6-3</a> shows the dependency tree for the sentence, “I am going to the conference in Berlin”:</p>&#13;
<div class="image"><a id="ch06fig03"/><img src="../Images/fig6-3.jpg" alt="image" width="671" height="168"/></div>&#13;
<p class="figcap"><em>Figure 6-3: A syntactic dependency tree of an utterance</em></p>&#13;
<p class="indent">The verb “going” is the root of the sentence, meaning it’s not a child of any other word. Its child to the immediate right is “to.” If you walk through the dependency tree, moving to the child to the immediate right of each word, you’ll finally reach “Berlin.” This shows that there’s a semantic connection between “to” and “Berlin” in this sentence.</p>&#13;
<h4 class="h4" id="lev82"><strong><em>Iterating over the Heads of Tokens</em></strong></h4>&#13;
<p class="noindent">Now let’s figure out how to express the relation between “to” and “Berlin” in the sentence programmatically. One way is to walk the dependency tree from left to right, starting from “to,” choosing only the immediate right child of each word along the way. If you can go from “to” to “Berlin” this way, you can reasonably assume that there’s a semantic connection between the two words.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_88"/>But this approach has a drawback. In some cases, a word might have more than one right child. For example, in the sentence “I am going to the conference on spaCy, which will be held in Berlin,” the word “conference” has two immediate right children: the words “on” and “held.” This forces you to check multiple branches, complicating the code.</p>&#13;
<p class="indent">On the other hand, although a head can have multiple children, each word in a sentence has exactly one head. This means you can instead move from right to left, starting from “Berlin” and trying to reach “to.” The following script implements this process in the <code>det_destination</code> function:</p>&#13;
<pre>   import spacy<br/>&#13;
   nlp = spacy.load('en')<br/>&#13;
   #Here's the function that figures out the destination<br/>&#13;
<span class="ent">➊</span> def det_destination(doc):<br/>&#13;
     for i, token in enumerate(doc):<br/>&#13;
   <span class="ent">➋</span> if token.ent_type != 0 and token.ent_type_ == 'GPE':<br/>&#13;
      <span class="ent">➌</span> while True:<br/>&#13;
        <span class="ent">➍</span> token = token.head<br/>&#13;
           if token.text == 'to':<br/>&#13;
          <span class="ent">➎</span> return doc[i].text<br/>&#13;
        <span class="ent">➏</span> if token.head == token:<br/>&#13;
             return 'Failed to determine'<br/>&#13;
     return 'Failed to determine'<br/>&#13;
   #Testing the det_destination function<br/>&#13;
   doc = nlp(u'I am going to the conference in Berlin.')<br/>&#13;
<span class="ent">➐</span> dest = det_destination(doc)<br/>&#13;
   print('It seems the user wants a ticket to ' + dest)</pre>&#13;
<p class="indent">In the <code>det_destination</code> function <span class="ent">➊</span>, we iterate over the tokens in the submitted utterance, looking for a <code>GPE</code> entity <span class="ent">➋</span>. If it’s found, we start a <code>while</code> loop <span class="ent">➌</span> that iterates over the head of each token, starting from the token containing the <code>GPE</code> entity <span class="ent">➍</span>. The loop stops when it reaches either the token containing “to” <span class="ent">➎</span> or the root of the sentence. We can check for the root by comparing a token to its head <span class="ent">➏</span>, because the head of the root token always refers to itself. (Alternatively, we can check for the <code>ROOT</code> tag.)</p>&#13;
<p class="indent">To test this function, we apply the pipeline to the sample sentence and then invoke the <code>det_destination</code> function on it <span class="ent">➐</span>.</p>&#13;
<p class="indent">The script should generate the following output:</p>&#13;
<pre>It seems the user wants a ticket to Berlin</pre>&#13;
<p class="indent">If we change the sample sentence so it doesn’t contain “to” or a <code>GPE</code> named entity, we should get the following output:</p>&#13;
<pre>It seems the user wants a ticket to Failed to determine</pre>&#13;
<p class="indent">We can improve the script so it uses another message for cases when it fails to determine the user’s destination.</p>&#13;
<h4 class="h4" id="lev83"><span epub:type="pagebreak" id="page_89"/><strong><em>Condensing a Text Using Dependency Trees</em></strong></h4>&#13;
<p class="noindent">The syntactic dependency tree approach isn’t limited to chatbots, of course. You could use it, for example, in report-processing applications. Say, you need to develop an application that has to condense retail reports by extracting only the most important information from them.</p>&#13;
<p class="indent">For example, you might want to select the sentences containing numbers, producing a concise summary of the data on sales volume, revenue, and costs. (You learned how to extract numbers in <a href="../Text/ch04.xhtml#ch04">Chapter 4</a>.) Then, to make your new report more concise, you might shorten the selected sentences.</p>&#13;
<p class="indent">As a quick example, consider the following sentence:</p>&#13;
<pre>The product sales hit a new record in the first quarter, with 18.6 million units sold.</pre>&#13;
<p class="indent">After processing, it should look like this:</p>&#13;
<pre>The product sales hit 18.6 million units sold.</pre>&#13;
<p class="indent">To accomplish this, you can analyze the dependency trees of sentences by following these steps:</p>&#13;
<ol>&#13;
<li class="noindent">Extract the entire phrase containing the number (it’s 18.6 in this example) by walking the heads of tokens, starting from the token containing the number and moving from left to right.</li>&#13;
<li class="noindent">Walk the dependency tree from the main word of the extracted phrase (the one whose head is out of the phrase) to the main verb of the sentence, iterating over the heads and picking them up to be used in a new sentence.</li>&#13;
<li class="noindent">Pick up the main verb’s subject, along with its leftward children, which typically include a determiner and possibly some other modifiers.</li>&#13;
</ol>&#13;
<p class="indent"><a href="../Text/ch06.xhtml#ch06fig04">Figure 6-4</a> represents this process.</p>&#13;
<div class="image"><a id="ch06fig04"/><img src="../Images/fig6-4.jpg" alt="image" width="670" height="282"/></div>&#13;
<p class="figcap"><em>Figure 6-4: An example of condensing a sentence to include only important elements</em></p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_90"/>Let’s start with the first step, which in this example should extract the phrase “18.6 million units sold.”. The following code snippet illustrates how to do this programmatically:</p>&#13;
<pre> doc = nlp(u"The product sales hit a new record in the first quarter, with 18.6 million units sold.")<br/>&#13;
 phrase = ''<br/>&#13;
 for token in doc:<br/>&#13;
<span class="ent">➊</span> if token.pos_ == 'NUM':<br/>&#13;
       while True:<br/>&#13;
         phrase = phrase + ' ' + token.text<br/>&#13;
      <span class="ent">➋</span> token = token.head<br/>&#13;
      <span class="ent">➌</span> if token not in list(token.head.lefts):<br/>&#13;
           phrase = phrase + ' ' + token.text<br/>&#13;
        <span class="ent">➍</span> break<br/>&#13;
    <span class="ent">➎</span> break<br/>&#13;
 print(phrase.strip())</pre>&#13;
<p class="indent">We iterate over the sentence’s tokens, looking for one that represents a number <span class="ent">➊</span>. If we find one, we start a <code>while</code> loop that iterates over right-hand heads <span class="ent">➋</span>, starting from the number token and then appending the text of each head to the <code>phrase</code> variable to form a new phrase. To make sure the head of the next token is to the right of that token, we check whether the token is in the list of its head’s left children <span class="ent">➌</span>. Once this condition returns false, we break from the <code>while</code> loop <span class="ent">➍</span> and then from the outer <code>for</code> loop <span class="ent">➎</span>.</p>&#13;
<p class="indent">Next, we walk the heads of tokens, starting from the main word of the phrase containing the number (“sold” in this example) until we reach the main verb of the sentence (“hit” in this example), excluding the adposition (“with” in this example). We can implement this as shown in the following listing:</p>&#13;
<pre> while True:<br/>&#13;
<span class="ent">➊</span> token = doc[token.i].head<br/>&#13;
   if token.pos_ != 'ADP':<br/>&#13;
  <span class="ent">➋</span> phrase = token.text + phrase<br/>&#13;
<span class="ent">➌</span> if token.dep_ == 'ROOT':<br/>&#13;
<span class="ent">➍</span> break</pre>&#13;
<p class="indent">We walk the heads of tokens <span class="ent">➊</span> in a <code>while</code> loop, appending the text of each head to the phrase being formed <span class="ent">➋</span>. After reaching the main verb (marked as <code>ROOT</code>) <span class="ent">➌</span>, we break from the loop <span class="ent">➍</span>.</p>&#13;
<p class="indent">Finally, we pick up the subject of the sentence, along with its left children: “The” and “product.” In this example, the subject is “sales,” so we pick up the following noun chunk: “The product sales.” This can be done with the following code:</p>&#13;
<pre><span class="ent">➊</span> for tok in token.lefts:<br/>&#13;
  <span class="ent">➋</span> if tok.dep_ == 'nsubj':<br/>&#13;
<span epub:type="pagebreak" id="page_91"/>   <span class="ent">➌</span> phrase = ' '.join([tok.text for tok in tok.lefts]) + ' ' + tok.text + ' '<br/>&#13;
      + phrase<br/>&#13;
      break<br/>&#13;
<span class="ent">➍</span> print(phrase)</pre>&#13;
<p class="indent">We start by iterating over the main verb’s children <span class="ent">➊</span>, searching for the subject <span class="ent">➋</span>. Then we prepend the subject’s children and the subject of the phrase <span class="ent">➌</span>. To see the resulting phrase, we print it <span class="ent">➍</span>.</p>&#13;
<p class="indent">The output should look like this:</p>&#13;
<pre>The product sales hit 18.6 million units sold.</pre>&#13;
<p class="indent">The result is a condensed version of the original sentence.</p>&#13;
<h4 class="h4" id="lev84"><strong><em>Try This</em></strong></h4>&#13;
<p class="noindent">Write a script that condenses financial reports by extracting only those sentences that contain phrases referring to an amount of money. Also, the script needs to condense the selected sentences so they include only the subject, the main verb, the phrase referring to an amount of money, and the tokens you can pick up when walking the heads starting from the main word of the money phrase up to the main verb of the sentence. For example, given the following sentence:</p>&#13;
<pre>The company, whose profits reached a record high this year, largely attributed<br/>&#13;
to changes in management, earned a total revenue of $4.26 million.</pre>&#13;
<p class="indent">Your script should return this sentence:</p>&#13;
<pre>The company earned revenue of $4.26 million.</pre>&#13;
<p class="indent">In this example, “million” is the main word in the phrase “$4.26 million.” The head of “million” is “of,” which is a child of “revenue,” which, in turn, is a child of “earned,” the main verb of the sentence.</p>&#13;
<h3 class="h3" id="lev85"><strong>Using Context to Improve the Ticket-Booking Chatbot</strong></h3>&#13;
<p class="noindent">As you’ve no doubt realized by now, there’s no single solution for all intelligent text-processing tasks. For example, the ticket-booking script shown earlier in this chapter will only find a destination if the submitted sentence contains the word “to.”</p>&#13;
<p class="indent">One way to make these scripts more useful is to take context into account to determine an appropriate response. Let’s increase the functionality of the ticket-booking script so it can handle a wider set of user input, including utterances that don’t contain a “to + <code>GPE</code>” pair in any combination. For example, look at the following utterance:</p>&#13;
<pre>I am attending the conference in Berlin.</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_92"/>Here, the user has expressed an intention to go to Berlin without “to.” Only the <code>GPE</code> entity “Berlin” is in the sentence. In such cases, it would be reasonable for a chatbot to ask a confirmatory question, such as the following:</p>&#13;
<pre>You want a ticket to Berlin, right?</pre>&#13;
<p class="indent">The improved ticket-booking chatbot should produce different outputs based on three different situations:</p>&#13;
<ul>&#13;
<li class="noindent">The user expresses a clear intention to book a ticket to a certain destination.</li>&#13;
<li class="noindent">It’s not immediately clear whether the user wants a ticket to the destination mentioned.</li>&#13;
<li class="noindent">The user doesn’t mention any destination.</li>&#13;
</ul>&#13;
<p class="indent">Depending on which category the user input falls under, the chatbot generates an appropriate response. <a href="../Text/ch06.xhtml#ch06fig05">Figure 6-5</a> illustrates how to represent this user input handling on a diagram.</p>&#13;
<div class="image"><a id="ch06fig05"/><img src="../Images/fig6-5.jpg" alt="image" width="451" height="337"/></div>&#13;
<p class="figcap"><em>Figure 6-5: An example of user input handling in a ticket-booking application</em></p>&#13;
<p class="indent">The following script implements this design. For convenience, the code is divided into several parts.</p>&#13;
<p class="indent">The first snippet contains the <code>guess_destination</code> function, which searches a sentence for a <code>GPE</code> entity. Also, we’ll need to insert the <code>dep_destination</code> function defined and discussed in “<a href="../Text/ch06.xhtml#lev82">Iterating Over the Heads of Tokens</a>” on <a href="../Text/ch06.xhtml#page_87">page 87</a>. Recall that this function searches a sentence for the “to + <code>GPE</code>” pattern. We’ll need the <code>dep_destination</code> and <code>guess_destination</code> functions to handle the first and second scenarios of user input, respectively.</p>&#13;
<span epub:type="pagebreak" id="page_93"/><pre>import spacy<br/>&#13;
nlp = spacy.load('en')<br/>&#13;
#Insert the dep_destination function from a previous listing here<br/>&#13;
#...<br/>&#13;
def guess_destination(doc):<br/>&#13;
  for token in doc:<br/>&#13;
 <span class="ent">➊</span> if token.ent_type != 0 and token.ent_type_ == 'GPE': <br/>&#13;
    <span class="ent">➋</span> return token.text<br/>&#13;
<span class="ent">➌</span> return 'Failed to determine'</pre>&#13;
<p class="indent">The code in the <code>guess_destination</code> function iterates over the tokens in a sentence, looking for a <code>GPE</code> entity <span class="ent">➊</span>. Once it finds one, the function returns it to the calling code <span class="ent">➋</span>. If it fails to find one, the function returns <code>'Failed to determine'</code> <span class="ent">➌</span>, meaning the sentence doesn’t contain a <code>GPE</code> entity.</p>&#13;
<p class="indent">In the <code>gen_function</code> that follows, we generate a response based on what the functions defined in the preceding snippet return.</p>&#13;
<pre> def gen_response(doc):<br/>&#13;
<span class="ent">➊</span> dest = det_destination(doc)<br/>&#13;
   if dest != 'Failed to determine':<br/>&#13;
  <span class="ent">➋</span> return 'When do you need to be in ' + dest + '?'<br/>&#13;
<span class="ent">➌</span> dest = guess_destination(doc)<br/>&#13;
   if dest != 'Failed to determine':<br/>&#13;
   <span class="ent">➍</span> return 'You want a ticket to ' + dest +', right?'<br/>&#13;
 <span class="ent">➎</span> return 'Are you flying somewhere?'</pre>&#13;
<p class="indent">The code in the <code>gen_response</code> function starts by invoking the <code>det_destination</code> function <span class="ent">➊</span>, which determines whether an utterance contains a “to + <code>GPE</code>” pair. If one is found, we assume that the user wants a ticket to the destination and they need to clarify their departure time <span class="ent">➋</span>.</p>&#13;
<p class="indent">If the <code>det_destination</code> function hasn’t found a “to + <code>GPE</code>” pair in the utterance, we invoke the <code>guess_destination</code> function <span class="ent">➌</span>. This function tries to find a <code>GPE</code> entity. If it finds such an entity, it asks the user a confirmatory question about whether they want to fly to that destination <span class="ent">➍</span>. Otherwise, if it finds no <code>GPE</code> entity in the utterance, the script asks the user whether they want to fly somewhere <span class="ent">➎</span>.</p>&#13;
<p class="indent">To test the code, we apply the pipeline to a sentence and then send the doc to the <code>gen_response</code> function we used in the previous listing:</p>&#13;
<pre>doc = nlp(u'I am going to the conference in Berlin.') <br/>&#13;
print(gen_response(doc))</pre>&#13;
<p class="indent">For the utterance submitted in this example, you should see the following output:</p>&#13;
<pre>When do you need to be in Berlin?</pre>&#13;
<p class="indent">You can experiment with the sample utterance to see different output.</p>&#13;
<h3 class="h3" id="lev86"><span epub:type="pagebreak" id="page_94"/><strong>Making a Smarter Chatbot by Finding Proper Modifiers</strong></h3>&#13;
<p class="noindent">One way to make your chatbot smarter is to use dependency trees to find modifiers for particular words. For example, you might teach your application to recognize the adjectives that are applicable to a given noun. Then you could tell the bot, “I’d like to read a book,” to which the smart bot could respond like this: “Would you like a fiction book?”</p>&#13;
<p class="indent">A <em>modifier</em> is an optional element in a phrase or a clause used to change the meaning of another element. Removing a modifier doesn’t typically change the basic meaning of the sentence, but it does make it less specific. As a quick example, consider the following two sentences:</p>&#13;
<pre>I want to read a book.<br/>&#13;
I want to read a book on Python.</pre>&#13;
<p class="indent">The first sentence doesn’t use modifiers. The second uses the modifier “on Python,” making your request more detailed.</p>&#13;
<p class="indent">If you want to be specific, you must use modifiers. For example, to generate a proper response to a user, you might need to learn which modifiers you can use in conjunction with a given noun or verb.</p>&#13;
<p class="indent">Consider the following phrase:</p>&#13;
<pre>That exotic fruit from Africa.</pre>&#13;
<p class="indent">In this noun phrase, “fruit” is the head, “that” and “exotic” are <em>premodifiers</em>—modifiers located in front of the word being modified—and “from Africa” is a <em>postmodifier</em> phrase—a modifier that follows the word it limits or qualifies. <a href="../Text/ch06.xhtml#ch06fig06">Figure 6-6</a> shows the dependency tree for this phrase.</p>&#13;
<div class="image"><a id="ch06fig06"/><img src="../Images/fig6-6.jpg" alt="image" width="490" height="240"/></div>&#13;
<p class="figcap"><em>Figure 6-6: An example of premodifiers and postmodifiers</em></p>&#13;
<p class="indent">Suppose you want to determine possible adjectival modifiers for the word “fruit.” (Adjectival modifiers are always premodifiers.) Also, you want to look at what <code>GPE</code> entities you can find in the postmodifiers of this same word. This information could later help you generate an utterance during a conversation on fruits.</p>&#13;
<p class="noindent"><span epub:type="pagebreak" id="page_95"/>The following script implements this design:</p>&#13;
<pre>   import spacy<br/>&#13;
   nlp = spacy.load('en')<br/>&#13;
<span class="ent">➊</span> doc = nlp(u"Kiwano has jelly-like flesh with a refreshingly fruity taste. This <br/>&#13;
   is a nice exotic fruit from Africa. It is definitely worth trying.")<br/>&#13;
<span class="ent">➋</span> fruit_adjectives = []<br/>&#13;
<span class="ent">➌</span> fruit_origins = []<br/>&#13;
   for token in doc:<br/>&#13;
  <span class="ent">➍</span> if token.text == 'fruit': <br/>&#13;
    <span class="ent">➎</span> fruit_adjectives = fruit_adjectives + [modifier.text for modifier in<br/>&#13;
       token.lefts if modifier.pos_ == 'ADJ']<br/>&#13;
    <span class="ent">➏</span> fruit_origins = fruit_origins + [doc[modifier.i + 1].text for modifier <br/>&#13;
       in token.rights if modifier.text == 'from' and doc[modifier.i + 1].ent_<br/>&#13;
       type != 0]<br/>&#13;
   print('The list of adjectival modifiers for word fruit:', fruit_adjectives)<br/>&#13;
   print('The list of GPE names applicable to word fruit as postmodifiers:', <br/>&#13;
   fruit_origins)</pre>&#13;
<p class="indent">We start by applying the pipeline to a short text that contains the word “fruit” with both premodifiers and postmodifiers <span class="ent">➊</span>. We define two empty lists: <code>fruit_adjectives</code> <span class="ent">➋</span> and <code>fruit_origins</code> <span class="ent">➌</span>. The first one will hold any adjectival modifiers found for the word “fruit.” The second list will hold any <code>GPE</code> entities found among the postmodifiers of “fruit.”</p>&#13;
<p class="indent">Next, in a loop iterating over the tokens of the entire text, we look for the word “fruit” <span class="ent">➍</span>. Once this word is found, we first determine its adjectival premodifiers by picking up its syntactic children to the left and choosing only adjectives (determiners and compounds can also be premodifiers). We append the adjectival modifiers to the <code>fruit_adjectives</code> list <span class="ent">➎</span>.</p>&#13;
<p class="indent">Then we search for postmodifiers by checking the right-hand syntactic children of the word “fruit.” In particular, we look for named entities, and then append them to the <code>fruit_origins</code> list <span class="ent">➏</span>.</p>&#13;
<p class="indent">The script outputs the following two lists:</p>&#13;
<pre>The list of adjectival modifiers for word fruit: ['nice', 'exotic']<br/>&#13;
The list of GPE names applicable to word fruit as postmodifiers: ['Africa']</pre>&#13;
<p class="indent">Now your bot “knows” that a fruit can be nice, exotic (or both nice and exotic), and might come from Africa.</p>&#13;
<h3 class="h3" id="lev87"><strong>Summary</strong></h3>&#13;
<p class="noindent">When you need to process an utterance, or even just a phrase, it’s often important to look at its structure to determine which general patterns it matches. Using spaCy’s linguistic features, you can detect these patterns, allowing your script to understand the user’s intention and respond properly.</p>&#13;
<p class="indent">Using patterns based on linguistic features works well when you need to recognize the general structure of a sentence, which involves the subject, modal auxiliary verb, main verb, and direct object. But a real-world application needs to recognize more complicated sentence structures <span epub:type="pagebreak" id="page_96"/>and be prepared for a wider set of user input. This is where the syntactic dependency tree of a sentence becomes very useful. You can walk the dependency tree of a sentence in different ways, extracting necessary pieces of information from it. For example, you can use dependency trees to find modifiers for particular words, and then use this information later to generate intelligent text.</p>&#13;
</div>&#13;
</body></html>
- en: '9'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '9'
- en: IDENTIFYING FRIEND OR FOE
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 识别朋友或敌人
- en: '![Image](../images/common.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/common.jpg)'
- en: Face detection is a machine learning technology that locates human faces in
    digital images. It’s the first step in the process of face *recognition*, a technique
    for identifying individual faces using code. Face detection and recognition methods
    have broad applications, such as tagging photographs on social media, autofocusing
    digital cameras, unlocking cell phones, finding missing children, tracking terrorists,
    facilitating secure payments, and more.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 人脸检测是一种机器学习技术，用于在数字图像中定位人脸。这是面部*识别*过程的第一步，面部识别是通过代码识别特定个体人脸的技术。人脸检测和识别方法有广泛的应用，例如社交媒体上的照片标记、数字相机的自动对焦、手机解锁、寻找失踪儿童、追踪恐怖分子、促进安全支付等。
- en: In this chapter, you’ll use machine learning algorithms in OpenCV to program
    a robot sentry gun. Because you’ll be distinguishing between humans and otherworldly
    mutants, you’ll only need to detect the *presence* of human faces rather than
    identify specific individuals. In [Chapter 10](ch10.xhtml), you’ll take the next
    step and identify people by their faces.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将使用OpenCV中的机器学习算法编程一个机器人岗哨枪。因为你需要区分人类和外星突变体，所以你只需要检测人脸的*存在*，而不是识别特定的个体。在[第10章](ch10.xhtml)中，你将迈出下一步，通过人脸来识别具体的人。
- en: '**Detecting Faces in Photographs**'
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**检测照片中的人脸**'
- en: Face detection is possible because human faces share similar patterns. Some
    common facial patterns are the eyes being darker than the cheeks and the bridge
    of the nose being brighter than the eyes, as seen in the left image of [Figure
    9-1](ch09.xhtml#ch09fig1).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 人脸检测之所以可行，是因为人脸具有相似的模式。一些常见的面部模式包括眼睛比脸颊暗，鼻梁比眼睛亮，正如在[图9-1](ch09.xhtml#ch09fig1)的左侧图像中所看到的。
- en: '![Image](../images/fig09_01.jpg)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/fig09_01.jpg)'
- en: 'Figure 9-1: Example of some consistently bright and dark regions in a face'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图9-1：面部中一些一致的明亮和暗淡区域的示例
- en: You can extract these patterns using templates like those in [Figure 9-2](ch09.xhtml#ch09fig2).
    These yield *Haar features*, a fancy name for the attributes of digital images
    used in object recognition. To calculate a Haar feature, place one of the templates
    on a grayscale image, add up the grayscale pixels that overlap with the white
    part, and subtract them from the sum of the pixels that overlap the black part.
    Thus, each feature consists of a single intensity value. We can use a range of
    template sizes to sample all possible locations on the image, making the system
    scale invariant.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用像[图9-2](ch09.xhtml#ch09fig2)中的模板来提取这些模式。它们产生了*Haar特征*，这是用于物体识别的数字图像属性的
    fancy 名称。要计算Haar特征，将其中一个模板放置在灰度图像上，将与白色部分重叠的灰度像素相加，然后从与黑色部分重叠的像素之和中减去它们。因此，每个特征由一个单一的强度值组成。我们可以使用不同大小的模板来采样图像上的所有可能位置，使得系统具有尺度不变性。
- en: '![Image](../images/fig09_02.jpg)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/fig09_02.jpg)'
- en: 'Figure 9-2: Some example Haar feature templates'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 图9-2：一些示例Haar特征模板
- en: In the middle image in [Figure 9-1](ch09.xhtml#ch09fig1), an “edge feature”
    template extracts the relationship between the dark eyes and the bright cheeks.
    In the far-right image in [Figure 9-1](ch09.xhtml#ch09fig1), a “line feature”
    template extracts the relationship between the dark eyes and the bright nose.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图9-1](ch09.xhtml#ch09fig1)中的中间图像中，一个“边缘特征”模板提取了黑暗眼睛和明亮脸颊之间的关系。在[图9-1](ch09.xhtml#ch09fig1)中的最右侧图像中，一个“线条特征”模板提取了黑暗眼睛和明亮鼻子之间的关系。
- en: By calculating Haar features on thousands of *known* face and nonface images,
    we can determine which combination of Haar features is most effective at identifying
    faces. This training process is slow, but it facilitates fast detection later.
    The resulting algorithm, known as a *face classifier*, takes the values of features
    in an image and predicts whether it contains a human face by outputting 1 or 0\.
    OpenCV ships with a pretrained face detection classifier based on this technique.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 通过计算成千上万张*已知*的人脸和非人脸图像的Haar特征，我们可以确定哪种Haar特征组合在识别面部时最有效。这个训练过程比较慢，但它为后续的快速检测提供了便利。最终的算法被称为*人脸分类器*，它通过输出1或0来预测图像是否包含人脸。OpenCV提供了基于这一技术的预训练人脸检测分类器。
- en: To apply the classifier, the algorithm uses a *sliding window* approach. A small
    rectangular area is incrementally moved across the image and evaluated using a
    *cascade classifier* consisting of multiple stages of filters. The filters at
    each stage are combinations of Haar features. If the window region fails to pass
    the threshold of a stage, it’s rejected, and the window slides to the next position.
    Quickly rejecting nonface regions, like the one shown in the right inset in [Figure
    9-3](ch09.xhtml#ch09fig3), helps speed up the overall process.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应用分类器，算法使用*滑动窗口*方法。一个小的矩形区域会逐步在图像上移动，并通过一个包含多级过滤器的*级联分类器*进行评估。每个阶段的过滤器是Haar特征的组合。如果窗口区域未通过某一阶段的阈值，它将被拒绝，窗口滑动到下一个位置。快速拒绝非人脸区域，例如[图9-3](ch09.xhtml#ch09fig3)右侧插图中的区域，有助于加速整个过程。
- en: '![Image](../images/fig09_03.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/fig09_03.jpg)'
- en: 'Figure 9-3: Images are searched for faces using a rectangular sliding window.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图9-3：使用矩形滑动窗口搜索人脸。
- en: If a region passes the threshold for a stage, the algorithm processes another
    set of Haar features and compares them to the threshold, and so on, until it either
    rejects or positively identifies a face. This causes the sliding window to speed
    up or slow down as it moves across an image. You can find a fantastic video example
    of this at *[https://vimeo.com/12774628/](https://vimeo.com/12774628/)*.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个区域通过了某个阶段的阈值，算法会处理另一组Haar特征并与阈值进行比较，依此类推，直到它要么拒绝，要么确定一个面部。这会导致滑动窗口在图像上移动时加速或减速。你可以在*[https://vimeo.com/12774628/](https://vimeo.com/12774628/)*上找到一个精彩的视频示例。
- en: For each face detected, the algorithm returns the coordinates of a rectangle
    around the face. You can use these rectangles as the basis for further analysis,
    such as identifying eyes.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个检测到的人脸，算法返回一个围绕人脸的矩形坐标。你可以使用这些矩形作为进一步分析的基础，例如识别眼睛。
- en: '**Project #13: Programming a Robot Sentry Gun**'
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**项目#13：编程机器人守卫炮**'
- en: Imagine that you’re a technician with the Coalition Marines, a branch of the
    Space Force. Your squad has been deployed to a secret research base operated by
    the Wykham-Yutasaki Corporation on planet LV-666\. While studying a mysterious
    alien apparatus, the researchers have inadvertently opened a portal to a hellish
    alternate dimension. Anyone who gets near the portal, including dozens of civilians
    and several of your comrades, mutates into a murderous mindless monstrosity! You’ve
    even caught security footage of the result ([Figure 9-4](ch09.xhtml#ch09fig4)).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你是联盟海军的技术员，隶属于太空部队的一支分队。你的小队被派遣到由威克汉-尤塔萨基公司在LV-666星球上运营的一个秘密研究基地。在研究一个神秘的外星设备时，研究人员不小心打开了通往地狱般异次元的门户。任何靠近门户的人，包括数十名平民和你的几位战友，都会变异成嗜血的无脑怪物！你甚至捕捉到了监控视频（见[图9-4](ch09.xhtml#ch09fig4)）。
- en: '![Image](../images/fig09_04.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/fig09_04.jpg)'
- en: 'Figure 9-4: Security camera footage of a mutated scientist (left) and marine
    (right)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图9-4：变异科学家的监控视频（左）和海军（右）
- en: According to the remaining scientists, the mutation affects more than just organic
    matter. Any gear the victim is wearing, such as helmets and goggles, is also transmogrified
    and fused into the flesh. Eye tissue is especially vulnerable. All the mutants
    formed so far are eyeless and blind, though this doesn’t seem to affect their
    mobility. They’re still ferocious, deadly, and unstoppable without military-grade
    weapons.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 根据剩余科学家的说法，变异不仅仅影响有机物质。受害者佩戴的任何装备，例如头盔和护目镜，也会被转化并与肉体融合。眼组织特别脆弱。迄今为止形成的所有变异体都是没有眼睛的盲者，尽管这似乎并不影响它们的行动能力。它们依然凶猛、致命且不可阻挡，除非有军用级武器。
- en: That’s where you come in. It’s your job to set up an automatic firing station
    to guard Corridor 5, a key access point in the compromised facility. Without it,
    your small squad is in danger of being outflanked and overrun by hordes of rampaging
    mutants.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是你的任务。你的工作是设置一个自动开火站点，以守卫被攻陷设施中的关键通道5。如果没有它，你的小队就有可能被变异怪物大军包围并压倒。
- en: The firing station consists of a UAC 549-B automated sentry gun, called a *robot
    sentry* by the grunts ([Figure 9-5](ch09.xhtml#ch09fig5)). It’s equipped with
    four M30 autocannons with 1,000 rounds of ammo and multiple sensors, including
    a motion detector, laser ranging unit, and optical camera. The gun also interrogates
    targets using an identification friend or foe (IFF) transponder. All Coalition
    Marines carry these transponders, allowing them to safely pass active sentry guns.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 火控站由一台UAC 549-B自动哨兵枪组成，步兵们称其为*机器人哨兵*（[图9-5](ch09.xhtml#ch09fig5)）。它配备了四门M30自动炮，拥有1,000发弹药以及多个传感器，包括运动探测器、激光测距单元和光学相机。该枪还通过敌友识别（IFF）应答器对目标进行识别。所有联军海军陆战队员都携带这些应答器，从而使他们能够安全地通过激活的哨兵枪。
- en: '![Image](../images/fig09_05.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/fig09_05.jpg)'
- en: 'Figure 9-5: A UAC 549-B automated sentry gun'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图9-5：UAC 549-B自动哨兵枪
- en: Unfortunately, the squad’s sentry gun was damaged during landing, so the transponders
    no longer function. Worse, the requisitions corporal forgot to download the software
    that visually interrogates targets. With the transponder sensor down, there’s
    no way to positively identify marines and civilians. You’ll need to get this fixed
    as quickly as possible, because your buddies are badly outnumbered and the mutants
    are on the move!
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，小队的哨兵枪在着陆时受损，因此应答器不再起作用。更糟糕的是，物资上士忘记下载用于视觉识别目标的软件。由于应答器传感器失效，现在无法正面识别海军陆战队员和平民。你需要尽快修复这个问题，因为你的战友人数严重不足，而变异体已经开始行动！
- en: Fortunately, planet LV-666 has no indigenous life forms, so you need to distinguish
    between humans and mutants only. Since the mutants are basically faceless, a face
    detection algorithm is the logical solution.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，LV-666星球没有本土生命形式，因此你只需要区分人类和变异体。由于变异体基本上没有面孔，人脸检测算法是最合适的解决方案。
- en: THE OBJECTIVE
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 目标
- en: Write a Python program that disables the sentry gun’s firing mechanism when
    it detects human faces in an image.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 编写一个Python程序，当哨兵枪检测到人脸时，禁用其开火机制。
- en: '***The Strategy***'
  id: totrans-32
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***策略***'
- en: In situations like this, it’s best to keep things simple and leverage existing
    resources. This means relying on OpenCV’s face detection functionality rather
    than writing customized code to recognize the humans on the base. But you can’t
    be sure how well these canned procedures will work, so you’ll need to guide your
    human targets to make the job as easy as possible.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，最好保持简单，并利用现有的资源。这意味着依赖OpenCV的人脸检测功能，而不是编写自定义代码来识别基地上的人类。但是你无法确定这些现成的程序是否能很好地工作，因此你需要引导你的目标人类，使任务尽可能简便。
- en: The sentry gun’s motion detector will handle the job of triggering the optical
    identification process. To permit humans to pass unharmed, you’ll need to warn
    them to stop and face the camera. They’ll need a few seconds to do this and a
    few seconds to proceed past the gun after they’re cleared.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 哨兵枪的运动探测器将负责触发光学识别过程。为了允许人类安全通过，你需要提醒他们停下并面对相机。他们需要几秒钟的时间来完成这一动作，之后在被确认清除后，他们才能继续通过哨兵枪。
- en: You’ll also want to run some tests to ensure OpenCV’s training set is adequate
    and you’re not generating any false positives that would let a mutant sneak by.
    You don’t want to kill anyone with friendly fire, but you can’t be too cautious,
    either. If one mutant gets by, everyone could perish.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 你还需要运行一些测试，确保OpenCV的训练集足够，并且没有生成任何假阳性，以免让变异体悄悄溜过。你不想因为误伤友军而杀死任何人，但你也不能过于谨慎。如果一个变异体溜过，所有人都可能丧命。
- en: '**NOTE**'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*In real life, the sentry guns would use a video feed. Since I don’t have my
    own film studio with special effects and makeup departments, you’ll work off still
    photos instead. You can think of these as individual video frames. Later in the
    chapter, you’ll get a chance to detect your own face using your computer’s video
    camera.*'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '*在现实生活中，哨兵枪将使用视频馈送。由于我没有自己的电影制作工作室以及特效和化妆部门，你将使用静态照片代替。你可以把这些照片当作独立的视频帧来看。稍后的章节中，你将有机会使用电脑的摄像头来检测自己的面孔。*'
- en: '***The Code***'
  id: totrans-38
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***代码***'
- en: The *sentry.py* code will loop through a folder of images, identify human faces
    in the images, and show the image with the faces outlined. It will then either
    fire or disable the gun depending on the result. You’ll use the images in the
    *corridor_5* folder in the *Chapter_9* folder, downloadable from *[https://nostarch.com/real-world-python/](https://nostarch.com/real-world-python/)*.
    As always, don’t move or rename any files after downloading and launch *sentry.py*
    from the folder in which it’s stored.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '*sentry.py* 代码将循环遍历一个图像文件夹，识别图像中的人脸，并显示带有勾画出人脸的图像。然后，根据结果，它会触发或禁用枪支。你将使用 *Chapter_9*
    文件夹中的 *corridor_5* 文件夹中的图像，该文件夹可以从 *[https://nostarch.com/real-world-python/](https://nostarch.com/real-world-python/)*
    下载。像往常一样，在下载后不要移动或重命名任何文件，并从存储该文件的文件夹中启动 *sentry.py*。'
- en: You’ll also need to install two modules, playsound and pyttsx3. The first is
    a cross-platform module for playing WAV and MP3 format audio files. You’ll use
    it to produce sound effects, such as machine gun fire and an “all clear” tone.
    The second is a cross-platform wrapper that supports the native text-to-speech
    libraries on Windows and Linux-based systems, including macOS. The sentry gun
    will use this to issue audio warnings and instructions. Unlike other text-to-speech
    libraries, pyttsx3 reads text directly from the program, rather than first saving
    it to an audio file. It also works offline, making it reliable for voice-based
    projects.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 你还需要安装两个模块，playsound 和 pyttsx3。第一个是一个跨平台模块，用于播放 WAV 和 MP3 格式的音频文件。你将使用它来产生声音效果，例如机枪射击声和“全部清除”音调。第二个是一个跨平台封装器，支持
    Windows 和基于 Linux 的系统（包括 macOS）上的本地文本转语音库。哨兵枪将使用它来发出音频警告和指令。与其他文本转语音库不同，pyttsx3
    直接从程序读取文本，而不是先将其保存到音频文件中。它也可以离线工作，使其成为语音项目的可靠选择。
- en: You can install both modules with pip in a PowerShell or Terminal window.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 PowerShell 或终端窗口中使用 pip 安装这两个模块。
- en: '[PRE0]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: If you encounter an error installing pyttsx3 on Windows, such as No module named
    win32.com.client, No module named win32, or No module named win32api, then install
    pypiwin32.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在 Windows 上安装 pyttsx3 时遇到错误，比如 No module named win32.com.client、No module
    named win32 或 No module named win32api，那么请安装 pypiwin32。
- en: '[PRE1]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: You may need to restart the Python shell and editor following this installation.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 安装后，你可能需要重新启动 Python shell 和编辑器。
- en: For more on playsound, see *[https://pypi.org/project/playsound/](https://pypi.org/project/playsound/)*.
    The documentation for pyttsx3 can be found at *[https://pyttsx3.readthedocs.io/en/latest/](https://pyttsx3.readthedocs.io/en/latest/)*
    and *[https://pypi.org/project/pyttsx3/](https://pypi.org/project/pyttsx3/)*.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 有关 playsound 的更多信息，请参阅 *[https://pypi.org/project/playsound/](https://pypi.org/project/playsound/)*。pyttsx3
    的文档可以在 *[https://pyttsx3.readthedocs.io/en/latest/](https://pyttsx3.readthedocs.io/en/latest/)*
    和 *[https://pypi.org/project/pyttsx3/](https://pypi.org/project/pyttsx3/)* 找到。
- en: If you don’t already have OpenCV installed, see “Installing the Python Libraries”
    on [page 6](ch01.xhtml#page_6).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你尚未安装 OpenCV，请参阅 [第 6 页](ch01.xhtml#page_6)中的“安装 Python 库”部分。
- en: '**Importing Modules, Setting Up Audio, and Referencing the Classifier Files
    and Corridor Images**'
  id: totrans-48
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**导入模块、设置音频并引用分类器文件和走廊图像**'
- en: '[Listing 9-1](ch09.xhtml#ch09list1) imports modules, initializes and sets up
    the audio engine, assigns the classifier files to variables, and changes the directory
    to the folder containing the corridor images.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '[清单 9-1](ch09.xhtml#ch09list1) 导入模块，初始化并设置音频引擎，将分类器文件分配给变量，并将目录更改为包含走廊图像的文件夹。'
- en: '[PRE2]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Listing 9-1: Importing modules, setting up the audio, and locating the classifier
    files and corridor images'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 清单 9-1：导入模块、设置音频，并定位分类器文件和走廊图像
- en: Except for datetime, playsound, and pytts3, the imports should be familiar to
    you if you’ve worked through the earlier chapters ➊. You’ll use datetime to record
    the exact time at which an intruder is detected in the corridor.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 datetime、playsound 和 pyttsx3 模块，如果你已经完成前面的章节 ➊，你应该对这些导入的模块很熟悉。你将使用 datetime
    来记录在走廊中检测到入侵者的准确时间。
- en: To use pytts3, initialize a pyttsx3 object and assign it to a variable named,
    by convention, engine ➋. According to the pyttsx3 docs, an application uses the
    engine object to register and unregister event callbacks, produce and stop speech,
    get and set speech engine properties, and start and stop event loops.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 pytts3，请初始化一个 pyttsx3 对象并将其分配给一个变量，通常命名为 engine ➋。根据 pyttsx3 文档，应用程序使用 engine
    对象来注册和注销事件回调，生成和停止语音，获取和设置语音引擎属性，以及启动和停止事件循环。
- en: In the next two lines, set the rate of speech and volume properties. The rate
    of speech value used here was obtained through trial and error. It should be fast
    but still clearly understandable. The volume should be set to the maximum value
    (1.0) so any humans stumbling into the corridor can easily hear the warning instructions.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的两行中，设置语音速率和音量属性。这里使用的语音速率值是通过反复试验得到的，应该快速但仍然清晰易懂。音量应设置为最大值（1.0），这样任何走进走廊的人都能清楚听到警告指令。
- en: 'The default voice on Windows is male, but other voices are available. For example,
    on a Windows 10 machine, you can switch to a female voice using the following
    voice ID:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Windows 系统上的默认语音为男性，但也可以选择其他语音。例如，在 Windows 10 机器上，您可以使用以下语音 ID 切换到女性语音：
- en: '[PRE3]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: To see a list of voices available on your platform, refer to “Changing voices”
    at *[https://pyttsx3.readthedocs.io/en/latest/](https://pyttsx3.readthedocs.io/en/latest/)*.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看平台上可用的语音列表，请参考*“更改语音”*，[https://pyttsx3.readthedocs.io/en/latest/](https://pyttsx3.readthedocs.io/en/latest/)。
- en: Next, set up the audio recording of gunfire, which you’ll play when a mutant
    is detected in the corridor. Specify the location of the audio file by generating
    a directory path string that will work on all platforms, which you do by combining
    the absolute path with the filename using the os.path.join() method. Use the same
    path for the *tone.wav* file, which you’ll use as an “all clear” signal when the
    program identifies a human.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，设置枪声的音频录制，当在走廊中检测到变异体时播放。通过生成一个适用于所有平台的目录路径字符串来指定音频文件的位置，方法是使用 os.path.join()
    方法将绝对路径与文件名结合起来。对于*tone.wav* 文件，使用相同的路径，当程序识别到人类时，它将作为“解除警报”信号使用。
- en: The pretrained Haar cascade classifiers should download as *.xml* files when
    you install OpenCV. Assign the path for the folder containing the classifiers
    to a variable ➌. The path shown is for my Windows machine; your path may be different.
    On macOS, for example, you may find them under *opencv/data/haarcascades*. You
    can also find them online at *[https://github.com/opencv/opencv/tree/master/data/haarcascades/](https://github.com/opencv/opencv/tree/master/data/haarcascades/)*.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在安装 OpenCV 时，预训练的 Haar cascade 分类器应该作为 *.xml* 文件下载。将包含分类器的文件夹路径分配给变量 ➌。显示的路径是我
    Windows 机器上的路径；您的路径可能会不同。例如，在 macOS 上，您可能会在 *opencv/data/haarcascades* 中找到它们。您还可以在网上找到它们，网址是*[https://github.com/opencv/opencv/tree/master/data/haarcascades/](https://github.com/opencv/opencv/tree/master/data/haarcascades/)。
- en: 'Another option for finding the path to the cascade classifiers is to use the
    preinstalled sysconfig module, as in the following snippet:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 查找 cascade 分类器路径的另一种方法是使用预安装的 sysconfig 模块，如下片段所示：
- en: '[PRE4]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This should work for Windows inside and outside of virtual environments. However,
    this will work on Ubuntu only within a virtual environment.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这在 Windows 系统中无论是在虚拟环境内外都应该有效。但在 Ubuntu 上，这仅在虚拟环境内有效。
- en: To load a classifier, use OpenCV’s CascadeClassifier() method. Use string concatenation
    to add the path variable to the filename string for the classifier and assign
    the result to a variable.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 要加载分类器，请使用 OpenCV 的 CascadeClassifier() 方法。使用字符串拼接将路径变量添加到分类器的文件名字符串中，并将结果分配给一个变量。
- en: Note that I use only two classifiers, one for frontal faces and one for eyes,
    to keep things simple. Additional classifiers are available for profiles, smiles,
    eyeglasses, upper bodies, and so on.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我只使用了两个分类器，一个用于正面人脸，一个用于眼睛，以保持简单。还可以使用其他分类器来检测侧面、微笑、眼镜、上半身等。
- en: Finish by pointing the program to the images taken in the corridor you are guarding.
    Change the directory to the proper folder ➍; then list the folder contents and
    assign the results to a contents variable. Because you’re not providing a full
    path to the folder, you’ll need to launch your program from the folder containing
    it, which should be one level above the folder with the images.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，指向您正在守卫的走廊中拍摄的图像。将目录更改为正确的文件夹 ➍；然后列出文件夹内容并将结果分配给一个内容变量。因为您没有提供文件夹的完整路径，所以需要从包含文件夹的文件夹中启动程序，该文件夹应该位于图像文件夹的上一层。
- en: '**Issuing a Warning, Loading Images, and Detecting Faces**'
  id: totrans-66
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**发出警告、加载图像并检测人脸**'
- en: '[Listing 9-2](ch09.xhtml#ch09list2) starts a for loop to iterate through the
    folder containing the corridor images. In real life, the motion detectors on the
    sentry guns would launch your program as soon as something entered the corridor.
    Since we don’t have any motion detectors, we’ll assume that each loop represents
    the arrival of a new intruder.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[清单9-2](ch09.xhtml#ch09list2)开始一个for循环，遍历包含走廊图像的文件夹。在现实生活中，守卫枪的运动探测器会在有人进入走廊时启动你的程序。由于我们没有运动探测器，我们假设每个循环代表一个新的入侵者的到来。'
- en: The loop immediately arms the gun and prepares it to fire. It then verbally
    requests that the intruder stop and face the camera. This would occur at a set
    distance from the gun, as determined by the motion detector. As a result, you
    know the faces will all be roughly the same size, making it easy to test the program.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 循环立即激活枪支并准备开火。然后，它口头要求入侵者停止并正对摄像头。这会在离枪支一定距离处发生，由运动传感器决定。因此，你知道这些面孔的大小大致相同，这使得测试程序变得容易。
- en: The intruder is given a few seconds to comply with the command. After that,
    the cascade classifier is called and used to search for faces.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 给入侵者几秒钟时间遵守命令。之后，调用级联分类器并用它来搜索面部。
- en: '[PRE5]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Listing 9-2: Looping through images, issuing a verbal warning, and searching
    for faces'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 清单9-2：遍历图像、发出口头警告并搜索面部
- en: Start looping through the images in the folder. Each new image represents a
    new intruder in the corridor. Print a log of the event and the time at which it
    occurred ➊. Note the f before the start of the string. This is the new *f-string*
    format introduced with Python 3.6 (*[https://www.python.org/dev/peps/pep-0498/](https://www.python.org/dev/peps/pep-0498/)*).
    An f-string is a literal string that contains expressions, such as variables,
    strings, mathematical operations, and even function calls, inside curly braces.
    When the program prints the string, it replaces the expressions with their values.
    These are the fastest and most efficient string formats in Python, and we certainly
    want this program to be fast!
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 开始遍历文件夹中的图像。每张新图像代表走廊中的一个新入侵者。打印事件日志和发生的时间 ➊。注意字符串前面的f。这是Python 3.6引入的*f-string*格式（*
    [https://www.python.org/dev/peps/pep-0498/](https://www.python.org/dev/peps/pep-0498/)*）。f-string是一个字面量字符串，它包含表达式，例如变量、字符串、数学运算，甚至函数调用，位于大括号内。当程序打印该字符串时，它会用表达式的值替换这些表达式。这些是Python中最快、最有效的字符串格式，我们当然希望这个程序运行得很快！
- en: Assume every intruder is a mutant and prepare to discharge the weapon. Then,
    verbally warn the intruder to stop and be scanned.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 假设每个入侵者都是变种人，并准备开火。然后，口头警告入侵者停止并进行扫描。
- en: Use the pyttsx3 engine object’s say() method to speak ➋. It takes a string as
    an argument. Follow this with the runAndWait() method. This halts program execution,
    flushes the say() queue, and plays the audio.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 使用pyttsx3引擎对象的say()方法来发声 ➋。它接受一个字符串作为参数。然后调用runAndWait()方法。它会暂停程序执行，清空say()队列并播放音频。
- en: '**NOTE**'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*For some macOS users, the program may exit with the second call to runAndWait().
    If this occurs, download the sentry_for_Mac_bug.py code from the book’s website.
    This program uses the operating system’s text-to-speech functionality in place
    of pyttsx3. You’ll still need to update the Haar cascade path variable in this
    program, as you did at ➌ in [Listing 9-1](ch09.xhtml#ch09list1).*'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '*对于一些macOS用户，程序可能在第二次调用runAndWait()时退出。如果发生这种情况，请从书籍的网站下载sentry_for_Mac_bug.py代码。该程序使用操作系统的文本到语音功能替代pyttsx3。你仍然需要更新程序中的Haar级联路径变量，正如你在➌处所做的那样，在[清单9-1](ch09.xhtml#ch09list1)中。*'
- en: Next, use the time module to pause the program for three seconds. This gives
    the intruder time to squarely face the gun’s camera.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，使用time模块暂停程序三秒钟。这样，入侵者有时间正对着枪的摄像头。
- en: At this point, you’d make a video capture, except we’re not using video. Instead,
    load the images in the *corridor_5* folder. Call the cv.imread() method with the
    IMREAD_GRAYSCALE flag ➌.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，你将进行视频捕捉，尽管我们不使用视频。相反，加载*coridor_5*文件夹中的图像。使用带有IMREAD_GRAYSCALE标志的cv.imread()方法
    ➌。
- en: Use the image’s shape attribute to get its height and width in pixels. This
    will come in handy later, when you post text on the images.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 使用图像的shape属性获取其高度和宽度（以像素为单位）。这将在稍后你在图像上添加文本时派上用场。
- en: 'Face detection works only on grayscale images, but OpenCV will convert color
    images behind the scenes when applying the Haar cascades. I chose to use grayscale
    from the start as the results look creepier when the images display. If you want
    to see the images in color, just change the two previous lines as follows:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 人脸检测仅适用于灰度图像，但在应用Haar级联时，OpenCV会在后台自动将彩色图像转换为灰度图像。我从一开始就选择使用灰度图像，因为图像显示时效果更恐怖。如果你想查看彩色图像，只需将前两行代码修改如下：
- en: '[PRE6]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Next, show the image prior to face detection, keep it up for two seconds (input
    as milliseconds), and then destroy the window. This is for quality control to
    be sure all the images are being examined. You can comment out these steps later,
    after you’re satisfied everything is working as planned.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，显示人脸检测前的图像，保持显示两秒钟（以毫秒为单位），然后销毁窗口。这是质量控制的一部分，确保所有图像都已被检查。你可以在确认一切按计划正常工作后，将这些步骤注释掉。
- en: 'Create an empty list to hold any faces found in the current image ➍. OpenCV
    treats images as NumPy arrays, so the items in this list are the corner- point
    coordinates (*x*, *y*, width, height) of a rectangle that frames the face, as
    shown in the following output snippet:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个空列表，用于存储当前图像中找到的人脸➍。OpenCV将图像视为NumPy数组，因此列表中的项目是框住人脸的矩形的角点坐标（*x*，*y*，宽度，高度），如以下输出片段所示：
- en: '[PRE7]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Now it’s time to detect faces using the Haar cascades. Do this for the face_cascade
    variable by calling the detectMultiscale() method. Pass the method the image and
    values for the scale factor and minimum number of neighbors. These can be used
    to tune the results in the event of false positives or failure to recognize faces.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候使用Haar级联来检测人脸了。通过调用face_cascade变量的detectMultiscale()方法来执行此操作。将图像以及scaleFactor和minNeighbors的值传递给该方法。这些值可以用于调整结果，以应对误检或未能识别人脸的情况。
- en: For good results, the faces in an image should be the same size as the ones
    used to train the classifier. To ensure they are, the scaleFactor parameter rescales
    the original image to the correct size using a technique called a *scale pyramid*
    ([Figure 9-6](ch09.xhtml#ch09fig6)).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得良好的结果，图像中的人脸应与训练分类器时使用的人脸大小相同。为了确保这一点，scaleFactor参数使用一种叫做*尺度金字塔*的技术，将原始图像缩放到正确的大小（见[图
    9-6](ch09.xhtml#ch09fig6)）。
- en: '![Image](../images/fig09_06.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/fig09_06.jpg)'
- en: 'Figure 9-6: Example “scale pyramid”'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9-6：“尺度金字塔”示例
- en: The scale pyramid resizes the image downward a set number of times. For example,
    a scaleFactor of 1.2 means the image will be scaled down in increments of 20 percent.
    The sliding window will repeat its movement across this smaller image and check
    again for Haar features. This shrinking and sliding will continue until the scaled
    image reaches the size of the images used for training. This is 20×20 pixels for
    the Haar cascade classifier (you can confirm this by opening one of the *.xml*
    files). Windows smaller than this can’t be detected, so the resizing ends at this
    point. Note that the scale pyramid will only *downscale* images, as upscaling
    can introduce artifacts in the resized image.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 尺度金字塔将图像按设定的次数向下缩放。例如，scaleFactor为1.2意味着图像将按20%的增量缩小。滑动窗口将继续在缩小后的图像上滑动，并再次检查Haar特征。这种缩小和滑动将持续进行，直到缩放后的图像达到训练时使用的图像大小。对于Haar级联分类器来说，这个大小是20×20像素（你可以通过打开一个*.xml*文件来确认这一点）。小于这个大小的窗口无法被检测到，因此缩放会在此结束。请注意，尺度金字塔仅会*缩小*图像，因为放大图像可能会引入失真。
- en: With each rescaling, the algorithm calculates lots of new Haar features, resulting
    in lots of false positives. To weed these out, use the minNeighbors parameter.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 每次缩放时，算法会计算大量新的Haar特征，从而产生大量误检。为了筛除这些误检，可以使用minNeighbors参数。
- en: To see how this process works, look at [Figure 9-7](ch09.xhtml#ch09fig7). The
    rectangles in this figure represent faces detected by the haarcascade_frontalface_alt2.xml
    classifier, with the scaleFactor parameter set to 1.05 and minNeighbors set to
    0\. The rectangles have different sizes depending on which scaled image—determined
    by the scaleFactor parameter—was in use when the face was detected. Although there
    are many false positives, the rectangles tend to cluster around the true face.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看这个过程是如何工作的，参见[图 9-7](ch09.xhtml#ch09fig7)。此图中的矩形框代表通过haarcascade_frontalface_alt2.xml分类器检测到的人脸，scaleFactor参数设置为1.05，minNeighbors设置为0。矩形框的大小取决于使用的缩放图像——由scaleFactor参数确定——当人脸被检测到时使用的图像大小。尽管会有很多误检，但矩形框通常会聚集在真实人脸周围。
- en: '![Image](../images/fig09_07.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/fig09_07.jpg)'
- en: 'Figure 9-7: Detected face rectangles with minNeighbors=0'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9-7：检测到的人脸矩形框，minNeighbors=0
- en: Increasing the value of the minNeighbors parameter will increase the quality
    of the detections but reduce their number. If you specify a value of 1, only rectangles
    with one or more closely neighboring rectangles are preserved, and all others
    are discarded ([Figure 9-8](ch09.xhtml#ch09fig8)).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 增加 minNeighbors 参数的值将提高检测的质量，但会减少检测到的数量。如果你指定值为 1，则只有具有一个或多个紧邻矩形的矩形会被保留，其他的都被丢弃
    ([图 9-8](ch09.xhtml#ch09fig8))。
- en: '![Image](../images/fig09_08.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/fig09_08.jpg)'
- en: 'Figure 9-8: Detected face rectangles with minNeighbors=1'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9-8：使用 minNeighbors=1 检测到的面部矩形
- en: Increasing the number of minimum neighbors to around five generally removes
    the false positives ([Figure 9-9](ch09.xhtml#ch09fig9)). This may be good enough
    for most applications, but dealing with terrifying interdimensional monstrosities
    demands more rigor.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 将最小邻居数增加到大约五通常可以消除误报 ([图 9-9](ch09.xhtml#ch09fig9))。这对于大多数应用来说可能足够了，但应对可怕的跨维怪物需要更严谨的处理。
- en: '![Image](../images/fig09_09.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/fig09_09.jpg)'
- en: 'Figure 9-9: Detected face rectangles with minNeighbors=5'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9-9：使用 minNeighbors=5 检测到的面部矩形
- en: To see why, check out [Figure 9-10](ch09.xhtml#ch09fig10). Despite using a minNeighbor
    value of 5, the toe region of the mutant is incorrectly identified as a face.
    With a little imagination, you can see two dark eyes and a bright nose at the
    top of the rectangle, and a dark, straight mouth at the base. This could allow
    the mutant to pass unharmed, earning you a dishonorable discharge at best and
    an excruciatingly painful death at worst.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 为了查看原因，查看 [图 9-10](ch09.xhtml#ch09fig10)。尽管使用了 minNeighbor 值为 5，但变种人的脚趾区域仍被错误地识别为面部。凭借一点想象力，你可以看到矩形顶部有两个黑色的眼睛和一个明亮的鼻子，底部有一个黑色、直线状的嘴巴。这可能让变种人毫发无损地通过，最好的结果是你被开除，最坏的结果则是经历一场极其痛苦的死亡。
- en: '![Image](../images/fig09_10.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/fig09_10.jpg)'
- en: 'Figure 9-10: A mutant’s right toe region incorrectly identified as a face'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9-10：变种人的右脚趾区域被错误地识别为面部
- en: Fortunately, this problem can be easily remedied. The solution is to search
    for more than just faces.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，这个问题可以很容易地解决。解决方案是搜索不仅仅是面部。
- en: '**Detecting Eyes and Disabling the Weapon**'
  id: totrans-104
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**检测眼睛并禁用武器**'
- en: Still in the for loop through the corridor images, [Listing 9-3](ch09.xhtml#ch09list3)
    uses OpenCV’s built-in eye cascade classifier to search for eyes in the list of
    detected face rectangles. Searching for eyes reduces false positives by adding
    a second verification step. And because mutants don’t have eyes, if at least one
    eye is found, you can assume a human is present and disable the sentry gun’s firing
    mechanism to let them pass.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 仍然在遍历走廊图像的 for 循环中，[列表 9-3](ch09.xhtml#ch09list3) 使用 OpenCV 内置的眼睛级联分类器在检测到的面部矩形列表中搜索眼睛。通过增加第二步验证，搜索眼睛可以减少误报。而且因为变种人没有眼睛，如果至少找到一只眼睛，你可以假定是人类存在，并禁用哨兵枪的射击机制，让他们通过。
- en: '[PRE8]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Listing 9-3: Detecting eyes in face rectangles and disabling the weapon'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9-3：在面部矩形中检测眼睛并禁用武器
- en: Print the name of the image being searched and start a loop through the rectangles
    in the face_rect_list. If a rectangle is present, start looping through the tuple
    of coordinates. Use these coordinates to make a subarray from the image, in which
    you’ll search for eyes ➊.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 打印正在搜索的图像名称，并开始遍历 face_rect_list 中的矩形。如果存在矩形，开始遍历坐标元组。使用这些坐标从图像中制作一个子数组，在其中搜索眼睛
    ➊。
- en: Call the eye cascade classifier on the subarray. Because you’re now searching
    a much smaller area, you can reduce the minNeighbors argument.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在子数组上调用眼睛级联分类器。由于现在搜索的是一个更小的区域，你可以减少 minNeighbors 参数的值。
- en: Like the cascade classifiers for faces, the eye cascade returns coordinates
    for a rectangle. Start a loop through these coordinates, naming them with an e
    on the end, which stands for “eye,” to distinguish them from the face rectangle
    coordinates ➋.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 像面部级联分类器一样，眼睛级联也会返回一个矩形的坐标。从这些坐标开始循环，并用 e 作为结尾命名它们，代表“眼睛”，以便与面部矩形的坐标 ➋ 区分开来。
- en: Next, draw a circle around the first eye you find. This is just for your own
    visual confirmation; as far as the algorithm’s concerned, the eye is already found.
    Calculate the center of the rectangle and then calculate a radius value that’s
    slightly larger than an eye. Use OpenCV’s circle() method to draw a white circle
    on the rect_4_eyes subarray.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，在你找到的第一个眼睛周围画一个圆圈。这只是为了你自己的视觉确认；就算法而言，眼睛已经被找到。计算矩形的中心，然后计算一个略大于眼睛的半径值。使用
    OpenCV 的 circle() 方法在 rect_4_eyes 子数组上画一个白色圆圈。
- en: Now, draw a rectangle around the face by calling OpenCV’s rectangle() method
    and passing it the img_gray array. Show the image for two seconds and then destroy
    the window. Because the rect_4_eyes subarray is part of img_gray, the circle will
    show up even though you didn’t explicitly pass the subarray to the im_show() method
    ([Figure 9-11](ch09.xhtml#ch09fig11)).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/fig09_11.jpg)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-11: Face rectangle and eye circle'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: With a human identified, disable the weapon ➌ and break out of the for loop.
    You need to identify only one eye to confirm that you have a face, so it’s time
    to move on to the next face rectangle.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '**Passing the Intruder or Discharging the Weapon**'
  id: totrans-116
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Still in the for loop through the corridor images, [Listing 9-4](ch09.xhtml#ch09list4)
    determines what happens if the weapon is disabled or if it’s allowed to fire.
    In the disabled case, it shows the image with the detected face and plays the
    “all clear” tone. Otherwise, it shows the image and plays the gunfire audio file.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Listing 9-4: Determining the course of action if the gun is disabled or enabled'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: Use a conditional to check whether the weapon is disabled. You set the discharge_weapon
    variable to True when you chose the current image from the *corridor_5* folder
    (see [Listing 9-2](ch09.xhtml#ch09list2)). If the previous listing found an eye
    in a face rectangle, it changed the state to False.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: If the weapon is disabled, show the positive detection image (such as in [Figure
    9-11](ch09.xhtml#ch09fig11)) and play the tone. First, call playsound, pass it
    the tone_path string, and set the block argument to False. By setting block to
    False, you allow playsound to run at the same time as OpenCV displays the image.
    If you set block=True, you won’t see the image until *after* the tone audio has
    completed. Show the image for two seconds and then destroy it and pause the program
    for five seconds using time.sleep().
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: If discharge_weapon is still True, print a message to the shell that the gun
    is firing. Use OpenCV’s putText() method to announce this in the center of the
    image and then show the image (see [Figure 9-12](ch09.xhtml#ch09fig12)).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/fig09_12.jpg)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-12: Example mutant window'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: 'Now play the gunfire audio. Use playsound, passing it the gunfire_path string
    and setting the block argument to False. Note that you have the option of removing
    the root_dir and gunfire_path lines of code in [Listing 9-1](ch09.xhtml#ch09list1)
    if you provide the full path when you call playsound. For example, I would use
    the following on my Windows machine:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Show the window for two seconds and then destroy it. Sleep the program for three
    seconds to pause between showing the mutant and displaying the next image in the
    *corridor_5* folder. When the loop completes, stop the pyttsx3 engine.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '***Results***'
  id: totrans-128
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Your *sentry.py* program repaired the damage to the sentry gun and allowed
    it to function without the need for transponders. It’s biased to preserve human
    life, however, which could lead to disastrous consequences: if a mutant enters
    the corridor at around the same time as a human, the mutant could slip by the
    defenses ([Figure 9-13](ch09.xhtml#ch09fig13)).'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/fig09_13.jpg)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-13: A worst-case scenario. Say “Cheese!”'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: Mutants might also trigger the firing mechanism with humans in the corridor,
    assuming the humans look away from the camera at the wrong moment ([Figure 9-14](ch09.xhtml#ch09fig14)).
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/fig09_14.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-14: You had one job!'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: I’ve seen enough sci-fi and horror movies to know that in a real scenario, I’d
    program the gun to shoot anything that moved. Fortunately, that’s a moral dilemma
    I’ll never have to *face*!
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: '**Detecting Faces from a Video Stream**'
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can also detect faces in real time using video cameras. This is easy to
    do, so we won’t make it a dedicated project. Enter the code in [Listing 9-5](ch09.xhtml#ch09list5)
    or use the digital version, *video_face_detect.py*, in the *Chapter_9* folder
    downloadable from the book’s website. You’ll need to use your computer’s camera
    or an external camera that works through your computer.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Listing 9-5: Detecting faces in a video stream'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: After importing OpenCV, set up your path to the Haar cascade classifiers as
    you did at ➌ in [Listing 9-1](ch09.xhtml#ch09list1). I use the *haarcascade_frontalface_alt.xml*
    file here as it has higher precision (fewer false positives) than the *haarcascade_frontalface_default.xml*
    file you used in the previous project. Next, instantiate a VideoCapture class
    object, called cap for “capture.” Pass the constructor the index of the video
    device you want to use ➊. If you have only one camera, such as your laptop’s built-in
    camera, then the index of this device should be 0.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: To keep the camera and face detection process running, use a while loop. Within
    the loop, you’ll capture each video frame and analyze it for faces, just as you
    did with the static images in the previous project. The face detection algorithm
    is fast enough to keep up with the continuous stream, despite all the work it
    must do!
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: To load the frames, call the cap object’s read() method. It returns a tuple
    consisting of a Boolean return code and a NumPy ndarray object representing the
    current frame. The return code is used to check whether you’ve run out of frames
    when reading from a file. Since we’re not reading from a file here, assign it
    to an underscore to indicate an insignificant variable.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: Next, reuse the code from the previous project that finds face rectangles and
    draws the rectangles on the frame. Display the frame with the OpenCV imshow()
    method. The program should draw a rectangle on this frame if it detects a face.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: To end the loop, you’ll press the Q key, for quit ➋. Start by calling OpenCV’s
    waitKey() method and passing it a short, one-millisecond time-span. This method
    will pause the program as it waits for a key press, but we don’t want to interrupt
    the video stream for too long.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: 'Python’s built-in ord() function accepts a string as an argument and returns
    the Unicode code point representation of the passed argument, in this case a lowercase
    *q*. You can see a mapping of characters to numbers here: *[http://www.asciitable.com/](http://www.asciitable.com/)*.
    To make this lookup compatible with all operating systems, you must include the
    bitwise AND operator, &, with the hexadecimal number FF (0xFF), which has an integer
    value of 255\. Using & 0xFF ensures only the last 8 bits of the variable are read.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: When the loop ends, call the cap object’s release() method. This frees up the
    camera for other applications. Complete the program by destroying the display
    window.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: 'You can add more cascades to the face detection to increase its accuracy, as
    you did in the previous project. If this slows detection too much, try scaling
    down the video image. Right after the call to cap.read(), add the following snippet:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The fx and fy arguments are scaling factors for the screen’s *x* and *y* dimensions.
    Using 0.5 will halve the default size of the window.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: The program should have no trouble tracking your face unless you do something
    crazy, like tilt your head slightly to the side. That’s all it takes to break
    detection and make the rectangle disappear ([Figure 9-15](ch09.xhtml#ch09fig15)).
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/fig09_15.jpg)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-15: Face detection using video frames'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: Haar cascade classifiers are designed to recognize upright faces, both frontal
    and profile views, and they do a great job. They can even handle eyeglasses and
    beards. But tilt your head, and they can quickly fail.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: An inefficient but simple way to manage tilted heads is to use a loop that rotates
    the images slightly before passing them on for face detection. The Haar cascade
    classifiers can handle a bit of tilt ([Figure 9-16](ch09.xhtml#ch09fig16)), so
    you could rotate the image by 5 degrees or so with each pass and have a good chance
    of getting a positive result.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/fig09_16.jpg)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-16: Rotating the image facilitates face detection.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: The Haar feature approach to face detection is popular because it’s fast enough
    to run in real time with limited computational resources. As you probably suspect,
    however, more accurate, sophisticated, and resource-intensive techniques are available.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: For example, OpenCV ships with an accurate and robust face detector based on
    the Caffe deep learning framework. To learn more about this detector, see the
    tutorial “Face Detection with OpenCV and Deep Learning” at *[https://www.pyimagesearch.com/](https://www.pyimagesearch.com/)*.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: Another option is to use OpenCV’s LBP cascade classifier for face detection.
    This technique divides a face into blocks and then extracts local binary pattern
    histograms (LBPHs) from them. Such histograms have proved effective at detecting
    *unconstrained* faces in images—that is, faces that aren’t well aligned and with
    similar poses. We’ll look at LBPH in the next chapter, where we’ll focus on *recognizing*
    faces rather than simply detecting them.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种选择是使用OpenCV的LBP级联分类器进行人脸检测。这种技术将人脸划分为多个块，并从中提取局部二值模式直方图（LBPH）。这种直方图在检测*无约束*的人脸（即未对齐且姿势各异的面孔）时非常有效。我们将在下一章中详细讨论LBPH，重点介绍*人脸识别*，而不仅仅是人脸检测。
- en: '**Summary**'
  id: totrans-160
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**总结**'
- en: In this chapter, you got to work with OpenCV’s Haar cascade classifier for detecting
    human faces; playsound, for playing audio files; and pyttsx3, for text-to-speech
    audio. Thanks to these useful libraries, you were able to quickly write a face
    detection program that also issued audio warnings and instructions.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，你使用了OpenCV的Haar级联分类器来检测人脸；使用了playsound库来播放音频文件；还使用了pyttsx3库来进行文本转语音。得益于这些有用的库，你能够快速编写一个不仅能检测人脸，还能发出语音警告和指令的程序。
- en: '**Further Reading**'
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**进一步阅读**'
- en: “Rapid Object Detection Using a Boosted Cascade of Simple Features” (Conference
    on Computer Vision and Pattern Recognition, 2001), by Paul Viola and Michael Jones,
    is the first object detection framework to provide practical, real-time object
    detection rates. It forms the basis for the face detection process used in this
    chapter.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: “使用提升级级联简单特征的快速物体检测”（计算机视觉与模式识别会议，2001年），由Paul Viola和Michael Jones提出，是第一个提供实用实时物体检测率的物体检测框架。它构成了本章用于人脸检测的基础。
- en: Adrian Rosebrock’s *[https://www.pyimagesearch.com/](https://www.pyimagesearch.com/)*
    website is an excellent source for building image search engines and finding loads
    of interesting computer vision projects, such as programs that detect fire and
    smoke, find targets in drone video streams, distinguish living faces from printed
    faces, automatically recognize license plates, and do much, much more.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: Adrian Rosebrock的*[https://www.pyimagesearch.com/](https://www.pyimagesearch.com/)*
    网站是构建图像搜索引擎和寻找大量有趣计算机视觉项目的绝佳资源，比如能够检测火灾和烟雾、在无人机视频流中寻找目标、区分真人面孔和打印的面孔、自动识别车牌等等。
- en: '**Practice Project: Blurring Faces**'
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**实践项目：模糊面孔**'
- en: Have you ever seen a documentary or news report where a person’s face has been
    blurred to preserve their anonymity, like in [Figure 9-17](ch09.xhtml#ch09fig17)?
    Well, this cool effect is easy to do with OpenCV. You just need to extract the
    face rectangle from a frame, blur it, and then write it back over the frame image,
    along with an (optional) rectangle outlining the face.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 你是否曾经看到过某个纪录片或新闻报道，其中一个人的面部被模糊处理以保护其匿名性，就像在[图9-17](ch09.xhtml#ch09fig17)中看到的那样？嗯，这个酷炫的效果通过OpenCV很容易实现。你只需要从一帧图像中提取出人脸矩形框，对其进行模糊处理，然后再将其写回到原图中，并可以选择在面部周围绘制一个矩形框。
- en: '![Image](../images/fig09_17.jpg)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/fig09_17.jpg)'
- en: 'Figure 9-17: Example of face blurring with OpenCV'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 图9-17：使用OpenCV进行面部模糊的示例
- en: Blurring averages pixels within a local matrix called a *kernel*. Think of the
    kernel as a box you place on an image. All the pixels in this box are averaged
    to a single value. The larger the box, the more pixels are averaged, and thus
    the smoother the image appears. Thus, you can think of blurring as a low-pass
    filter that blocks high-frequency content, such as sharp edges.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 模糊操作是通过在一个称为*核*的局部矩阵内对像素进行平均来实现的。可以将核想象成一个你放置在图像上的框。框内的所有像素都会被平均成一个值。框越大，平均的像素越多，因此图像看起来越平滑。因此，可以将模糊视为一种低通滤波器，它会阻挡高频内容，如锐利的边缘。
- en: Blurring is the only step in this process you haven’t done before. To blur an
    image, use the OpenCV blur() method and pass it an image and a tuple of the kernel
    size in pixels.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 模糊是这个过程中的唯一一个你之前没有做过的步骤。要模糊图像，可以使用OpenCV的blur()方法，并传入图像和一个表示像素大小的元组。
- en: '[PRE13]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: In this example, you replace the value of a given pixel in image with the average
    of all the pixels in a 20×20 square centered on that pixel. This operation repeats
    for every pixel in image.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，你将图像中给定像素的值替换为以该像素为中心的20×20正方形区域内所有像素的平均值。这个操作会对图像中的每个像素重复执行。
- en: You can find a solution, *practice_blur.py*, in the appendix and in the *Chapter_9*
    folder downloadable from the book’s website.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在附录中和从书籍网站下载的*Chapter_9*文件夹中找到解决方案，名为*practice_blur.py*。
- en: '**Challenge Project: Detecting Cat Faces**'
  id: totrans-174
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**挑战项目：检测猫脸**'
- en: 'It turns out there are three animal life forms on planet LV-666: humans, mutants,
    and cats. The base’s mascot, Mr. Kitty, has free rein of the place and is prone
    to wander through Corridor 5.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 结果发现，LV-666星球上有三种动物生命形态：人类、变种人和猫。基地的吉祥物，小猫先生，拥有自由出入的权限，并且经常会在走廊5中闲逛。
- en: Edit and calibrate *sentry.py* so that Mr. Kitty can freely pass. This will
    be a challenge, as cats aren’t known for obeying verbal orders. To get him to
    at least look at the camera, you might add a “Here kitty, kitty” or “Puss, puss,
    puss” to the pyttsx3 verbal commands. Or better, add the sound of a can of tuna
    being opened using playsound!
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 编辑并校准*sentry.py*，使得小猫先生可以自由通行。这将是一个挑战，因为猫并不以听从口头命令而闻名。为了至少让它看向摄像头，你可以在pyttsx3的语音命令中添加“Here
    kitty, kitty”或“Puss, puss, puss”。或者更好，使用playsound添加开罐头的声音！
- en: You can find Haar classifiers for cat faces in the same OpenCV folder as the
    classifiers you used in Project 13, and an empty corridor image, *empty_corridor.png*,
    in the book’s downloadable *Chapter_9* folder. Select a few cat images from the
    internet, or your personal collection, and paste them in different places in the
    empty corridor. Use the humans in the other images to gauge the proper scale for
    the cat.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在与项目13中使用的分类器相同的OpenCV文件夹中找到用于猫脸的Haar分类器，并且在书籍可下载的*Chapter_9*文件夹中可以找到一张空的走廊图片，*empty_corridor.png*。从互联网上或你个人的收藏中选择几张猫的图片，并将它们粘贴在空走廊的不同地方。使用其他图片中的人类来估计猫的适当比例。

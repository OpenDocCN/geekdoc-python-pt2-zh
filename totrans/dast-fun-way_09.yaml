- en: '9'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '9'
- en: Spatial Trees
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 空间树
- en: '![](image_fi/book_art/chapterart.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](image_fi/book_art/chapterart.png)'
- en: The previous chapter showed how nearest-neighbor search allows us to find nearby
    or close data points, broadening our ability to answer coffee-related questions,
    such as finding the closest physical location or finding items with similar attributes.
    In this chapter, we build on the concepts of tree-based data structures and spatial
    partitioning to further improve our nearest-neighbor searches.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 上一章展示了最近邻搜索如何帮助我们找到附近或接近的数据点，拓宽了我们回答与咖啡相关的问题的能力，比如找到最近的物理位置或找到具有相似属性的项目。在本章中，我们基于树形数据结构和空间划分的概念，进一步改进我们的最近邻搜索。
- en: Chapter 8 discussed how we can adapt the algorithmic concepts for finding a
    specific value to the more general problem of finding nearest neighbors. We also
    saw how operations become more difficult as we transition from a single dimension
    to multiple dimensions. Maybe we want to find nearby coffee shops in two-dimensional
    space or similar friends (based on empathy, willingness to listen, and the ever-important
    coolness factor). Grids replace the simple arrays, and it’s no longer sufficient
    to sort along a single dimension.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 第八章讨论了如何将寻找特定值的算法概念适应到更一般的寻找最近邻问题中。我们还看到，当从一维过渡到多维时，操作变得更加复杂。也许我们想要在二维空间中找到附近的咖啡店，或者寻找相似的朋友（基于同理心、愿意倾听和永恒重要的酷感）。网格取代了简单的数组，单纯沿着一个维度排序已经不再足够。
- en: 'This chapter introduces two new tree-based data structures: uniform quadtrees
    and k-d trees. The term *quadtree* is often used to describe an entire class of
    two-dimensional data structures, based on the original quadtree proposed by computer
    scientists Raphael Finkel and Jon Bentley, that partition each two-dimensional
    node into four subquadrants at each level. We focus on a uniform quadtree such
    as the structure proposed by researcher and inventor David P. Anderson. This structure
    has equal-sized subregions that mirror the grid structure, thus building upon
    our discussions in the previous chapter. In contrast, *k-d trees*, invented by
    Jon Bentley, use a more flexible binary partitioning scheme that can further adapt
    to the data and allow us to scale to higher dimensions. Through examining quadtrees
    and k-d trees, we learn to generalize and modify tree-based data structures—and
    examine these data structures by comparison with the projects of city planners.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了两种基于树的数据结构：统一四叉树和k-d树。*四叉树*这个术语通常用来描述一类二维数据结构，基于计算机科学家Raphael Finkel和Jon
    Bentley提出的原始四叉树，该树将每个二维节点划分为四个子象限。我们关注的是统一四叉树，如研究员和发明家David P. Anderson提出的结构。该结构具有与网格结构相对应的大小相等的子区域，从而建立在上一章的讨论基础上。相比之下，*k-d树*由Jon
    Bentley发明，采用一种更灵活的二叉划分方案，可以进一步适应数据，并允许我们扩展到更高维度。通过研究四叉树和k-d树，我们学会了如何推广和修改基于树的数据结构，并通过与城市规划项目的对比来考察这些数据结构。
- en: Quadtrees
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 四叉树
- en: While grids provide a convenient data structure for storing two-dimensional
    data, they come with their own host of complexities. As we saw in the previous
    chapter, both the overhead and usefulness of grids depend heavily on how finely
    we partition the space. Using a large number of grid bins (by creating a finely
    grained grid) takes significant memory and may require us to search many bins.
    On the other hand, coarsely grained partitioning can result in a large number
    of points per bin, as in [Figure 9-1](#figure9-1), resembling a simple linear
    scan over a large number of individual points.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然网格为存储二维数据提供了一个便捷的数据结构，但它们也有自己的一系列复杂性。正如我们在上一章所看到的，网格的开销和实用性很大程度上取决于我们如何划分空间。使用大量网格箱子（通过创建细粒度网格）需要大量内存，并且可能需要我们搜索多个箱子。另一方面，粗略的划分可能导致每个箱子内有大量数据点，如[图9-1](#figure9-1)所示，这类似于对大量单个点进行简单线性扫描。
- en: '![A two‐by‐two grid with 11 data points and a single target point.](image_fi/502604c09/f09001.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![一个二维网格，包含11个数据点和一个目标点。](image_fi/502604c09/f09001.png)'
- en: 'Figure 9-1: A grid with a small number of bins'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 图9-1：具有少量箱子的网格
- en: We can think of the grids in terms of different approaches to home organization.
    If we throw all our kitchen equipment into a single massive drawer, it takes forever
    to find a given item. This is equivalent to having a single large grid bin. To
    improve matters, suppose we separate utensils into different drawers and cookware
    into various cupboards depending on their usage. We even put cereals on one shelf
    and spices on another. This is equivalent to using finer-grained bins. Suddenly
    things are looking up—we no longer need to search under the frying pans to find
    the cinnamon. A little additional structure makes our cooking routine significantly
    easier.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从不同的家庭组织方法来思考这些网格。如果我们把所有厨房用具都扔进一个巨大的抽屉里，找到某个物品就需要花费很长时间。这相当于使用一个巨大的网格箱。为了改善这种情况，假设我们将餐具分开存放在不同的抽屉里，并根据用途将炊具存放在不同的橱柜中。我们甚至将麦片放在一层架子上，将香料放在另一层架子上。这相当于使用更细粒度的网格。突然之间，情况变得好转了——我们不再需要在煎锅下方寻找肉桂粉。稍加额外的结构就能大大简化我们的烹饪流程。
- en: However, we can take the idea too far. Perhaps we have too many utensils and
    it takes too long to search the packed drawer. We might improve efficiency by
    splitting the utensils into a drawer for scooping utensils and one for non-scooping
    utensils. But imagine the overhead of storing each utensil in its own drawer—or
    worse, allocating a drawer for each potential utensil we might buy. Soon we’re
    staring at a whole wall of drawers, wondering how many we’ll need to check to
    find something to beat our eggs. This is what happens when we use grids with overly
    fine bins.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们可能会将这一概念推得过头。也许我们拥有太多的餐具，且整理的抽屉过于拥挤，搜索起来非常耗时。我们或许可以通过将餐具分为一个专门放铲子、另一个放非铲子的抽屉来提高效率。但试想一下，将每个餐具都单独存放在一个抽屉里，甚至为每一个可能购买的餐具分配一个抽屉——这种做法的开销可想而知。很快，我们将面对一整面墙的抽屉，心里想着到底要打开多少个抽屉，才能找到一个打蛋器。这就是当我们使用过于精细的网格时的情况。
- en: The solution to this conundrum is to partition space dynamically relative to
    the data. We only bring in additional structure, and its corresponding overhead,
    when we need it. We start with a coarse-grained partition of the space. Maybe
    we wait to allocate a separate drawer for spatulas until we have at least five.
    Until then we can store them with the ladles and whisks. When we need more granularity,
    we subpartition our space further. To provide this dynamism, we can turn to *uniform
    quadtrees*.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这一难题的方法是根据数据动态划分空间。只有在需要时，我们才引入额外的结构及其相应的开销。我们从对空间进行粗粒度划分开始。也许我们等到至少拥有五个铲子时，再为它们分配一个单独的抽屉。在此之前，我们可以将它们和勺子、搅拌器一起存放。当我们需要更精细的粒度时，我们进一步对子空间进行划分。为了提供这种动态性，我们可以借助*均匀四叉树*。
- en: A uniform quadtree brings the branching structure of trees to grids. Each node
    in the tree represents a region of space. The root node represents the entire
    space covered by the tree and all points contained within this space. Each node
    is partitioned into four equal-sized quadrants, with a child node for each non-empty
    quadrant. The term *uniform* refers to the fact that nodes are partitioned into
    equal-sized spatial regions and thus partition the space within the node uniformly.
    [Figure 9-2](#figure9-2) illustrates a quadtree split.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 一个均匀的四叉树将树的分支结构引入网格。树中的每个节点代表一个空间区域。根节点代表树所覆盖的整个空间以及该空间内的所有点。每个节点被划分为四个大小相等的象限，每个非空象限都有一个子节点。术语*均匀*指的是节点被划分为大小相等的空间区域，因此在节点内均匀地划分了空间。[图
    9-2](#figure9-2)展示了四叉树的分割。
- en: '![The root node of the quadtree shown at the top encompasses the entire space
    and contains 11 points. Each of the four children contains a uniform region of
    the root node’s space and all points that fall within that region.](image_fi/502604c09/f09002.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![如图所示，四叉树的根节点包含整个空间并包含 11 个点。每个四个子节点包含根节点空间中的一个均匀区域，并包含该区域内的所有点。](image_fi/502604c09/f09002.png)'
- en: 'Figure 9-2: A quadtree node can have up to four children representing four
    equal-sized quadrants of that space.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9-2：一个四叉树节点最多可以有四个子节点，分别代表该空间的四个大小相等的象限。
- en: When discussing the four subtrees, it’s common to label them NorthWest, NorthEast,
    SouthWest, and SouthEast to reflect their spatial positions in the original region.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论四个子树时，通常将它们标记为西北（NorthWest）、东北（NorthEast）、西南（SouthWest）和东南（SouthEast），以反映它们在原始区域中的空间位置。
- en: Internal quadtree nodes store pointers to up to four children, along with associated
    metadata such as the number of points in the branch or the region’s spatial bounds
    (the minimum and maximum values for the node along the x- and y-dimension). Leaf
    nodes store a list of points that fall within that region, along with any desired
    metadata. We can use a single data structure for both internal and leaf nodes
    by keeping both a 2×2 grid of pointers to child nodes (for internal nodes) and
    an array for points (for leaf nodes). We either set the child entries to `null`
    in a leaf node or use an empty array for internal nodes.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 内部四叉树节点存储指向最多四个子节点的指针，并附带相关的元数据，如分支中点的数量或区域的空间边界（该节点在x维和y维的最小值和最大值）。叶节点存储一个包含该区域内点的列表，以及任何所需的元数据。我们可以通过保持一个2×2的子节点指针网格（对于内部节点）和一个点数组（对于叶节点）来使用单一的数据结构表示内部节点和叶节点。我们要么将叶节点中的子条目设置为`null`，要么在内部节点中使用一个空数组。
- en: 'The following is an example of a composite data structure for the `QuadTreeNode`:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是`QuadTreeNode`的复合数据结构示例：
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We use a simple composite data structure for the points:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为点使用了一个简单的复合数据结构：
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: As in the previous chapter, we could alternatively store the points in arrays
    or ordered tuples.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如同前一章所述，我们也可以将点存储在数组或有序元组中。
- en: 'Technically, we don’t need to store the spatial bounds of the node explicitly.
    We can instead derive the bounds for each node from bounds of the root node and
    the sequence of splits, since each node partitions its points along the middle
    of each dimension, slicing the space into four predictably sized subregions. Given
    the root node’s original bounds and the series of branches, we can compute the
    bounds for any child node precisely. However, precomputing and storing the bounds
    has one distinct advantage: at any given node we can simply look up the bounds
    instead of deriving them, making implementing our search algorithms significantly
    easier. I’ve often found that the value of storing this type of additional spatial
    information outweighs the additional memory costs.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 从技术上讲，我们不需要显式地存储节点的空间边界。我们可以通过根节点的边界和分割序列推导出每个节点的边界，因为每个节点在每个维度的中间对其点进行分区，将空间切割成四个可预测大小的子区域。给定根节点的原始边界和一系列分支，我们可以精确计算出任何子节点的边界。然而，预计算并存储边界有一个明显的优势：在任何给定的节点，我们可以简单地查找边界，而不是推导它们，这使得实现搜索算法变得更加容易。我常常发现，存储这种类型的额外空间信息的价值远远超过了额外的内存成本。
- en: The power of quadtrees is that branching at each level (where there are enough
    points) effectively creates an adaptive, hierarchical grid. [Figure 9-3](#figure9-3)
    shows an example of one quadtree’s spatial partitioning.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 四叉树的优势在于，每个级别的分支（当有足够多的点时）实际上创建了一个自适应的层次网格。[图9-3](#figure9-3)展示了一个四叉树空间分区的示例。
- en: '![A visualization of a four‐level quadtree. Lines indicate the splits at each
    level.](image_fi/502604c09/f09003.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![四级四叉树的可视化图。线条表示每个级别的分割。](image_fi/502604c09/f09003.png)'
- en: 'Figure 9-3: The spatial partition created by a quadtree'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图9-3：四叉树创建的空间分区
- en: Imagine the successive partitions of a quadtree and how we search them as the
    interactive geographical search software in a sci-fi thriller. The protagonists
    crowd the command room and stare at a large screen representing the entire city.
    Tense music plays. As new information pours in, the operator selects a quadrant
    from the screen. Someone says, “Zoom in there and enhance,” and the operator does
    so. Regardless of the dialogue, this operation is the equivalent to descending
    a level in the quadtree. In an instant, the command room’s screen displays a subset
    of the city. The entire range under display is a single quadrant of the previous
    level. Everyone stares at the new geo-subset intently, before they select a further
    subquadrant and zoom in again. The search concludes when our heroes have found
    the transmitter closest to the target points.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 想象四叉树的连续分区以及我们如何像科幻惊悚片中的互动地理搜索软件那样搜索它们。主角们挤满指挥室，盯着代表整个城市的大屏幕。紧张的音乐响起。随着新信息的涌入，操作员从屏幕中选择一个象限。有人说：“放大那里并增强，”操作员照做了。无论对话如何，这个操作相当于在四叉树中向下一级。刹那间，指挥室的屏幕显示了城市的一个子集。屏幕下的整个范围是上一级的一个象限。每个人都专注地盯着新的地理子集，然后选择一个更小的子象限再次放大。当我们的英雄们找到了离目标点最近的发射器时，搜索结束。
- en: 'As with other trees, we can add a wrapper data structure around the uniform
    quadtree to simplify bookkeeping:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他树结构一样，我们可以在统一的四叉树上添加一个包装数据结构，以简化账务管理：
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The root node is created as an empty node with the correct dimensions at the
    time the tree itself is created, so we do not need to worry about its being null.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: Building Uniform Quadtrees
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We build these magical quadtrees by recursively dividing our allocated space
    into smaller and smaller subregions. Since data can contain arbitrarily close
    or even duplicate points, we need additional logic to determine when to stop subdividing
    and designate a node with multiple points as a leaf. At each level, we check whether
    we need to make the current node an internal node (with child nodes) or a leaf
    node (with a list of points). There are different mechanisms we can use for this
    test, but here are the most common:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: Are there enough points to justify a split? If we have too few points, the cost
    of checking the distance to the child nodes is higher than exhaustively checking
    each of the points. It’s not worth the overhead.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Are the spatial bounds large enough to justify a split? What if we have 10 points
    in exactly the same location? We could split and split and split without ever
    partitioning the points. It’s a waste of time and memory.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Have we hit a maximum depth? This provides an alternate check to prevent us
    from wasting time and memory on excessive subdivision by capping how deep our
    tree can be.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We can visualize this process as an unconventional city planner’s attempt to
    divide up the land such that each parcel has a building. Unacquainted with modern
    geographical partitioning techniques, the planner always divides regions into
    four equal-sized quadrants. Each time they look at a plot of land, they ask, “Are
    there too many buildings on this land?” and “Is this plot big enough to divide
    up further? I can’t sell a 2-foot by 2-foot lot. People would laugh.” The third
    criterion (maximum depth) represents how much subdividing the planner is willing
    to do before they give up. After four levels, the planner might call it “good
    enough” and move on. If the criteria for stopping aren’t met, the planner sighs,
    mumbles “Really? Again?” and subdivides the plot.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: When partitioning a level, we divide the current space into four equal quadrants,
    partition the points according to quadrant, and recursively examine each one.
    If we set the minimum of points to 1 and the maximum depth to 4 (including the
    root), we’d construct the tree in [Figure 9-4](#figure9-4). As shown by the illustration,
    we can save memory by only storing the non-empty children for each node. If a
    quadrant doesn’t have a child, we can set its pointer to `null`.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '![The figure shows a quadtree with four levels. Each leaf node contains a single
    point.](image_fi/502604c09/f09004.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-4: An example quadtree with four levels'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: The code for bulk construction of quadtrees is very similar to the code presented
    in the next section for adding points. In fact, iteratively adding points to an
    empty quadtree is a good approach for constructing it.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: Adding Points
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Since quadtrees are dynamic data structures, we can efficiently add points
    while maintaining the tree structure. We start with the wrapper function for the
    `QuadTree` data structure:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 由于四叉树是动态数据结构，我们可以在保持树结构的同时高效地添加点。我们从`QuadTree`数据结构的包装函数开始：
- en: '[PRE3]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This wrapper guarantees we are always calling `QuadTreeNodeInsert` with a non-null
    node. The code also checks that the inserted point falls within the quadtree’s
    bounds. This is critical, as uniform quadtrees use equal-sized bins and cannot
    be dynamically resized. All points must fall within the root node’s spatial bounds.
    The code returns `False` if the point is out of range, but, depending on the implementation,
    you might want to use another mechanism such as returning an error or throwing
    an exception.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这个包装器保证我们总是以非空节点调用`QuadTreeNodeInsert`。代码还会检查插入的点是否在四叉树的边界内。这一点至关重要，因为均匀四叉树使用相同大小的区域，不能动态调整大小。所有的点必须落在根节点的空间边界内。如果点超出范围，代码会返回`False`，但是根据实现方式，您可能希望使用其他机制，如返回错误或抛出异常。
- en: 'As shown in the following code, adding points to a node consists of traversing
    the tree to find the new point’s location. This search can end in one of two ways:
    at a leaf node or at an internal dead end. If we terminate the search at a leaf
    node, we can add the new point there. Depending on our splitting criteria (spatial
    bounds, max depth, and number of points), we might need to split the node into
    subnodes. If we end at an internal dead end, then we have found a path that previously
    didn’t contain any points. We can create the appropriate node.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如下列代码所示，将点添加到节点的过程包括遍历树以找到新点的位置。这个搜索可以以两种方式之一结束：在叶子节点处或在内部死胡同处。如果我们在叶子节点处终止搜索，我们可以将新点添加到该处。根据我们的拆分标准（空间边界、最大深度和点的数量），我们可能需要将节点拆分为子节点。如果我们停在了内部死胡同处，那么我们找到了一个先前没有包含任何点的路径。我们可以创建合适的节点。
- en: '[PRE4]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The code starts by incrementing `num_points` to represent the new point ❶. The
    function then determines which of the four bins the new point falls into by computing
    the size of the bins and using that to map the x and y indices to either `0` or
    `1` ❷. If the node is not a leaf, the code needs to recursively add the point
    to the correct child ❸. It starts by checking whether the child exists. If not
    (if the child’s pointer is `null`), it creates the child ❹. We use the fact that
    both `xbin` and `ybin` are either `0` or `1` to simplify the logic. Instead of
    enumerating all four cases, we can compute the child’s bounds with arithmetic.
    Finally, at leaf nodes, the code inserts the points directly into the node ❺.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 代码首先通过递增`num_points`来表示新的点❶。然后，函数通过计算各个区域的大小，确定新点属于四个区域中的哪一个，并使用这些信息将x和y索引映射到`0`或`1`❷。如果节点不是叶子节点，代码需要递归地将点添加到正确的子节点❸。它首先检查子节点是否存在。如果不存在（如果子节点的指针是`null`），则创建子节点❹。我们利用`xbin`和`ybin`都只有`0`或`1`这一事实，简化逻辑。我们可以通过算术运算计算出子节点的边界，而无需枚举所有四种情况。最后，在叶子节点上，代码直接将点插入到节点中❺。
- en: We aren’t done yet, though. The code needs to check whether the splitting conditions
    are met ❻; if so, it splits the current leaf node. Luckily, we can reuse the same
    insertion function for splitting as we did to add a point. The code marks the
    node as a non-leaf (`node.is_leaf = False`) and reinserts the points one at a
    time using a `FOR` loop ❼. Because the current node is no longer a leaf node,
    the reinserted points now fall through to the correct children, with new children
    created as needed. However, since we used the function twice for each point, we
    have to correct `num_points` to avoid double-counting the reinserted points ❽
    (due to the counter increment at ❶). The code also clears the list of points at
    the newly internal node.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们还没有完成。代码需要检查是否满足拆分条件❻；如果满足，则拆分当前的叶子节点。幸运的是，我们可以重复使用相同的插入函数来进行拆分，就像我们用来添加点的函数一样。代码将节点标记为非叶子节点（`node.is_leaf
    = False`），并使用`FOR`循环将点逐个重新插入❼。由于当前节点不再是叶子节点，重新插入的点现在会通过到正确的子节点，并根据需要创建新的子节点。然而，由于我们对每个点都使用了该函数两次，我们必须修正`num_points`以避免重新插入的点被重复计算❽（因为在❶时进行了计数器递增）。代码还会清空新内部节点的点列表。
- en: '[Figure 9-5](#figure9-5) shows what happens if we add two points to the tree.
    The inserted open-circle point causes one node to split before triggering the
    max-depth condition. The resulting leaf node holds two points. The inserted open-square
    point adds a single new child node corresponding to its parent NorthWest quadrant.
    The code does not split again because of the minimum number of points condition.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: As noted in the previous section, we can use this approach to construct a uniform
    quadtree from a set of points. First, we create an empty root node with the necessary
    spatial bounds. Then we incrementally add each point from our set. Since splits
    are always based at the halfway point along each dimension, the tree structure
    does not change due to the order in which we insert the points.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '![A figure showing the addition of two points to the uniform quadtree. The
    open circle is inserted in the root’s NorthWest Child and that node’s SouthWest
    child. The previous leaf now has two points and is split again. Both points are
    in the same resulting node, which is a leaf due to the depth constraint.](image_fi/502604c09/f09005.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-5: An example of adding two points, indicated by a shaded circle and
    shaded square, to a quadtree'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: Removing Points
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Removing points from a node follows a similar, but more complex, process as
    inserting points. We delete the point from the list in the leaf node. We can then
    proceed back up the tree, removing splits that are no longer warranted by our
    criteria. This can involve recursively extracting the points from each of the
    node’s children (which may themselves have children) and merging them into a single
    list at the next leaf node.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: One additional difficulty is determining which point to delete. As with grids,
    the user might insert arbitrarily close or even duplicate points. In the code
    below, we delete the first matching point in the leaf node’s list. Due to floating-point
    errors (rounding due to a floating-point variable’s limited precision), we also
    cannot use a direct equality test. Therefore, we use a helper function to find
    a point that is close enough. We can reuse the `approx_equal` function from Listing
    8-3 for this test.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: 'We also use a helper function to collapse nodes that no longer meet our splitting
    criteria. The code collapses a node with children and returns an array with all
    the subtree’s points:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The code starts by checking whether the current node is already a leaf and,
    if so, directly returning the array of points ❶. Otherwise, the node is internal,
    and the code needs to aggregate the individual data points from each child. The
    code loops through each of the four children, checking whether they are `null`
    and, if not, recursively calling `QuadTreeNodeCollapse` to aggregate the points
    ❷. The function finishes by setting the current node to be a leaf ❸ and returning
    the points ❹.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: With that helper function, we can move on to the deletion function. We start
    with the wrapper.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The wrapper function starts by checking that the point lies within the bounds
    of the tree and thus could be in the tree. If so, it calls the recursive deletion
    function.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 包装函数首先检查点是否位于树的边界内，因此可能在树中。如果是，它会调用递归删除函数。
- en: The recursive deletion code proceeds down the tree as though searching for the
    point. When it reaches a leaf, it deletes the point if it exists. It then returns
    up the tree, collapsing nodes as needed. The function returns `True` if a point
    was deleted.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 递归删除代码按照搜索点的方式向树下方继续。当它到达叶节点时，如果点存在，它会删除该点。然后它会返回到上层节点，根据需要合并节点。如果删除了点，函数返回`True`。
- en: '[PRE7]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The code starts by checking whether the recursion has reached a leaf node ❶.
    If so, it iterates through the array of points ❷, checking whether each one matches
    the target point ❸. If the code finds a matching point, it removes it from the
    array, decrements the count of points in this node, and returns `True` to indicate
    a successful deletion. Note that only a single matching point is ever deleted.
    If the code does not find a matching point at the leaf, it returns `False`.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 代码首先检查递归是否已经到达叶节点❶。如果是，它会遍历点数组❷，检查每个点是否与目标点匹配❸。如果代码找到了匹配的点，它将从数组中移除该点，减少该节点中的点数，并返回`True`表示删除成功。请注意，每次只删除一个匹配的点。如果代码在叶节点没有找到匹配的点，它将返回`False`。
- en: The search then progresses down into the bin into which the target point would
    be assigned ❹. The code checks whether the correct child exists and, if not, returns
    `False` to indicate the point is not in the tree ❺. Otherwise, the code recursively
    calls `QuadTreeNodeDelete` on the child ❻.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索然后继续进入目标点应分配的桶❹。代码检查是否存在正确的子节点，如果不存在，返回`False`，表示该点不在树中❺。否则，代码递归地在子节点上调用 `QuadTreeNodeDelete`
    ❻。
- en: If the recursive call to `QuadTreeNodeDelete` returns `True`, then the code
    has deleted a point from one of its children. It updates the count of points and
    checks whether the child is empty ❼. If so, it deletes the child node. Then the
    code checks whether the current node continues to meet the criteria for being
    an internal node ❽. If not, it collapses the node. The code returns `True` to
    indicate the deletion was successful. If the recursive call did not return `True`,
    then no point was deleted. The function finishes by returning `False` ❾.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如果递归调用 `QuadTreeNodeDelete` 返回 `True`，则代码已从某个子节点删除了一个点。它更新点的数量，并检查该子节点是否为空❼。如果为空，它删除子节点。然后代码检查当前节点是否仍符合内部节点的标准❽。如果不符合，它将合并该节点。代码返回
    `True`，表示删除成功。如果递归调用没有返回 `True`，则没有删除任何点。函数最终返回 `False`❾。
- en: Searching Uniform QuadTrees
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 搜索均匀四叉树
- en: We begin our search of the quadtree at the root node. At each node, we first
    ask whether the node could contain anything closer than our current candidate.
    If so, for an internal node we explore the children recursively, and for a leaf
    node we test the points directly. However, if we determine that the current node
    could *not* contain our nearest neighbor, we can prune the search by ignoring
    not only that node but its entire subtree.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从根节点开始搜索四叉树。在每个节点，我们首先问该节点是否可能包含比我们当前候选点更接近的点。如果是，对于内部节点我们递归地探索子节点，对于叶节点我们直接测试点。然而，如果我们确定当前节点*不能*包含最近邻点，我们可以通过忽略该节点及其整个子树来修剪搜索。
- en: 'We check the compatibility of points within a node using the same test we applied
    to grid cells in Chapter 8. We have similar information at our disposal: the location
    of the point and the bounding box of the region. As described in the previous
    chapter, the distance computation is:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用与第8章中对网格单元应用的相同测试来检查节点内点的兼容性。我们拥有类似的信息：点的位置和区域的边界框。如前一章所述，距离计算公式为：
- en: '![g09001](image_fi/502604c09/g09001.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![g09001](image_fi/502604c09/g09001.png)'
- en: where
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 哪里
- en: IF *x* < *x*[min] THEN *x*[dist] = *x*[min] – *x*
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 *x* < *x*[min] 那么 *x*[dist] = *x*[min] – *x*
- en: IF *x*[min] ≤ *x* ≤ *x*[max] THEN *x*[dist] = 0
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 *x*[min] ≤ *x* ≤ *x*[max] 那么 *x*[dist] = 0
- en: IF *x* > *x*[max] THEN *x*[dist] = *x* – *x*[max]
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 *x* > *x*[max] 那么 *x*[dist] = *x* – *x*[max]
- en: and
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 和
- en: IF *y < y*[min]THEN *y*[dist] *= y*[min] *– y*
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 *y < y*[min] 那么 *y*[dist] *= y*[min] *– y*
- en: IF *y*[min] ≤ *y* ≤ *y*[max] THEN *y*[dist] = 0
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 *y*[min] ≤ *y* ≤ *y*[max] 那么 *y*[dist] = 0
- en: IF *y* > *y*[max] THEN *y*[dist] = *y* – *y*[max]
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 *y* > *y*[max] 那么 *y*[dist] = *y* – *y*[max]
- en: In short, we’re checking the distance from our search target to the closest
    possible point contained in the node’s spatial region. To revisit the example
    from the last chapter, we’re once again asking how far our lazy neighbor would
    need to throw a ball in order to just barely return it to our yard. This check
    only tests whether a point at this distance could exist within the node. We need
    to explore the node to see what points exist.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，我们正在检查搜索目标到节点空间区域中可能存在的最近点的距离。回顾一下上一章的例子，我们再次问：我们的懒惰邻居需要扔多远的球才能刚好把它扔回我们的院子里？这个检查只测试一个点在此距离内是否可能存在于节点中。我们需要探索该节点，以查看其中存在的点。
- en: Consider searching for the nearest neighbor of the point marked with an X in
    [Figure 9-6](#figure9-6). This figure shows the same distribution of points as
    our original map of coffee shop locations in Figure 8-3, where the X is our current
    location and the other points are nearby cafés.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑搜索标记为 X 的点在[图 9-6](#figure9-6)中的最近邻。该图显示了与我们在图 8-3 中的原始咖啡馆位置地图相同的点分布，其中 X
    是我们当前位置，其他点是附近的咖啡馆。
- en: We start at the root node with a dummy candidate point with infinite distance.
    We haven’t seen any candidate neighbors yet, so we need something with which to
    start our search. Using a dummy point with infinite distance allows the algorithm
    to accept the first point it finds as the new candidate without requiring any
    special logic. Any point we find is going to be closer than infinitely far away,
    and every region will contain closer points. In the case of searching for coffee
    shops, this corresponds to starting with an imaginary café that is infinitely
    far away. Any real café on our list is guaranteed to be closer than this imaginary
    point.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从根节点开始，使用一个具有无限距离的虚拟候选点。我们还没有看到任何候选邻居，因此我们需要一些东西来开始我们的搜索。使用一个虚拟的无限远点使得算法能够接受它找到的第一个点作为新的候选点，而无需任何特殊的逻辑。我们找到的任何点都将比无限远的点更近，并且每个区域都会包含更近的点。在寻找咖啡馆的例子中，这相当于从一个想象中的无限远的咖啡馆开始。我们列表中的任何真实咖啡馆都保证比这个虚拟点更近。
- en: '![A set of two‐dimensional points. There are 11 data points and 1 query point
    in the upper left‐hand area of the plot.](image_fi/502604c09/f09006.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![一组二维点。图中左上角有 11 个数据点和 1 个查询点。](image_fi/502604c09/f09006.png)'
- en: 'Figure 9-6: An example data set for nearest-neighbor search'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9-6：最近邻搜索的示例数据集
- en: 'Since our (dummy) candidate point has infinite distance, our compatibility
    test for the root node passes. At least one of the points in the root node *could*
    be less than infinitely far away. Although this test is mathematically identical
    to the one we used for grid cells, it has one big practical difference: the size
    of the cells we are testing varies at each level of the tree. At higher levels,
    each node covers a large amount of space. As we descend lower, the spatial bounds
    tighten.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的（虚拟）候选点的距离是无限的，因此我们对根节点的兼容性测试通过了。根节点中的至少一个点*可能*距离不再是无限远的。尽管这个测试在数学上与我们对网格单元使用的测试是相同的，但它有一个大的实际差异：我们测试的单元格的大小在树的每一层都不同。在较高层级，每个节点覆盖的空间较大。随着层级下降，空间范围变得更加紧凑。
- en: We prioritize which child node to search first based on the childrens’ proximity
    to the query point. After all, we ultimately want to find the closest point and
    prune as much as possible. So we consider the x and y splits and ask “Into which
    of the four quadrants would our target point fall?” In this case, our query point
    falls in the NorthWest quadrant, as shown in [Figure 9-7](#figure9-7), so we start
    there.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们根据子节点与查询点的接近程度来优先决定首先搜索哪个子节点。毕竟，我们最终是想找到最近的点并尽可能地进行剪枝。因此，我们考虑 x 和 y 的划分，并问：“我们的目标点会落入哪一个象限？”在这种情况下，我们的查询点位于西北象限，如[图
    9-7](#figure9-7)所示，所以我们从这里开始。
- en: We proceed down the pointer to the NorthWest child and find ourselves focusing
    on a subset of both the space and the points as shown in [Figure 9-8](#figure9-8).
    The grayed-out nodes represent nodes that have not been explored, and the grayed-out
    points have not been checked.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们沿着指针进入西北子节点，发现自己专注于空间和点的子集，如[图 9-8](#figure9-8)所示。灰色区域的节点表示尚未探索的节点，灰色的点表示尚未检查的点。
- en: '![The figure shows the root node with lines to indicate its partition into
    four quadrants. The query point is shown as an X in the NorthWest quadrant.](image_fi/502604c09/f09007.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![该图显示了根节点，线条指示它被划分为四个象限。查询点在西北象限中以 X 标记。](image_fi/502604c09/f09007.png)'
- en: 'Figure 9-7: The query point falls within the NorthWest quadrant of the quadtree’s
    root node.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9-7：查询点位于四叉树根节点的西北象限内。
- en: '![The diagram shows the first three levels of a quadtree. The child corresponding
    to the root node’s northwest quadrant is circled to indicate that the search is
    exploring that node.](image_fi/502604c09/f09008.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![该图显示了四叉树的前三个级别。与根节点西北象限对应的子节点被圈出，表示搜索正在探索该节点。](image_fi/502604c09/f09008.png)'
- en: 'Figure 9-8: The nearest-neighbor search for the example shown in [Figure 9-6](#figure9-6)
    starts by searching the subtree corresponding to the NorthWest quadrant of the
    root node.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9-8：如[图 9-6](#figure9-6)所示的例子中的最近邻搜索，从搜索根节点的西北象限对应的子树开始。
- en: Again, our test of spatial compatibility reveals that this node *could* contain
    our nearest neighbor. The minimum distance to the any point in the node is less
    than that of our current (dummy) candidate. We’re at another internal node, which
    means that the space is further partitioned into four subregions.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们的空间兼容性测试表明这个节点*可能*包含我们的最近邻。该节点中任何点的最小距离都比当前（假定的）候选点距离更小。我们处于另一个内部节点，这意味着空间进一步被划分成四个子区域。
- en: Our search continues to the SouthWest child of the internal node in question,
    as illustrated in [Figure 9-9](#figure9-9). We choose this node because it is
    the closest to our query point. For the third time, the compatibility test passes.
    Since we’re at a leaf node, we explicitly check the distance to each point in
    that node. In this case, there is only a single point, and it is closer than our
    dummy candidate.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的搜索继续到相关内部节点的西南子节点，如[图 9-9](#figure9-9)所示。我们选择这个节点，因为它离查询点最近。第三次，兼容性测试通过。由于我们处于叶子节点，因此我们显式检查该节点中每个点到查询点的距离。在这个例子中，只有一个点，它比我们的假定候选点更近。
- en: '![The diagram shows the first three levels of a quadtree. Three nodes are solid:
    the root node, the root node’s NorthWest child, and that node’s SouthWest child.
    The current node in the search is circled.](image_fi/502604c09/f09009.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![该图显示了四叉树的前三个级别。三个节点是实心的：根节点、根节点的西北子节点，以及该子节点的西南子节点。当前搜索的节点被圈出。](image_fi/502604c09/f09009.png)'
- en: 'Figure 9-9: At the second level of the quadtree, our search starts with the
    closest quadrant to the target point, SouthWest.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9-9：在四叉树的第二级，我们的搜索从离目标点最近的象限开始，即西南象限。
- en: We’ve found our first real candidate nearest neighbor! Its distance becomes
    our minimum distance so far. We can be pickier about all future points. In our
    running example of finding a nearby coffee shop, this first neighbor represents
    the closest coffee shop found so far. The distance to this point is the maximum
    distance that we’ll need to travel to get a cup of coffee. We might find closer
    coffee shops later in our search, but at least we don’t have to travel infinite
    miles. The relief is palpable.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们找到了第一个真正的最近邻候选！它的距离成为迄今为止的最小距离。我们可以在未来的所有点中更加挑剔。在我们寻找附近咖啡店的例子中，这个第一个邻居代表了目前为止找到的最近咖啡店。到这个点的距离是我们为了喝一杯咖啡而需要走的最远距离。我们可能在搜索过程中找到更近的咖啡店，但至少我们不必走无穷远。松了一口气。
- en: 'Once we’ve tested all the points in a leaf node, we return to the (internal)
    parent node and check the remainder of the children. Now that we have a real candidate
    and distance, our pruning tests have power. We check the compatibility of all
    remaining child quadrants: NorthWest, NorthEast, and SouthEast. Our distance test
    shows that we can skip the NorthWest quadrant: as shown in [Figure 9-10](#figure9-10),
    the closest possible point in its spatial bounds is further than the candidate
    we already have. It can’t possibly contain a better neighbor.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们测试了叶子节点中的所有点，我们会返回到（内部）父节点并检查其余子节点。现在我们有了一个真实的候选点和距离，我们的剪枝测试便有了实际意义。我们检查所有剩余子象限的兼容性：西北、东北和东南。我们的距离测试显示我们可以跳过西北象限：如[图
    9-10](#figure9-10)所示，其空间范围内的最近可能点比我们已有的候选点更远。它不可能包含更好的邻居。
- en: '![A diagram showing the four quadrants in the root’s NorthWest child. Lines
    from the query point to the best node so far indicate the threshold distance.
    The min distance to the current node’s NorthWest child is also indicated by a
    longer line.](image_fi/502604c09/f09010.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![一个示意图，显示根节点西北子节点中的四个象限。从查询点到当前最佳节点的线表示阈值距离。到当前节点的西北子节点的最小距离也由一条较长的线表示。](image_fi/502604c09/f09010.png)'
- en: 'Figure 9-10: An illustration of the relative distance between the best candidate
    seen so far and the current node’s NorthWest quadrant'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: We can also skip the empty NorthEast and SouthEast quadrants. Since they don’t
    have any points, they can’t have a better neighbor either. Our search can discard
    both quadrants without a distance test because their pointers will be `null` to
    indicate that no such child exists. We’ve managed to prune three of the four quadrants
    in this node as illustrated by the grayed-out quadrants in [Figure 9-11](#figure9-11).
    The two data points in the NorthWest quadrant also remain gray, because we never
    tested them.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '![The search has returned to the root node’s NorthWest child. Three of the
    node’s quadrants are grayed out to indicate they were pruned from the search.](image_fi/502604c09/f09011.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-11: The nearest-neighbor search is able to skip three of the node’s
    four quadrants.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: Once we’ve finished checking the quadrants within an internal node, we return
    to its parent and repeat the process. The next closest quadrant is SouthWest,
    which our pruning test confirms is close enough to possibly contain a better neighbor,
    as shown in [Figure 9-12](#figure9-12).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: Any time we find a child that, according to our simple distance test, *could*
    contain a closer point, we proceed down that pathway to check if there are indeed
    closer neighbors. In this case, our search descends into the SouthWest quadrant.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '![An illustration of pruning at the root node. The query point is shown with
    an X, and a line shows the distance to the best neighbor so far. A second line
    shows the (smaller) distance to the root’s SouthWest child.](image_fi/502604c09/f09012.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-12: A pruning test where the candidate quadrant could include a closer
    neighbor than the current best point'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: At the next level, four potential quadrants again vie for our attention. Armed
    with a real candidate point and its corresponding distance, we can aggressively
    prune our search, as shown in [Figure 9-13](#figure9-13). We check the NorthWest
    quadrant (and its single point) because it falls within our distance threshold.
    We can skip the other three quadrants; the NorthEast and SouthWest quadrants are
    both empty and thus have null child pointers, and we use a distance test to confirm
    that the SouthEast quadrant is too far away to contain a better neighbor.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: This time when we return to the root node, we can prune out the two remaining
    children, as shown in [Figure 9-14](#figure9-14).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: The remote expanses of both the NorthEast and SouthEast quadrants lie well outside
    our distance threshold.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: '![The search has progressed down the entire branch corresponding to the root
    node’s SouthWest child. That child has three of its four quadrants grayed out.
    ](image_fi/502604c09/f09013.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-13: While checking the root node’s SouthWest quadrant, the nearest-neighbor
    search can again skip three of the four subquadrants.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '![The search has returned to the root node. Two of the root node’s quadrants
    are grayed out. Nine of the 11 data points remain gray.](image_fi/502604c09/f09014.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-14: Upon returning to the root node of the quadtree, the search can
    skip two of that node’s quadrants.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: Nearest-Neighbor Search Code
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To simplify our implementation of the nearest-neighbor search code, we start
    with a helper function to compute the distance from the target point (*x*, *y*)
    to a node. The code for checking the minimum distance to a node is similar to
    the minimum distance code presented for grids in the last chapter:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: However, in this case, the code does not need to compute the minimum and maximum
    bounds for the node, since each node stores them explicitly.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: The main search algorithm uses the same recursive formulation described for
    other tree-based methods. Our implementation of this search algorithm includes
    a parameter `best_dist` that represents the distance so far. By passing `best_dist`
    to our search function, we can simplify the pruning logic. If the minimum distance
    to the current node is greater than the best distance so far, we can terminate
    that branch of the search. The function then returns a *closer* point if it finds
    one and `null` otherwise. It’s important to note that in this implementation,
    a return value of `null` means that there are no points in the current node closer
    than `best_dist`.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: 'We use a thin wrapper that passes along the root node and an initial infinite
    distance:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Our wrapper function for nearest-neighbor search does not check that the target
    point falls within the quadtree bounds. This allows us to use the code to find
    neighbors within the tree for target points that fall outside the tree’s bounds,
    increasing the usefulness of the code.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the code for recursively searching the nodes:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The function starts with the pruning test, skipping the node and returning `null`
    if no point could be closer than `best_dist` ❶. The code then checks if it is
    at a leaf node ❷. If it has reached a leaf, it uses a `FOR` loop to check whether
    each point is closer than `best_dist`, updating `best_dist` and `best_candidate`
    if so. At the end of this loop, we return `best_candidate`, which has the value
    `null` if we haven’t found a new closer point.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: The next block of code handles the logic for an internal node. We have only
    made it this far if the node isn’t a leaf and thus doesn’t have any candidate
    points. Some basic numerical tests and integer manipulation control the order
    that the code searches the children, allowing the code to search the closest child
    first and then expand to the rest of the children. The code starts by computing
    into which x and y bin the candidate point should fall ❸, adjusting the value
    so that `xbin` and `ybin` both fall within [0, 1], and thus indicates the closest
    child node. This adjustment is necessary because, for many internal nodes, our
    target point will lie completely outside the 2×2 grid represented by the current
    node.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: We then recursively explore the non-null children using a pair of nested `FOR`
    loops to iterate over the pairs ❹. Each time we check whether we find a closer
    point (represented by `quad_best != null)` and, if so, update both `best_candidate`
    and `best_dist` ❺. At the end of the function, we return `best_candidate`. As
    in the case of the leaf node, `best_candidate` may be `null` if we haven’t found
    a point closer than the original `best_dist`.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: k-d Trees
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We’ve solved the problem of dynamic splits for two dimensions, so now it’s time
    to turn our attention to searching for points or nearest neighbors in three or
    more dimensions using k-d trees. We’ve already seen the disappointment that can
    result when we don’t account for all the relevant attributes in our coffee. Higher-dimensional
    problems are common whenever we’re looking for similar points in data sets, such
    as searching for similar conditions (temperature, pressure, humidity) in a weather
    data set.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: In theory, we could scale quadtrees by simply splitting along more dimensions.
    *Octtrees*, for example, are three-dimensional versions that split into eight
    subnodes at each level. Eight-way splits may not seem too bad, but this approach
    clearly doesn’t scale gracefully with the number of dimensions. If we want to
    build a tree over *D*-dimensional data, we need to split along all *D* dimensions
    at once, giving us 2^(*D*) children for each internal node. If we were building
    a data structure over weather data containing temperature, pressure, humidity,
    precipitation, and wind speed, we would be using five-dimensional points and splitting
    32 subtrees at each level! This immense overhead is the same problem we found
    when scaling grids to higher dimensions.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: To effectively scale to higher dimensions, we need to rein in the branching
    factor. There are a variety of powerful data structures designed to enable efficient
    proximity search in higher dimensions. One example is the k-d tree, which builds
    off similar concepts as the quadtree.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: k-d Tree Structure
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A *k-d tree* is a spatial data structure that combines the spatial partitioning
    of quadtrees with the binary branching factor of a binary search tree, giving
    us the best of both worlds. Instead of splitting along every dimension at every
    level, the k-d tree chooses a single dimension and splits the data along that
    dimension. Each internal node thus partitions the data into exactly two children:
    a left child whose points fall below (or equal to) the split value, and a right
    child whose points fall above the split value.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: When working with k-d trees, we lose the regular grid-like structure of the
    uniform quadtree, but, in exchange, we return to the two-way branching factor
    we know and love from binary search trees. This ability to partition along a single
    dimension in turn allows the k-d tree to scale to higher-dimensional data sets.
    We no longer need to split into 2^(*D*) children at each level. [Figure 9-15](#figure9-15)
    shows an example k-d tree.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: '![The root node of the k‐d tree is split along the y‐dimension. Each of the
    two resulting children is split along the x‐dimension.](image_fi/502604c09/f09015.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-15: A k-d tree split along a single dimension at each level'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: 'A k-d tree can adjust more flexibly to the structure of the data than quadtrees.
    We’re not constrained to split in the midpoint of every dimension at once. Instead
    of partitioning space into 2^(*D*) equally sized grid cells, we can choose a split
    dimension and value that are best suited to the data at each node. Each internal
    node thus stores both the dimension along which we’re partitioning (`split_dim`)
    and the value (`split_val`), with points assigned to the left child if their value
    in that one dimension is less than or equal to the node’s split value:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Rather than split along alternating axes, producing partitioning similar to
    that of the quadtree in [Figure 9-15](#figure9-15), we can tailor our tree structure
    by choosing splits based on the composition of the data points within the current
    node, thus allowing us to make splits that will better aid our future searches.
    We might choose the split value based on the overall bounds of the node, such
    as splitting in the middle of the widest dimension. Or we could choose the split
    value based on the distribution of data points, such as splitting at the middle
    of the range or the median of the points’ values along the split dimension. The
    difference between these two options is illustrated in [Figure 9-16](#figure9-16).
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '![The left box shows points partitioned at the middle of the x‐dimension, splitting
    the space in half. The right box shows points partitioned at the median value
    along the x‐dimension, resulting in two boxes with an approximately equal number
    of points but different sizes.](image_fi/502604c09/f09016b.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-16: A node split at the middle (left) and median (right)'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: 'The flexible structure of the k-d tree means we need to take additional care
    when dealing with nodes’ spatial bounds. Unlike the uniform quadtree’s square
    grid cells, the nodes of a k-d tree cover multidimensional rectangles of the overall
    search space. The width in each dimension can be completely different. Some nodes
    might be square-ish, while others might be long and thin. We represent a node’s
    area by explicitly tracking the multidimensional rectangle defining its spatial
    bounds—the minimum and maximum values in each dimension. Since we can have an
    arbitrary number of dimensions, we store the bounds in two arrays, `x_min` and
    `x_max`, where `x_min[d]` represents the lowest value along dimension `d` contained
    within the current node and `x_max[d]` represents the highest. All points within
    the node satisfy:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: As a result of its complexity, each k-d tree node stores a significant amount
    of information. While this might initially seem like expensive overhead, as we’ll
    see in this section, the cost is offset by the power and flexibility of tree itself.
    As with every other data structure in this book, we are making an explicit tradeoff
    in terms of memory, data structure complexity, and later algorithmic efficiency.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example composite data structure for the `KDTreeNode`:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: In this case, we use an array to represent each point, allowing it to have arbitrary
    dimensions.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: As with other trees in this book, we can wrap the nodes in an outer data structure
    such as a `KDTree`.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: It is helpful to store the number of dimensions in this wrapper data structure
    to check for consistency during operations such as insertion, deletion, or search.
    The value of `num_dimensions` is set at time of the k-d tree’s creation and remains
    fixed for this tree.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: 'This flexibility of choosing a strategy for splitting nodes illustrates the
    true power of the k-d tree: we’re augmenting the spatial partitioning of quadtrees
    to further adapt to the data. If our points are clustered, we choose splits that
    provide the most information by focusing on those regions. [Figure 9-17](#figure9-17)
    demonstrates this dynamic partitioning.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '![The figure of a k‐d tree with horizontal or vertical lines representing the
    different splits at each level. The subdivisions are all of different dimensions.](image_fi/502604c09/f09017.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-17: The spatial partition created by a k-d tree'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: Consider our ongoing task of locating nearby coffee shops. If we are taking
    a road trip along Interstate 95 from Florida to Maine, we could preprocess the
    data to store only those coffee shops within 50 miles of the highway.[Figure 9-18](#figure9-18)
    shows an example distribution of this shape.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: 'This prefiltering helps limit the search space to only coffee shops near the
    highway, yet we can make our searches even more efficient by storing these locations
    in a spatial data structure. We want to narrow our search to the appropriate region
    along the highway as well. After all, there is no need to check coffee shops in
    Massachusetts while we are still in South Carolina. We quickly see that a uniform
    partitioning scheme is far from ideal: our trip covers over 1,500 miles of mostly
    northward driving. Since we have already filtered to only shops along the highway,
    we do not gain as much pruning from partitioning uniformly east and west as well.
    We can increase the amount of pruning, and thus decrease the search cost, by biasing
    our partitions along the north-south direction.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: To give another analogy, if quadtrees are the daily routine of a city planner
    following rigid regulations to divide up a map, k-d trees represent a city planner
    with a wider range of tools at their disposal. They’re no longer constrained to
    divide each plot into perfect squares. Instead, they have the flexibility to partition
    the space according to the distribution of actual points. Our city planner chooses
    the widest dimension to split in order to minimize long, narrow zones. They also
    use the median point along this dimension to provide a balanced tree. The result
    might not always look as orderly as the quadtrees squares, but it can be much
    more effective.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: '![A scatterplot of points in the shape of Route 95.](image_fi/502604c09/f09018.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-18: An example of how coffee shops might be distributed along a major
    highway'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: Tighter Spatial Bounds
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We can often further improve a spatial tree’s pruning power by tracking the
    bounding box of all the points falling within a given node instead of the node’s
    total spatial bounds. This changes our pruning question from “Could a nearest-neighbor
    candidate exist in the space covered by the node?” to “Could a nearest-neighbor
    candidate exist in the bounding boxes of actual points within the node?” While
    this might seem like a small change, depending on what logic we use to split the
    nodes, we can see significant savings, as shown in [Figure 9-19](#figure9-19).
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: '![The tight bounding box of a k‐d tree node is shown as a dashed box bounding
    the points within the node.](image_fi/502604c09/f09019.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-19: The bounding box of points within a k-d tree node'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: If we use these tighter bounding boxes during node construction, we can better
    adapt to the data. We are no longer splitting based on the entire possible spatial
    region, but rather on the region occupied by actual points. The resulting k-d
    tree structure looks like the one in [Figure 9-20](#figure9-20). The black boxes
    indicate the tight bounding boxes at each node. The gray points and lines are
    shown to place the nodes’ bounds in the context of the rest of the data set.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: '![Each node in the k‐d tree is shown as a set of points, and a tight bounding
    box is laid over the grayed‐out full data set.](image_fi/502604c09/f09020.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-20: A three-level k-d tree and the bounding boxes for each node'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: During a search, we use the black boxes (tight bounding boxes) for pruning.
    As you can see from the figure, the resulting regions can be significantly smaller,
    allowing us to prune much more aggressively. Since the tight bounding box is smaller,
    it will often have a greater minimum distance to our query point.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use a simple helper function to compute the tight bounding boxes from
    a set of points represented as arrays ([Listing 9-1](#listing9-1)):'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Listing 9-1: A helper function to compute the tight bounding box of the points
    in a node'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: The code extracts the number of points and number of dimensions from the input
    data ❶. It then creates new arrays `L` and `H` to hold the low and high bounds,
    respectively, ❷ and seeds them with the coordinates of the first point in our
    array ❸. The code then iterates through the remaining points in the array and
    checks whether any of them fall outside the bounds ❹. If so, it extends the bounds.
    The code ends by returning the two arrays ❺.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: This helper function also illustrates the benefit of prechecking that all our
    points contain the correct number of dimensions in the `KDTree`’s wrapper function.
    This check ensures that we do not try to access our invalid array entries for
    our data points.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: Of course, tracking these additional bounds adds significant complexity when
    we start dealing with dynamic changes. Adding points to a k-d tree can increase
    the bounds for a given node. Similarly, removing nodes may shrink the bounds.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: Building k-d Trees
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Construction of a k-d tree uses a recursive process similar to the one for
    binary search trees, but with a few major differences. We start with all the data
    points and divide them into two subsets by picking a splitting dimension and value.
    This process repeats at each level until we hit our termination criteria: a minimum
    number of points left at the node, a minimum width, or a max depth. Generally,
    we use two of these tests, minimum number of points and minimum width, but using
    at least one of the last two tests is essential to avoid infinite recursion when
    you have duplicate data points.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: 'We start with a wrapper function to check that our data is valid:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The code starts by checking that all points have the correct dimensionality.
    It then checks that there are points from which to build the tree. If so, it allocates
    a new root node (overwriting the previous tree) and recursively builds the k-d
    tree using the function below. Otherwise, it sets the root to `null` to indicate
    an empty tree.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: The primary difference between k-d tree and quadtree construction is that k-d
    trees require us to choose a single split dimension at each level. If we are using
    tight bounding boxes, we also need to compute the bounding boxes over *D* dimensions.
    While these changes make the code a little longer (with extra loops over *D*),
    they don’t add any real complexity. The code for building a k-d tree recursively
    partitions our set of points among the child nodes until we reach the termination
    criteria.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This code starts with bookkeeping to fill in the information needed at each
    node. We record the essential details, such as the number of points and number
    of dimensions of the current points ❶. Then the function loops over all the points,
    computing the tight bounding box for the node ❷ using the helper function in [Listing
    9-1](#listing9-1).
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: Once we have the bounds, the code loops over each of the dimensions to find
    the widest dimension ❸. We use this loop for one of the stopping conditions for
    the recursion (not splitting a node that is too small). If the node does not meet
    the conditions to keep splitting, the code stores all the points in a list at
    the leaf ❹. Otherwise, the code picks a split dimension and a split value for
    the node ❺. The code iterates over the current set of points, partitioning them
    into two arrays, `left_pts` and `right_pts`, according to the split dimension
    and value ❻. Those arrays are used to recursively build the two children nodes
    ❼.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: 'One approach for choosing `split_dim` and `split_val` is to split along the
    middle of the widest dimension. The code for this is relatively simple and most
    of it can be incorporated into the initial block that finds the widest dimension
    ❸:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'and then later setting the split dimension and the value at ❺:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Bulk construction of k-d trees has a significant advantage over dynamically
    inserting and removing points. By considering all the data points during construction,
    we can better adapt the structure of the tree to the data. We choose splits based
    on all the data points instead of the subset inserted so far.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: k-d Tree Operations
  id: totrans-185
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The basic operations of inserting points, deleting points, and searching the
    k-d tree follow the same approach as with quadtrees. We start all operations at
    the top of the tree (root node) and use the split values to navigate down the
    appropriate branches. The major difference is that, instead of picking which of
    four quadrants to explore, we use `split_dim` and test against `split_val` to
    choose one of two children. As the high-level concepts are similar to those presented
    for the quadtree, we will not go into the code in detail for each one. Instead,
    let’s look at some of the differences.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: Insertion When inserting points into a k-d tree node, we use `split_dim` and
    `split_val` to determine which branch to take. We split leaf nodes if they meet
    our split condition using the same approach as we would use during bulk construction.
    Finally, if we are tracking the tight bounding box for each node, we need to update
    the bounds to account for the new point. Since we are adding points, this update
    will always increase the size of the bounding box.
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This code iterates over each dimension of the new point, checks whether it falls
    outside the bounding box, and, if so, updates the bounds.
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Deletion When deleting points in a k-d tree, we use `split_dim` and `split_val`
    to determine which branch to take during our search for the point. After deleting
    a node, we return to the root of the tree. At each node along the way, we check
    whether the bounds can be tightened (using the points in a leaf or the two children’s
    bounding boxes for an internal node). We also check whether internal nodes can
    be collapsed.
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Search The key difference in the search operations between a quadtree and a
    k-d tree is in testing whether we can prune nodes. For example, we can compute
    the Euclidean distance between a point *x* and the closest possible point in a
    node’s (non-uniform, *D*-dimensional) bounding box using an extension of the formula
    ![i09001](image_fi/502604c09/i09001.png) that we used for quadtrees and grids.
    We start by competing the minimum distance from the point to the node’s spatial
    bounds along each individual dimension:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: IF *x*[*d*] < *x*[min][*d*] THEN *dist*[d] = *x*[min][*d*] − *x*[*d*]
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: IF *x*[min][*d*] ≤ *x* ≤ *x*[max][*d*] THEN *dist*[d] = 0
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: IF *x*[*d*] > *x*[max][*d*] THEN *dist*[d] = *x*[*d*] − *x*[max][*d*]
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: 'where *x*[*d*] represents the query point’s *d*th dimension, and *x*[min][*d*]and
    *x*[max][*d*] represent the node’s low and high bounds in the *d*thdimension.
    Then we compute the sum of squared distances along each dimension and take the
    square root. We can implement this entire computation as a `WHILE` loop over the
    dimensions:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Note that k-d trees can be more sensitive to additions and deletions than quadtrees.
    While both trees can become unbalanced due to the splitting rules and the distribution
    of points, k-d trees’ splits are chosen based on the data at the time. If we significantly
    change the distribution of points, the original split values may no longer be
    good ones. During bulk construction, we can adapt the splits to the data at hand,
    considering such factors as the depth of the tree, whether it is balanced, and
    the tightness of the nodes’ spatial bounds. This illustrates another tradeoff
    we see with data structures—the performance of a structure may degrade as the
    data changes.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: Why This Matters
  id: totrans-198
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The quadtree and k-d trees are examples of how we can combine the power of dynamic
    data structures with the spatial structure in our search problem. By branching
    along multiple dimensions at once, quadtrees allow us to adapt the resolution
    of a grid to the density of data points in a local area. High-density areas result
    in deeper branches and thus a finer-grained grid. At the same time, retaining
    a regular grid structure introduces new costs for higher dimensions. Examining
    how quadtrees, octtrees, and their variants scale across different data sets provides
    an important lens for how we think about utilizing spatial structure.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: A k-d tree represents a combination of the concepts we have built up over the
    past few chapters to solve the problem of nearest-neighbor search. It solves the
    problem of having a high branching factor by returning to the core concepts of
    binary search trees and choosing a single dimension along which to split at each
    node. In addition, it allows more flexibility to adapt to the structure of the
    data, increasing pruning power.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: Quadtrees and k-d trees aren’t the only data structures for facilitating nearest-neighbor
    searches. There are a wealth of other tree-based and non-tree-based approaches.
    The topic of spatial data structures could fill multiple books. As with almost
    everything in computer science, each approach comes with its own tradeoffs in
    terms of program complexity, computational cost, and memory usage. For the purpose
    of this book, quadtrees and k-d trees serve as excellent examples of how we can
    combine the spatial pruning of nearest-neighbor search with tree-based structures
    to allow the spatial trees to adapt to the data at hand.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL

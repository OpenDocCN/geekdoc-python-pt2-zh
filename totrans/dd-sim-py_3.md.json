["```py\nnumber = None\nwhile number is None:\n    try:\n        number = int(input(\"Enter a number: \"))\n    except ValueError:\n        print(\"You must enter a number.\")\n\nprint(f\"You entered {number}\")\n```", "```py\nEnter a number: forty\nYou must enter a number.\nEnter a number: \nYou must enter a number.\nEnter a number: 40\nYou entered 40\n```", "```py\nnumber = None\nwhile number is None:\n    try:\n        **raw =** input(\"Enter a number **('q' to quit):** \")\n        **if raw == 'q':**\n **break**\n        number = **int(raw)**\n    except ValueError:\n print(\"You must enter a number.\")\n\nprint(f\"You entered {number}\")\n```", "```py\nEnter a number ('q' to quit): foo\nYou must enter a number.\nEnter a number ('q' to quit): q\nYou entered None\n```", "```py\nnumber = None\nwhile number is None:\n    try:\n        raw = input(\"Enter a number ('q' to quit): \")\n        if raw == 'q':\n            break\n        number = int(raw)\n    except ValueError:\n        print(\"You must enter a number.\")\n**else:**\n **print(f\"You entered {number}\")**\n```", "```py\nEnter a number ('q' to quit): q\n```", "```py\nnumbers = [\"One\", \"Two\", \"Three\"]\n\nfor number in numbers:\n    print(number)\nelse:\n    print(\"We're done!\")\n```", "```py\nOne\nTwo\nThree\nWe're done!\n```", "```py\norder = (\"Jason\", \"pumpkin spice latte\", 12)\n```", "```py\nprint(order[1])  # prints \"pumpkin spice latte\"\n```", "```py\norders = (\"pumpkin spice latte\",)\n```", "```py\nfrom collections import namedtuple\n\nCoffeeOrder = namedtuple( ❶ \"CoffeeOrder\", ❷('item', 'addons', 'to_go'))\n\norder = CoffeeOrder('pumpkin spice latte', ('whipped cream',), True)\nprint( ❸ order.item)  # prints 'pumpkin spice latte'\nprint( ❹ order[2])    # prints 'True'\n```", "```py\nspecials = [\"pumpkin spice latte\", \"caramel macchiato\", \"mocha cappuccino\"]\n```", "```py\nprint(specials[1])      # prints \"caramel macchiato\"\n```", "```py\ndrink = specials.pop()  # return and remove last item\nprint(drink)            # prints \"mocha cappuccino\"\nprint(specials)         # prints ['pumpkin spice latte', 'caramel macchiato']\n```", "```py\ndrink = specials.pop(1)  # return and remove item [1]\nprint(drink)             # prints \"caramel macchiato\"\nprint(specials)          # prints ['pumpkin spice latte']\n```", "```py\nspecials.append(\"cold brew\")  # inserts item at end\nprint(specials)               # prints ['pumpkin spice latte', 'cold brew']\n```", "```py\nspecials.insert(1, \"americano\")  # inserts as item [1]\nprint(specials)                  # prints ['pumpkin spice latte', 'americano', 'cold brew']\n```", "```py\nfrom collections import deque\ncustomers = deque(['Daniel', 'Denis'])\n```", "```py\ncustomers.append('Simon')\nprint(customers)  # prints deque(['Daniel', 'Denis', 'Simon'])\n```", "```py\ncustomer = customers.popleft()\nprint(customer)   # prints 'Daniel'\nprint(customers)  # prints deque(['Denis', 'Simon'])\n```", "```py\ncustomers.appendleft('James')\nprint(customers)  # prints deque(['James', 'Denis', 'Simon'])\n```", "```py\nlast_in_line = customers.pop()\nprint(last_in_line)  # prints 'Simon'\n```", "```py\nprint(customers)  # prints deque(['James', 'Denis'])\n```", "```py\nraffle = {'James', 'Denis', 'Simon'}\n```", "```py\nraffle.add('Daniel')\nraffle.add('Denis')\nprint(raffle)  # prints {'Daniel', 'Denis', 'Simon', 'James'}\n```", "```py\nraffle.discard('Simon')\nprint(raffle)  # prints {'Daniel', 'Denis', 'James'}\n```", "```py\nwinner = raffle.pop()\nprint(winner)  # prints arbitrary item of set, e.g. 'Denis'\n```", "```py\nraffle = {'Kyle', 'Denis', 'Jason'}\nprev_winners = frozenset({'Denis', 'Simon'})\n```", "```py\nraffle -= prev_winners  # remove previous winners\nprint(raffle)           # prints {'Jason', 'Kyle'}\n```", "```py\nwinner = raffle.pop()\nprint(winner)  # prints arbitrary item of set, e.g. 'Kyle'\n```", "```py\nmenu = {\"drip\": 1.95, \"cappuccino\": 2.95}\n```", "```py\nprint(menu[\"drip\"])  # prints 1.95\n```", "```py\nmenu[\"americano\"] = 2.49\nprint(menu)  # prints {'drip': 1.95, 'cappuccino': 2.95, 'americano': 2.49}\n```", "```py\ndel menu[\"americano\"]  # removes \"americano\" from dictionary\nprint(menu)            # prints {'drip': 1.95, 'cappuccino': 2.95}\n```", "```py\nmenu = {'drip': 1.95, 'cappuccino': 2.95, 'americano': 2.49}\n\ndef checkout(order):\n    try:\n        print(f\"Your total is { ❶ menu[order]}\")\n    except KeyError:\n        print(\"That item is not on the menu.\")\n\ncheckout(\"drip\")  # prints \"Your total is 1.95\"\ncheckout(\"tea\")   # prints \"That item is not on the menu.\"\n```", "```py\nmenu = {'drip': 1.95, 'cappuccino': 2.95, 'americano': 2.49}\n\ndef checkout(order):\n  ❶ if order in menu:\n        print(f\"Your total is { ❷ menu[order]}\")\n    else:\n        print(\"That item is not on the menu.\")\n\ncheckout(\"drip\")  # prints \"Your total is 1.95\"\ncheckout(\"tea\")   # prints \"That item is not on the menu.\"\n```", "```py\nfrom collections import deque\n\ncustomers = deque(['Kyle', 'Simon', 'James'])\n```", "```py\nfirst, second, third = customers\nprint(first)   # prints 'Kyle'\nprint(second)  # prints 'Simon'\nprint(third)   # prints 'James'\n```", "```py\nfrom collections import deque\n\ncustomers = deque(['Kyle', 'Simon', 'James'])\n**customers.append('Daniel')**\n```", "```py\nfirst, second, third = customers  **# raises ValueError**\nprint(first)                      # never reached\nprint(second)                     # never reached\nprint(third)                      # never reached\n```", "```py\nfirst, second, third**, _** = customers\nprint(first)    # prints 'Kyle'\nprint(second)   # prints 'Simon'\nprint(third)    # prints 'James'\n```", "```py\nfirst, second, **_, _** = customers\nprint(first)   # prints 'Kyle'\nprint(second)  # prints 'Simon'\n```", "```py\nbaristas = ('Jason'**,**)\nbarista, = baristas\nprint(barista)  # prints 'Jason'\n```", "```py\nfirst, second, ***rest** = customers\nprint(first)    # prints 'Kyle'\nprint(second)   # prints 'Simon'\nprint(**rest**)     # prints ['James', 'Daniel']\n```", "```py\nfirst, *middle, last = customers\nprint(first)    # prints 'Kyle'\nprint(middle)   # prints ['Simon', 'James']\nprint(last)     # prints 'Daniel'\n```", "```py\n*_, second_to_last, last = customers\nprint(second_to_last)  # prints 'James'\nprint(last)            # prints 'Daniel'\n```", "```py\nmenu = {'drip': 1.95, 'cappuccino': 2.95, 'americano': 2.49}\n```", "```py\na, b, c = menu\nprint(a)  # prints 'drip'\nprint(b)  # prints 'cappuccino'\nprint(c)  # prints 'americano'\n```", "```py\na, b, c = **menu.values()**\nprint(a)  # prints 1.95\nprint(b)  # prints 2.95\nprint(c)  # prints 2.49\n```", "```py\na, b, c = **menu.items()**\nprint(a)  # prints ('drip', 1.95)\nprint(b)  # prints ('cappuccino', 2.95)\nprint(c)  # prints ('americano', 2.49)\n```", "```py\n(a_name, a_price), (b_name, b_price), *_ = menu.items()\nprint(a_name)    # prints 'drip'\nprint(a_price)   # prints 1.95\nprint(b_name)    # prints 'cappuccino'\nprint(b_price)   # prints 2.95\n```", "```py\norder = ['venti', 'no whip', 'mocha latte', 'for here']\n\nmatch order:\n    case ('tall', *drink, 'for here'):\n        drink = ' '.join(drink)\n        print(f\"Filling ceramic mug with {drink}.\")\n    case ['grande', *drink, 'to go']:\n        drink = ' '.join(drink)\n        print(f\"Filling large paper cup with {drink}.\")\n    case ('venti', *drink, 'for here'):\n        drink = ' '.join(drink)\n        print(f\"Filling extra large tumbler with {drink}.\")\n```", "```py\norder = {\n    'size': 'venti',\n    'notes': 'no whip',\n    'drink': 'mocha latte',\n    'serve': 'for here'\n}\n\nmatch order:\n    case {'size': 'tall', 'serve': 'for here', 'drink': drink}:\n        print(f\"Filling ceramic mug with {drink}.\")\n    case {'size': 'grande', 'serve': 'to go', 'drink': drink}:\n        print(f\"Filling large paper cup with {drink}.\")\n    case {'size': 'venti', 'serve': 'for here', 'drink': drink}:\n        print(f\"Filling extra large tumbler with {drink}.\")\n```", "```py\norder = {\n    'size': 'venti',\n    'notes': 'no whip',\n    'drink': 'mocha latte',\n    'serve': 'for here'\n}\n\nmatch order:\n    case {'size': 'tall', 'serve': 'for here', ****rest}**:\n        **drink = f\"{rest['notes']} {rest['drink']}\"**\n        print(f\"Filling ceramic mug with {drink}.\")\n    case {'size': 'grande', 'serve': 'to go', ****rest}**:\n        **drink = f\"{rest['notes']} {rest['drink']}\"**\n        print(f\"Filling large paper cup with {drink}.\")\n    case {'size': 'venti', 'serve': 'for here', ****rest}**:\n        **drink = f\"{rest['notes']} {rest['drink']}\"**\n        print(f\"Filling extra large tumbler with {drink}.\")\n```", "```py\nmatch order:\n    case {'size': 'tall', 'serve': 'for here'}:\n        drink = f\"{**order**['notes']} {**order**['drink']}\"\n        print(f\"Filling ceramic mug with {drink}.\")\n    case {'size': 'grande', 'serve': 'to go'}:\n        drink = f\"{**order**['notes']} {**order**['drink']}\"\n        print(f\"Filling large paper cup with {drink}.\")\n    case {'size': 'venti', 'serve': 'for here'}:\n        drink = f\"{**order**['notes']} {**order**['drink']}\"\n        print(f\"Filling extra large tumbler with {drink}.\")\n```", "```py\nspecials = [\"pumpkin spice latte\", \"caramel macchiato\", \"mocha cappuccino\"]\nprint(specials[1])  # prints \"caramel macchiato\"\nspecials[1] = \"drip\"\nprint(specials[1])  # prints \"drip\"\n```", "```py\nspecials = [\"pumpkin spice latte\", \"caramel macchiato\", \"mocha cappuccino\"]\nprint(**specials.__getitem__(1)**)  # prints \"caramel macchiato\"\n**specials.__setitem__(1, \"drip\")**\nprint(**specials.__getitem__(1)**)  # prints \"drip\"\n```", "```py\n[`start`:`stop`:`step`]\n```", "```py\norders = [\n    \"caramel macchiato\",\n    \"drip\",\n    \"pumpkin spice latte\",\n    \"drip\",\n    \"cappuccino\",\n    \"americano\",\n    \"mocha latte\",\n]\n```", "```py\nthree_four_five = orders[3:6]\nprint(three_four_five)  # prints ['drip', 'cappuccino', 'americano']\n```", "```py`One important rule: `start` must always refer to an item that comes before `stop`. By default, lists are traversed first to last, so the `start` must be less than `stop`.    A slice doesn’t require all three arguments. If you leave out `start`, the slice begins at the first element. If you leave off `stop`, the slice finishes with the final element.    If I wanted all the items in the list except the first four, I’d use this:    ```", "```py    Listing 9-55: *slice_orders.py:3*    I start at index `4`. Then, since I didn’t specify a `stop` after the required colon, the slice includes the rest of the items up to the very end of the list.    I can access the first two items in the list this way:    ```", "```py    Listing 9-56: *slice_orders.py:4*    I didn’t specify a start before the colon, so it defaults to the beginning of the list. The end, which is *exclusive*, is `2`, so the slice includes all items before index `2`. This gives me the first two items in the list.    ### Negative Indices    I can also use negative numbers as indices, which enable me to count backward from the end of the list or tuple. For example, an index of `-1` refers to the last item in the list:    ```", "```py    Listing 9-57: *slice_orders.py:5*    Negative indices work with slicing, too. For example, if I wanted to get the three orders at the end of the list, I could use this:    ```", "```py    Listing 9-58: *slice_orders.py:6*    The slice starts at the third index from the end (`-3`) and goes to the end. When determining negative indices, remember that `-1` is the last item—that is, it’s one index before the “end,” which *has* no index.    If I wanted the third-from-last and second-from-last orders, but not the last order, I could define both `start` and `stop` as negative indices:    ```", "```py    Listing 9-59: *slice_orders.py:7*    Remember, the `start` index must always come before the `stop`, and lists are traversed from left to right, by default. Thus, the `start` must be `-3`, or third-from-end, and the `stop` must be `-1`; so the last included index is `-2`, or second-from-end.    ### Steps    By default, lists are traversed first to last, from the lowest index to the highest, one by one. The third part of the slice notation, `step`, lets you change that behavior so you can better control which values are included in the slice, and in what order.    For example, I could create a slice containing every other coffee order, starting from the second order, by setting the `step` part to `2`:    ```", "```py    Listing 9-60: *slice_orders.py:8*    I `start` the slice at index `1`. Since I haven’t specified a `stop` index, the slice goes to the end of the list. The `step` argument of `2` tells Python to grab every second item. With the `orders` list, that means the slice will consist of the items at indices `1`, `3`, and `5`.    A negative `step` argument reverses the direction the list or tuple is read in. For example, a `step` of `-1`, with no `start` or `stop`, will return a reversed version of the entire `orders` list:    ```", "```py    Listing 9-61: *slice_orders.py:9*    You’ll notice I had to precede the `-1` with two colons, to delineate that no values had been specified for `start` or `stop`. Otherwise, Python would have no way to know that the `-1` was for the third argument.    I can even get a reversed version of the data sliced in [Listing 9-60](#listing9-60), although there’s a bit of a trick to it. Here’s the code:    ```", "```py    Listing 9-62: *slice_orders.py:10*    The `step` of `-2` means the slice grabs every other value in reverse order. The list is traversed from right to left. That changes the behavior of `start` and `stop`. I `start` at the second-to-last item (`-2`), but because I omitted a value for `stop`, it defaults to the beginning of the list, instead of the end. If I left off both `start` and `stop`, I’d get every other value in reverse, starting from the last item.    This reversed behavior radically affects what values are used for `start` and `stop`, and this misunderstanding can easily result in bugs. For example, if I want the third, fourth, and fifth items in reverse order, my first attempt might look like the following, which would *not* work:    ```", "```py    Listing 9-63: *slice_orders.py:11a*    The negative `step` value means I’m traversing the list in reverse order. Remember that `start` must always be traversed before `stop`.    If I traverse the list from ending to beginning, then I have to reverse the `start` and `stop` values, like so:    ```", "```py    Listing 9-64: *slice_orders.py:11b*    Moving backward through the list, the slice starts at index `5` and stops at index `2`, which is not included.    ### Copy with Slice    One more thing to know about slices is that they always return a new list or tuple with the selected items; the original list or tuple still exists as it was. This code creates a perfect shallow copy of the list:    ```", "```py    Listing 9-65: *slice_orders.py:12*    Since neither `start` nor `stop` is specified, the slice includes all items.    ### Slice Objects    You can also directly create a `slice` object for reuse by using the `slice()` initializer method.    ```", "```py    The `start`, `stop`, and (optionally) `step` values are passed as positional arguments. In practice, this approach is more limited than regular slice notation, since it is not possible to omit the `stop` value.    In any case, I can now use `my_slice` in place of slice notation, such as in the `print()` statement above.    ### Slicing on Custom Objects    If you want to implement slicing in your own objects, you’ll only need to accept a slice object as an argument on the same special methods needed to make the object subscriptable: `__getitem__(self, sliced)`, `__setitem__(self, sliced)`, and `__delitem__(self, sliced)`. Then, you can get the three parts of the slice object with `sliced.start`, `sliced.stop`, and `sliced.step`.    A decent example for this would be pretty involved, so I’ll leave this explanation here.    ### Using islice    You can still slice a deque or any collection that isn’t subscriptable by using `itertools.islice()`, which behaves the same as slice notation, except that it doesn’t support negative values for any of the parameters.    The arguments that `islice()` accepts are ordered, so you have to remember the order:    ```", "```py    For example, `islice()` can take a slice from a dictionary, which cannot be sliced by ordinary slice notation because it isn’t subscriptable. Here, I get every other item from the dictionary:    ```", "```py    Listing 9-66: *islice_orders.py*    I pass the dictionary as a list of tuples to the `islice` ❶, followed by the `start`, `stop`, and `step` values necessary to take every other item. Then, I create a new dictionary from the `islice` and bind it to `menu`. Running that code produces the following output:    ```", "```py    ## The in Operator    You can use the `in` operator to quickly check whether a particular value is contained in any collection.    As before, I’ll start with a list of orders:    ```", "```py    Listing 9-67: *in_orders.py:1*    For example, I might need to see if anyone wants a mocha cappuccino in my `orders` list before I open the new bottle of chocolate syrup:    ```", "```py    Listing 9-68: *in_orders.py:2*    I place the value I’m looking for to the left of the `in` operator and the collection I’m searching to the right. The operator returns `True` if at least one instance of the value is found in the collection; otherwise, it returns `False`.    You can also check whether a list omits a specific item. For example, I might decide to shut off the coffee maker if no one wants any drip coffee right now. I can check if there are any orders for `\"drip\"` with this code:    ```", "```py    Listing 9-69: *in_orders.py:3*    The addition of `not` inverts the `in` condition, so the expression evaluates to `True` if the value is *not* found in the collection.    You can add support for the `in` operator to your custom classes by implementing the special method `__contains__()`.    ## Checking Collection Length    To find out how many items a collection contains, use the `len()` function. That’s all there is to it. For example, if I have a list of waiting customers, I can find out how many customers are standing in line:    ```", "```py    Listing 9-70: *len_customers.py*    The `len()` function returns the number of items in `customers` as an integer. Since there are three items in `customers`, the value `3` is returned. In the case of a dictionary, `len()` would return the number of key-value pairs.    You’ll use `len()` less than you might expect when you employ iteration, which changes the way you traverse through collections such that you seldom need to know the length.    You don’t even need `len()` when testing whether a collection is empty. If a collection contains content, it is “truthy,” meaning it can be evaluated directly to `True`. Otherwise, if the collection is empty, it is “falsey,” meaning it evaluates directly to `False`. I’ll use this to see if there are any customers in the café right now.    ```", "```py    Listing 9-71: *no_customers.py*    Because `customers` is empty, it is “falsey,” meaning it evaluates to `False` in a boolean context, such as when used as an expression ❶. Therefore, when the above program is run, the following is displayed:    ```", "```py    Sure enough, if I directly cast `customers` to a boolean value, it prints `False`.    Usually, the only time you’ll use `len()` is when you need the length of a collection as a piece of data in its own right, such as when calculating the average number of orders per day for the week:    ```", "```py    Listing 9-72: *average_orders.py*    The `average_orders` is printed to the screen:    ```", "```py    ## Iteration    All collections in Python are designed to work with *iteration*, by which you can directly access items on demand, one by one. Iteration patterns aren’t even limited to collections. You can leverage this concept to generate or process data *iteratively*: “on demand,” instead of all up front. You’ll see this in depth in Chapter 10.    Before you can start using iteration effectively, you must understand how it actually works. Then, you can use it to access, sort, and process items in collections.    ### Iterables and Iterators    One of the most compelling features of Python is its approach to iteration, by way of two fairly straightforward concepts: *iterables* and *iterators*.    An *iterable* is any object whose items or values can be accessed one at a time, on demand. For example, a list is an iterable; you can iterate over each item in the list, one by one. For an object to be iterable, it must have an associated iterator, which is returned from the object’s instance method `__iter__()`.    An *iterator* is the object that performs the actual iteration, providing ready access to the next item in the iterable it is traversing. To be an iterable, an object needs to implement the special method `__next__()`, which accepts no parameters and returns a value. This method advances to the next item in the iterable it traverses and returns that value.    Iterators must also implement the method `__iter__()`, which returns the iterator object itself (usually `self`). This convention is necessary so that code that accepts an iterable can also accept an iterator without any difficulty, as you’ll see shortly.    That’s really all there is to it! All collections are iterables, and each has at least one dedicated companion iterator class.    I’ll implement a custom iterator class later in this chapter.    ### Manually Using Iterators    Before introducing automatic iteration, it’s helpful to understand what is going on behind the scenes when using an iterator.    To demonstrate this, I’ll traverse the values in a list, using an iterator I manually access and control. I’ll go through this example twice: once, directly calling the special methods; and another time, allowing Python to call them implicitly.    I’ll start by defining a list, which is an iterable:    ```", "```py    Listing 9-73: *specials_iteration.py:1*    To iterate over the collection, I first acquire an iterator:    ```", "```py    Listing 9-74: *specials_iteration.py:2*    A list, like all iterables, implements the special method `__iter__()`, which returns an iterator object for this list. I acquire two separate iterators here, each of which can operate independently of the other.    When I check the data type of `first_iterator`, I see it’s an instance of the class `list_iterator`, as seen in the output:    ```", "```py    I use the iterator object to access the items in the list `specials`:    ```", "```py    Listing 9-75: *specials_iteration.py:3*    The first call to the iterator’s `__next__()` method advances to the first item in the list and returns its value, which I bind to `item` and print to the screen, outputting the following:    ```", "```py    A subsequent call advances to and returns the second item:    ```", "```py    Listing 9-76: *specials_iteration.py:4*    That outputs the following:    ```", "```py    Each iterator tracks its position in the iterable separately. If I call the `__next__()` method on `second_iterator`, it advances to and returns the first item in the list:    ```", "```py    Listing 9-77: *manual_iteration.py:5*    Printing `item` shows the first item in the list:    ```", "```py    Yet `first_iterator` still remembers its own position and can be advanced to the third item in the list:    ```", "```py    Listing 9-78: *specials_iteration.py:6*    That prints the value of the third item:    ```", "```py    Once an iterator has run through all the items in the iterable being traversed, calling `__next__()` again raises the special exception `StopIteration`:    ```", "```py    Listing 9-79: *specials_iteration.py:7*    Thankfully, I don’t need to call `__iter__()` and `__next__()` manually, in any case. Instead, I can use Python’s built-in functions `iter()` and `next()` and pass in the iterable or iterator, respectively. The special methods will be invoked behind the scenes.    Here’s that same example again, but now using those built-in functions:    ```", "```py    Listing 9-80: *specials_iteration.py:2b-7b*    As you can see, there’s a lot of repetition in this manual approach, which suggests that I could use a loop to handle iteration. In fact, using a `for` loop is the standard way to work with iteration, as it calls `iter()` and `next()` implicitly, so I don’t have to. However, to drive the underlying mechanics home first, I’ll wrap this same manual iteration logic in a `while` loop:    ```", "```py    Listing 9-81: *specials_iteration_v2.py*    I first acquire an iterator for the `specials` list ❶. Then, in an infinite `while` loop, I try to access the next value in the iterable by passing the iterator to `next()` ❷. If this raises the `StopIteration` exception ❸, I know I’ve traversed all the items in the `specials` list, and I break out of the loop with the `break` keyword. Otherwise, I print out the `item` I receive from the iterator.    Although it’s helpful to understand how to manually handle iterators, you will seldom need to! A `for` loop would almost always handle the example in [Listing 9-81](#listing9-81):    ```", "```py    Listing 9-82: *specials_iteration_v3.py*    This eliminates the need to directly acquire an iterator. I’ll cover this approach next.    ### Iterating with for Loops    One very helpful rule for loops and iteration in Python is that *you never need a counter variable for loop control*. In other words, virtually none of the traditional loop algorithms you’re used to apply here! Python always has a better way, mainly because iterables can directly control `for` loops.    Take another look at that queue of people at the Uncomment Café. For each person in line, the barista would take an order, make it, and deliver it. Here’s how I would do that. (For expediency of example, this code merely announces that each order is ready.)    ```", "```py    Listing 9-83: *iterate_orders_list.py*    I loop through the `customers` list, which is an iterable. On each iteration, I bind each current item to `customer` so it works in the suite of the loop like any other variable ❶.    For each item in the list, I print a string announcing the order for the `customer` for that iteration. Here’s the output of that code (truncated):    ```", "```py    A linear collection is pretty straightforward (no pun intended). Iterables with multiple values in any given item, such as from the `items()` dictionary view or from a two-dimensional list, must be treated differently.    To demonstrate this, I’ll rewrite `customers` as a list of tuples, with each tuple containing a name and a coffee order. Then, I’ll loop through them to announce their order:    ```", "```py    Listing 9-84: *iterate_orders_dict.py:1*    In the `for` loop, I iterate over the list `customers`. On the left, I unpack each tuple item on the list into two names: `customer` and `drink` ❶.    Here’s the resulting output:    ```", "```py    ### Sorting Collections in Loops    Loops also allow you to do more advanced processing of this data. For example, let’s say everyone could submit their orders through an app. (We are programmers, after all.)    I might want to sort the list of orders alphabetically, so I can search through them more easily. However, I still want to follow a first-come, first-served rule. Therefore, I don’t want to modify the original `customers` list, since its sequence still matters:    ```", "```py    Listing 9-85: *iterate_orders_dict.py:2*    The `sorted()` ❶ function returns a list of the sorted items from whatever collection is passed to it. By default, it will sort by the first value in an item, in ascending order. In this case, the first item is the customer name, but I want to sort by the name of the drink ordered instead. I change this behavior by passing a callable *key function* to the `key=` named argument ❷. This callable, a `lambda` in this case, must accept an item as an argument and return the value I want to sort that item by. In this case, I want to sort by the second item in each tuple, which I return via `x[1]` ❸. Through all of this, `customers` remains unchanged.    You’ll also notice that I use the underscore in the unpacking list to ignore the first value in each tuple, the customer name, because I don’t need it in this loop. This is usually the best way to pick and choose items from a small tuple in a `for` loop. On the other hand, if each item were a collection with many subitems, it might work better to bind the entire item to one name and access what I need from it in the suite of the loop.    Running that code, I get this output for this part:    ```", "```py    ### Enumerating Loops    You never need a counter variable for loop control. This will come as a major paradigm shift to many developers, who are used to C-style loop control. You may wonder what to do if you need the index itself.    Python offers `enumerate()` for such situations. The added benefit of using this function instead of manual indices is that it works with all iterables, even those that aren’t subscriptable.    I’ll use `enumerate()` to see the order of each person in line, along with their order:    ```", "```py    Listing 9-86: *iterate_orders_dict.py:3*    Here, `enumerate()` returns a tuple with the count (which is sometimes, coincidentally, the index) as an integer in the first position and the item from the collection in the second. By default, the count would start at 0, but I want the first person in line to be displayed as “`#1`”—so I override this default by passing `1` to `start=`.    Since my collection consists of tuples, I have to use compound unpacking with parentheses to get each item from within the tuple item ❶. Once I have the number, the customer name, and the drink, I compose those pieces together into a single `print` statement.    The output of this part of the code looks like this:    ```", "```py    ### Mutation in Loops    You’ll notice that I’ve been using a `list` for my queue of customers, whereas before, I used a `deque` and removed customers from the queue after serving them. This is preferable, so I’ll start by defining the `customers` deque:    ```", "```py    Listing 9-87: *process_orders.py:1*    Combining the knowledge so far, you might think, “Aha! I only need to use a `deque` and `popleft()` after each customer.” Yet, if I try to follow that approach, it won’t run:    ```", "```py    Listing 9-88: *process_orders.py:2a*    The issue here is that I’m mutating the collection while I’m iterating over it! This can confuse the iterator, potentially causing all sorts of undefined behavior, so Python tries not to allow it. Attempting to mutate a collection while iterating over it, whether you’re adding, removing, or reordering items, usually raises a `RuntimeError`.    There are two ways to fix this problem. The first is to make a copy of the collection before iterating over it:    ```", "```py    Listing 9-89: *process_orders.py:2b*    I had to use the `copy()` method, since deques don’t support the slice notation that would have allowed the snazzier colon in square brackets (`[:]`). Because the loop is iterating over a copy of the collection ❶, I am free to mutate the original however I like ❷, although this is seldom considered the ideal solution.    Since I want to remove items until the collection is emptied, I can use a `while` loop instead of a `for` loop:    ```", "```py    Listing 9-90: *process_orders.py:2c*    The `while` loop iterates until the collection `customers` indicates it is empty by evaluating to `False`. On each iteration, I use `popleft()` to access the next item, since that both returns and removes the item from the collection ❷. Unpacking is done in the suite of the loop ❶.    On the other hand, if I wanted to expand or reorder the contents of a collection while iterating over it, I’d need to create a new collection.    To demonstrate this, here is a rather convoluted example. For every drink ordered, I want to create a second serving of the same drink later. (I’ll leave the purpose behind this to your imagination.) In my first attempt at this, I’ll do this the wrong way, which won’t work.    As usual, I start by defining my list:    ```", "```py    Here, I’m attempting to add the same drink to the end of the list I’m iterating over:    ```", "```py    Listing 9-91: *double_orders.py:2a*    This example is particularly evil because, unlike the prior example, a `RuntimeError` is not raised when I attempt to mutate `orders` from within the suite of the loop. Instead, because there’s always a new item at the end of the list `orders`, the loop keeps running until the program runs out of memory and dies. Yuck.    To correct this, I need to create a new list for appending to:    ```", "```py    Listing 9-92: *double_orders.py:2b*    I define `new_orders` as a copy of `orders`, using slice notation to create the exact copy. Then, I iterate over `orders`, but I append to `new_orders`. Finally, when I’m done, I rebind `orders` to the new list, throwing the old list away.    ### Loop Nesting and Alternatives    As you might expect, you can nest loops. One situation where I might use this would be when running a coffee-tasting event where I wanted each guest to taste each type of coffee. Here’s a program to tell me who to give what sample to.    I start by defining two lists: one of samples and the other of guests:    ```", "```py    Listing 9-93: *tasting_lists.py:1*    Now I iterate over both lists at once:    ```", "```py    Listing 9-94: *tasting_lists.py:2a*    The outer loop iterates over the list `samples`. For each item in `samples`, the inner loop iterates over the list of `guests`, giving each one a sample.    Running that code produces the following output (truncated for brevity):    ```", "```py    Using nested loops is seldom considered the best solution in Python, for a couple of reasons. First, nesting itself is something Python developers like to avoid, as suggested by The Zen of Python:    > Flat is better than nested.    Nested structures are less readable and more *brittle*, meaning they are easily mistyped, due to their reliance on multiple levels of indentation. Python developers conventionally like to avoid any unnecessary nesting. A readable solution that is *flatter* (with less nesting) will almost invariably be preferred.    Second, *it’s impossible to break out of nested loops*. The `continue` and `break` keywords can only control the loop they’re directly in, not any outer or inner loops thereof. There are some “clever” ways around this, like putting the nested loop in a function and breaking out of the function by using a `return` statement. However, these hacks add complexity, nesting layers, or both, and they are thus discouraged.    Instead, anytime you’re thinking of using a nested loop, consider whether there are any viable alternatives. In the case of my example, I can achieve the same result as before in a single loop by using the `product()` function from the incredibly versatile `itertools` module (which I’ll introduce properly later):    ```", "```py    Listing 9-95: *tasting_lists.py:2b*    The `itertools.product()` function combines two or more iterables into a single iterable that contains tuples with every possible combination of items ❷. I unpack each of these tuples into names I can use to access the individual values in the suite of the loop ❶.    The output is the exact same as before.    Between the built-in iteration functions and the `itertools` module, Python has functions to cover most common situations where nested loops might ordinarily be used. If nothing already exists to do what you want, you can always write your own iterable function (called a *generator*; see Chapter 10) or an iterable class (see later in this chapter).    It may be impossible to avoid nested loops in most cases, but you’ll often find there is a cleaner, flatter solution.    ## Iteration Tools    Python has a whole bevy of handy tools for iterating over containers. For most of these, the official documentation is your friend. I’ll skim through some of the most common and useful tools here.    ### Basic Built-in Tools    A number of iteration tools are built into the language itself. Each of these requires you to pass at least a single iterable.    *   `all()` returns `True` if every item in the iterable evaluates to `True`. *   `any()` returns `True` if any item in the iterable evaluates to `True`. *   `enumerate()` (seen earlier) is an iterable that returns a tuple for each item in the iterable you pass to it. The first value in the tuple is the item’s “index,” and the second is the item value itself. This even works with iterables that aren’t subscriptable. This tool optionally accepts a `start=` argument, which defines the integer value to use as the first index. *   `max()` returns the largest item in the iterable. It optionally accepts a `key=` argument, which is usually a callable specifying what part of a collection item to sort on. *   `min()` is the same as `max()`, except that it returns the smallest item in the iterable. *   `range()` is an iterable that returns a sequence of integers from an optional starting value (default `0`) to one less than an ending value. An optional third argument can define the step. The `range(3)` iterable produces the values `(0,1,2)`, while `range(2,5)` produces the values `(2,3,4)`, and `range(1,6,2)` produces the values `(1,3,5)`. *   `reversed()` returns an iterator that iterates through the iterable, backward.     `sorted()` returns a list containing all the items of the iterable, sorted. It optionally accepts a `key=` argument, which is used in the same way as on `max()`. *   `sum()` returns the sum of all the items in the iterable, so long as all the items are numeric values. It optionally accepts a `start=` argument, which is the initial value of the sum.    The last three built-in iterables I’ll cover are more complicated, so I’ll detail each in the following subsections.    ### Filter    The `filter` iterable allows you to search for values in an iterable that fit a particular criterion. Say I have a list of orders and I want to find out how many of them call for drip coffee:    ```", "```py    Listing 9-96: *orders_filter.py*    To create the `filter` instance, I call its initializer ❷ and pass two arguments: the callable to use for filtering ❸ and the iterable being filtered ❹. I convert this `filter` iterable to a list ❶ before assigning that list to `drip_orders`.    Remember, the callable you use for filtering can be a function, a lambda, or anything else that can be treated as a function. Whatever the callable is, it should return a value that can be evaluated to a boolean, indicating whether the value passed to it should be included in the end result. In this case, that filtering callable will be a lambda, which returns `True` if the string `'drip'` is anywhere in the value passed to it ❸. Because the logic is simple, the lambda makes sense, but if I had wanted more complicated test logic, I would have written a proper function instead. The `filter` iterable will contain those items that pass the test specified by the lambda.    Finally, I print out the number of items in `drip_orders` ❺, which is the number of items that `filter` extracted from `orders`.    It just goes to show, you can even make a coffee filter with Python!    ### Map    The `map` iterable will pass every item in an iterable to a callable as an argument. Then, it will pass the returned value back as its own current iterative value.    In my café, I can define a function for brewing and then use `map()` to apply that function to each of the pending orders.    I’ll start by defining my orders list:    ```", "```py    Listing 9-97: *brew_map.py:1*    I’ll also define a function to handle brewing:    ```", "```py    Listing 9-98: *brew_map.py:2*    This function accepts an order as its sole argument, and then it returns that same order after it has been “made.”    I want to call `brew()` for each item in `orders`, passing each current order as an argument. For that, I’ll use `map()`:    ```", "```py    Listing 9-99: *brew_map.py:3*    In my `for` loop, I create an instance of the `map` iterable, passing the `brew()` function and the `orders` collection to the `map` initializer.    For each item in `orders`, the `brew()` function is called, and the item is passed as the argument. The value returned by `brew()` is then passed back by the `map` to the loop, which binds it to `order`, so it can be used in the suite of the loop. This process repeats until every item in `orders` has been iterated over.    You can also use `map()` with multiple iterables, with the current item of each being used as one of the arguments to the callable. Once one of the iterators has run out of values, `map` is done. Here’s how I would use it to add the cost and tip for multiple orders:    ```", "```py    Listing 9-100: *grand_total_map.py*    I have two lists: `cost` contains the price of each order, and `tip` contains the tip given for each order. In the loop, I create a `map` that calls the `operator.add()` function, passing the current item from `cost` as the first argument and the current item from `tip` as the second argument. The sum of the two values is returned and bound to `total`. I print that `total` value out, formatting it to display values to two decimal places.    Running that code outputs this:    ```", "```py    ### Zip    The `zip` iterable combines multiple iterables together. On each iteration, it takes the next value for each iterable in turn and packs them all together into a tuple. Once one of the iterables has been exhausted, `zip` stops.    This is particularly useful if you want to create a dictionary from multiple lists, although you could populate any collection using `zip`.    Here, I start with two lists. One list represents the regular customers, and one represents their usual orders. I want to turn this into a dictionary, so I can look up “the usual” by customer name:    ```", "```py    Listing 9-101: *usuals_zip.py*    I create a `zip` iterable ❷ whose items are tuples derived from the items in the `regulars` ❸ and `usuals` ❹ iterables: `('William', 'french press')`, `('Devin', 'double-shot espresso')`, and so forth. Then, I pass this iterable to the `dict()` initializer ❶, creating a dictionary (`usual_orders`) with the first item of each tuple as the key and the second item of each tuple as the value.    I’ll demonstrate that this works by looking up and printing Devin’s usual order:    ```", "```py    Listing 9-102: *usuals_zip.py*    The dictionary contains five items, since the shortest iterable, `regulars`, had five items. As a result, the excess item in `usuals` (namely, `'drip'`) is ignored by `zip`.    ### Itertools    The `itertools` module contains many useful classes for working with iteration. Very few Python developers memorize all of these. They instead refer to the documentation via the website or the `help()` command, whenever the topic comes up.    Here are a few highlights. Understand that I’ll skip most of the optional arguments, for the sake of brevity:    1.  `accumulate` repeatedly performs a two-argument function and uses the result of each call as the first argument for the next call. The current item in the iterable is the second argument. On each iteration, the current result is returned. By default, this uses the `operator.add()` function. 2.  `chain` produces a list containing each item from each iterable passed to it, in order. `chain([1,2,3], [4,5,6])` would produce `1`, `2`, `3`, `4`, `5`, and `6`. 3.  `combinations` produces every possible subsequence of items in the provided iterable, with the specified number of items in each combination. `combinations([1,2,3], 2)` would produce `(1, 2)`, `(1, 3)`, and `(2, 3)`. 4.  `dropwhile` drops (skips) items in an iterable as long as some expression evaluates to `True`, and then it returns every item after that. So `dropwhile(lambda n:n!=42, [5,6,42,7,53])` would produce `42`, `7`, and `53`, since the predicate lambda returns `True` until it encounters the value `42`. 5.  `filterfalse` is the same as `filter`, except that it works in exactly the opposite manner: the callable must return `False` to include the item. 6.  `islice` performs slices on nonsubscriptable iterables. It is identical in behavior to slicing, except that it doesn’t support negative values for the `start`, `stop`, or `step`. 7.  `permutations` produces every possible permutation of the items in the provided iterable, with the specified number of items in each permutation. `permutations([1,2,3], 2)` would produce `(1, 2)`, `(1, 3)`, `(2, 1)`, `(2, 3)`, `(3, 1)`, and `(3, 2)`. 8.  `product` produces the Cartesian product of the provided iterables. `product([1,2], [3,4])` would produce `(1, 3)`, `(1, 4)`, `(2, 3)`, and `(2, 4)`. 9.  `starmap` behaves like `map`, except that it passes each item in the provided iterator as a starred argument. `starmap(func, [(1,2), (3,4)]` would call `func(1,2)` and then `func(3,4)`. 10.  `takewhile` behaves in exactly the opposite way as does `dropwhile`. It takes items from the provided iterator, as long as the provided predicate evaluates to `True`. As soon as the predicate evaluates to `False`, it ignores the rest of the items.    There are a few more classes in `itertools` besides these. Read the documentation for more information!    ## Custom Iterable Classes    Though Python offers plenty of collections and other iterables, there may arise a situation when you need to write your *own* iterable class. Thankfully, this is not difficult.    Often, you’ll write two classes: an *iterable* and a corresponding *iterator*. This is a matter of separation of concerns: the iterable is responsible for storing or generating values, while the iterator is responsible for tracking the current position in that iterable. This allows you to make multiple independent iterator instances for the same iterable.    There are situations where it is beneficial for a single class to be both an iterable and an iterator. One such situation occurs when the iterable object’s data is nonreproducible, such as with data streamed over a network. Another case is infinite iterators, which I’ll revisit in Chapter 10.    For now, I’ll stick with the typical two-class approach. Here’s a simple iterable class that I can use for tracking café patrons and the details of their orders. (In the real world, I probably wouldn’t solve the problem with a custom iterable class like this, but it works as an example.)    I’ll start by defining the iterable class for tracking customers:    ```", "```py    Listing 9-103: *cafequeue.py:1*    The class will have three instance attributes: `_queue`, a list containing customer names; `_orders`, a dictionary storing customer orders; and `_togo`, a dictionary storing whether the customer wants their order to go or not.    To make the class iterable, I define the `__iter__()` special method:    ```", "```py    Listing 9-104: *cafequeue.py:2*    The `__iter__()` method must return an instance of the corresponding iterator class. (I’ll define this class in a moment.)    To make this iterable class useful, I’d like to do some other things with it, besides iterate over its data. The `add_customer()` instance method will allow me to add a new customer:    ```", "```py    Listing 9-105: *cafequeue.py:3*    I will want to check how many customers are in line by using the `len()` built-in function, so I must define the `__len__()` special instance method:    ```", "```py    Listing 9-106: *cafequeue.py:4*    Remember, `len()` is only for when I actually need to work with the length of the queue itself. For example, if I wanted an LCD display in the cafe to show how many customers are in line, the code for that display could use `len()` on a `CafeQueue` object to get that data. Even so, I never use `len()` directly in the loop header as part of iteration.    Finally, I’d like to check whether a particular customer is in the queue, so I define the `__contains__()` special method:    ```", "```py    Listing 9-107: *cafequeue.py:5*    Now that I have the `CafeQueue` class, I can define the corresponding iterator class, which I’m calling `CafeQueueIterator`. Ordinarily, these two classes would be defined in the same module, as I’ve done here.    I’ll start with the iterator’s initializer:    ```", "```py    Listing 9-108: *cafequeue.py:6*    This iterator class is responsible for keeping track of its own position in the iterable. The initializer receives a single argument: the iterable instance associated with the iterator instance ❶.    This is why, in the iterable’s `__iter__()` method, I can use the line `return CafeQueueIterator(self)` (see [Listing 9-108](#listing9-108)). I pass the iterable instance to the iterator initializer, where it is stored as the instance attribute `_cafe`.    An iterator class must define the special method `__next__()`, which returns the next item in the iterable:    ```", "```py    Listing 9-109: *cafequeue.py:7*    The `__next__()` method is responsible for keeping track of the iterator’s position in the iterable. Iterables can be infinite (something I’ll cover in depth in Chapter 10), so there is no built-in means of stopping iteration. In `__next__()`, if I’ve iterated over all the items in the iterable ❶, I raise `StopIteration` ❷. Otherwise, after retrieving the current item from the iterable, I must update the iterator’s position ❸ before finally returning the item ❹.    Each item contains multiple elements, so I pack the data for an item into a tuple: `(``customer``,` `orders``,` `to_go``)`. This can be unpacked in a `for` loop during iteration. If you look at the `CafeQueue` class again ([Listing 9-103](#listing9-103)), you’ll notice that `orders` will be a tuple of varying length, containing each order for the customer.    The special method `__iter__()` must also be defined in an iterator class. This method is always expected to return an iterator, but since this instance *is* an iterator, `__iter__()` only needs to return `self`.    ```", "```py    Listing 9-110: *cafequeue.py:8*    Now that I have both my iterable (`CafeQueue`) and iterator (`CafeQueueIterator`) classes written, I can use them like any other collection. I create a new `CafeQueue` and populate it with data:    ```", "```py    Listing 9-111: *cafequeue.py:9*    Before I iterate over the collection, I’ll test using `len()` and `in`:    ```", "```py    Listing 9-112: *cafequeue.py:10*    I can see how many customers are in the queue with `len()` and check for individual customers using `in`. All’s well, so far!    I want to use this new iterable to automate making and delivering orders to the customers. Remember that each item in the iterable will be a tuple `(``customers``,` `orders``,` `to_go``)` and that `orders` is itself a tuple of unknown length. Although it’s simple in this example, you can imagine that brewing an order could theoretically be quite involved, so I’ll use the stand-alone `brew()` function from [Listing 9-98](#listing9-98) to handle each order:    ```", "```py    Listing 9-113: *cafequeue.py:11*    Nothing remarkable there.    So then, here’s the loop for working with the `CafeQueue` instance `queue`:    ```", "```py    Listing 9-114: *cafequeue.py:12*    The `for` loop iterates over `queue`, unpacking each item tuple into three names: `customer`, `orders`, and `to_go`.    I use a nested loop to pass each item in the `orders` tuple to the `brew()` function ❶. This particular `for` loop is pretty simple, so I can write it as a flat statement.    Finally, I use `to_go` to determine whether to announce the order is ready or to take it out to the customer’s table.    ## Wrapping Up    Iteration simplifies how one works with loops and collections. Practically any class can be an iterable if it defines an `__iter__()` method, which returns a corresponding iterator object. An iterator class keeps track of its position in traversing its corresponding iterable, and it must have a `__next__()` method for returning the next item in the iterable. All Python collections are iterables, and the language offers a number of useful iterator classes, including many in the `itertools` module.    Python’s `for` loop is designed specifically for working with iterables and iterators; it handles the calls to `__iter__()` and `__next__()` behind the scenes, allowing you to focus on what you want to do with each item instead.    Now’s a good time to get a coffee refill before we dive into the next chapter, wherein I’ll introduce the related concepts of *infinite iterators*, *generators*, and *generator expressions*. (Bring me back a pumpkin spice latte while you’re up there, hey?)```", "```py```", "```py import time sleepy = ['no pause', time.sleep(1), time.sleep(2)] # ...three second pause... print(sleepy[0])  # prints 'no pause' ```", "```py from itertools import product from string import ascii_uppercase as alphabet   def gen_license_plates():     for letters in ❶ product(alphabet, repeat=3):         letters = ❷ \"\".join(letters)         if letters == 'GOV':             continue        ❸ for numbers in range(1000):             yield f'{letters} {numbers:03}' ```", "```py license_plates = gen_license_plates() ```", "```py for plate in license_plates:     print(plate) ```", "```py AAA 000 AAA 001 AAA 002 `# --snip--` ZZZ 997 ZZZ 998 ZZZ 999 ```", "```py registrations = {}   def new_registration(owner):     if owner not in registrations:         plate = ❶ next(license_plates)         registrations[owner] = plate         return plate     return None ```", "```py # Fast-forward through several results for testing purposes. for _ in range(4441888):     next(license_plates) ```", "```py name = \"Jason C. McDonald\" my_plate = new_registration(name) print(my_plate) print(registrations[name]) ```", "```py GOW 888 GOW 888 ```", "```py from random import choice  colors = ['red', 'green', 'blue', 'silver', 'white', 'black'] vehicles = ['car', 'truck', 'semi', 'motorcycle', None] ```", "```py class Traffic:     def __iter__(self):         return self ```", "```py  def __next__(self):         vehicle = choice(vehicles)          if vehicle is None:             raise StopIteration          color = choice(colors)          return f\"{color} {vehicle}\" ```", "```py # merge into traffic count = 0 for count, vehicle in enumerate(Traffic(), start=1):     print(f\"Wait for {vehicle}...\")  print(f\"Merged after {count} vehicles!\") ```", "```py Wait for green car... Wait for red truck... Wait for silver car... Merged after 3 vehicles! ```", "```py from random import choice  colors = ['red', 'green', 'blue', 'silver', 'white', 'black'] vehicles = ['car', 'truck', 'semi', 'motorcycle', None] ```", "```py def traffic():     while True:         vehicle = choice(vehicles)          if vehicle is None:             return          color = choice(colors)         yield f\"{color} {vehicle}\" ```", "```py # merge into traffic count = 0 for count, vehicle in enumerate(**traffic()**, start=1):     print(f\"Wait for {vehicle}...\")  print(f\"Merged after {count} vehicles!\") ```", "```py Wait for white truck... Wait for silver semi... Merged after 2 vehicles! ```", "```py from random import choice  colors = ['red', 'green', 'blue', 'silver', 'white', 'black'] vehicles = ['car', 'truck', 'semi', 'motorcycle', None] ```", "```py def traffic():     while True:         vehicle = choice(vehicles)         color = choice(colors)         yield f\"{color} {vehicle}\" ```", "```py def car_wash(traffic, limit):     count = 0     for vehicle in traffic:         print(f\"Washing {vehicle}.\")         count += 1         if count >= limit:             traffic.close() ```", "```py car_wash(traffic(), 10) ```", "```py **queue = traffic()** car_wash(**queue**, 10) ```", "```py **next(queue)**  # raises StopIteration, since car_wash called close() ```", "```py Washing red motorcycle. Washing red semi. `# --snip--` Washing green semi. Washing red truck. ```", "```py def traffic():     while True:         vehicle = choice(vehicles)         color = choice(colors)         **try:**             yield f\"{color} {vehicle}\"         **except GeneratorExit:**             **print(\"No more vehicles.\")**             **raise** ```", "```py Washing green semi. Washing black truck. `# --snip--` Washing blue motorcycle. Washing silver semi. No more vehicles. ```", "```py from random import choice colors = ['red', 'green', 'blue', 'silver', 'white', 'black'] vehicles = ['car', 'truck', 'semi', 'motorcycle', None]  def traffic():     while True:         vehicle = choice(vehicles)         color = choice(colors)  try:             yield f\"{color} {vehicle}\"       ❶ except ValueError:           ❷ print(f\"Skipping {color} {vehicle}...\")           ❸ continue         except GeneratorExit:             print(\"No more vehicles.\")             raise ```", "```py def wash_vehicle(vehicle):     if 'semi' in vehicle:         raise ValueError(\"Cannot wash vehicle.\")     print(f\"Washing {vehicle}.\") ```", "```py def car_wash(traffic, limit):     count = 0     for vehicle in traffic:         try:             wash_vehicle(vehicle)         except Exception as e:           ❶ traffic.throw(e)         else:             count += 1         if count >= limit:             traffic.close() ```", "```py queue = traffic() car_wash(queue, 10) ```", "```py Washing white car. Washing red motorcycle. Skipping green semi... Washing red truck. Washing green car. Washing blue truck. Washing blue truck. Skipping white semi... Washing green truck. Washing green motorcycle. Washing black motorcycle. Washing red truck. No more vehicles. ```", "```py from random import choice, randint  colors = ['red', 'green', 'blue', 'silver', 'white', 'black'] vehicles = ['car', 'truck', 'semi', 'motorcycle', None] ```", "```py def biker_gang():     for _ in range(randint(2, 10)):         color = ❶ choice(colors)       ❷ yield f\"{color} motorcycle\" ```", "```py def traffic():     while True:         **if randint(1, 50) == 50:** ❶ **yield from biker_gang()** ❷ **continue**                  vehicle = choice(vehicles)         color = choice(colors)         yield f\"{color} {vehicle}\" ```", "```py count = 0 for count, vehicle in enumerate(traffic()):     print(f\"{vehicle}\")     if count == 100:         break ```", "```py black motorcycle green truck `# --snip--` red car black motorcycle black motorcycle blue motorcycle white motorcycle green motorcycle blue motorcycle white motorcycle silver semi `# --snip--` blue truck silver truck ```", "```py def license_plates():     for num in range(1000):         yield f'ABC {num:03}' ```", "```py for plate in license_plates():     print(plate) ```", "```py ABC 000 ABC 001 ABC 002 `# --snip--` ABC 997 ABC 998 ABC 999 ```", "```py **license_plates = (** f'ABC {number:03}'      for number in range(1000) **)** ```", "```py for plate in license_plates:      print(plate) ```", "```py import time sleepy = **(time.sleep(t) for t in range(0, 3))** ```", "```py print(\"Calling...\") next(sleepy) print(\"Done!\") ```", "```py import time sleepy = **(time.sleep(t) for t in [1, 2, 3, 4, 5])** ```", "```py **from itertools import product** **from string import ascii_uppercase as alphabet**  license_plates = (     f'**{** ❶ **\"\".join(letters)}** {number:03}'     **for letters in** ❷ **product(alphabet, repeat=3)**   ❸ for number in range(1000) ) ```", "```py registrations = {}   def new_registration(owner):     if owner not in registrations:         plate = next(license_plates)         registrations[owner] = plate         return True     return False   # Fast-forward through several results for testing purposes. for _ in range(4441888):     next(license_plates)  name = \"Jason C. McDonald\" my_plate = new_registration(name) print(registrations[name]) ```", "```py GOV 888 ```", "```py from itertools import product from string import ascii_uppercase as alphabet  license_plates = (     f'{\"\".join(letters)} {numbers:03}'     for letters in product(alphabet, repeat=3)     **if letters != ('G', 'O', 'V')**     for numbers in range(1000) ) ```", "```py def license_plate_generator():     for letters in product(alphabet, repeat=3):         if letters != ('G', 'O', 'V'):             for numbers in range(1000):                 yield f'{\"\".join(letters)} {numbers:03}' ```", "```py GOW 888 ```", "```py divis_by_three = (n for n in range(100) if n % 3 == 0) ```", "```py divis_by_three = (n for n in range(100) if n % 3 == 0 **else \"redacted\"**) ```", "```py SyntaxError: invalid syntax ```", "```py def divis_by_three():     for n in range(100):         if n % 3 == 0:         else:  # SyntaxError!             \"redacted\"             yield n ```", "```py def divis_by_three():     for n in range(100):         yield n if n % 3 == 0 else \"redacted\" ```", "```py divis_by_three = (n **if n % 3 == 0 else \"redacted\"** for n in range(100)) ```", "```py divis_by_three = (n if n % 3 == 0 for n in range(100)) ```", "```py SyntaxError: invalid syntax ```", "```py def divis_by_three():     for n in range(100):         yield n if n % 3 == 0  # syntax error ```", "```py def divis_by_three():     for n in range(100):         if n % 3 == 0:             yield n ```", "```py divis_by_three = (n for n in range(100) if n % 3 == 0) ```", "```py from itertools import product from string import ascii_uppercase as alphabet  license_plates = (     **f'**❶ **{**letters**}** {numbers:03}'     for letters in **(**         **\"\".join(chars)**         **for chars in** product(alphabet, repeat=3)     **)**     if letters != 'GOV'     for numbers in range(1000) ) ```", "```py orders = ['cold brew', 'lemongrass tea', 'chai latte', 'medium drip',           'french press', 'mocha cappuccino', 'pumpkin spice latte',           'double-shot espresso', 'dark roast drip', 'americano']  drip_orders = [ ❶ order ❷ for order in orders ❸ if 'drip' in order]  print(f'There are {len(drip_orders)} orders for drip coffee.') ```", "```py odd_remainders = {100 % divisor for divisor in range(1, 100, 2)} print(odd_remainders) ```", "```py {0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 29, 30, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49} ```", "```py squares = {n : n ** 2 for n in range(1,101)} print(squares[2]) print(squares[7]) print(squares[11]) ```", "```py 4 49 121 ```", "```py primary = [     c     for m in status['members']     if m['stateStr'] == 'PRIMARY'     for c in rs_config['members']     if m['name'] == c['host']     ]  secondary = [     c     for m in status['members']     if m['stateStr'] == 'SECONDARY'     for c in rs_config['members']     if m['name'] == c['host']     ]  hidden = [     m     for m in rs_config['members']     if m['hidden']     ] ```", "```py cropids = [self.roidb[inds[i]]['chip_order'][     self.crop_idx[inds[i]] % len(self.roidb[inds[i]]['chip_order'])]  for i in range(cur_from, cur_to) ] ```", "```py some_list = getTheDataFromWhereever() [API.download().process(foo) for foo in some_list] ```", "```py some_list = getTheDataFromWhereever() for foo in some_list:     API.download().process(foo) ```", "```py from random import choice   def color_counter(color):     matches = 0     while True:       ❶ vehicle = yield         if color in vehicle:             matches += 1         print(f\"{matches} so far.\") ```", "```py colors = ['red', 'green', 'blue', 'silver', 'white', 'black'] vehicles = ['car', 'truck', 'semi', 'motorcycle']   def traffic():     while True:         vehicle = choice(vehicles)         color = choice(colors)         yield f\"{color} {vehicle}\" ```", "```py counter = color_counter('red') ```", "```py counter.send(None)  # prime the coroutine ```", "```py next(counter)  # prime the coroutine ```", "```py for count, vehicle in enumerate(traffic(), start=1):     if count < 100:         counter.send(vehicle)     else:         counter.close()         break ```", "```py 0 so far. 0 so far. 1 so far. `# --snip--` 19 so far. 19 so far. 19 so far. ```", "```py def color_counter(color):     matches = 0     while True:         vehicle = yield **matches**         if color in vehicle:             matches += 1 ```", "```py **matches = 0** for count, vehicle in enumerate(traffic(), start=1):     if count < 100:         **matches =** counter.send(vehicle)     else:         counter.close()         break  **print(f\"There were {matches} matches.\")** ```", "```py There were 18 matches. ```", "```py def coroutine():     ret = None     while True:         print(\"...\")       ❶ recv = ❷ yield ret       ❸ print(f\"recv: {recv}\")       ❹ ret = recv   co = coroutine() current = ❺ co.send(None) ❻ print(f\"current (ret): {current}\")  for i in range(10):   ❼ current = ❽ co.send(i)   ❾ print(f\"current (ret): {current}\")  co.close() ```", "```py print(\"Normal message\") print(\"Scary error occurred\") ```", "```py $ **python3 print_error.py > output.txt 2> error.txt** $ **cat output.txt** A normal message. A scary error occurred. $ **cat error.txt** $ ```", "```py **import sys** print(\"Normal message\") print(\"Scary error occurred\"**, file=sys.stderr**) ```", "```py $ **python3 print_error.py > output.txt 2> error.txt** $ **cat output.txt** A normal message. $ **cat error.txt** A scary error occurred. ```", "```py import time  print(\"Downloading\", end='') for n in range(20):     print('.', end='', flush=True)     time.sleep(0.1) print(\"\\nDownload completed!\") ```", "```py number = 245 street = \"8th Street\" city = \"San Francisco\" state = \"CA\" zip_code = 94103 ```", "```py print(f\"{number} {street} {city} {state} {zip_code}\") ```", "```py print(number, street, city, state, zip_code) ```", "```py 245 8th Street San Francisco CA 94103 ```", "```py nearby_properties = {     \"N. Anywhere Ave.\":     {         123: 156_852,         124: 157_923,         126: 163_812,         127: 144_121,         128: 166_356,     },     \"N. Everywhere St.\":     {         4567: 175_753,         4568: 166_212,         4569: 185_123,     } } ```", "```py for street, properties in nearby_properties.items():     for address, value in properties.items():         print(f\"{street}\\t{address}\\t${value:,}\") ```", "```py for street, properties in nearby_properties.items():     for address, value in properties.items():         print(**street, address, f\"${value:,}\", sep='\\t'**) ```", "```py `# --snip--` N. Anywhere Ave.        127     $144,121 N. Anywhere Ave.        128     $166,356 N. Everywhere St.       4567    $175,753 `# --snip--` ```", "```py for street, properties in nearby_properties.items():     for address, value in properties.items():         print(street, address, f\"${value:,}\", **sep='  |  '**) ```", "```py `# --snip--` N. Anywhere Ave.  |  127  |  $144,121 N. Anywhere Ave.  |  128  |  $166,356 N. Everywhere St.  |  4567  |  $175,753 `# --snip--` ```", "```py mls = input(\"Search: MLS#\") print(f\"Searching for property with MLS#{mls}...\") ```", "```py Search: MLS#`2092412` Searching for property with MLS#2092412... ```", "```py house = open(\"213AnywhereAve.txt\") print(house.read()) house.close() ```", "```py Beautiful 3 bed, 2.5 bath on 2 acres. Finished basement, covered porch. Kitchen features granite countertops and new appliances. Large fenced yard with mature trees and garden space. $856,752  ```", "```py house = open(\"213AnywhereAve.txt\") **try:**     print(house.read()) **finally:**     house.close() ```", "```py **with** open(\"213AnywhereAve.txt\") **as house:**     print(house.read()) ```", "```py with open(\"213AnywhereAve.txt\", 'r') as file:     print(file.readable())  # prints 'True'     print(file.writable())  # prints 'False'     print(file.seekable())  # prints 'True' ```", "```py 78 Somewhere Road, Anytown PA  Tiny 2-bed, 1-bath bungalow. Needs repairs. Built in 1981; original kitchen and appliances. Small backyard with old storage shed. Built on ancient burial ground. $431,998  ```", "```py with open('78SomewhereRd.txt', 'r') as house:     contents = house.read()     print(type(contents))  # prints <class 'str'>     print(contents) ```", "```py  print(repr(contents)) ```", "```py '78 Somewhere Road, Anytown PA\\nTiny 2 bed, 1 bath `#` `--snip--`' ```", "```py with open('78SomewhereRd.txt', 'r') as house:     **print(house.read(20))** ```", "```py 78 Somewhere Road, A ```", "```py with open('78SomewhereRd.txt', 'r') as house:     line1 = house.readline()     line2 = house.readline()     print(repr(line1))     print(repr(line2)) ```", "```py '78 Somewhere Road, Anytown PA\\n' 'Tiny 2 bed, 1 bath bungalow.\\n' ```", "```py with open('78SomewhereRd.txt', 'r') as house:     lines = house.readlines()     for line in lines:         print(line.strip()) ```", "```py 78 Somewhere Road, Anytown PA Tiny 2-bed, 1-bath bungalow. Needs repairs. Built in 1981; original kitchen and appliances. Small backyard with old storage shed. Built on ancient burial ground. $431,998 ```", "```py with open('78SomewhereRd.txt', 'r') as house:     for line in house:         print(line.strip()) ```", "```py with open('78SomewhereRd.txt', 'r') as house:     for _ in range(3):         print(house.readline().strip())         house.seek(0) ```", "```py 78 Somewhere Road, Anytown PA 78 Somewhere Road, Anytown PA 78 Somewhere Road, Anytown PA ```", "```py with open('78SomewhereRd.txt', 'r') as house:     for **n** in range(**10**):         **house.seek(n)**         print(house.readline().strip()) ```", "```py 78 Somewhere Road, Anytown PA 8 Somewhere Road, Anytown PA Somewhere Road, Anytown PA Somewhere Road, Anytown PA omewhere Road, Anytown PA mewhere Road, Anytown PA ewhere Road, Anytown PA where Road, Anytown PA here Road, Anytown PA ere Road, Anytown PA ```", "```py with open('78SomewhereRd.txt', 'r+') as real_estate_listing:     contents = real_estate_listing.read() ```", "```py  contents = contents.replace('Tiny', 'Cozy')     contents = contents.replace('Needs repairs', 'Full of potential')     contents = contents.replace('Small', 'Compact')     contents = contents.replace('old storage shed', 'detached workshop')     contents = contents.replace('Built on ancient burial ground.',                                 'Unique atmosphere.') ```", "```py  real_estate_listing.seek(0)     real_estate_listing.write(contents) ```", "```py  real_estate_listing.truncate() ```", "```py 78 Somewhere Road, Anytown PA Cozy 2-bed, 1-bath bungalow. Full of potential. Built in 1981; original kitchen and appliances. Compact backyard with detached workshop. Unique atmosphere. $431,998  ```", "```py with open('78SomewhereRd.txt', 'r+') as real_estate_listing:     contents = real_estate_listing.**readlines()** ```", "```py  **new_contents = []**  **for line in contents:**  **line = line.**replace('Tiny', 'Cozy')  **line = line.**replace('Needs repairs', 'Full of potential')  **line = line.**replace('Small', 'Compact')  **line = line.**replace('old storage shed', 'detached workshop')  **line = line.**replace('Built on ancient burial ground',                             'Unique atmosphere')         **new_contents.append(line)** ```", "```py  real_estate_listing.seek(0)     real_estate_listing.**writelines(new_contents)**     real_estate_listing.truncate() ```", "```py nearby_properties = {     \"N. Anywhere Ave.\":     {         123: 156_852,         124: 157_923,         126: 163_812,         127: 144_121,         128: 166_356     },     \"N. Everywhere St.\":     {         4567: 175_753,         4568: 166_212,         4569: 185_123     } } ```", "```py **with open('listings.txt', 'w') as real_estate_listings:**     for street, properties in nearby_properties.items():         for address, value in properties.items():             print(street, address, f\"${value:,}\",                   sep='  |  ',                   **file=real_estate_listings**) ```", "```py `# --snip--` N. Anywhere Ave.  |  127  |  $144,121 N. Anywhere Ave.  |  128  |  $166,356 N. Everywhere St. |  4567 |  $175,753 `# --snip--` ```", "```py`### How Context Managers Work    For an object to be a context manager, it must implement two special methods: `__enter__()` and `__exit__()`.    Streams implement both of these methods. The `__exit__()` method closes the stream, eliminating the need to remember to manually close the stream.    The `__enter__()` method is responsible for any setup before the context manager is used. This method doesn’t do anything interesting in the case of a stream, although some context manager classes make more use of `__enter__()`, as you’ll see in the custom context manager example later.    According to PEP 343, which defined context managers, the `with` compound statement is roughly equivalent to this:    ```", "```py    The expression passed to the `with` statement is used to initialize an object. The `__enter__()` method is called on that object to perform whatever tasks should be completed before the object is used. (Again, in the case of streams, this method does nothing.) Next, the suite of the `with` statement is called within the context of a `try` clause. Whether it succeeds or fails, the `__exit__()` method will be called, usually to perform any necessary cleanup tasks on the object.    Recalling the example from [Listing 11-17](#listing11-17), if Python didn’t have `with` statements, I’d need to use the following code to ensure a file was closed, whether there was an error or not:    ```", "```py    Listing 11-33: *read_real_estate_listing_file.py:1a*    Because streams like `real_estate_listing` are context managers, I can instead represent that same logic as follows:    ```", "```py    Listing 11-34: *read_real_estate_listing_file.py:1b*    Once again, `__enter__()` does nothing, but it is called as a matter of convention on context managers. The `__exit__()` method closes the stream when I’m done. This version feels more verbose, but as it uses the special methods of the context manager, the logic can be handled entirely in a single `with` statement:    ```", "```py    Listing 11-35: *read_real_estate_listing_file.py:1c*    This is much easier to remember and type. It’s all made possible by context managers.    ### Using Multiple Context Managers    You can use multiple context managers in a `with` statement, which can open up all sorts of possibilities. For example, say I want to be able to read from two files at once, perhaps to combine them into one or to look for differences between them. (In the interest of expediency, I won’t actually do anything with these files in this example; I’ll just open them.)    To open multiple streams in a single `with` statement, I separate the `open()` expressions in the header with a comma, like this:    ```", "```py    Listing 11-36: *multiple_streams.py*    I can use the streams `left` and `right` in the usual manner. When the `with` statement ends, both streams are closed automatically.    ### Implementing the Context Management Protocol    The *context management protocol* is the fancy, official term for the `__enter__()` and `__exit__()` special methods. Any object that implements these two special methods can be managed by the `with` statement. They’re not limited to working with streams; you can use them to automate doing anything that needs to be done before or after usage of an object.    Remember that these methods need only be implemented. If you don’t need one or the other to actually do anything, don’t write any functionality into the unneeded method.    To demonstrate this, I’ll work with the example of a house showing. Before you can show a prospective buyer a home, you have to unlock the front door. When you leave, you lock the door again. This sort of pattern is precisely what a context manager is for.    First, I define the entire `House` class:    ```", "```py    Listing 11-37: *house_showing.py:1*    This class relies entirely on concepts from prior chapters, so I won’t detail implementation here. In short, a `House` object is initialized with an address, a value to use as the house key, and a keyword argument describing each room. You’ll notice that my initializer converts underscores in the keyword argument names to spaces before storing the room name in the `self._rooms` dictionary. It changes both the room name and the description to lowercase. This will make the usage of the class feel more obvious and less error-prone.    The important part of this example is the `HouseShowing` class, which I’ll ultimately write as a context manager by defining the `__enter__()` and `__exit__()` special methods in the upcoming [Listing 11-39](#listing11-39) and [Listing 11-41](#listing11-41), respectively. First, I’ll define the class and its initializer:    ```", "```py    Listing 11-38: *house_showing.py:2*    In the initializer, I accept two arguments: a `House` instance and the key value with which to unlock the house. In the next two sections, I’ll add the `__enter__()` and `__exit__()` special instance methods, to make `HouseShowing` a context manager.    ### The __enter__() Method    Before I can show any room in the `House`, I must always unlock the house first. If the key is wrong, I can’t get in, so there’s no point in continuing with the showing. Since this behavior should always occur before any other use of a `House` instance, it is handled by the `__enter__()` special instance method:    ```", "```py    Listing 11-39: *house_showing.py:3*    I attempt to unlock the house using the key with which I initialized `HouseShowing`. Notice that I don’t perform any error handling here. Always allow errors originating from the usage of your class to bubble up through this method, so the developer using your class can fix their code.    Importantly, I *must* return the instance from `__enter__()` for the `with` statement to be able to work with it!    The user should be able to work with this object directly, instead of having to drill down into an attribute. The main purpose of a house showing is to see the different rooms, so I write a method for that:    ```", "```py    Listing 11-40: *house_showing.py:4*    Once again, you’ll notice that I don’t handle any of the possible exceptions from `house.explore()` here, as they all relate to the usage of the class. If the error stems from how the class is used, the exception should be handled in the usage as well.    ### The __exit__() Method    When I leave the house, either because the tour is over or I couldn’t find a sunroom, I always want to lock up. That behavior is handled by the special instance method `__exit__()`:    ```", "```py    Listing 11-41: *house_showing.py:5*    This method must accept three arguments besides `self`. If an exception is raised anywhere in the suite of the `with` statement, these three parameters will describe the exception’s type (`exc_type`), message (`exc_val`), and traceback (`exc_tb`). If there is no exception, all three of these parameters will have the value `None`. The parameter names I’m using here are conventional. You can call them whatever you like, but I recommend sticking with these names unless you have a good reason to change them.    Although `__exit__()` must accept these arguments, you’re not required to do anything with them. They’re useful if you need to take different close or cleanup actions when certain exceptions occur. In my case, if there was any exception ❶, I apologize to the client while locking up the house ❷. In my particular code, I make no use of the message (`exc_val`) and traceback (`exc_tb`) arguments. If there was no exception, I only lock the house.    Importantly, `__exit__()` *does not have any role in raising or handling the error*! It acts as a listener, eavesdropping on any exceptions that occur in the `with` suite. Within `__exit__()`, I use conditional statements to work with the exceptions passed as arguments. I cannot use `try` for this, because any exceptions never bubble up through `__exit__()` directly, as you’ll notice in [Listing 11-34](#listing11-34). I should never re-raise the exceptions passed in either, because any exception that occurs in the suite of the `with` will be raised by the responsible statement and should be handled by the caller. Once again: `__exit__()` has no role in handling these exceptions. The only exceptions that an `__exit__()` method should ever handle are those its own suite directly caused.    ### Using the Custom Class    Now that my class is a context manager, I can write my usage. I start by creating a `House` object:    ```", "```py    Listing 11-42: *house_showing.py:6*    In creating the `House` instance, I’m defining a `house_key` value of `1803`, which is the value I’ll have to provide later when defining the `HouseShowing`.    I create a new `HouseShowing` in the context of a `with` statement, passing the `House` instance I created (`house`) to it. For the sake of example, I’m using the wrong `house_key` value (`9999`), so I should get an exception:    ```", "```py    Listing 11-43: *house_showing.py:7a*    In the header, I create a new instance of `HouseShowing`. Its `__enter__()` method is called by the `with` statement. The value returned from `__enter__()` is bound to `showing`. If I had forgotten to return anything from `__enter__()` in [Listing 11-39](#listing11-39), `showing` would have been bound to `None`, and this code wouldn’t have worked.    Since `house_key` is wrong and I cannot unlock the house, here’s the output from running the program as it is right now:    ```", "```py    Because the `house_key` value was wrong, `showing.__enter__()` encountered an exception, which I allowed to remain unhandled. This is important, because my code in [Listing 11-43](#listing11-43) is wrong. I need to pass the correct value for `house_key`. The `with` statement didn’t even try to run its suite. It encountered an exception and gave up.    I’ll correct the value I’m passing to `house_key`:    ```", "```py    Listing 11-44: *house_showing.py:7b*    Now, I’ll be able to unlock the house. In the suite of the `with` statement, I make three calls to the `show()` method. The first two will work, because the `House` instance bound to `house` has those rooms defined (see [Listing 11-42](#listing11-42)), but the third will fail with an exception. Take a look at the output:    ```", "```py    The `with` statement calls `showing.__enter__()` on `HouseShowing`, which in turn calls `house.unlock_house()`, as indicated by the message `House unlocked`. Then, with each call to `showing.show()` in the suite of the `with` statement, a description of the requested room is printed out.    The third call to `showing.show()` in [Listing 11-44](#listing11-44), requesting to see the porch, fails with an exception because the house doesn’t have a porch. Instead, `showing.__exit__()` is called, and the exception is passed to it. The apology is printed, and then `house.lock_house()` is called.    After all this, the traceback of the exception is printed.    To fix the problem with the code, I’d need to drop the request to see the porch and replace it with a room that does exist. Perhaps I’ll look at the kitchen instead.    ```", "```py    Listing 11-45: *house_showing.py:7c*    Running this version outputs the following:    ```", "```py    No errors here. The house is unlocked, the requested rooms are shown, and then the house is locked again. Because there were no exceptions raised in the suite, `house.__exit__()` does not print the apology from before.    ## Paths    So far, I’ve used files located in the same directory as the module opening them. In real programs, a file may be anywhere on the system. This is far from trivial, which is probably why most tutorials skim over this topic. I’ll dive deep into file paths here.    First, file paths are not the same on all operating systems. UNIX-style systems, such as macOS and Linux, use the POSIX file path conventions, while Windows uses an entirely different scheme. Second, you can’t always be sure what directory your code is being run in, so relative paths only get you so far. Third, you can’t make assumptions about the name or location of important directories, such as the user’s home directory. In short, file paths are tricky to generalize.    To get around all of these issues, Python offers two modules: `os` and `pathlib`. Up until Python 3.6, using the `os` package and its submodule (`os.path`) was the standard way of working with file paths. Even now, this remains a common approach. The `os` package allows you to work portably with whatever operating system your code is running on, yet the package as a whole is plagued with complexity, verbosity, and some pretty snarly legacy code. It’s also considered something of a “junk drawer,” since it contains all the functions and classes designed for working with the operating system. Thus, it can be hard to know what to use from the `os` module or even how to use it.    The `pathlib` module was introduced in Python 3.4 and became fully supported by `open()` in Python 3.6\\. It offers a cleaner, better organized, and more predictable way of handling paths. More importantly, it replaces most of `os.path` and cleanly incorporates much of the filesystem functionality offered by `os` and another useful module: `glob`, which allows you to find multiple paths fitting a particular pattern, following UNIX rules.    I recommend preferring `pathlib` for the sake of maintainability, readability, and performance, so that’s what I’ll focus on here. If you find yourself working with legacy code, or if you need a few of the advanced functions in `os.path`, refer to the official documentation for the `os.path` module: [https://docs.python.org/3/library/os.path.html](https://docs.python.org/3/library/os.path.html).    ### Path Objects    The `pathlib` module provides several related classes that represent filesystem paths. These are called *path-like* classes—as of Python 3.6, they all inherit from the `os.Pathlike` abstract class—and they are immutable representations of a filesystem path. Importantly, path-like objects are *not* based on strings; they’re unique objects with their own behaviors, based on the parts of a path and how those parts fit together, so they abstract out a lot of the logic.    One of the nice things about `pathlib` path objects is that they handle all the different filesystem conventions quietly, behind the scenes, as appropriate to the system: current directory (`.`), parent directory (`..`), slashes (`/` or `\\`), and so forth.    There are two types of path-like objects: *pure paths* and *concrete paths*.    #### Pure Paths    A *pure path* represents a path and allows you to work with it, without accessing the underlying filesystem. Instantiating an object from the `PurePath` class will automatically create a `PurePosixPath` or `PureWindowsPath` object behind the scenes, depending on the operating system. You can usually entrust this to Python to figure out, although you can instantiate the specific type of path if you need it for your code.    ```", "```py    Listing 11-46: *relative_path.py:1a*    I can pass the `PurePath` object to the `open()` function to open *../some_file.txt*. However, I cannot interact with the filesystem through the `path` object itself, as I attempt to do with `path.touch()`, which fails.    If you only intend to use the path in a call to `open()`, or if you otherwise don’t plan to interact with the system directly through the path object’s methods, then you should use a pure path, which will help prevent you from accidentally modifying the filesystem.    #### Concrete Paths    A *concrete path* provides methods for interacting with the filesystem. Instantiating an object from the `Path` class will create either a `PosixPath` or a `WindowsPath` object:    ```", "```py    Listing 11-47: *relative_path.py:1b*    This code is exactly the same as in [Listing 11-46](#listing11-46), except that I’m defining a `Path` object instead of a `PurePath`. As a result, I can still open the path, but I can also use methods on the `path` object to interact directly with the filesystem. For example, I can use `path.touch()` to create an empty file at *../some_file.txt*, if that file doesn’t already exist.    If you are explicitly coupling your implementation to a particular operating system, use either the `Windows` or the `Posix` form of the class; otherwise, use the `PurePath` or `Path` class.    ### Parts of a Path    A path-like object is made up of parts that the path class joins together behind the scenes, based on the operating system. There are two ways of writing a path: *absolute* and *relative*. Both ways of writing paths work in all the `PurePath` and `Path` objects.    An *absolute* path is one that starts from the root of the filesystem. The absolute path to a file always starts with an *anchor* and ends with the *name—the full filename. The name consists of a *stem* (that is, the filename) before the first nonleading dot and, typically, one or more *suffixes* after the dot. For example, consider the following fictional path:*   *```", "```py    The anchor here is the leading forward slash (`/`). The name is `file.txt`, with a stem of `file` and a suffix of `.txt`. I’ll break down a couple of more complex examples shortly.    These parts can be retrieved from the path-like object. You can use the `PurePath.parts()` method, which returns a tuple of parts. Otherwise, you can access specific components as properties.    Here’s a function that prints out each part of a path passed to it. I’ll discuss the function, then employ it in the next couple of sections to dissect a Windows path and a POSIX path, respectively.    ```", "```py    Listing 11-48: *path_parts.py:1*    The `path.parents` property is an iterable collection. The first item, `parents[0]`, is the immediate parent and is the same as `path.parent`. The next item, `parents[1]`, is the parent of `parents[0]`, and so on.    The `path.suffixes` property is a list of the suffixes, as some files can have more than one, especially on POSIX. These will be listed left to right, so `path.suffixes[-1]` is always the last suffix.    Now that I have this function, I can run a couple of paths through it to see the parts, which I’ll do in Listings 11-49 and 11-50.    #### Parts of a Windows Path    I’ll start by breaking down an absolute path on Windows. (It doesn’t matter here whether you’re working with a pure path or a concrete path; the paths *themselves* are structured the same in both.)    I break down the parts of an example path on Windows in [Figure 11-1](#figure11-1).  ![](Images/f11001.png)    Figure 11-1: Parts of a Windows absolute path      In a Windows path, the anchor consists of the *drive*, which is `C:` in [Figure 11-1](#figure11-1), and a *root*, which is `\\`. The *parent* is the path to the containing directory—in this case, `C:\\Windows\\System\\`. That can be further broken down into three subparents: `C:\\` (also the anchor), `Windows\\`, and `System\\`.    The *name* consists of the *stem*, which is usually the filename (`python37`) before the first nonleading dot; and the *suffix* or *suffixes*, which is the file extension (`.dll`) after the dot.    I’ll break that down again, using my function from [Listing 11-48](#listing11-48):    ```", "```py    Listing 11-49: *path_parts.py:2a*    You’ll notice that I used forward slashes as the directory separator, which are not typically employed in Windows paths. The `pathlib` module allows me to use either forward slashes (`/`) or escaped backslashes (`\\\\`) for paths on any system, and it handles the switch behind the scenes. (Remember that single backslashes are escape characters in Python.) Forward slashes are less prone to typos, and using them eliminates the risk of accidentally omitting one of the pair of backslashes. I therefore recommend sticking with forward slashes when you can.    Running that code outputs all the parts of the path:    ```", "```py    This is consistent with the parts I outlined in [Figure 11-1](#figure11-1). I have the absolute path to each parent in ascending order, starting from the immediate parent of the file, `C:\\Windows\\System`.    The name is `python37.dll`, which is broken into the stem (`python37`) and one suffix (`.dll`).    #### Parts of a POSIX Path    Filesystem paths on UNIX-like systems, like Linux or macOS, are a little different. They follow the path conventions laid out by the POSIX standard.  ![](Images/f11002.png)    Figure 11-2: Parts of a POSIX absolute path      In a POSIX absolute path, the *root* only contains the *anchor* (`/`). The *drive* part is always empty on POSIX paths, but the property itself exists for compatibility. The *name* part at the end consists of a *stem* (which again is generally the filename) before the first nonleading dot, plus one or more *suffixes* (which usually make up the file extension).    Passing that path to my `path_parts()` function from [Listing 11-48](#listing11-48) shows all these parts:    ```", "```py    Listing 11-50: *path_parts.py:2b*    The output is as follows:    ```", "```py    This example demonstrates a unique issue you may encounter with file extensions. While there are valid file extensions that consist of multiple suffixes, such as *.tar.gz* (for a GZ-compressed tarball), not every suffix is part of the file extension. This is a perfect example: the intended filename is `libpython3.7m`, but `pathlib` incorrectly interprets the `.7m` as one of the suffixes because of its leading dot. Meanwhile, because the intended file extension (`.so.1`) is actually composed of two suffixes, the stem is incorrectly detected as `libpython3.7m.so` and the suffix as just `.1`. You’ll need to keep this in mind when looking for the file extension on a path. There’s no simple or obvious way to resolve this; you have to take it case by case, as needed for your code. In short, don’t rely too much on `pathlib`’s ability to discern the stem and suffix; it can fail you in quite annoying ways.    ### Creating a Path    You can define a path using the desired class initializer, such as `PureWindowsPath` or `PosixPath`, by passing the path as a string. From there, you can use the path with `open()` or any other file operation. For example, on my own UNIX system, I can access my bash history like this:    ```", "```py    Listing 11-51: *read_from_path.py:1a*    Because I’m specifying a POSIX-format path and I plan to access the underlying filesystem using the methods on my `path` object, I use `PosixPath` class. If I wanted this to work on Windows as well, I’d use `Path`, but since `.bash_history` isn’t necessarily a file that appears on Windows, I’ll stick with `PosixPath` here.    After initializing the path-like object and binding it to `path`, I can open it. There are two ways to do this; either pass it to `open()` or use the functionally identical `open()` method on the `Path` object(not available on `PurePath`). I’ll use the latter:    ```", "```py    Listing 11-52: *read_from_path.py:2*    In this example, I only want the last line of the file, so I have to iterate over the whole thing. By time the loop finishes, the name `line` will have been bound to the string of the last line read. There’s no easier way to seek the end of a text file for reading.    Finally, I print out this line, stripping off the trailing line break by using the `strip()` method.    Running that code shows me the last line I ran in my shell:    ```", "```py    This works well on my machine, but it certainly won’t work on yours, unless your username is *also* `jason`. It also won’t work if your system structures home directories differently than mine. I need a more portable approach, and this is where `pathlib` really shines.    ```", "```py    Listing 11-53: *read_from_path.py:1b*    The `joinpath()` method combines two or more paths together and is available on all six `pathlib` classes. `PosixPath.home()` returns the absolute path to the current user’s home directory. (The same method exists on `WindowsPath` and refers to the user directory.)    I join `.bash_history` to this home directory path.    I can use this new path in the exact same way as in [Listing 11-51](#listing11-51). Running the revised code produces the same output:    ```", "```py    Yet, there’s an even shorter way: `pathlib` classes implement the forward-slash operator (`/`) to make it easier to join path-like objects to each other, or even to strings:    ```", "```py    Listing 11-54: *read_from_path.py:1c*    I’ll leave it to you to decide whether that reads cleaner than `PosixPath.joinpath()`, but I certainly prefer it. They’re functionally identical, so use whichever one feels more readable in your particular situation.    There’s one other shortcut I can use in this code. On UNIX-like systems, the tilde character (`~`) refers to the user’s home folder, so I could just write my entire path using this convention and then have `pathlib` expand to the full absolute path:    ```", "```py    Listing 11-55: *read_from_path.py:1d*    This is the most readable approach by far, and it behaves the same as before.    ### Relative Paths    A *relative* path is one that starts from the current position, instead of the root of the filesystem. Path-like objects can handle relative paths just as easily as absolute ones. Relative paths are based on the *current working directory*, which is the directory the user (or system) is currently running commands from.    This is useful, for example, if I have a Python program, `magic_program`, that I invoke from the command line and to which I can pass a path. The path will be received by the program as a string and will be interpreted as a `Path` object. If my current working directory were something long or difficult to type, it would be quite inconvenient to have to type an absolute path to a file contained in (or below) that directory, like this:    ```", "```py    This invocation is painful! If I’m already in that *DeadSimplePython/* directory, I should be able to pass a relative path:    ```", "```py    Whew! That’s much easier to use. Because of relative paths, it would be possible to write this program.    You can get the current working directory with the `Path.cwd()` command, like this:    ```", "```py    That code would print out the absolute path to the current working directory, in the appropriate path format for your system.    Any path that does not lead with an anchor (typically `/`) is considered a relative path. Additionally, a single dot (`.`) represents the current directory, and a double dot (`..`) represents the previous, or parent, directory. In this way, you can construct a relative path in the same manner as an absolute path. For example, if I wanted to look for a `settings.ini` file in the parent of the current working directory, I could do so with the following:    ```", "```py    This path can be converted to an absolute path using the `Path.resolve()` method. It resolves the dot operators (`.` and `..`) in paths and any symbolic links. Other redundant path elements, such as extra slashes or unnecessary dot operators (such as `.//dir1/../dir1///dir2`), are cleaned up.    Although I could resolve the path in a subsequent line of code, I prefer to modify that line to resolve the path right on the spot.    ```", "```py    `path` is now an absolute path to *settings.ini*.    ### Paths Relative to Package    Sooner or later, you’ll want to package noncode resources (like images or sounds) alongside your Python project and then access them from your code. You won’t know for certain where the user has placed your Python project directory on his or her filesystem; even if you knew where it *should* be, the user or system might have moved it. You need a way to create the absolute path to the noncode resources you shipped with your package. “Aha!” you may think. “This is a perfect situation for a relative path!” You would be wrong.    A common trap to fall into is to assume that the current working directory is the location of the current or main Python module. *That is not necessarily the case!* When you set up your project correctly, as I described in Chapter 4, you can run a Python module from anywhere on the system. Your current location is the current working directory, and all paths will be relative to that location. You need a way to find the resources that does *not* depend on the current working directory; in other words, relative paths are out.    I’ll use my *omission* project from Chapter 4 as an example. Here’s the project structure:    ```", "```py    Listing 11-56: File structure for *omission* project    With my module *omission/game/contentloader.py*, I want to load the text file containing the game content, which is stored at *omission/resources/content/content.txt*.    In my initial attempt, I incorrectly assumed the current working directory would be the location of *content_loader.py*. Thus, I tried to open the *content.txt* file with a relative path something like this:    ```", "```py    Listing 11-57: *content_loader.py:1a*    Because I was starting my *omission* program by running *omission.py* from the root of my repository, *omission-git* was incidentally my working directory, so this code appeared to work.    Temporarily sticking the following line of code into my *content_loader.py* module confirmed that, by printing out the absolute path to that directory:    ```", "```py    “That’s easy,” I thought to myself. “I just write all my paths relative to `omission-git`.” (This is where things went really wrong!) I changed my code to use paths relative to that *omission-git/* directory like this:    ```", "```py    Listing 11-58: *content_loader.py:1b*    The program appeared to work now—I could pass `path` to `open()` and read the contents without any problems. All my tests passed, and I happily moved on. It wasn’t until I started packaging that I discovered something was still wrong. If I executed the *omission.py* module from any directory other than the one it was stored in, the program would crash with a `FileNotFoundError`.    After checking the current working directory again, as before, I realized what I mentioned earlier: the current working directory is wherever the module is invoked *from*, not where it lives, and all paths are relative to that current working directory.    The solution was to base my relative paths off of the special `__file__` attribute of modules, which contains the absolute path to the module on the current system. I utilize that special attribute like this:    ```", "```py    Listing 11-59: *content_loader.py:1c*    I convert the `__file__` attribute to a `Path` object. Since this attribute may return a relative path, I use `resolve()` to convert it to an absolute path, so I don’t have to bother with the current working directory. `path` is now an absolute path to the current module. I need to work with an absolute path for the rest of this code to work.    Next, now that I have an absolute path to this *content_loader.py* module, I can craft a path to the file I want *relative to this module*. Knowing my project’s directory structure, I need to start from the top-level package, `omission`, instead of in the `game` subpackage this module is in. I get this part of the path with `path.parents[1]`, for the parent path, one level removed.    Finally, I combine the absolute path of the `omission` package with the relative path to the file I want. The result is an absolute path to my *content.txt* file that will work, no matter where the `omission` package lives on the filesystem or where it’s executed from.    This approach works for most practical cases, but beware that `__file__` is an *optional* attribute. It’s not defined for built-in modules, C modules that are statically linked to the interpreter, and anything run in the REPL. To get around these problems, you can use the rather robust `pkg_resources` module to achieve the same end as you would with `__file__`. You can learn more about this from [https://setuptools.readthedocs.io/en/latest/pkg_resources.html](http://setuptools.readthedocs.io/en/latest/pkg_resources.html).    Unfortunately, both `__file__` and libraries like `pkg_resources` are incompatible with some packaging tools. This is really more of problem with the tools than with the pattern, since no one has any alternatives! There’s no more elegant solution here. Just be aware of this limitation when selecting packaging tools.    ### Path Operations    The `pathlib` concrete path objects provide methods of performing many common file operations in a platform-agnostic fashion. Two of the most convenient of these methods are `Path.read_text()` and `Path.write_text()`, which provide a quick way to read and write entire text files without having to define a separate stream object or `with` statement. In this usage, the stream object is created and managed internally, within the `Path` object. The former reads in and returns the entire contents of the file as a string; the latter writes a string out as a file, overwriting the existing file if there is one.    [Table 11-2](#table11-2) outlines several more of the file operation methods on `Path`. Each of these would be run directly on a `Path`, `WindowsPath`, or `PosixPath` object, referred to as `path` below.      Table 11-2: Filesystem Operations on Path       | **File operation methods** | **Functionalities** | | --- | --- | | `path.mkdir()` | Creates a directory at `path`. If the optional `parents=` argument is `True`, it will create any missing parent directories. | | `path.rename(``name``)` | Renames the item (file or directory) at `path` to `name`. On Unix, if the file `name` exists at the path and the user has the correct permissions, it will be replaced. | | `path.replace(``name``)` | Renames the item (file or directory) at `path` to `name`, replacing any existing file by that name. Unlike `rename`, this will *always* replace any existing file by the same name, assuming the correct file permissions. | | `path.rmdir()` | Removes the directory at `path`. It must be empty; otherwise, an `OSError` will be raised. | | `path.unlink()` | Removes the file or symbolic link (filesystem shortcut) at `path`. Cannot be used to remove directories. In Python 3.8 and later, if the optional `missing_ok=` argument is `True`, attempting to remove a file that does not exist will *not* raise `FileNotFoundError`. | | `path.glob()` | Returns a generator of path-like objects for all items at `path` that match the specified `pattern`, according to the syntax of a Unix-style `glob` search. | | `path.iterdir()` | Returns a generator of path-like objects for all items at `path`. | | `path.touch()` | Creates an empty file at `path`. Normally, nothing happens if it already exists. If the optional `exist_ok=` argument is `False` and the file exists, a `FileExistsError` is raised. | | `path.symlink_to(``target``)` | Creates a symbolic link at `path` to `target`. | | `path.link_to(``target``)` | Creates a hard link at `path` to `target` (Python 3.8 and later only). |    In addition, you get information about the file or directory a `Path` object points to, as shown in [Table 11-3](#table11-3).      Table 11-3: File Information Methods on Path       | **File information methods** | **Functionalities** | | --- | --- | | `path.exists()` | Returns `True` if `path` points to an existing file or symbolic link. | | `path.is_file()` | Returns `True` if `path` points to a file or symbolic link to a file. | | `path.is_dir()` | Returns `True` if `path` points to a directory or symbolic link to a directory. | | `path.is_symlink()` | Returns `True` if `path` points to a symbolic link. | | `path.is_absolute()` | Returns `True` if `path` is absolute. |    I’ve only covered a portion of `pathlib`’s functionality. I strongly recommend you browse through the official module documentation, which has a complete list of methods and their usages: [https://docs.python.org/3/library/pathlib.html](https://docs.python.org/3/library/pathlib.html).    ### Out-of-Place File Writes    As I mentioned earlier in the chapter, `path.replace()` is particularly useful as part of a technique for preventing file corruption if there’s a computer or program crash during writing. Instead of directly modifying a file in place, you can write to a new file and then replace the old file with the new version.    To demonstrate this, I’ll rewrite one of my earlier examples (Listings 11-37 through 11-39) to employ `pathlib` and use this technique:    ```", "```py    Listing 11-60: *rewrite_using_tmp.py:1*    I read in the file from *78SomewhereRd.txt* as before, except that this time, I only open the file in read mode, instead of read-write. Once I’ve finished with it, I can safely close the file. My revised data is waiting in the string `contents`.    Now, I create a new temporary file path and write my data out to that new file:    ```", "```py    Listing 11-61: *rewrite_using_tmp.py:2*    I use `path.with_name()` to create a new `Path`, with the name provided as an argument. In this case, the new name is the same as the old name, but with `.tmp` appended to the end. I open that new path in write mode and write the string `contents` out to it.    At this point, my original *78SomewhereRd.txt* and my new *78SomewhereRd.txt.tmp* files exist side by side. I conclude by moving the temporary file into the place of the original, overwriting it.    ```", "```py    Listing 11-62: *rewrite_using_tmp.py:3*    That `replace()` method has the operating system perform the replacement, instead of doing it itself. This is a virtually instantaneous operation, in contrast to writing to the file, which may take a bit of time, depending on the size. Now, I only have the revised *78SomewhereRd.txt*, and the temporary file is gone.    The benefit of this technique is that, had my computer crashed while I was writing to the file, the worst outcome would be that I’d have a corrupt *78SomewhereRd.txt.tmp* file. My original *78SomewhereRd.txt* would be unchanged and unharmed.    ### The os Module    Python’s `os` module allows you to interface with the operating system in a relatively platform-agnostic fashion. Most code written before Python 3.6, and even a lot of modern code, still uses the `os.path` and `os` modules for handling paths. As I’ve mentioned, `pathlib` is going to be the better tool for working with the filesystem in most cases, but `os` still has many uses. For some longtime Python developers, using `os` is also just a habit.    As of Python 3.8, `os.path` has 12 functions, with no existing equivalent in `pathlib`. One example is `os.path.getsize(``pathlike``)`, which returns the size of the item at `pathlike` in bytes. Meanwhile, `os` itself has dozens of functions for interacting with the filesystem in a much more low-level, technical fashion than `pathlib`.    Thankfully, since Python 3.6, `pathlib` and `os` play well together. I recommend using `pathlib` as much as you can—it will fully satisfy the majority of use cases—and bring in the `os` or `os.path` modules anytime you need one of their unique functionalities. The documentation will be helpful if you want to learn more about these modules: [https://docs.python.org/3/library/os.html](https://docs.python.org/3/library/os.html).    The `os` module is not limited to working with the filesystem, so it will come up again in later chapters.    ## File Formats    Up to this point, I’ve worked entirely with plaintext files. This works for storing plain strings, but it’s not usually sufficient for more structured data. Here, I’ll discuss working with other file formats.    In many cases, you’ll get more reliable results by using an existing standard file format. However, it’s always possible to design your own format and write custom parser logic for it, so long as you’re willing to put the effort into designing, testing, and maintaining it.    Python offers tools for a few of the most common formats in the standard library, and many other formats are supported through third-party libraries. Here, I’ll cover usage of the popular JSON format and then give an overview of a few other common formats.    The process of converting Python data to a format for storage is called *serialization*, and the reverse is *deserialization*.    ### JSON    *JSON*, or *JavaScript Object Notation*, is one of the most popular text-based file formats among Python developers. JSON data can be structured in a variety of ways, the most common being storing the contents of a Python dictionary in a file.    The built-in `json` module allows you to easily convert data between JSON data and many built-in Python data types and collections. In the case of JSON, serialization and deserialization are not perfect inverses of one another, as seen in [Table 11-4](#table11-4).      Table 11-4: JSON Serialization and Deserialization Types       | **Python (to serialize)** | **JSON (serialized)** | **Python (deserialized)** | | --- | --- | --- | | `dict` | object (All keys are strings!) | `dict` | | `list` `tuple` | array  | `list`  | | `bool` | boolean | `bool` | | `str` | string | `str` | | `int` `int-derived enums` | number (int)  | `int`  | | `float` `float-derived enums` | number (real)  | `float`  | | `None` | null | `None` |    Anything directly derived from these Python types can also be JSON-serialized, but all other objects *cannot* be serialized to JSON on their own and must be converted to a type that can be.    To make a custom class JSON-serializable, you would need to define a new object that subclasses `json.JSONEncoder` and overrides its `default()` method. See the documentation for more information about this: [https://docs.python.org/3/library/json.html#json.JSONEncoder](https://docs.python.org/3/library/json.html#json.JSONEncoder).    #### Writing to JSON    Writing to JSON is refreshingly simple, in comparison to working with many other file formats. You use the `json.dump()` function to convert data to JSON format and write it to a file. Alternatively, you use `json.dumps()` to create and write JSON code to a string if you want to wait and write it to a stream later. I’ll demonstrate the former technique in this example.    I’ll work with my `nearby_properties` nested dictionary from [Listing 11-7](#listing11-7), which I want to write out to a file I’ll call *nearby.json*:    ```", "```py    Listing 11-63: *write_house_json.py:1*    The only change from the prior example ([Listing 11-7](#listing11-7)) is that I’m now importing the `json` module.    I’m converting a dictionary containing only serializable types (see [Table 11-4](#table11-4)) directly to a stream using `json.dump()`:    ```", "```py    Listing 11-64: *write_house_json.py:2*    First, I use `open()` to create a writable stream for the *nearby.json* file. The `json.dump()` function requires two arguments. The first is the object being written out, which can be *any* serializable object. In this case, I’m writing out the dictionary `nearby_properties`.    The second argument is the stream I want to write to, which must be a writable text-based stream. Here, I pass `jsonfile`, which is the text-based stream opened in write mode in the `with` statement.    That’s all it takes to write a Python dictionary to a JSON file!    The `json.dumps()` function works in exactly the same manner, except that it returns a Python string containing the JSON code, rather than requiring you to pass a stream to it.    After running my code, I can open up the newly created *nearby.json* and see the contents, which are in JSON format:    ```", "```py    Listing 11-65: *nearby.json*    #### Reading from JSON    You can directly deserialize a JSON file into the corresponding Python object using the `json.load()` function, which accepts the source stream object as an argument. If I have JSON code in a Python string, I can also deserialize it directly with `json.loads()`, passing the string as an argument.    I’ll use `json.load()` to deserialize my nested dictionary from my *nearby.json* file:    ```", "```py    Listing 11-66: *read_house_json.py:1*    I open the JSON file in read mode, and then I pass the stream to `json.load()`. That will return the deserialized object, which in this case is a dictionary I bind to `nearby_from_file`.    There is one important difference between this dictionary and the one I started with in [Listing 11-65](#listing11-65). I’ll demonstrate this difference by printing out the literal representation of each key and value:    ```", "```py    Listing 11-67: *read_house_json.py:2*    The f-string here embeds the values of `k2` and `v2` in the string, and the `!r` formats them as if they had been run through `repr()`.    Can you spot the difference with this dictionary in the output?    ```", "```py    The key values for the inner dictionaries are strings now—instead of integers, as in the original dictionary ([Listing 11-63](#listing11-63))—because the key in a JSON object is always a string. This is a perfect example of serialization and deseralization not being inverse operations. If I wanted to get back to using integers for my keys, I’d need to rewrite this code to handle that conversion iteratively. That’s beyond the scope of this chapter, so I’ll leave this example as is.    ### Other Formats    I could devote an entire book just to working with file formats in Python (although I don’t think my editor would go for it). Instead, I’ll breeze through several of the most common formats. For each of these, you can pair the concepts from this chapter with the documentation for the particular modules or libraries you’re using.    #### CSV    One of the most common structured text formats is *CSV*, which stands for *comma-separated values*. As its name suggests, it separates individual values with commas. Sets of values are separated by newline characters (`\\n`).    CSV format is used by nearly all spreadsheets and databases, although seldom in a standardized manner. A CSV file exported by Excel may not be the same as one exported by a UNIX program. These subtle differences, known as *dialects*, ordinarily make working with CSV a bit tricky.    Python’s standard library includes a `csv` module that not only handles serializing to and deserializing from CSV files, but also abstracts out the differences between CSV dialects.    To learn more about the `csv` module, see the Python documentation: [https://docs.python.org/3/library/csv.html#module-csv](https://docs.python.org/3/library/csv.html#module-csv).    #### INI    The *INI* format is excellent for storing configuration files, especially settings. It’s an informal standard that is designed to be human-readable and easy to parse. You’ll find INI files on Windows and Unix systems alike. You’ve almost certainly encountered files like *php.ini* and *Desktop.ini*—and perhaps, you’ve even encountered *tox.ini*, which is used by many Python tools, including `flake8` and `pytest`. It’s also common to find *.conf*, *.cfg,* and even *.txt* files that use this INI format.    Python’s standard library includes the `configparser` module for working with INI-style files, although this module invented its own format for multiline strings. This makes the module’s output potentially incompatible with anything other than Python’s `configparser`, and it has no support for nested sections. It also can’t work with the value-type prefixes used by Windows Registry-style INI files.    See the official documentation for `configparser` to learn how to use it: [https://docs.python.org/3/library/configparser.html#module-configparser](https://docs.python.org/3/library/configparser.html#module-configparser).    Alternatively, the third-party library *configobj* supports nested sections and the standard multiline strings, along with many other features lacking in `configparser`. Files created by this module are compatible with other INI parsers, especially those in other languages. The official documentation for this library is available at [https://configobj.readthedocs.io/en/latest/](https://configobj.readthedocs.io/en/latest/).    #### XML    *XML* is a structured markup language based upon the idea of tags, elements, and attributes. Many other file formats use the XML syntax, including *XHTML*, *SVG*, *RSS*, and most office document formats (*DOCX* and *ODT*). You can use XML to devise your own text-based file formats.    Python developers often shun XML in favor of JSON, for two reasons: *simplicity of usage* and *security*. The same structures can be represented in both JSON and XML, but working with XML in Python involves eight different modules. These are all covered in detail at [https://docs.python.org/3/library/xml.html](https://docs.python.org/3/library/xml.html). Given a choice between XML and JSON, you’ll always find it easier to work with the latter.    XML also has a number of security vulnerabilities, which must be taken into account whenever you’re deserializing untrusted or unauthenticated data. The built-in Python modules specifically are vulnerable to some of these attacks, so when security is a factor, the documentation advises use of the *defusedxml* and *defusedexpat* third-party libraries.    Alternatively, you can use the third-party library *lxml*, which addresses many of these issues. More information about this library is available at [https://lxml.de/](https://lxml.de/).    #### HTML    I doubt I need to tell you what *HTML* is, since it is ubiquitous on the internet. Python allows you to work with HTML files via the built-in `html` module and its two submodules: `html.parser` and `html.entities`. This is a very deep rabbit hole (unsurprisingly), so I’ll leave you to explore it on your own if you’re interested. The documentation is a good place to start: [https://docs.python.org/3/library/html.html](https://docs.python.org/3/library/html.html).    There are also some excellent third-party libraries for working with HTML, including *lxml.html* (part of *lxml*) and *beautifulsoup4*. You can learn more about the latter at [https://www.crummy.com/software/BeautifulSoup/](https://www.crummy.com/software/BeautifulSoup/).    #### YAML    *YAML* is a popular alternative to markup languages like XML; its name is a recursive acronym for *YAML Ain’t Markup Language*. YAML covers many of the same use cases as XML, but with a simpler syntax.    The latest version of this language—YAML 1.2—implements all the features of JSON, in addition to its own syntax. This means all JSON is also valid YAML 1.2\\. Besides this, all JSON output by Python using default settings is compatible with YAML 1.0 and 1.1\\. Thus, at least in Python, YAML is always a superset of JSON. One particular advantage of YAML over JSON is its support for comments.    The third-party *PyYAML* library is listed on the Python wiki as being the only YAML parser that has attempted compliance with the YAML standard. More information about this library can be found at [https://pyyaml.org/](https://pyyaml.org/).    YAML does have potential security concerns—namely, it can be used to execute arbitrary Python code. The PyYAML library has a `yaml.safe_load()` function that mitigates this risk, so that should be used instead of `yaml.load()`.    #### TOML    Another option for configuration files is *TOML*, an acronym for *Tom’s Obvious, Minimal Language*. It’s an open format created by Tom Preston-Werner. It draws inspiration from INI, but it implements a formal specification.    The most popular third-party library for working with TOML is appropriately called *toml*. You can learn more about it at [https://github.com/uiri/toml/](https://github.com/uiri/toml/).    #### ODF    The *Open Document Format* (ODF) is an XML-based document format developed and maintained by the Organization for the Advancement of Structured Information Standards (OASIS). It is being widely adopted and is increasingly becoming a ubiquitous document standard. It is used by nearly all modern word processors, including LibreOffice, Microsoft Word, and Google Docs.    The primary use for ODF is when working with data ordinarily handled by an office suite. Perhaps you’re writing a grammar checker, a spreadsheet validator, a word processor, or a slide deck organizer.    One of the most popular Python libraries for working with the Open Document Format is *odfpy*, which is developed and maintained by the European Environmental Agency. More information and documentation for this library is available at [https://github.com/eea/odfpy/wiki/](https://github.com/eea/odfpy/wiki/).    #### RTF    The *Rich Text Format* (RTF) is a popular document format that supports basic text formatting. Although it’s a proprietary format originally developed by Microsoft for Word, it’s relatively common for basic documents because of its simplicity and portability. Although the format is no longer in active development and has lost ground to the Open Document Format, it is still just as usable as ever.    There are a few third-party packages for working with Rich Text Format. The most popular library for Python 2 was *PyRTF*. Two forks of that library exist for Python 3: *PyRTF3* and *rtfx*. (As of this writing, the *PyRTF3* library is unmaintained, although it is still available in pip.) *RTFMaker* is a newer alternative, presently under active development. Unfortunately, documentation for all four libraries is sparse, so plan on sailing into uncharted waters if you use any of these libraries.    Alternatively, if none of these libraries do what you need or you don’t want to work without documentation, the Rich Text Format is simple enough that you can write your own basic parser with a little research. It’s a closed specification, so it can be hard to find the official documents, but version 1.5 of the Rich Text Format Specification is archived here: [http://www.biblioscape.com/rtf15_spec.htm](http://www.biblioscape.com/rtf15_spec.htm).    ## Wrapping Up    Who would have guessed how much was involved in working with text files in Python? I’ve only scratched the surface of this topic, the complexity of which is belied by the existence of so many five-minute beginner’s tutorials.    Opening a file is easy enough, using a `with` statement and the `open()` function. The `pathlib` module handles paths in a platform-agnostic fashion, so you can stop worrying about which way your slash is supposed to lean. Dozens of modules (from the standard library and third-party developers) exist for handling the countless text-based file formats out there, often via a few method calls. When you put all these pieces together, you ultimately get delightfully simple, yet robust, patterns for handling text files.    In the next chapter, I’ll introduce the techniques necessary to work with binary data in Python, especially in the context of reading and writing binary files.    It feels good to move beyond the boundaries of the program execution and create real files on the user’s computer, doesn’t it?*```", "```py```", "``` chapter = 0xc print(chapter)  # prints '12' ```", "``` chapter = 0xc print(bin(chapter))  # prints '0b1100' print(hex(chapter))  # prints '0xc' print(oct(chapter))  # prints '0o14' ```", "``` print(bin(42))   # prints  '0b101010' print(bin(-42))  # prints '-0b101010' ```", "``` print(bin(-42 & 0b11111111))  # prints '0b11010110' ```", "```  0b**1**101 & 0b**1**010 = 0b**1**000 ```", "```  0b**11**0**1** | 0b**1**0**1**0 = 0b**1111** ```", "```  0b1**101** ^ 0b1**010** = 0b0**111** ```", "``` ~ 0b0101 = 0b1010 ```", "``` ~ 0b000...0101 = 0b111...1010 ```", "``` print(bin(~0b0101))           # prints '-0b110' (that is, -0b0101 - 0b1) print(bin(~0b0101 & 0b1111))  # prints '0b1010' (much better) ```", "``` `<<`) and *Right Shift* (`` `>>`) operators. In binary arithmetic, there are two types of shifts, of which a programming language can only use one on its shift operators. The *logical shift* allows bits to “drop off” the end of the number, shifting in zeros at the other end to replace discarded bits. The *arithmetic shift* does the same as the logical shift, but it will also shift in the *sign bit* (`1` in negative numbers) where necessary to preserve the sign. `` ```", "````` ```py`Every language must decide which form of bitwise shift its operators should use, and Python uses the *arithmetic shift*. In addition, because of the infinite nature of integers, you cannot discard bits with a left shift; the integer will keep growing to accommodate them, as you can see here:    ``` print(bin(0b1100 << 4))   # prints '0b11000000' ```py    Listing 12-6: bitwise_shift.py:1    That probably won’t have any profound effect on your code, but it may change how you implement some binary algorithms that rely on discarding bits with a left shift.    A right shift will preserve the sign, so it will shift in `0`s on the left for positive integers and `1`s for negative integers:    ``` print(bin(0b1100 >> 4))   # prints  '0b0' (0b0...0000) print(bin(-0b1100 >> 4))  # prints '-0b1' (0b1...1111) ```py    Listing 12-7: bitwise_shift.py:2    In summary, [Table 12-8](#table12-8) shows those bitwise operators again, as well as their corresponding special methods.      Table 12-8: Bitwise Operators       | **Operator** | **Use** | **Binary (not Python) example** | **Special method** | | --- | --- | --- | --- | | `&` | Bitwise And | `1100 & 1011 ⇒ 1000` | `__and__(``a``,` `b``)` | | `&#124;` | Bitwise Or | `1100 &#124; 1011 ⇒ 1111` | `__or__(``a``,` `b``)` | | `^` | Bitwise Exclusive Or (Bitwise XOR) | `1100 ^ 1011 ⇒ 0111` | `__xor__(``a``,` `b``)` | | `~` | Bitwise Inversion (Bitwise Not) | `~1100 ⇒ 0011` | `__inv__(``a``)` `__invert__(``a``)` | | `<<` | Left (arithmetic) Shift | `0111 << 2 ⇒ 11100` | `__lshift__(``a``,` `b``)` | | `>>` | Right (arithmetic) Shift | `0111 >> 2 ⇒ 0001` `1..1010 2 ⇒ 1..1110` | `__rshift__(``a``,` `b``)` |    These operators also work on boolean values, which are internally based on integers (much to the consistent annoyance of one of my colleagues!). They won’t work like this on other types—only on booleans and integers.    Be cautious when using bitwise with existing custom classes! Because they’re uncommonly used compared to many other operators, some classes choose to repurpose the bitwise operators for altogether unrelated purposes. Thus, performing bitwise operations on anything except an integer or boolean can result in wildly unpredictable behavior. Be sure to read the documentation on any class you want to use before you rely on the bitwise operators with it!    You can make your own objects work with the bitwise operators themselves by implementing the corresponding special methods from [Table 12-8](#table12-8).    ## Bytes Literals    Another way to represent binary in Python is with a *bytes literal*, which looks like a string literal prepended with `b`, such as `b\"HELLO\"` or `b\"\\xAB\\x42\"`. These are not strings, but rather sequences of bytes, with each byte represented by either an ASCII character (such as `\"H\"` for `0x48`) or a hexadecimal escape sequence (such as `\"\\x42\"` for `0x42`). Unlike integer objects, bytes literals have the explicit size and implied byte order you give them.    Here’s that example bytes literal, which contains the binary equivalent of the string “HELLO”:    ``` bits = b\"HELLO\" ```py    Listing 12-8: bytes_literal.py:1a    Although a bytes literal isn’t exactly a string, most of the rules of string literals still apply here, with two major exceptions. First, a bytes literal can only contain ASCII characters (values `0x00` to `0xFF`), partly because each item in a bytes literal must be exactly one byte in size, and partly for backward compatibility with Python 2 and other languages that use ASCII text encoding. Second, unlike strings, bytes literals cannot be formatted via f-strings.    In all Python strings, you can use the escape sequence `'\\x``hh'` to represent a character with the hexadecimal value `hh`. Unlike in some languages, the escape sequence must always contain a two-digit hexadecimal number. It does not matter whether the digits `A` through `F` are uppercase or lowercase: `'\\xAB'` and `'\\xab'` are treated the same, although Python always outputs the latter.    For example, if I knew the hexadecimal codes I needed for `\"HELLO\"`, I could use them in place of some (or all) the ASCII character literals:    ``` bits = b\"**\\x48\\x45\\x4C\\x4C\\x4F**\" ```py    Listing 12-9: bytes_literal.py:1b    These hexadecimal literals are also needed when the desired value cannot be represented by a visible character, such as `'\\x07'`, which in ASCII is the nonprinting control code `BEL`, which sounds the system bell. (And yes, `print('\\x07')` will indeed play a sound, assuming you haven’t turned off your system bell in your terminal or system settings.)    You can also create raw bytes literals, wherein the backslash character (`\\`) is always treated as a literal character. Because of this, raw bytes literals cannot interpret escape sequences, which limits their usefulness. However, if you don’t need escape sequences and do want literal backslashes, then raw bytes literals can occasionally come in handy. To define a raw bytes literal, precede the string with either `rb` or `br`. I demonstrate this below:    ``` bits_escaped = b\"\\\\A\\\\B\\\\C\\\\D\\\\E\" bits_raw = br\"\\A\\B\\C\\D\\E\" print(bits_raw)                  # prints b'\\\\A\\\\B\\\\C\\\\D\\\\E' print(bits_escaped == bits_raw)  # prints 'True' ```py    Listing 12-10: bytes_literal.py:2    Both `bits_escaped` and `bits_raw` have exactly the same value, as demonstrated by the comparison in the `print()` statement, but the value assigned to `bits_raw` was easier to type.    ## Bytes-Like Objects    If you need to store binary data, Python offers *bytes-like objects*. Unlike integers, these objects have a fixed size and an *implied* byte order. This means they have the byte order you followed when you provided the bytes to the bytes-like object; it also means you are responsible for explicitly defining the byte order of the data you provide. This can be helpful when the infinite nature of integers gets underfoot. Bytes-like objects also provide a number of utility functions, unlike bytes literals.    There’s one drawback: the bitwise operators don’t work with bytes-like objects. That may sound strange, and even annoying, and the exact reasons for this are largely unknown. There are two very plausible reasons, however.    First, it’s essential to avoid unexpected behavior relating to byte order. If you tried to perform a bitwise operation on a big-endian and a little-endian object greater than one byte, the result’s byte order would be unclear. You’d run the risk of getting garbage output, which would be quite difficult to debug.    Second, it’s difficult to predict how to handle bitwise operations on bytes-like objects of different lengths. You could pad them to be the same length, but you’d again need to know the byte order to do that correctly.    Instead of making the language guess how to implicitly resolve these difficult patches of logic, bytes-like objects just don’t support bitwise operators. There are a couple of ways to perform bitwise manipulations on bytes-like objects, but they’re a little more involved. I’ll come back to that shortly.    There are two primary bytes-like objects: `bytes`, which is immutable, and `bytearray`, which is mutable. Both objects are identical in all other regards: they provide the same functionality as any other Python sequence and offer the same methods and behaviors. The two objects are even interoperable.    The decision of whether to use `bytes` or `bytearray` comes down solely to whether you want a mutable or an immutable object. For simplicity, I’ll mainly use the `bytes` object in this section; the code would be the same for `bytearray`.    ### Creating a bytes Object    There are six ways to create a bytes-like object—not counting the default and copy initializers, which create an empty object or copy the value of another bytes-like object, respectively.    The trouble is, passing a binary literal to the initializer unexpectedly results in an empty bytes object. This occurs because a binary literal is really an integer, and passing an integer `n` to the `bytes()` constructor creates an empty bytes object with a size of `n` bytes:    ``` bits = bytes(0b110) print(bits)  # prints '\\x00\\x00\\x00\\x00\\x00\\x00' ```py    Listing 12-11: init_bytes.py:1a    The `bits` object is exactly six (`0b110`) bytes long, and each of those bits is set to zero. Although this may feel like surprising behavior, remember that any binary data passed to `bytes` must have an explicit byte order, something that isn’t inherent to Python integers.    You can create a bytes object from binary literals in a couple of ways. One way is to pass an iterable of integers to the bytes initializer. However, each of the integers provided by the iterable must be positive and representable in a single byte—that is, it must be between the values of `0` and `255`, inclusive—or a `ValueError` will be raised.    The fastest way to do that here is to pack my binary literal into a tuple by itself:    ``` bits = bytes(**(**0b110**,)**) print(bits)  # prints \"b'\\x06'\" ```py    Listing 12-12: init_bytes.py:1b    Recall that I must provide a trailing comma (`,`) in a single-element tuple, or else it will be interpreted as a literal integer instead.    Another way to accomplish this same goal would be to wrap the binary literal in square brackets (`[ ]`) to define a list. Because each integer in the iterable fits in a single byte, the order in which the items are provided by the iterable effectively defines the byte order.    Yet another way to initialize a bytes object is to assign a bytes literal:    ``` bits = b'\\x06' print(bits)  # prints \"b'\\x06'\" ```py    Listing 12-13: init_bytes.py:2a    In the case of `bytearray`, you’d pass that literal to the initializer:    ``` bits = **bytearray(**b'\\x06'**)** print(bits)  # prints \"b'\\x06'\" ```py    Listing 12-14: init_bytes.py:2b    No surprises there.    Finally, I can create a bytes object from any string, although I must explicitly state the text encoding being used:    ``` bits = bytes('☺', encoding='utf-8') print(bits)  # prints \"b'\\xe2\\x98\\xba'\" ```py    Listing 12-15: init_bytes.py:3    The smiley face emoji (`☺`) is a Unicode character with a UTF-8 encoding that spans three bytes: `0xE298BA`. If you’re familiar with Unicode, you’ll notice what is not happening here: bytes is *not* using the formal Unicode code point for the smiley face emoji (`U+263A`), but rather, it is using the internal binary representation that UTF-8 uses.    I could have left the keyword off the `encoding=` argument, and many Python programmers will, but I prefer to spell it out explicitly. Just know that `bytes('☺', 'utf-8')` is equivalent.    ### Using int.to_bytes()    Perhaps the easiest way to convert between an integer and a bytes-like object is with the `int.to_bytes()` method.    As mentioned, when working with bytes, you must specify the byte order. The byte order required is often determined by your situation, such as what particular file format you’re working with. Networks always use big-endian byte order.    Beyond that, the choice is somewhat arbitrary. If the data is only being used by my application, I’ll usually stick to big-endian, which is my preference; if the data will be handled by system processes, I’ll employ the system’s byte order, which I determine with the following:    ``` import sys  print(sys.byteorder)  # prints 'little' ```py    Listing 12-16: int_to_bytes.py:1    The `sys.byteorder` attribute provides the byte order of the current system as a string. On my machine, as on most modern computers, the value is the string `'little'`, for little-endian.    Now, I can create my `bytes` object:    ``` answer = 42 bits = answer.to_bytes( ❶ 4, byteorder=sys.byteorder) print(bits.hex( ❷ sep=' '))  # prints '2a 00 00 00' ```py    Listing 12-17: int_to_bytes.py:2a    I start by binding an integer value to the name `answer`. All `int` objects have a `to_bytes()` method for converting the value to a bytes-like object. I call that method on `answer`, passing the desired size in bytes (arbitrary for this example) of the resulting bytes-like object ❶ and the byte order to use. I bind the `bytes` object to the name `bits`.    Finally, to make the output more readable, I print out the value of `bits` in hexadecimal, instead of the default bytestring, separating the individual byte values with spaces ❷. The value `42` is representable with only one byte, and this byte (`2a`) appears on the left, since I’m using little-endian byte order.    When I try this with negative numbers, things get a little trickier. The same method as above would not work for the value `-42`:    ``` answer = -42 bits = answer.to_bytes(4, byteorder=sys.byteorder) print(bits.hex(sep=' ')) ```py    Listing 12-18: int_to_bytes.py:3a    This code fails on the `answer.to_bytes()` method call with the following:    ``` Traceback (most recent call last):   File \"tofrombytes.py\", line 10, in <module>     bits = answer.to_bytes(4, byteorder=sys.byteorder) OverflowError: can't convert negative int to unsigned ```py    To get around this, I must explicitly specify that the integer is *signed*, meaning two’s complement is being used to represent negative numbers:    ``` answer = -42 bits = answer.to_bytes(4, byteorder=sys.byteorder**, signed=True**) print(bits.hex(sep=' '))  # prints 'd6 ff ff ff' ```py    Listing 12-19: int_to_bytes.py:3b    This version works as expected, as you can see from the output of the `print` statement.    By default, the `signed` parameter is `False` to avoid surprises, many originating from the fact that Python only *pretends* to use two’s complement but is really doing its own thing. In any case, you should get into the habit of setting it to `True` when converting anything that *might* be a negative number to an integer. If the integer value is positive, setting `signed` to `True` won’t have any effect:    ``` answer = 42 bits = answer.to_bytes(4, byteorder=sys.byteorder, **signed=True**) print(bits.hex(sep=' '))  # prints '2a 00 00 00' ```py    Listing 12-20: int_to_bytes.py:2b    ### Sequence Operations    Nearly all operations you can perform on a sequence like a tuple or a list, you can do with bytes-like objects. For example, to see if there’s a particular sequence of bytes in a larger bytes object, you can use the `in` operator:    ``` bits = b'\\xaa\\xbb\\xcc\\xdd\\xee\\xff' print(b'\\xcc\\xdd' in bits)  # prints 'True' ```py    Listing 12-21: bytes_in.py    The `in` operator here is acting like it would with a string.    I won’t go into any more depth on these operations here, as they behave precisely like they would in `tuple` (for `bytes`) or `list` (for `bytearray`).    ### Converting bytes to int    You can create an integer from a `bytes` object using `int.from_bytes()`. I’ll start by defining a `bytes` object to convert from:    ``` import sys  bits = ❶ (-42).to_bytes(4, byteorder=sys.byteorder, signed=True) ```py    Listing 12-22: bytes_to_int.py:1    In the same way I called `to_bytes()` on a name bound to an integer value, I call the same method on an integer literal wrapped in parentheses here ❶. This code defines a new `bytes` object, bound to the name `bits`, with the same value as in [Listing 12-19](#listing12-19).    To convert the value from `bits` into an integer value, I use the `int.from_bytes()` method, which I’m calling on the `int` class:    ``` answer = int.from_bytes(bits, byteorder=sys.byteorder, signed=True) print(answer)  # prints '-42' ```py    Listing 12-23: bytes_to_int.py:2    I pass `bits` to the method and indicate the `byteorder` and the `bytes` object used. I also indicate via `signed=True` that the bytes object is using two’s complement to represent negative values. The byte order and signed values are not remembered by the bytes object; you’ll need to know these whenever converting from `bytes` objects to integers.    The value of `answer` is `-42`, which was obtained from the bytes object.    ## struct    The deeper you get into Python’s inner workings, the more you discover the C language peeking through. This is largely owing to the fact that CPython, the primary implementation of Python, is written in C. Interoperability with C remains a factor in how the language is implemented. One example of this is the `struct` module. It was originally created to allow data to be moved between Python values and C structs. It soon proved to be a handy way to convert values to packed binary data, specifically *contiguous* binary data, which is stored one item after the next in memory.    The modern `struct` module uses `bytes` for storing this binary data, providing the sixth way of creating bytes-like objects. Unlike `int.to_bytes()`, which is limited to integers, the `struct.pack()` method can also convert floating-point numbers and strings (character arrays) to binary, using whichever byte order you request. However, remember that strings themselves are unaffected by byte order. You can also use `struct.pack()` to pack multiple values into the same `bytes` object and later unpack those individual values into separate variables.    By default, `struct` will align all values to the exact sizes expected by the C compiler on your system, padding (or truncating padding) where necessary, although you can change this alignment behavior to use standard sizes instead.    ### struct Format String and Packing    The byte order, alignment behavior, and data types for `struct` are determined by the *format string*, which must be passed to any of the module’s functions, or else to the initializer of the `struct.Struct` object, which lets you reuse the format string more efficiently.    Often, the first character of the format string defines the byte order and alignment behavior, as in [Table 12-9](#table12-9).      Table 12-9: struct Format String Byte Order Flags       | **Character** | **Behavior** | | --- | --- | | `@` | Use native byte order and alignment (default). | | `=` | Use native byte order, but no alignment. | | `<` | Little-endian, no alignment. | | `>` | Big-endian, no alignment. | | `!` | Network standard: big-endian, no alignment (same as `>`). |    If you omit this initial character, `struct` will use the native byte order and alignment (same as if you start with `@`), padding the data as necessary to make sense to the C compiler. The rest of the string indicates the data types and order of the values being packed into the struct. Each of the basic C data types is represented by a character, as shown in [Table 12-10](#table12-10).      Table 12-10: struct Format Characters       | **Character** | **C type** | **Python type** | **Standard size** | | --- | --- | --- | --- | | `?` | `_Bool` (C99) | `bool` | 1 | | `c` | `char` | `bytes(1)` | 1 | | `b` | `signed char` | `int` | 1 | | `B` | `unsigned char` | `int` | 1 | | `h` | `short` | `int` | 2 | | `H` | `unsigned short` | `int` | 2 | | `i` | `int` | `int` | 4 | | `I` | `unsigned int` | `int` | 4 | | `l` | `long` | `int` | 4 | | `L` | `unsigned long` | `int` | 4 | | `q` | `long long` | `int` | 8 | | `Q` | `unsigned long long` | `int` | 8 | | `e` | (IEEE 754 binary16 “half precision”) | `float` | 2 | | `f` | `float` | `float` | 4 | | `d` | `double` | `float` | 8 | | `s` | `char[]` | `bytes` |  | | `p` | `char[]` (Pascal string) | `bytes` |  | | `x` | (pad byte) | effectively `bytes(1)` |  |    Most of these types are self-explanatory, especially if you know C (or C++, for that matter). When using native alignment, the size of each type will depend on the system; otherwise, `struct` uses the standard size.    If I wanted to pack two integers and a boolean, in that order, using big-endian notation (and standard sizes), I’d use the following format string:    ``` import struct  bits = struct.pack('>ii?', 4, 2, True) print(bits)  # prints '\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x02\\x01' ```py    Listing 12-24: struct_multiple_values.py:1a    Here, I use the `struct.pack()` function, to which I pass the format string and all the values I want to pack, in order. This creates a bytes object.    Alternatively, I can precede the type character with the desired number of values of that type. Here, I specify two adjacent integer values with `2i`, instead of `ii`. The outcome is the same as before:    ``` import struct  bits = struct.pack(**'>2i?'**, 4, 2, True) print(bits)  # prints '\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x02\\x01' ```py    Listing 12-25: struct_multiple_values.py:1b    The format character `'e'` refers to the *half-precision* floating-point number introduced in the 2008 revision of the IEEE 754, which is the document that defines the floating-point standard used by all modern computers.    The pad byte, `'x'`, is exactly one empty byte (`\\x00`). Use `'x'` to manually pad your data. For example, to pack two integers with exactly three empty bytes between them, I’d use the following:    ``` import struct  bits = struct.pack('>i3xi', -4, -2) print(bits)  # prints '\\xff\\xff\\xff\\xfc\\x00\\x00\\x00\\xff\\xff\\xff\\xfe' ```py    Listing 12-26: struct_ints_padded.py:1    There are two ways to represent strings in `struct`. Typically, you must *null-terminate* traditional strings (`'s'`), meaning the last character is always `\\x00`, to mark the end. The number preceding the format character is the length of the string in characters; `'10s'` would be a 10-character string (that is, 9 characters and the null terminator byte). I can pack the string `\"Hi!\"` like this:    ``` import struct  bits = struct.pack('>4s', b\"Hi!\") print(bits)  # prints 'Hi!\\x00' ```py    Listing 12-27: struct_string.py:1    You’ll notice that I wrote my string as a bytes literal by prepending it with `b`. The `struct.pack()` method cannot work directly with strings, but rather must have a bytes literal where the format calls for a string. (A little later, I have an example where I convert a typical UTF-8 string to a bytes literal.)    As long as you know the size of your string and the data will only ever be read by your code, you don’t have to include the null terminator byte here. However, it’s good to be in the habit if you’ll be sending your data out of Python. If a C program tried to work with a string that lacked a null terminator, some pretty strange behavior could result.    Alternatively, you can use a Pascal string (`'p'`), which begins with a single byte representing the size as an integer. This string format doesn’t require a null termination character, because its size is explicitly stored in the first byte. However, it also effectively limits the maximum size of the string to 255 bytes.    ``` bits = struct.pack('>4p', b\"Hi!\") print(bits)  # prints '\\x03Hi!' ```py    Listing 12-28: struct_string.py:2    Another consideration is that you may need to pad your `struct` to the *word size*, which is the smallest addressable chunk of memory, on your system. This is especially relevant when packing data to be handed off to C.    For example, a C `struct` of two longs and one short has a length of 24 bytes, but the format string `'@llh'` only produces an 18-byte chunk of binary. To correct this, append the format string with a zero, followed by the largest type in your struct; in this case, that format string would be `'@llh0l'`:    ``` struct.calcsize('@llh')    # prints '18' (wrong) struct.calcsize('@llh0l')  # prints '24' (correct, what C expects) ```py    There is never any danger in padding this way. If it’s not needed, the size will be unaffected. This is only applicable when using native byte order and alignment (`@`), which is necessary for exchanging data with C. If you’re specifying byte order manually or using network standard (no alignment), this won’t matter and will have no effect.    There are also three types I’ve deliberately omitted from [Table 12-10](#table12-10): `ssize_t` (`n`), `size_t` (`N`), and `void*` (`P`). These are only available if you’re using native byte ordering and alignment (`@`), but you won’t need those unless you’re moving data between C and Python. See the documentation if you need to know about them: [https://docs.python.org/3/library/struct.html#format-characters.](https://docs.python.org/3/library/struct.html#format-characters.)    ### Unpacking with struct    To unpack data from a `struct` back into Python values, I must first determine the appropriate format string for the binary data.    Consider an integer packed into `bytes` using native byte order and alignment:    ``` import struct  answer = -360 bits = struct.pack('i', answer) ```py    Listing 12-29: struct_int.py:1    As long as I know that `bits` uses native ordering and contains a single integer, I can retrieve that integer with `struct.unpack()`:    ``` new_answer, = struct.unpack('i', bits) print(new_answer)  # prints '-360' ```py    Listing 12-30: struct_int.py:2    Notice that I included a trailing comma (`,`) after `new_answer` in the assignment statement. The `struct.unpack()` function always returns a tuple, which I must unpack. Since that tuple contains only one value, the trailing comma forces it to unpack; otherwise, `new_answer` would be bound to the tuple itself.    As one more example, I’ll unpack the two integers from the bytes-like object from [Listing 12-26](#listing12-26):    ``` first, second = struct.unpack('>i3xi', bits) print(first, second)  # prints '-4 -2' ```py    Listing 12-31: struct_ints_padded.py:2    The three pad bytes (`'3x'`) are discarded, and the two integers are unpacked into the names `first` and `second`.    When working with `struct`, it is absolutely imperative that you know the format string that was used to pack the `struct` in the first place. Observe what would happen if I changed the format string in a few ways:    ``` wrong = struct.unpack('<i3xi', bits)   # wrong byte order print(*wrong)                          # prints '-50331649 -16777217'  wrong = struct.unpack('>f3xf', bits)   # wrong types print(*wrong)                          # prints 'nan nan'  wrong = struct.unpack('>hh3xhh', bits) # wrong integer type print(*wrong)                          # prints '-1 -4 -1 -2'  wrong = struct.unpack('>q3xq', bits)   # data sizes too large print(*wrong)                          # throws struct.error ```py    Listing 12-32: struct_ints_padded.py:3    All but the last example *seem* to work, but all the values I’ve unpacked are wrong. The moral is simple: know your layout so you can use the correct format strings.    ### struct objects    If you need to use the same format string repeatedly, the most efficient approach is to initialize a `struct.Struct` object, which provides methods analogous to the `struct` functions. For example, here I want to repeatedly pack two integers and a floating-point number into bytes objects, so I’ll create a `Struct` object.    ``` import struct  packer = struct.Struct('iif') ```py    Listing 12-33: struct_object.py:1    I create a `Struct` object with the format string `'iif'`, and I bind it to the name `packer`. The `Struct` object remembers this format string and uses it for any `pack()` or `unpack()` calls on the object.    Next, I’ll write a generator that produces some strange numeric data and packs it into bytes-like objects:    ``` def number_grinder(n):     for right in range(1, 100):         left = right % n         result = left / right         yield packer.pack(left, right, result) ```py    Listing 12-34: struct_object.py:2    In this example, I’m iterating over integers 1 through 99 as the `right` operand of division, and then I’m taking as the `left` operand the modulo of the `right` value and whatever number was passed to the function as `n`. Then, I perform the division with left and right, binding the result to `result`. (There’s no particular reason for this math; it’s just for fun.)    Next, I use `packer.pack()` and pass it the operands and the result of the division. The `packer` object uses the format string I passed to its initializer earlier.    In the next part of my code, I retrieve the packed `struct` data from the generator and, for the sake of the example, unpack the data again, using the `packer` object:    ``` for bits in number_grinder(5):     print(*packer.unpack(bits)) ```py    Listing 12-35: struct_object.py:3    If you run that code, you’ll see the `left`, `right`, and `result` values that had been packed into the bytes objects yielded by the generator. This is a silly example, of course; in the real world, I would have done something useful with this binary data, such as storing it in a file, instead of merely unpacking it again.    ## Bitwise on Bytes-Like Objects    As I mentioned earlier, bytes-like objects, including `bytes` and `bytearray`, do not directly support bitwise operators. Annoying as this may seem, it makes sense when you consider that bytes-like objects don’t know their own byte order. If you performed a bitwise operation between a big-endian and a little-endian value, it would be impossible to determine the byte order of the result. If there’s one thing that Python developers hate, it’s unclear behavior.    It is possible to perform bitwise operations on bytes-like objects, but you must use one of two workarounds.    ### Bitwise Operations via Integers    The first option is to convert the bytes-like objects to integers first, which resolves the byte order. Integers in Python are technically infinite, so this approach can be leveraged for handling binary data of differing lengths.    Here, I write a function to handle a bitwise operation between two bytes-like objects:    ``` def bitwise_and(left, right, *, byteorder):     size = max(len(left), len(right)) ```py    Listing 12-36: bitwise_via_int.py:1    My `bitwise_and()` function accepts three arguments: the two bytes-like objects (`left` and `right`) as operands for the bitwise operation, plus the byteorder. You will recall that the `*` in the parameter list forces all parameters after it, namely `byteorder`, to be keyword-only arguments. I don’t offer a default argument for `byteorder`, for the same reason `bytes` objects don’t have bitwise operators. If the user is unable to provide this argument explicitly, the function should fail, rather than potentially producing garbage output.    To convert the result back to `bytes` in the last step, I must know the size of the result (which should be size of the largest `bytes` object passed to it) so I don’t chop off leading or trailing zeros—or actual data, if this were for another bitwise operation!    Because `bytes` is a sequence, it implements the `__len__()` special method. In my function, I take the `max()` of the lengths of the two `bytes` arguments, and I use that value as the size of the output. Here’s the next piece of the function I started in [Listing 12-36](#listing12-36):    ```  left = int.from_bytes(left, byteorder=byteorder)     right = int.from_bytes(right, byteorder=byteorder) ```py    Listing 12-37: bitwise_via_int.py:2    I convert the `left` and `right` bytes-like objects to integers by using the `int.from_bytes()` method, employing the byte order passed to my function. Meanwhile, in writing my code, I must assume the arguments from [Listing 12-36](#listing12-36) are mutable, lest `bitwise_and()` have a risk of side effects.    Please note, *I am not using* `signed=True` *here*! This is utterly vital for the bitwise operation to turn out right. Otherwise, my function will interpret any bytes-like object with a `1` in the most significant bit as indicative of a negative integer. This would thereby pad the significant end of the integer with infinite `1`s. The effective result of `0xCCCCCC & 0xAAAA` according to this function would then be `0xCC8888`, rather than the correct value of `0x008888`.    Now that I have integer forms of these arguments, I can use the normal bitwise operator on them. Here’s the last piece of the function, continued from [Listing 12-37](#listing12-37):    ```  result = left & right     return result.to_bytes(size, byteorder, signed=True) ```py    Listing 12-38: bitwise_via_int.py:3    I bind the result of the bitwise operation to `result`. Finally, I convert `result` back to a `bytes` object, using the `size` I determined earlier, the `byteorder` passed to my function, and `signed=True` to handle conversion of any possible negative integer values. I return the resulting bytes-like object.    I’ll use my `bitwise_and()` function to perform a bitwise operation with any two bytes-like objects:    ``` bits = b'\\xcc\\xcc\\xcc'   # 0b110011001100110011001100 bitfilter = b'\\xaa\\xaa'  # 0b1010101010101010  result = bitwise_and(bits, bitfilter, byteorder='big') print(result)            # prints \"b'\\x00\\x88\\x88'\" ```py    Listing 12-39: bitwise_via_int.py:4    The result is exactly right! It doesn’t matter what bytes-like objects I pass to this function; it will work as expected.    ### Bitwise Operations via Iteration    The bitwise-via-integers approach is the most flexible, but it can be impractical when you’re working with a lot of data, since you’re duplicating the contents of the two `bytes` objects in `int`. For the algorithmic efficiency crowd, the integer approach has a space complexity of `Θ(n)`. Another option is to use iteration, instead of using integers as intermediary objects. Interestingly, both options have roughly the same time complexity. In fact, the iterative approach is slightly *slower*! Its strength is a lower space complexity, which lets it avoid excessive memory consumption when processing a large amount of data.    When you have a lot of binary data on which to perform bitwise operations, it’s sometimes better to leverage the iterable nature of bytes-like objects. Here, I’ll write another function for performing a bitwise operation on two bytes-like objects, this time with iteration:    ``` def bitwise_and(left, right):     return bytes(l & r for l, r in zip(left, right)) ```py    Listing 12-40: bitwise_via_iter.py:1a    Within my `bitwise_and()` function, I employ a generator expression to create a new `bytes` object, which I ultimately return. Iterating over bytes-like objects yields positive integer values equivalent to each byte. The `zip()` function allows me to iterate over both the `left` and `right` bytes objects at the same time, and then I take the bitwise and (`&`) of the pair of integers produced on each iteration.    I use this function in much the same manner as with the integer version, except that I don’t need to bother with the byte order. The implicit byte order of the operands is used. (As mentioned earlier, it’s your responsibility to ensure the byte orders are the same!)    Here’s the usage of my function from [Listing 12-40](#listing12-40):    ``` bits = b'\\xcc\\xcc\\xcc'   # 0b110011001100110011001100 bitfilter = b'\\xaa\\xaa'  # 0b1010101010101010  result = bitwise_and(bits, bitfilter) print(result)            # prints \"b'\\x88\\x88'\" ```py    Listing 12-41: bitwise_via_iter.py:2    This present approach has one significant limitation: I can only reliably perform bitwise operations if the operands are the same length. Otherwise, the result will only be as long as the shortest operand object.    It is possible to work with operands of different sizes, but for that, I must know the byte order again, so I know which side to pad. It took me and my colleague Daniel Foerster a fair bit of back-and-forth to work out a reliable and Pythonic solution to this particular problem.    Here’s an expanded form of the iterative `bitwise_and()` function from [Listing 12-40](#listing12-40), which now handles bytes-like objects of different sizes:    ``` import itertools   def bitwise_and(left, right, ***, byteorder**):  **pad_left = itertools.repeat(0, max(len(right) - len(left), 0))**  **pad_right = itertools.repeat(0, max(len(left) - len(right), 0))**  ****if byteorder == 'big':**  **left_iter = itertools.chain(pad_left, left)**  **right_iter = itertools.chain(pad_right, right)**  **elif byteorder == 'little':**  **left_iter = itertools.chain(left, pad_left)**  **right_iter = itertools.chain(right, pad_right)**  **else:**  **raise ValueError(\"byteorder must be either 'little' or 'big'\")**          return bytes(l & r for l, r in zip(**left_iter, right_iter**))** ```py   **Listing 12-42: bitwise_via_iter.py:1b    I create `pad_left` and `pad_right`, which are iterables for the padding on the `left` or `right` operands, respectively. Each of these uses `itertools.repeat()` to produce the value `0` on each iteration, up to a particular number of iterations. That limit is calculated as how many more bytes the other operand has than one I’m padding, or zero if this operand is the larger of the two.    Next, I create two more iterables that combine the padding and the operand for each side of the bitwise operation. The byte order determines the order in which I combine the padding and operand iterables, as the padding must be applied to the higher-value end.    If anything other than `'big'` or `'little'` is passed to the `byteorder` parameter, I raise a `ValueError`. (The exception and its message I raise there are the same as what `int.from_bytes()` would raise with a nonsense `byteorder` argument.)    Finally, with the `left_iter` and `right_iter` iterables, which will produce the same number of bytes, I perform the iterative bitwise in a generator expression, as before.    The usage and return of this version of my `bitwise_and()` function is identical to that of the integer-based version:    ``` bits = b'\\xcc\\xcc\\xcc'   # 0b110011001100110011001100 bitfilter = b'\\xaa\\xaa'  # 0b1010101010101010  result = bitwise_and(bits, bitfilter**, byteorder='big'**) print(result)            # prints \"b'\\x00\\x88\\x88'\" ```py    Listing 12-43: bitwise_via_iter.py:2b    Again, the advantage of the iterative approach is that it is optimized for space complexity. In terms of time complexity, it is slower than the integer-based approach from earlier, so it should be reserved for working with particularly large bytes-like objects. Otherwise, stick with `int.from_bytes()` and `int.to_bytes()` for bitwise operations on bytes-like objects.    ## memoryview    When you’re slicing a bytes object, a copy of the data being sliced is created. Ordinarily, this has no negative effects, especially when you’re going to assign the data anyway. However, when you’re working with particularly large slices, especially repeatedly, all that copying can create some serious performance slowdowns.    The `memoryview` class helps alleviate that, by accessing the raw memory data of any object that implements the *buffer protocol*, a set of methods that provide and govern access to an underlying memory array. Bytes-like objects fit this qualification, and you’ll most often use `memoryview` with `bytes` and `bytearray`. You won’t often encounter the buffer protocol in any types other than binary-oriented objects, although `array.array` is a notable exception. (In fact, the buffer protocol is defined and implemented at the C level, rather than in Python itself, so implementing it in your own classes is decidedly nontrivial.)    Since `memoryview` is designed to provide very low-level access to memory, it has a lot of particularly advanced methods and concepts, which I won’t get into here. I will show you its most basic usage: slicing, or accessing a part of, a bytes-like object by reading in place, rather than by making a copy of the sliced data. Although this is only called for when dealing with particularly large buffers, I’ll demonstrate with a small `bytes` object for brevity.    In this example, I want to employ slicing to confirm that a bit of binary data fits a particular format—perhaps that two `0xFF` bytes appear after every three bytes. (Why I’d do this in the real world is beyond me; I just needed an example.) Effectively, I want to slice the fourth and fifth bytes from every five bytes, as the first three of each set of five can be anything.    I’ll start with the version without `memoryview` first, for reference:    ``` def verify(bits):     for i in range(3, len(bits), 5):         if bits[i:i+2] != b'\\xff\\xff':             return False     return True ```py    Listing 12-44: slicing_with_memoryview.py:1a    With this function, I iterate based on the fourth byte (the first in the pair), via the `for` loop. As soon as I reach the end of `bits`, I know I’ve processed everything. (If this ever slices out only the last byte, the code runs just fine and returns `False`, as it should.)    Within each iteration of my loop, I slice out the two bytes I care about with `bits[i:i+2]` and compare that to the `b'\\xff\\xff'` I’m checking for. If it doesn’t match, I immediately return `False`. However, if the code makes it through the loop without that condition failing, then the function returns `True`.    Here’s the usage:    ``` good = b'\\x11\\x22\\x33\\xff\\xff\\x44\\x55\\x66\\xff\\xff\\x77\\x88' print(verify(good))  # prints 'True'  nope = b'\\x11\\x22\\x33\\xff\\x44\\x55\\x66\\x77\\xff\\x88\\x99\\xAA' print(verify(nope))  # prints 'False' ```py    Listing 12-45: slicing_with_memoryview.py:2    As I mentioned, this code is perfectly fine in most cases. When I slice, I make a copy of those two bytes. But if that slice is something on the order of two *kilobytes* in length, with hundreds of slices being made, I may run into some serious performance issues with all that copying.    This is where `memoryview` comes in handy. I’ll update my example to use that instead.    ``` def verify(bits):     **is_good = True**  **view = memoryview(bits)**     for i in range(3, len(**view**), 5):         if **view**[i:i+2] != b'\\xff\\xff':             **is_good = False**             **break**     **view.release()**     return **is_good** ```py    Listing 12-46: slicing_with_memoryview.py:1b    The code is functionally the same as before, except that this time, I create a `memoryview` object, which I bind to the name `view`, to give me direct access to the underlying memory of `bits`.    I can use `memoryview` in essentially the same way as I would `bytes`, except that slicing on a `memoryview` only views the data in place, rather than creating a copy of the data.    It is *vital* that I release the `memoryview` as soon as I’m done with it, by calling the `release()` method on my `memoryview` object. Objects that support the buffer protocol know when they’re being watched by a `memoryview`, and they will change their behavior in various ways to prevent memory errors. For example, a `bytearray` object will not resize as long as there’s a `memoryview` of it. It is always safe to call the `release()` method; at worst, it will do nothing at all. Once I release a `memoryview`, I cannot use it further. Attempting to do so would raise a `ValueError`.    Unfortunately, my code is still rather un-Pythonic, what with having to assign a value to `is_good` and return with that name at the function end. I’d like to polish that up.    Hmm . . . I have to remember to close something when I’m finished with it. Surely, that means `memoryview` is also a context manager that I can use in a `with` statement. Sure enough, that works! I can incorporate that technique to make my function more concise and Pythonic:    ``` def verify(bits):     **with memoryview(bits) as view:**         for i in range(3, len(view), 5):             if view[i:i+2] != b'\\xff\\xff':                 **return False**  **return True** ```py    Listing 12-47: slicing_with_memoryview.py:1c    That’s more like it. This code still behaves the same as the preceding two versions, but it reads cleaner and doesn’t make copies of the data it’s slicing out. The usage and outcome are the same as in [Listing 12-45](#listing12-45).    ## Reading and Writing Binary Files    Just as you can write strings out to a file using a stream, you can use a stream to write binary data to a file. Binary file formats, as you’ll see later, have a few advantages over text-based file formats, especially in terms of compact file sizes and faster processing. The techniques are almost identical to those in Chapter 11, with one critical difference: the stream must be opened in *binary mode*, instead of the default text mode. This returns a `BufferedReader`, `BufferedWriter`, or `BufferedRandom` object, depending on the mode you open with (see Table 11-1 from Chapter 11).    There are a number of existing file formats for storing data in binary, which I’ll discuss later, but for this example, I’ll create my own format using `struct`. This may be called for sometimes in your own projects, when you need to store very specific data in a particular manner. Designing your own binary file format can require considerable thought and planning, but when done right, a custom file format can be made to fit your data like a glove. As you’ll see, `struct` is particularly suitable for this, because of its format strings.    ### Organizing the Data    In this section, I’ll create a basic class structure for keeping track of a personal bookshelf. Ultimately, I’ll be able to write this bookshelf data to a binary stream (including a binary file) and create a bookshelf from a binary stream.    I’ll break my code down into three files: *book.py*, *bookshelf.py*, and *__main__.py*, all in the same package. That package will also need to contain an *__init__.py* file, which will be empty in this case. All of these files will go into a directory, *rw_binary_example/*, which will become the package. Here’s my file structure for the example:    ``` rw_binary_example/ ├── book.py ├── bookshelf.py ├── __init__.py ├── __main__.py ```py    Listing 12-48: File structure of rw_binary_example/ package    #### The Book class    The basic unit of data in my code is a `Book`, which I’ll write as its own class:    ``` import struct   class Book:      packer = ❶ struct.Struct(\">64sx64sx2h\")      def __init__(self, title=\"\", author=\"\", pages=0, pages_read=0):         self.title = title         self.author = author         self.pages = pages         self.pages_read = pages_read              def update_progress(self, pages_read):         self.pages_read = min(pages_read, self.pages) ```py    Listing 12-49: book.py:1    Most of this will look familiar by now. A book has a `title`, an `author`, a page count (`pages`), and an instance attribute for tracking how many pages have been read (`pages_read`). I also provide an `update_progress()` method to update the number of pages the user has read so far.    The line of particular interest here is the one where I define the class attribute `packer`. I bind this name to a `Struct` object, wherein I define the binary format for my object in a format string ❶. Here, I use the `Struct` object instead of the `pack()` function directly from the `struct` module. I do this for two reasons: (1) so there’s a single canonical source for the binary format I’m using and (2) because it means the format string is *precompiled* into a Python bytecode object, making for more efficient reuse.    I’m using big-endian byte order, not only because it’s familiar, but also because it’s what I’d use if I wanted to send this data over the internet (although I’m not doing so here). If I have to make a somewhat arbitrary decision, like choosing a byte order, I might as well maximize the possibilities of what I can do with the data!    I’ll also set a limit on the size of my string. I need a predictable format so I can read from the binary data later, and working with data that varies in size can be forbiddingly difficult. For my program, I set a size limit of 64 bytes, which should be sufficient for encoding most book titles and authors. I use `64s` in my format string to denote the `struct` fields for title and author. I also follow each of these fields with a padding byte (`x`), which will guarantee that these fields can always be interpreted as C-style null-terminated strings, even if all 64 characters are used. That makes for one less potential bug if my data needs to be interpreted by code in another programming language.    I also specify two 2-byte (short) integers (`2h`) for storing the page count and pages read. This should be sufficient space for both, since a book with more than 32,767 pages is rather an absurd idea. (I could also make this number unsigned, but I don’t really need the slightly higher maximum value. Perhaps I’ll find a clever use for negative values in a later version of my code.) If I try to pack too large a value into a struct field, a `struct.error` exception will be raised.    Now that I have my class and its format string, I can write an instance method for converting to binary the book data from the `Book` class I started in [Listing 12-49](#listing12-49):    ```  def serialize(self):         return self.packer.pack(             self.title.encode(),             self.author.encode(),             self.pages,             self.pages_read         ) ```py    Listing 12-50: book.py:2    To use the precompiled format string from earlier, I call the `pack()` method on the `self.packer` instance attribute, instead of using `struct.pack()`. I only need to pass the data I’m packing into binary.    I must call the `encode()` method on each of my strings to convert them from UTF-8 to bytes literal strings. I could also have used `self.title.encode(encoding='utf-8')` to explicitly specify the encoding. I might specify the encoding if I were using some string encoding other than the default UTF-8.    The integer values, `self.pages` and `self.pages_read`, can be passed as is.    The `self.packer.pack()` method returns a bytes object, which I then return from the `serialize` method.    #### The Bookshelf class    My program will store a collection of `Book` objects in a `Bookshelf`, which will be little more than a thin wrapper around a list:    ``` import struct from .book import Book  class Bookshelf:     fileinfo = ❶ struct.Struct('>h')     version = 1      def __init__(self, *books):         self.shelf = [*books]              def __iter__(self):         return iter(self.shelf)              def add_books(self, *books):         self.shelf.extend(books) ```py    Listing 12-51: bookshelf.py:1    I’m importing the `Book` class from the `book` module that lives in the same package as this module, so I use a relative import, as seen on the first line.    The `Bookshelf` class initializes the list, `self.shelf`, which will store any book objects passed as arguments to the initializer. Users can also add more books to the shelf with the `add_books()` method.    I allow iterating over the books directly by returning the iterator for the list from `__iter__()`, as there’s no need to reinvent the wheel here.    I could add some other features, such as removing or looking up specific books, but I want to keep this simple, to focus on converting this data to binary.    Most important to this example is the additional `Struct` that I’ve created and bound to `fileinfo`. I’ll use it to store the file format ❶. Along with that, I have a `version` class attribute for tracking the file format version number. This way, if I later change my *.shlf* file format, I can tell my future code how to read both the old and the new files.    I define a method for writing this data to a binary stream. You’ll recall from Chapter 11 that files are opened as streams. I can also apply these same techniques to send the data to another process or over a network to another machine.    ```  def write_to_stream(self, stream):         stream.write(self.fileinfo.pack(self.version))         for book in self.shelf:             stream.write(book.serialize()) ```py    Listing 12-52: bookshelf.py:2    The `write_to_stream()` method accepts a stream object as an argument. I write the *.shlf* file format version, `version`, to the binary stream first. My code can later check this first value and ensure the *.shlf* file being read follows the expected format.    Next, I iterate over the `Book` objects in the `self.shelf` list, call the `serialize()` method on each book, and write the returned bytes object to the stream using `stream.write()`. Since the stream automatically moves its position to the end of the last data I wrote to the binary file, I don’t need to call `stream.seek()` at any point.    ### Writing to a File    Now, I can put my `Book` and `Bookshelf` classes to work to store some data:    ``` from .bookshelf import Bookshelf from .book import Book   def write_demo_file():     # Write to file      cheuk_ting_bookshelf = Bookshelf(         Book(\"Automate the Boring Stuff with Python\", \"Al Sweigart\", 592, 592),         Book(\"Doing Math with Python\", \"Amit Saha\", 264, 100),         Book(\"Black Hat Python\", \"Justin Seitz\", 192, 0),         Book(\"Serious Python\", \"Julien Danjou\", 240, 200),         Book(\"Real-World Python\", \"Lee Vaughan\", 370, 370),     ) ```py    Listing 12-53: __main__.py:1    I import my `Book` and `Bookshelf` classes at the top of the module. In my `write_demo_file()` function, I create the new `Bookshelf` object `cheuk_ting_bookshelf` and fill it with some data. Cheuk Ting sure has good taste in books!    Next, within that same `write_file()` method, I add the following to open a file in binary write mode:    ```  with open('mybookshelf.shlf', 'bw') as file:         cheuk_ting_bookshelf.write_to_stream(file) ```py    Listing 12-54: __main__.py:2    You’ll recall from Chapter 11 that including `b` in the mode string on `open()` will open the stream in *binary mode*, instead of the default text mode. I want to write out the file, overwriting its contents if the file already exists, so I use `w` mode.    To aid you in following this example, I’ll create a stub function for my `read_demo_file()` function now and fill it in later:    ``` def read_demo_file():     \"\"\"TODO: Write me.\"\"\" ```py    Listing 12-55: __main__.py:3a    After opening my file, I pass it to the `write_to_stream()` method of my `cheuk_ting_bookshelf` object.    At the bottom of *__main__.py*, I must include the usual boilerplate for executing my `main()` function:    ``` if __name__ == \"__main__\":     write_demo_file() ```py    Listing 12-56: *__main__.py:4a*    That’s it! Running the package (via `python3 -m rw_binary_example`) creates a new file in my current working directory entitled *mybookshelf.shlf*. If you open that file in a text editor capable of displaying binary files, such as Visual Studio Code, you’ll likely see the titles and authors of the books displayed amidst a bunch of strange symbols.    I’ve created a binary file containing my data! (I’ll admit, I did some serious chuckling to myself after I got this example working.)    ### Reading from a Binary File    The *.shlf* file I created is merely a blob of binary data, with no information on how to read it. For my *.shlf* format to be of any use, I need to expand my program to be able to read in the data from *.shlf* files, converting that binary data back into strings and integers.    In the `Book` class again, I add a method for creating a new object from the binary data I would read from a *.shlf* file:    ```  @classmethod     def deserialize(cls, bits):         title, author, pages, pages_read = cls.packer.unpack(bits)         title = title.decode()         author = author.decode() ```py    Listing 12-57: *book.py:3*    I’ve chosen to make this a class method, rather than an instance method, to prevent the undesired side effect of overwriting another book. The method accepts a bytes object, and I use the `Book.packer` class attribute (see [Listing 12-49](#listing12-49)) to unpack the binary data into four names.    I use `decode()` to convert the strings from bytes to UTF-8\\. As before, if I were decoding into anything other than UTF-8, I’d need to specify the encoding via the `encoding=` parameter of `decode()`.    The `unpack()` method automatically converts the integer values to `int`.    Finally, within this same `deserialize()` class method, I create and return a new `Book` object from the values I unpacked:    ```  return cls(title, author, pages, pages_read) ```py    Listing 12-58: *book.py:4*    I’ll put this new class method to work in my `Bookshelf` class.    Next, I’ll add a `from_stream()` class method for creating a new Bookshelf from a binary stream:    ```  @classmethod     def from_stream(cls, stream):         size = cls.fileinfo.size         version, = cls.fileinfo.unpack(stream.read(size))         if version != 1:             raise ValueError(f\"Cannot open .shlf v{version}; expect v1.\") ```py    Listing 12-59: *bookshelf.py:3*    My `from_stream()` class method receives a stream object as an argument, `stream`.    Before I do any processing, I need to check the format version of a *.shlf* file, in case some user in the future tries to open a (theoretical, for now) version-2 file with this package. To do that, I first determine how many bytes to read off the beginning of my file, where I stored the version data. `Struct` objects like `cls.fileinfo` (see [Listing 12-51](#listing12-51)) have a `size` attribute, which returns an integer representing the exact number of bytes needed to represent data packed into that `Struct`.    I read the number of bytes indicated by `size` from the binary stream using `stream.read(size)`, and I pass the returned bytes literal to `cls.fileinfo.unpack()`. That returns a tuple of values, but as the tuple has only one value in this case, I must be careful to unpack that value into `version`, rather than binding the tuple itself to that name.    I check the returned file format version before proceeding, raising a `ValueError` if the format version is wrong for this code. A future expanded version of this code might allow me to switch which `Struct` object I use in the `Book` module, based on the format version of the file being read.    Now, I prepare to read the data for the individual books:    ```  size = Book.packer.size         shelf = Bookshelf() ```py    Listing 12-60: *bookshelf.py:4*    I get the size in bytes of the `Struct` object the `Book` class uses, and I store that in `size`. I instantiate a new `Bookshelf` object, which I bind to `shelf`. I’m now ready to read the rest of the data in the binary stream:    ```  while bits := stream.read(size):             shelf.add_books(Book.deserialize(bits))                      return shelf ```py    Listing 12-61: *bookshelf.py:5*    Within the header of a loop, I use `stream.read(size)` to read the next segment of data from the binary stream, which I bind to `bits`. I’m using an *assignment expression*, via the *walrus operator*, in this context, so I can also check the value of `bits` right here in the loop header. Then, I implicitly check that *bits* is not an empty bytes literal (`bytes()`)—the value of `bits` will be “falsey,” or implicitly evaluate to `False` in the conditional, only if it is actually empty—which would indicate that I’ve reached the end of the stream. Any other value of `bits`, even `b'\\x00'`, would cause this expression to evaluate to `True`.    Within the suite of this loop, I create a new `Book` from the binary data in `bits`, using the `Book.deserialize()` class method. Then, I add that `Book` object to the `Bookshelf` object bound to `shelf`, which I build here.    Finally, after the loop completes, I return `shelf`.    Because of how I’ve structured the `Bookshelf` and `Book` classes, the code for reading a *.shlf* file is quite elegant. I’ll fill in my `read_demo_file()` function in the *__main__.py* module now.    Laís received some book recommendations from her friend Cheuk Ting in a *.shlf* file, so she needs to open that file. Here is the code that allows her to do so with the `Bookshelf` class:    ``` def read_demo_file():     with open('mybookshelf.shlf', 'br') as file:         lais_bookshelf = Bookshelf.from_stream(file)              for book in lais_bookshelf:         print(book.title) ```py    Listing 12-62: *__main__.py:3b*    I open the *mybookshelf.shlf* file in *binary read* mode (`br`). I pass the `file` stream object to `Bookshelf.from_stream()`, and then I bind the resulting `Bookshelf` object to `lais_bookshelf`.    Finally, to verify everything has worked, I iterate over each book in `lais_bookshelf` and print the titles.    I must be certain to call `read_demo_file()`:    ``` if __name__ == \"__main__\":     write_demo_file()     read_demo_file() ```py    Listing 12-63: *__main__.py:4b*    Running that code outputs the following:    ``` Automate the Boring Stuff with Python Doing Math with Python Black Hat Python Serious Python Real-World Python ```py    Laís’s bookshelf is now identical to Cheuk Ting’s!    I hope Cheuk Ting remembers to recommend *Dead Simple Python* to Laís, too, after she gets done with it.    ### Seek with Binary Stream    When working with streams, you can change stream position if you only want to read or modify part of a stream, rather than traversing or processing the whole thing. Recall from Chapter 11 that you can work with the stream position on a text stream using the `tell()` and `seek()` methods. You can use these same methods with binary stream objects, namely `BufferedReader`, `BufferedWriter`, and `BufferedRandom`, but with some additional functionality on `seek()`.    The `seek()` method accepts two arguments. The first is `offset`, which is the number of bytes to move in the stream. Positive offset values move forward, and negative offset values move backward.    The second argument is `whence`, which provides the starting position that `offset` moves from. With text streams, the offset must be zero. That limitation doesn’t exist on binary streams!    With binary streams, there are three possible values for whence: `0` for start, `1` for current position, and `2` for end. If I wanted to seek to six bytes from the end of a stream, I’d do something like this:    ``` from pathlib import Path Path('binarybits.dat').write_bytes(b'ABCDEFGHIJKLMNOPQRSTUVWXYZ')   with open('binarybits.dat', 'br') as file:     file.seek(-6, 2) ```py    Listing 12-64: *seek_binary_stream.py:1*    Providing a whence of `2` means I start seeking from the end of the stream, and the offset argument of `-6` moves back six bytes from there.    Similarly, if I then wanted to move forward two bytes from the current stream position, I’d use the following:    ```  file.seek(2, 1) ```py    Listing 12-65: *seek_binary_stream.py:2*    The whence argument of `1` starts the seek from the current position, and the offset argument of `2` moves forward two bytes from there.    One word of caution when using `seek()`: only use positive offsets when starting at the beginning of your file (a whence of `0`, the default), or the statement will raise an `OSError`. Similarly, be careful not to rewind past the start of the stream when using a negative offset and a whence of `1`.    Always use negative offsets when starting at the end of your file (a whence of `2`). Positive offsets won’t raise an error, but seeking past the end of the buffer is rather pointless, if benign. Seeking past the end and then writing data to the buffer from that position will actually drop said data into a black hole; it won’t be written to the stream. If you want to append to a stream, position yourself at the end with `file.seek(0, 2)`.    ### BufferedRWPair    One of the fun things about writing a book like *Dead Simple Python* is discovering unfamiliar techniques. While perusing the Python documentation for this section, I learned about another type of binary stream called a `BufferedRWPair`, which accepts two stream objects: one to read from and another to write from. (These *must* be different stream objects!)    The primary use of `BufferedRWPair` is in working with a socket or a two-way pipe, wherein your code communicates with another process on the system through two separate buffers: one for receiving data from the other process and another for sending data.    Another use would be to simplify the process of reading data from one source, possibly process it, and then send it somewhere else. For example, I could use this to read data from a device’s serial port and write it directly out to a file.    I won’t write a full example for this here, as it would be fairly involved and likely use topics I haven’t covered. (I prefer to stay reasonably relevant.) The usage of `BufferedRWPair` is about the same as any other byte stream, except that you’d explicitly initialize it by passing two streams: one to read and one to write.    For a simple example, I’ll first create a binary file containing some data using the normal means:    ``` from pathlib import Path Path('readfrom.dat').write_bytes(b'\\xaa\\xbb\\xcc') ```py    Listing 12-66: *creating_bufferedrwpair.py:1*    This code only creates the file *readfrom.dat*, so I have something to read from in the important part of the example.    I create a `BufferedRWPair` by passing it a stream to read and a stream to write. I’ll use the `open()` method on `Path` to create the streams:    ``` from io import BufferedRWPair with BufferedRWPair(Path('readfrom.dat').open('rb'), Path('writeto.dat').open('wb')) as buffer:     data = buffer.read()     print(data)  # prints \"b'\\xaa\\xbb\\xcc'\"     buffer.write(data) ```py    Listing 12-67: *creating_bufferedrwpair.py:2*    To verify this works, I’ll open *writeto.dat* directly in read mode to see its contents:    ``` Path('writeto.dat').read_bytes()  # prints \"b'\\xaa\\xbb\\xcc'\" ```py    Listing 12-68: *creating_bufferedrwpair.py:3*    That’s clearly an oversimplified example, but you get the essential idea. There are many uses for `BufferedRWPair` in advanced situations. Chances are, you’ll know when you need it.    ## Serialization Techniques    As mentioned in Chapter 11, *serialization* is the process of converting data to a format that can be stored. This data can be written to a file, transmitted over a network, or even shared between processes. The inverse operation is *deserialization*, which converts the serialized data back into its original form, or at least a close equivalent.    I also touched on a number of formats used for serialization, especially JSON and CSV. All of these formats were text based and intended to be human readable, which makes them excellent candidates for files that the user should be able to modify by hand. Human-readable formats are also *futureproof*, meaning in this case that the deserialization process can be reverse engineered if the presently used technology or format specification ever ceases to exist. (And that happens more often than you might think!)    There are a few disadvantages of using human-readable, text-based serialization formats, rather than *binary* serialization formats. The first is size: it will virtually always take more memory to represent non-string data as a string than to use its original, binary form. Text-based formats are also often slower to deserialize, in contrast to binary formats. This is one reason why binary formats are better suited to the *virtual machine* design pattern, wherein different bytes correspond to different behaviors. Most interpreted languages, including Python itself, use some form of this design pattern internally.    The third disadvantage of text-based serialization formats is the same as one of its advantages: the file can be easily modified. You may want to discourage users from directly editing particularly complex or fragile data, as minor errors can corrupt the file. Using binary serialization formats is an effective way of discouraging file tampering.    A good example of this is *Minecraft’s .dat* file format, which contains serialized game world data in a binary format. (The fact that *Minecraft* is written in Java is beside the point; principles of serialization are language agnostic.) It’s important to note that obfuscation is not an effective security technique. *Minecraft* *.dat* files are still editable by the end user, as evidenced by third-party programs like MCEdit.    If you want to protect your serialized data, *encryption* is your only answer. How you apply encryption depends on your situation.    For example, the space simulator game *Oolite* uses XML to serialize player data so the file can still be read and edited by the user, but it includes a hash string of the data in the file so the game can detect cheating and make minor adjustments to gameplay.    In an application where security really matters, the serialized data will often be fully encrypted. Many applications will store saved passwords in this manner, encrypted behind a master password or key, to prevent the data from being intercepted. The passwords must be serialized and stored to disk for the program to retain them, but the encryption ensures that no one else can deserialize the data.    In short, your decision on whether to use text-based or binary serialization depends entirely on your situation. Binary serialization can offer smaller file sizes, faster deserialization, and the added benefit of discouraging tampering by end users. However, binary-based formats are not as futureproof as text-based formats, and they can also give users an uneasy feeling of opacity about the data. These are the reasons why they’re seldom used for serializing settings.    ### Forbidden Tools: pickle, marshal, and shelve    *Pickle* is a common built-in serialization tool. It stores Python objects in a binary format that can be saved to a file and then later deserialized, or *unpickled*, into a Python object again. Sounds perfect, right?    There’s a big red box at the top of the documentation that screams about security concerns with `pickle`, and it may be tempting to overlook that. “This is merely a calculator app,” a developer might say. “Security doesn’t matter here.”    Except the security here has nothing to do with the data itself. Pickled data can be tampered with to execute arbitrary code, meaning if you use `pickle` for serialization, your Python program can be made to do *literally anything*. If someone modifies pickled data on a user’s machine, which isn’t difficult to do, your harmless Python program will become malware as soon as it unpickles that file.    It’s possible to guard against file tampering by signing data with a message authentication module called `hmac`, but at that point, it would be more straightforward to use the other techniques from this chapter to serialize data in a secure fashion. Pickled data isn’t intended to make sense outside of Python anyway, whereas a custom serialization approach *could* be made portable.    What’s more, `pickle` is painfully slow and produces some pretty bloated files. It’s practically the most inefficient way to serialize anything to a file, even before I consider security.    There are two related built-in tools in Python: `marshal` and `shelve`. The former, `marshal`, is really only intended to be used internally by Python, as its deliberately undocumented specification can change between Python versions. It also has the same issues related to security and performance as does `pickle`, so it shouldn’t be considered an alternative. Even if it were perfect, it would still not be intended for your use.    The `shelve` module is built on `pickle`, and it should be dismissed for the same reasons as `pickle`.    Frankly, `pickle`, `marshal`, and `shelve` offer no advantages over other serialization-to-file techniques. They’re like `sudo pip`: they *appear* to work until they completely kick the pooch, at which point, you discover in the most painful way possible how much evil they conceal.    Ignore the myriad tutorials and misguided Stack Overflow answers on this one. Unless you’re transferring data directly between processes, please forget that these modules exist at all, except to warn other Python developers away from them. Leave the `pickle` in the fridge.    You may wonder why these modules are even included in the standard library in the first place. There are a few factors.    First, `pickle` does have one valid use: transferring data between running processes. This is safe because the data is never written to a file. Speed and size are still problems here, but there are efforts to mitigate these issues, as it’s believed to be easier to redeem `pickle` than to invent a whole new protocol. Python 3.8 saw a new version of the `pickle` protocol, which is meant to improve handling of large data (see PEP 574). I’ll revisit `pickle` in Chapter 17, when I cover multiprocessing.    Second, plenty of Python code exists that relies on these modules. At one time, `pickle` was considered the “one obvious way” of serializing data, although it has long since fallen out of favor as its flaws have become apparent. There’s already a move to deprecate and remove many so-called “dead batteries” (a reference to Python’s “batteries included” nature) from the standard library, but `pickle` isn’t on that list because of its use in multiprocessing.    That leaves only one solution: accept that `pickle`, `marshal`, and `shelve` have their uses, but that serialization-to-file is not among them.    ### Serialization Formats    So if `pickle` and friends are out, what options remain? Thankfully, quite a few! I’ve compiled a short list of some of the most common and popular binary serialization formats, but it is far from exhaustive. If you are interested in any of these file formats, peruse the official documentation for the associated module or library.    #### Property List    The *property list*, or *.plist* file, is a serialization format that was created for the NeXTSTEP operating system in the 1980s and was further developed for its descendants: macOS and GNUstep. Although it is primarily used with these platforms, you can certainly employ property lists in your own project. This is one of the best ways to perform binary serialization without `pickle`.    There are two major flavors of property list: binary and the human-readable, XML-based form. Both can be serialized and deserialized with the built-in `plistlib` module.    One of the advantages of property lists in Python is that they can directly serialize most basic types, including dictionaries, which are frequently used as the top-level objects (like with JSON).    To learn more, read the official documentation at [https://docs.python.org/3/library/plistlib.html](https://docs.python.org/3/library/plistlib.html).    #### MessagePack    One of the leading formats for binary serialization is *MessagePack*, which is designed to produce simple, compact serialized output. It is based on JSON, and for the most part, it can represent the same sort of data.    The official third-party package, *msgpack*, can be installed via pip. More information and official documentation can be found on the MessagePack website: [https://msgpack.org/](https://msgpack.org/).    #### BSON    Another binary serialization format based on JSON is called *BSON* (for “binary JSON”). Being a binary format, BSON is much faster to deserialize than JSON. It also usually produces files that are smaller, though still larger than those produced by MessagePack. In certain situations, BSON files can even be larger than the equivalent JSON file. BSON also provides some additional types over MessagePack.    As MongoDB makes significant use of the BSON format, the MongoDB package for Python, *pymongo*, provides a *bson* package. A fork of this package is also available simply as *bson*, if you don’t want the whole *pymongo* package. You can also learn more about BSON from the specification’s official website: [http://bsonspec.org/](http://bsonspec.org/).    #### CBOR    The *Concise Binary Object Representation*, or *CBOR*, is a binary serialization format that focuses on concise encoding. Like BSON and MessagePack, it is also based on the JSON data model. Unlike its cousins, CBOR is officially defined as an internet standard by the Internet Engineering Task Force in RFC 8949, and it is employed in the Internet of Things.    There are a few packages available through pip for working with CBOR, the most up-to-date of which is *cbor2*. More information about the format is available from the official website: [https://cbor.io/](https://cbor.io/).    #### NetCDF    The *Network Common Data Form*, or *NetCDF*, is a binary serialization format designed primarily for working with array-oriented scientific data. It was created in 1989, based on NASA’s Common Data Format, although the two formats are no longer compatible. NetCDF is still maintained by the *University Corporation for Atmospheric Research* (*UCAR*).    The *netCDF4* package from pip provides modules for working with the NetCDF format. You can also learn more about the format at [https://www.unidata.ucar.edu/software/netcdf/](https://www.unidata.ucar.edu/software/netcdf/).    #### Hierarchial Data Format    The *Hierarchial Data Format*, or *HDF*, is a binary serialization format designed for storing large amounts of data. It is developed and maintained by the not-for-profit HDF Group, and it is used heavily in science, engineering, finance, data analysis, and even creative projects. It has had a central role in some major NASA projects, and it was employed in producing movies such as *The Lord of the Rings* and *Spider-Man 3*.    HDF5 is the latest version of the format and is the current recommended standard. The HDF Group still supports and maintains HDF4.    A number of third-party modules exist for working with HDF. Two of the leading options are *h5py* and *tables*. More information about the format is available from The HDF Group’s website: [https://www.hdfgroup.org/](https://www.hdfgroup.org/).    #### Protocol Buffers    Google’s *Protocol Buffers* is an increasingly popular binary serialization format, but I’m addressing it last because it operates in a very different manner from the others.    Unlike in most formats, which have existing standard specifications, you define a tailor-made specification for your file in a special *.proto* schema file. This schema is then compiled into your favorite language, using Google’s proto compiler; in the case of Python, it produces a Python module. You would then use this generated module for serialization and deserialization, according to the specification you created.    If you’re interested in this, refer to Google’s official documentation: [https://developers.google.com/protocol-buffers/docs/pythontutorial](https://developers.google.com/protocol-buffers/docs/pythontutorial).    #### A Few More    There are also a number of binary serialization formats designed for specific purposes, such as *GRIB* in meteorology and *FITS* in astronomy. Often, the best way to find a serialization format that fits your purpose is to think about your data first, how it should be stored, and in what situations it needs to be deserialized. Once you find a format that fits your particular need, find (or write) a module to work with it in Python.    ## Wrapping Up    Binary is the language of computers. It is one of the most reliable ways for your program to share data outside of itself, whether through files (as you’ve seen here) or across processes or networks. Binary serialization formats generally offer smaller file sizes and faster deserialization than text-based formats, at the cost of less human readability. Whether you should use text or binary for any particular task partly depends on your audience: *text is for humans, binary is for computers*. Besides this, consider the available tooling for any given format and its suitability for the data you want to encode. For example, even if a user will never need to interact with a settings file, *.json* remains a popular format, if for no other reason than the ease of debugging it!    The goal of a programmer is ultimately to serve as the translator between humans and computers. It takes time to master thinking in bits and bytes, binary and hexadecimal, but it’s a skill well worth cultivating. No matter how high up the tower of abstractions a programmer climbs, they can never really escape the fundamental computer language upon which everything is built. An expert programmer is one who is fluent in both human language and computer logic; the more you know of both, the better you can utilize the tools Python or any other language offers you.**```` ```py``*`````", "```````"]
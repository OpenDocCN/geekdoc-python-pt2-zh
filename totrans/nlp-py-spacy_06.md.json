["```py\n   import spacy\n\n   nlp = spacy.load('en')\n\n   doc1 = nlp(u'We can overtake them.')\n\n   doc2 = nlp(u'You must specify it.')\n\n➊ for i in range(len(doc1)-1): \n\n   ➋ if doc1[i].dep_ == doc2[i].dep_:\n\n     ➌ print(doc1[i].text, doc2[i].text, doc1[i].dep_, spacy.explain(doc1[i].dep_))\n```", "```py\nWe       You     nsubj  nominal subject\n\ncan      must    aux    auxiliary\n\novertake specify ROOT   None\n\nthem     it      dobj   direct object\n```", "```py\nWe       You     PRON  pronoun\n\ncan      must    VERB  verb\n\novertake specify VERB  verb\n\nthem     it      PRON  pronoun\n```", "```py\nsents = list(doc.sents)\n```", "```py\n   import spacy\n\n   nlp = spacy.load('en')\n\n➊ def dep_pattern(doc):\n\n  ➋ for i in range(len(doc)-1):\n\n    ➌ if doc[i].dep_ == 'nsubj' and doc[i+1].dep_ == 'aux' and\n\n       doc[i+2].dep_ == 'ROOT':\n\n      ➍ for tok in doc[i+2].children:\n\n             if tok.dep_ == 'dobj':\n\n          ➎ return True\n\n  ➏ return False\n\n➐ doc = nlp(u'We can overtake them.')\n\n   if ➑dep_pattern(doc):\n\n     print('Found')\n\n   else:\n\n     print('Not found')\n```", "```py\nFound\n```", "```py\n   import spacy\n\n   from spacy.matcher import Matcher\n\n   nlp = spacy.load(\"en\")\n\n➊ matcher = Matcher(nlp.vocab)\n\n➋ pattern = [{\"DEP\": \"nsubj\"}, {\"DEP\": \"aux\"}, {\"DEP\": \"ROOT\"}]\n\n➌ matcher.add(\"NsubjAuxRoot\", None, pattern)\n\n   doc = nlp(u\"We can overtake them.\")\n\n➍ matches = matcher(doc)\n\n➎ for match_id, start, end in matches:\n\n       span = doc[start:end]\n\n    ➏ print(\"Span: \", span.text)\n\n       print(\"The positions in the doc are: \", start, \"-\", end)\n```", "```py\nSpan: We can overtake\n\nThe positions in the doc are: 0 - 3\n```", "```py\nimport spacy\n\nnlp = spacy.load('en')\n\n#Insert the dep_pattern function from a previous listing here\n\n#...\n\n➊ def pos_pattern(doc):\n\n  ➋ for token in doc:\n\n       if token.dep_ == 'nsubj' and token.tag_ != 'PRP':\n\n         return False\n\n       if token.dep_ == 'aux' and token.tag_ != 'MD':\n\n         return False\n\n       if token.dep_ == 'ROOT' and token.tag_ != 'VB':\n\n         return False\n\n       if token.dep_ == 'dobj' and token.tag_ != 'PRP':\n\n         return False\n\n  ➌ return True\n\n   #Testing code\n\n   doc = nlp(u'We can overtake them.')\n\n➍ if dep_pattern(doc) and pos_pattern(doc):\n\n       print('Found')\n\n   else:\n\n       print('Not found')\n```", "```py\nFound\n```", "```py\nNot found\n```", "```py\nThe trucks are traveling slowly. We can overtake them.\n```", "```py\n   import spacy\n\n   nlp = spacy.load('en')\n\n   #Insert the dep_pattern and pos_pattern functions from the previous\n\n   listings here\n\n   #...\n\n➊ def pron_pattern(doc):\n\n  ➋ plural = ['we','us','they','them']\n\n     for token in doc:\n\n    ➌ if token.dep_ == 'dobj' and token.tag_ == 'PRP':\n\n      ➍ if token.text in plural:\n\n        ➎ return 'plural'\n\n         else:\n\n        ➏ return 'singular'\n\n  ➐ return 'not found'\n\n   doc = nlp(u'We can overtake them.')\n\n   if dep_pattern(doc) and pos_pattern(doc):\n\n       print('Found:', 'the pronoun in position of direct object is',\n\n       pron_pattern(doc))\n\n   else:\n\n       print('Not found')\n```", "```py\nFound: the pronoun in position of direct object is plural\n```", "```py\nDevelopers might follow this rule.\n```", "```py\nThe symbols are clearly distinguishable. I can recognize them promptly.\n```", "```py\nI can recognize symbols promptly too.\n```", "```py\n   import spacy\n\n   nlp = spacy.load('en')\n\n   #Insert the dep_pattern, pos_pattern and pron_pattern functions from the \n\n   previous listings here\n\n   #...\n\n➊ def find_noun(➋sents, ➌num):\n\n     if num == 'plural':\n\n    ➍ taglist = ['NNS','NNPS']\n\n     if num == 'singular':\n\n    ➎ taglist = ['NN','NNP']\n\n  ➏ for sent in reversed(sents):\n\n    ➐ for token in sent:\n\n      ➑ if token.tag_ in taglist:\n\n           return token.text\n\n     return 'Noun not found'\n```", "```py\n   def gen_utterance(doc, noun):\n\n     sent = ''\n\n  ➊ for i,token in enumerate(doc):\n\n    ➋ if token.dep_ == 'dobj' and token.tag_ == 'PRP':\n\n      ➌ sent = doc[:i].text + ' ' + noun + ' ' + doc[i+1:len(doc)-2].text + 'too.'\n\n      ➍ return sent\n\n   ➎ return 'Failed to generate an utterance'\n```", "```py\n➊ doc = nlp(u'The symbols are clearly distinguishable. I can recognize them \n\n   promptly.')\n\n➋ sents = list(doc.sents)\n\n   response = ''\n\n   noun = ''\n\n➌ for i, sent in enumerate(sents): \n\n     if dep_pattern(sent) and pos_pattern(sent):\n\n  ➍ noun = find_noun(sents[:i], pron_pattern(sent))\n\n       if noun != 'Noun not found':\n\n    ➎ response = gen_utterance(sents[i],noun)\n\n       break\n\nprint(response)\n```", "```py\nI can recognize symbols too.\n```", "```py\nI need an air ticket to Berlin.\n```", "```py\nI am going to the conference in Berlin. I need an air ticket. \n\nI am going to the conference, which will be held in Berlin. I would like to\n\nbook an air ticket.\n```", "```py\nI want to book a ticket on a direct flight without landing in Berlin.\n```", "```py\n   import spacy\n\n   nlp = spacy.load('en')\n\n   #Here's the function that figures out the destination\n\n➊ def det_destination(doc):\n\n     for i, token in enumerate(doc):\n\n   ➋ if token.ent_type != 0 and token.ent_type_ == 'GPE':\n\n      ➌ while True:\n\n        ➍ token = token.head\n\n           if token.text == 'to':\n\n          ➎ return doc[i].text\n\n        ➏ if token.head == token:\n\n             return 'Failed to determine'\n\n     return 'Failed to determine'\n\n   #Testing the det_destination function\n\n   doc = nlp(u'I am going to the conference in Berlin.')\n\n➐ dest = det_destination(doc)\n\n   print('It seems the user wants a ticket to ' + dest)\n```", "```py\nIt seems the user wants a ticket to Berlin\n```", "```py\nIt seems the user wants a ticket to Failed to determine\n```", "```py\nThe product sales hit a new record in the first quarter, with 18.6 million units sold.\n```", "```py\nThe product sales hit 18.6 million units sold.\n```", "```py\n doc = nlp(u\"The product sales hit a new record in the first quarter, with 18.6 million units sold.\")\n\n phrase = ''\n\n for token in doc:\n\n➊ if token.pos_ == 'NUM':\n\n       while True:\n\n         phrase = phrase + ' ' + token.text\n\n      ➋ token = token.head\n\n      ➌ if token not in list(token.head.lefts):\n\n           phrase = phrase + ' ' + token.text\n\n        ➍ break\n\n    ➎ break\n\n print(phrase.strip())\n```", "```py\n while True:\n\n➊ token = doc[token.i].head\n\n   if token.pos_ != 'ADP':\n\n  ➋ phrase = token.text + phrase\n\n➌ if token.dep_ == 'ROOT':\n\n➍ break\n```", "```py\n➊ for tok in token.lefts:\n\n  ➋ if tok.dep_ == 'nsubj':\n\n   ➌ phrase = ' '.join([tok.text for tok in tok.lefts]) + ' ' + tok.text + ' '\n\n      + phrase\n\n      break\n\n➍ print(phrase)\n```", "```py\nThe product sales hit 18.6 million units sold.\n```", "```py\nThe company, whose profits reached a record high this year, largely attributed\n\nto changes in management, earned a total revenue of $4.26 million.\n```", "```py\nThe company earned revenue of $4.26 million.\n```", "```py\nI am attending the conference in Berlin.\n```", "```py\nYou want a ticket to Berlin, right?\n```", "```py\nimport spacy\n\nnlp = spacy.load('en')\n\n#Insert the dep_destination function from a previous listing here\n\n#...\n\ndef guess_destination(doc):\n\n  for token in doc:\n\n ➊ if token.ent_type != 0 and token.ent_type_ == 'GPE': \n\n    ➋ return token.text\n\n➌ return 'Failed to determine'\n```", "```py\n def gen_response(doc):\n\n➊ dest = det_destination(doc)\n\n   if dest != 'Failed to determine':\n\n  ➋ return 'When do you need to be in ' + dest + '?'\n\n➌ dest = guess_destination(doc)\n\n   if dest != 'Failed to determine':\n\n   ➍ return 'You want a ticket to ' + dest +', right?'\n\n ➎ return 'Are you flying somewhere?'\n```", "```py\ndoc = nlp(u'I am going to the conference in Berlin.') \n\nprint(gen_response(doc))\n```", "```py\nWhen do you need to be in Berlin?\n```", "```py\nI want to read a book.\n\nI want to read a book on Python.\n```", "```py\nThat exotic fruit from Africa.\n```", "```py\n   import spacy\n\n   nlp = spacy.load('en')\n\n➊ doc = nlp(u\"Kiwano has jelly-like flesh with a refreshingly fruity taste. This \n\n   is a nice exotic fruit from Africa. It is definitely worth trying.\")\n\n➋ fruit_adjectives = []\n\n➌ fruit_origins = []\n\n   for token in doc:\n\n  ➍ if token.text == 'fruit': \n\n    ➎ fruit_adjectives = fruit_adjectives + [modifier.text for modifier in\n\n       token.lefts if modifier.pos_ == 'ADJ']\n\n    ➏ fruit_origins = fruit_origins + [doc[modifier.i + 1].text for modifier \n\n       in token.rights if modifier.text == 'from' and doc[modifier.i + 1].ent_\n\n       type != 0]\n\n   print('The list of adjectival modifiers for word fruit:', fruit_adjectives)\n\n   print('The list of GPE names applicable to word fruit as postmodifiers:', \n\n   fruit_origins)\n```", "```py\nThe list of adjectival modifiers for word fruit: ['nice', 'exotic']\n\nThe list of GPE names applicable to word fruit as postmodifiers: ['Africa']\n```"]
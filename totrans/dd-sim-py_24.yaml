- en: '19'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Debugging and Logging
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/book_art/chapterart.png)'
  prefs: []
  type: TYPE_IMG
- en: Mistakes in code are inevitable. The bugs you’ll encounter can range from simple
    typos to malformed logic, from misunderstood usage to those strange errors that
    originate from deeper in the tech stack. As Lubarsky’s Law of Cybernetic Entomology
    observes, “There is always one more bug.” When things go horribly wrong in your
    code, you’re going to need the tools to find and fix the problem. In this chapter,
    you’ll learn all about those tools.
  prefs: []
  type: TYPE_NORMAL
- en: 'I’ll begin by covering three features of the Python language that you can add
    to your code to help you debug it later: warnings, logging, and assertions. These
    are improvements over using print statements for debugging purposes, as you are
    likely to forget where your “debugging” print statements are or may be tempted
    to leave them in place in production.'
  prefs: []
  type: TYPE_NORMAL
- en: Then, I’ll guide you through the use of the Python debugger (`pdb`), which helps
    you step through the logic in your Python program, and `faulthandler`, which enables
    you to investigate undefined behavior in the C code behind Python. Finally, I’ll
    discuss using Bandit to check for security problems in your code.
  prefs: []
  type: TYPE_NORMAL
- en: Warnings
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can use a *warning* to notify the user of a problem that the program worked
    around or alert a developer to an upcoming breaking change in a later version
    of your library. Unlike an exception, which we discussed in Chapter 8, a warning
    won’t crash the program. This is preferable for problems that don’t interfere
    with the program’s normal function.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, warnings are more convenient than print statements because they’re
    output to the standard error stream by default. In a print statement like `print("My
    warning message", file=sys.stderr)`, I must explicitly output to the standard
    error stream.
  prefs: []
  type: TYPE_NORMAL
- en: 'Python offers a warning module with a bevy of additional features and behaviors.
    To issue warnings, use the `warnings.warn()` function. For example, this rather
    theatrical (if silly) program aims to write some text to a file. If the value
    of `thumbs` is `"pricking"`, I issue a warning that something evil is coming.
    After the warning, I open a file, *locks.txt*, and write some text to it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 19-1: *basic_warning.py:1a*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Running that module outputs the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The warning appears on the terminal via the standard error stream, but importantly,
    it does not crash the program. The file *locks.txt* is still created with the
    desired text:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 19-2: *locks.txt*'
  prefs: []
  type: TYPE_NORMAL
- en: Types of Warnings
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Warnings come in different types, each of which can be treated differently,
    as you see fit. For example, you should probably let your user know if the program
    had to work around a missing file on their system, but you may not want to bother
    them with warnings about weird syntax in the code; such warnings are things only
    a developer would need to know. Warning categories allow you to handle these different
    situations in a manner appropriate to your project.
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 19-1](#table19-1) lists the various types of warnings, all of which
    inherit from the `Warning` base class. Just as you can create a custom `Exception`,
    you can create your own types of warnings by inheriting from the `Warning` class
    of any of its subclasses in [Table 19-1](#table19-1).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 19-1: Warning Categories'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Class** | **Usage** | **Ignored by default** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `UserWarning` | The default if no category is specified in `warn()` |  |'
  prefs: []
  type: TYPE_TB
- en: '| `DeprecationWarning` | Warnings about deprecated features, intended for developers
    | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| `PendingDeprecationWarning` | Warnings about features that will be deprecated
    in the future | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| `FutureWarning` | Warnings about deprecated features, intended for users
    (Prior to 3.7, this instead referred to a feature’s behavior being changed.) |  |'
  prefs: []
  type: TYPE_TB
- en: '| `SyntaxWarning` | Warnings about potentially problematic syntax |  |'
  prefs: []
  type: TYPE_TB
- en: '| `RuntimeWarning` | Warnings about questionable runtime behavior |  |'
  prefs: []
  type: TYPE_TB
- en: '| `ImportWarning` | Warnings related to importing modules | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| `UnicodeWarning` | Warnings related to Unicode |  |'
  prefs: []
  type: TYPE_TB
- en: '| `BytesWarning` | Warnings related to bytes-like objects |  |'
  prefs: []
  type: TYPE_TB
- en: '| `ResourceWarning` | Warnings related to hardware resource usage | ✓ |'
  prefs: []
  type: TYPE_TB
- en: This table is up-to-date for Python 3.7 through at least Python 3.10\. Earlier
    versions of Python ignore different warnings by default, meaning you’ll have to
    explicitly enable those warnings to see them while running the program.
  prefs: []
  type: TYPE_NORMAL
- en: 'To issue a particular type of warning, pass the desired `Warning` class as
    the second argument of `warn()`. For irony’s sake, I’ll revise my earlier example
    to issue a `FutureWarning`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 19-3: *basic_warning.py:1b*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Running that code produces the following output on the terminal, in addition
    to creating the same *locks.txt* file as before:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Filtering Warnings
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The *warnings filter* controls how warnings are displayed, and it can be passed
    as an argument to the Python interpreter when you run a module or package. For
    example, you can display a warning once or multiple times, hide it altogether,
    or even cause it to crash a program. (I’ll explain why you’d want to in the Converting
    Warnings to Exceptions section below.)
  prefs: []
  type: TYPE_NORMAL
- en: 'Warning filters are composed of five optional fields, separated by colons:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[Table 19-2](#table19-2) explains what each of those fields does.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 19-2: Warning Filter Field'
  prefs: []
  type: TYPE_NORMAL
- en: '| `action` | How the warning should be displayed. There are six options for
    this field: `default`, `error`, `always`, `module`, `once`, and `ignore`. (See
    [Table 19-3](#table19-3).) |'
  prefs: []
  type: TYPE_TB
- en: '| `message` | A regular expression that the warning message must match to be
    filtered. |'
  prefs: []
  type: TYPE_TB
- en: '| `category` | The warning category to be filtered. |'
  prefs: []
  type: TYPE_TB
- en: '| `module` | The module the warning must occur in to be filtered. (Not to be
    confused with the `module` option for the `action` field.) |'
  prefs: []
  type: TYPE_TB
- en: '| `lineno` | The line number where the warning must occur to be filtered. |'
  prefs: []
  type: TYPE_TB
- en: You can omit any field, but you’d still need to include the appropriate number
    of delimiting colons between fields. If you were to specify ``action and `category`
    but omit `message`, you’d still need the separating colons between them:``
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice, however, that I did not need any trailing colons for the omitted `module`
    and `lineno` fields, as those came after the last field I specified: `category`.'
  prefs: []
  type: TYPE_NORMAL
- en: Using the `message` field, you can filter warnings that have a particular message.
    The `module` field can be used to filter warnings only in a particular module.
  prefs: []
  type: TYPE_NORMAL
- en: Hiding Duplicate Warnings
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: It isn’t uncommon for a warning to be raised multiple times, such as if it appears
    in a function that is called more than once. The `action` field controls this.
    [Table 19-3](#table19-3) shows the possible options you could pass to `action`
    `.`
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 19-3: Warning Filter Action Options'
  prefs: []
  type: TYPE_NORMAL
- en: '| `ignore` | Never show the warning. |'
  prefs: []
  type: TYPE_TB
- en: '| `once` | Only show the warning once, for the whole program. |'
  prefs: []
  type: TYPE_TB
- en: '| `module` | Only show the warning once per module. |'
  prefs: []
  type: TYPE_TB
- en: '| `default` | Show the warning once per module and line number. |'
  prefs: []
  type: TYPE_TB
- en: '| `always` | Always show the warning, no matter how often it occurs. |'
  prefs: []
  type: TYPE_TB
- en: '| `error` | Convert the warning to an exception. |'
  prefs: []
  type: TYPE_TB
- en: 'For example, if I only wanted to see the first instance of any particular warning
    in a module, I’d pass the string `module` to the `action` field, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: I pass the warnings filter to the warning filter flag, `-W`, followed by the
    warning filter itself (with no space in between the flag and the filter.) This
    flag must come *before* the module to run, as it’s an argument for Python itself.
    If it came at the end, it would be erroneously passed as an argument to the *basic_warning.py*
    module itself.
  prefs: []
  type: TYPE_NORMAL
- en: Likewise, you can alternatively print only the first occurrence of each warning
    in the entire program’s run with `-Wonce`.
  prefs: []
  type: TYPE_NORMAL
- en: Ignoring Warnings
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'You can also use warning filters to hide an entire category of warnings from
    an end user by using the `ignore` action. Let’s say you don’t want the user to
    see all the deprecation warnings you plan to address in the next version of your
    program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The `ignore` action hides warnings, and `DeprecationWarning` in the `category`
    field causes only deprecation warnings to be hidden while the Python module is
    running.
  prefs: []
  type: TYPE_NORMAL
- en: Converting Warnings into Exceptions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Using the `error` action, you can convert warnings into fatal exceptions to
    crash the program. This is possible because the base class `Warning` inherits
    from the `Exception` class. The following example turns all warnings into errors
    when running a particular module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Since no other fields are provided in the filter, this `error` action will affect
    all warnings. This might be helpful in continuous integration systems where a
    pull request should automatically be rejected if there are warnings.
  prefs: []
  type: TYPE_NORMAL
- en: Another reason why you might raise warnings as exceptions is to ensure your
    program isn’t using any deprecated code. You can turn all `DeprecationWarning`
    warnings into errors with `-Werror::DeprecationWarning` and then resolve them
    one by one, until your program runs.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, turning errors into exceptions can have negative consequences because
    it also turns any warnings from within dependencies or the standard library into
    errors. To get around this, I need to limit the warning filter, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This warning filter will only convert warnings to errors in the module I’m directly
    executing, and it will handle any warnings from elsewhere according to the default
    rules.
  prefs: []
  type: TYPE_NORMAL
- en: 'To convert warnings to errors across an entire package, such as my `timecard`
    package, without getting warnings from dependencies and the standard library,
    I’d use the following filter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The regular expression `timecard[.*]` matches any module contained in the `timecard`
    package or any `subpackage` thereof.
  prefs: []
  type: TYPE_NORMAL
- en: There is quite a bit more to warning filters that’s outside the scope of this
    chapter. I recommend reading further at [https://docs.python.org/3/library/warnings.xhtml](https://docs.python.org/3/library/warnings.xhtml).
  prefs: []
  type: TYPE_NORMAL
- en: Logging
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In Chapter 8, you learned how to log exceptions, rather than merely passing
    them to `print()`. This technique has a few advantages. It grants you control
    over whether messages are sent to the standard output or to a file, and it gives
    you the ability to filter messages based on their severity. The severity levels,
    in increasing order of severity, are as follows: `DEBUG`, `INFO`, `WARNING`, `ERROR`,
    and `CRITICAL`.'
  prefs: []
  type: TYPE_NORMAL
- en: The patterns I used in Chapter 9 were sufficient to get you this far, but logging
    in a production-grade project requires a bit more thought. You must consider which
    messages should be visible under which circumstances and how different types of
    messages should be logged. A critical warning might need to be displayed on the
    terminal and stored in a file, while an informative message about a normal operation
    may be hidden, except when the user runs the program in a provided “verbose” mode.
  prefs: []
  type: TYPE_NORMAL
- en: 'To handle all things logging, Python provides the `logging` module, which defines
    four components: `Logger`, `Handler`, `Filter`, and `Formatter`. I’ll break down
    each of these in turn.'
  prefs: []
  type: TYPE_NORMAL
- en: Logger Objects
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A `Logger` object handles your logging messages. It accepts messages to be logged
    as `LogRecord` objects and passes them on to one or more `Handler` objects, based
    on the reported severity. I’ll come back to severity and `Handler` shortly.
  prefs: []
  type: TYPE_NORMAL
- en: 'A typical project has one `Logger` per module. Never instantiate these `Logger`
    objects yourself. Instead, you must acquire `Logger` objects with `logger.getLogger()`,
    instead of instantiating them. This ensures that more than one logger with the
    same name is never created:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The `__name__` attribute is the name of the current module, as well as its parent
    packages (if any). If no `Logger` object yet exists by that name, it is created
    behind the scenes. In either case, the `Logger` object is bound to `logger` and
    becomes ready for use.
  prefs: []
  type: TYPE_NORMAL
- en: This pattern works in most situations. In the entry module for a package, however,
    you must explicitly declare the name of the logger, using the name of the package.
    Using the `__name__` attribute here would be impractical, since it will always
    report the name of the entry module as `__main__`. This logger should have the
    package name, so it can serve as the primary logger for all the modules belonging
    to the package. All the other loggers will pass their messages up to this one.
  prefs: []
  type: TYPE_NORMAL
- en: 'To illustrate the use of `Logger`, I’ll create a `letter_counter` package for
    determining the most commonly occurring letters in a given passage of text. The
    package will use logging to handle warnings and informative messages. Here is
    the beginning of my `__main__.py` module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 19-4: *letter_counter/__main__.py:1*'
  prefs: []
  type: TYPE_NORMAL
- en: I acquire the `Logger` object by passing the name of the package explicitly
    to the `logging.getLogger()` function ❶ and then binding that object to `logger`.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important that the name of this logger should match the package name, so
    it can serve as the primary logger for the `letter_counter` package.
  prefs: []
  type: TYPE_NORMAL
- en: 'I must also acquire a `Logger` object for each module and subpackage in this
    package that needs to perform logging. Here, the *letter.py* module acquires a
    logger:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 19-5: *letter_counter/**letters**.py:1*'
  prefs: []
  type: TYPE_NORMAL
- en: Because this `__name__` expression resolves to `letter_counter.letters`, the
    `letter_counter` logger created in [Listing 19-4](#listing19-4) automatically
    becomes the parent of this logger. As a result, all messages passed to the logger
    in *letters.py* will be passed in turn to the `letter_counter` logger.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the same way, I can add a logger to the other file in my package, *common.py*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 19-6: *letter_counter/**common**.py:1*'
  prefs: []
  type: TYPE_NORMAL
- en: Handler Objects
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `Handler` is responsible for sending the `LogRecord` objects to the right
    place, whether that be the standard output, the standard error, a file, over a
    network, or some other location. The logging module contains a number of built-in
    `Handler` objects, all of which are thoroughly documented at [https://docs.python.org/3/library/logging.handlers.xhtml](https://docs.python.org/3/library/logging.handlers.xhtml).
    This chapter won’t cover many of these useful handlers, so the documentation is
    well worth a quick read. In most situations, however, you’ll wind up using one
    of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`StreamHandler` sends logging output to streams, especially the standard output
    and standard error streams. You may pass the desired output stream to the `logging.StreamHandler`
    class initializer; otherwise, `sys.stderr` is used by default. Although you can
    use this handler for logging to a file, `FileHandler` will give you better results
    for that use case.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`FileHandler` sends logging output to files. You must pass the filename or
    `Path` to the target output file to the `logging.FileHandler` class initializer.
    (There are a number of further specialized `Handler` classes for dealing with
    rotating and system log files.)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SocketHandler` sends logging output to a network socket over TCP. You would
    pass the host and port as arguments to the `logging.handlers.SocketHandler` class
    initializer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SMTPHandler` sends logging output to an email address via SMTP. The mail host,
    sender email address, recipient email address, subject, and login credentials
    all have to be passed to the `logging.handlers.SMTPHandler` class initializer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`NullHandler` sends logging output into the black hole at the heart of a captive
    dark star, never to be seen or heard from again. Nothing has to be passed to the
    `logging.NullHandler` class initializer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'I’ll continue my `letter_counter` package example by printing all the `LogRecord`
    objects in the `letter_counter` package to the terminal with `logging.StreamHandler()`,
    which sends logs to the standard-output or standard-error streams. I add this
    handler to my top-level `Logger` object like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 19-7: *letter_counter/__main__.py:2*'
  prefs: []
  type: TYPE_NORMAL
- en: Because I did not specify a stream with the `StreamHandler()` constructor, `stream_handler`
    will pass messages to the `sys.stderr` stream.
  prefs: []
  type: TYPE_NORMAL
- en: Notice that I only need to add the `Handler` to the `letter_counter` logger.
    Since the loggers for `letter_counter.letters` and `letter_counter.common` are
    children, they will pass all their `LogRecord` objects up to their parent.
  prefs: []
  type: TYPE_NORMAL
- en: 'You may attach as many handlers as you like, to any of the loggers. Child loggers
    will still relay their `LogRecord` objects to their parents in addition to employing
    their own handlers, unless you set the `propagate` attribute of a child logger
    to `False`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: In my example, I don’t need to add any handlers to the child loggers. I can
    let the loggers pass their `LogRecord` objects back up to the parent logger, which
    has the one `StreamHandler` attached.
  prefs: []
  type: TYPE_NORMAL
- en: Logging with Levels
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: My logging example is still incomplete because it doesn’t include the *severity*
    *level* of each message, which indicates the message’s relative importance.
  prefs: []
  type: TYPE_NORMAL
- en: Logging with levels allows you to configure a logging system to display only
    messages that are at or above a given severity level. For example, you may want
    to see all `DEBUG` messages while developing, but end users should only see `WARNING`
    messages and above.
  prefs: []
  type: TYPE_NORMAL
- en: There are six built-in severity levels, as outlined in [Table 19-4](#table19-4).
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 19-4: Logging Severity Levels'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Level** | **Numeric value** | **Use** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `CRITICAL` | 50 | Messages related to horrible, terrible, no good, very bad,
    everything-is-broken situations |'
  prefs: []
  type: TYPE_TB
- en: '| `ERROR` | 40 | Messages related to an error that can probably be recovered
    from (meaning at least all is not lost) |'
  prefs: []
  type: TYPE_TB
- en: '| `WARNING` | 30 | Messages related to problems that are not (yet) errors but
    may require attention |'
  prefs: []
  type: TYPE_TB
- en: '| `INFO` | 20 | Informative and useful messages that are not related to actual
    problems |'
  prefs: []
  type: TYPE_TB
- en: '| `DEBUG` | 10 | Messages that are only of interest to developers, particularly
    when hunting for bugs |'
  prefs: []
  type: TYPE_TB
- en: '| `NOTSET` | 0 | Only used to specify that all messages should be displayed
    (never used as a message severity level) |'
  prefs: []
  type: TYPE_TB
- en: 'To assign a level to a message when logging it, use the `Logger` instance method
    corresponding to the level for the message, as I do in this function from *letter_counter/common.py*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 19-8: *letter_counter/**common**.py:2*'
  prefs: []
  type: TYPE_NORMAL
- en: This function converts a string to all lowercase and filters it down to contain
    only letters. The important part of this example is the `logger.debug()` method
    call, which passes a `LogRecord` to this module’s `logger` object ([Listing 19-6](#listing19-6))
    with level `DEBUG`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Meanwhile, over in *letter_counter/letters.py*, I have some `INFO` level messages
    I need to output under certain circumstances:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 19-9: *letter_counter/**letters**.py:1*'
  prefs: []
  type: TYPE_NORMAL
- en: These functions count up the number of vowels and consonants in a given string,
    and they return the vowel or consonant that appears most frequently. The important
    parts here are the two calls to `logger.info()` ❶ ❷. Notice that these messages
    are logged only if an empty string is passed to `most_common_consonant()` or `most_common_vowel()`.
  prefs: []
  type: TYPE_NORMAL
- en: Controlling the Log Level
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Any given `Logger` object can be set to pick up `LogRecord` objects with a particular
    level or higher, using the `setLevel()` method. As with adding `Handler` objects,
    you only need to set the level on the top-level logger. While you *can* set it
    on child loggers if you see fit to do so, they will no longer delegate their `LogRecord`
    objects to their parents. By default, a `Logger` has a level of `NOTSET`, causing
    it to delegate its `LogRecord` objects up the hierarchy. As soon as a `Logger`
    with a level other than `NOTSET` is encountered in that hierarchy, the chain of
    delegation stops.
  prefs: []
  type: TYPE_NORMAL
- en: 'In my example, I set the logging level on the top-level logger to `WARNING`
    by default, but I allow users to pass a `-v` argument on the invocation of my
    package to instead set the level to `INFO`. I’m using the built-in `argparse`
    module to handle command-line arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 19-10: *letter_counter/__main__.py:3*'
  prefs: []
  type: TYPE_NORMAL
- en: 'I won’t go into the usage of `argparse` in much detail here, as it’s largely
    off-topic and the official `argparse` tutorial does a decent job of introducing
    it: [https://docs.python.org/3/howto/argparse.xhtml](https://docs.python.org/3/howto/argparse.xhtml).
    Suffice to say that I define two arguments: a `-v` flag for toggling verbose mode
    ❶ and the path to the file the program should read from ❷. That flag is the important
    part in this situation. If it was passed in the package invocation, I set the
    level of `logger` to `logging.INFO` ❸. Otherwise, I use `logging.WARNING`, thereby
    ignoring all messages logged with `logger.info()`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the rest of my `__main__.py` module, which reads the file, calls the
    functions to count letters, and displays the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 19-11: *letter_counter/__main__.py:4*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Nothing much to see here in relation to logging, except for a couple more logged
    messages: one at `INFO` level ❶ and one at `WARNING` level ❷.'
  prefs: []
  type: TYPE_NORMAL
- en: Running the Example
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To demonstrate the logging system at work, I’ll invoke my package from the
    command line, passing it a path to a text file containing The Zen of Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Because I omitted the `-v` flag, the logging level is `WARNING`, meaning only
    messages at level `WARNING`, `ERROR`, or `CRITICAL` will be logged. Since *zen.txt*
    is a valid path, I see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, I’ll add that `-v` flag to my invocation, which should change the logger
    level according to the logic in [Listing 19-10](#listing19-10):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'This causes the output to change a bit:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'I now see the `INFO` level message from *letter_counter/__main__.py*. However,
    since the file exists and isn’t empty, I don’t see any of the `INFO` messages
    from the other modules. To see those, I’ll pass a path to an empty file instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The output now contains additional messages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'You’ll notice one other message that is absent: the letter count message from
    *letter_counter/common.py* ([Listing 19-8](#listing19-8)). As it was logged at
    level `DEBUG`, it is still being ignored with the logger set to level `INFO`.
    I would have to modify my code to see it.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For one last test, I’ll drop the `-v` flag, thereby using the `WARNING` level
    on the logger, and I will pass an invalid file name in the invocation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'This time, I see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: That output would be the same in this scenario whether I passed the `-v` flag
    to my program or not, as `WARNING` is higher priority than `INFO`.
  prefs: []
  type: TYPE_NORMAL
- en: Filter, Formatter, and Configuration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are two more components you can add to a logging system: a *Filter* and
    a *Formatter*.'
  prefs: []
  type: TYPE_NORMAL
- en: A `Filter` object further defines where to pick up `LogRecord` objects, and
    it can be applied to a `Logger` or `Handler` using the `addFilter()` method. You
    can also use any callable object as a filter.
  prefs: []
  type: TYPE_NORMAL
- en: A `Formatter` object is responsible for converting a `LogRecord` object to a
    string. These are usually defined by passing a special format string to the ``logging.Formatter()
    function. You can also add a single `Formatter` to a `Handler` object with the
    `setFormatter()` method.``
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30] THICKNESS = 0.125  # must be a positive number [PRE31] THICKNESS =
    0.125 **if __debug__:**  **if not THICKNESS > 0:**  **raise AssertionError("Vinyl
    must have a positive thickness!")** [PRE32] THICKNESS = 0.125 **assert THICKNESS
    > 0, "Vinyl must have a positive thickness!"** [PRE33] def fit_records(width,
    shelves):     records_per_shelf = width / THICKNESS     records = records_per_shelf
    * shelves     return int(records) [PRE34] def get_number(prompt):     while True:         value
    = input(prompt)         try:             assert value.isnumeric(), "You must enter
    a whole number"             value = int(value)             assert value > 0, "You
    must enter a positive number."         except AssertionError as e:             print(e)             continue         value
    = int(value)         return value [PRE35] def main():     width = get_number("What
    is the bookcase shelf width (in inches)? ")     print("How many shelves are...")     shelves_lp
    = get_number("    12+ inches high? ")     shelves_78 = get_number("    10-11.5
    inches high? ")     shelves_single = get_number("    7-9.5 inches high? ")      records_lp
    = fit_records(width, shelves_lp)     records_single = fit_records(width, shelves_single)     records_78
    = fit_records(width, shelves_78)      print(f"You can fit {records_lp} LPs, "           f"{records_single}
    singles, and "           f"{records_78} 78s.")   if __name__ == "__main__":     main()
    [PRE36] $ **python3 -O vinyl_collector.py**  What is the bookcase shelf width
    (in inches)? -4 How many shelves are...  12+ inches high? 0     10-11.5 inches
    high? 4     7-9.5 inches high? -4 You can fit 0 LPs, 128 singles, and -128 78s.
    [PRE37] def get_number(prompt):     while True:         value = input(prompt)         try:             value
    = int(value)         **except ValueError:**             **print(**"You must enter
    a whole number."**)**             continue          **if value <= 0:**             **print(**"You
    must enter a positive number."**)**             **continue**          return value
    [PRE38] THICKNESS = -0.125  **# HACK: this value is now wrong, for test purposes**
    assert THICKNESS > 0, "Vinyl must have a positive thickness!" [PRE39] python3
    vinyl_collector.py [PRE40] Traceback (most recent call last):   File "./vinyl_collector.py",
    line 2, in <module>     assert THICKNESS > 0, "Vinyl must have a positive thickness!"
    AssertionError: Vinyl must have a positive thickness! [PRE41] python3 -O vinyl_collector.py
    [PRE42] What is the bookcase shelf width (in inches)? 1 How many shelves are at
    least...     12 inches high? 1     10 inches high? 2     7 inches high? 3 You
    can fit -8 LPs, -24 singles, or -16 78s. [PRE43]`If you’re using an IDE, it may
    include features that integrate with `pdb` or else offer its own alternative debugger.
    While you should familiarize yourself with your IDE’s debugging tools, it is also
    helpful to know how to use `pdb` on the command line, especially for those cases
    where you don’t have access to your development environment of choice.    ###
    A Debugging Example    The best way to learn how to use the debugger is to try
    it out. [Listing 19-20](#listing19-20) is a complete module with a fairly pesky
    bug. If you take the time to read it, you’ll probably figure out the problem yourself,
    but production code is rarely this linear. So, even if you think you’ve identified
    the problem, enter this code into a file as is. I’ll work with this code quite
    a lot through the rest of the chapter.    [PRE44]    Listing 19-20: *train_timetable.py*    This
    module simulates grabbing live data about a particular train, perhaps from API
    transit data. It then processes that data to find particular information. (A more
    realistic example might work with data in the widely used *General Transit Feed
    Specification (GTFS)* format; this imaginary API merely serves up a list of dictionaries.)    If
    you run this code, it crashes with an exception that may seem indicative of a
    simple mistake in my code:    [PRE45]    “Oh, sure,” I might say to myself. “I
    must have forgotten my return statement.” But when I check the `arrives_at()`
    function, the logic makes sense. Besides, the station ID `''coon_rapids_fridley''`
    is *right there* in the test data! Something spooky is going on here.    Enter
    debugger, stage left.    ### Starting the Debugger    You’ll usually want to run
    the debugger directly on your code. One way is to invoke `pdb` from the command
    line when you run your program. For example, if I wanted to invoke the debugger
    on my *train_timetable.py* module, I could do this:    [PRE46]    Since Python
    3.7, the `pdb` module can also run a package with `-m` in the same manner as the
    interpreter. If I wanted to run my `timecard` package within the debugger, I’d
    do this:    [PRE47]    Either way, the module or package is started in the `pdb`
    shell. The debugger immediately stops the program, awaiting a command.    [PRE48]    At
    the `(Pdb)` prompt, I can enter debugger shell commands. I’ll come back to the
    usage of this debugger shell in a moment.    Another way of starting the debugger
    is by setting a breakpoint directly in your code. When you run the code normally,
    it will hit this breakpoint and hand off control to `pdb`.    From Python 3.7
    onward, you can set a breakpoint anywhere in your code with the following built-in
    function:    [PRE49]    Prior to 3.7, you could do the same with the following:    [PRE50]    Breakpoints
    will save you considerable time if you have an idea where the bug might originate
    from, or at least where the problematic execution stack begins. If you have a
    breakpoint set in your code, you only need to execute the program normally:    [PRE51]    This
    command starts the program normally, but as soon as it hits the breakpoint, the
    Python interpreter hands off execution control to `pdb`.    ### Debugger Shell
    Commands    The `pdb` tool has quite a few commands you can enter at the `(Pdb)`
    prompt to control and monitor the execution of the code.    In Appendix B, I document
    the most important `pdb` commands. These commands are also exhaustively documented
    at [https://docs.python.org/3/library/pdb.xhtml](https://docs.python.org/3/library/pdb.xhtml),
    although that page can be a bit hard to navigate when you’re looking for something
    in particular.    While I won’t be able to demonstrate many of the `pdb` commands,
    I’ll walk you through debugging this particular example from [Listing 19-20](#listing19-20).    ###
    Stepping Through the Code    For this example, I’ll start debugging at the top
    of my code by invoking `pdb` directly, like this:    [PRE52]    I’ll use the debugger
    as shown below. I strongly encourage you to follow along.    The `pdb` session
    starts at the top of the module, but the problem is farther down. I use the `next`
    (or `n`) command to move down to the beginning of the usage section of my module.    [PRE53]    When
    I reach the first function call ❶, I use the `list` (or `l`) command to see the
    nearby code. I’m currently stopped on line 34, as indicated by the `->` in the
    code.    ### Setting a Breakpoint and Stepping into a Function    I know I’m having
    a problem around line 39, so I’ll set a breakpoint there:    [PRE54]    The command
    `break 39` sets a breakpoint on line 39\. I then use the `continue` command to
    proceed to that breakpoint, since it is later in the execution flow than the present
    position.    Next, I use the `step` (or `s`) command to step into the `arrives_at()`
    function. Then, before checking that code, I use the `args` command to see what
    values were passed to the function:    [PRE55]    The station ID for Coon Rapids
    Fridley looks odd ❷, and it certainly doesn’t match the station ID I’m looking
    for ❶. The data in `timetable` is getting mutated somewhere, and this is probably
    part of the reason why my code is returning `None`. Still, I need to confirm my
    theory.    ### Moving Through the Execution Stack    Since I didn’t change the
    station ID in this part of the code, the problem must exist in an earlier part
    of the code. I *could* start over with a fresh debugging session, so I could stop
    earlier in the execution stack, but when debugging in a large, real-world program,
    that could be a royal pain. Thankfully, `pdb` provides an alternative.    First,
    I need to know where I am in the execution stack. The `where` command shows me
    the current stack trace, which is composed of four frames:    [PRE56]    I’m currently
    at the bottommost frame, as indicated by the `>` character ❶. I can move up one
    frame with the `up` command, which changes my focus to this line:    [PRE57]    Next,
    I’ll inspect the nearby code:    [PRE58]    I use the `l` command (an alias for
    `list`) to see the surrounding code. You can see that line 39 has a breakpoint,
    indicated by the `B`. The `->` also indicates that this is my current position.    I
    know from earlier that `timetable` is getting mutated somewhere unexpected. The
    first suspect is that `next_station()` function call on line 36, so I set a breakpoint
    there with `b 36` (the same as `break 36`).    I must move backward in the execution
    stack, which is one of the cool features of `pdb`. There are two ways to do this:
    either I could use the `restart` command from this point and then continue to
    the new breakpoint, or I could use `jump`. Because the latter is a bit trickier,
    I’ll show how to accomplish it here.    The difficulty with using `jump` comes
    from the fact that I cannot jump from any position other than the newest frame,
    and I’m one level removed from that. There are a few ways around this. I could
    set a breakpoint at a later line on the outer scope and then continue to it. My
    present situation is simple enough, so I can use the `next` command from this
    point to step out of the current function call:    [PRE59]    I’m now in a position
    to jump. However, an important distinction between `restart` and `jump` is that
    while the former starts afresh, the latter executes with the current state staying
    as it is. This means that if I want to get an accurate picture of what’s happening,
    I need to get a fresh value for `timetable` without changing anything else. The
    easiest way to do that in this code is to jump to line 34:    [PRE60]    Immediately
    after making the jump, `pdb` stays paused, awaiting further instructions. I run
    this line with `n` and then confirm that `timetable` is back to what it should
    be by pretty-printing it with `pp timetable`.    ### Inspecting the Source    Now,
    I’ll see how `timetable` is getting messed up. I don’t need to `continue` at this
    point, as I’m already sitting on line 36, where I’d wanted to check next. I know
    that the data in `timetable` is being mutated, so I inspect the code of `next_station()`
    with the `source next_station` command:    [PRE61]    Hmm . . . line 24 is intriguing,
    isn’t it? That’s the logic for changing from so-called *lower_snake_case* to *Title
    Case*. I don’t want to waste time stepping through that `for` loop, so I set a
    breakpoint on the suspect line with `b 24` and then continue execution with `c`.    Now
    I can check the before-and-after state of `station`:    [PRE62]    Aha! The first
    time I check station with `p station`, it has the correct station ID. After running
    that suspect line with `n`, I check the value again and find it has changed. That’s
    not so bad in itself, but if I look at the value `timetable` with `pp timetable`,
    I find the change was made there.    Although a tuple itself is immutable, this
    isn’t necessary true of its items, and a dictionary is most certainly mutable.
    By binding an item from the tuple to `station` and then mutating it, that change
    is visible in the tuple. The `next_station()` function has side effects. The `arrives_at()`
    function couldn’t find the station with the expected ID because the ID had been
    changed.    ### Checking a Solution    Once I have found the problem, I can quit
    the debugger and fix it. However, if I’m wrong, I have to start all over, and
    that could be a pain! Since I’m already located at the point of error, I’ll try
    changing the dictionary back to what it should be.    I can execute a Python statement
    at the current position, effectively before the line I’m stopped on, using the
    `!` command:    [PRE63]    After running the statement that fixes the value of
    `station`, I confirm that the fix worked with `pp timetable`. Sure enough, the
    `''coon_rapids_fridley''` entry changed to what it should be. Then, I move forward
    to the next line of code with the `n` command.    Just because I fixed a problem
    in the code doesn’t mean I fixed the only problem. I need to let the program finish
    running to be absolutely certain the problem is resolved. I list all the breakpoints
    with `b` (or `break`) without arguments. For this example, I’ll clear breakpoints
    1 and 2, as those are the ones that will get in the way when I continue:    [PRE64]    Now,
    I have removed the breakpoints I don’t need anymore. (I could also have cleared
    all breakpoints using `clear`.)    I continue from here using the `continue` command:    [PRE65]    While
    the output for “Next station is . . . ” isn’t what I want—I’ll have to work out
    a solution for that—the rest of the code functions without crashing. I’ve solved
    it! Finally, I can exit the `pdb` shell with `q` and then change my code based
    on what I discovered.    ### Postmortem Debugging    So far, you’ve seen that
    you can run a debugger from the top of a program or from a preset breakpoint.
    A third way to run a debugger is *postmortem*, meaning after a fatal crash has
    taken place. This is best thought of as a snapshot of the moment of the crash.
    You cannot move about in the code, set breakpoints, step into function calls,
    or jump around. However, you *can* inspect anything you want from the point of
    the crash.    There are a couple of ways to start postmortem debugging. The easiest
    way is to start the module in the interactive Python shell and allow it to crash,
    then invoke the postmortem debugger with `import pdb; pdb.pm()`:    [PRE66]    There’s
    not much I can do here apart from inspection, which means this technique isn’t
    terribly helpful in this particular scenario. That said, I could still check the
    value bound to the names `timetable` and `station`, which might grant me some
    initial insight:    [PRE67]    This is quite similar to print statement debugging,
    at least from the point of failure. From this, I could ascertain that the `timetable`
    itself might have been mutated unexpectedly, which is a useful insight. From here,
    I could start the module over in regular debugging mode and follow up that idea,
    as you saw me do earlier.    ## Using faulthandler    If you’ve ever worked with
    C or C++, you may be familiar with the concept of *undefined behavior*, or a situation
    in code with no formal definition for how it should be handled. Code with undefined
    behavior may do anything: it might appear to work, fail with an error, or even
    do something weird.    You may hear many Python developers say, “Python doesn’t
    have undefined behavior!” This is only partly true. Nothing in Python’s own language
    specification is marked as “undefined behavior.” Everything should either work
    in a defined fashion or fail with a specific error.    True as that may be, CPython
    (the default interpreter) and many common Python extensions and libraries are
    still built with C, and undefined behavior is a possibility in C. If you search
    for the term *undefined* in the Python documentation, you’ll find a few advanced
    situations where undefined behavior is possible.    When you believe you’re up
    against undefined behavior, particularly *segmentation faults*—fatal system errors
    resulting from a program trying to access computer memory it doesn’t have permission
    to access—the `faulthandler` module is one of the most helpful tools in your toolbox.    To
    demonstrate this tool’s use, consider the following brief segment of Python code
    with undefined behavior:    [PRE68]    Listing 19-21: *segfault.py:1a*    The
    undefined behavior here comes from the underlying C code: I attempt to set the
    memory at address `0`, the *null pointer*, to the value `254`. The behavior of
    accessing or modifying memory at the null pointer is undefined. While anything
    could happen, this particular action almost always results in a segmentation fault:    [PRE69]    It’s
    easy to spot this problem in a simple, two-line program, but imagine if this error
    occurred in a vast project with hundreds of lines.    This is where `faulthandler`
    comes in handy. It allows you to quickly locate the line in your code that contains
    the undefined behavior. There are two ways to run this tool for a project. The
    first way is to invoke it with `-X faulthandler` when you run the interpreter:    [PRE70]    Alternatively,
    you can enable `faulthandler` directly in your code:    [PRE71]    Listing 19-22:
    *segfault.py:1b*    Because the line enabling `faulthandler` is intended to be
    removed once the problem has been found, it’s acceptable to cram the import statement
    onto the same line as the call to `enable()`.    Regardless of how you enable
    `faulthandler`, the output is essentially the same. As soon as a segmentation
    fault or similar fatal error is encountered, you’ll see a complete stack trace:    [PRE72]    Based
    on this traceback, you can see that the problem is on line 5 of *segfault.py*
    (from [Listing 19-22](#listing19-22)), which contains the invalid call to `ctypes.memset`.    ##
    Evaluating Your Program’s Security with Bandit    As I’ve alluded to throughout
    this book, your choices about what modules and libraries you use and how you use
    them may introduce risks of a number of security concerns into your code. While
    you should try to stay informed about vulnerabilities, it’s not practical to memorize
    every single possible issue. Thankfully, you can employ a tool to help monitor
    your code’s security.    *Bandit* is a security-focused static analyzer. It checks
    your code for security issues by building and testing it as an *abstract syntax
    tree (AST)*, which is a tree data structure that represents the overall structure
    of the code. You can install the `bandit` package from pip and use it in the manner
    of most other static analyzers.    Consider the following very small program,
    which contains a significant security issue:    [PRE73]    Listing 19-23: *magic_calculator.py:1a*    Rather
    than point out the security problem here myself, I’ll run this program through
    Bandit to see what issues it finds:    [PRE74]    Here’s the output:    [PRE75]    The
    first warning ❶ complains about the `input()` built-in function being insecure
    in Python 2\. In looking at that warning, a developer might be tempted to say,
    “Oh, Bandit must be wrong. It’s complaining about Python 2, and I’m using Python
    3!” In fact, it’s not wrong here. I am assuming that the code will be run in Python
    3, but it might accidentally get executed by Python 2, where `input()` actually
    *is* insecure.    To fix this, I need to add a shebang to the top of my module,
    to ensure that the code will be executed by Python 3:    [PRE76]    Listing 19-24:
    *magic_calculator.py:1b*    Bandit’s second issue ❷ comes with a suggestion: switch
    to `ast.literal_eval()` instead of `eval()`, as the latter is vulnerable to code
    injection attacks. I’ll revise accordingly:    [PRE77]    Listing 19-25: *magic_calculator.py:1c*    Rerunning
    Bandit on this revised code shows no more issues. You can find the tool’s full
    documentation at [https://bandit.readthedocs.io/en/latest/](https://bandit.readthedocs.io/en/latest/).    The
    topic of security may feel irrelevant to your project, but you must remember that
    it doesn’t necessarily have anything to do with the data your program works with!
    Many security issues are related to an attacker using your code as a vector or
    tool in an oft-unrelated attack. Security flaws are like a screen door on a bank
    vault. It doesn’t matter how it got there, who is meant to use it, or how helpful
    it is to the authorized users. Sooner or later, someone is going to abuse it for
    illicit or unauthorized purposes.    ## Reporting Bugs to Python    Sometimes,
    the problem in your code isn’t your fault! Python, like all code, has bugs that
    crop up now and then. Once you’re quite certain the bug isn’t coming from your
    own code or a third-party module or package, you are strongly encouraged to report
    the bug to the Python developers.    Your first step should be to check whether
    the bug has already been reported. In any issue tracker, this can be tricky, so
    be patient with this step. All issues for Python are tracked at [https://bugs.python.org/](https://bugs.python.org/),
    so it’s worthwhile to have an account there. Try searching the site for different
    words, focusing on the parts of the language you’re using and any keywords in
    error messages you’ve received. Make sure to omit any words that are unique to
    your code, as they probably won’t appear in other bug reports. Also, don’t count
    out previously closed bugs as candidates. Regressions happen. If you find an existing
    bug that matches your situation, leave a comment with the information you have.    If
    you can’t find a matching issue, open a new bug report. Be prepared to put some
    time and effort into it. Since you’re the one facing the bug, you’re in a better
    position than anyone to pin it down. Provide as much information as possible to
    help the Python developers reproduce it. Be prepared to respond to further questions,
    as you’ll likely need to try some things out to prove your code isn’t the real
    issue.    The Python documentation has a helpful guide explaining how to report
    bugs effectively. Before reporting an issue, please read that guide at [https://docs.python.org/3/bugs.xhtml](https://docs.python.org/3/bugs.xhtml).    Security
    issues should be handled separately from normal bugs, as they need to be treated
    with confidentiality to minimize the risks to existing code. If you come across
    a security flaw in Python, please report it via email to [security@python.org](http://mailto:security@python.org),
    following the instructions at [https://www.python.org/dev/security/](https://www.python.org/dev/security/).    ##
    Wrapping Up    When it comes to combating bugs, the best defense is a good offense.
    Writing your code to make good use of exceptions, warnings, assertions, and logging
    will save you debugging work later.    When bugs do happen, don’t limit yourself
    to cramming `print()` statements into every part of your code. Logging and `assert`
    statements are helpful for manual debugging and catching problems while developing.
    Meanwhile, the Python debugger (`pdb`) is one of the most useful tools in your
    toolbox, and it is well worth learning to use, no matter how fancy the debugger
    in your IDE is.    Python’s default implementation, CPython, and many extensions
    besides, are built in C. This means that undefined behavior and other C-related
    bugs can creep into your Python code. When this happens, `faulthandler` is your
    best friend.    Finally, be prepared to check for and address security flaws in
    your code before anyone can take advantage of them. Bandit helps you get started
    with this, though true security testing will go beyond the scope of that tool.    Bugs
    may be inevitable, but the Python ecosystem provides excellent tools for catching,
    examining, and fixing them![PRE78]``'
  prefs: []
  type: TYPE_NORMAL

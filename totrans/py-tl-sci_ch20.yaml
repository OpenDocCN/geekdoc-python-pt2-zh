- en: '**20'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**20'
- en: PANDAS, SEABORN, AND SCIKIT-LEARN**
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: PANDAS、SEABORN 和 SCIKIT-LEARN**
- en: '![image](../images/common.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/common.jpg)'
- en: A common scientific practice is evaluating data and using it to generate predictive
    models. In this chapter, we’ll use three of Python’s most popular open source
    libraries to solve a zoological classification problem. Using this hands-on, project-based
    approach will showcase the functionality and synergy among the libraries and demonstrate
    what’s involved in doing science with Python.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 一种常见的科学实践是评估数据并利用它来生成预测模型。在本章中，我们将使用 Python 的三个最受欢迎的开源库来解决一个动物分类问题。通过这种基于项目的实践方法，将展示这些库的功能和协同效应，并演示使用
    Python 做科学研究的具体过程。
- en: For data loading, analysis, and manipulation, we’ll use the pandas package (*[https://pandas.pydata.org/](https://pandas.pydata.org/)).*
    Built on NumPy and Matplotlib, pandas uses array-based computing under the hood
    but has simpler syntax, making coding and plotting faster, easier, and more error
    free. Unlike native Python, pandas can intelligently read tabular text-file data,
    recognizing columns, rows, headers, and so on. And unlike NumPy, on which it’s
    built, pandas can handle heterogeneous data types such as mixtures of text and
    numbers.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数据加载、分析和处理，我们将使用 pandas 包（*[https://pandas.pydata.org/](https://pandas.pydata.org/)*）。pandas
    基于 NumPy 和 Matplotlib 构建，虽然底层使用基于数组的计算，但它的语法更简单，使得编写代码和绘图更加快速、容易且更少出错。与原生 Python
    不同，pandas 能够智能地读取表格文本文件数据，识别列、行、标题等内容。与 NumPy 不同，pandas 能处理异质数据类型，如文本和数字的混合数据。
- en: We’ll also use the seaborn library (*[https://seaborn.pydata.org/](https://seaborn.pydata.org/)*),
    which wraps Matplotlib to produce more attractive and easier visualizations. It
    represents a nice plotting compromise between the highly customizable but verbose
    syntax of Matplotlib and the bare-bones simplicity of pandas. Even better, seaborn
    is tightly integrated with pandas for seamless plotting and effective data exploration.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将使用 seaborn 库（*[https://seaborn.pydata.org/](https://seaborn.pydata.org/)*），它封装了
    Matplotlib，用于生成更具吸引力且更易于理解的可视化图表。它在高度可定制但冗长的 Matplotlib 语法和简单的 pandas 之间提供了一个良好的折衷。更好的是，seaborn
    与 pandas 紧密集成，能够无缝地进行绘图和有效的数据探索。
- en: Lastly, the scikit-learn library (*[https://scikit-learn.org/](https://scikit-learn.org/)*)
    is Python’s primary general-purpose machine learning toolkit. It provides algorithms
    for classification, regression, clustering, dimensionality reduction, preprocessing,
    and model selection.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，scikit-learn 库（*[https://scikit-learn.org/](https://scikit-learn.org/)*）是
    Python 的主要通用机器学习工具包。它提供了分类、回归、聚类、降维、预处理和模型选择的算法。
- en: In the sections that follow, you’ll apply these libraries to a real-world problem
    and observe how they work together. But, due to their enormous size and scope,
    we won’t be able to study them in-depth. Whole books have been dedicated to each,
    and the admittedly non-exhaustive pandas overview in Wes McKinney’s *Python for
    Data Analysis*, 2nd edition requires no less than 270 pages!
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，你将应用这些库来解决一个实际问题，并观察它们如何协同工作。但由于这些库的规模和范围庞大，我们无法深入研究它们。每个库都有专门的书籍，Wes
    McKinney 的 *《Python 数据分析》* 第二版中关于 pandas 的概述就足足有270页，尽管它不是全面的。
- en: If you’d like a complete picture, I list some additional resources in the “Summary”
    section at the end of this chapter. You can also find useful tutorials and examples
    in the official websites, cited previously.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解完整的内容，我在本章末的“总结”部分列出了一些附加资源。你还可以在之前提到的官方网站上找到有用的教程和示例。
- en: '**Introducing the pandas Series and DataFrame**'
  id: totrans-9
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**介绍 pandas Series 和 DataFrame**'
- en: The pandas library contains data structures designed for working with common
    data sources such as Excel spreadsheets and SQL relational databases. Its two
    primary data structures are series and DataFrames. Other libraries, like seaborn,
    are designed to integrate well with these data structures and supply additional
    functionality, making pandas a great foundation to any data science project.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: pandas 库包含用于处理常见数据源（如 Excel 表格和 SQL 关系数据库）的数据结构。它的两个主要数据结构是 Series 和 DataFrame。其他库（如
    seaborn）则设计用于与这些数据结构良好集成，并提供额外的功能，使得 pandas 成为任何数据科学项目的良好基础。
- en: '***The Series Data Structure***'
  id: totrans-11
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***Series 数据结构***'
- en: A *series* is a one-dimensional labeled array that can hold any type of data
    such as integers, floats, strings, and so on. Because pandas is based on NumPy,
    a series object is basically two associated arrays. One array contains the data
    point values, which can have any NumPy data type. The other array contains labels
    for each data point, called *indexes* ([Table 20-1](ch20.xhtml#ch020tab1)).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '*Series* 是一种一维的带标签数组，可以容纳任何类型的数据，例如整数、浮点数、字符串等。由于 pandas 基于 NumPy，因此序列对象本质上是两个关联的数组。一个数组包含数据点的值，可以是任何
    NumPy 数据类型；另一个数组包含每个数据点的标签，称为 *索引*（[表 20-1](ch20.xhtml#ch020tab1)）。'
- en: '**Table 20-1:** A Series Object'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**表 20-1：** 一个 Series 对象'
- en: '| **Index** | **Value** |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| **索引** | **值** |'
- en: '| --- | --- |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 0 | 42 |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 42 |'
- en: '| 1 | 549 |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 549 |'
- en: '| 2 | '' Steve '' |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| 2 | '' Steve '' |'
- en: '| 3 | –66.6 |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| 3 | -66.6 |'
- en: Unlike the indexes of Python list items, the indexes in a series don’t need
    to be an integer. In [Table 20-2](ch20.xhtml#ch020tab2), the indexes are the names
    of elements, and the values are their atomic numbers.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Python 列表项的索引不同，序列中的索引不需要是整数。在 [表 20-2](ch20.xhtml#ch020tab2) 中，索引是元素的名称，而值是它们的原子序数。
- en: '**Table 20-2:** A Series Object with Meaningful Indexes'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**表 20-2：** 一个具有有意义索引的 Series 对象'
- en: '| **Index** | **Value** |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| **索引** | **值** |'
- en: '| --- | --- |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Silicon | 14 |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| 硅 | 14 |'
- en: '| Sodium | 11 |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| 钠 | 11 |'
- en: '| Argon | 18 |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 氩 | 18 |'
- en: '| Cobalt | 27 |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| 钴 | 27 |'
- en: A series acts much like a Python dictionary in so much as indexes represent
    keys. It can thus serve as a replacement for a dictionary in many contexts. Another
    useful feature is that different series will align by index label when doing arithmetic
    operations between them even if the labels don’t occur in the same order.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 一个序列的作用类似于 Python 字典，其中索引代表键。因此，它可以在许多场景中作为字典的替代品。另一个有用的特性是，在进行算术操作时，即使标签的顺序不同，不同的序列也会根据索引标签对齐。
- en: As with a list or NumPy array, you can slice a series or select individual elements
    by specifying an index. You can manipulate the series many ways, such as filtering
    it, performing mathematical operations on it, and merging it with other series.
    To see the many attributes and methods available for a series object, visit *[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html).*
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 与列表或 NumPy 数组类似，你可以通过指定索引来切片一个序列或选择单独的元素。你可以以多种方式操作序列，例如过滤它、对其进行数学运算，或将其与其他序列合并。要查看序列对象的众多属性和方法，请访问
    *[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html)*。
- en: '***The DataFrame Data Structure***'
  id: totrans-30
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***DataFrame 数据结构***'
- en: A *DataFrame* is a more complex structure made up of two dimensions. It’s a
    collection of objects organized using a tabular structure, like a spreadsheet,
    with columns, rows, and data ([Table 20-3](ch20.xhtml#ch020tab3)). You can think
    of it as an ordered collection of columns with two indexing arrays. Each column
    represents a pandas series.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '*DataFrame* 是一种由两维结构组成的更复杂的数据结构。它是一个使用表格结构组织的对象集合，类似于电子表格，包含列、行和数据（[表 20-3](ch20.xhtml#ch020tab3)）。你可以将其视为一个有序的列集合，配有两个索引数组。每一列代表一个
    pandas 序列。'
- en: '**Table 20-3:** A DataFrame Object'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**表 20-3：** 一个 DataFrame 对象'
- en: '| **Columns** |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| **列** |'
- en: '| --- |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| **Index** | **Country** | **State** | **County** | **Population** |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| **索引** | **国家** | **州** | **县** | **人口** |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 0 | USA | Alabama | Autauga | 54,571 |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 美国 | 阿拉巴马州 | 奥陶戈 | 54,571 |'
- en: '| 1 | USA | Alabama | Baldwin | 182,265 |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 美国 | 阿拉巴马州 | 巴尔德温 | 182,265 |'
- en: '| 2 | USA | Alabama | Barbour | 27,457 |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 美国 | 阿拉巴马州 | 巴伯 | 27,457 |'
- en: '| 3 | USA | Alabama | Bibb | 22,915 |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 美国 | 阿拉巴马州 | 比布 | 22,915 |'
- en: The first index, for the rows, works much like the index array in a series.
    The second keeps track of the series of labels, with each label representing a
    column header. DataFrames also resemble dictionaries; the column names form the
    keys, and the series of data in each column forms the values. Like series, DataFrames
    come with many attributes and methods. For more information on these, see *[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)*.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个索引用于行，类似于序列中的索引数组。第二个索引用于跟踪标签序列，每个标签表示一个列标题。DataFrame 也类似于字典；列名是键，每列中的数据序列是值。像序列一样，DataFrame
    拥有许多属性和方法。有关更多信息，请参见 *[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)*。
- en: By integrating index objects and labels into their structure, you can easily
    manipulate DataFrames. We’ll look at some of this functionality as we work through
    the classification problem. You can also get up to speed on the basics by visiting
    the “10 Minutes to pandas” tutorial at *[https://pandas.pydata.org/docs/user_guide/10min.html](https://pandas.pydata.org/docs/user_guide/10min.html)*.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将索引对象和标签集成到结构中，你可以轻松地操作数据框（DataFrames）。我们将在处理分类问题时查看一些这样的功能。你也可以通过访问“10分钟快速了解pandas”教程来掌握基础知识，网址为
    *[https://pandas.pydata.org/docs/user_guide/10min.html](https://pandas.pydata.org/docs/user_guide/10min.html)*。
- en: '**The Palmer Penguins Project**'
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**Palmer Penguins 项目**'
- en: The *Palmer Penguins dataset* consists of 342 observations of Antarctic penguins
    from three islands in the Palmer Archipelago ([Figure 20-1](ch20.xhtml#ch020fig1)).
    It was made available through the *Palmer Station Antarctica LTER* (*[https://pallter.marine.rutgers.edu/](https://pallter.marine.rutgers.edu/)*).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '*Palmer Penguins 数据集*包含了来自南极洲帕尔默群岛三个岛屿的342个企鹅观察数据（[图 20-1](ch20.xhtml#ch020fig1)）。该数据集通过*Palmer
    Station Antarctica LTER*（* [https://pallter.marine.rutgers.edu/](https://pallter.marine.rutgers.edu/)
    *）提供。'
- en: '![Image](../images/20fig01.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig01.jpg)'
- en: '*Figure 20-1: The location of Dream, Torgersen, and Biscoe Islands, Palmer
    Archipelago, Antarctica*'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-1：Dream、Torgersen 和 Biscoe 岛，帕尔默群岛，南极洲的位置*'
- en: Three different penguin species were sampled in the study. In order of decreasing
    body size, these are the Gentoo, Chinstrap, and Adélie ([Figure 20-2](ch20.xhtml#ch020fig2)).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 研究中采样了三种不同的企鹅物种。按体型从大到小排列，它们是信天翁企鹅、帽带企鹅和阿德利企鹅（[图 20-2](ch20.xhtml#ch020fig2)）。
- en: '![Image](../images/20fig02.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig02.jpg)'
- en: '*Figure 20-2: The three penguin species in the Palmer Penguins dataset, as
    drawn by Charles Joseph Hullmandel (courtesy of Wikimedia Commons)*'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-2：由查尔斯·约瑟夫·赫尔曼德尔（Charles Joseph Hullmandel）绘制的 Palmer Penguins 数据集中的三种企鹅物种（图片来自
    Wikimedia Commons）*'
- en: The goal of this project will be to generate a model to predict the species
    of penguin from a combination of morphological features such as flipper length
    and body mass. In machine learning, this is considered a *classification* problem.
    We’ll use pandas to load, explore, validate, and clean the data, seaborn to plot
    the data, and scikit-learn to produce the predictive model.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 本项目的目标是生成一个模型，通过翅膀长度、体重等形态特征的组合来预测企鹅物种。在机器学习中，这被认为是一个 *分类* 问题。我们将使用 pandas 加载、探索、验证和清理数据，使用
    seaborn 绘制数据，使用 scikit-learn 构建预测模型。
- en: '***The Project Outline***'
  id: totrans-51
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***项目大纲***'
- en: 'Data science projects like this one follow a series of logical steps, as listed
    here:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 像这样的数据科学项目遵循一系列逻辑步骤，如下所示：
- en: Frame the problem (the single most important step).
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义问题（最重要的一步）。
- en: Collect raw data and set up the project.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 收集原始数据并设置项目。
- en: Process the data (through cleaning, merging, infilling, reducing, and so on).
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 处理数据（通过清洗、合并、填充、简化等方式）。
- en: Explore the data.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 探索数据。
- en: Perform in-depth analysis and develop models and algorithms.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进行深入分析并开发模型和算法。
- en: Apply the models and present the project results.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用模型并展示项目结果。
- en: Jupyter Notebook is ideal for this process, as it can handle all the steps in
    order and is basically self-documenting. It can also be turned into a slideshow
    for presentations (as discussed in [Chapter 5](ch05.xhtml)).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Jupyter Notebook 非常适合此过程，因为它可以按顺序处理所有步骤，且基本上是自文档化的。它还可以转化为幻灯片用于展示（如[第5章](ch05.xhtml)中讨论的）。
- en: '***Setting Up the Project***'
  id: totrans-60
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***项目设置***'
- en: For this project, we’ll use Jupyter Notebook in a dedicated project folder.
    We’ll install Notebook and the scientific and plotting libraries using the naive
    approach, in other words, directly in a conda environment within the project folder
    (see [Chapter 5](ch05.xhtml)). In general, you use the naive approach when you
    want to work with *specific* and *persistent* versions of a library or application.
    We’re using it here for practice, as we’ve previously been focusing on the modular
    approach, in which Notebook is installed in the *base* environment.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本项目，我们将在专用项目文件夹中使用 Jupyter Notebook。我们将使用最简单的方式安装 Notebook 和科学绘图库，即直接在项目文件夹中的
    conda 环境中安装（参见[第5章](ch05.xhtml)）。通常，当你希望使用 *特定的* 和 *持久的* 版本库或应用程序时，会使用这种简单的方法。我们在这里使用它进行实践，因为之前我们一直专注于模块化方法，在这种方法中，Notebook
    安装在 *base* 环境中。
- en: Start by making a folder named *penguins* under your user directory. Although
    you can do this through Anaconda Navigator, the command line is more succinct,
    so we’ll use that going forward.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，在你的用户目录下创建一个名为 *penguins* 的文件夹。虽然你可以通过 Anaconda Navigator 执行此操作，但命令行更加简洁，因此我们接下来将使用命令行。
- en: 'To make the directories for the project, open Anaconda Prompt (in Windows)
    or a terminal (in macOS or Linux) and enter the following (using your own directory
    path):'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 要为项目创建目录，请打开 Anaconda 提示符（在 Windows 中）或终端（在 macOS 或 Linux 中），然后输入以下命令（请使用你自己的目录路径）：
- en: '[PRE0]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This makes a *penguins* directory with a *notebooks* subdirectory. Next, create
    a conda environment named *penguins_env* under the project directory, activate
    it, and install the libraries we’ll use (substituting your own path where needed):'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个名为 *penguins* 的目录，并在其中创建一个 *notebooks* 子目录。接下来，在项目目录下创建一个名为 *penguins_env*
    的 conda 环境，激活它，并安装我们将要使用的库（根据需要替换自己的路径）：
- en: '[PRE1]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: You now have a conda environment for the project that contains the notebook,
    pandas, python, scikit-learn, and seaborn packages. Remember from [Chapter 2](ch02.xhtml)
    that this environment is isolated and can’t “see” other packages on your system,
    such as those in the *base* environment.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你已经为项目创建了一个 conda 环境，其中包含 notebook、pandas、python、scikit-learn 和 seaborn 包。请记得在
    [第 2 章](ch02.xhtml) 中提到，这个环境是隔离的，不能“看到”系统中其他的包，例如 *base* 环境中的包。
- en: At this point, your *penguins_env* should be active, and your project directory
    structure should look like [Figure 20-3](ch20.xhtml#ch020fig3). We’ll be loading
    the dataset straight from seaborn, so there’s no need for a *data* folder.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，你的 *penguins_env* 应该已经激活，项目目录结构应该如 [图 20-3](ch20.xhtml#ch020fig3) 所示。我们将直接从
    seaborn 加载数据集，因此无需创建 *data* 文件夹。
- en: '![Image](../images/20fig03.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig03.jpg)'
- en: '*Figure 20-3: Directory structure for the penguins project*'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-3：penguins 项目的目录结构*'
- en: 'To create a notebook for the project, first navigate to the *notebooks* folder
    using Anaconda Prompt or the terminal:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 要为项目创建一个 notebook，首先使用 Anaconda 提示符或终端导航到 *notebooks* 文件夹：
- en: '[PRE2]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'To launch Notebook, enter the following:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 要启动 Notebook，输入以下命令：
- en: '[PRE3]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: You should now see the Jupyter dashboard in your browser. Click the **New**
    button and choose **Python[conda env:penguins_env]** to create a new notebook.
    A new notebook should appear in your browser. Click **Untitled**, name it *penguins_project*,
    and then click the **Save** button. You’re ready to go!
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你应该在浏览器中看到 Jupyter 仪表板。点击 **New** 按钮，选择 **Python[conda env:penguins_env]**
    来创建一个新的 notebook。一个新的 notebook 应该会在浏览器中出现。点击 **Untitled**，将其命名为 *penguins_project*，然后点击
    **Save** 按钮。你准备好了！
- en: '**NOTE**'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*If you want to open the notebook in the future using Anaconda Navigator, launch
    Navigator, use the Environments tab to activate penguins_env, and then click the
    Launch button on the Jupyter Notebook tile. This will open the dashboard, where
    you can navigate to the notebook folder and launch penguins_project.ipynb. If
    you want to use Notebook in JupyterLab, see the instructions in [Chapter 6](ch06.xhtml)
    for installing JupyterLab and launching Notebook.*'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你以后想使用 Anaconda Navigator 打开 notebook，请启动 Navigator，使用 Environments 标签激活
    penguins_env，然后点击 Jupyter Notebook 磁贴上的 Launch 按钮。这将打开仪表板，你可以导航到 notebook 文件夹并启动
    penguins_project.ipynb。如果你想在 JupyterLab 中使用 Notebook，请参阅 [第 6 章](ch06.xhtml) 中的
    JupyterLab 安装和启动 Notebook 的说明。*'
- en: '***Importing Packages and Setting Up the Display***'
  id: totrans-78
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***导入包和设置显示***'
- en: 'In the first notebook cell, import Matplotlib, seaborn, and pandas. Enter the
    following code and execute it using SHIFT-ENTER, which automatically moves you
    to a new blank cell:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一个 notebook 单元格中，导入 Matplotlib、seaborn 和 pandas。输入以下代码并使用 SHIFT-ENTER 执行，它会自动跳转到一个新的空白单元格：
- en: '[PRE4]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**NOTE**'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*Normally, we would perform all the imports here, but for the sake of the narrative,
    we’ll import the scikit-learn components later, so we can discuss them just before
    applying them.*'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '*通常，我们会在这里执行所有导入操作，但为了叙述的方便，我们将在稍后导入 scikit-learn 组件，这样我们可以在应用它们之前讨论这些组件。*'
- en: By default, Notebook displays only one output per cell. The `%config` magic
    command overrides this, allowing us to see multiple outputs, such as a data table
    plus a bar chart, in a single output cell.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Notebook 每个单元格只显示一个输出。使用 `%config` 魔法命令可以覆盖此设置，使我们能够在一个单元格中看到多个输出，例如数据表和条形图。
- en: The default seaborn color palette is undeniably beautiful (see *[http://seaborn.pydata.org/tutorial/function_overview.html](http://seaborn.pydata.org/tutorial/function_overview.html)*),
    but it loses its charm somewhat in a black-and-white book. As a compromise, we’ll
    use the `whitegrid` stylesheet and reset the palette to black, red, and gray,
    one for each of the three penguin species in the dataset.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: seaborn 默认的颜色调色板无疑是美丽的（见 *[http://seaborn.pydata.org/tutorial/function_overview.html](http://seaborn.pydata.org/tutorial/function_overview.html)*），但在黑白书籍中，它的魅力略有失色。作为折中，我们将使用
    `whitegrid` 样式表，并将调色板重置为黑色、红色和灰色，每种颜色代表数据集中的三种企鹅物种。
- en: '***Loading the Dataset***'
  id: totrans-85
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***加载数据集***'
- en: Seaborn comes with a few practice datasets that are automatically downloaded
    during installation. These are all comma-separated values (*.csv*) files stored
    in a repository at *[https://github.com/mwaskom/seaborn-data/](https://github.com/mwaskom/seaborn-data/)*.
    If you ever need to get the dataset names, you can retrieve them by running `sns.get_dataset_names()`
    in a notebook or console (after importing seaborn, of course).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: seaborn 附带了一些练习数据集，这些数据集在安装时会自动下载。这些数据集都是逗号分隔值（*.csv*）文件，存储在 *[https://github.com/mwaskom/seaborn-data/](https://github.com/mwaskom/seaborn-data/)*
    仓库中。如果你需要获取数据集名称，可以通过在笔记本或控制台中运行 `sns.get_dataset_names()` 来检索（当然，前提是先导入 seaborn）。
- en: As a data analysis tool, pandas can read and write data stored in many types
    of media, such as files and databases ([Table 20-4](ch20.xhtml#ch020tab4)). Example
    syntax is `df = pd.read_excel('`filename.xlsx`')` and `df.to_excel('`filename.xlsx`'),`
    where `df` stands for *DataFrame*. For more options, visit *[https://pandas.pydata.org/docs/reference/io.html](https://pandas.pydata.org/docs/reference/io.html)*.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据分析工具，pandas 可以读取和写入存储在多种介质中的数据，如文件和数据库（见[表 20-4](ch20.xhtml#ch020tab4)）。示例语法为
    `df = pd.read_excel('`filename.xlsx`')` 和 `df.to_excel('`filename.xlsx`')`，其中
    `df` 代表 *DataFrame*。欲了解更多选项，请访问 *[https://pandas.pydata.org/docs/reference/io.html](https://pandas.pydata.org/docs/reference/io.html)*。
- en: In addition to the methods in [Table 20-4](ch20.xhtml#ch020tab4), the `read_table()`
    method reads tabular data, such as text *(.txt*) files, in which the values are
    separated by spaces or tabs. Python can generally detect the separator in use,
    but you can also pass it as an argument, for example, `sep='\t'` for a tab.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 除了[表 20-4](ch20.xhtml#ch020tab4)中的方法外，`read_table()`方法可以读取表格数据，例如文本 *(.txt*)
    文件，其中值由空格或制表符分隔。Python 通常能自动检测分隔符，但你也可以将分隔符作为参数传入，例如，`sep='\t'`表示制表符。
- en: '**Table 20-4:** Useful pandas I/O Methods'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**表 20-4：** 有用的 pandas I/O 方法'
- en: '| **Input (Reader)** | **Output (Writer)** |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| **输入（读取器）** | **输出（写入器）** |'
- en: '| --- | --- |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `read_csv()` | `to_csv()` |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| `read_csv()` | `to_csv()` |'
- en: '| `read_excel()` | `to_excel()` |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| `read_excel()` | `to_excel()` |'
- en: '| `read_hdf()` | `to_hdf()` |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| `read_hdf()` | `to_hdf()` |'
- en: '| `read_sql()` | `to_sql()` |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| `read_sql()` | `to_sql()` |'
- en: '| `read_json()` | `to_json()` |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| `read_json()` | `to_json()` |'
- en: '| `read_html()` | `to_html()` |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| `read_html()` | `to_html()` |'
- en: '| `read_stata()` | `to_stata()` |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| `read_stata()` | `to_stata()` |'
- en: '| `read_clipboard()` | `to_clipboard()` |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| `read_clipboard()` | `to_clipboard()` |'
- en: '| `read_pickle()` | `to_pickle()` |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| `read_pickle()` | `to_pickle()` |'
- en: Besides loading external sources, you can create a DataFrame from many different
    types of input. These include 2D `ndarray`s, lists of lists or tuples, list of
    dictionaries or series, an existing DataFrame, and more.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 除了加载外部数据源，你还可以从多种不同类型的输入中创建 DataFrame。这些包括 2D `ndarray`、列表的列表或元组、字典或系列的列表、现有的
    DataFrame 等。
- en: 'In spite of all these choices, we’ll use seaborn’s `load_dataset()` method
    to load the penguins dataset. This specialized method reads a CSV-format dataset
    from the seaborn repository and returns a pandas DataFrame object. Enter the following
    in the new cell and press SHIFT-ENTER:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有这么多选择，我们将使用 seaborn 的`load_dataset()`方法来加载企鹅数据集。这个专用方法从 seaborn 仓库中读取一个 CSV
    格式的数据集，并返回一个 pandas DataFrame 对象。在新的单元格中输入以下内容并按 SHIFT-ENTER：
- en: '[PRE5]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**NOTE**'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*In this notebook, I’m using simple comments, such as # Load penguins dataset,
    as cell headers. To make proper headers, you can add a Markdown cell before each
    code cell, as described in [Chapter 5](ch05.xhtml).*'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '*在本笔记本中，我使用了简单的注释，例如 # 加载企鹅数据集，作为单元格标题。为了制作合适的标题，你可以在每个代码单元格之前添加一个 Markdown
    单元格，如[第 5 章](ch05.xhtml)中所述。*'
- en: In the previous code, we assigned the DataFrame to a variable named `df`. This
    is handy, as the name reflects the datatype. There’s no reason why you couldn’t
    use another name, however, such as `penguins_df`.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们将 DataFrame 分配给名为 `df` 的变量。这是方便的，因为这个名称反映了数据类型。然而，你也可以使用其他名称，比如 `penguins_df`。
- en: '***Displaying the DataFrame and Renaming Columns***'
  id: totrans-107
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***显示 DataFrame 并重命名列***'
- en: 'The first thing you’ll want to do after loading the data is look at it. For
    larger datasets such as penguins, pandas will show you part of the top and part
    of the bottom of a DataFrame by default. To see an example, enter the following,
    and then press CTRL-ENTER to execute the cell without leaving it:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 加载数据后，首先你需要查看数据。对于像企鹅这样的较大数据集，pandas 默认会显示 DataFrame 的部分顶部和部分底部。要查看示例，输入以下内容，然后按
    CTRL-ENTER 执行单元格而不离开：
- en: '[PRE6]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'To see the entire DataFrame in a scrollable output cell, place this command
    at the top of the cell and rerun it: `pd.set_option(''display.max_rows'', None)`.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 要在可滚动的输出单元格中查看整个 DataFrame，将此命令放在单元格顶部并重新运行：`pd.set_option('display.max_rows',
    None)`。
- en: Calling the DataFrame displays all the columns along with the first five rows
    and last five rows ([Figure 20-4](ch20.xhtml#ch020fig4)). When possible, column
    names should be descriptive and short. However, this isn’t always an option, so
    let’s practice changing a column header.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 调用 DataFrame 会显示所有列及前五行和后五行数据（[图 20-4](ch20.xhtml#ch020fig4)）。如果可能，列名应该简洁且具有描述性。然而，这并非总是可行的，因此我们来练习更改列标题。
- en: '![Image](../images/20fig04.jpg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig04.jpg)'
- en: '*Figure 20-4: DataFrame head and tail display*'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-4：DataFrame 头部和尾部显示*'
- en: In the same cell, add the following code to rename the `sex` header to `gender`.
    The `inplace` argument tells pandas to alter the current DataFrame rather than
    return a copy. Press CTRL-SHIFT to execute the code and move to a new cell.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在同一个单元格中，添加以下代码以将 `sex` 列标题重命名为 `gender`。`inplace` 参数告诉 pandas 更改当前的 DataFrame，而不是返回一个副本。按
    CTRL-SHIFT 执行代码并跳转到新单元格。
- en: '[PRE7]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The `head()` method displays the first five rows in a DataFrame, as shown in
    [Figure 20-5](ch20.xhtml#ch020fig5). To see more, just pass it the number of rows
    you want to see as an argument.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '`head()` 方法显示 DataFrame 中的前五行，如[图 20-5](ch20.xhtml#ch020fig5)所示。要查看更多行，只需将你想查看的行数作为参数传递给它。'
- en: '![Image](../images/20fig05.jpg)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig05.jpg)'
- en: '*Figure 20-5: The head of the DataFrame after changing the sex column header
    to gender*'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-5：更改 sex 列标题为 gender 后的 DataFrame 头部*'
- en: 'In [Figure 20-4](ch20.xhtml#ch020fig4) the number of rows and columns is included
    at the bottom of the output. You might immediately notice an issue: there are
    344 rows, but earlier, I stated that the dataset has 342 observations. The discrepancy
    could be due to one of two common dataset problems: duplicate or missing values.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图 20-4](ch20.xhtml#ch020fig4)中，输出底部包含了行数和列数。你可能会立即注意到一个问题：有344行数据，但之前我提到数据集有342个观察值。这一差异可能是由两个常见的数据集问题引起的：重复或缺失值。
- en: '***Checking for Duplicates***'
  id: totrans-120
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***检查重复数据***'
- en: It’s not uncommon for data rows to become duplicated by accident. This can happen
    during the initial creation of a dataset, in later edits, or during data transfers
    and transformations. You should remove this redundant data before you begin an
    analysis because it takes up memory, slows processing speeds, and distorts statistics
    due to the overweighting of the duplicate values.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 数据行意外重复并不罕见。这可能发生在数据集初次创建时，之后的编辑中，或在数据传输和转换过程中。在开始分析之前，你应该删除这些冗余数据，因为它占用了内存，降低了处理速度，并由于重复值的过度权重而扭曲统计数据。
- en: 'Fortunately, pandas comes with the `duplicated()` method for finding duplicate
    rows. In the new cell, enter the following and then press CTRL-ENTER:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，pandas 提供了 `duplicated()` 方法来查找重复的行。在新单元格中输入以下内容，然后按 CTRL-ENTER 执行：
- en: '[PRE8]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'You should get the following output, as there are no duplicate rows:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该会得到以下输出，因为没有重复行：
- en: '[PRE9]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Had there been any duplicates in the dataset, we could have removed them using
    the `drop_duplicates()` method, like so:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据集中存在重复项，我们可以使用 `drop_duplicates()` 方法将其移除，方法如下：
- en: '[PRE10]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'You can also look across specific columns for duplicate values. At the bottom
    of the current cell, enter the following and execute it by pressing SHIFT-ENTER:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以查看特定列中的重复值。在当前单元格底部输入以下内容，并通过按 SHIFT-ENTER 执行：
- en: '[PRE11]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Note that the inner square brackets define a Python list with column names,
    whereas the outer brackets represent “selection brackets” used to select data
    from a pandas DataFrame. We specified four of the seven columns, producing the
    output in [Figure 20-6](ch20.xhtml#ch020fig6).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，内部的方括号定义了一个包含列名的 Python 列表，而外部的方括号表示“选择括号”，用于从 pandas DataFrame 中选择数据。我们指定了七列中的四列，产生了[图
    20-6](ch20.xhtml#ch020fig6)中的输出。
- en: '![Image](../images/20fig06.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig06.jpg)'
- en: '*Figure 20-6: Row with duplicate values across the four columns with the float
    data type*'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-6：四列浮动数据类型中具有重复值的行*'
- en: As you’ll see in a moment, row 339 is a duplicate of row 3 (for the four columns
    specified). But even though there are duplicate values here, they’re not the kind
    that we need to treat as duplicates. Instead, they represent *missing values*,
    which we’ll cover in the next section.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你马上就会看到的，第339行是第3行的重复（针对四个指定的列）。但是，尽管这里有重复值，它们并不是我们需要当作重复数据来处理的类型。相反，它们表示*缺失值*，我们将在下一节讨论这个问题。
- en: '***Handling Missing Values***'
  id: totrans-134
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***处理缺失值***'
- en: The duplicate values in [Figure 20-6](ch20.xhtml#ch020fig6) are represented
    by the *Not a Number* (`NaN`) value. This is a special floating-point value recognized
    by all systems that use the standard IEEE floating-point representation. For computational
    speed and convenience, it serves as the default missing value marker for both
    NumPy and pandas. `NaN` and Python’s built-in `None` value are essentially interchangeable.
    By default, these null values are not included in computations.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '[图20-6](ch20.xhtml#ch020fig6)中的重复值由*非数字*（`NaN`）表示。这是一个特殊的浮点值，所有使用IEEE标准浮点表示法的系统都能识别它。为了计算速度和便捷性，它作为NumPy和pandas的默认缺失值标记。`NaN`和Python的内建`None`值基本上是可以互换的。默认情况下，这些空值不会参与计算。'
- en: '**Finding Missing Values**'
  id: totrans-136
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**查找缺失值**'
- en: 'Missing data values reduce statistical power and can cause bias when estimating
    parameters and making predictions. To find the missing values in the penguins
    DataFrame, enter the following in a new cell and then press SHIFT-RETURN:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失数据值会减少统计效能，并且在估算参数和进行预测时可能引入偏差。要查找企鹅数据框中的缺失值，在一个新单元格中输入以下内容，然后按SHIFT-RETURN：
- en: '[PRE12]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The first method sums the missing values and displays the results as a table
    ([Figure 20-7](ch20.xhtml#ch020fig7)). The penguins dataset is missing 11 gender
    calls and a total of 8 morphological measurements.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个方法将缺失值求和并以表格形式显示结果（[图20-7](ch20.xhtml#ch020fig7)）。企鹅数据集缺失了11个性别标注和总计8个形态测量值。
- en: '![Image](../images/20fig07.jpg)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig07.jpg)'
- en: '*Figure 20-7: The output of df.isnull().sum()*'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '*图20-7：df.isnull().sum()的输出*'
- en: The second call indexes the DataFrame where a value in *any* column is missing
    (as opposed to *all*). Remember, pandas is built on NumPy, so axis 1 refers to
    columns and axis 0 refers to rows. You should get the result depicted in [Figure
    20-8](ch20.xhtml#ch020fig8).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 第二次调用会索引DataFrame，其中*任何*列的值缺失（而不是*所有*列）。记住，pandas是基于NumPy构建的，因此轴1指的是列，轴0指的是行。你应该得到[图20-8](ch20.xhtml#ch020fig8)中所示的结果。
- en: '![Image](../images/20fig08.jpg)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig08.jpg)'
- en: '*Figure 20-8: All the DataFrame rows containing missing data*'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '*图20-8：所有包含缺失数据的DataFrame行*'
- en: '**Filling and Removing Missing Values**'
  id: totrans-145
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**填充和删除缺失值**'
- en: Missing values must be addressed before you try to conduct analyses or build
    models from a dataset. Although ignoring the issue is a possibility, it’s much
    better to either fill in the missing values or remove (drop) them completely.
    Methods for doing this are listed in [Table 20-5](ch20.xhtml#ch020tab5).
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在你尝试从数据集进行分析或构建模型之前，必须处理缺失值。虽然忽略这个问题是一个选择，但最好是填补缺失值或完全删除它们。处理方法列出了在[表20-5](ch20.xhtml#ch020tab5)中。
- en: '**Table 20-5:** Useful Methods for Handling Missing Data'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '**表20-5：** 处理缺失数据的有用方法'
- en: '| **Method** | **Description** |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| **方法** | **描述** |'
- en: '| --- | --- |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `dropna` | Depending on arguments, remove row or column that contains missing
    data based on whether any or all values are null. |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| `dropna` | 根据参数，移除包含缺失数据的行或列，依据是任何值或所有值是否为空。 |'
- en: '| `fillna` | Fill in missing value with a constant or an interpolation method.
    Arguments include the `ffill` and `bfill` methods. |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| `fillna` | 用常数值或插值方法填充缺失值。参数包括`ffill`和`bfill`方法。 |'
- en: '| `ffill` | “Forward fill” by propagating the last valid observation forward.
    |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| `ffill` | “向前填充”通过将最后一个有效观察值向前传播。 |'
- en: '| `bfill` | “Back fill” by replacing missing values with values from the next
    row or column, as specified. |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| `bfill` | “向后填充”通过用下一个行或列中的值来替代缺失值，如所指定的那样。 |'
- en: '| `isnull` | Return Boolean indicating missing/NA values. |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| `isnull` | 返回布尔值，指示缺失/NA值。 |'
- en: '| `notnull` | Negate `isnull`. |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| `notnull` | 否定`isnull`。 |'
- en: 'Options for filling in the missing values with `fillna()` include replacing
    them with the mean, median, or most frequent values in the dataset so that the
    overall statistics aren’t skewed. For example, to use the mean value of a column,
    you would use this syntax (don’t add this to your project code):'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`fillna()`填补缺失值的选项包括用数据集中的均值、中位数或最频繁值来替换它们，从而避免整体统计数据的偏差。例如，要使用列的均值，你可以使用以下语法（不要将其添加到你的项目代码中）：
- en: '[PRE13]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '**NOTE**'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*The pandas library tries to mimic the R programming language, and the na in
    the fillna() method stands for the NA (not available) marker used for missing
    data in R.*'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '*pandas库试图模仿R编程语言，而fillna()方法中的na代表R中用于表示缺失数据的NA（不可用）标记。*'
- en: Filling in the missing data is important when a dataset is small and you need
    to take into account every observation. And if only a single column among many
    is missing a value, you might not want to “throw away” all the other useful data
    in the row.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 填充缺失数据对于数据集较小且需要考虑每一个观测值的情况非常重要。如果在众多列中只有一列缺少值，你可能不希望“丢弃”行中其他所有有用的数据。
- en: 'Because we have a robust dataset and can’t easily impute and replace missing
    gender data, we’ll *drop* the rows with missing data. In the new cell, enter the
    following and then press SHIFT-ENTER:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们拥有一个强大的数据集，且无法轻易插补和替换缺失的性别数据，因此我们将*删除*包含缺失数据的行。在新单元格中输入以下内容，然后按SHIFT-ENTER：
- en: '[PRE14]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Using an assignment statement when calling `dropna()` causes the current DataFrame
    (`df`) to be overwritten. This allows the DataFrame to evolve over time, but be
    aware that to erase changes and restore the DataFrame to its previous state, you’ll
    need to run all the cells above the current cell. Passing a `how` argument of
    `any` to `dropna()` means that any row with at least one missing value will be
    deleted.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 使用赋值语句调用`dropna()`会导致当前的DataFrame（`df`）被覆盖。这使得DataFrame可以随着时间变化，但需要注意的是，要撤销更改并恢复DataFrame的先前状态，你需要运行当前单元格上方的所有单元格。将`how`参数设置为`any`传递给`dropna()`意味着任何包含至少一个缺失值的行都会被删除。
- en: To check the results, rerun the `isnull()` method. You should get the output
    in [Figure 20-9](ch20.xhtml#ch020fig9).
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查结果，重新运行`isnull()`方法。你应该会得到[图 20-9](ch20.xhtml#ch020fig9)中的输出。
- en: '![Image](../images/20fig09.jpg)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig09.jpg)'
- en: '*Figure 20-9: A summary of null values after dropping nulls*'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-9：删除空值后空值的总结*'
- en: The DataFrame no longer includes missing values.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrame中不再包含缺失值。
- en: '**Reindexing**'
  id: totrans-168
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**重新索引**'
- en: '*Reindexing* refers to the process of making data conform to a given set of
    labels along a particular axis. Missing value markers will be automatically inserted
    in label locations where no data for the label exists.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '*重新索引*是指使数据符合特定轴上给定标签集的过程。在标签位置上没有数据时，缺失值标记会自动插入。'
- en: 'When we dropped the rows with null values in the previous section, we also
    deleted their corresponding indexes. To see the result, run the following code
    in the new cell and press SHIFT-ENTER:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在上一部分删除了带有空值的行时，我们也删除了它们相应的索引。要查看结果，请在新单元格中运行以下代码并按SHIFT-ENTER：
- en: '[PRE15]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: As you can see in [Figure 20-10](ch20.xhtml#ch020fig10), there is a gap in the
    DataFrame index (leftmost column) where row 3, which contained a null value, was
    dropped.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 如[图 20-10](ch20.xhtml#ch020fig10)所示，DataFrame的索引（最左侧的列）中存在一个空隙，这是因为包含空值的第3行被删除了。
- en: '![Image](../images/20fig10.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig10.jpg)'
- en: '*Figure 20-10: Dropping rows results in missing DataFrame indexes.*'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-10：删除行导致缺失的DataFrame索引。*'
- en: To restore the indexes, run the following and then execute the cell using SHIFT-ENTER.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 若要恢复索引，请运行以下代码并使用SHIFT-ENTER执行该单元格。
- en: '[PRE16]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'In the `reset_index()` method, `drop=True` signals that the old index isn’t
    preserved as a new column in the DataFrame, because there’s no need to keep that
    information. The `inplace=True` argument means that the method adjusts the current
    DataFrame rather than returning a copy. As an alternative, you could simply reassign
    the DataFrame, like so:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在`reset_index()`方法中，`drop=True`表示旧的索引不会作为新列保留在DataFrame中，因为不需要保留该信息。`inplace=True`参数表示该方法会直接修改当前的DataFrame，而不是返回一个副本。作为替代，你也可以简单地重新分配DataFrame，如下所示：
- en: '[PRE17]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Calling the `head()` method shows that the indexes are now consecutively ordered
    ([Figure 20-11](ch20.xhtml#ch020fig11)).
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 调用`head()`方法显示索引现在按顺序排列（[图 20-11](ch20.xhtml#ch020fig11)）。
- en: '![Image](../images/20fig11.jpg)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig11.jpg)'
- en: '*Figure 20-11: The DataFrame head after reindexing*'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-11：重新索引后的DataFrame头部*'
- en: Pandas includes several other reindexing functions, such as `reindex()` and
    `reindex_like()`. You can find these, and other DataFrame functions, at *[https://pandas.pydata.org/pandas-docs/stable/reference/frame.html](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html)*.
    For more on missing values, see *[https://pandas.pydata.org/docs/user_guide/missing_data.html](https://pandas.pydata.org/docs/user_guide/missing_data.html)*.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas 包含了其他几个重新索引的函数，如 `reindex()` 和 `reindex_like()`。你可以在 *[https://pandas.pydata.org/pandas-docs/stable/reference/frame.html](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html)*
    找到这些函数和其他 DataFrame 函数。关于缺失值的更多内容，请参见 *[https://pandas.pydata.org/docs/user_guide/missing_data.html](https://pandas.pydata.org/docs/user_guide/missing_data.html)*。
- en: '***Exploring the Dataset***'
  id: totrans-183
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***探索数据集***'
- en: At this point, you’ve cleaned the data by checking for duplicates, removing
    missing values, and reindexing the DataFrame. Of course, there might still be
    problems, such as incorrect values (a penguin body mass of one million grams,
    for example). Catching and correcting these requires an exploration of the dataset,
    and pandas and seaborn provide several methods to aid you in this process. These
    same methods will help you to understand the dataset so that you can formulate
    a plan for addressing the project goal.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 到这一步，你已经通过检查重复项、移除缺失值和重新索引 DataFrame 来清理了数据。当然，仍然可能存在问题，比如错误的值（例如，企鹅的体重为一百万克）。捕捉并纠正这些问题需要对数据集进行探索，pandas
    和 seaborn 提供了多种方法来帮助你完成这一过程。这些方法还将帮助你理解数据集，从而为解决项目目标制定计划。
- en: '**Describing the DataFrame**'
  id: totrans-185
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**描述 DataFrame**'
- en: 'Let’s explore the DataFrame using a combination of tables and graphs. To begin,
    we’ll look at the data types in play and overall statistics. In a new cell, enter
    the following and then press SHIFT-ENTER:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过表格和图表的结合来探索 DataFrame。首先，我们将查看使用的数据类型和总体统计信息。在一个新的单元格中，输入以下内容并按下 SHIFT-ENTER：
- en: '[PRE18]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This produces the output shown in [Figure 20-12](ch20.xhtml#ch020fig12).
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成如[图 20-12](ch20.xhtml#ch020fig12)所示的输出。
- en: '![Image](../images/20fig12.jpg)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig12.jpg)'
- en: '*Figure 20-12: Output of the dtypes() and describe() methods*'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-12：dtypes() 和 describe() 方法的输出*'
- en: The `describe()` method returns a quick-look statistical overview of the DataFrame.
    Passing it `all` produces a statistical summary of *all* the columns. If you omit
    the `include` argument, you’ll see only a summary of the *numeric* columns.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '`describe()` 方法返回 DataFrame 的快速统计概览。传入 `all` 会生成 *所有* 列的统计摘要。如果省略 `include`
    参数，则只会显示 *数值* 列的摘要。'
- en: The `NaN` values present in the table represent *not applicable* values rather
    than missing values. For example, you can’t take the mean of a categorical feature
    like `species`, so the result is presented as `NaN`.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 表中存在的 `NaN` 值表示 *不适用* 值，而不是缺失值。例如，你不能对一个像 `species` 这样的类别特征计算均值，因此结果显示为 `NaN`。
- en: The stats table doesn’t tell you if every value in the dataset is valid, but
    it does help bracket how good or bad things can be. If the minimum, maximum, and
    mean values appear to be reasonable, the dataset is probably reliable.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 统计表不会告诉你数据集中的每个值是否有效，但它有助于框定事情的好坏。如果最小值、最大值和均值看起来合理，那么数据集可能是可靠的。
- en: '**Counting Observations Using countplot**'
  id: totrans-194
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**使用 countplot 计数观察值**'
- en: Tables of data, although useful, can be dense and difficult to interpret. For
    example, is the data skewed toward male or female penguins? The information is
    there, but you must work to back it out.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 数据表虽然有用，但可能密集且难以解读。例如，数据是偏向雄性还是雌性企鹅？这些信息是存在的，但你需要努力去提取它。
- en: In these cases, it’s beneficial to create a visualization of the data. The seaborn
    library provides many statistical plot types for data exploration ([Table 20-6](ch20.xhtml#ch020tab6)).
    You can see examples of these in the seaborn gallery (*[https://seaborn.pydata.org/examples/index.html](https://seaborn.pydata.org/examples/index.html)*),
    and you can find a plotting tutorial at *[https://seaborn.pydata.org/tutorial.html](https://seaborn.pydata.org/tutorial.html)*.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些情况下，创建数据的可视化是有益的。seaborn 库提供了许多用于数据探索的统计图表类型（[表 20-6](ch20.xhtml#ch020tab6)）。你可以在
    seaborn 画廊中查看这些示例 (*[https://seaborn.pydata.org/examples/index.html](https://seaborn.pydata.org/examples/index.html)*)，并且可以在
    *[https://seaborn.pydata.org/tutorial.html](https://seaborn.pydata.org/tutorial.html)*
    找到绘图教程。
- en: '**Table 20-6:** Useful seaborn Plotting Methods'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '**表 20-6：有用的 seaborn 绘图方法**'
- en: '| **Method** | **Description** |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| **方法** | **描述** |'
- en: '| --- | --- |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `barplot()` | Categorical data presented with bars whose heights or lengths
    are proportional to the values that they represent. |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| `barplot()` | 通过条形图呈现类别数据，条形的高度或长度与所代表的值成比例。 |'
- en: '| `boxplot()` | Graphical representation of the locality, spread, and skewness
    groups of numerical data through their quartiles. |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| `boxplot()` | 通过四分位数表示数值数据的局部性、离散程度和偏度分组的图形表示。 |'
- en: '| `countplot()` | A visualization of the counts of observations in each categorical
    bin using bars. |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| `countplot()` | 使用条形图显示每个类别数据分箱中的观察计数的可视化。 |'
- en: '| `histplot()` | Series of bars used to bin and display continuous data in
    a categorical form. |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| `histplot()` | 用于将连续数据按类别形式分箱并显示的条形图序列。 |'
- en: '| `jointgrid()` | Grid for drawing a bivariate plot with marginal univariate
    plots. |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| `jointgrid()` | 用于绘制包含边际单变量图的双变量图的网格。 |'
- en: '| `jointplot()` | `jointgrid()` wrapper for drawing `jointgrid()` of two variables
    using canned bivariate and univariate graphs. |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| `jointplot()` | 用于绘制两个变量的`jointgrid()`图形的`jointgrid()`封装函数，使用标准的双变量和单变量图形。
    |'
- en: '| `lineplot()` | Graphical display of data along a number line where markers
    recorded above the responses indicate the number of occurrences. |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| `lineplot()` | 在数轴上显示数据的图形，其中标记位于响应值之上，表示出现次数。 |'
- en: '| `pairgrid()` | Subplot grid for plotting pairwise relationships in a dataset.
    |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| `pairgrid()` | 用于绘制数据集中成对关系的子图网格。 |'
- en: '| `pairplot()` | Easier-to-use wrapper for `pairgrid()`. |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| `pairplot()` | 更易于使用的`pairgrid()`封装函数。 |'
- en: '| `relplot()` | Function for visualizing statistical relationships using scatter
    plots and line plots |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| `relplot()` | 用于通过散点图和折线图可视化统计关系的函数。 |'
- en: '| `scatterplot()` | Graph that uses Cartesian coordinates to display values
    for two variables. Additional variables can be incorporated through marker coding
    (color/size/shape). |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| `scatterplot()` | 使用笛卡尔坐标显示两个变量值的图形。可以通过标记编码（颜色/大小/形状）加入其他变量。 |'
- en: '| `stripplot()` | A scatterplot for which one variable is categorical. |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| `stripplot()` | 一个类别变量的散点图。 |'
- en: '| `swarmplot()` | A stripplot with non-overlapping points. |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| `swarmplot()` | 一个没有重叠点的stripplot。 |'
- en: '| `violinplot()` | A combination of boxplot and kernel density estimate showing
    the distribution of quantitative data across several levels of one (or more) categorical
    variables. |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| `violinplot()` | 结合了箱线图和核密度估计，展示跨越一个或多个类别变量水平的定量数据分布。 |'
- en: 'Let’s look at an example in which we plot the number of penguins and their
    gender. In a new cell, enter the following and then press SHIFT-ENTER:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个示例，其中我们绘制企鹅的数量和性别。在新单元格中输入以下内容，然后按SHIFT-ENTER：
- en: '[PRE19]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: This produces the output in [Figure 20-13](ch20.xhtml#ch020fig13).
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 这将在[图 20-13](ch20.xhtml#ch020fig13)中生成输出结果。
- en: By visualizing the data, we can instantly see that the Chinstrap species is
    a bit underrepresented, and the division between genders is close to equal.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 通过可视化数据，我们可以立刻看到鹤顶企鹅物种的样本略显不足，而且性别之间的分布几乎是平衡的。
- en: '![Image](../images/20fig13.jpg)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig13.jpg)'
- en: '*Figure 20-13: Bar chart of penguin species and gender counts*'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-13：企鹅物种和性别数量的条形图*'
- en: 'What about the distribution of penguins *per island*? Are they one big happy
    family, or do some prefer one island over another? To check, in a new cell, enter
    the following code and then press SHIFT-ENTER:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 那么企鹅的*岛屿分布*是怎样的呢？它们是一个大家庭，还是有些更喜欢某个岛屿呢？为了检查这一点，在新单元格中输入以下代码，然后按SHIFT-ENTER：
- en: '[PRE20]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This code counts the penguins per island, presents the results in a bar chart,
    and colors the bars based on species ([Figure 20-14](ch20.xhtml#ch020fig14)).
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码统计了每个岛屿上的企鹅数量，将结果以条形图呈现，并根据物种为条形着色（参见[图 20-14](ch20.xhtml#ch020fig14)）。
- en: '![Image](../images/20fig14.jpg)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig14.jpg)'
- en: '*Figure 20-14: Bar chart of the number of penguins sampled per island, colored
    by species*'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-14：每个岛屿上采样的企鹅数量条形图，按物种着色*'
- en: Based on [Figure 20-14](ch20.xhtml#ch020fig14), we can see that the Adélie penguins
    live on all the islands, but the Chinstraps are found only on Dream Island, and
    the Gentoos only on Biscoe Island (see [Figure 20-1](ch20.xhtml#ch020fig1) for
    island locations). So, if you have measurements from Torgersen Island, you know
    you’re dealing with an Adélie. And the dimensional space is reduced for the other
    two islands, as you need to choose between only two species on both islands.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 基于[图 20-14](ch20.xhtml#ch020fig14)，我们可以看到，阿德利企鹅生活在所有岛屿上，但鹤顶企鹅仅分布在梦岛，而金图企鹅仅分布在比斯科岛（岛屿位置请参见[图
    20-1](ch20.xhtml#ch020fig1)）。所以，如果你从托尔格森岛获得测量数据，你就知道那是阿德利企鹅。而对于其他两个岛屿，由于你只能在这两个岛屿上选择两种物种，维度空间就被简化了。
- en: '**NOTE**'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*An assumption here is that each island was thoroughly sampled. We’re saying
    that if a penguin species is not present in the dataset for a particular island,
    that species doesn’t live on that island. You’d want to verify this assumption
    in a real study, as absence of evidence is not evidence of absence.*'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '*这里的假设是每个岛屿都已被充分采样。我们假设如果某个岛屿的数据集中没有某种企鹅物种，说明该物种不在该岛屿上栖息。你应该在实际研究中验证这一假设，因为缺乏证据并不等于证据缺失。*'
- en: Another way to count each species per island is to use the pandas `get_dummies()`
    method in combination with the `groupby()` method. The first method converts categorical
    variables to *dummy variables*, which are numeric variables used to represent
    categorical data. The second method is used to group large amounts of data and
    compute operations on these groups.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种按岛屿统计每种物种的方法是结合使用 pandas 的 `get_dummies()` 方法和 `groupby()` 方法。第一个方法将分类变量转换为
    *虚拟变量*，这些是用于表示分类数据的数值变量。第二个方法用于对大量数据进行分组并对这些组执行操作。
- en: 'In this case, we want to *sum* the penguin species per island, so we chain
    the methods and pass them the `species` column grouped by the `island` column,
    followed by the `sum()` method. In a new cell, enter the following code and then
    press SHIFT-ENTER:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们希望按岛屿 *汇总* 企鹅物种，因此我们将方法链式调用，并将按 `island` 列分组的 `species` 列传递给它，接着使用
    `sum()` 方法。在新的单元格中输入以下代码，然后按 SHIFT-ENTER：
- en: '[PRE21]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The call to `print()` lets you see the names of the new “dummy” columns (highlighted
    in bold):'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 调用 `print()` 可以让你看到新“虚拟”列的名称（以粗体显示）：
- en: '[PRE22]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The final line of code displays the new columns in the `count_df` DataFrame
    ([Figure 20-15](ch20.xhtml#ch020fig15)).
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的最后一行显示了 `count_df` 数据框中的新列（[图 20-15](ch20.xhtml#ch020fig15)）。
- en: '![Image](../images/20fig15.jpg)'
  id: totrans-234
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/20fig15.jpg)'
- en: '*Figure 20-15: The count_df DataFrame that sums columns per island per penguin
    species*'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-15：按岛屿和企鹅物种汇总列的 count_df 数据框*'
- en: An advantage of checking tabular data is that low values are just as apparent
    as high values. With a bar chart, very low values may be mistaken for 0, due to
    the shortness of the bars.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 检查表格数据的一个优势是，低值和高值同样显而易见。而在条形图中，低值可能会被误认为是 0，因为条形的高度较短。
- en: You can read more about the `get_dummies()` and `groupby()` methods at *[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html)*
    and *[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html)*,
    respectively.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 *[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html)*
    和 *[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html)*
    上阅读更多关于 `get_dummies()` 和 `groupby()` 方法的信息。
- en: '**Getting the Big Picture with pairplot**'
  id: totrans-238
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**通过 pairplot 获取整体图像**'
- en: Because visualizations are so effective for understanding data, seaborn provides
    the `pairplot()` method for plotting pairwise relationships in a dataset. This
    method creates a grid of axes where each variable shares the y-axis across a single
    row and the x-axis across a single column. This lets you quickly spot patterns
    in the data.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 由于可视化对于理解数据非常有效，seaborn 提供了 `pairplot()` 方法，用于绘制数据集中变量之间的成对关系。此方法创建一个坐标轴网格，其中每个变量在单独的一行共享
    y 轴，在单独的一列共享 x 轴。这样可以帮助你快速发现数据中的模式。
- en: 'To make a pairplot, in a new cell, enter the following code and then press
    SHIFT-ENTER:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建 pairplot，在新的单元格中输入以下代码，然后按 SHIFT-ENTER：
- en: '[PRE23]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The arguments here are the name of the DataFrame, the column used to color the
    plots, and the marker types. You can find a list of marker types at *[https://matplotlib.org/stable/api/markers_api.html](https://matplotlib.org/stable/api/markers_api.html)*.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的参数是数据框的名称、用于为图形着色的列和标记类型。你可以在 *[https://matplotlib.org/stable/api/markers_api.html](https://matplotlib.org/stable/api/markers_api.html)*
    上找到标记类型的列表。
- en: Because the dataset contains only four numeric columns, the pairplot ([Figure
    20-16](ch20.xhtml#ch020fig16)) is very accessible and easy to consume.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据集只有四列数值型数据，pairplot（[图 20-16](ch20.xhtml#ch020fig16)）非常直观且易于理解。
- en: '![Image](../images/20fig16.jpg)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/20fig16.jpg)'
- en: '*Figure 20-16: The pairplot for the penguins dataset*'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-16：企鹅数据集的 pairplot*'
- en: The pairplot makes it easy to see data distributions and relationships. For
    example, the scatterplots where the points cluster into separate groups are important
    because they indicate that classification strategies such as principal component
    analysis (PCA) and *k*-nearest neighbors should be able to distinguish one species
    from another. Scatterplots with linear relationships, like flipper length versus
    body mass, suggest that regression techniques could predict one of these features
    when the other is known.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: pairplot 使得查看数据分布和关系变得容易。例如，散点图中点聚集成不同的组是重要的，因为它们表明像主成分分析（PCA）和 *k* 最近邻等分类策略应该能够区分不同物种。具有线性关系的散点图，如鳍长与体重的关系，表明回归技术在已知其中一个特征时可以预测另一个特征。
- en: '**Digging into Details with scatterplot**'
  id: totrans-247
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**深入挖掘散点图的细节**'
- en: 'Despite being packed with information, even a pairplot can’t tell the whole
    story. For example, what role does gender play in determining the body mass and
    bill length of each species? To explore this, you’ll need more detailed plots.
    In a new cell, enter the following and press SHIFT-ENTER:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管包含了大量信息，即使是 pairplot 也不能讲述完整的故事。例如，性别在决定每个物种的体重和喙长中起什么作用？要探究这个问题，你需要更详细的图表。在一个新单元格中输入以下内容，然后按
    SHIFT-ENTER：
- en: '[PRE24]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: In the call to `scatterplot()`, the `hue`, `style`, and `size` arguments control
    marker color, shape, and size, respectively. The first two are based on `species`,
    and the latter on `gender`; thus, data points representing female penguins are
    sized differently than males of the same species. Calling `legend()` with the
    `bbox_to_anchor` argument prevents the legend from posting over the plot and obscuring
    some of the data. You should get the results in [Figure 20-17](ch20.xhtml#ch020fig17).
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `scatterplot()` 的调用中，`hue`、`style` 和 `size` 参数分别控制标记的颜色、形状和大小。前两个基于 `species`，后者基于
    `gender`；因此，表示雌性企鹅的数据点在同一物种中与雄性企鹅的大小不同。调用 `legend()` 并使用 `bbox_to_anchor` 参数可以防止图例覆盖图表，遮挡一些数据。你应该会在
    [图 20-17](ch20.xhtml#ch020fig17) 中看到结果。
- en: '![Image](../images/20fig17.jpg)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig17.jpg)'
- en: '*Figure 20-17: A scatterplot of bill length versus body mass, colored by species
    and sized by gender*'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-17：鳍长与体重的散点图，按物种着色，按性别调整大小*'
- en: This plot shows that the female of each species tends to be smaller, with shorter
    bills and lower body mass than the males. Bill length also appears to be more
    strongly correlated with body mass for the Adélie and Gentoo species, regardless
    of gender.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 这个图表显示，每个物种的雌性通常比雄性更小，喙较短，体重较轻。喙长和体重之间的相关性对于阿德利企鹅和金图企鹅物种而言似乎更强，无论性别如何。
- en: You can learn more about the scatterplot at *[https://seaborn.pydata.org/generated/seaborn.scatterplot.html](https://seaborn.pydata.org/generated/seaborn.scatterplot.html)*.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过 *[https://seaborn.pydata.org/generated/seaborn.scatterplot.html](https://seaborn.pydata.org/generated/seaborn.scatterplot.html)*
    学习更多关于散点图的内容。
- en: '**Investigating Categorical Scatter Using boxplot and stripplot**'
  id: totrans-255
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**使用箱线图和条形图调查类别散点图**'
- en: 'We can explore the gender relationships further using different types of plots
    such as *box plots* and *strip plots*. To make a box plot, in a new cell, enter
    the following code and then press SHIFT-ENTER:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用不同类型的图表，如 *箱线图* 和 *条形图*，进一步探索性别关系。要创建一个箱线图，在新单元格中输入以下代码，然后按 SHIFT-ENTER：
- en: '[PRE25]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: This produces the plot in [Figure 20-18](ch20.xhtml#ch020fig18).
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 这会生成图 [图 20-18](ch20.xhtml#ch020fig18)。
- en: '![Image](../images/20fig18.jpg)'
  id: totrans-259
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig18.jpg)'
- en: '*Figure 20-18: A box-and-whisker plot of penguin body mass by species by gender*'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-18：按物种和性别划分的企鹅体重箱线图*'
- en: Box plots provide insight on the symmetry, grouping, and skewness of data. Each
    box encompasses the first through third quartiles of the data distribution, with
    the vertical line within the box marking the median value. The “whiskers” extend
    to show the rest of the distribution, except for points that are considered “outliers,”
    which are represented by diamonds.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 箱线图提供了关于数据对称性、分组和偏斜度的洞察。每个箱体表示数据分布的第一到第三四分位数，箱内的垂直线表示中位数值。 “胡须”延伸至显示其余的分布，排除被视为“异常值”的点，这些异常值以菱形表示。
- en: Based on the box plot in [Figure 20-18](ch20.xhtml#ch020fig18), Adélie and Chinstrap
    penguins are similar in size and smaller than Gentoo penguins, and the females
    tend to be smaller for all species. There is overlap between the genders, however,
    meaning body mass alone cannot positively differentiate males from females.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 根据[图 20-18](ch20.xhtml#ch020fig18)中的箱型图，阿德利企鹅和帽带企鹅的体型相似，都比金图企鹅小，而且所有物种的雌性企鹅通常都比雄性小。然而，性别之间存在重叠，这意味着单靠体重不能明显区分雄性和雌性。
- en: 'The seaborn strip plot posts the actual data points rather than summarizing
    them, as in the box plot. Let’s examine bill length measurements in both species
    and genders. In a new cell, enter the following code and then press SHIFT-ENTER:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: seaborn 条形图会显示实际数据点，而不是像箱型图那样对数据进行总结。让我们来看看两种物种和性别的喙长测量值。在一个新的单元格中，输入以下代码，然后按
    SHIFT-ENTER：
- en: '[PRE26]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The `dodge` argument shifts points for each species to reduce overlap, making
    the plot easier to read ([Figure 20-19](ch20.xhtml#ch020fig19)).
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '`dodge` 参数会将每个物种的点进行偏移，从而减少重叠，使图表更易阅读（见[图 20-19](ch20.xhtml#ch020fig19)）。'
- en: '![Image](../images/20fig19.jpg)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/20fig19.jpg)'
- en: '*Figure 20-19: A strip plot of penguin bill length by species by gender*'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-19：按物种和性别分组的企鹅喙长条形图*'
- en: Based on the plot, we can see that the Adélie penguins have markedly shorter
    bills than the other two species. Gender differences are less distinct, though
    female penguins of all species tend to have shorter bills, on average.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 根据图表，我们可以看到，阿德利企鹅的喙比其他两种企鹅明显短。性别差异较小，尽管所有物种的雌性企鹅的喙通常较短，平均而言。
- en: '**Combining Views Using jointplot**'
  id: totrans-269
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**使用 jointplot 组合视图**'
- en: Another potentially characteristic feature of the penguins is the vertical thickness
    of the bill, referred to as its *depth*. You can see in [Figure 20-2](ch20.xhtml#ch020fig2)
    that Gentoos have narrow, pointed bills, whereas the other two species have more
    bulbous bills. Although there are numerous ways to compare these graphically,
    let’s try out a joint plot using a *kernel density estimation (KDE)*.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 企鹅的另一个可能的特征是喙的垂直厚度，称为其 *深度*。你可以在[图 20-2](ch20.xhtml#ch020fig2)中看到，金图企鹅的喙窄且尖，而其他两种物种的喙则更圆胖。尽管有许多方法可以通过图形进行比较，但我们将尝试使用
    *核密度估计（KDE）* 来绘制一个联合图。
- en: A KDE plot is a method for visualizing the distribution of observations in a
    dataset, much like a histogram. But whereas a histogram approximates the underlying
    probability density of the data by counting observations in discrete bins, a KDE
    plot smooths the observations using a Gaussian kernel, producing a continuous
    density estimate. This results in a less cluttered and more interpretable plot
    when drawing multiple distributions. The `joinplot()` method lets you plot two
    variables using bivariate and univariate KDE graphs.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: KDE 图是一种可视化数据集观察分布的方法，类似于直方图。但与直方图通过计数离散区间内的观察值来逼近数据的概率密度不同，KDE 图通过使用高斯核平滑观察值，从而产生连续的密度估计。这使得在绘制多个分布时，图表更简洁、更易于理解。`joinplot()`
    方法允许你使用双变量和单变量的 KDE 图来绘制两个变量。
- en: 'In a new cell, enter the following and then press SHIFT-ENTER:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个新的单元格中，输入以下内容，然后按 SHIFT-ENTER：
- en: '[PRE27]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: This produces the chart in [Figure 20-20](ch20.xhtml#ch020fig20).
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成[图 20-20](ch20.xhtml#ch020fig20)中的图表。
- en: '![Image](../images/20fig20.jpg)'
  id: totrans-275
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/20fig20.jpg)'
- en: '*Figure 20-20: A joint plot of bill depth versus bill length by species*'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-20：按物种分组的喙深与喙长的联合图*'
- en: From the Gaussian curves along the edges of the joint plot, it’s clear that
    the Adélie is distinguished by its shorter bill length, and the Gentoo by its
    shallower bill depth.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 从联合图中沿边缘的高斯曲线可以看出，阿德利企鹅因其较短的喙长而有所区别，而金图企鹅则因其较浅的喙深而有所区别。
- en: You can customize joint plots in many ways. To see some examples, check out
    the documentation at *[http://seaborn.pydata.org/generated/seaborn.jointplot.html](http://seaborn.pydata.org/generated/seaborn.jointplot.html)*.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过多种方式自定义 jointplot。要查看一些示例，请查看文档中的 *[http://seaborn.pydata.org/generated/seaborn.jointplot.html](http://seaborn.pydata.org/generated/seaborn.jointplot.html)*。
- en: '**Visualizing Multiple Dimensions Using radviz**'
  id: totrans-279
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**使用 radviz 可视化多个维度**'
- en: The pandas library comes with its own plotting capability built on Matplotlib.
    This includes the `radviz()` (radial visualization) method for plotting multidimensional
    datasets in a 2D format ([Figure 20-21](ch20.xhtml#ch020fig21)).
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: pandas 库自带基于 Matplotlib 的绘图功能。这包括用于以二维格式绘制多维数据集的 `radviz()`（径向可视化）方法（见[图 20-21](ch20.xhtml#ch020fig21)）。
- en: '![Image](../images/20fig21.jpg)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/20fig21.jpg)'
- en: '*Figure 20-21: An example radviz plot for an automotive dataset*'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-21：汽车数据集的一个示例 Radviz 图*'
- en: In a radial visualization, the dimensions in a DataFrame, such as a penguin’s
    body mass or bill length, are evenly spaced around the circumference of a circle.
    Data in these numerical columns are normalized to values between 0 and 1 so that
    all dimensions have equal weights. These are then projected into the circular
    2D space as if imaginary springs anchor them to the column labels along the circumference.
    A point is plotted where the sum of the “spring” forces acting on it equals zero.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 在径向可视化中，DataFrame 中的维度，如企鹅的体重或喙长，会均匀地分布在圆周上。这些数值型列中的数据会被归一化到 0 到 1 之间，以确保所有维度的权重相等。然后，这些数据会投影到圆形的二维空间中，就像假想的弹簧将它们固定在圆周上的列标签处。一个点被绘制在“弹簧”力作用的合力为零的地方。
- en: Radial visualizations are intuitive by nature. Points with similar dimension
    values will plot near the center, as will points with similar values whose dimensions
    are opposite each other on the circle. Points with dimension values greater than
    others will be “pulled” toward that side of the circle. The penguins dataset has
    only four dimensions, but the `radviz()` method can handle many more.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 径向可视化本质上是直观的。具有相似维度值的点会聚集在圆心附近，维度值相似且位于圆上相对位置的点也会聚集在一起。维度值较大的点会被“拉”向圆的这一侧。企鹅数据集只有四个维度，但
    `radviz()` 方法可以处理更多维度。
- en: 'To make a radial visualization, in a new cell, enter the following and then
    press SHIFT-ENTER:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 要制作径向可视化，请在新单元格中输入以下内容，然后按 SHIFT-ENTER：
- en: '[PRE28]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: For a better-looking radviz plot, reset the default seaborn plotting parameters
    using the `set_theme()` method and set the context to `'talk'` ➊. The `context`
    parameter controls the scaling of plot elements like label size and line thickness.
    The base context is `notebook`, and the other contexts are `paper`, `talk`, and
    `poster`, which are just versions of the `notebook` parameter scaled by different
    values. Using the `talk` argument ensures that the plot labels are easy to read.
    To better increase readability, manually set the figure size to 7" × 7".
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使 Radviz 图看起来更好，可以使用 `set_theme()` 方法重置默认的 seaborn 绘图参数，并将上下文设置为 `'talk'`
    ➊。`context` 参数控制图表元素的缩放，比如标签大小和线条粗细。基本上下文是 `notebook`，其他上下文有 `paper`、`talk` 和
    `poster`，这些都是通过不同的缩放值调整后的 `notebook` 参数。使用 `talk` 参数可以确保图表标签易于阅读。为了更好地提高可读性，手动将图形尺寸设置为
    7" × 7"。
- en: Next, call pandas’ `plotting.radviz()` method ➋. This method accepts only one
    categorical column, called the `class_column`, which in this case will be `species`.
    The rest of the DataFrame columns are assumed to be numerical, so we must remove
    the `island` and `gender` columns, which don’t contain numerical data. You could
    do this by creating a copy of the DataFrame, but because we need only this revised
    DataFrame for plotting, we’ll temporarily delete the columns, using the `drop()`
    method, while passing the DataFrame to the `radviz()` method.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，调用 pandas 的 `plotting.radviz()` 方法 ➋。此方法只接受一个类别列，称为 `class_column`，在此例中为
    `species`。其他 DataFrame 列假定为数值型，因此我们需要删除不包含数值数据的 `island` 和 `gender` 列。你可以通过创建
    DataFrame 的副本来实现这一点，但因为我们只需要这个修改后的 DataFrame 来进行绘图，所以我们将临时删除这些列，使用 `drop()` 方法，同时将
    DataFrame 传递给 `radviz()` 方法。
- en: 'The `drop()` method takes two arguments: the column names as a list, and the
    axis number, where 0 = row and 1 = column. Unless you pass it an `inplace=True`
    argument, the DataFrame will be changed for only the current operation.'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '`drop()` 方法接受两个参数：作为列表的列名和轴编号，其中 0 = 行，1 = 列。除非你传递 `inplace=True` 参数，否则 DataFrame
    只会在当前操作中发生变化。'
- en: Because we’re not plotting with seaborn, we need to remind pandas of the color
    scheme we’re using and then change the marker style and transparency to make over-posted
    points easier to see. Moving the legend to the side also helps. Notice how we’re
    able to mix in seaborn (`sns`) and Matplotlib’s `pyplot` (`plt`) with pandas `plotting`.
    This is because both seaborn and pandas are built on top of Matplotlib.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们没有使用 seaborn 绘图，所以需要提醒 pandas 使用我们选择的颜色方案，并且更改标记样式和透明度，以便更容易看到重叠的点。将图例移到一旁也有帮助。注意我们是如何将
    seaborn (`sns`) 和 Matplotlib 的 `pyplot` (`plt`) 与 pandas 的 `plotting` 结合使用的。这是因为
    seaborn 和 pandas 都是建立在 Matplotlib 之上的。
- en: You should see the plot depicted in [Figure 20-22](ch20.xhtml#ch020fig22).
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该能看到 [图 20-22](ch20.xhtml#ch020fig22) 中显示的图表。
- en: '![Image](../images/20fig22.jpg)'
  id: totrans-292
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig22.jpg)'
- en: '*Figure 20-22: Radviz plot for the penguins dataset*'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-22：企鹅数据集的 Radviz 图*'
- en: In the plot, the Gentoo data points form a distinct cluster skewed toward body
    mass and flipper length. The similarly sized Chinstrap and Adélie penguins are
    distinguished mainly by bill length, which “pulls” the Chinstrap points to the
    right of center.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 在图中，Gentoo数据点形成一个明显的簇，倾向于体重和鳍肢长度。体型相似的Chinstrap和Adélie企鹅主要通过喙长区分，这使得Chinstrap的点位于中心的右侧。
- en: The radviz plot is another way of exploring the data, and it becomes more useful
    with more dimensions. To read more about the pandas implementation, visit *[https://pandas.pydata.org/docs/reference/api/pandas.plotting.radviz.html](https://pandas.pydata.org/docs/reference/api/pandas.plotting.radviz.html)*.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: radviz图是探索数据的另一种方式，并且在数据维度更多时变得更有用。要了解更多关于pandas实现的内容，请访问*[https://pandas.pydata.org/docs/reference/api/pandas.plotting.radviz.html](https://pandas.pydata.org/docs/reference/api/pandas.plotting.radviz.html)*。
- en: 'It’s worth noting here that we changed the plotting style. I’ll be continuing
    with this new look, but if you want to return to the previous `''whitegrid''`
    style, you’ll need to enter the following code in a new cell before making more
    plots:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 这里值得注意的是，我们更改了绘图样式。我将继续使用这种新样式，但如果你想返回到以前的`'whitegrid'`样式，需要在新单元格中输入以下代码，然后再绘制更多图形：
- en: '[PRE29]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '**Quantifying Correlations Using corr()**'
  id: totrans-298
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**使用corr()量化相关性**'
- en: The pandas `DataFrame` class comes with a `corr()` method that quantifies data
    correlations by computing a pairwise correlation of columns, excluding NA/null
    values. This is useful when you plan to use regression techniques to make predictions.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: pandas的`DataFrame`类提供了一个`corr()`方法，通过计算列之间的逐对相关性（排除NA/null值）来量化数据相关性。当你计划使用回归技术进行预测时，这非常有用。
- en: 'In a new cell, enter the following and then press SHIFT-ENTER:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个新单元格中，输入以下内容并按SHIFT-ENTER：
- en: '[PRE30]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The first line calls the `corr()` method and assigns the results to the correlations
    variable. The next line plots the results as a seaborn heatmap ([Figure 20-23](ch20.xhtml#ch020fig23)).
    The `center` argument is optional and tells the method the value at which to center
    the colormap when plotting divergent data. With a value of `1`, the best correlations
    will plot in black. The `annot` argument turns on the plot annotations within
    each colored square.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 第一行调用`corr()`方法，并将结果赋值给correlations变量。下一行将结果绘制为seaborn热图（[图20-23](ch20.xhtml#ch020fig23)）。`center`参数是可选的，它告诉该方法绘制分歧数据时，色彩映射的中心值。如果值为`1`，最佳相关性将以黑色显示。`annot`参数启用每个彩色方块内的绘图注释。
- en: '![Image](../images/20fig23.jpg)'
  id: totrans-303
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig23.jpg)'
- en: '*Figure 20-23: The correlation heatmap*'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '*图20-23：相关性热图*'
- en: The heatmap confirms and quantifies correlations that we noted in the pairplot
    ([Figure 20-16](ch20.xhtml#ch020fig16)). Flipper length and body mass are the
    most closely correlated, followed by flipper length and bill length.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 热图确认并量化了我们在pairplot中注意到的相关性（[图20-16](ch20.xhtml#ch020fig16)）。鳍肢长度和体重的相关性最强，其次是鳍肢长度和喙长。
- en: For more on the `corr()` method and seaborn heatmap, visit *[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html)*
    and *[https://seaborn.pydata.org/generated/seaborn.heatmap.html](https://seaborn.pydata.org/generated/seaborn.heatmap.html)*.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于`corr()`方法和seaborn热图的信息，请访问*[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html)*和*[https://seaborn.pydata.org/generated/seaborn.heatmap.html](https://seaborn.pydata.org/generated/seaborn.heatmap.html)*。
- en: '**TEST YOUR KNOWLEDGE**'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '**测试你的知识**'
- en: 1.  Which of the following are advantages of pandas series or DataFrames over
    NumPy arrays?
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 1.  以下哪些是pandas系列或数据框相比NumPy数组的优势？
- en: a.  Ability to use heterogeneous data types
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: a.  使用异构数据类型的能力
- en: b.  Ability to use either numbers *or* labels as indexes
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: b.  能够使用数字*或*标签作为索引
- en: c.  Ability to load Python dictionaries
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: c.  加载Python字典的能力
- en: d.  Ease of use with tabular data
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: d.  处理表格数据的易用性
- en: '2.  True or False: Reindexing is required after renaming columns in a DataFrame.'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 2.  对错：在重命名数据框中的列后需要重新索引。
- en: '3.  Convert the following dictionary into a DataFrame and rename the last column
    to “whales”:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 3.  将以下字典转换为数据框，并将最后一列重命名为“whales”：
- en: 'animals = {''canines'': [''husky'', ''poodle'', ''bulldog''],'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 'animals = {''canines'': [''husky'', ''poodle'', ''bulldog''],'
- en: '''felines'': [''Siamese'', ''Persian'', ''Maine Coon''],'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: '''felines'': [''Siamese'', ''Persian'', ''Maine Coon''],'
- en: '''cetaceans'': [''humpback'', ''sperm'', ''right'']}'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: '''cetaceans'': [''humpback'', ''sperm'', ''right'']}'
- en: 4.  Display the first row of the `animals` DataFrame from the previous question.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 4.  显示上一题中`animals`数据框的第一行。
- en: '5.  Flip the rows and columns in the `animals` DataFrame (hint: look up the
    pandas `transpose()` method).'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 5.  翻转`animals`数据框中的行和列（提示：查阅 pandas 的`transpose()`方法）。
- en: '***Predicting Penguin Species Using k-Nearest Neighbors***'
  id: totrans-320
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***使用 k-最近邻算法预测企鹅物种***'
- en: The goal of this project is to develop a model that classifies penguins based
    on the Palmer Archipelago dataset. Our data exploration has revealed that four
    morphological features (bill length and depth, flipper length, and body mass)
    form separate but overlapping clusters in numerous plots. This implies that a
    machine learning classification algorithm should be able to handle the problem.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 本项目的目标是开发一个基于 Palmer Archipelago 数据集对企鹅进行分类的模型。我们的数据探索显示，四个形态特征（喙长和喙深、鳍长和体重）在多个图表中形成了不同但重叠的聚类。这意味着一个机器学习分类算法应该能够处理这个问题。
- en: It’s always best to start simple, and if you do a little research, you’ll find
    that *k-Nearest Neighbors* (*k*-NN) is one of the most basic, beginner-friendly,
    yet important classification algorithms in machine learning. It uses distance
    measures to intuitively find the *k* nearest neighbors to a new, unknown data
    point and then uses those neighbors to make a prediction.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 最好从简单的开始，如果你稍微做些研究，你会发现 *k-最近邻*（*k*-NN）是机器学习中最基础、最适合初学者的分类算法之一。它使用距离度量直观地找到一个新未知数据点的
    *k* 个最近邻，然后利用这些邻居做出预测。
- en: In [Figure 20-24](ch20.xhtml#ch020fig24), numerical data points for two categorical
    classes (A and B) are plotted in a scattergram. A new and unlabeled data point
    (⋆) falls between the two clusters. To classify this new point, the algorithm’s
    *k* parameter has been set to 7\. As most of the closest points belong to Class
    B, the new data point will be assigned to B. Because this is a “voting” algorithm,
    *k* should always be set to an odd number to avoid a tie.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图 20-24](ch20.xhtml#ch020fig24)中，两个分类类（A 和 B）的数值数据点在散点图中绘制。一个新的未标记数据点（⋆）位于两个聚类之间。为了对这个新点进行分类，算法的
    *k* 参数设置为7。由于大多数最接近的点属于 B 类，因此新数据点将被分配到 B 类。由于这是一个“投票”算法，*k* 应始终设置为奇数，以避免出现平局。
- en: '![Image](../images/20fig24.jpg)'
  id: totrans-324
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig24.jpg)'
- en: '*Figure 20-24: Example of the k-NN algorithm choosing the seven nearest neighbors
    to a new data point*'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-24：k-NN 算法选择七个最接近的新数据点邻居的示例*'
- en: Besides being intuitive and easy to explain, *k*-NN runs quickly, works well
    with small datasets, is robust to noise, and can be tuned for greater accuracy.
    It’s also versatile, given that it can be applied to both classification and regression
    problems.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 除了直观且易于解释外，*k*-最近邻算法运行速度快，适用于小型数据集，能有效抵抗噪声，并且可以调优以提高准确性。它还具有多功能性，因为可以同时应用于分类和回归问题。
- en: The algorithm needs a dense dataset, however, so that points aren’t too far
    apart. The more data *dimensions* you have, like flipper length and body mass,
    the more data you need for *k*-NN to work properly.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，该算法需要一个密集的数据集，以确保数据点之间不会相距太远。数据维度越多（例如鳍长和体重），所需的数据量就越大，以确保*k*-最近邻算法能够正常工作。
- en: In addition, *k*-NN, like other machine learning algorithms, requires its own
    data preparation routines. Because the algorithm works only with numerical data,
    you’ll commonly need to convert categorical values to integers and normalize numerical
    values between 0 and 1\. Normalization is needed so that dimensions with larger
    values don’t skew the distance calculations.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，*k*-最近邻算法像其他机器学习算法一样，需要自己的数据准备流程。由于该算法只能处理数值数据，因此通常需要将分类值转换为整数，并将数值数据归一化到0和1之间。归一化是必要的，因为较大数值的维度会扭曲距离计算。
- en: '**Converting Categorical Data to Numerical Data**'
  id: totrans-329
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**将分类数据转换为数值数据**'
- en: As stated previously, the *k*-NN algorithm uses *numerical* data. To take advantage
    of important non-numerical data, such as the island of origin and gender, you
    need to convert these values into numbers.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，*k*-最近邻算法使用 *数值* 数据。为了利用重要的非数值数据，例如来源岛屿和性别，你需要将这些值转换为数字。
- en: 'Let’s do this first for the `island` column, using the pandas `get_dummies()`
    method that we used previously when counting penguins per island. Next, we’ll
    repeat the exercise manually for gender so that you can practice DataFrame *indexing*.
    In a new cell, enter the following and then press SHIFT-ENTER:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 首先对`island`列执行此操作，使用我们之前在计算每个岛屿企鹅数量时用过的 pandas `get_dummies()`方法。接下来，我们将手动对性别重复这个练习，这样你可以练习
    DataFrame *索引*。在一个新单元格中输入以下内容，然后按 SHIFT-ENTER：
- en: '[PRE31]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: To use `get_dummies()`, pass it the DataFrame and the column label that you
    want to convert. Assign the result to a new DataFrame named `knn_df`. The method
    will create three new columns—one for each island—with values of either 0 or 1,
    depending on the value in the `island` column (either `Biscoe`, `Dream`, or `Torgersen`).
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 `get_dummies()`，将数据框和你想转换的列标签传递给它。将结果赋值给一个名为 `knn_df` 的新数据框。该方法将创建三个新列——每个岛屿一个——其值为
    0 或 1，具体取决于 `island` 列中的值（可能是 `Biscoe`、`Dream` 或 `Torgersen`）。
- en: Next, for demonstration purposes, we’ll use a different approach to convert
    the `gender` column to new `male` and `female` columns. We’ll create a new column
    for each class and fill it with zeros. Then, using conditional statements, we’ll
    find the rows where the targeted class exists and change the column values to
    ones. For example, the column for male penguins will contain `1` for rows in the
    `gender` column containing a male designation; for all other rows, the column
    will contain `0`.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，为了演示，我们将使用不同的方法将 `gender` 列转换为新的 `male` 和 `female` 列。我们将为每个类别创建一个新列，并用零填充它。然后，使用条件语句，我们将查找目标类别所在的行，并将列值更改为一。例如，雄性企鹅的列将在
    `gender` 列包含雄性标记的行中显示 `1`；对于所有其他行，该列将显示 `0`。
- en: Start by creating a new column named `male`. Assign to that column a value of
    `0` ➊. Next, use the pandas `loc` indexing operator to select a *subset* of the
    `knn_df` DataFrame. Because pandas can use both label-based and integer-based
    indexing for rows and columns, it comes with two indexing operators. The `loc`
    operator is for strictly label-based indexing, and the `iloc` operator handles
    cases in which the labels are strictly integers. In our case, the columns use
    labels (such as “species”) and the rows use integers.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，创建一个名为 `male` 的新列。为该列分配一个值 `0` ➊。接下来，使用 pandas 的 `loc` 索引运算符来选择 `knn_df`
    数据框的一个 *子集*。因为 pandas 可以使用基于标签和基于整数的索引来处理行和列，所以它有两个索引运算符。`loc` 运算符用于严格基于标签的索引，而
    `iloc` 运算符用于处理标签严格为整数的情况。在我们的例子中，列使用标签（例如“species”），行使用整数。
- en: The current operation will convert `Male` values in the `gender` column to `1`
    values in the `male` column. So, select the gender column (`knn_df['gender']`)
    and then use a conditional to overwrite the `0` values that we set in the previous
    line. What you’re saying here is, “get the `gender` column and, if its value is
    `Male`, put a `1` in the `male` column.”
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 当前操作将把 `gender` 列中的 `Male` 值转换为 `male` 列中的 `1` 值。所以，选择 `gender` 列（`knn_df['gender']`），然后使用条件语句覆盖我们在前一行中设置的
    `0` 值。你在这里的意思是，“获取 `gender` 列，如果它的值是 `Male`，就将 `1` 放入 `male` 列中。”
- en: Repeat this code for the female column and then check the results by using the
    `iloc` operator to sample rows throughout the DataFrame ➋. This works like indexing
    a list, for which you start at the beginning, go up to index 300, and use a step
    of 30 to select every 30th row.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 对女性列重复这段代码，然后通过使用 `iloc` 运算符对数据框中的行进行采样来检查结果 ➋。这就像索引一个列表，你从头开始，到达索引 300，并使用步长
    30 来选择每第 30 行。
- en: You should get the output in [Figure 20-24](ch20.xhtml#ch020fig24). Note the
    five new columns on the right side of the DataFrame. The categorical island and
    gender columns can now be used by the *k*-NN algorithm, so you can make use of
    all the data at your disposal.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该在[图 20-24](ch20.xhtml#ch020fig24)中看到输出。注意数据框右侧的五个新列。现在，类别化的岛屿和性别列可以被 *k*-NN
    算法使用，这样你就可以利用所有可用数据。
- en: '![Image](../images/20fig25.jpg)'
  id: totrans-339
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig25.jpg)'
- en: '*Figure 20-25: A sample of the new knn_df DataFrame with new numerical columns
    for islands and gender*'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-25：一个新的 knn_df 数据框示例，其中包含岛屿和性别的新数值列*'
- en: By converting the gender and island data to numbers, we’ve supplemented our
    morphological data with two more dimensions.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将性别和岛屿数据转换为数字，我们为形态学数据补充了两个新维度。
- en: If your goal was to predict the species of penguins sampled at sea, you’d want
    to drop the island-related columns because you couldn’t be sure of a penguin’s
    point of origin.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的目标是预测在海上采集的企鹅物种，你可能需要删除与岛屿相关的列，因为你无法确定企鹅的原始地点。
- en: '**Setting Up the Training and Testing Data**'
  id: totrans-343
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**设置训练和测试数据**'
- en: The *k*-NN classifier is a *supervised* learning algorithm. This means that
    you show it what the answer *should* look like by providing a set of examples
    known as the “training” dataset. You can’t use all the available data for the
    training set, however, as you’ll have no objective way to test the results. Consequently,
    you need to randomly split out a smaller subset of the data that you can use to
    test the model’s accuracy.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: '*k*-NN分类器是一种*监督学习*算法。这意味着你通过提供一组已知的例子，即“训练”数据集，向它展示答案应该是什么样子。然而，你不能使用所有可用的数据作为训练集，因为这样你就没有客观的方式来测试结果。因此，你需要随机地划分出一个较小的子集，用来测试模型的准确性。'
- en: As a lazy learning algorithm, *k*-NN doesn’t have an actual training phase in
    which it “learns” a discriminative function to apply to new data. Instead, it
    loads, or memorizes, the data and performs calculations with it during the prediction
    phase.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一种懒惰学习算法，*k*-NN没有实际的训练阶段，在训练阶段它不会“学习”一个判别函数来应用于新数据。相反，它加载或记住数据，并在预测阶段使用数据进行计算。
- en: 'For convenience, scikit-learn provides the `train_test_split()` method as part
    of the `sklearn.model_selection` module. In a new cell, enter the following and
    then press SHIFT-ENTER:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便，scikit-learn将`train_test_split()`方法提供为`sklearn.model_selection`模块的一部分。在新的单元格中输入以下代码，然后按SHIFT-ENTER：
- en: '[PRE32]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: After importing the module, call the pandas `select_dtypes()` method on the
    new `knn_df` DataFrame ➊. This method returns a subset of a DataFrame including
    or excluding columns based on their data type. We want the numerical columns for
    use with the *k*-NN algorithm, so set `include` equal to `'number'` and assign
    the result to a variable named `X`.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 导入模块后，在新的`knn_df`数据框上调用pandas的`select_dtypes()`方法 ➊。此方法返回一个数据框的子集，包含或排除根据数据类型筛选的列。我们需要数值列用于*k*-NN算法，因此将`include`设置为`'number'`，并将结果赋值给名为`X`的变量。
- en: Next, assign the `species` column to a variable named `y`. This represents the
    categorical class you’re trying to predict. Note that the uppercase “X,” lowercase
    “y” format follows the convention in the scikit-learn documentation.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，将`species`列赋值给名为`y`的变量。这代表你要预测的分类标签。请注意，大写的“X”和小写的“y”格式遵循scikit-learn文档中的惯例。
- en: Split out the training and testing data using the `train_test_split()` method
    ➋. You’ll need to unpack four variables for both `X` and `y` training and testing.
    Because we passed the method DataFrames, it will return DataFrames.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`train_test_split()`方法分割训练和测试数据 ➋。你需要为`X`和`y`的训练和测试解包四个变量。因为我们传递给方法的是数据框，它将返回数据框。
- en: A key argument here is `test_size`, expressed as a proportion of the complete
    dataset. By default, this is 0.25, or 25 percent. So, for our penguins dataset,
    this represents 83 samples (332 × 0.25).
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的一个关键参数是`test_size`，它表示完整数据集的比例。默认情况下，这个值是0.25，也就是25%。因此，对于我们的企鹅数据集，这代表83个样本（332
    × 0.25）。
- en: To avoid biasing, the `train_test_split()` method randomly shuffles the data
    before splitting it. For reproducible output across multiple function calls, you
    can pass an integer to the `random_state` argument. As written, this code lets
    you produce one set of repeatable training and testing data. To generate a new
    random set, you’ll need to either change the `random_state` value or not use it
    at all.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免偏倚，`train_test_split()`方法会在划分数据前随机打乱数据。为了在多次函数调用中生成可复现的结果，你可以向`random_state`参数传递一个整数。按照当前的写法，这段代码让你产生一组可重复的训练和测试数据。要生成新的随机数据集，你需要更改`random_state`的值或完全不使用它。
- en: Although we don’t need it here to get a good result, the `train_test_split()`
    method comes with a `stratify` parameter that ensures the split preserves the
    proportions of samples of each target class as observed in the original dataset.
    So, if the original dataset sampled 25 percent of Class A and 75 percent of Class
    B, the training and testing sets would reflect this proportion. This helps you
    avoid sampling bias, wherein a sample is not representative of the true population.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在这里我们不需要它来获得良好的结果，但`train_test_split()`方法带有一个`stratify`参数，它确保数据划分时保持每个目标类样本的比例与原始数据集中的比例一致。因此，如果原始数据集采样了25%的A类和75%的B类，训练集和测试集将反映这一比例。这有助于避免抽样偏差，即样本不能代表真实的总体。
- en: To read more about the `train_test_split()` method, visit *[https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)*.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于 `train_test_split()` 方法的信息，请访问 *[https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)*。
- en: '**Normalizing the Data**'
  id: totrans-355
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**标准化数据**'
- en: Each numerical data column in the training and testing sets should be normalized
    to values between 0 and 1\. This prevents columns with large numerical values
    from biasing the *k*-NN distance measurement.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 训练集和测试集中的每一列数值数据应该被标准化到 0 和 1 之间。这可以防止具有大数值的列对 *k*-NN 距离度量造成偏差。
- en: 'Because column transformations, such as normalization, are a common operation
    in machine learning, scikit-learn comes with two modules, `compose` and `preprocessing`,
    to simplify the task. In a new cell, enter the following and then press SHIFT-ENTER:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 由于列转换（例如标准化）是机器学习中的常见操作，scikit-learn 提供了两个模块，`compose` 和 `preprocessing`，来简化这一任务。在一个新的单元格中输入以下内容，然后按
    SHIFT-ENTER：
- en: '[PRE33]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Start by importing the `make_column_transformer()` method and the `MinMaxScaler()`
    method. The first method lets us transform columnar data; the second method specifies
    how to do it.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 首先导入 `make_column_transformer()` 方法和 `MinMaxScaler()` 方法。第一个方法让我们转换列数据；第二个方法指定如何进行转换。
- en: To normalize the data, scale it so that the minimum and maximum values fall
    between 0 and 1\. Pass the `make_column_transformer()` method the `MinMaxScaler()`
    method ➊. Next, pass it the columns that you want to transform; in this case,
    the numerical columns that aren’t already scaled to 0 and 1\. By default, the
    transformer *drops* columns that you didn’t specify in the previous argument.
    To prevent this, set the `remainder` argument to `passthrough`.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 为了标准化数据，需要将其缩放，使得最小值和最大值介于 0 和 1 之间。将 `make_column_transformer()` 方法与 `MinMaxScaler()`
    方法一起传入 ➊。接下来，传入你希望转换的列；在此情况下，是那些尚未缩放到 0 和 1 的数值列。默认情况下，转换器会 *丢弃* 你在前一个参数中未指定的列。为了避免这种情况，将
    `remainder` 参数设置为 `passthrough`。
- en: Now you need to apply the transformer by calling its `fit_transform()` method
    and passing it the `X_train` variable you made in the previous section. This method
    transforms the data and concatenates the results, returning an array. To convert
    this array back into a DataFrame, call pandas’ `DataFrame` class and pass it the
    `X_train` array ➋. The column transformer renames the columns as well as transforming
    them, so for the `columns` argument, call the `get_feature_names_out()` method
    on the `column_transformer` object.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你需要通过调用 `fit_transform()` 方法并传入你在上一节创建的 `X_train` 变量来应用转换器。此方法会转换数据并将结果合并，返回一个数组。要将此数组转换回
    DataFrame，请调用 pandas 的 `DataFrame` 类并传入 `X_train` 数组 ➋。列转换器不仅会转换列，还会重命名它们，因此对于
    `columns` 参数，请在 `column_transformer` 对象上调用 `get_feature_names_out()` 方法。
- en: Call `X_train.head()` to see the results, and then repeat this code for the
    testing set. The two DataFrame heads are shown in [Figure 20-26](ch20.xhtml#ch020fig26).
    In both, the columns should have new names, all the columns should contain numerical
    data, and values should fall between 0.0 and 1.0.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 调用 `X_train.head()` 查看结果，然后为测试集重复此代码。两个 DataFrame 的表头显示在 [图 20-26](ch20.xhtml#ch020fig26)
    中。在两个 DataFrame 中，列应该具有新名称，所有列应包含数值数据，且值应介于 0.0 和 1.0 之间。
- en: '![Image](../images/20fig26.jpg)'
  id: totrans-363
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig26.jpg)'
- en: '*Figure 20-26: The head of the normalized X_train and X_test DataFrames (shown
    horizontally truncated)*'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-26：标准化后的 X_train 和 X_test DataFrame 的表头（横向截断显示）*'
- en: To read more about the scikit-learn column transformer, visit *[https://scikit-learn.org/stable/modules/generated/sklearn.compose.make_column_transformer.html](https://scikit-learn.org/stable/modules/generated/sklearn.compose.make_column_transformer.html)*.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于 scikit-learn 列转换器的信息，请访问 *[https://scikit-learn.org/stable/modules/generated/sklearn.compose.make_column_transformer.html](https://scikit-learn.org/stable/modules/generated/sklearn.compose.make_column_transformer.html)*。
- en: You now have numbers-only DataFrames that can be used for training and testing.
    The `x_test` and `y_test` DataFrames let you relate these numerical DataFrames
    back to a species call. With only seven dimensions, this is a *low-dimensional*
    dataset. A *high-dimensional* dataset, common in machine learning, could have
    100,000-plus features!
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你有了只有数字的 DataFrame，可以用于训练和测试。`x_test` 和 `y_test` DataFrame 让你将这些数字 DataFrame
    与物种标签关联起来。这个数据集只有七个维度，是一个 *低维* 数据集。一个 *高维* 数据集，在机器学习中很常见，可能包含超过 100,000 个特征！
- en: '**Running k-NN and Checking the Accuracy of the Prediction**'
  id: totrans-367
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**运行 k-NN 并检查预测的准确性**'
- en: At this point, the data is ready to be used with the *k*-NN classifier. It’s
    time to name that penguin!
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 到此为止，数据已经准备好用于 *k*-NN 分类器了。是时候给那只企鹅命名了！
- en: 'In a new cell, enter the following code and then press SHIFT-ENTER:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个新的单元格中，输入以下代码，然后按下 SHIFT-ENTER 键：
- en: '[PRE34]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: To run *k*-NN, you need to import the `KNeighborsClassifier` class from the
    scikit-learn `neighbors` module (*[https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)*).
    To check the results, import the `accuracy_score()` method from the `metrics`
    module.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行 *k*-NN，你需要从 scikit-learn 的 `neighbors` 模块中导入 `KNeighborsClassifier` 类（*[https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)*）。要检查结果，请从
    `metrics` 模块中导入 `accuracy_score()` 方法。
- en: Call the `KNeighborsClassifier` and pass it a `k` value of `5`, and a `p` value
    of `2`. The `p` value tells the classifier to use Euclidian, or straight-line,
    distance measurements. This is usually appropriate for low-dimensional datasets
    with few outliers.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 调用 `KNeighborsClassifier`，并传入 `k` 值为 `5`，`p` 值为 `2`。`p` 值告诉分类器使用欧几里得（即直线）距离度量。通常，低维数据集且异常值较少时，这种方式是合适的。
- en: Next, call the classifier’s `fit()` method to train it and then run the `predict()`
    method on the `X_test` dataset. This will take the measurement data you *withheld*
    from training and predict the species.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，调用分类器的 `fit()` 方法来训练模型，然后在 `X_test` 数据集上运行 `predict()` 方法。这将使用你 *从训练中保留*
    的测量数据来预测物种。
- en: Finish by calling the `accuracy_score()` method and passing it the `y_test`
    and `predictions` variables. This method will compare the two datasets and store
    the accuracy measure in the `accuracy` variable, which you then print ([Figure
    20-27](ch20.xhtml#ch020fig27)).
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，调用 `accuracy_score()` 方法，并传入 `y_test` 和 `predictions` 变量。此方法将比较这两个数据集，并将准确度指标存储在
    `accuracy` 变量中，随后你可以打印出来（[图 20-27](ch20.xhtml#ch020fig27)）。
- en: '![Image](../images/20fig27.jpg)'
  id: totrans-375
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/20fig27.jpg)'
- en: '*Figure 20-27: The accuracy of the k-NN model*'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-27：k-NN 模型的准确度*'
- en: Right out of the gate, the model correctly matched about 99 percent of the samples
    in the `X_test` dataset. But don’t get too excited. It’s only matched samples
    in a *randomly chosen* subset of the `penguins` dataset. If you generate a new
    test set by changing the `train_test_split()` method’s `random_state` argument
    from `300` to `500` and rerun the cells, you’ll get an accuracy of `0.9642857142857143`.
    Although this is about as good as it gets for a real-world dataset, let’s use
    this discrepancy to see how you might handle a larger mismatch in a different
    project.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 一开始，模型准确地匹配了 `X_test` 数据集中的约 99% 的样本。但不要太激动。这仅仅是匹配了 `penguins` 数据集中的一个 *随机选择*
    子集中的样本。如果你通过将 `train_test_split()` 方法的 `random_state` 参数从 `300` 改为 `500` 来生成一个新的测试集，并重新运行这些单元格，你会得到
    `0.9642857142857143` 的准确度。虽然这对于一个真实世界的数据集来说已经算是最好的结果，但我们可以利用这个差异来探讨如何在其他项目中处理更大程度的错配。
- en: '**Optimizing the k Value Using Cross-Validation**'
  id: totrans-378
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**使用交叉验证优化 k 值**'
- en: The goal of supervised machine learning is to generalize *beyond* what we see
    in training samples so that we can reliably classify new data. The *k*-NN classifier
    uses numerous *hyperparameters* such as `k`, `p`, and `weights` to control the
    learning process. In addition, the `test_size` and other parameters in the `train_test_split()`
    method can have a big impact on model results. You can think of these parameters
    as knobs that you can turn to “tune” or “dial in” the model fit.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 监督式机器学习的目标是使模型能够超越我们在训练样本中看到的内容，从而能够可靠地分类新的数据。*k*-NN 分类器使用多个 *超参数*，如 `k`、`p`
    和 `weights` 来控制学习过程。此外，`train_test_split()` 方法中的 `test_size` 和其他参数也会对模型结果产生重大影响。你可以将这些参数视为可以调节的旋钮，来“调整”或“定制”模型的拟合程度。
- en: You must be careful however, not to tune things *too* finely. *Overfitting*
    is a common problem that can lurk behind an apparently accurate model ([Figure
    20-28](ch20.xhtml#ch020fig28)).
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，必须小心不要将参数调整得 *过* 精细。*过拟合* 是一个常见问题，它可能潜藏在一个表面上看似准确的模型背后（[图 20-28](ch20.xhtml#ch020fig28)）。
- en: '![Image](../images/20fig28.jpg)'
  id: totrans-381
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/20fig28.jpg)'
- en: '*Figure 20-28: An example of model fits with original training set (left) and
    superimposed with new, unmatched training set (right)*'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-28：原始训练集（左）和与新、未匹配的训练集叠加（右）的模型拟合示例*'
- en: In [Figure 20-28](ch20.xhtml#ch020fig28), the chart on the left shows three
    fits (over, under, and best) to a randomized training dataset. Any points that
    fall to the right of these lines will be classified as belonging to Class B.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图20-28](ch20.xhtml#ch020fig28)中，左侧的图表展示了对随机化训练数据集的三种拟合（过拟合、欠拟合和最佳拟合）。任何落在这些线右侧的点将被归类为属于B类。
- en: If the left-hand chart represents all the data we would ever have, the overfitted
    model would be the most accurate. But look what happens when we choose and post
    a new training set (right side of [Figure 20-28](ch20.xhtml#ch020fig28)). Some
    points stay the same and others change, and the overfitted model no longer matches
    the data as well. On the other hand, the underfitted model can neither model the
    training data nor generalize sufficiently to match new data.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 如果左侧图表代表我们将来所有的数据，过拟合的模型将是最准确的。但当我们选择并发布一个新的训练集（[图20-28](ch20.xhtml#ch020fig28)右侧）时，看看会发生什么。一些点保持不变，其他点发生变化，过拟合的模型不再与数据匹配。另一方面，欠拟合的模型既无法拟合训练数据，也无法足够地推广到新数据。
- en: Typically, the smaller the *k* value, the “tighter” the fit of the model to
    the data and the more likely that it is overfit; the larger the *k* value, the
    more likely that the model is underfit.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，*k* 值越小，模型与数据的拟合越“紧密”，也越容易出现过拟合；*k* 值越大，模型越可能出现欠拟合。
- en: In [Figure 20-28](ch20.xhtml#ch020fig28), the more generalized “Best fit” model
    does a good job of matching the two datasets. To achieve this generalized model,
    we’ll need to find the best values for the important hyperparameters. But this
    isn’t something that can be intuited when working in multidimensional space. It
    requires iterative investigation, where parameters are changed multiple times
    and the results are tabulated and scored.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图20-28](ch20.xhtml#ch020fig28)中，更加泛化的“最佳拟合”模型很好地匹配了这两个数据集。为了实现这个泛化模型，我们需要找到重要超参数的最佳值。但在多维空间中工作时，这不是直观的。它需要通过迭代调查，在多次改变参数后，记录和评分结果。
- en: In the code that follows, we’ll investigate a range of *k* values using *cross-validation*
    (*cv* for short). This is a model validation technique for assessing how the results
    of a statistical analysis will generalize to a new, unknown dataset. It also helps
    flag issues like overfitting.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的代码中，我们将使用 *交叉验证*（简称 *cv*）来研究一系列 *k* 值。这是一种模型验证技术，用于评估统计分析结果如何推广到新的、未知的数据集。它还帮助发现诸如过拟合等问题。
- en: Cross-validation resamples different parts of the training set to create testing
    sets. To ensure that the entire training set is evaluated, it repeats this sampling
    multiple times. As it iterates, it changes the value of a hyperparameter, like
    *k*, and scores the result based on model accuracy. When the optimal parameters
    are identified, you input them in the *k*-NN classifier and perform a final evaluation
    against the test dataset, which has been kept separate from the cv process ([Figure
    20-29](ch20.xhtml#ch020fig29)).
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证通过重新抽样训练集的不同部分来创建测试集。为了确保整个训练集都得到评估，它会多次重复这种抽样。随着迭代的进行，它会改变一个超参数的值，比如 *k*，并根据模型准确性对结果进行评分。当找到最佳参数时，你将其输入到
    *k*-NN分类器中，并对与交叉验证过程分离的测试数据集进行最终评估（[图20-29](ch20.xhtml#ch020fig29)）。
- en: '![Image](../images/20fig29.jpg)'
  id: totrans-389
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig29.jpg)'
- en: '*Figure 20-29: Building a predictive model using cross-validation (modified
    from [scikit-learn.org](http://scikit-learn.org))*'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: '*图20-29：使用交叉验证构建预测模型（修改自[scikit-learn.org](http://scikit-learn.org))*'
- en: 'To use cross-validation on our penguins dataset model, in a new cell, enter
    the following and then press SHIFT-ENTER:'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 要在我们的企鹅数据集模型上使用交叉验证，在新单元格中输入以下内容，然后按下SHIFT-ENTER：
- en: '[PRE35]'
  id: totrans-392
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: We’ll use NumPy to make a range of *k* values to evaluate, and average, the
    results of each cv iteration. The `cross_validate()` method is found in the scikit-learn
    `model_selection` module.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 NumPy 来创建一系列 *k* 值，以评估并平均每次交叉验证迭代的结果。`cross_validate()` 方法位于 scikit-learn
    的 `model_selection` 模块中。
- en: Python dictionaries are great for storing data like test results, and they can
    easily be turned into pandas DataFrames. After the imports, create a dictionary
    named `cv_metrics` with keys for the average training set and cross-validation
    score per iteration. The initial values for these dictionary keys are empty lists.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: Python 字典非常适合存储诸如测试结果之类的数据，并且可以轻松转换为 pandas DataFrame。在导入之后，创建一个名为 `cv_metrics`
    的字典，键为每次迭代的平均训练集和交叉验证分数。这些字典键的初始值是空列表。
- en: 'Next, make a `num_neighbors` dictionary with one key-value pair: *k* and a
    1D `ndarray` from 1 to 25\. These represent the range of *k* values you’ll be
    testing.'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，创建一个`num_neighbors`字典，其中包含一个键值对：*k*和从1到25的1D`ndarray`。这些代表您将要测试的*k*值范围。
- en: Loop through the `num_neighbors` dictionary and pass the current *k* value to
    the `KNeighborsClassifier` ➊. Then, call the `cross_validate()` method, pass it
    the `knn` model and the training data, and set the `return_train_score` argument
    to `True`. Finish each loop by appending the score results to the appropriate
    key in the `cv_metrics` dictionary. Use the NumPy `mean()` method to average the
    scores for each data point during the process.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 遍历`num_neighbors`字典，并将当前的*k*值传递给`KNeighborsClassifier` ➊。然后，调用`cross_validate()`方法，将其传递给`knn`模型和训练数据，并将`return_train_score`参数设置为`True`。在每次循环结束时，将分数结果附加到`cv_metrics`字典中的相应键中。使用NumPy的`mean()`方法对整个过程中每个数据点的分数进行平均。
- en: Outside the loop, turn the `cv_metrics` dictionary into a DataFrame ➋ and then
    add the `num_neighbors` dictionary as a new column on the leftmost side of the
    DataFrame. Do this by calling the `insert()` method on the DataFrame and passing
    it the first column position (`loc=0`), the column name, and the value, obtained
    by passing the `num_neighbors` dictionary the `k` key. Finish by calling `head(10)`
    to display the first 10 rows.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 在循环之外，将`cv_metrics`字典转换为DataFrame ➋，然后将`num_neighbors`字典作为新列添加到DataFrame的最左侧。通过在DataFrame上调用`insert()`方法，并传递第一列位置（`loc=0`）、列名和值（通过将`num_neighbors`字典传递给`k`键获得）。最后调用`head(10)`以显示前10行。
- en: Rather than scroll through the DataFrame looking for the *k* value with the
    best score, let pandas find it using the `idxmax()` method, which returns the
    index of the first occurrence of a maximum value over a requested axis. This is
    axis 0 (row) by default. When you print the result, you should see the output
    in [Figure 20-30](ch20.xhtml#ch020fig30).
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 与其在DataFrame中滚动查找具有最佳分数的*k*值，不如使用`idxmax()`方法让pandas来找到它，该方法返回请求轴上第一次出现的最大值的索引。默认情况下，这是轴0（行）。当打印结果时，您应该在[图20-30](ch20.xhtml#ch020fig30)中看到输出。
- en: Comparing cross-validation and training scores can be insightful with respect
    to model overfitting and underfitting. The process is computationally expensive
    for high-dimensionality datasets, however, and the training scores are not required
    to select the best parameters.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 比较交叉验证和训练分数可以深入了解模型的过拟合和欠拟合情况。然而，对于高维数据集来说，这个过程计算开销很大，并且不需要训练分数来选择最佳参数。
- en: '![Image](../images/20fig30.jpg)'
  id: totrans-400
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../images/20fig30.jpg)'
- en: '*Figure 20-30: The first 10 rows in the cv_metrics DataFrame and the cv choice
    for best k value*'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: '*图20-30：cv_metrics DataFrame中的前10行和最佳*k*值的cv选择*'
- en: 'To plot the cv results, in a new cell, enter the following and then press SHIFT-ENTER:'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 要绘制cv结果，在新单元格中输入以下内容，然后按SHIFT-ENTER：
- en: '[PRE36]'
  id: totrans-403
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The first line resets the seaborn color palette that we’ve been using for a
    consistent look. The next line prepares the DataFrame for plotting. In seaborn,
    plotting multiple columns against the same y-axis requires a call to the pandas
    `melt()` method. This method returns a new DataFrame reshaped into a long table
    with one row for each column. To learn about wide-form and long-form data, see
    *[https://seaborn.pydata.org/tutorial/data_structure.html](https://seaborn.pydata.org/tutorial/data_structure.html)*.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 第一行重置我们一直使用的seaborn颜色调色板，以保持一致的外观。下一行准备DataFrame进行绘图。在seaborn中，将多列绘制到同一y轴上需要调用pandas的`melt()`方法。此方法返回一个新的DataFrame，将其重塑为长表格，每列一个行。有关宽格式和长格式数据的详细信息，请参阅*[https://seaborn.pydata.org/tutorial/data_structure.html](https://seaborn.pydata.org/tutorial/data_structure.html)*。
- en: With the new `df_melt` DataFrame, you can call seaborn’s `lineplot()` method
    to get the plot in [Figure 20-31](ch20.xhtml#ch020fig31). The top curve represents
    the average training score.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 使用新的`df_melt` DataFrame，您可以调用seaborn的`lineplot()`方法来获得[图20-31](ch20.xhtml#ch020fig31)中的绘图。顶部曲线代表平均训练分数。
- en: '![Image](../images/20fig31.jpg)'
  id: totrans-406
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../images/20fig31.jpg)'
- en: '*Figure 20-31: A comparison of the average training scores and cross-validation
    scores with the k value*'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: '*图20-31：使用*k*值进行平均训练分数和交叉验证分数的比较*'
- en: 'If you expect to work extensively with pandas, consider learning its plotting
    syntax. For example, you can re-create [Figure 20-31](ch20.xhtml#ch020fig31) with
    a single line: `cv_metrics_df.plot.line(x=''k'')`. The plots are less customizable
    than with seaborn or Matplotlib, but they’re more than suitable for data exploration.
    To learn more, visit *[https://pandas.pydata.org/docs/getting_started/intro_tutorials/04_plotting.html](https://pandas.pydata.org/docs/getting_started/intro_tutorials/04_plotting.html)*.'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你计划广泛使用 pandas，考虑学习它的绘图语法。例如，你可以用一行代码重新创建[图 20-31](ch20.xhtml#ch020fig31)：`cv_metrics_df.plot.line(x='k')`。这些图表的自定义能力不如
    seaborn 或 Matplotlib，但对于数据探索来说已经足够。要了解更多信息，请访问 *[https://pandas.pydata.org/docs/getting_started/intro_tutorials/04_plotting.html](https://pandas.pydata.org/docs/getting_started/intro_tutorials/04_plotting.html)*。
- en: A model that is underfit will have both low training and low testing accuracy,
    whereas an overfit model will have a high training accuracy but a low testing
    accuracy. On the left side of [Figure 20-31](ch20.xhtml#ch020fig31), where *k*
    = 1, the training set is perfectly accurate because the training data point is
    compared only to itself. The cv results, however, are less accurate. This indicates
    slight overfitting, which we would expect with a low value of *k*.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 欠拟合的模型将具有较低的训练和测试准确性，而过拟合的模型将具有较高的训练准确性，但测试准确性较低。在[图 20-31](ch20.xhtml#ch020fig31)的左侧，当
    *k* = 1 时，训练集是完全准确的，因为训练数据点仅与其自身进行比较。然而，交叉验证结果却不那么准确。这表明存在轻微的过拟合，我们可以预期在 *k* 值较低时会出现这种情况。
- en: On the right side of the figure, where *k* is greater than 20, accuracy falls
    off for both curves. The model is trying to accommodate too many data points and
    is becoming underfit.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 在图的右侧，当 *k* 大于 20 时，两个曲线的准确性都会下降。模型试图适应过多的数据点，导致出现欠拟合。
- en: When *k* = 4, the cv score reaches its highest average accuracy, and the two
    curves begin to meet and run parallel to each other. In this case, values of *k*
    between 5 and 10 will only add computational burden without increasing the model
    accuracy.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 当 *k* = 4 时，交叉验证得分达到了最高的平均准确性，两个曲线开始汇聚并平行运行。在这种情况下，5 到 10 之间的 *k* 值只会增加计算负担，而不会提高模型准确性。
- en: If you change the `random_state` or the `test_size` parameters in the `train_test_split()`method
    and rerun the code, you’ll see variations in the choice of best *k* value. This
    is because the model starts out with such high accuracy that subtle stochastic
    effects can have a large relative impact with essentially no absolute impact.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你更改 `train_test_split()` 方法中的 `random_state` 或 `test_size` 参数并重新运行代码，你会看到最佳
    *k* 值的变化。这是因为模型开始时的准确性非常高，因此微小的随机效应可以产生较大的相对影响，而几乎没有绝对影响。
- en: '**Optimizing Multiple Hyperparameters Using GridSearchCV**'
  id: totrans-413
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**使用 GridSearchCV 优化多个超参数**'
- en: Running cross-validations can take time, so scikit-learn comes with a convenience
    class called `GridSearchCV`. It takes a dictionary of parameter names and values,
    cross-validates them, and reports the outcome. You can find the documentation
    at *[https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)*.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 运行交叉验证可能需要一些时间，因此 scikit-learn 提供了一个名为 `GridSearchCV` 的便捷类。它接受一个参数名称和值的字典，对其进行交叉验证，并报告结果。你可以在
    *[https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)*
    上找到文档。
- en: 'In a new cell, enter the following and then press SHIFT-ENTER:'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个新的单元格中，输入以下内容并按 SHIFT-ENTER：
- en: '[PRE37]'
  id: totrans-416
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: A dictionary named `params` holds the hyperparameter ranges. In this example,
    the *k* (`n_neighbors`) range is a NumPy array, and the `weights` and `p` parameters
    use lists.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 一个名为 `params` 的字典包含超参数范围。在此示例中，*k*（`n_neighbors`）范围是一个 NumPy 数组，`weights` 和
    `p` 参数使用列表。
- en: The `GridSearchCV` class needs to know the DataFrame you’re using (`knn`), the
    name of the parameters dictionary (`params`), what to score on (`accuracy`), and
    how much detail you want it to report. By passing it `verbose=1`, we suppressed
    most of the extraneous output.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: '`GridSearchCV` 类需要知道你正在使用的 DataFrame（`knn`）、参数字典的名称（`params`）、评分依据（`accuracy`）以及你希望它报告的详细程度。通过传递
    `verbose=1`，我们抑制了大部分无关的输出。'
- en: After fitting the model, you can print the `best_params_` attribute to see the
    results ([Figure 20-32](ch20.xhtml#ch020fig32)).
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 在拟合模型后，你可以打印 `best_params_` 属性查看结果（[图 20-32](ch20.xhtml#ch020fig32)）。
- en: '![Image](../images/20fig32.jpg)'
  id: totrans-420
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig32.jpg)'
- en: '*Figure 20-32: Results of running GridSearchCV*'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-32：运行 GridSearchCV 的结果*'
- en: Next, in a new cell, pass the best parameters identified by the grid search
    to the `KNeighborsClassifier`, fit the model, predict against the testing dataset,
    and evaluate the accuracy. This corresponds to the “retrained model” and “final
    evaluation” steps shown in [Figure 20-29](ch20.xhtml#ch020fig29).
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，在一个新单元格中，将网格搜索识别的最佳参数传递给 `KNeighborsClassifier`，拟合模型，对测试数据集进行预测，并评估准确性。这对应于图
    [Figure 20-29](ch20.xhtml#ch020fig29) 中的“重新训练的模型”和“最终评估”步骤。
- en: '[PRE38]'
  id: totrans-423
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: You should get the output shown in [Figure 20-33](ch20.xhtml#ch020fig33).
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到如图 [Figure 20-33](ch20.xhtml#ch020fig33) 所示的输出。
- en: '![Image](../images/20fig33.jpg)'
  id: totrans-425
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig33.jpg)'
- en: '*Figure 20-33: Model accuracy after applying the optimized hyperparameters*'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-33：应用优化超参数后的模型准确性*'
- en: You might notice that this score is worse than the one we got initially using
    `k=5` ([Figure 20-27](ch20.xhtml#ch020fig27)). That’s because this initial run
    on a *single* train-test dataset was equivalent to a lucky roll of dice. The current
    model built with `k=4` has been tested over *multiple* datasets and should, when
    used repeatedly, yield the same average accuracy as `k=5` (see [Figure 20-31](ch20.xhtml#ch020fig31))
    but with better computational efficiency.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会注意到，这个分数比我们最初使用 `k=5` 时的分数差（见 [Figure 20-27](ch20.xhtml#ch020fig27)）。这是因为这次在
    *单一* 训练-测试数据集上的初步运行相当于一次幸运的骰子投掷。当前使用 `k=4` 构建的模型已经在 *多个* 数据集上进行了测试，并且在重复使用时应该会得到与
    `k=5` 相同的平均准确度（见 [Figure 20-31](ch20.xhtml#ch020fig31)），但具有更好的计算效率。
- en: Along these lines, we’ve used only 75 percent of the penguins dataset to train
    the model. How do we know that 80 percent wouldn’t produce better results? To
    find out, you could use a loop to run multiple combinations of the `test_size`
    and `random_state` parameters of the `train_test_split()` method and model each.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些思路下，我们仅使用了企鹅数据集的75%来训练模型。我们怎么知道80%的数据比例不会得到更好的结果呢？为了找出答案，你可以使用一个循环，运行 `train_test_split()`
    方法的 `test_size` 和 `random_state` 参数的多个组合，并对每个组合进行建模。
- en: The need to test many parameter and dataset combinations, along with heavy memory
    use, renders the *k*-NN algorithm inappropriate for very large datasets. Otherwise,
    it has numerous benefits, including being simple to use, easy to understand, fast
    to train, versatile, and agnostic to assumptions about the underlying data distributions.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 需要测试许多参数和数据集组合，并且内存使用量较大，这使得 *k*-NN 算法不适用于非常大的数据集。否则，它有许多优点，包括易于使用、易于理解、训练速度快、多功能且不依赖于底层数据分布的假设。
- en: '**TEST YOUR KNOWLEDGE**'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: '**测试你的知识**'
- en: '6.  For a big picture overview of a dataset, call the:'
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 6.  要概览数据集的整体情况，可以调用：
- en: a.  seaborn `relplot()` method
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: a.  seaborn `relplot()` 方法
- en: b.  pandas `radviz()` method
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: b.  pandas `radviz()` 方法
- en: c.  seaborn `pairplot()` method
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: c.  seaborn `pairplot()` 方法
- en: d.  seaborn `jointplot()` method
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: d.  seaborn `jointplot()` 方法
- en: '7.  The *k*-NN algorithm is appropriate for:'
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 7.  *k*-NN 算法适用于：
- en: a.  Classification in high-dimensional datasets
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: a.  高维数据集中的分类
- en: b.  Projects for which computer memory is at a premium
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: b.  计算机内存稀缺的项目
- en: c.  Classification in a noisy, low-dimensional dataset
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: c.  在嘈杂、低维数据集中的分类
- en: d.  All of the above
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: d.  以上所有
- en: '8.  Using a very low *k* value with the *k*-NN algorithm can result in:'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 8.  使用非常低的 *k* 值与 *k*-NN 算法一起使用可能导致：
- en: a.  Excessive run times
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: a.  过长的运行时间
- en: b.  An underfit model
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: b.  一个欠拟合的模型
- en: c.  An overfit model
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: c.  一个过拟合的模型
- en: d.  A generalized model
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: d.  一个通用模型
- en: '9.  In machine learning, a hyperparameter is:'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 9.  在机器学习中，超参数是：
- en: a.  A parameter chosen automatically by the algorithm
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: a.  一个由算法自动选择的参数
- en: b.  A parameter set at the top level of an algorithm
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: b.  设置在算法顶层的参数
- en: c.  An adjustable parameter used to control the learning process
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: c.  一个可调节的参数，用于控制学习过程
- en: d.  An overly excitable parameter
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: d.  一个过于兴奋的参数
- en: '10.  Cross-validation is used to:'
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 10.  交叉验证用于：
- en: a.  Check the accuracy of a model against an independent test set
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: a.  检查模型在独立测试集上的准确性
- en: b.  Find the best hyperparameters from an input range of hyperparameters
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: b.  从超参数输入范围中找到最优的超参数
- en: c.  Check a dataset for duplicate samples
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: c.  检查数据集是否有重复样本
- en: d.  Gain insight on model underfitting and overfitting
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: d.  获取关于模型欠拟合和过拟合的洞察
- en: '**Summary**'
  id: totrans-456
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**总结**'
- en: 'The Palmer penguins project provided a good overview of how pandas, seaborn,
    and scikit-learn work, how they work together, and what you can accomplish using
    them. At this point, though, you’ve barely glimpsed the enormity of these packages.
    To expand your knowledge, I recommend the official library documentation cited
    in the introduction to this chapter as well as the following books:'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: Palmer 企鹅项目提供了一个很好的概述，展示了 pandas、seaborn 和 scikit-learn 的工作原理，它们是如何协同工作的，以及你可以使用它们完成什么任务。然而，在这一点上，你仅仅是略微接触到了这些包的庞大功能。为了扩展你的知识，我推荐参考本章介绍中的官方库文档以及以下书籍：
- en: '*Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython*,
    2nd edition, by Wes McKinney (O’Reilly Media, 2018), is an indispensable guide
    by the creator of the pandas library.'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python 数据分析：使用 Pandas、NumPy 和 IPython 进行数据整理*，第二版，Wes McKinney 著（O’Reilly
    Media，2018年），是由 pandas 库的创建者编写的不可或缺的指南。'
- en: '*Python Data Science Handbook: Essential Tools for Working with Data*, by Jake
    VanderPlas (O’Reilly Media, 2016), is a thorough reference for important Python
    data science tools, including pandas.'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python 数据科学手册：处理数据的必备工具*，Jake VanderPlas 著（O’Reilly Media，2016年），是一本详尽的参考书，涵盖了重要的
    Python 数据科学工具，包括 pandas。'
- en: '*Hands-on Machine Learning with Scikit-Learn, Keras, & TensorFlow: Concepts,
    Tools, and Techniques to Build Intelligent Systems*, 2nd edition, by Aurélien
    Géron (O’Reilly Media, 2019), provides practical instruction for machine learning
    novices.'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: '*动手实践机器学习：Scikit-Learn、Keras 与 TensorFlow 的概念、工具与技术*，第二版，Aurélien Géron 著（O’Reilly
    Media，2019年），为机器学习初学者提供了实用的指导。'
- en: 'Although the penguins project covered a lot of ground, it didn’t address one
    of the most important forms of structured data used by scientists: time series
    data. In the next and final chapter, we’ll look at methods for incorporating dates
    and times in your programs and plots.'
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管企鹅项目覆盖了很多内容，但它并没有涉及科学家使用的最重要的结构化数据形式之一：时间序列数据。在接下来的最终章节中，我们将探讨如何在程序和图表中加入日期和时间的方法。

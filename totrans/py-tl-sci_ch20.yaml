- en: '**20'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**20'
- en: PANDAS, SEABORN, AND SCIKIT-LEARN**
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: PANDAS、SEABORN 和 SCIKIT-LEARN**
- en: '![image](../images/common.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/common.jpg)'
- en: A common scientific practice is evaluating data and using it to generate predictive
    models. In this chapter, we’ll use three of Python’s most popular open source
    libraries to solve a zoological classification problem. Using this hands-on, project-based
    approach will showcase the functionality and synergy among the libraries and demonstrate
    what’s involved in doing science with Python.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 一种常见的科学实践是评估数据并利用它来生成预测模型。在本章中，我们将使用 Python 的三个最受欢迎的开源库来解决一个动物分类问题。通过这种基于项目的实践方法，将展示这些库的功能和协同效应，并演示使用
    Python 做科学研究的具体过程。
- en: For data loading, analysis, and manipulation, we’ll use the pandas package (*[https://pandas.pydata.org/](https://pandas.pydata.org/)).*
    Built on NumPy and Matplotlib, pandas uses array-based computing under the hood
    but has simpler syntax, making coding and plotting faster, easier, and more error
    free. Unlike native Python, pandas can intelligently read tabular text-file data,
    recognizing columns, rows, headers, and so on. And unlike NumPy, on which it’s
    built, pandas can handle heterogeneous data types such as mixtures of text and
    numbers.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数据加载、分析和处理，我们将使用 pandas 包（*[https://pandas.pydata.org/](https://pandas.pydata.org/)*）。pandas
    基于 NumPy 和 Matplotlib 构建，虽然底层使用基于数组的计算，但它的语法更简单，使得编写代码和绘图更加快速、容易且更少出错。与原生 Python
    不同，pandas 能够智能地读取表格文本文件数据，识别列、行、标题等内容。与 NumPy 不同，pandas 能处理异质数据类型，如文本和数字的混合数据。
- en: We’ll also use the seaborn library (*[https://seaborn.pydata.org/](https://seaborn.pydata.org/)*),
    which wraps Matplotlib to produce more attractive and easier visualizations. It
    represents a nice plotting compromise between the highly customizable but verbose
    syntax of Matplotlib and the bare-bones simplicity of pandas. Even better, seaborn
    is tightly integrated with pandas for seamless plotting and effective data exploration.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将使用 seaborn 库（*[https://seaborn.pydata.org/](https://seaborn.pydata.org/)*），它封装了
    Matplotlib，用于生成更具吸引力且更易于理解的可视化图表。它在高度可定制但冗长的 Matplotlib 语法和简单的 pandas 之间提供了一个良好的折衷。更好的是，seaborn
    与 pandas 紧密集成，能够无缝地进行绘图和有效的数据探索。
- en: Lastly, the scikit-learn library (*[https://scikit-learn.org/](https://scikit-learn.org/)*)
    is Python’s primary general-purpose machine learning toolkit. It provides algorithms
    for classification, regression, clustering, dimensionality reduction, preprocessing,
    and model selection.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，scikit-learn 库（*[https://scikit-learn.org/](https://scikit-learn.org/)*）是
    Python 的主要通用机器学习工具包。它提供了分类、回归、聚类、降维、预处理和模型选择的算法。
- en: In the sections that follow, you’ll apply these libraries to a real-world problem
    and observe how they work together. But, due to their enormous size and scope,
    we won’t be able to study them in-depth. Whole books have been dedicated to each,
    and the admittedly non-exhaustive pandas overview in Wes McKinney’s *Python for
    Data Analysis*, 2nd edition requires no less than 270 pages!
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，你将应用这些库来解决一个实际问题，并观察它们如何协同工作。但由于这些库的规模和范围庞大，我们无法深入研究它们。每个库都有专门的书籍，Wes
    McKinney 的 *《Python 数据分析》* 第二版中关于 pandas 的概述就足足有270页，尽管它不是全面的。
- en: If you’d like a complete picture, I list some additional resources in the “Summary”
    section at the end of this chapter. You can also find useful tutorials and examples
    in the official websites, cited previously.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解完整的内容，我在本章末的“总结”部分列出了一些附加资源。你还可以在之前提到的官方网站上找到有用的教程和示例。
- en: '**Introducing the pandas Series and DataFrame**'
  id: totrans-9
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**介绍 pandas Series 和 DataFrame**'
- en: The pandas library contains data structures designed for working with common
    data sources such as Excel spreadsheets and SQL relational databases. Its two
    primary data structures are series and DataFrames. Other libraries, like seaborn,
    are designed to integrate well with these data structures and supply additional
    functionality, making pandas a great foundation to any data science project.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: pandas 库包含用于处理常见数据源（如 Excel 表格和 SQL 关系数据库）的数据结构。它的两个主要数据结构是 Series 和 DataFrame。其他库（如
    seaborn）则设计用于与这些数据结构良好集成，并提供额外的功能，使得 pandas 成为任何数据科学项目的良好基础。
- en: '***The Series Data Structure***'
  id: totrans-11
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***Series 数据结构***'
- en: A *series* is a one-dimensional labeled array that can hold any type of data
    such as integers, floats, strings, and so on. Because pandas is based on NumPy,
    a series object is basically two associated arrays. One array contains the data
    point values, which can have any NumPy data type. The other array contains labels
    for each data point, called *indexes* ([Table 20-1](ch20.xhtml#ch020tab1)).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '*Series* 是一种一维的带标签数组，可以容纳任何类型的数据，例如整数、浮点数、字符串等。由于 pandas 基于 NumPy，因此序列对象本质上是两个关联的数组。一个数组包含数据点的值，可以是任何
    NumPy 数据类型；另一个数组包含每个数据点的标签，称为 *索引*（[表 20-1](ch20.xhtml#ch020tab1)）。'
- en: '**Table 20-1:** A Series Object'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**表 20-1：** 一个 Series 对象'
- en: '| **Index** | **Value** |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| **索引** | **值** |'
- en: '| --- | --- |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 0 | 42 |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 42 |'
- en: '| 1 | 549 |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 549 |'
- en: '| 2 | '' Steve '' |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| 2 | '' Steve '' |'
- en: '| 3 | –66.6 |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| 3 | -66.6 |'
- en: Unlike the indexes of Python list items, the indexes in a series don’t need
    to be an integer. In [Table 20-2](ch20.xhtml#ch020tab2), the indexes are the names
    of elements, and the values are their atomic numbers.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Python 列表项的索引不同，序列中的索引不需要是整数。在 [表 20-2](ch20.xhtml#ch020tab2) 中，索引是元素的名称，而值是它们的原子序数。
- en: '**Table 20-2:** A Series Object with Meaningful Indexes'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**表 20-2：** 一个具有有意义索引的 Series 对象'
- en: '| **Index** | **Value** |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| **索引** | **值** |'
- en: '| --- | --- |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Silicon | 14 |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| 硅 | 14 |'
- en: '| Sodium | 11 |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| 钠 | 11 |'
- en: '| Argon | 18 |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 氩 | 18 |'
- en: '| Cobalt | 27 |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| 钴 | 27 |'
- en: A series acts much like a Python dictionary in so much as indexes represent
    keys. It can thus serve as a replacement for a dictionary in many contexts. Another
    useful feature is that different series will align by index label when doing arithmetic
    operations between them even if the labels don’t occur in the same order.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 一个序列的作用类似于 Python 字典，其中索引代表键。因此，它可以在许多场景中作为字典的替代品。另一个有用的特性是，在进行算术操作时，即使标签的顺序不同，不同的序列也会根据索引标签对齐。
- en: As with a list or NumPy array, you can slice a series or select individual elements
    by specifying an index. You can manipulate the series many ways, such as filtering
    it, performing mathematical operations on it, and merging it with other series.
    To see the many attributes and methods available for a series object, visit *[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html).*
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 与列表或 NumPy 数组类似，你可以通过指定索引来切片一个序列或选择单独的元素。你可以以多种方式操作序列，例如过滤它、对其进行数学运算，或将其与其他序列合并。要查看序列对象的众多属性和方法，请访问
    *[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html)*。
- en: '***The DataFrame Data Structure***'
  id: totrans-30
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***DataFrame 数据结构***'
- en: A *DataFrame* is a more complex structure made up of two dimensions. It’s a
    collection of objects organized using a tabular structure, like a spreadsheet,
    with columns, rows, and data ([Table 20-3](ch20.xhtml#ch020tab3)). You can think
    of it as an ordered collection of columns with two indexing arrays. Each column
    represents a pandas series.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '*DataFrame* 是一种由两维结构组成的更复杂的数据结构。它是一个使用表格结构组织的对象集合，类似于电子表格，包含列、行和数据（[表 20-3](ch20.xhtml#ch020tab3)）。你可以将其视为一个有序的列集合，配有两个索引数组。每一列代表一个
    pandas 序列。'
- en: '**Table 20-3:** A DataFrame Object'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**表 20-3：** 一个 DataFrame 对象'
- en: '| **Columns** |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| **列** |'
- en: '| --- |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| **Index** | **Country** | **State** | **County** | **Population** |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| **索引** | **国家** | **州** | **县** | **人口** |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 0 | USA | Alabama | Autauga | 54,571 |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 美国 | 阿拉巴马州 | 奥陶戈 | 54,571 |'
- en: '| 1 | USA | Alabama | Baldwin | 182,265 |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 美国 | 阿拉巴马州 | 巴尔德温 | 182,265 |'
- en: '| 2 | USA | Alabama | Barbour | 27,457 |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 美国 | 阿拉巴马州 | 巴伯 | 27,457 |'
- en: '| 3 | USA | Alabama | Bibb | 22,915 |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 美国 | 阿拉巴马州 | 比布 | 22,915 |'
- en: The first index, for the rows, works much like the index array in a series.
    The second keeps track of the series of labels, with each label representing a
    column header. DataFrames also resemble dictionaries; the column names form the
    keys, and the series of data in each column forms the values. Like series, DataFrames
    come with many attributes and methods. For more information on these, see *[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)*.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个索引用于行，类似于序列中的索引数组。第二个索引用于跟踪标签序列，每个标签表示一个列标题。DataFrame 也类似于字典；列名是键，每列中的数据序列是值。像序列一样，DataFrame
    拥有许多属性和方法。有关更多信息，请参见 *[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)*。
- en: By integrating index objects and labels into their structure, you can easily
    manipulate DataFrames. We’ll look at some of this functionality as we work through
    the classification problem. You can also get up to speed on the basics by visiting
    the “10 Minutes to pandas” tutorial at *[https://pandas.pydata.org/docs/user_guide/10min.html](https://pandas.pydata.org/docs/user_guide/10min.html)*.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将索引对象和标签集成到结构中，你可以轻松地操作数据框（DataFrames）。我们将在处理分类问题时查看一些这样的功能。你也可以通过访问“10分钟快速了解pandas”教程来掌握基础知识，网址为
    *[https://pandas.pydata.org/docs/user_guide/10min.html](https://pandas.pydata.org/docs/user_guide/10min.html)*。
- en: '**The Palmer Penguins Project**'
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**Palmer Penguins 项目**'
- en: The *Palmer Penguins dataset* consists of 342 observations of Antarctic penguins
    from three islands in the Palmer Archipelago ([Figure 20-1](ch20.xhtml#ch020fig1)).
    It was made available through the *Palmer Station Antarctica LTER* (*[https://pallter.marine.rutgers.edu/](https://pallter.marine.rutgers.edu/)*).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '*Palmer Penguins 数据集*包含了来自南极洲帕尔默群岛三个岛屿的342个企鹅观察数据（[图 20-1](ch20.xhtml#ch020fig1)）。该数据集通过*Palmer
    Station Antarctica LTER*（* [https://pallter.marine.rutgers.edu/](https://pallter.marine.rutgers.edu/)
    *）提供。'
- en: '![Image](../images/20fig01.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig01.jpg)'
- en: '*Figure 20-1: The location of Dream, Torgersen, and Biscoe Islands, Palmer
    Archipelago, Antarctica*'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-1：Dream、Torgersen 和 Biscoe 岛，帕尔默群岛，南极洲的位置*'
- en: Three different penguin species were sampled in the study. In order of decreasing
    body size, these are the Gentoo, Chinstrap, and Adélie ([Figure 20-2](ch20.xhtml#ch020fig2)).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 研究中采样了三种不同的企鹅物种。按体型从大到小排列，它们是信天翁企鹅、帽带企鹅和阿德利企鹅（[图 20-2](ch20.xhtml#ch020fig2)）。
- en: '![Image](../images/20fig02.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig02.jpg)'
- en: '*Figure 20-2: The three penguin species in the Palmer Penguins dataset, as
    drawn by Charles Joseph Hullmandel (courtesy of Wikimedia Commons)*'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-2：由查尔斯·约瑟夫·赫尔曼德尔（Charles Joseph Hullmandel）绘制的 Palmer Penguins 数据集中的三种企鹅物种（图片来自
    Wikimedia Commons）*'
- en: The goal of this project will be to generate a model to predict the species
    of penguin from a combination of morphological features such as flipper length
    and body mass. In machine learning, this is considered a *classification* problem.
    We’ll use pandas to load, explore, validate, and clean the data, seaborn to plot
    the data, and scikit-learn to produce the predictive model.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 本项目的目标是生成一个模型，通过翅膀长度、体重等形态特征的组合来预测企鹅物种。在机器学习中，这被认为是一个 *分类* 问题。我们将使用 pandas 加载、探索、验证和清理数据，使用
    seaborn 绘制数据，使用 scikit-learn 构建预测模型。
- en: '***The Project Outline***'
  id: totrans-51
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***项目大纲***'
- en: 'Data science projects like this one follow a series of logical steps, as listed
    here:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 像这样的数据科学项目遵循一系列逻辑步骤，如下所示：
- en: Frame the problem (the single most important step).
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义问题（最重要的一步）。
- en: Collect raw data and set up the project.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 收集原始数据并设置项目。
- en: Process the data (through cleaning, merging, infilling, reducing, and so on).
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 处理数据（通过清洗、合并、填充、简化等方式）。
- en: Explore the data.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 探索数据。
- en: Perform in-depth analysis and develop models and algorithms.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进行深入分析并开发模型和算法。
- en: Apply the models and present the project results.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用模型并展示项目结果。
- en: Jupyter Notebook is ideal for this process, as it can handle all the steps in
    order and is basically self-documenting. It can also be turned into a slideshow
    for presentations (as discussed in [Chapter 5](ch05.xhtml)).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Jupyter Notebook 非常适合此过程，因为它可以按顺序处理所有步骤，且基本上是自文档化的。它还可以转化为幻灯片用于展示（如[第5章](ch05.xhtml)中讨论的）。
- en: '***Setting Up the Project***'
  id: totrans-60
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***项目设置***'
- en: For this project, we’ll use Jupyter Notebook in a dedicated project folder.
    We’ll install Notebook and the scientific and plotting libraries using the naive
    approach, in other words, directly in a conda environment within the project folder
    (see [Chapter 5](ch05.xhtml)). In general, you use the naive approach when you
    want to work with *specific* and *persistent* versions of a library or application.
    We’re using it here for practice, as we’ve previously been focusing on the modular
    approach, in which Notebook is installed in the *base* environment.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本项目，我们将在专用项目文件夹中使用 Jupyter Notebook。我们将使用最简单的方式安装 Notebook 和科学绘图库，即直接在项目文件夹中的
    conda 环境中安装（参见[第5章](ch05.xhtml)）。通常，当你希望使用 *特定的* 和 *持久的* 版本库或应用程序时，会使用这种简单的方法。我们在这里使用它进行实践，因为之前我们一直专注于模块化方法，在这种方法中，Notebook
    安装在 *base* 环境中。
- en: Start by making a folder named *penguins* under your user directory. Although
    you can do this through Anaconda Navigator, the command line is more succinct,
    so we’ll use that going forward.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，在你的用户目录下创建一个名为 *penguins* 的文件夹。虽然你可以通过 Anaconda Navigator 执行此操作，但命令行更加简洁，因此我们接下来将使用命令行。
- en: 'To make the directories for the project, open Anaconda Prompt (in Windows)
    or a terminal (in macOS or Linux) and enter the following (using your own directory
    path):'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 要为项目创建目录，请打开 Anaconda 提示符（在 Windows 中）或终端（在 macOS 或 Linux 中），然后输入以下命令（请使用你自己的目录路径）：
- en: '[PRE0]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This makes a *penguins* directory with a *notebooks* subdirectory. Next, create
    a conda environment named *penguins_env* under the project directory, activate
    it, and install the libraries we’ll use (substituting your own path where needed):'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个名为 *penguins* 的目录，并在其中创建一个 *notebooks* 子目录。接下来，在项目目录下创建一个名为 *penguins_env*
    的 conda 环境，激活它，并安装我们将要使用的库（根据需要替换自己的路径）：
- en: '[PRE1]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: You now have a conda environment for the project that contains the notebook,
    pandas, python, scikit-learn, and seaborn packages. Remember from [Chapter 2](ch02.xhtml)
    that this environment is isolated and can’t “see” other packages on your system,
    such as those in the *base* environment.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你已经为项目创建了一个 conda 环境，其中包含 notebook、pandas、python、scikit-learn 和 seaborn 包。请记得在
    [第 2 章](ch02.xhtml) 中提到，这个环境是隔离的，不能“看到”系统中其他的包，例如 *base* 环境中的包。
- en: At this point, your *penguins_env* should be active, and your project directory
    structure should look like [Figure 20-3](ch20.xhtml#ch020fig3). We’ll be loading
    the dataset straight from seaborn, so there’s no need for a *data* folder.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，你的 *penguins_env* 应该已经激活，项目目录结构应该如 [图 20-3](ch20.xhtml#ch020fig3) 所示。我们将直接从
    seaborn 加载数据集，因此无需创建 *data* 文件夹。
- en: '![Image](../images/20fig03.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig03.jpg)'
- en: '*Figure 20-3: Directory structure for the penguins project*'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-3：penguins 项目的目录结构*'
- en: 'To create a notebook for the project, first navigate to the *notebooks* folder
    using Anaconda Prompt or the terminal:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 要为项目创建一个 notebook，首先使用 Anaconda 提示符或终端导航到 *notebooks* 文件夹：
- en: '[PRE2]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'To launch Notebook, enter the following:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 要启动 Notebook，输入以下命令：
- en: '[PRE3]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: You should now see the Jupyter dashboard in your browser. Click the **New**
    button and choose **Python[conda env:penguins_env]** to create a new notebook.
    A new notebook should appear in your browser. Click **Untitled**, name it *penguins_project*,
    and then click the **Save** button. You’re ready to go!
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你应该在浏览器中看到 Jupyter 仪表板。点击 **New** 按钮，选择 **Python[conda env:penguins_env]**
    来创建一个新的 notebook。一个新的 notebook 应该会在浏览器中出现。点击 **Untitled**，将其命名为 *penguins_project*，然后点击
    **Save** 按钮。你准备好了！
- en: '**NOTE**'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*If you want to open the notebook in the future using Anaconda Navigator, launch
    Navigator, use the Environments tab to activate penguins_env, and then click the
    Launch button on the Jupyter Notebook tile. This will open the dashboard, where
    you can navigate to the notebook folder and launch penguins_project.ipynb. If
    you want to use Notebook in JupyterLab, see the instructions in [Chapter 6](ch06.xhtml)
    for installing JupyterLab and launching Notebook.*'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你以后想使用 Anaconda Navigator 打开 notebook，请启动 Navigator，使用 Environments 标签激活
    penguins_env，然后点击 Jupyter Notebook 磁贴上的 Launch 按钮。这将打开仪表板，你可以导航到 notebook 文件夹并启动
    penguins_project.ipynb。如果你想在 JupyterLab 中使用 Notebook，请参阅 [第 6 章](ch06.xhtml) 中的
    JupyterLab 安装和启动 Notebook 的说明。*'
- en: '***Importing Packages and Setting Up the Display***'
  id: totrans-78
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***导入包和设置显示***'
- en: 'In the first notebook cell, import Matplotlib, seaborn, and pandas. Enter the
    following code and execute it using SHIFT-ENTER, which automatically moves you
    to a new blank cell:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一个 notebook 单元格中，导入 Matplotlib、seaborn 和 pandas。输入以下代码并使用 SHIFT-ENTER 执行，它会自动跳转到一个新的空白单元格：
- en: '[PRE4]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**NOTE**'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*Normally, we would perform all the imports here, but for the sake of the narrative,
    we’ll import the scikit-learn components later, so we can discuss them just before
    applying them.*'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '*通常，我们会在这里执行所有导入操作，但为了叙述的方便，我们将在稍后导入 scikit-learn 组件，这样我们可以在应用它们之前讨论这些组件。*'
- en: By default, Notebook displays only one output per cell. The `%config` magic
    command overrides this, allowing us to see multiple outputs, such as a data table
    plus a bar chart, in a single output cell.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Notebook 每个单元格只显示一个输出。使用 `%config` 魔法命令可以覆盖此设置，使我们能够在一个单元格中看到多个输出，例如数据表和条形图。
- en: The default seaborn color palette is undeniably beautiful (see *[http://seaborn.pydata.org/tutorial/function_overview.html](http://seaborn.pydata.org/tutorial/function_overview.html)*),
    but it loses its charm somewhat in a black-and-white book. As a compromise, we’ll
    use the `whitegrid` stylesheet and reset the palette to black, red, and gray,
    one for each of the three penguin species in the dataset.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: seaborn 默认的颜色调色板无疑是美丽的（见 *[http://seaborn.pydata.org/tutorial/function_overview.html](http://seaborn.pydata.org/tutorial/function_overview.html)*），但在黑白书籍中，它的魅力略有失色。作为折中，我们将使用
    `whitegrid` 样式表，并将调色板重置为黑色、红色和灰色，每种颜色代表数据集中的三种企鹅物种。
- en: '***Loading the Dataset***'
  id: totrans-85
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***加载数据集***'
- en: Seaborn comes with a few practice datasets that are automatically downloaded
    during installation. These are all comma-separated values (*.csv*) files stored
    in a repository at *[https://github.com/mwaskom/seaborn-data/](https://github.com/mwaskom/seaborn-data/)*.
    If you ever need to get the dataset names, you can retrieve them by running `sns.get_dataset_names()`
    in a notebook or console (after importing seaborn, of course).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: seaborn 附带了一些练习数据集，这些数据集在安装时会自动下载。这些数据集都是逗号分隔值（*.csv*）文件，存储在 *[https://github.com/mwaskom/seaborn-data/](https://github.com/mwaskom/seaborn-data/)*
    仓库中。如果你需要获取数据集名称，可以通过在笔记本或控制台中运行 `sns.get_dataset_names()` 来检索（当然，前提是先导入 seaborn）。
- en: As a data analysis tool, pandas can read and write data stored in many types
    of media, such as files and databases ([Table 20-4](ch20.xhtml#ch020tab4)). Example
    syntax is `df = pd.read_excel('`filename.xlsx`')` and `df.to_excel('`filename.xlsx`'),`
    where `df` stands for *DataFrame*. For more options, visit *[https://pandas.pydata.org/docs/reference/io.html](https://pandas.pydata.org/docs/reference/io.html)*.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据分析工具，pandas 可以读取和写入存储在多种介质中的数据，如文件和数据库（见[表 20-4](ch20.xhtml#ch020tab4)）。示例语法为
    `df = pd.read_excel('`filename.xlsx`')` 和 `df.to_excel('`filename.xlsx`')`，其中
    `df` 代表 *DataFrame*。欲了解更多选项，请访问 *[https://pandas.pydata.org/docs/reference/io.html](https://pandas.pydata.org/docs/reference/io.html)*。
- en: In addition to the methods in [Table 20-4](ch20.xhtml#ch020tab4), the `read_table()`
    method reads tabular data, such as text *(.txt*) files, in which the values are
    separated by spaces or tabs. Python can generally detect the separator in use,
    but you can also pass it as an argument, for example, `sep='\t'` for a tab.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 除了[表 20-4](ch20.xhtml#ch020tab4)中的方法外，`read_table()`方法可以读取表格数据，例如文本 *(.txt*)
    文件，其中值由空格或制表符分隔。Python 通常能自动检测分隔符，但你也可以将分隔符作为参数传入，例如，`sep='\t'`表示制表符。
- en: '**Table 20-4:** Useful pandas I/O Methods'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**表 20-4：** 有用的 pandas I/O 方法'
- en: '| **Input (Reader)** | **Output (Writer)** |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| **输入（读取器）** | **输出（写入器）** |'
- en: '| --- | --- |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `read_csv()` | `to_csv()` |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| `read_csv()` | `to_csv()` |'
- en: '| `read_excel()` | `to_excel()` |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| `read_excel()` | `to_excel()` |'
- en: '| `read_hdf()` | `to_hdf()` |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| `read_hdf()` | `to_hdf()` |'
- en: '| `read_sql()` | `to_sql()` |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| `read_sql()` | `to_sql()` |'
- en: '| `read_json()` | `to_json()` |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| `read_json()` | `to_json()` |'
- en: '| `read_html()` | `to_html()` |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| `read_html()` | `to_html()` |'
- en: '| `read_stata()` | `to_stata()` |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| `read_stata()` | `to_stata()` |'
- en: '| `read_clipboard()` | `to_clipboard()` |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| `read_clipboard()` | `to_clipboard()` |'
- en: '| `read_pickle()` | `to_pickle()` |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| `read_pickle()` | `to_pickle()` |'
- en: Besides loading external sources, you can create a DataFrame from many different
    types of input. These include 2D `ndarray`s, lists of lists or tuples, list of
    dictionaries or series, an existing DataFrame, and more.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 除了加载外部数据源，你还可以从多种不同类型的输入中创建 DataFrame。这些包括 2D `ndarray`、列表的列表或元组、字典或系列的列表、现有的
    DataFrame 等。
- en: 'In spite of all these choices, we’ll use seaborn’s `load_dataset()` method
    to load the penguins dataset. This specialized method reads a CSV-format dataset
    from the seaborn repository and returns a pandas DataFrame object. Enter the following
    in the new cell and press SHIFT-ENTER:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有这么多选择，我们将使用 seaborn 的`load_dataset()`方法来加载企鹅数据集。这个专用方法从 seaborn 仓库中读取一个 CSV
    格式的数据集，并返回一个 pandas DataFrame 对象。在新的单元格中输入以下内容并按 SHIFT-ENTER：
- en: '[PRE5]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**NOTE**'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*In this notebook, I’m using simple comments, such as # Load penguins dataset,
    as cell headers. To make proper headers, you can add a Markdown cell before each
    code cell, as described in [Chapter 5](ch05.xhtml).*'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '*在本笔记本中，我使用了简单的注释，例如 # 加载企鹅数据集，作为单元格标题。为了制作合适的标题，你可以在每个代码单元格之前添加一个 Markdown
    单元格，如[第 5 章](ch05.xhtml)中所述。*'
- en: In the previous code, we assigned the DataFrame to a variable named `df`. This
    is handy, as the name reflects the datatype. There’s no reason why you couldn’t
    use another name, however, such as `penguins_df`.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们将 DataFrame 分配给名为 `df` 的变量。这是方便的，因为这个名称反映了数据类型。然而，你也可以使用其他名称，比如 `penguins_df`。
- en: '***Displaying the DataFrame and Renaming Columns***'
  id: totrans-107
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***显示 DataFrame 并重命名列***'
- en: 'The first thing you’ll want to do after loading the data is look at it. For
    larger datasets such as penguins, pandas will show you part of the top and part
    of the bottom of a DataFrame by default. To see an example, enter the following,
    and then press CTRL-ENTER to execute the cell without leaving it:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 加载数据后，首先你需要查看数据。对于像企鹅这样的较大数据集，pandas 默认会显示 DataFrame 的部分顶部和部分底部。要查看示例，输入以下内容，然后按
    CTRL-ENTER 执行单元格而不离开：
- en: '[PRE6]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'To see the entire DataFrame in a scrollable output cell, place this command
    at the top of the cell and rerun it: `pd.set_option(''display.max_rows'', None)`.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 要在可滚动的输出单元格中查看整个 DataFrame，将此命令放在单元格顶部并重新运行：`pd.set_option('display.max_rows',
    None)`。
- en: Calling the DataFrame displays all the columns along with the first five rows
    and last five rows ([Figure 20-4](ch20.xhtml#ch020fig4)). When possible, column
    names should be descriptive and short. However, this isn’t always an option, so
    let’s practice changing a column header.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 调用 DataFrame 会显示所有列及前五行和后五行数据（[图 20-4](ch20.xhtml#ch020fig4)）。如果可能，列名应该简洁且具有描述性。然而，这并非总是可行的，因此我们来练习更改列标题。
- en: '![Image](../images/20fig04.jpg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig04.jpg)'
- en: '*Figure 20-4: DataFrame head and tail display*'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-4：DataFrame 头部和尾部显示*'
- en: In the same cell, add the following code to rename the `sex` header to `gender`.
    The `inplace` argument tells pandas to alter the current DataFrame rather than
    return a copy. Press CTRL-SHIFT to execute the code and move to a new cell.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在同一个单元格中，添加以下代码以将 `sex` 列标题重命名为 `gender`。`inplace` 参数告诉 pandas 更改当前的 DataFrame，而不是返回一个副本。按
    CTRL-SHIFT 执行代码并跳转到新单元格。
- en: '[PRE7]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The `head()` method displays the first five rows in a DataFrame, as shown in
    [Figure 20-5](ch20.xhtml#ch020fig5). To see more, just pass it the number of rows
    you want to see as an argument.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '`head()` 方法显示 DataFrame 中的前五行，如[图 20-5](ch20.xhtml#ch020fig5)所示。要查看更多行，只需将你想查看的行数作为参数传递给它。'
- en: '![Image](../images/20fig05.jpg)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig05.jpg)'
- en: '*Figure 20-5: The head of the DataFrame after changing the sex column header
    to gender*'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-5：更改 sex 列标题为 gender 后的 DataFrame 头部*'
- en: 'In [Figure 20-4](ch20.xhtml#ch020fig4) the number of rows and columns is included
    at the bottom of the output. You might immediately notice an issue: there are
    344 rows, but earlier, I stated that the dataset has 342 observations. The discrepancy
    could be due to one of two common dataset problems: duplicate or missing values.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图 20-4](ch20.xhtml#ch020fig4)中，输出底部包含了行数和列数。你可能会立即注意到一个问题：有344行数据，但之前我提到数据集有342个观察值。这一差异可能是由两个常见的数据集问题引起的：重复或缺失值。
- en: '***Checking for Duplicates***'
  id: totrans-120
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***检查重复数据***'
- en: It’s not uncommon for data rows to become duplicated by accident. This can happen
    during the initial creation of a dataset, in later edits, or during data transfers
    and transformations. You should remove this redundant data before you begin an
    analysis because it takes up memory, slows processing speeds, and distorts statistics
    due to the overweighting of the duplicate values.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 数据行意外重复并不罕见。这可能发生在数据集初次创建时，之后的编辑中，或在数据传输和转换过程中。在开始分析之前，你应该删除这些冗余数据，因为它占用了内存，降低了处理速度，并由于重复值的过度权重而扭曲统计数据。
- en: 'Fortunately, pandas comes with the `duplicated()` method for finding duplicate
    rows. In the new cell, enter the following and then press CTRL-ENTER:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，pandas 提供了 `duplicated()` 方法来查找重复的行。在新单元格中输入以下内容，然后按 CTRL-ENTER 执行：
- en: '[PRE8]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'You should get the following output, as there are no duplicate rows:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该会得到以下输出，因为没有重复行：
- en: '[PRE9]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Had there been any duplicates in the dataset, we could have removed them using
    the `drop_duplicates()` method, like so:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据集中存在重复项，我们可以使用 `drop_duplicates()` 方法将其移除，方法如下：
- en: '[PRE10]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'You can also look across specific columns for duplicate values. At the bottom
    of the current cell, enter the following and execute it by pressing SHIFT-ENTER:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以查看特定列中的重复值。在当前单元格底部输入以下内容，并通过按 SHIFT-ENTER 执行：
- en: '[PRE11]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Note that the inner square brackets define a Python list with column names,
    whereas the outer brackets represent “selection brackets” used to select data
    from a pandas DataFrame. We specified four of the seven columns, producing the
    output in [Figure 20-6](ch20.xhtml#ch020fig6).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，内部的方括号定义了一个包含列名的 Python 列表，而外部的方括号表示“选择括号”，用于从 pandas DataFrame 中选择数据。我们指定了七列中的四列，产生了[图
    20-6](ch20.xhtml#ch020fig6)中的输出。
- en: '![Image](../images/20fig06.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig06.jpg)'
- en: '*Figure 20-6: Row with duplicate values across the four columns with the float
    data type*'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-6：四列浮动数据类型中具有重复值的行*'
- en: As you’ll see in a moment, row 339 is a duplicate of row 3 (for the four columns
    specified). But even though there are duplicate values here, they’re not the kind
    that we need to treat as duplicates. Instead, they represent *missing values*,
    which we’ll cover in the next section.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你马上就会看到的，第339行是第3行的重复（针对四个指定的列）。但是，尽管这里有重复值，它们并不是我们需要当作重复数据来处理的类型。相反，它们表示*缺失值*，我们将在下一节讨论这个问题。
- en: '***Handling Missing Values***'
  id: totrans-134
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***处理缺失值***'
- en: The duplicate values in [Figure 20-6](ch20.xhtml#ch020fig6) are represented
    by the *Not a Number* (`NaN`) value. This is a special floating-point value recognized
    by all systems that use the standard IEEE floating-point representation. For computational
    speed and convenience, it serves as the default missing value marker for both
    NumPy and pandas. `NaN` and Python’s built-in `None` value are essentially interchangeable.
    By default, these null values are not included in computations.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '[图20-6](ch20.xhtml#ch020fig6)中的重复值由*非数字*（`NaN`）表示。这是一个特殊的浮点值，所有使用IEEE标准浮点表示法的系统都能识别它。为了计算速度和便捷性，它作为NumPy和pandas的默认缺失值标记。`NaN`和Python的内建`None`值基本上是可以互换的。默认情况下，这些空值不会参与计算。'
- en: '**Finding Missing Values**'
  id: totrans-136
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**查找缺失值**'
- en: 'Missing data values reduce statistical power and can cause bias when estimating
    parameters and making predictions. To find the missing values in the penguins
    DataFrame, enter the following in a new cell and then press SHIFT-RETURN:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失数据值会减少统计效能，并且在估算参数和进行预测时可能引入偏差。要查找企鹅数据框中的缺失值，在一个新单元格中输入以下内容，然后按SHIFT-RETURN：
- en: '[PRE12]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The first method sums the missing values and displays the results as a table
    ([Figure 20-7](ch20.xhtml#ch020fig7)). The penguins dataset is missing 11 gender
    calls and a total of 8 morphological measurements.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个方法将缺失值求和并以表格形式显示结果（[图20-7](ch20.xhtml#ch020fig7)）。企鹅数据集缺失了11个性别标注和总计8个形态测量值。
- en: '![Image](../images/20fig07.jpg)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig07.jpg)'
- en: '*Figure 20-7: The output of df.isnull().sum()*'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '*图20-7：df.isnull().sum()的输出*'
- en: The second call indexes the DataFrame where a value in *any* column is missing
    (as opposed to *all*). Remember, pandas is built on NumPy, so axis 1 refers to
    columns and axis 0 refers to rows. You should get the result depicted in [Figure
    20-8](ch20.xhtml#ch020fig8).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 第二次调用会索引DataFrame，其中*任何*列的值缺失（而不是*所有*列）。记住，pandas是基于NumPy构建的，因此轴1指的是列，轴0指的是行。你应该得到[图20-8](ch20.xhtml#ch020fig8)中所示的结果。
- en: '![Image](../images/20fig08.jpg)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig08.jpg)'
- en: '*Figure 20-8: All the DataFrame rows containing missing data*'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '*图20-8：所有包含缺失数据的DataFrame行*'
- en: '**Filling and Removing Missing Values**'
  id: totrans-145
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**填充和删除缺失值**'
- en: Missing values must be addressed before you try to conduct analyses or build
    models from a dataset. Although ignoring the issue is a possibility, it’s much
    better to either fill in the missing values or remove (drop) them completely.
    Methods for doing this are listed in [Table 20-5](ch20.xhtml#ch020tab5).
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在你尝试从数据集进行分析或构建模型之前，必须处理缺失值。虽然忽略这个问题是一个选择，但最好是填补缺失值或完全删除它们。处理方法列出了在[表20-5](ch20.xhtml#ch020tab5)中。
- en: '**Table 20-5:** Useful Methods for Handling Missing Data'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '**表20-5：** 处理缺失数据的有用方法'
- en: '| **Method** | **Description** |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| **方法** | **描述** |'
- en: '| --- | --- |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `dropna` | Depending on arguments, remove row or column that contains missing
    data based on whether any or all values are null. |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| `dropna` | 根据参数，移除包含缺失数据的行或列，依据是任何值或所有值是否为空。 |'
- en: '| `fillna` | Fill in missing value with a constant or an interpolation method.
    Arguments include the `ffill` and `bfill` methods. |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| `fillna` | 用常数值或插值方法填充缺失值。参数包括`ffill`和`bfill`方法。 |'
- en: '| `ffill` | “Forward fill” by propagating the last valid observation forward.
    |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| `ffill` | “向前填充”通过将最后一个有效观察值向前传播。 |'
- en: '| `bfill` | “Back fill” by replacing missing values with values from the next
    row or column, as specified. |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| `bfill` | “向后填充”通过用下一个行或列中的值来替代缺失值，如所指定的那样。 |'
- en: '| `isnull` | Return Boolean indicating missing/NA values. |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| `isnull` | 返回布尔值，指示缺失/NA值。 |'
- en: '| `notnull` | Negate `isnull`. |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| `notnull` | 否定`isnull`。 |'
- en: 'Options for filling in the missing values with `fillna()` include replacing
    them with the mean, median, or most frequent values in the dataset so that the
    overall statistics aren’t skewed. For example, to use the mean value of a column,
    you would use this syntax (don’t add this to your project code):'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`fillna()`填补缺失值的选项包括用数据集中的均值、中位数或最频繁值来替换它们，从而避免整体统计数据的偏差。例如，要使用列的均值，你可以使用以下语法（不要将其添加到你的项目代码中）：
- en: '[PRE13]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '**NOTE**'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*The pandas library tries to mimic the R programming language, and the na in
    the fillna() method stands for the NA (not available) marker used for missing
    data in R.*'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '*pandas库试图模仿R编程语言，而fillna()方法中的na代表R中用于表示缺失数据的NA（不可用）标记。*'
- en: Filling in the missing data is important when a dataset is small and you need
    to take into account every observation. And if only a single column among many
    is missing a value, you might not want to “throw away” all the other useful data
    in the row.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 填充缺失数据对于数据集较小且需要考虑每一个观测值的情况非常重要。如果在众多列中只有一列缺少值，你可能不希望“丢弃”行中其他所有有用的数据。
- en: 'Because we have a robust dataset and can’t easily impute and replace missing
    gender data, we’ll *drop* the rows with missing data. In the new cell, enter the
    following and then press SHIFT-ENTER:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们拥有一个强大的数据集，且无法轻易插补和替换缺失的性别数据，因此我们将*删除*包含缺失数据的行。在新单元格中输入以下内容，然后按SHIFT-ENTER：
- en: '[PRE14]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Using an assignment statement when calling `dropna()` causes the current DataFrame
    (`df`) to be overwritten. This allows the DataFrame to evolve over time, but be
    aware that to erase changes and restore the DataFrame to its previous state, you’ll
    need to run all the cells above the current cell. Passing a `how` argument of
    `any` to `dropna()` means that any row with at least one missing value will be
    deleted.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 使用赋值语句调用`dropna()`会导致当前的DataFrame（`df`）被覆盖。这使得DataFrame可以随着时间变化，但需要注意的是，要撤销更改并恢复DataFrame的先前状态，你需要运行当前单元格上方的所有单元格。将`how`参数设置为`any`传递给`dropna()`意味着任何包含至少一个缺失值的行都会被删除。
- en: To check the results, rerun the `isnull()` method. You should get the output
    in [Figure 20-9](ch20.xhtml#ch020fig9).
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查结果，重新运行`isnull()`方法。你应该会得到[图 20-9](ch20.xhtml#ch020fig9)中的输出。
- en: '![Image](../images/20fig09.jpg)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig09.jpg)'
- en: '*Figure 20-9: A summary of null values after dropping nulls*'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-9：删除空值后空值的总结*'
- en: The DataFrame no longer includes missing values.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrame中不再包含缺失值。
- en: '**Reindexing**'
  id: totrans-168
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**重新索引**'
- en: '*Reindexing* refers to the process of making data conform to a given set of
    labels along a particular axis. Missing value markers will be automatically inserted
    in label locations where no data for the label exists.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '*重新索引*是指使数据符合特定轴上给定标签集的过程。在标签位置上没有数据时，缺失值标记会自动插入。'
- en: 'When we dropped the rows with null values in the previous section, we also
    deleted their corresponding indexes. To see the result, run the following code
    in the new cell and press SHIFT-ENTER:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在上一部分删除了带有空值的行时，我们也删除了它们相应的索引。要查看结果，请在新单元格中运行以下代码并按SHIFT-ENTER：
- en: '[PRE15]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: As you can see in [Figure 20-10](ch20.xhtml#ch020fig10), there is a gap in the
    DataFrame index (leftmost column) where row 3, which contained a null value, was
    dropped.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 如[图 20-10](ch20.xhtml#ch020fig10)所示，DataFrame的索引（最左侧的列）中存在一个空隙，这是因为包含空值的第3行被删除了。
- en: '![Image](../images/20fig10.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig10.jpg)'
- en: '*Figure 20-10: Dropping rows results in missing DataFrame indexes.*'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-10：删除行导致缺失的DataFrame索引。*'
- en: To restore the indexes, run the following and then execute the cell using SHIFT-ENTER.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 若要恢复索引，请运行以下代码并使用SHIFT-ENTER执行该单元格。
- en: '[PRE16]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'In the `reset_index()` method, `drop=True` signals that the old index isn’t
    preserved as a new column in the DataFrame, because there’s no need to keep that
    information. The `inplace=True` argument means that the method adjusts the current
    DataFrame rather than returning a copy. As an alternative, you could simply reassign
    the DataFrame, like so:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在`reset_index()`方法中，`drop=True`表示旧的索引不会作为新列保留在DataFrame中，因为不需要保留该信息。`inplace=True`参数表示该方法会直接修改当前的DataFrame，而不是返回一个副本。作为替代，你也可以简单地重新分配DataFrame，如下所示：
- en: '[PRE17]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Calling the `head()` method shows that the indexes are now consecutively ordered
    ([Figure 20-11](ch20.xhtml#ch020fig11)).
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 调用`head()`方法显示索引现在按顺序排列（[图 20-11](ch20.xhtml#ch020fig11)）。
- en: '![Image](../images/20fig11.jpg)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig11.jpg)'
- en: '*Figure 20-11: The DataFrame head after reindexing*'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-11：重新索引后的DataFrame头部*'
- en: Pandas includes several other reindexing functions, such as `reindex()` and
    `reindex_like()`. You can find these, and other DataFrame functions, at *[https://pandas.pydata.org/pandas-docs/stable/reference/frame.html](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html)*.
    For more on missing values, see *[https://pandas.pydata.org/docs/user_guide/missing_data.html](https://pandas.pydata.org/docs/user_guide/missing_data.html)*.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas 包含了其他几个重新索引的函数，如 `reindex()` 和 `reindex_like()`。你可以在 *[https://pandas.pydata.org/pandas-docs/stable/reference/frame.html](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html)*
    找到这些函数和其他 DataFrame 函数。关于缺失值的更多内容，请参见 *[https://pandas.pydata.org/docs/user_guide/missing_data.html](https://pandas.pydata.org/docs/user_guide/missing_data.html)*。
- en: '***Exploring the Dataset***'
  id: totrans-183
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***探索数据集***'
- en: At this point, you’ve cleaned the data by checking for duplicates, removing
    missing values, and reindexing the DataFrame. Of course, there might still be
    problems, such as incorrect values (a penguin body mass of one million grams,
    for example). Catching and correcting these requires an exploration of the dataset,
    and pandas and seaborn provide several methods to aid you in this process. These
    same methods will help you to understand the dataset so that you can formulate
    a plan for addressing the project goal.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 到这一步，你已经通过检查重复项、移除缺失值和重新索引 DataFrame 来清理了数据。当然，仍然可能存在问题，比如错误的值（例如，企鹅的体重为一百万克）。捕捉并纠正这些问题需要对数据集进行探索，pandas
    和 seaborn 提供了多种方法来帮助你完成这一过程。这些方法还将帮助你理解数据集，从而为解决项目目标制定计划。
- en: '**Describing the DataFrame**'
  id: totrans-185
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**描述 DataFrame**'
- en: 'Let’s explore the DataFrame using a combination of tables and graphs. To begin,
    we’ll look at the data types in play and overall statistics. In a new cell, enter
    the following and then press SHIFT-ENTER:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过表格和图表的结合来探索 DataFrame。首先，我们将查看使用的数据类型和总体统计信息。在一个新的单元格中，输入以下内容并按下 SHIFT-ENTER：
- en: '[PRE18]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This produces the output shown in [Figure 20-12](ch20.xhtml#ch020fig12).
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成如[图 20-12](ch20.xhtml#ch020fig12)所示的输出。
- en: '![Image](../images/20fig12.jpg)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/20fig12.jpg)'
- en: '*Figure 20-12: Output of the dtypes() and describe() methods*'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-12：dtypes() 和 describe() 方法的输出*'
- en: The `describe()` method returns a quick-look statistical overview of the DataFrame.
    Passing it `all` produces a statistical summary of *all* the columns. If you omit
    the `include` argument, you’ll see only a summary of the *numeric* columns.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '`describe()` 方法返回 DataFrame 的快速统计概览。传入 `all` 会生成 *所有* 列的统计摘要。如果省略 `include`
    参数，则只会显示 *数值* 列的摘要。'
- en: The `NaN` values present in the table represent *not applicable* values rather
    than missing values. For example, you can’t take the mean of a categorical feature
    like `species`, so the result is presented as `NaN`.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 表中存在的 `NaN` 值表示 *不适用* 值，而不是缺失值。例如，你不能对一个像 `species` 这样的类别特征计算均值，因此结果显示为 `NaN`。
- en: The stats table doesn’t tell you if every value in the dataset is valid, but
    it does help bracket how good or bad things can be. If the minimum, maximum, and
    mean values appear to be reasonable, the dataset is probably reliable.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 统计表不会告诉你数据集中的每个值是否有效，但它有助于框定事情的好坏。如果最小值、最大值和均值看起来合理，那么数据集可能是可靠的。
- en: '**Counting Observations Using countplot**'
  id: totrans-194
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**使用 countplot 计数观察值**'
- en: Tables of data, although useful, can be dense and difficult to interpret. For
    example, is the data skewed toward male or female penguins? The information is
    there, but you must work to back it out.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 数据表虽然有用，但可能密集且难以解读。例如，数据是偏向雄性还是雌性企鹅？这些信息是存在的，但你需要努力去提取它。
- en: In these cases, it’s beneficial to create a visualization of the data. The seaborn
    library provides many statistical plot types for data exploration ([Table 20-6](ch20.xhtml#ch020tab6)).
    You can see examples of these in the seaborn gallery (*[https://seaborn.pydata.org/examples/index.html](https://seaborn.pydata.org/examples/index.html)*),
    and you can find a plotting tutorial at *[https://seaborn.pydata.org/tutorial.html](https://seaborn.pydata.org/tutorial.html)*.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些情况下，创建数据的可视化是有益的。seaborn 库提供了许多用于数据探索的统计图表类型（[表 20-6](ch20.xhtml#ch020tab6)）。你可以在
    seaborn 画廊中查看这些示例 (*[https://seaborn.pydata.org/examples/index.html](https://seaborn.pydata.org/examples/index.html)*)，并且可以在
    *[https://seaborn.pydata.org/tutorial.html](https://seaborn.pydata.org/tutorial.html)*
    找到绘图教程。
- en: '**Table 20-6:** Useful seaborn Plotting Methods'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '**表 20-6：有用的 seaborn 绘图方法**'
- en: '| **Method** | **Description** |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| **方法** | **描述** |'
- en: '| --- | --- |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `barplot()` | Categorical data presented with bars whose heights or lengths
    are proportional to the values that they represent. |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
- en: '| `boxplot()` | Graphical representation of the locality, spread, and skewness
    groups of numerical data through their quartiles. |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
- en: '| `countplot()` | A visualization of the counts of observations in each categorical
    bin using bars. |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
- en: '| `histplot()` | Series of bars used to bin and display continuous data in
    a categorical form. |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
- en: '| `jointgrid()` | Grid for drawing a bivariate plot with marginal univariate
    plots. |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
- en: '| `jointplot()` | `jointgrid()` wrapper for drawing `jointgrid()` of two variables
    using canned bivariate and univariate graphs. |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
- en: '| `lineplot()` | Graphical display of data along a number line where markers
    recorded above the responses indicate the number of occurrences. |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
- en: '| `pairgrid()` | Subplot grid for plotting pairwise relationships in a dataset.
    |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
- en: '| `pairplot()` | Easier-to-use wrapper for `pairgrid()`. |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
- en: '| `relplot()` | Function for visualizing statistical relationships using scatter
    plots and line plots |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
- en: '| `scatterplot()` | Graph that uses Cartesian coordinates to display values
    for two variables. Additional variables can be incorporated through marker coding
    (color/size/shape). |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
- en: '| `stripplot()` | A scatterplot for which one variable is categorical. |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
- en: '| `swarmplot()` | A stripplot with non-overlapping points. |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
- en: '| `violinplot()` | A combination of boxplot and kernel density estimate showing
    the distribution of quantitative data across several levels of one (or more) categorical
    variables. |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
- en: 'Let’s look at an example in which we plot the number of penguins and their
    gender. In a new cell, enter the following and then press SHIFT-ENTER:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: This produces the output in [Figure 20-13](ch20.xhtml#ch020fig13).
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: By visualizing the data, we can instantly see that the Chinstrap species is
    a bit underrepresented, and the division between genders is close to equal.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/20fig13.jpg)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
- en: '*Figure 20-13: Bar chart of penguin species and gender counts*'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: 'What about the distribution of penguins *per island*? Are they one big happy
    family, or do some prefer one island over another? To check, in a new cell, enter
    the following code and then press SHIFT-ENTER:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This code counts the penguins per island, presents the results in a bar chart,
    and colors the bars based on species ([Figure 20-14](ch20.xhtml#ch020fig14)).
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/20fig14.jpg)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
- en: '*Figure 20-14: Bar chart of the number of penguins sampled per island, colored
    by species*'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: Based on [Figure 20-14](ch20.xhtml#ch020fig14), we can see that the Adélie penguins
    live on all the islands, but the Chinstraps are found only on Dream Island, and
    the Gentoos only on Biscoe Island (see [Figure 20-1](ch20.xhtml#ch020fig1) for
    island locations). So, if you have measurements from Torgersen Island, you know
    you’re dealing with an Adélie. And the dimensional space is reduced for the other
    two islands, as you need to choose between only two species on both islands.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: '*An assumption here is that each island was thoroughly sampled. We’re saying
    that if a penguin species is not present in the dataset for a particular island,
    that species doesn’t live on that island. You’d want to verify this assumption
    in a real study, as absence of evidence is not evidence of absence.*'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '*这里的假设是每个岛屿都已被充分采样。我们假设如果某个岛屿的数据集中没有某种企鹅物种，说明该物种不在该岛屿上栖息。你应该在实际研究中验证这一假设，因为缺乏证据并不等于证据缺失。*'
- en: Another way to count each species per island is to use the pandas `get_dummies()`
    method in combination with the `groupby()` method. The first method converts categorical
    variables to *dummy variables*, which are numeric variables used to represent
    categorical data. The second method is used to group large amounts of data and
    compute operations on these groups.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种按岛屿统计每种物种的方法是结合使用 pandas 的 `get_dummies()` 方法和 `groupby()` 方法。第一个方法将分类变量转换为
    *虚拟变量*，这些是用于表示分类数据的数值变量。第二个方法用于对大量数据进行分组并对这些组执行操作。
- en: 'In this case, we want to *sum* the penguin species per island, so we chain
    the methods and pass them the `species` column grouped by the `island` column,
    followed by the `sum()` method. In a new cell, enter the following code and then
    press SHIFT-ENTER:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们希望按岛屿 *汇总* 企鹅物种，因此我们将方法链式调用，并将按 `island` 列分组的 `species` 列传递给它，接着使用
    `sum()` 方法。在新的单元格中输入以下代码，然后按 SHIFT-ENTER：
- en: '[PRE21]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The call to `print()` lets you see the names of the new “dummy” columns (highlighted
    in bold):'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 调用 `print()` 可以让你看到新“虚拟”列的名称（以粗体显示）：
- en: '[PRE22]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The final line of code displays the new columns in the `count_df` DataFrame
    ([Figure 20-15](ch20.xhtml#ch020fig15)).
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的最后一行显示了 `count_df` 数据框中的新列（[图 20-15](ch20.xhtml#ch020fig15)）。
- en: '![Image](../images/20fig15.jpg)'
  id: totrans-234
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/20fig15.jpg)'
- en: '*Figure 20-15: The count_df DataFrame that sums columns per island per penguin
    species*'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-15：按岛屿和企鹅物种汇总列的 count_df 数据框*'
- en: An advantage of checking tabular data is that low values are just as apparent
    as high values. With a bar chart, very low values may be mistaken for 0, due to
    the shortness of the bars.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 检查表格数据的一个优势是，低值和高值同样显而易见。而在条形图中，低值可能会被误认为是 0，因为条形的高度较短。
- en: You can read more about the `get_dummies()` and `groupby()` methods at *[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html)*
    and *[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html)*,
    respectively.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 *[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html)*
    和 *[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html)*
    上阅读更多关于 `get_dummies()` 和 `groupby()` 方法的信息。
- en: '**Getting the Big Picture with pairplot**'
  id: totrans-238
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**通过 pairplot 获取整体图像**'
- en: Because visualizations are so effective for understanding data, seaborn provides
    the `pairplot()` method for plotting pairwise relationships in a dataset. This
    method creates a grid of axes where each variable shares the y-axis across a single
    row and the x-axis across a single column. This lets you quickly spot patterns
    in the data.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 由于可视化对于理解数据非常有效，seaborn 提供了 `pairplot()` 方法，用于绘制数据集中变量之间的成对关系。此方法创建一个坐标轴网格，其中每个变量在单独的一行共享
    y 轴，在单独的一列共享 x 轴。这样可以帮助你快速发现数据中的模式。
- en: 'To make a pairplot, in a new cell, enter the following code and then press
    SHIFT-ENTER:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建 pairplot，在新的单元格中输入以下代码，然后按 SHIFT-ENTER：
- en: '[PRE23]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The arguments here are the name of the DataFrame, the column used to color the
    plots, and the marker types. You can find a list of marker types at *[https://matplotlib.org/stable/api/markers_api.html](https://matplotlib.org/stable/api/markers_api.html)*.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的参数是数据框的名称、用于为图形着色的列和标记类型。你可以在 *[https://matplotlib.org/stable/api/markers_api.html](https://matplotlib.org/stable/api/markers_api.html)*
    上找到标记类型的列表。
- en: Because the dataset contains only four numeric columns, the pairplot ([Figure
    20-16](ch20.xhtml#ch020fig16)) is very accessible and easy to consume.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据集只有四列数值型数据，pairplot（[图 20-16](ch20.xhtml#ch020fig16)）非常直观且易于理解。
- en: '![Image](../images/20fig16.jpg)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/20fig16.jpg)'
- en: '*Figure 20-16: The pairplot for the penguins dataset*'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-16：企鹅数据集的 pairplot*'
- en: The pairplot makes it easy to see data distributions and relationships. For
    example, the scatterplots where the points cluster into separate groups are important
    because they indicate that classification strategies such as principal component
    analysis (PCA) and *k*-nearest neighbors should be able to distinguish one species
    from another. Scatterplots with linear relationships, like flipper length versus
    body mass, suggest that regression techniques could predict one of these features
    when the other is known.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: '**Digging into Details with scatterplot**'
  id: totrans-247
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Despite being packed with information, even a pairplot can’t tell the whole
    story. For example, what role does gender play in determining the body mass and
    bill length of each species? To explore this, you’ll need more detailed plots.
    In a new cell, enter the following and press SHIFT-ENTER:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: In the call to `scatterplot()`, the `hue`, `style`, and `size` arguments control
    marker color, shape, and size, respectively. The first two are based on `species`,
    and the latter on `gender`; thus, data points representing female penguins are
    sized differently than males of the same species. Calling `legend()` with the
    `bbox_to_anchor` argument prevents the legend from posting over the plot and obscuring
    some of the data. You should get the results in [Figure 20-17](ch20.xhtml#ch020fig17).
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/20fig17.jpg)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
- en: '*Figure 20-17: A scatterplot of bill length versus body mass, colored by species
    and sized by gender*'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: This plot shows that the female of each species tends to be smaller, with shorter
    bills and lower body mass than the males. Bill length also appears to be more
    strongly correlated with body mass for the Adélie and Gentoo species, regardless
    of gender.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: You can learn more about the scatterplot at *[https://seaborn.pydata.org/generated/seaborn.scatterplot.html](https://seaborn.pydata.org/generated/seaborn.scatterplot.html)*.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: '**Investigating Categorical Scatter Using boxplot and stripplot**'
  id: totrans-255
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'We can explore the gender relationships further using different types of plots
    such as *box plots* and *strip plots*. To make a box plot, in a new cell, enter
    the following code and then press SHIFT-ENTER:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: This produces the plot in [Figure 20-18](ch20.xhtml#ch020fig18).
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/20fig18.jpg)'
  id: totrans-259
  prefs: []
  type: TYPE_IMG
- en: '*Figure 20-18: A box-and-whisker plot of penguin body mass by species by gender*'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: Box plots provide insight on the symmetry, grouping, and skewness of data. Each
    box encompasses the first through third quartiles of the data distribution, with
    the vertical line within the box marking the median value. The “whiskers” extend
    to show the rest of the distribution, except for points that are considered “outliers,”
    which are represented by diamonds.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: Based on the box plot in [Figure 20-18](ch20.xhtml#ch020fig18), Adélie and Chinstrap
    penguins are similar in size and smaller than Gentoo penguins, and the females
    tend to be smaller for all species. There is overlap between the genders, however,
    meaning body mass alone cannot positively differentiate males from females.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 根据[图 20-18](ch20.xhtml#ch020fig18)中的箱型图，阿德利企鹅和帽带企鹅的体型相似，都比金图企鹅小，而且所有物种的雌性企鹅通常都比雄性小。然而，性别之间存在重叠，这意味着单靠体重不能明显区分雄性和雌性。
- en: 'The seaborn strip plot posts the actual data points rather than summarizing
    them, as in the box plot. Let’s examine bill length measurements in both species
    and genders. In a new cell, enter the following code and then press SHIFT-ENTER:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: seaborn 条形图会显示实际数据点，而不是像箱型图那样对数据进行总结。让我们来看看两种物种和性别的喙长测量值。在一个新的单元格中，输入以下代码，然后按
    SHIFT-ENTER：
- en: '[PRE26]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The `dodge` argument shifts points for each species to reduce overlap, making
    the plot easier to read ([Figure 20-19](ch20.xhtml#ch020fig19)).
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '`dodge` 参数会将每个物种的点进行偏移，从而减少重叠，使图表更易阅读（见[图 20-19](ch20.xhtml#ch020fig19)）。'
- en: '![Image](../images/20fig19.jpg)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/20fig19.jpg)'
- en: '*Figure 20-19: A strip plot of penguin bill length by species by gender*'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-19：按物种和性别分组的企鹅喙长条形图*'
- en: Based on the plot, we can see that the Adélie penguins have markedly shorter
    bills than the other two species. Gender differences are less distinct, though
    female penguins of all species tend to have shorter bills, on average.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 根据图表，我们可以看到，阿德利企鹅的喙比其他两种企鹅明显短。性别差异较小，尽管所有物种的雌性企鹅的喙通常较短，平均而言。
- en: '**Combining Views Using jointplot**'
  id: totrans-269
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**使用 jointplot 组合视图**'
- en: Another potentially characteristic feature of the penguins is the vertical thickness
    of the bill, referred to as its *depth*. You can see in [Figure 20-2](ch20.xhtml#ch020fig2)
    that Gentoos have narrow, pointed bills, whereas the other two species have more
    bulbous bills. Although there are numerous ways to compare these graphically,
    let’s try out a joint plot using a *kernel density estimation (KDE)*.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 企鹅的另一个可能的特征是喙的垂直厚度，称为其 *深度*。你可以在[图 20-2](ch20.xhtml#ch020fig2)中看到，金图企鹅的喙窄且尖，而其他两种物种的喙则更圆胖。尽管有许多方法可以通过图形进行比较，但我们将尝试使用
    *核密度估计（KDE）* 来绘制一个联合图。
- en: A KDE plot is a method for visualizing the distribution of observations in a
    dataset, much like a histogram. But whereas a histogram approximates the underlying
    probability density of the data by counting observations in discrete bins, a KDE
    plot smooths the observations using a Gaussian kernel, producing a continuous
    density estimate. This results in a less cluttered and more interpretable plot
    when drawing multiple distributions. The `joinplot()` method lets you plot two
    variables using bivariate and univariate KDE graphs.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: KDE 图是一种可视化数据集观察分布的方法，类似于直方图。但与直方图通过计数离散区间内的观察值来逼近数据的概率密度不同，KDE 图通过使用高斯核平滑观察值，从而产生连续的密度估计。这使得在绘制多个分布时，图表更简洁、更易于理解。`joinplot()`
    方法允许你使用双变量和单变量的 KDE 图来绘制两个变量。
- en: 'In a new cell, enter the following and then press SHIFT-ENTER:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个新的单元格中，输入以下内容，然后按 SHIFT-ENTER：
- en: '[PRE27]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: This produces the chart in [Figure 20-20](ch20.xhtml#ch020fig20).
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成[图 20-20](ch20.xhtml#ch020fig20)中的图表。
- en: '![Image](../images/20fig20.jpg)'
  id: totrans-275
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/20fig20.jpg)'
- en: '*Figure 20-20: A joint plot of bill depth versus bill length by species*'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20-20：按物种分组的喙深与喙长的联合图*'
- en: From the Gaussian curves along the edges of the joint plot, it’s clear that
    the Adélie is distinguished by its shorter bill length, and the Gentoo by its
    shallower bill depth.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 从联合图中沿边缘的高斯曲线可以看出，阿德利企鹅因其较短的喙长而有所区别，而金图企鹅则因其较浅的喙深而有所区别。
- en: You can customize joint plots in many ways. To see some examples, check out
    the documentation at *[http://seaborn.pydata.org/generated/seaborn.jointplot.html](http://seaborn.pydata.org/generated/seaborn.jointplot.html)*.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过多种方式自定义 jointplot。要查看一些示例，请查看文档中的 *[http://seaborn.pydata.org/generated/seaborn.jointplot.html](http://seaborn.pydata.org/generated/seaborn.jointplot.html)*。
- en: '**Visualizing Multiple Dimensions Using radviz**'
  id: totrans-279
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**使用 radviz 可视化多个维度**'
- en: The pandas library comes with its own plotting capability built on Matplotlib.
    This includes the `radviz()` (radial visualization) method for plotting multidimensional
    datasets in a 2D format ([Figure 20-21](ch20.xhtml#ch020fig21)).
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: pandas 库自带基于 Matplotlib 的绘图功能。这包括用于以二维格式绘制多维数据集的 `radviz()`（径向可视化）方法（见[图 20-21](ch20.xhtml#ch020fig21)）。
- en: '![Image](../images/20fig21.jpg)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/20fig21.jpg)'
- en: '*Figure 20-21: An example radviz plot for an automotive dataset*'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: In a radial visualization, the dimensions in a DataFrame, such as a penguin’s
    body mass or bill length, are evenly spaced around the circumference of a circle.
    Data in these numerical columns are normalized to values between 0 and 1 so that
    all dimensions have equal weights. These are then projected into the circular
    2D space as if imaginary springs anchor them to the column labels along the circumference.
    A point is plotted where the sum of the “spring” forces acting on it equals zero.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: Radial visualizations are intuitive by nature. Points with similar dimension
    values will plot near the center, as will points with similar values whose dimensions
    are opposite each other on the circle. Points with dimension values greater than
    others will be “pulled” toward that side of the circle. The penguins dataset has
    only four dimensions, but the `radviz()` method can handle many more.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: 'To make a radial visualization, in a new cell, enter the following and then
    press SHIFT-ENTER:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: For a better-looking radviz plot, reset the default seaborn plotting parameters
    using the `set_theme()` method and set the context to `'talk'` ➊. The `context`
    parameter controls the scaling of plot elements like label size and line thickness.
    The base context is `notebook`, and the other contexts are `paper`, `talk`, and
    `poster`, which are just versions of the `notebook` parameter scaled by different
    values. Using the `talk` argument ensures that the plot labels are easy to read.
    To better increase readability, manually set the figure size to 7" × 7".
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: Next, call pandas’ `plotting.radviz()` method ➋. This method accepts only one
    categorical column, called the `class_column`, which in this case will be `species`.
    The rest of the DataFrame columns are assumed to be numerical, so we must remove
    the `island` and `gender` columns, which don’t contain numerical data. You could
    do this by creating a copy of the DataFrame, but because we need only this revised
    DataFrame for plotting, we’ll temporarily delete the columns, using the `drop()`
    method, while passing the DataFrame to the `radviz()` method.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: 'The `drop()` method takes two arguments: the column names as a list, and the
    axis number, where 0 = row and 1 = column. Unless you pass it an `inplace=True`
    argument, the DataFrame will be changed for only the current operation.'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: Because we’re not plotting with seaborn, we need to remind pandas of the color
    scheme we’re using and then change the marker style and transparency to make over-posted
    points easier to see. Moving the legend to the side also helps. Notice how we’re
    able to mix in seaborn (`sns`) and Matplotlib’s `pyplot` (`plt`) with pandas `plotting`.
    This is because both seaborn and pandas are built on top of Matplotlib.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: You should see the plot depicted in [Figure 20-22](ch20.xhtml#ch020fig22).
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/20fig22.jpg)'
  id: totrans-292
  prefs: []
  type: TYPE_IMG
- en: '*Figure 20-22: Radviz plot for the penguins dataset*'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: In the plot, the Gentoo data points form a distinct cluster skewed toward body
    mass and flipper length. The similarly sized Chinstrap and Adélie penguins are
    distinguished mainly by bill length, which “pulls” the Chinstrap points to the
    right of center.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: The radviz plot is another way of exploring the data, and it becomes more useful
    with more dimensions. To read more about the pandas implementation, visit *[https://pandas.pydata.org/docs/reference/api/pandas.plotting.radviz.html](https://pandas.pydata.org/docs/reference/api/pandas.plotting.radviz.html)*.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: 'It’s worth noting here that we changed the plotting style. I’ll be continuing
    with this new look, but if you want to return to the previous `''whitegrid''`
    style, you’ll need to enter the following code in a new cell before making more
    plots:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '**Quantifying Correlations Using corr()**'
  id: totrans-298
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The pandas `DataFrame` class comes with a `corr()` method that quantifies data
    correlations by computing a pairwise correlation of columns, excluding NA/null
    values. This is useful when you plan to use regression techniques to make predictions.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: 'In a new cell, enter the following and then press SHIFT-ENTER:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The first line calls the `corr()` method and assigns the results to the correlations
    variable. The next line plots the results as a seaborn heatmap ([Figure 20-23](ch20.xhtml#ch020fig23)).
    The `center` argument is optional and tells the method the value at which to center
    the colormap when plotting divergent data. With a value of `1`, the best correlations
    will plot in black. The `annot` argument turns on the plot annotations within
    each colored square.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/20fig23.jpg)'
  id: totrans-303
  prefs: []
  type: TYPE_IMG
- en: '*Figure 20-23: The correlation heatmap*'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: The heatmap confirms and quantifies correlations that we noted in the pairplot
    ([Figure 20-16](ch20.xhtml#ch020fig16)). Flipper length and body mass are the
    most closely correlated, followed by flipper length and bill length.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: For more on the `corr()` method and seaborn heatmap, visit *[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html)*
    and *[https://seaborn.pydata.org/generated/seaborn.heatmap.html](https://seaborn.pydata.org/generated/seaborn.heatmap.html)*.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: '**TEST YOUR KNOWLEDGE**'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: 1.  Which of the following are advantages of pandas series or DataFrames over
    NumPy arrays?
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: a.  Ability to use heterogeneous data types
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: b.  Ability to use either numbers *or* labels as indexes
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: c.  Ability to load Python dictionaries
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: d.  Ease of use with tabular data
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: '2.  True or False: Reindexing is required after renaming columns in a DataFrame.'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: '3.  Convert the following dictionary into a DataFrame and rename the last column
    to “whales”:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: 'animals = {''canines'': [''husky'', ''poodle'', ''bulldog''],'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: '''felines'': [''Siamese'', ''Persian'', ''Maine Coon''],'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: '''cetaceans'': [''humpback'', ''sperm'', ''right'']}'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: 4.  Display the first row of the `animals` DataFrame from the previous question.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: '5.  Flip the rows and columns in the `animals` DataFrame (hint: look up the
    pandas `transpose()` method).'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: '***Predicting Penguin Species Using k-Nearest Neighbors***'
  id: totrans-320
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The goal of this project is to develop a model that classifies penguins based
    on the Palmer Archipelago dataset. Our data exploration has revealed that four
    morphological features (bill length and depth, flipper length, and body mass)
    form separate but overlapping clusters in numerous plots. This implies that a
    machine learning classification algorithm should be able to handle the problem.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: It’s always best to start simple, and if you do a little research, you’ll find
    that *k-Nearest Neighbors* (*k*-NN) is one of the most basic, beginner-friendly,
    yet important classification algorithms in machine learning. It uses distance
    measures to intuitively find the *k* nearest neighbors to a new, unknown data
    point and then uses those neighbors to make a prediction.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: In [Figure 20-24](ch20.xhtml#ch020fig24), numerical data points for two categorical
    classes (A and B) are plotted in a scattergram. A new and unlabeled data point
    (⋆) falls between the two clusters. To classify this new point, the algorithm’s
    *k* parameter has been set to 7\. As most of the closest points belong to Class
    B, the new data point will be assigned to B. Because this is a “voting” algorithm,
    *k* should always be set to an odd number to avoid a tie.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/20fig24.jpg)'
  id: totrans-324
  prefs: []
  type: TYPE_IMG
- en: '*Figure 20-24: Example of the k-NN algorithm choosing the seven nearest neighbors
    to a new data point*'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: Besides being intuitive and easy to explain, *k*-NN runs quickly, works well
    with small datasets, is robust to noise, and can be tuned for greater accuracy.
    It’s also versatile, given that it can be applied to both classification and regression
    problems.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
- en: The algorithm needs a dense dataset, however, so that points aren’t too far
    apart. The more data *dimensions* you have, like flipper length and body mass,
    the more data you need for *k*-NN to work properly.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
- en: In addition, *k*-NN, like other machine learning algorithms, requires its own
    data preparation routines. Because the algorithm works only with numerical data,
    you’ll commonly need to convert categorical values to integers and normalize numerical
    values between 0 and 1\. Normalization is needed so that dimensions with larger
    values don’t skew the distance calculations.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: '**Converting Categorical Data to Numerical Data**'
  id: totrans-329
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: As stated previously, the *k*-NN algorithm uses *numerical* data. To take advantage
    of important non-numerical data, such as the island of origin and gender, you
    need to convert these values into numbers.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s do this first for the `island` column, using the pandas `get_dummies()`
    method that we used previously when counting penguins per island. Next, we’ll
    repeat the exercise manually for gender so that you can practice DataFrame *indexing*.
    In a new cell, enter the following and then press SHIFT-ENTER:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: To use `get_dummies()`, pass it the DataFrame and the column label that you
    want to convert. Assign the result to a new DataFrame named `knn_df`. The method
    will create three new columns—one for each island—with values of either 0 or 1,
    depending on the value in the `island` column (either `Biscoe`, `Dream`, or `Torgersen`).
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
- en: Next, for demonstration purposes, we’ll use a different approach to convert
    the `gender` column to new `male` and `female` columns. We’ll create a new column
    for each class and fill it with zeros. Then, using conditional statements, we’ll
    find the rows where the targeted class exists and change the column values to
    ones. For example, the column for male penguins will contain `1` for rows in the
    `gender` column containing a male designation; for all other rows, the column
    will contain `0`.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
- en: Start by creating a new column named `male`. Assign to that column a value of
    `0` ➊. Next, use the pandas `loc` indexing operator to select a *subset* of the
    `knn_df` DataFrame. Because pandas can use both label-based and integer-based
    indexing for rows and columns, it comes with two indexing operators. The `loc`
    operator is for strictly label-based indexing, and the `iloc` operator handles
    cases in which the labels are strictly integers. In our case, the columns use
    labels (such as “species”) and the rows use integers.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
- en: The current operation will convert `Male` values in the `gender` column to `1`
    values in the `male` column. So, select the gender column (`knn_df['gender']`)
    and then use a conditional to overwrite the `0` values that we set in the previous
    line. What you’re saying here is, “get the `gender` column and, if its value is
    `Male`, put a `1` in the `male` column.”
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: Repeat this code for the female column and then check the results by using the
    `iloc` operator to sample rows throughout the DataFrame ➋. This works like indexing
    a list, for which you start at the beginning, go up to index 300, and use a step
    of 30 to select every 30th row.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: You should get the output in [Figure 20-24](ch20.xhtml#ch020fig24). Note the
    five new columns on the right side of the DataFrame. The categorical island and
    gender columns can now be used by the *k*-NN algorithm, so you can make use of
    all the data at your disposal.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/20fig25.jpg)'
  id: totrans-339
  prefs: []
  type: TYPE_IMG
- en: '*Figure 20-25: A sample of the new knn_df DataFrame with new numerical columns
    for islands and gender*'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: By converting the gender and island data to numbers, we’ve supplemented our
    morphological data with two more dimensions.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
- en: If your goal was to predict the species of penguins sampled at sea, you’d want
    to drop the island-related columns because you couldn’t be sure of a penguin’s
    point of origin.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: '**Setting Up the Training and Testing Data**'
  id: totrans-343
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The *k*-NN classifier is a *supervised* learning algorithm. This means that
    you show it what the answer *should* look like by providing a set of examples
    known as the “training” dataset. You can’t use all the available data for the
    training set, however, as you’ll have no objective way to test the results. Consequently,
    you need to randomly split out a smaller subset of the data that you can use to
    test the model’s accuracy.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: As a lazy learning algorithm, *k*-NN doesn’t have an actual training phase in
    which it “learns” a discriminative function to apply to new data. Instead, it
    loads, or memorizes, the data and performs calculations with it during the prediction
    phase.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
- en: 'For convenience, scikit-learn provides the `train_test_split()` method as part
    of the `sklearn.model_selection` module. In a new cell, enter the following and
    then press SHIFT-ENTER:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: After importing the module, call the pandas `select_dtypes()` method on the
    new `knn_df` DataFrame ➊. This method returns a subset of a DataFrame including
    or excluding columns based on their data type. We want the numerical columns for
    use with the *k*-NN algorithm, so set `include` equal to `'number'` and assign
    the result to a variable named `X`.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
- en: Next, assign the `species` column to a variable named `y`. This represents the
    categorical class you’re trying to predict. Note that the uppercase “X,” lowercase
    “y” format follows the convention in the scikit-learn documentation.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: Split out the training and testing data using the `train_test_split()` method
    ➋. You’ll need to unpack four variables for both `X` and `y` training and testing.
    Because we passed the method DataFrames, it will return DataFrames.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
- en: A key argument here is `test_size`, expressed as a proportion of the complete
    dataset. By default, this is 0.25, or 25 percent. So, for our penguins dataset,
    this represents 83 samples (332 × 0.25).
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
- en: To avoid biasing, the `train_test_split()` method randomly shuffles the data
    before splitting it. For reproducible output across multiple function calls, you
    can pass an integer to the `random_state` argument. As written, this code lets
    you produce one set of repeatable training and testing data. To generate a new
    random set, you’ll need to either change the `random_state` value or not use it
    at all.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
- en: Although we don’t need it here to get a good result, the `train_test_split()`
    method comes with a `stratify` parameter that ensures the split preserves the
    proportions of samples of each target class as observed in the original dataset.
    So, if the original dataset sampled 25 percent of Class A and 75 percent of Class
    B, the training and testing sets would reflect this proportion. This helps you
    avoid sampling bias, wherein a sample is not representative of the true population.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
- en: To read more about the `train_test_split()` method, visit *[https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)*.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
- en: '**Normalizing the Data**'
  id: totrans-355
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Each numerical data column in the training and testing sets should be normalized
    to values between 0 and 1\. This prevents columns with large numerical values
    from biasing the *k*-NN distance measurement.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
- en: 'Because column transformations, such as normalization, are a common operation
    in machine learning, scikit-learn comes with two modules, `compose` and `preprocessing`,
    to simplify the task. In a new cell, enter the following and then press SHIFT-ENTER:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Start by importing the `make_column_transformer()` method and the `MinMaxScaler()`
    method. The first method lets us transform columnar data; the second method specifies
    how to do it.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
- en: To normalize the data, scale it so that the minimum and maximum values fall
    between 0 and 1\. Pass the `make_column_transformer()` method the `MinMaxScaler()`
    method ➊. Next, pass it the columns that you want to transform; in this case,
    the numerical columns that aren’t already scaled to 0 and 1\. By default, the
    transformer *drops* columns that you didn’t specify in the previous argument.
    To prevent this, set the `remainder` argument to `passthrough`.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
- en: Now you need to apply the transformer by calling its `fit_transform()` method
    and passing it the `X_train` variable you made in the previous section. This method
    transforms the data and concatenates the results, returning an array. To convert
    this array back into a DataFrame, call pandas’ `DataFrame` class and pass it the
    `X_train` array ➋. The column transformer renames the columns as well as transforming
    them, so for the `columns` argument, call the `get_feature_names_out()` method
    on the `column_transformer` object.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
- en: Call `X_train.head()` to see the results, and then repeat this code for the
    testing set. The two DataFrame heads are shown in [Figure 20-26](ch20.xhtml#ch020fig26).
    In both, the columns should have new names, all the columns should contain numerical
    data, and values should fall between 0.0 and 1.0.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/20fig26.jpg)'
  id: totrans-363
  prefs: []
  type: TYPE_IMG
- en: '*Figure 20-26: The head of the normalized X_train and X_test DataFrames (shown
    horizontally truncated)*'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
- en: To read more about the scikit-learn column transformer, visit *[https://scikit-learn.org/stable/modules/generated/sklearn.compose.make_column_transformer.html](https://scikit-learn.org/stable/modules/generated/sklearn.compose.make_column_transformer.html)*.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
- en: You now have numbers-only DataFrames that can be used for training and testing.
    The `x_test` and `y_test` DataFrames let you relate these numerical DataFrames
    back to a species call. With only seven dimensions, this is a *low-dimensional*
    dataset. A *high-dimensional* dataset, common in machine learning, could have
    100,000-plus features!
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
- en: '**Running k-NN and Checking the Accuracy of the Prediction**'
  id: totrans-367
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: At this point, the data is ready to be used with the *k*-NN classifier. It’s
    time to name that penguin!
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
- en: 'In a new cell, enter the following code and then press SHIFT-ENTER:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: To run *k*-NN, you need to import the `KNeighborsClassifier` class from the
    scikit-learn `neighbors` module (*[https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)*).
    To check the results, import the `accuracy_score()` method from the `metrics`
    module.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
- en: Call the `KNeighborsClassifier` and pass it a `k` value of `5`, and a `p` value
    of `2`. The `p` value tells the classifier to use Euclidian, or straight-line,
    distance measurements. This is usually appropriate for low-dimensional datasets
    with few outliers.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
- en: Next, call the classifier’s `fit()` method to train it and then run the `predict()`
    method on the `X_test` dataset. This will take the measurement data you *withheld*
    from training and predict the species.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
- en: Finish by calling the `accuracy_score()` method and passing it the `y_test`
    and `predictions` variables. This method will compare the two datasets and store
    the accuracy measure in the `accuracy` variable, which you then print ([Figure
    20-27](ch20.xhtml#ch020fig27)).
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/20fig27.jpg)'
  id: totrans-375
  prefs: []
  type: TYPE_IMG
- en: '*Figure 20-27: The accuracy of the k-NN model*'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
- en: Right out of the gate, the model correctly matched about 99 percent of the samples
    in the `X_test` dataset. But don’t get too excited. It’s only matched samples
    in a *randomly chosen* subset of the `penguins` dataset. If you generate a new
    test set by changing the `train_test_split()` method’s `random_state` argument
    from `300` to `500` and rerun the cells, you’ll get an accuracy of `0.9642857142857143`.
    Although this is about as good as it gets for a real-world dataset, let’s use
    this discrepancy to see how you might handle a larger mismatch in a different
    project.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
- en: '**Optimizing the k Value Using Cross-Validation**'
  id: totrans-378
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The goal of supervised machine learning is to generalize *beyond* what we see
    in training samples so that we can reliably classify new data. The *k*-NN classifier
    uses numerous *hyperparameters* such as `k`, `p`, and `weights` to control the
    learning process. In addition, the `test_size` and other parameters in the `train_test_split()`
    method can have a big impact on model results. You can think of these parameters
    as knobs that you can turn to “tune” or “dial in” the model fit.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
- en: You must be careful however, not to tune things *too* finely. *Overfitting*
    is a common problem that can lurk behind an apparently accurate model ([Figure
    20-28](ch20.xhtml#ch020fig28)).
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/20fig28.jpg)'
  id: totrans-381
  prefs: []
  type: TYPE_IMG
- en: '*Figure 20-28: An example of model fits with original training set (left) and
    superimposed with new, unmatched training set (right)*'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
- en: In [Figure 20-28](ch20.xhtml#ch020fig28), the chart on the left shows three
    fits (over, under, and best) to a randomized training dataset. Any points that
    fall to the right of these lines will be classified as belonging to Class B.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
- en: If the left-hand chart represents all the data we would ever have, the overfitted
    model would be the most accurate. But look what happens when we choose and post
    a new training set (right side of [Figure 20-28](ch20.xhtml#ch020fig28)). Some
    points stay the same and others change, and the overfitted model no longer matches
    the data as well. On the other hand, the underfitted model can neither model the
    training data nor generalize sufficiently to match new data.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
- en: Typically, the smaller the *k* value, the “tighter” the fit of the model to
    the data and the more likely that it is overfit; the larger the *k* value, the
    more likely that the model is underfit.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
- en: In [Figure 20-28](ch20.xhtml#ch020fig28), the more generalized “Best fit” model
    does a good job of matching the two datasets. To achieve this generalized model,
    we’ll need to find the best values for the important hyperparameters. But this
    isn’t something that can be intuited when working in multidimensional space. It
    requires iterative investigation, where parameters are changed multiple times
    and the results are tabulated and scored.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
- en: In the code that follows, we’ll investigate a range of *k* values using *cross-validation*
    (*cv* for short). This is a model validation technique for assessing how the results
    of a statistical analysis will generalize to a new, unknown dataset. It also helps
    flag issues like overfitting.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
- en: Cross-validation resamples different parts of the training set to create testing
    sets. To ensure that the entire training set is evaluated, it repeats this sampling
    multiple times. As it iterates, it changes the value of a hyperparameter, like
    *k*, and scores the result based on model accuracy. When the optimal parameters
    are identified, you input them in the *k*-NN classifier and perform a final evaluation
    against the test dataset, which has been kept separate from the cv process ([Figure
    20-29](ch20.xhtml#ch020fig29)).
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/20fig29.jpg)'
  id: totrans-389
  prefs: []
  type: TYPE_IMG
- en: '*Figure 20-29: Building a predictive model using cross-validation (modified
    from [scikit-learn.org](http://scikit-learn.org))*'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
- en: 'To use cross-validation on our penguins dataset model, in a new cell, enter
    the following and then press SHIFT-ENTER:'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-392
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: We’ll use NumPy to make a range of *k* values to evaluate, and average, the
    results of each cv iteration. The `cross_validate()` method is found in the scikit-learn
    `model_selection` module.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
- en: Python dictionaries are great for storing data like test results, and they can
    easily be turned into pandas DataFrames. After the imports, create a dictionary
    named `cv_metrics` with keys for the average training set and cross-validation
    score per iteration. The initial values for these dictionary keys are empty lists.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, make a `num_neighbors` dictionary with one key-value pair: *k* and a
    1D `ndarray` from 1 to 25\. These represent the range of *k* values you’ll be
    testing.'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
- en: Loop through the `num_neighbors` dictionary and pass the current *k* value to
    the `KNeighborsClassifier` ➊. Then, call the `cross_validate()` method, pass it
    the `knn` model and the training data, and set the `return_train_score` argument
    to `True`. Finish each loop by appending the score results to the appropriate
    key in the `cv_metrics` dictionary. Use the NumPy `mean()` method to average the
    scores for each data point during the process.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
- en: Outside the loop, turn the `cv_metrics` dictionary into a DataFrame ➋ and then
    add the `num_neighbors` dictionary as a new column on the leftmost side of the
    DataFrame. Do this by calling the `insert()` method on the DataFrame and passing
    it the first column position (`loc=0`), the column name, and the value, obtained
    by passing the `num_neighbors` dictionary the `k` key. Finish by calling `head(10)`
    to display the first 10 rows.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
- en: Rather than scroll through the DataFrame looking for the *k* value with the
    best score, let pandas find it using the `idxmax()` method, which returns the
    index of the first occurrence of a maximum value over a requested axis. This is
    axis 0 (row) by default. When you print the result, you should see the output
    in [Figure 20-30](ch20.xhtml#ch020fig30).
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
- en: Comparing cross-validation and training scores can be insightful with respect
    to model overfitting and underfitting. The process is computationally expensive
    for high-dimensionality datasets, however, and the training scores are not required
    to select the best parameters.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/20fig30.jpg)'
  id: totrans-400
  prefs: []
  type: TYPE_IMG
- en: '*Figure 20-30: The first 10 rows in the cv_metrics DataFrame and the cv choice
    for best k value*'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
- en: 'To plot the cv results, in a new cell, enter the following and then press SHIFT-ENTER:'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-403
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The first line resets the seaborn color palette that we’ve been using for a
    consistent look. The next line prepares the DataFrame for plotting. In seaborn,
    plotting multiple columns against the same y-axis requires a call to the pandas
    `melt()` method. This method returns a new DataFrame reshaped into a long table
    with one row for each column. To learn about wide-form and long-form data, see
    *[https://seaborn.pydata.org/tutorial/data_structure.html](https://seaborn.pydata.org/tutorial/data_structure.html)*.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
- en: With the new `df_melt` DataFrame, you can call seaborn’s `lineplot()` method
    to get the plot in [Figure 20-31](ch20.xhtml#ch020fig31). The top curve represents
    the average training score.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/20fig31.jpg)'
  id: totrans-406
  prefs: []
  type: TYPE_IMG
- en: '*Figure 20-31: A comparison of the average training scores and cross-validation
    scores with the k value*'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
- en: 'If you expect to work extensively with pandas, consider learning its plotting
    syntax. For example, you can re-create [Figure 20-31](ch20.xhtml#ch020fig31) with
    a single line: `cv_metrics_df.plot.line(x=''k'')`. The plots are less customizable
    than with seaborn or Matplotlib, but they’re more than suitable for data exploration.
    To learn more, visit *[https://pandas.pydata.org/docs/getting_started/intro_tutorials/04_plotting.html](https://pandas.pydata.org/docs/getting_started/intro_tutorials/04_plotting.html)*.'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
- en: A model that is underfit will have both low training and low testing accuracy,
    whereas an overfit model will have a high training accuracy but a low testing
    accuracy. On the left side of [Figure 20-31](ch20.xhtml#ch020fig31), where *k*
    = 1, the training set is perfectly accurate because the training data point is
    compared only to itself. The cv results, however, are less accurate. This indicates
    slight overfitting, which we would expect with a low value of *k*.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
- en: On the right side of the figure, where *k* is greater than 20, accuracy falls
    off for both curves. The model is trying to accommodate too many data points and
    is becoming underfit.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
- en: When *k* = 4, the cv score reaches its highest average accuracy, and the two
    curves begin to meet and run parallel to each other. In this case, values of *k*
    between 5 and 10 will only add computational burden without increasing the model
    accuracy.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
- en: If you change the `random_state` or the `test_size` parameters in the `train_test_split()`method
    and rerun the code, you’ll see variations in the choice of best *k* value. This
    is because the model starts out with such high accuracy that subtle stochastic
    effects can have a large relative impact with essentially no absolute impact.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
- en: '**Optimizing Multiple Hyperparameters Using GridSearchCV**'
  id: totrans-413
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Running cross-validations can take time, so scikit-learn comes with a convenience
    class called `GridSearchCV`. It takes a dictionary of parameter names and values,
    cross-validates them, and reports the outcome. You can find the documentation
    at *[https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)*.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
- en: 'In a new cell, enter the following and then press SHIFT-ENTER:'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-416
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: A dictionary named `params` holds the hyperparameter ranges. In this example,
    the *k* (`n_neighbors`) range is a NumPy array, and the `weights` and `p` parameters
    use lists.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
- en: The `GridSearchCV` class needs to know the DataFrame you’re using (`knn`), the
    name of the parameters dictionary (`params`), what to score on (`accuracy`), and
    how much detail you want it to report. By passing it `verbose=1`, we suppressed
    most of the extraneous output.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
- en: After fitting the model, you can print the `best_params_` attribute to see the
    results ([Figure 20-32](ch20.xhtml#ch020fig32)).
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/20fig32.jpg)'
  id: totrans-420
  prefs: []
  type: TYPE_IMG
- en: '*Figure 20-32: Results of running GridSearchCV*'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
- en: Next, in a new cell, pass the best parameters identified by the grid search
    to the `KNeighborsClassifier`, fit the model, predict against the testing dataset,
    and evaluate the accuracy. This corresponds to the “retrained model” and “final
    evaluation” steps shown in [Figure 20-29](ch20.xhtml#ch020fig29).
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-423
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: You should get the output shown in [Figure 20-33](ch20.xhtml#ch020fig33).
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/20fig33.jpg)'
  id: totrans-425
  prefs: []
  type: TYPE_IMG
- en: '*Figure 20-33: Model accuracy after applying the optimized hyperparameters*'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
- en: You might notice that this score is worse than the one we got initially using
    `k=5` ([Figure 20-27](ch20.xhtml#ch020fig27)). That’s because this initial run
    on a *single* train-test dataset was equivalent to a lucky roll of dice. The current
    model built with `k=4` has been tested over *multiple* datasets and should, when
    used repeatedly, yield the same average accuracy as `k=5` (see [Figure 20-31](ch20.xhtml#ch020fig31))
    but with better computational efficiency.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
- en: Along these lines, we’ve used only 75 percent of the penguins dataset to train
    the model. How do we know that 80 percent wouldn’t produce better results? To
    find out, you could use a loop to run multiple combinations of the `test_size`
    and `random_state` parameters of the `train_test_split()` method and model each.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
- en: The need to test many parameter and dataset combinations, along with heavy memory
    use, renders the *k*-NN algorithm inappropriate for very large datasets. Otherwise,
    it has numerous benefits, including being simple to use, easy to understand, fast
    to train, versatile, and agnostic to assumptions about the underlying data distributions.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
- en: '**TEST YOUR KNOWLEDGE**'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
- en: '6.  For a big picture overview of a dataset, call the:'
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
- en: a.  seaborn `relplot()` method
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
- en: b.  pandas `radviz()` method
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
- en: c.  seaborn `pairplot()` method
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
- en: d.  seaborn `jointplot()` method
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
- en: '7.  The *k*-NN algorithm is appropriate for:'
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
- en: a.  Classification in high-dimensional datasets
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
- en: b.  Projects for which computer memory is at a premium
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
- en: c.  Classification in a noisy, low-dimensional dataset
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
- en: d.  All of the above
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
- en: '8.  Using a very low *k* value with the *k*-NN algorithm can result in:'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
- en: a.  Excessive run times
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
- en: b.  An underfit model
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
- en: c.  An overfit model
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
- en: d.  A generalized model
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
- en: '9.  In machine learning, a hyperparameter is:'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
- en: a.  A parameter chosen automatically by the algorithm
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
- en: b.  A parameter set at the top level of an algorithm
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
- en: c.  An adjustable parameter used to control the learning process
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
- en: d.  An overly excitable parameter
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
- en: '10.  Cross-validation is used to:'
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
- en: a.  Check the accuracy of a model against an independent test set
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
- en: b.  Find the best hyperparameters from an input range of hyperparameters
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
- en: c.  Check a dataset for duplicate samples
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
- en: d.  Gain insight on model underfitting and overfitting
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
- en: '**Summary**'
  id: totrans-456
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The Palmer penguins project provided a good overview of how pandas, seaborn,
    and scikit-learn work, how they work together, and what you can accomplish using
    them. At this point, though, you’ve barely glimpsed the enormity of these packages.
    To expand your knowledge, I recommend the official library documentation cited
    in the introduction to this chapter as well as the following books:'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
- en: '*Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython*,
    2nd edition, by Wes McKinney (O’Reilly Media, 2018), is an indispensable guide
    by the creator of the pandas library.'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
- en: '*Python Data Science Handbook: Essential Tools for Working with Data*, by Jake
    VanderPlas (O’Reilly Media, 2016), is a thorough reference for important Python
    data science tools, including pandas.'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
- en: '*Hands-on Machine Learning with Scikit-Learn, Keras, & TensorFlow: Concepts,
    Tools, and Techniques to Build Intelligent Systems*, 2nd edition, by Aurélien
    Géron (O’Reilly Media, 2019), provides practical instruction for machine learning
    novices.'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
- en: 'Although the penguins project covered a lot of ground, it didn’t address one
    of the most important forms of structured data used by scientists: time series
    data. In the next and final chapter, we’ll look at methods for incorporating dates
    and times in your programs and plots.'
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL

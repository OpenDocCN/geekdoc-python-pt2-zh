["```py\n$ pip install spacy\n```", "```py\n$ pip3.5 install spacy\n```", "```py\n$ python -m spacy info\n```", "```py\n$ pip install -U spacy\n```", "```py\n$ python -m spacy download en\n```", "```py\n$ python -m spacy download en_core_web_md\n```", "```py\nnlp = spacy.load('en')\n```", "```py\n➊ import spacy\n\n➋ nlp = spacy.load('en') \n\n➌ doc = nlp(u'I am flying to Frisco')\n\n➍ print([w.text for w in doc])\n```", "```py\n['I', 'am', 'flying', 'to', 'Frisco']\n```", "```py\nimport spacy\n\nnlp = spacy.load('en')\n\ndoc = nlp(u'this product integrates both libraries for downloading and\napplying patches')\n\nfor token in doc:\n\n  print(➊token.text, ➋token.lemma_)\n```", "```py\n\nthis        this\n\nproduct     product\n\nintegrates  integrate\n\nboth        both\n\nlibraries   library\n\nfor         for\n\ndownloading download\n\nand         and\n\napplying    apply\n\npatches     patch\n```", "```py\nI am flying to Frisco.\n```", "```py\n   import spacy\n\n   from spacy.symbols import ORTH, LEMMA\n\n   nlp = spacy.load('en')\n\n   doc = nlp(u'I am flying to Frisco')\n\n   print([w.text for w in doc])\n\n➊ special_case = [{ORTH: u'Frisco', LEMMA: u'San Francisco'}]\n\n➋ nlp.tokenizer.add_special_case(u'Frisco', special_case)\n\n➌ print([w.lemma_ for w in nlp(u'I am flying to Frisco')])\n```", "```py\n['I', 'am', 'flying', 'to', 'Frisco']\n\n['-PRON-', 'be', 'fly', 'to', 'San Francisco']\n```", "```py\nI have flown to LA. Now I am flying to Frisco.\n```", "```py\n['-PRON-', 'have', 'fly', 'to', 'LA', '.', 'now', '-PRON-', 'be', 'fly', 'to', 'San Francisco', '.']\n```", "```py\nI flew to LA.\n\nI have flown to LA.\n\nI need to fly to LA.\n\nI am flying to LA.\n\nI will fly to LA.\n```", "```py\nimport spacy\n\nnlp = spacy.load('en')\n\ndoc = nlp(u'I have flown to LA. Now I am flying to Frisco.')\n\nprint([w.text for w in doc if ➊w.tag_== ➋'VBG' or w.tag_== ➌'VB'])\n```", "```py\n['flying']\n```", "```py\nprint([w.text for w in doc if w.pos_ == 'PROPN'])\n```", "```py\n['LA', 'Frisco']\n```", "```py\nimport spacy\n\nnlp = spacy.load('en')\n\ndoc = nlp(u'I have flown to LA. Now I am flying to Frisco.')\n\nfor token in doc:\n\n  print(token.text, ➊token.pos_, ➋token.dep_)\n```", "```py\n\nI      PRON   nsubj\n\nhave   VERB   aux\n\nflown  VERB   ROOT\n\nto     ADP    prep\n\nLA     PROPN  pobj\n\n.      PUNCT  punct\n\nNow    ADV    advmod\n\nI      PRON   nsubj\n\nam     VERB   aux\n\nflying VERB   ROOT\n\nto     ADP    prep\n\nFrisco PROPN  pobj\n\n.      PUNCT  punct\n```", "```py\nfor token in doc:\n\n  print(➊token.head.text, token.dep_, token.text)\n```", "```py\n\nflown  nsubj  I\n\nflown  aux    have\n\nflown  ROOT   flown\n\nflown  prep   to\n\nto     pobj   LA\n\nflown  punct  .\n\nflying advmod Now\n\nflying nsubj  I\n\nflying aux    am\n\nflying ROOT   flying\n\nflying prep   to\n\nto     pobj   Frisco\n\nflying punct  .\n```", "```py\n   import spacy\n\n   nlp = spacy.load('en')\n\n   doc = nlp(u'I have flown to LA. Now I am flying to Frisco.')\n\n➊ for sent in doc.sents:\n\n  ➋ print([w.text for w in sent ➌if w.dep_ == 'ROOT' or w.dep_ == 'pobj'])\n```", "```py\n['flown', 'LA']\n\n['flying', 'Frisco']\n```", "```py\n ['fly', 'San Francisco']\n```", "```py\n import spacy\n\n nlp = spacy.load('en')\n\n doc = nlp(u'I have flown to LA. Now I am flying to Frisco.')\n\n for token in doc:\n\n➊ if token.ent_type != 0:\n\n    print(token.text, ➋token.ent_type_)\n```", "```py\nLA     GPE\n\nFrisco GPE\n```"]
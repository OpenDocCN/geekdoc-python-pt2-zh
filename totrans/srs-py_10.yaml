- en: '**10**'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**10**'
- en: '**PERFORMANCES AND OPTIMIZATIONS**'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**性能与优化**'
- en: '![image](../images/common01.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/common01.jpg)'
- en: Optimizing is rarely the first thing you think about when developing, but there
    always comes a time when optimizing for better performance will be appropriate.
    That’s not to say you should write a program with the idea that it will be slow,
    but thinking about optimization without first figuring out the right tools to
    use and doing the proper profiling is a waste of time. As Donald Knuth wrote,
    “Premature optimization is the root of all evil.”^([1](footnote.xhtml#foot2))
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 优化通常不是开发过程中最先考虑的事情，但总有那么一刻，优化以提高性能会变得合适。这并不是说你应该以程序会慢为前提来编写程序，而是在没有首先弄清楚应该使用哪些工具并进行适当的性能分析的情况下考虑优化，是浪费时间。正如唐纳德·克努斯所写的，“过早的优化是万恶之源。”^([1](footnote.xhtml#foot2))
- en: Here, I’ll show you how to use the right approach to write fast code and where
    to look when more optimization is needed. Many developers try to guess where Python
    might be slower or faster. Rather than speculating, this chapter will help you
    understand how to profile your application so you’ll know what part of your program
    is slowing things down and where the bottlenecks are.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我将向你展示如何使用正确的方法编写快速的代码，以及在需要更多优化时该从哪里着手。许多开发者试图猜测 Python 可能在哪些地方更慢或更快。与其猜测，本章将帮助你理解如何分析你的应用程序，以便你知道程序的哪些部分在拖慢速度，瓶颈在哪里。
- en: '**Data Structures**'
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**数据结构**'
- en: Most programming problems can be solved in an elegant and simple manner with
    the right data structures—and Python provides many data structures to choose from.
    Learning to leverage those existing data structures results in cleaner and more
    stable solutions than coding custom data structures.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数编程问题可以通过正确的数据结构以简洁优雅的方式解决——Python 提供了许多数据结构供你选择。学会利用这些现有的数据结构，能比编写自定义数据结构提供更简洁、更稳定的解决方案。
- en: 'For example, everybody uses `dict`, but how many times have you seen code trying
    to access a dictionary by catching the `KeyError` exception, as shown here:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，每个人都会使用`dict`，但是你多少次见到代码试图通过捕获`KeyError`异常来访问字典，如下所示：
- en: '[PRE0]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Or by checking whether the key is present first:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 或者通过先检查键是否存在：
- en: '[PRE1]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'If you use the `get()` method already provided by the `dict` class, you can
    avoid having to catch an exception or checking the key’s presence in the first
    place:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用`dict`类已经提供的`get()`方法，你可以避免捕获异常或在一开始就检查键是否存在：
- en: '[PRE2]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The method `dict.get()` can also return a default value instead of `None`;
    just call it with a second argument:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '`dict.get()`方法还可以返回一个默认值，而不是`None`；只需传入第二个参数：'
- en: '[PRE3]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Many developers are guilty of using basic Python data structures without being
    aware of all the methods they provide. This is also true for sets; methods in
    set data structures can solve many problems that would otherwise need to be addressed
    by writing nested `for`/`if` blocks. For example, developers often use `for`/`if`
    loops to determine whether an item is in a list, like this:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 许多开发者在使用基础的 Python 数据结构时，常常没有意识到它们提供的所有方法。集合也是如此；集合数据结构中的方法可以解决许多本来需要编写嵌套`for`/`if`块来处理的问题。例如，开发者常常使用`for`/`if`循环来判断某个项是否在列表中，如下所示：
- en: '[PRE4]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The loop iterates over each item in the list and checks that all items are
    either `foo` or `bar`. But you can write this more efficiently, removing the need
    for a loop:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这个循环遍历列表中的每一项，检查所有项是否是`foo`或`bar`。但是，你可以通过更高效的方式编写代码，避免使用循环：
- en: '[PRE5]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This changes the code to convert the fields to a set, and it gets the rest of
    the set by subtracting the `set(['foo', 'bar'])`. It then converts the set to
    a Boolean value, which indicates whether any items that aren’t `foo` and `bar`
    are left over. By using sets, there is no need to iterate over any list and to
    check items one by one. A single operation on two sets, done internally by Python,
    is faster.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码将字段转换为集合，并通过从`set(['foo', 'bar'])`中减去其差集来获取其余部分。然后，它将集合转换为布尔值，表示是否剩下任何非`foo`和`bar`的项。通过使用集合，不再需要遍历任何列表逐一检查项。Python
    内部对两个集合进行的单次操作要更快。
- en: Python also has more advanced data structures that can greatly reduce the burden
    of code maintenance. For example, take a look at [Listing 10-1](ch10.xhtml#ch10list1).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Python 还提供了更先进的数据结构，可以大大减轻代码维护的负担。例如，看看[列表 10-1](ch10.xhtml#ch10list1)。
- en: '[PRE6]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '*Listing 10-1: Adding an entry in a dictionary of sets*'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '*列表 10-1：向集合字典中添加一个条目*'
- en: This code is perfectly valid, but how many times will your programs require
    a variation of [Listing 10-1](ch10.xhtml#ch10list1)? Tens? Hundreds?
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码是完全有效的，但你的程序会有多少次需要[清单10-1](ch10.xhtml#ch10list1)的变种呢？几十次？几百次？
- en: 'Python provides the `collections.defaultdict` structure, which solves the problem
    in an elegant way:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Python提供了`collections.defaultdict`结构，它以优雅的方式解决了这个问题：
- en: '[PRE7]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Each time you try to access a nonexistent item from your `dict`, the `defaultdict`
    will use the function that was passed as argument to its constructor to build
    a new value, instead of raising a `KeyError`. In this case, the `set()` function
    is used to build a new `set` each time we need it.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 每次你尝试从`dict`中访问一个不存在的项时，`defaultdict`会使用作为参数传递给其构造函数的函数来构建一个新值，而不是引发`KeyError`。在这种情况下，`set()`函数用于每次我们需要时构建一个新的`set`。
- en: 'The `collections` module offers a few more data structures that you can use
    to solve other kinds of problems. For example, imagine that you want to count
    the number of distinct items in an iterable. Let’s take a look at the `collections.Counter()`
    method, which provides methods that solve this problem:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '`collections`模块提供了几种额外的数据结构，可以用来解决其他类型的问题。例如，假设你想要统计一个可迭代对象中不同项的数量。让我们看一下`collections.Counter()`方法，它提供了解决这个问题的方法：'
- en: '[PRE8]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The `collections.Counter` object works with any iterable that has hashable items,
    removing the need to write your own counting functions. It can easily count the
    number of letters in a string and return the top *n* most common items of an iterable.
    You might have tried to implement something like this on your own if you were
    not aware it was already provided by Python’s Standard Library.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '`collections.Counter`对象适用于任何具有可哈希项的可迭代对象，免去了你编写自己的计数函数的需求。它可以轻松计算字符串中字母的数量，并返回可迭代对象中最常见的前*n*个项。如果你没有意识到Python标准库已经提供了这个功能，可能你会尝试自己实现类似的功能。'
- en: With the right data structure, the correct methods, and—obviously—an adequate
    algorithm, your program should perform well. However, if it is not performing
    well enough, the best way to get clues about where it might be slow and need optimization
    is to profile your code.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 使用正确的数据结构、正确的方法，以及显然——足够的算法，你的程序应该表现良好。然而，如果它的表现不够好，获得有关程序在哪些地方可能变慢并需要优化的线索，最好的方法是对代码进行性能分析。
- en: '**Understanding Behavior Through Profiling**'
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**通过性能分析理解行为**'
- en: '*Profiling* is a form of dynamic program analysis that allows us to understand
    how a program behaves. It allows us to determine where there might be bottlenecks
    and a need for optimization. A profile of a program takes the form of a set of
    statistics that describe how often parts of the program execute and for how long.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '*性能分析*是一种动态程序分析方法，它让我们了解程序的行为。它使我们能够确定哪些地方可能存在瓶颈并需要优化。程序的性能分析结果以一组统计数据的形式呈现，描述了程序各部分执行的频率和持续时间。'
- en: Python provides a few tools for profiling your program. One, `cProfile`, is
    part of the Python Standard Library and does not require installation. We’ll also
    look at the `dis` module, which can disassemble Python code into smaller parts,
    making it easier to understand what is happening under the hood.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Python提供了一些工具来分析程序的性能。其中一个是`cProfile`，它是Python标准库的一部分，不需要额外安装。我们还将查看`dis`模块，它可以将Python代码拆解成更小的部分，使我们更容易理解底层发生了什么。
- en: '***cProfile***'
  id: totrans-34
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***cProfile***'
- en: Python has included `cProfile` by default since Python 2.5\. To use `cProfile`,
    call it with your program using the syntax `python –m cProfile <program`>. This
    should load and enable the `cProfile` module, then run the regular program with
    instrumentation enabled, as shown in [Listing 10-2](ch10.xhtml#ch10list2).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 自Python 2.5起，Python默认包括了`cProfile`。要使用`cProfile`，可以使用语法`python –m cProfile <program>`来调用它。这将加载并启用`cProfile`模块，然后按正常方式运行程序，并启用性能分析，如[清单10-2](ch10.xhtml#ch10list2)所示。
- en: '[PRE9]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '*Listing 10-2: Default output of cProfile used against a Python script*'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单10-2：使用cProfile对Python脚本进行的默认输出*'
- en: '[Listing 10-2](ch10.xhtml#ch10list2) shows the output of running a simple script
    with `cProfile`. This tells you the number of times each function in the program
    was called and the time spent on its execution. You can also use the `-s` option
    to sort by other fields; for example, `-s time` would sort the results by internal
    time.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[清单10-2](ch10.xhtml#ch10list2)展示了使用`cProfile`运行一个简单脚本的输出。它告诉你程序中每个函数被调用的次数以及执行花费的时间。你还可以使用`-s`选项按其他字段排序；例如，`-s
    time`将按内部时间排序结果。'
- en: We can visualize the information generated by `cProfile` using a great tool
    called KCacheGrind. This tool was created to deal with programs written in C,
    but luckily we can use it with Python data by converting the data to a call tree.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: 'The `cProfile` module has an `-o` option that allows you to save the profiling
    data, and `pyprof2calltree` can convert data from one format to the other. First,
    install the converter with the following:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Then run the converter as shown in [Listing 10-3](ch10.xhtml#ch10list3) to both
    convert the data (`-i` option) and run KCacheGrind with the converted data (`-k`
    option).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '*Listing 10-3: Running cProfile and launching KCacheGrind*'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: Once KCacheGrind opens, it will display information that looks like that in
    [Figure 10-1](ch10.xhtml#ch10fig1). With these visual results, you can use the
    call graph to follow the percentage of time spent in each function, allowing you
    to determine what part of your program might be consuming too many resources.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: The easiest way to read KCacheGrind is to start with the table on the left of
    the screen, which lists all the functions and methods executed by your program.
    You can sort these by execution time, then identify the one that consumes the
    most CPU time and click on it.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: The right panels of KCacheGrind can show you which functions have called that
    function and how many times, as well as which other functions are being called
    by the function. The call graph of your program, including the execution time
    of each part, is easy to navigate.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: This should allow you to better understand which parts of your code might need
    optimization. The way to optimize the code is up to you and depends on what your
    program is trying to achieve!
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f10-01.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-1: Example of KCacheGrind output*'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: While retrieving information about how your program runs and visualizing it
    works well to get a macroscopic view of your program, you might need a more microscopic
    view of some parts of the code to inspect its elements more closely. In such a
    case, I find it better to rely on the `dis` module to find out what’s going on
    behind the scenes.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: '***Disassembling with the dis Module***'
  id: totrans-52
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The `dis` module is a disassembler of Python bytecode. Taking code apart can
    be useful to understand what’s going on behind each line so you can properly optimize
    it. For example, [Listing 10-4](ch10.xhtml#ch10list4) shows the `dis.dis()` function,
    which disassembles whichever function you pass as a parameter and prints the list
    of bytecode instructions that are run by the function.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '*Listing 10-4: Disassembling a function*'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: 'In [Listing 10-4](ch10.xhtml#ch10list4), the function `x` is disassembled and
    its constituents, made of bytecode instructions, are printed. There are only two
    operations here: loading a constant (`LOAD_CONST`), which is `42`, and returning
    that value (`RETURN_VALUE`).'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: 'To see `dis` in action and how it can be useful, we’ll define two functions
    that do the same thing—concatenate three letters—and disassemble them to see how
    they do their tasks in different ways:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Both functions appear to do the same thing, but if we disassemble them using
    `dis.dis`, as shown in [Listing 10-5](ch10.xhtml#ch10list5), we’ll see that the
    generated bytecode is a bit different.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '*Listing 10-5: Disassembling functions that concatenate strings*'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: In the second function in [Listing 10-5](ch10.xhtml#ch10list5), we store `abc[0]`
    in a temporary variable before running the loop. This makes the bytecode that’s
    executed inside the loop a little smaller than the bytecode for the first function,
    as we avoid having to do the `abc[0]` lookup for each iteration. Measured using
    `timeit`, the second version is 10 percent faster than the first function; it
    takes a whole microsecond less to execute! Obviously this microsecond is not worth
    optimizing for unless you call this function billions of times, but this is the
    kind of insight that the `dis` module can provide.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: Whether you rely on “tricks” such as storing the value outside the loop depends
    on the situation—ultimately, it should be the compiler’s work to optimize this
    kind of thing. On the other hand, it’s difficult for the compiler to be sure that
    optimization wouldn’t have negative side effects because Python is heavily dynamic.
    In [Listing 10-5](ch10.xhtml#ch10list5), using `abc[0]` will call `abc.__getitem__`,
    which could have side effects if it has been overridden by inheritance. Depending
    on the version of the function you use, the `abc.__getitem__` method will be called
    once or several times, which might make a difference. Therefore, be careful when
    writing and optimizing your code!
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: '**Defining Functions Efficiently**'
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One common mistake I have found when reviewing code is definitions of functions
    within functions. This is inefficient because the function is then redefined repeatedly
    and needlessly. For example, [Listing 10-6](ch10.xhtml#ch10list6) shows the `y()`
    function being defined multiple times.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '*Listing 10-6: Function redefinition*'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 10-6](ch10.xhtml#ch10list6) shows the calling of `MAKE_FUNCTION`,
    `STORE_FAST`, `LOAD_FAST`, and `CALL_FUNCTION`, which requires many more opcodes
    than those needed to return `42`, as seen in [Listing 10-4](ch10.xhtml#ch10list4).'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: The only case in which you’d need to define a function within a function is
    when building a function closure, and this is a perfectly identified use case
    in Python’s opcodes with `LOAD_CLOSURE`, as shown in [Listing 10-7](ch10.xhtml#ch10list7).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '*Listing 10-7: Defining a closure*'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: While you probably won’t need to use it every day, disassembling code is a handy
    tool for when you want a closer look at what happens under the hood.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: '**Ordered Lists and bisect**'
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Next, let’s look at optimizing lists. If a list is unsorted, the worst-case
    scenario for finding a particular item’s position in the list has a complexity
    of *O(n)*, meaning that in the worst case, you’ll find your item after iterating
    over every item of the list.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: The usual solution for optimizing this problem is to use a *sorted* list instead.
    Sorted lists use a bisecting algorithm for lookup to achieve a retrieve time of
    *O(log n)*. The idea is to recursively split the list in half and look on which
    side, left or right, the item must appear in and so which side should be searched
    next.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: Python provides the `bisect` module, which contains a bisection algorithm, as
    shown in [Listing 10-8](ch10.xhtml#ch10list8).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '*Listing 10-8: Using bisect to find a needle in a haystack*'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in [Listing 10-8](ch10.xhtml#ch10list8), the `bisect.bisect()` function
    returns the position where an element should be inserted to keep the list sorted.
    Obviously, this only works if the list is properly sorted to begin with. Initial
    sorting allows to us get the *theoretical* index of an item: `bisect()` does not
    return whether the item is in the list but where the item should be if it is in
    the list. Retrieving the item at this index will answer the question about whether
    the item is in the list.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: If you wish to insert the element into the correct sorted position immediately,
    the `bisect` module provides the `insort_left()` and `insort_right()` functions,
    as shown in [Listing 10-9](ch10.xhtml#ch10list9).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '*Listing 10-9: Inserting an item in a sorted list*'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the `bisect` module, you could also create a special `SortedList` class
    inheriting from `list` to create a list that is always sorted, as shown in [Listing
    10-10](ch10.xhtml#ch10list10):'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '*Listing 10-10: A SortedList object implementation*'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: 'Using a `list` class like this is slightly slower when it comes to inserting
    the item, because the program has to look for the right spot to insert it. However,
    this class is faster at using the `index()` method than its parent. Obviously,
    one shouldn’t use the `list.append()` method on this class: you can’t append an
    item at the end of the list or it could end up unsorted!'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: Many Python libraries implement various versions of [Listing 10-10](ch10.xhtml#ch10list10)
    for many more data types, such as binary or red-black tree structures. The `blist`
    and `bintree` Python packages contain code that can be used for these purposes
    and are a handy alternative to implementing and debugging your own version.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we’ll see how the native tuple data type provided by Python
    can be leveraged to make your Python code a little faster.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '**namedtuple and Slots**'
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Often in programming, you’ll need to create simple objects that possess only
    a few fixed attributes. A simple implementation might be something along these
    lines:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This definitely gets the job done. However, there is a downside to this approach.
    Here we’re creating a class that inherits from the object class, so by using this
    `Point` class, you are instantiating full objects and allocating a lot of memory.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这肯定能完成任务。然而，这种方法也有一个缺点。在这里，我们创建了一个继承自对象类的类，因此通过使用这个`Point`类，你会实例化完整的对象并分配大量的内存。
- en: In Python, regular objects store all of their attributes inside a dictionary,
    and this dictionary is itself stored in the `__dict__` attribute, as shown in
    [Listing 10-11](ch10.xhtml#ch10list11).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Python 中，常规对象将其所有属性存储在一个字典中，而这个字典本身存储在`__dict__`属性中，如[清单 10-11](ch10.xhtml#ch10list11)所示。
- en: '[PRE21]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '*Listing 10-11: How attributes are stored internally in a Python object*'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单 10-11：Python 对象中属性的内部存储方式*'
- en: For Python, the advantage of using a `dict` is that it allows you to add as
    many attributes as you want to an object. The drawback is that using a dictionary
    to store these attributes is expensive in terms of memory—you need to store the
    object, the keys, the value references, and everything else. That makes it slow
    to create and slow to manipulate, with a high memory cost.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Python 来说，使用`dict`的优势在于它允许你向对象添加任意数量的属性。缺点是，使用字典来存储这些属性在内存方面开销很大——你需要存储对象、键、值引用以及其他所有内容。这使得创建和操作变得缓慢，并且内存成本很高。
- en: 'As an example of this unnecessary memory usage, consider the following simple
    class:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 作为这种不必要内存使用的示例，请考虑以下简单的类：
- en: '[PRE22]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: This creates a simple `Point` object with a single attribute named `x`. Let’s
    check the memory usage of this class using the `memory_profiler`, a nice Python
    package that allows us to see the memory usage of a program line by line, and
    a small script that creates 100,000 objects, as shown in [Listing 10-12](ch10.xhtml#ch10list12).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这创建了一个简单的`Point`对象，其中包含一个名为`x`的属性。让我们使用`memory_profiler`来检查这个类的内存使用情况，这是一个非常实用的
    Python 包，允许我们逐行查看程序的内存使用情况，且有一个小脚本可以创建 100,000 个对象，如[清单 10-12](ch10.xhtml#ch10list12)所示。
- en: '[PRE23]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '*Listing 10-12: Using memory_profiler on a script using objects*'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单 10-12：在使用对象的脚本中使用 memory_profiler*'
- en: '[Listing 10-12](ch10.xhtml#ch10list12) demonstrates that creating 100,000 of
    the objects of the `Foobar` class would consume 40MB of memory. Although 400 bytes
    per object might not sound that big, when you are creating thousands of objects,
    the memory adds up.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '[清单 10-12](ch10.xhtml#ch10list12)演示了创建`Foobar`类的 100,000 个对象会消耗 40MB 的内存。虽然每个对象
    400 字节可能不算大，但当你创建成千上万个对象时，内存消耗就会逐渐累积。'
- en: 'There is a way to use objects while avoiding this default behavior of `dict`:
    classes in Python can define a `__slots__` attribute that will list only the attributes
    allowed for instances of this class. Instead of allocating a whole dictionary
    object to store the object attributes, you can use a *list* object to store them.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 有一种方法可以避免使用`dict`的默认行为：Python 中的类可以定义一个`__slots__`属性，列出该类实例允许的属性。这样， instead
    of 分配整个字典对象来存储对象属性，你可以使用一个*列表*对象来存储它们。
- en: 'If you go through CPython source code and take a look at the *Objects/typeobject.c*
    file, it is quite easy to understand what Python does when `__slots__` is set
    on a class. [Listing 10-13](ch10.xhtml#ch10list13) is an abbreviated version of
    the function that handles this:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你查看 CPython 的源代码并查看 *Objects/typeobject.c* 文件，理解当类上设置了`__slots__`时 Python
    所做的事情会很容易。[清单 10-13](ch10.xhtml#ch10list13)是处理此功能的函数的简化版：
- en: '[PRE24]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '*Listing 10-13: An extract from Objects/typeobject.c*'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单 10-13：来自 Objects/typeobject.c 的摘录*'
- en: As you can see in [Listing 10-13](ch10.xhtml#ch10list13), Python converts the
    content of `__slots__` into a tuple and then into a list, which it builds and
    sorts before converting the list back into a tuple to use and store in the class.
    In this way, Python can retrieve the values quickly, without having to allocate
    and use an entire dictionary.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在[清单 10-13](ch10.xhtml#ch10list13)中看到的，Python 会将`__slots__`的内容转换为元组，然后再转换为列表，之后它会构建并排序列表，然后再将列表转换回元组用于使用和存储在类中。通过这种方式，Python
    能够快速检索值，而无需分配和使用整个字典。
- en: 'It’s easy enough to declare and use such a class. All you need to do is to
    set the `__slots__` attribute to a list of the attributes that will be defined
    in the class:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 声明并使用这样的类相当简单。你需要做的就是将`__slots__`属性设置为一个列出将要在类中定义的属性的列表：
- en: '[PRE25]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: We can compare the memory usage of the two approaches using the `memory_profiler`
    Python package, as shown in [Listing 10-14](ch10.xhtml#ch10list14).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `memory_profiler` Python 包来比较这两种方法的内存使用情况，如[清单 10-14](ch10.xhtml#ch10list14)所示。
- en: '[PRE26]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '*Listing 10-14: Running memory_profiler on the script using __slots__*'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 10-14](ch10.xhtml#ch10list14) shows that this time, less than 12MB
    of memory was needed to create 100,000 objects—or fewer than 120 bytes per object.
    Thus, by using the `__slots__` attribute of Python classes, we can reduce memory
    usage, so when we are creating a large number of simple objects, the `__slots__`
    attribute is an effective and efficient choice. However, this technique shouldn’t
    be used for performing static typing by hardcoding the list of attributes of every
    class: doing so wouldn’t be in the spirit of Python programs.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: The drawback here is that the list of attributes is now fixed. No new attribute
    can be added to the `Foobar` class at runtime. Due to the fixed nature of the
    attribute list, it’s easy enough to imagine classes where the attributes listed
    would always have a value and where the fields would always be sorted in some
    way.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: This is exactly what occurs in the `namedtuple` class from the `collection`
    module. This `namedtuple` class allows us to dynamically create a class that will
    inherit from the tuple class, thus sharing characteristics such as being immutable
    and having a fixed number of entries.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: Rather than having to reference them by index, `namedtuple` provides the ability
    to retrieve tuple elements by referencing a named attribute. This makes the tuple
    easier to access for humans, as shown in [Listing 10-15](ch10.xhtml#ch10list15).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '*Listing 10-15: Using namedtuple to reference tuple elements*'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 10-15](ch10.xhtml#ch10list15) shows how you can create a simple class
    with just one line of code and then instantiate it. We can’t change any attributes
    of objects of this class or add attributes to them, both because the class inherits
    from `namedtuple` and because the `__slots__` value is set to an empty tuple,
    avoiding the creation of the `__dict__`. Since a class like this would inherit
    from tuple, we can easily convert it to a list.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 10-16](ch10.xhtml#ch10list16) demonstrates the memory usage of the
    `namedtuple` class factory.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '*Listing 10-16: Using namedtuple to run memory_profiler on a script*'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: 'At around 13MB for 100,000 objects, using `namedtuple` is slightly less efficient
    than using an object with `__slots__`, but the bonus is that it is compatible
    with the tuple class. It can therefore be passed to many native Python functions
    and libraries that expect an iterable as an argument. A `namedtuple` class factory
    also enjoys the various optimizations that exist for tuples: for example, tuples
    with fewer items than `PyTuple_MAXSAVESIZE` (20 by default) will use a faster
    memory allocator in CPython.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: The `namedtuple` class also provides a few extra methods that, even if prefixed
    by an underscore, are actually intended to be public. The `_asdict()` method can
    convert the `namedtuple` to a `dict` instance, the `_make()` method allows you
    to convert an existing iterable object to this class, and `_replace()` returns
    a new instance of the object with some fields replaced.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: Named tuples are a great replacement for small objects that consists of only
    a few attributes and do not require any custom methods—consider using them rather
    than dictionaries, for example. If your data type needs methods, has a fixed list
    of attributes, and might be instantiated thousands of times, then creating a custom
    class using `__slots__` might be a good idea to save some memory.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '**Memoization**'
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Memoization* is an optimization technique used to speed up function calls
    by caching their results. The results of a function can be cached only if the
    function is *pure*, meaning that it has no side effects and does not depend on
    any global state. (See [Chapter 8](ch08.xhtml#ch08) for more on pure functions.)'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: One trivial function that can be memoized is `sin()`, shown in [Listing 10-17](ch10.xhtml#ch10list17).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '*Listing 10-17: A memoized sin() function*'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: In [Listing 10-17](ch10.xhtml#ch10list17), the first time that `memoized_sin()`
    is called with an argument that is not stored in `_SIN_MEMOIZED_VALUES`, the value
    is computed and stored in this dictionary. If we call the function with the same
    value again, the result will be retrieved from the dictionary rather than recomputed.
    While `sin()` computes very quickly, some advanced functions involving more complicated
    computations may take longer, and this is where memoization really shines.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: If you’ve already read about decorators (if not, see “[Decorators and When to
    Use Them](ch07.xhtml#lev1sec34)” on [page 100](ch07.xhtml#page_100)), you might
    see a perfect opportunity to use them here, and you’d be right. PyPI lists a few
    implementations of memoization through decorators, from very simple cases to the
    most complex and complete.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: Starting with Python 3.3, the `functools` module provides a *least recently
    used (LRU)* cache decorator. This provides the same functionality as memoization,
    but with the benefit that it limits the number of entries in the cache, removing
    the least recently used one when the cache reaches its maximum size. The module
    also provides statistics on cache hits and misses (whether something was in the
    accessed cache or not), among other data. In my opinion, these statistics are
    must-haves when implementing such a cache. The strength of using memoization,
    or any caching technique, is in the ability to meter its usage and usefulness.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 10-18](ch10.xhtml#ch10list18) demonstrates how to use the `functools.lru_cache()`
    method to implement the memoization of a function. When decorated, the function
    gets a `cache_info()` method that can be called to get statistics about the cache
    usage.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '*Listing 10-18: Inspecting cache statistics*'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 10-18](ch10.xhtml#ch10list18) demonstrates how your cache is being
    used and how to tell whether there are optimizations to be made. For example,
    if the number of misses is high when the cache is not full, then the cache may
    be useless because the arguments passed to the function are never identical. This
    will help determine what should or should not be memoized!'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '**Faster Python with PyPy**'
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*PyPy* is an efficient implementation of the Python language that complies
    with standards: you should be able to run any Python program with it. Indeed,
    the canonical implementation of Python, CPython—so called because it’s written
    in C—can be very slow. The idea behind PyPy was to write a Python interpreter
    in Python itself. In time, it evolved to be written in RPython, which is a restricted
    subset of the Python language.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: RPython places constraints on the Python language such that a variable’s type
    can be inferred at compile time. The RPython code is translated into C code, which
    is compiled to build the interpreter. RPython could of course be used to implement
    languages other than Python.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: What’s interesting in PyPy, besides the technical challenge, is that it is now
    at a stage where it can act as a faster replacement for CPython. PyPy has a *just-in-time
    (JIT)* compiler built-in; in other words, it allows the code to run faster by
    combining the speed of compiled code with the flexibility of interpretation.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: How fast? That depends, but for pure algorithmic code, it is much faster. For
    more general code, PyPy claims to achieve three times the speed of CPython most
    of the time. Unfortunately, PyPy also has some of the limitations of CPython,
    including the *global interpreter lock (GIL)*, which allows only one thread to
    execute at a time.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: Though it’s not strictly an optimization technique, targeting PyPy as one of
    your supported Python implementations might be a good idea. To make PyPy a support
    implementation, you need to make sure that you are testing your software under
    PyPy as you would under CPython. In [Chapter 6](ch06.xhtml#ch06), we discussed
    `tox` (see “Using `virtualenv` with `tox`” on [page 92](ch06.xhtml#page_92)),
    which supports the building of virtual environments using PyPy, just as it does
    for any version of CPython, so putting PyPy support in place should be pretty
    straightforward.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: Testing PyPy support right at the beginning of the project will ensure that
    there’s not too much work to do at a later stage if you decide that you want to
    be able to run your software with PyPy.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '*For the Hy project discussed in [Chapter 9](ch09.xhtml#ch09), we successfully
    adopted this strategy from the beginning. Hy always has supported PyPy and all
    other CPython versions without much trouble. On the other hand, OpenStack failed
    to do so for its projects and, as a result, is now blocked by various code paths
    and dependencies that don’t work on PyPy for various reasons; they weren’t required
    to be fully tested in the early stages.*'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: PyPy is compatible with Python 2.7 and Python 3.5, and its JIT compiler works
    on 32- and 64-bit, x86, and ARM architectures and under various operating systems
    (Linux, Windows, and Mac OS X). PyPy often lags behind CPython in features, but
    it regularly catches up. Unless your project is reliant on the latest CPython
    features, this lag might not be a problem.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '**Achieving Zero Copy with the Buffer Protocol**'
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Often programs have to deal with huge amounts of data in the form of large arrays
    of bytes. Handling such a large quantity of input in strings can be very ineffective
    once you start manipulating the data by copying, slicing, and modifying it.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: Let’s consider a small program that reads a large file of binary data and copies
    it partially into another file. To examine the memory usage of this program, we
    will use `memory_profiler`, as we did earlier. The script to partially copy the
    file is shown in [Listing 10-19](ch10.xhtml#ch10list19).
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '*Listing 10-19: Partially copying a file*'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: Running the program in [Listing 10-19](ch10.xhtml#ch10list19) using `memory_profiler`
    produces the output shown in [Listing 10-20](ch10.xhtml#ch10list20).
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '*Listing 10-20: Memory profiling of partial file copy*'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: According to the output, the program reads 10MB from *_/dev/urandom* ➊. Python
    needs to allocate around 10MB of memory to store this data as a string. It then
    copies the entire block of data, minus the first KB ➋.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: What’s interesting in [Listing 10-20](ch10.xhtml#ch10list20) is that the program’s
    memory usage is increased by about 10MB when building the variable `content_to_write`.
    In fact, the `slice` operator is copying the entirety of content, minus the first
    KB, into a new string object, allocating a large chunk of the 10MB.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: Performing this kind of operation on large byte arrays is going to be a disaster
    since large pieces of memory will be allocated and copied. If you have experience
    writing in C code, you know that using the `memcpy()` function has a significant
    cost in terms of both memory usage and general performance.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: But as a C programmer, you’ll also know that strings are arrays of characters
    and that nothing stops you from looking at only *part* of an array without copying
    it. You can do this through the use of basic pointer arithmetic, assuming that
    the entire string is in a contiguous memory area.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: This is also possible in Python using objects that implement the *buffer protocol*.
    The buffer protocol is defined in PEP 3118, as a C API that needs to be implemented
    on various types for them to provide this protocol. The `string` class, for example,
    implements this protocol.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: 'When you implement this protocol on an object, you can then use the `memoryview`
    class constructor to build a new `memoryview` object that will reference the original
    object memory. For example, [Listing 10-21](ch10.xhtml#ch10list21) shows how to
    use `memoryview` to access slice of a string without doing any copying:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '*Listing 10-21: Using memoryview to avoid copying data*'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: At ➊, you find the ASCII code for the letter *b*. In [Listing 10-21](ch10.xhtml#ch10list21),
    we are making use of the fact that the `memoryview` object’s `slice` operator
    itself returns a `memoryview` object. That means it does *not* copy any data but
    merely references a particular slice of it, saving the memory that would be used
    by a copy. [Figure 10-2](ch10.xhtml#ch10fig2) illustrates what happens in [Listing
    10-21](ch10.xhtml#ch10list21).
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f10-02.jpg)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-2: Using slice on memoryview objects*'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: We can rewrite the program from [Listing 10-19](ch10.xhtml#ch10list19), this
    time referencing the data we want to write using a `memoryview` object rather
    than allocating a new string.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '*Listing 10-22: Partially copying a file using memoryview*'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: 'The program in [Listing 10-22](ch10.xhtml#ch10list22) uses half the memory
    of the first version in [Listing 10-19](ch10.xhtml#ch10list19). We can see this
    by testing it with `memory_profiler` again, like so:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: These results show that we are reading 10,000KB from */dev/urandom* and not
    doing much with it ➊. Python needs to allocate 9.77MB of memory to store this
    data as a string ➋.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: We reference the entire block of data minus the first KB, because we won’t be
    writing that first KB to the target file. Because we aren’t copying, no more memory
    is used!
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: 'This kind of trick is especially useful when dealing with sockets. When sending
    data over a socket, it’s possible that the data might split between calls rather
    than be sent in a single call: the `socket.send` methods return the actual data
    length that was able to be sent by the network, which might be smaller than the
    data that was intended to be sent. [Listing 10-23](ch10.xhtml#ch10list23) shows
    how the situation is usually handled.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '*Listing 10-23: Sending data over a socket*'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: First, we build a `bytes` object that contains the letter *a* more than 100
    million times ➊. Then we remove the first `sent` bytes ➋.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: Using a mechanism that implemented in [Listing 10-23](ch10.xhtml#ch10list23),
    a program will copy the data over and over until the socket has sent everything.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: We can alter the program in [Listing 10-23](ch10.xhtml#ch10list23) to use `memoryview`
    to achieve the same functionality with zero copying, and therefore higher performance,
    as shown in [Listing 10-24](ch10.xhtml#ch10list24).
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '*Listing 10-24: Sending data over a socket using memoryview*'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: First, we build a `bytes` object that contains the letter *a* more than 100
    million times ➊. Then, we build a new `memoryview` object pointing to the data
    that remains to be sent, rather than copying that data ➋. This program won’t copy
    anything, so it won’t use any more memory than the 100MB initially needed for
    the `data` variable.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ve seen how `memoryview` objects can be used to write data efficiently,
    and this same method can be used to *read* data. Most I/O operations in Python
    know how to deal with objects implementing the buffer protocol: they can read
    from those, and also write to those. In this case, we don’t need `memoryview`
    objects; we can just ask an I/O function to write into our preallocated object,
    as shown in [Listing 10-25](ch10.xhtml#ch10list25).'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '*Listing 10-25: Writing into a preallocated bytearray*'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: In [Listing 10-25](ch10.xhtml#ch10list25), by using the `readinto()` method
    of the opened file, Python can directly read the data from the file and write
    it to a preallocated `bytearray`. With such techniques, it’s easy to preallocate
    a buffer (as you would do in C to mitigate the number of calls to `malloc()`)
    and fill it at your convenience. Using `memoryview`, you can place data at any
    point in the memory area, as shown in [Listing 10-26](ch10.xhtml#ch10list26).
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '*Listing 10-26: Writing into an arbitrary position of bytearray*'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: We reference the `bytearray` from offset 4 to its end ➊. Then, we write the
    content of */dev/urandom* from offset 4 to the end of `bytearray`, effectively
    reading just 4 bytes ➋.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: The buffer protocol is extremely important for achieving low memory overhead
    and great performances. As Python hides all the memory allocations, developers
    tend to forget what happens under the hood, at great cost to the speed of their
    programs!
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: Both the objects in the `array` module and the functions in the `struct` module
    can handle the buffer protocol correctly and can therefore perform efficiently
    when targeting zero copying.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '**Summary**'
  id: totrans-192
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As we’ve seen in this chapter, there are plenty of ways to make Python code
    faster. Choosing the right data structure and using the correct methods for manipulating
    the data can have a huge impact in terms of CPU and memory usage. That’s why it’s
    important to understand what happens in Python internally.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: However, optimization should never be done prematurely, without first performing
    a proper profiling. It is too easy to waste time rewriting some barely used code
    with a faster variant while missing central pain points. Don’t miss the big picture.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: '**Victor Stinner on Optimization**'
  id: totrans-195
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Victor is a longtime Python hacker, a core contributor, and the author of many
    Python modules. He authored PEP 454 in 2013, which proposed a new `tracemalloc`
    module to trace memory block allocation inside Python, and he wrote a simple AST
    optimizer called FAT. He also regularly contributes to the improvement of CPython
    performance.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: '**What’s a good starting strategy for optimizing Python code?**'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: The strategy is the same in Python as in other languages. First, you need a
    well-defined use case in order to get a stable and reproducible benchmark. Without
    a reliable benchmark, trying different optimizations may result in wasted time
    and premature optimization. Useless optimizations may make the code worse, less
    readable, or even slower. A useful optimization must speed the program up by at
    least 5 percent if it’s to be worth pursuing.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: If a specific part of the code is identified as being “slow,” a benchmark should
    be prepared on this code. A benchmark on a short function is usually called a
    *micro-benchmark*. The speedup should be at least 20 percent, maybe 25 percent,
    to justify an optimization on a micro-benchmark.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: It may be interesting to run a benchmark on different computers, different operating
    systems, or different compilers. For example, performances of `realloc()` may
    vary between Linux and Windows.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: '**What are your recommended tools for profiling or optimizing Python code?**'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: Python 3.3 has a `time.perf_counter()` function to measure elapsed time for
    a benchmark. It has the best resolution available.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: A test should be run more than once; three times is a minimum, and five may
    be enough. Repeating a test fills disk cache and CPU caches. I prefer to keep
    the minimum timing; other developers prefer the geometric mean.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: For micro-benchmarks, the `timeit` module is easy to use and gives results quickly,
    but the results are not reliable using default parameters. Tests should be repeated
    manually to get stable results.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing can take a lot of time, so it’s better to focus on functions that
    use the most CPU power. To find these functions, Python has `cProfile` and `profile`
    modules to record the amount of time spent in each function.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: '**Do you have any Python tricks that could improve performance?**'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: 'You should reuse the Standard Library as much as possible—it’s well tested
    and also usually efficient. Built-in Python types are implemented in C and have
    good performance. Use the correct container to get the best performance; Python
    provides many different kind of containers: `dict`, `list`, `deque`, `set`, and
    so on.'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: There are some hacks for optimizing Python, but you should avoid these because
    they make the code less readable in exchange for a minor speedup.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: The Zen of Python (PEP 20) says, “There should be one—and preferably only one—obvious
    way to do it.” In practice, there are different ways to write Python code, and
    performances are not the same. Only trust benchmarks on your use case.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: '**Which areas of Python have the poorest performance and should be watched
    out for?**'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: In general, I prefer not to worry about performance while developing a new application.
    Premature optimization is the root of all evil. When you identify slow functions,
    change the algorithm. If the algorithm and the container types are well chosen,
    you might rewrite short functions in C to get the best performance.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: One bottleneck in CPython is the global interpreter lock, known as the GIL.
    Two threads cannot execute Python bytecode at the same time. However, this limitation
    only matters if two threads are executing pure Python code. If most processing
    time is spent in function calls, and these functions release the GIL, then the
    GIL is not the bottleneck. For example, most I/O functions release the GIL.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: The multiprocessing module can easily be used to work around the GIL. Another
    option, more complex to implement, is to write asynchronous code. Twisted, Tornado,
    and Tulip projects, which are network-oriented libraries, make use of this technique.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: '**What are some often-seen performance mistakes?**'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: When Python is not well understood, inefficient code can be written. For example,
    I have seen `copy.deepcopy()` misused, when no copying was required.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: Another performance killer is an inefficient data structure. With less than
    100 items, the container type has no impact on performance. With more items, the
    complexity of each operation (`add`, `get`, `delete`) and its effects must be
    known.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL

<html><head></head><body><div id="sbo-rt-content"><h2 class="h2" id="ch15"><span epub:type="pagebreak" id="page_377"/><strong><span class="big">15</span><br/>A CASE STUDY: CLASSIFYING AUDIO SAMPLES</strong></h2>&#13;
<div class="imagec"><img src="Images/common.jpg" alt="image" width="189" height="189"/></div>&#13;
<p class="noindents">Let’s bring together everything that we’ve learned throughout the book. We’ll be looking at a single case study. The scenario is this: we are data scientists, and our boss has tasked us with building a classifier for audio samples stored as <em>.wav</em> files. We’ll begin with the data itself. We first want to build some basic intuition for how it’s structured. From there, we’ll build augmented datasets we can use for training models. The first dataset uses the sound samples themselves, a one-dimensional dataset. We’ll see that this approach isn’t as successful as we would like it to be.</p>&#13;
<p class="indent">We’ll then turn the audio data into images to allow us to explore two-dimensional CNNs. This change of representation will lead to a big improvement in model performance. Finally, we’ll combine multiple models in ensembles to see how to leverage the relative strengths and weaknesses of the individual models to boost overall performance still more.</p>&#13;
<h3 class="h3" id="lev1_101"><span epub:type="pagebreak" id="page_378"/>Building the Dataset</h3>&#13;
<p class="noindent">There are 10 classes in our dataset, which consists of 400 samples total, 40 samples per class, each 5 seconds long. We’ll assume we cannot get any more data because it’s time-consuming and expensive to record the samples and label them. We must work with the data we are given and no more.</p>&#13;
<p class="indent">Throughout this book, we have consistently preached about the necessity of having a good dataset. We’ll assume that the dataset we have been handed is complete in the sense that our system will encounter only types of sound samples in the dataset; there will be no unknown class or classes. Additionally, we’ll also assume that the balanced nature of the dataset is real, and all classes are indeed equally likely.</p>&#13;
<p class="indent">The audio dataset we’ll use is called ESC-10. For a complete description, see “ESC: Dataset for Environmental Sound Classification” by Karol J. Piczal (2015). The dataset is available at <a href="https://github.com/karoldvl/ESC-50/">https://github.com/karoldvl/ESC-50/</a>. But it needs to be extracted from the larger ESC-50 dataset, which doesn’t have a license we can use. The ESC-10 subset does.</p>&#13;
<p class="indent">Let’s do some preprocessing to extract the ESC-10 <em>.wav</em> files from the larger ESC-50 dataset. Download the single ZIP-file version of the dataset from the preceding URL and expand it. This will create a directory called <em>ESC-50-master</em>. Then, use the code in <a href="ch15.xhtml#ch15lis1">Listing 15-1</a> to build the ESC-10 dataset from it.</p>&#13;
<p class="programs" id="ch15lis1">import sys <br/>&#13;
import os<br/>&#13;
import shutil<br/>&#13;
<br/>&#13;
classes = { <br/>&#13;
    "rain":0,<br/>&#13;
    "rooster":1,<br/>&#13;
    "crying_baby":2,<br/>&#13;
    "sea_waves":3,<br/>&#13;
    "clock_tick":4,<br/>&#13;
    "sneezing":5,<br/>&#13;
    "dog":6,<br/>&#13;
    "crackling_fire":7,<br/>&#13;
    "helicopter":8,<br/>&#13;
    "chainsaw":9,<br/>&#13;
}   <br/>&#13;
<br/>&#13;
with open("ESC-50-master/meta/esc50.csv") as f:<br/>&#13;
    lines = [i[:-1] for i in f.readlines()]<br/>&#13;
lines = lines[1:]<br/>&#13;
<br/>&#13;
os.system("rm -rf ESC-10")<br/>&#13;
os.system("mkdir ESC-10")<br/>&#13;
os.system("mkdir ESC-10/audio")<br/>&#13;
<br/>&#13;
<span epub:type="pagebreak" id="page_379"/>meta = []<br/>&#13;
for line in lines:<br/>&#13;
    t = line.split(",")<br/>&#13;
    if (t[-3] == 'True'):<br/>&#13;
        meta.append("ESC-10/audio/%s %d" % (t[0],classes[t[3]]))<br/>&#13;
        src = "ESC-50-master/audio/"+t[0]<br/>&#13;
        dst = "ESC-10/audio/"+t[0]<br/>&#13;
        shutil.copy(src,dst)<br/>&#13;
<br/>&#13;
with open("ESC-10/filelist.txt","w") as f:<br/>&#13;
    for m in meta:<br/>&#13;
        f.write(m+"\n")</p>&#13;
<p class="figcap"><em>Listing 15-1: Building the ESC-10 dataset</em></p>&#13;
<p class="indent">The code uses the ESC-50 metadata to identify the sound samples that belong to the 10 classes of the ESC-10 dataset and then copies them to the <em>ESC-10/audio</em> directory. It also writes a list of the audio files to <em>filelist.txt</em>. After running this code, we’ll use only the ESC-10 files.</p>&#13;
<p class="indent">If all is well, we should now have 400 five-second <em>.wav</em> files, 40 from each of the 10 classes: rain, rooster, crying baby, sea waves, clock tick, sneezing, dog, crackling fire, helicopter, and chainsaw. We’ll politely refrain from asking our boss exactly why she wants to discriminate between these particular classes of sound.</p>&#13;
<h4 class="h4" id="lev2_137">Augmenting the Dataset</h4>&#13;
<p class="noindent">Our first instinct should be that our dataset is too small. After all, we have only 40 examples of each sound, and we know that some of those will need to be held back for testing, leaving even fewer per class for training.</p>&#13;
<p class="indent">We could resort to <em>k</em>-fold validation, but in this case, we’ll instead opt for data augmentation. So, how do we augment audio data?</p>&#13;
<p class="indent">Recall, the goal of data augmentation is to create new data samples that could plausibly come from the classes in the dataset. With images, we can make obvious changes like shifting, flipping left and right, and so on. With continuous vectors, we’ve seen how to use PCA to augment the data (see <a href="ch05.xhtml#ch05">Chapter 5</a>). To augment the audio files, we need to think of things we can do that will produce new files that still sound like the original class. Four thoughts come to mind.</p>&#13;
<p class="indent">First, we can shift the sample in time, much as we can shift an image to the left or right a few pixels. Second, we can simulate a noisy environment by adding a small amount of random noise to the sound itself. Third, we can shift the pitch of the sound, and make it higher or lower by some small amount. Not surprisingly, this is known as <em>pitch shifting</em>. Finally, we can lengthen or compress the sound in time. This is known as <em>time shifting</em>.</p>&#13;
<p class="indent">Doing all of this sounds complicated, especially if we haven’t worked with audio data before. I should point out that in practice, being presented with unfamiliar data is a very real possibility; we don’t all get to choose what we need to work with.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_380"/>Fortunately for us, we’re working in Python, and the Python community is vast and talented. It turns out that adding one library to our system will allow us to easily do time stretching and pitch shifting. Let’s install the <span class="literal">librosa</span> library. This should do the trick for us:</p>&#13;
<p class="programs">$ <span class="codestrong1">sudo pip3 install librosa</span></p>&#13;
<p class="indent">With the necessary library installed, we can augment the ESC-10 dataset with the code in <a href="ch15.xhtml#ch15lis2">Listing 15-2</a>.</p>&#13;
<p class="programs" id="ch15lis2">   import os<br/>&#13;
   import random<br/>&#13;
   import numpy as np<br/>&#13;
   from scipy.io.wavfile import read, write<br/>&#13;
   import librosa as rosa<br/>&#13;
   N = 8<br/>&#13;
   os.system("rm -rf augmented; mkdir augmented")<br/>&#13;
   os.system("mkdir augmented/train augmented/test")<br/>&#13;
<span class="ent">❶</span> src_list = [i[:-1] for i in open("ESC-10/filelist.txt")]<br/>&#13;
   z = [[] for i in range(10)]<br/>&#13;
   for s in src_list:<br/>&#13;
       _,c = s.split()<br/>&#13;
       z[int(c)].append(s)<br/>&#13;
<span class="ent">❷</span> train = []<br/>&#13;
   test = []<br/>&#13;
   for i in range(10):<br/>&#13;
       p = z[i]<br/>&#13;
       random.shuffle(p)<br/>&#13;
       test += p[:8]<br/>&#13;
       train += p[8:]<br/>&#13;
   random.shuffle(train)<br/>&#13;
   random.shuffle(test)<br/>&#13;
   augment_audio(train, "train")<br/>&#13;
   augment_audio(test, "test")</p>&#13;
<p class="figcap"><em>Listing 15-2: Augmenting the ESC-10 dataset, part 1</em></p>&#13;
<p class="indent">This code loads the necessary modules, including the <span class="literal">librosa</span> module, which we’ll just call <span class="literal">rosa</span>, and two functions from the SciPy <span class="literal">wavfile</span> module that let us read and write NumPy arrays as <em>.wav</em> files.</p>&#13;
<p class="indent">We set the number of samples per class that we’ll hold back for testing (<span class="literal">N=8</span>) and create the output directory where the augmented sound files will reside (<span class="literal">augmented</span>). Then we read the file list we created with <a href="ch15.xhtml#ch15lis1">Listing 15-1</a> <span class="ent">❶</span>. Next, we create a nested list (<span class="literal">z</span>) to hold the names of the audio files associated with each of the 10 classes.</p>&#13;
<p class="indent">Using the list of files per class, we pull it apart and create <span class="literal">train</span> and <span class="literal">test</span> file lists <span class="ent">❷</span>. Notice that we randomly shuffle the list of files per class and the final <span class="literal">train</span> and <span class="literal">test</span> lists. This code follows the convention we discussed in <a href="ch04.xhtml#ch04">Chapter 4</a> of separating train and test first, then augmenting.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_381"/>We can augment the train and test files by calling <span class="literal">augment_audio</span>. This function is in <a href="ch15.xhtml#ch15lis3">Listing 15-3</a>.</p>&#13;
<p class="programs" id="ch15lis3">def augment_audio(src_list, typ):<br/>&#13;
    flist = []<br/>&#13;
    for i,s in enumerate(src_list):<br/>&#13;
        f,c = s.split()<br/>&#13;
     <span class="ent">❶</span> wav = read(f) # (sample rate, data)<br/>&#13;
        base = os.path.abspath("augmented/%s/%s" % <br/>&#13;
                               (typ, os.path.basename(f)[:-4]))<br/>&#13;
        fname = base+".wav"<br/>&#13;
     <span class="ent">❷</span> write(fname, wav[0], wav[1])<br/>&#13;
        flist.append("%s %s" % (fname,c))<br/>&#13;
        for j in range(19):<br/>&#13;
            d = augment(wav)<br/>&#13;
            fname = base+("_%04d.wav" % j)<br/>&#13;
         <span class="ent">❸</span> write(fname, wav[0], d.astype(wav[1].dtype))<br/>&#13;
            flist.append("%s %s" % (fname,c))<br/>&#13;
<br/>&#13;
    random.shuffle(flist)<br/>&#13;
    with open("augmented_%s_filelist.txt" % typ,"w") as f:<br/>&#13;
        for z in flist:<br/>&#13;
            f.write("%s\n" % z)</p>&#13;
<p class="figcap"><em>Listing 15-3: Augmenting the ESC-10 dataset, part 2</em></p>&#13;
<p class="indent">The function loops over all the filenames in the given list (<span class="literal">src_list</span>), which will be either train or test. The filename is separated from the class label, and then the file is read from disk <span class="ent">❶</span>. As indicated in the comment, <span class="literal">wav</span> is a list of two elements. The first is the sampling rate in Hz (cycles per second). This is how often the analog waveform was digitized to produce the <em>.wav</em> file. For ESC-10, the sampling rate is always 44,100 Hz, which is the standard rate for a compact disc. The second element is a NumPy array containing the actual digitized sound samples. These are the values we’ll augment to produce new data files.</p>&#13;
<p class="indent">After setting up some output pathnames, we write the original sound sample to the augmented directory <span class="ent">❷</span>. Then, we start a loop to generate 19 more augmented versions of the current sound sample. The augmented dataset, as a whole, will be 20 times larger, for a total of 8,000 sound files, 6,400 for training and 1,600 for testing. Note, the sound samples for an augmented source file are assigned to <span class="literal">d</span>. The new sound file is written to disk using the sample rate of 44,100 Hz and the augmented data matching the datatype of the source <span class="ent">❸</span>.</p>&#13;
<p class="indent">As we create the augmented sound files, we also keep track of the filename and class and write them to a new file list. Here <span class="literal">typ</span> is a string indicating train or test.</p>&#13;
<p class="indent">This function calls yet another function, <span class="literal">augment</span>. This is the function that generates an augmented version of a single sound file by randomly applying some subset of the four augmentation strategies mentioned <span epub:type="pagebreak" id="page_382"/>previously: shifting, noise, pitch shifting, or time-shifting. Some or all of these might be used for any call to <span class="literal">augment</span>. The <span class="literal">augment</span> function itself is shown in <a href="ch15.xhtml#ch15lis4">Listing 15-4</a>.</p>&#13;
<p class="programs" id="ch15lis4">def augment(wav):<br/>&#13;
    sr = wav[0]<br/>&#13;
    d = wav[1].astype("float32")<br/>&#13;
 <span class="ent">❶</span> if (random.random() &lt; 0.5):<br/>&#13;
        s = int(sr/4.0*(np.random.random()-0.5))<br/>&#13;
        d = np.roll(d,s)<br/>&#13;
        if (s &lt; 0):<br/>&#13;
            d[s:] = 0<br/>&#13;
        else:<br/>&#13;
            d[:s] = 0<br/>&#13;
 <span class="ent">❷</span> if (random.random() &lt; 0.5):<br/>&#13;
        d += 0.1*(d.max()-d.min())*np.random.random(d.shape[0])<br/>&#13;
 <span class="ent">❸</span> if (random.random() &lt; 0.5):<br/>&#13;
        pf = 20.0*(np.random.random()-0.5)<br/>&#13;
        d = rosa.effects.pitch_shift(d, sr, pf) <br/>&#13;
 <span class="ent">❹</span> if (random.random() &lt; 0.5):<br/>&#13;
        rate = 1.0 + (np.random.random()-0.5)<br/>&#13;
        d = rosa.effects.time_stretch(d,rate)<br/>&#13;
        if (d.shape[0] &gt; wav[1].shape[0]):<br/>&#13;
            d = d[:wav[1].shape[0]]<br/>&#13;
        else:<br/>&#13;
            w = np.zeros(wav[1].shape[0], dtype="float32")<br/>&#13;
            w[:d.shape[0]] = d <br/>&#13;
            d = w.copy()<br/>&#13;
    return d</p>&#13;
<p class="figcap"><em>Listing 15-4: Augmenting the ESC-10 dataset, part 3</em></p>&#13;
<p class="indent">This function separates the samples (<span class="literal">d</span>) from the sample rate (<span class="literal">sr</span>) and makes sure the samples are floating-point numbers. For ESC-10, the source samples are all of type <span class="literal">int16</span> (signed 16-bit integers). Next come four <span class="literal">if</span> statements. Each one asks for a single random float, and if that float is less than 0.5, we execute the body of the <span class="literal">if</span>. This means that we apply each possible augmentation with a probability of 50 percent.</p>&#13;
<p class="indent">The first <span class="literal">if</span> shifts the sound samples in time <span class="ent">❶</span> by rolling the NumPy array, a vector, by some number of samples, <span class="literal">s</span>. This value amounts to at most an eighth of a second, <span class="literal">sr/4.0</span>. Note that the shift can be positive or negative. The quantity <span class="literal">sr/4.0</span> is the number of samples in a quarter of a second. However, the random float is in the range [<em>–</em>0.5,+0.5], so the ultimate shift is at most an eighth of a second. If the shift is negative, we need to zero samples at the end of the data; otherwise, we zero samples at the start.</p>&#13;
<p class="indent">Random noise is added by literally adding a random value of up to one-tenth of the range of the audio signal back in <span class="ent">❷</span>. When played, this adds hiss, as you might hear on an old cassette tape.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_383"/>Next comes shifting the pitch of the sample by using <span class="literal">librosa</span>. The pitch shift is expressed in musical steps, or fractions thereof. We randomly pick a float in the range [<em>–</em>10,+10] (<span class="literal">pf</span>) and pass it along with the data (<span class="literal">d</span>) and sampling rate (<span class="literal">sr</span>) to the <span class="literal">librosa</span> <span class="literal">pitch_shift</span> effect function <span class="ent">❸</span>.</p>&#13;
<p class="indent">The last augmentation uses the <span class="literal">librosa</span> function to stretch or compress time (<span class="literal">time_stretch</span>) <span class="ent">❹</span>. We adjust using an amount of time (<span class="literal">rate</span>) that is in the range [<em>–</em>0.5,+0.5]. If time was stretched, we need to chop off the extra samples to ensure that the sample length remains constant. If time was compressed, we need to add zero samples at the end.</p>&#13;
<p class="indent">Lastly, we return the new, augmented samples.</p>&#13;
<p class="indent">Running the code in <a href="ch15.xhtml#ch15lis2">Listing 15-2</a> creates a new <em>augmented</em> data directory with subdirectories <em>train</em> and <em>test</em>. These are the raw sound files that we’ll work with going forward. I encourage you to listen to some of them to understand what the augmentations have done. The filenames should help you quickly tell the originals from the augmentations.</p>&#13;
<h4 class="h4" id="lev2_138">Preprocessing Our Data</h4>&#13;
<p class="noindent">Are we ready to start building models? Not yet. Our experience told us that the dataset was too small, and we augmented accordingly. However, we haven’t yet turned the raw data into something we can pass to a model.</p>&#13;
<p class="indent">A first thought is to use the raw sound samples. These are already vectors representing the audio signal, with the time between the samples set by the sampling rate of 44,100 Hz. But we don’t want to use them as they are. The samples are all exactly five seconds long. At 44,100 samples per second, that means each sample is a vector of 44,100 × 5 = 220,500 samples. That’s too long for us to work with effectively.</p>&#13;
<p class="indent">With a bit more thought, we might be able to convince ourselves that distinguishing between a crying baby and a barking dog might not need such a high sampling rate. What if instead of keeping all the samples, we kept only every 100th sample? Moreover, do we really need five seconds’ worth of data to identify the sounds? What if we kept only the first two seconds worth?</p>&#13;
<p class="indent">Let’s keep only the first two seconds of each sound file; that’s 88,200 samples. And let’s keep only every 100th sample, so each sound file now becomes a vector of 882 elements. That’s hardly more than an unraveled MNIST digit image, and we know we can work with those.</p>&#13;
<p class="indent"><a href="ch15.xhtml#ch15lis5">Listing 15-5</a> has the code to build the actual initial version of the dataset we’ll use to build the models.</p>&#13;
<p class="programs" id="ch15lis5">import os<br/>&#13;
import random<br/>&#13;
import numpy as np<br/>&#13;
from scipy.io.wavfile import read<br/>&#13;
sr = 44100 # Hz<br/>&#13;
N = 2*sr   # number of samples to keep<br/>&#13;
w = 100    # every 100<br/>&#13;
<br/>&#13;
<span epub:type="pagebreak" id="page_384"/>afiles = [i[:-1] for i in open("augmented_train_filelist.txt")]<br/>&#13;
trn = np.zeros((len(afiles),N//w,1), dtype="int16") <br/>&#13;
lbl = np.zeros(len(afiles), dtype="uint8")<br/>&#13;
for i,t in enumerate(afiles):<br/>&#13;
 <span class="ent">❶</span> f,c = t.split()<br/>&#13;
    trn[i,:,0] = read(f)[1][:N:w]<br/>&#13;
    lbl[i] = int(c)<br/>&#13;
np.save("esc10_raw_train_audio.npy", trn)<br/>&#13;
np.save("esc10_raw_train_labels.npy", lbl)<br/>&#13;
<br/>&#13;
afiles = [i[:-1] for i in open("augmented_test_filelist.txt")]<br/>&#13;
tst = np.zeros((len(afiles),N//w,1), dtype="int16") <br/>&#13;
lbl = np.zeros(len(afiles), dtype="uint8")<br/>&#13;
for i,t in enumerate(afiles):<br/>&#13;
    f,c = t.split()<br/>&#13;
    tst[i,:,0] = read(f)[1][:N:w]<br/>&#13;
    lbl[i] = int(c)<br/>&#13;
np.save("esc10_raw_test_audio.npy", tst)<br/>&#13;
np.save("esc10_raw_test_labels.npy", lbl)</p>&#13;
<p class="figcap"><em>Listing 15-5: Building reduced samples dataset</em></p>&#13;
<p class="indent">This code builds train and test NumPy files containing the raw data. The data is from the augmented sound files we built in <a href="ch15.xhtml#ch15lis2">Listing 15-2</a>. The file list contains the file location and class label <span class="ent">❶</span>. We load each file in the list and put it into an array, either the train or test array.</p>&#13;
<p class="indent">We have a one-dimensional feature vector and a number of train or test files, so we might expect we need a two-dimensional array to store our data, either 6400 × 882 for the training set or 1600 × 882 for the test set. However, we know we’ll ultimately be working with Keras, and we know that Keras wants a dimension for the number of channels, so we define the arrays to be 6400 × 882 × 1 and 1600 × 882 × 1 instead. The most substantial line in this code is the following:</p>&#13;
<p class="programs">trn[i,:,0] = read(f)[1][:N:w]</p>&#13;
<p class="indent">It reads the current sound file, keeps only the sound samples (<span class="literal">[1]</span>), and from the sound samples keeps only the first two seconds, worth at every 100th sample, <span class="literal">[:N:w]</span>. Spend a little time with this code. If you’re confused, I’d suggest experimenting with NumPy at the interactive Python prompt to understand what it’s doing.</p>&#13;
<p class="indent">In the end, we have train and test files for the 882 element vectors and associated labels. We’ll build our first models with these. <a href="ch15.xhtml#ch15fig1">Figure 15-1</a> shows the resulting vector for a crying baby.</p>&#13;
<div class="image" id="ch15fig1"><span epub:type="pagebreak" id="page_385"/><img src="Images/15fig01.jpg" alt="image" width="643" height="479"/></div>&#13;
<p class="figcap"><em>Figure 15-1: Feature vector for a crying baby</em></p>&#13;
<p class="indent">The x-axis is sample number (think “time”), and the y-axis is the sample value.</p>&#13;
<h3 class="h3" id="lev1_102">Classifying the Audio Features</h3>&#13;
<p class="noindent">We have our training and test sets. Let’s build some models and see how they do. Since we have feature vectors, we can start quickly with classical models. After those, we can build some one-dimensional convolutional networks and see if they perform any better.</p>&#13;
<h4 class="h4" id="lev2_139">Using Classical Models</h4>&#13;
<p class="noindent">We can test the same suite of classical models we used in <a href="ch07.xhtml#ch07">Chapter 7</a> with the breast cancer dataset. <a href="ch15.xhtml#ch15lis6">Listing 15-6</a> has the setup code.</p>&#13;
<p class="programs" id="ch15lis6">   import numpy as np<br/>&#13;
   from sklearn.neighbors import NearestCentroid<br/>&#13;
   from sklearn.neighbors import KNeighborsClassifier<br/>&#13;
   from sklearn.naive_bayes import GaussianNB<br/>&#13;
   from sklearn.ensemble import RandomForestClassifier<br/>&#13;
   from sklearn.svm import LinearSVC<br/>&#13;
<br/>&#13;
   x_train = np.load("esc10_raw_train_audio.npy")[:,:,0]<br/>&#13;
   y_train = np.load("esc10_raw_train_labels.npy")<br/>&#13;
   (*\pagebreak*)<br/>&#13;
<span epub:type="pagebreak" id="page_386"/>   x_test  = np.load("esc10_raw_test_audio.npy")[:,:,0]<br/>&#13;
   y_test  = np.load("esc10_raw_test_labels.npy")<br/>&#13;
<br/>&#13;
<span class="ent">❶</span> x_train = (x_train.astype('float32') + 32768) / 65536<br/>&#13;
   x_test = (x_test.astype('float32') + 32768) / 65536<br/>&#13;
<br/>&#13;
   train(x_train, y_train, x_test, y_test)</p>&#13;
<p class="figcap"><em>Listing 15-6: Classifying the audio features with classical models, part 1</em></p>&#13;
<p class="indent">Here we import the necessary model types, load the dataset, scale it, and then call a <span class="literal">train</span> function that we’ll introduce shortly.</p>&#13;
<p class="indent">Scaling is crucial here. Consider the y-axis range for <a href="ch15.xhtml#ch15fig1">Figure 15-1</a>. It goes from about –4000 to 4000. We need to scale the data so that the range is smaller and the values are closer to being centered around 0. Recall, for the MNIST and CIFAR-10 datasets, we divided by the maximum value to scale to [0,1].</p>&#13;
<p class="indent">The sound samples are 16-bit signed integers. This means the full range of values they can take on covers [<em>–</em>32,768,+32,767]. If we make the samples floats, add 32,768, and then divide by 65,536 (twice the lower value) <span class="ent">❶</span>, we’ll get samples in the range [0,1), which is what we want.</p>&#13;
<p class="indent">Training and evaluating the classical models is straightforward, as shown in <a href="ch15.xhtml#ch15lis7">Listing 15-7</a>.</p>&#13;
<p class="programs" id="ch15lis7">def run(x_train, y_train, x_test, y_test, clf):<br/>&#13;
    clf.fit(x_train, y_train)<br/>&#13;
    score = 100.0*clf.score(x_test, y_test)<br/>&#13;
    print("score = %0.2f%%" % score)<br/>&#13;
<br/>&#13;
def train(x_train, y_train, x_test, y_test):<br/>&#13;
    print("Nearest Centroid          : ", end='')<br/>&#13;
    run(x_train, y_train, x_test, y_test, NearestCentroid())<br/>&#13;
    print("k-NN classifier (k=3)     : ", end='')<br/>&#13;
    run(x_train, y_train, x_test, y_test, KNeighborsClassifier(n_neighbors=3))<br/>&#13;
    print("k-NN classifier (k=7)     : ", end='')<br/>&#13;
    run(x_train, y_train, x_test, y_test, KNeighborsClassifier(n_neighbors=7))<br/>&#13;
    print("Naive Bayes (Gaussian)    : ", end='')<br/>&#13;
    run(x_train, y_train, x_test, y_test, GaussianNB())<br/>&#13;
    print("Random Forest (trees=  5) : ", end='')<br/>&#13;
    run(x_train, y_train, x_test, y_test, <br/>&#13;
        RandomForestClassifier(n_estimators=5))<br/>&#13;
    print("Random Forest (trees= 50) : ", end='')<br/>&#13;
    run(x_train, y_train, x_test, y_test, <br/>&#13;
        RandomForestClassifier(n_estimators=50))<br/>&#13;
    print("Random Forest (trees=500) : ", end='')<br/>&#13;
    run(x_train, y_train, x_test, y_test, <br/>&#13;
        RandomForestClassifier(n_estimators=500))<br/>&#13;
    print("Random Forest (trees=1000): ", end='')<br/>&#13;
    run(x_train, y_train, x_test, y_test, <br/>&#13;
<span epub:type="pagebreak" id="page_387"/>        RandomForestClassifier(n_estimators=1000))<br/>&#13;
    print("LinearSVM (C=0.01)        : ", end='')<br/>&#13;
    run(x_train, y_train, x_test, y_test, LinearSVC(C=0.01))<br/>&#13;
    print("LinearSVM (C=0.1)         : ", end='')<br/>&#13;
    run(x_train, y_train, x_test, y_test, LinearSVC(C=0.1))<br/>&#13;
    print("LinearSVM (C=1.0)         : ", end='')<br/>&#13;
    run(x_train, y_train, x_test, y_test, LinearSVC(C=1.0))<br/>&#13;
    print("LinearSVM (C=10.0)        : ", end='')<br/>&#13;
    run(x_train, y_train, x_test, y_test, LinearSVC(C=10.0))</p>&#13;
<p class="figcap"><em>Listing 15-7: Classifying the audio features with classical models, part 2</em></p>&#13;
<p class="indent">The <span class="literal">train</span> function creates the particular model instances and then calls <span class="literal">run</span>. We saw this same code structure in <a href="ch07.xhtml#ch07">Chapter 7</a>. The <span class="literal">run</span> function uses <span class="literal">fit</span> to train the model and <span class="literal">score</span> to score the model on the test set. For the time being, we’ll evaluate the models based solely on their overall accuracy (the score). Running this code produces output like this:</p>&#13;
<p class="programs">Nearest Centroid          : score = 11.9%<br/>&#13;
k-NN classifier (k=3)     : score = 12.1%<br/>&#13;
k-NN classifier (k=7)     : score = 10.5%<br/>&#13;
Naive Bayes (Gaussian)    : score = 28.1%<br/>&#13;
Random Forest (trees=  5) : score = 22.6%<br/>&#13;
Random Forest (trees= 50) : score = 30.8%<br/>&#13;
Random Forest (trees=500) : score = 32.8%<br/>&#13;
Random Forest (trees=1000): score = 34.4%<br/>&#13;
LinearSVM (C=0.01)        : score = 16.5%<br/>&#13;
LinearSVM (C=0.1)         : score = 17.5%<br/>&#13;
LinearSVM (C=1.0)         : score = 13.4%<br/>&#13;
LinearSVM (C=10.0)        : score = 10.2%</p>&#13;
<p class="indent">We can see very quickly that the classical models have performed terribly. Many of them are essentially guessing the class label. There are 10 classes, so random chance guessing should have an accuracy around 10 percent. The best-performing classical model is a Random Forest with 1,000 trees, but even that is performing at only 34.44 percent—far too low an overall accuracy to make the model one we’d care to use in most cases. The dataset is not a simple one, at least not for old-school approaches. Somewhat surprisingly, the Gaussian Naïve Bayes model is right 28 percent of the time. Recall that the Gaussian Naïve Bayes expects the samples to be independent from one another. Here the independence assumption between the sound samples for a particular test input is not valid. The feature vector, in this case, represents a signal evolving in time, not a collection of features that are independent of each other.</p>&#13;
<p class="indent">The models that failed the most are Nearest Centroid, <em>k</em>-NN, and the linear SVMs. We have a reasonably high-dimensional input, 882 elements, but only 6,400 of them in the training set. That is likely too few samples for the nearest neighbor classifiers to make use of—the feature space is too sparsely populated. Once again, the curse of dimensionality is rearing its ugly head. <span epub:type="pagebreak" id="page_388"/>The linear SVM fails because the features seem not to be linearly separable. We did not try an RBF (Gaussian kernel) SVM, but we’ll leave that as an exercise for the reader. If you do try it, remember that there are now two hyperparameters to tune: <em>C</em> and <em>γ</em>.</p>&#13;
<h4 class="h4" id="lev2_140">Using a Traditional Neural Network</h4>&#13;
<p class="noindent">We haven’t yet tried a traditional neural network. We could use the sklearn <span class="literal">MLPClassifier</span> class as we did before, but this is a good time to show how to implement a traditional network in Keras. <a href="ch15.xhtml#ch15lis8">Listing 15-8</a> has the code.</p>&#13;
<p class="programs" id="ch15lis8">import keras<br/>&#13;
from keras.models import Sequential<br/>&#13;
from keras.layers import Dense, Dropout, Flatten<br/>&#13;
from keras import backend as K<br/>&#13;
import numpy as np<br/>&#13;
<br/>&#13;
batch_size = 32<br/>&#13;
num_classes = 10<br/>&#13;
epochs = 16<br/>&#13;
nsamp = (882,1)<br/>&#13;
x_train = np.load("esc10_raw_train_audio.npy")<br/>&#13;
y_train = np.load("esc10_raw_train_labels.npy")<br/>&#13;
x_test  = np.load("esc10_raw_test_audio.npy")<br/>&#13;
y_test  = np.load("esc10_raw_test_labels.npy")<br/>&#13;
x_train = (x_train.astype('float32') + 32768) / 65536<br/>&#13;
x_test = (x_test.astype('float32') + 32768) / 65536<br/>&#13;
y_train = keras.utils.to_categorical(y_train, num_classes)<br/>&#13;
y_test = keras.utils.to_categorical(y_test, num_classes)<br/>&#13;
<br/>&#13;
model = Sequential()<br/>&#13;
model.add(Dense(1024, activation='relu', input_shape=nsamp))<br/>&#13;
model.add(Dropout(0.5))<br/>&#13;
model.add(Dense(512, activation='relu'))<br/>&#13;
model.add(Dropout(0.5))<br/>&#13;
model.add(Flatten())<br/>&#13;
model.add(Dense(num_classes, activation='softmax'))<br/>&#13;
<br/>&#13;
model.compile(loss=keras.losses.categorical_crossentropy,<br/>&#13;
              optimizer=keras.optimizers.Adam(),<br/>&#13;
              metrics=['accuracy'])<br/>&#13;
model.fit(x_train, y_train,<br/>&#13;
          batch_size=batch_size,<br/>&#13;
          epochs=epochs,<br/>&#13;
          verbose=0,<br/>&#13;
          validation_data=(x_test, y_test))<br/>&#13;
          (*\pagebreak*)<br/>&#13;
<span epub:type="pagebreak" id="page_389"/>score = model.evaluate(x_test, y_test, verbose=0)<br/>&#13;
print('Test accuracy:', score[1])</p>&#13;
<p class="figcap"><em>Listing 15-8: A traditional neural network in Keras</em></p>&#13;
<p class="indent">After loading the necessary modules, we load the data itself and scale it as we did for the classical models. Next, we build the model architecture. We need only <span class="literal">Dense</span> layers and <span class="literal">Dropout</span> layers. We do put in a <span class="literal">Flatten</span> layer to eliminate the extra dimension (note the shape of <span class="literal">nsamp</span>) before the final softmax output. Unfortunately, this model does not improve things for us: we achieve an accuracy of only 27.6 percent.</p>&#13;
<h4 class="h4" id="lev2_141">Using a Convolutional Neural Network</h4>&#13;
<p class="noindent">Classical models and the traditional neural network don’t cut it. We should not be too surprised, but it was easy to give them a try. Let’s move on and apply a one-dimensional convolutional neural network to this dataset to see if it performs any better.</p>&#13;
<p class="indent">We haven’t worked with one-dimensional CNNs yet. Besides the structure of the input data, the only difference is that we replace calls to <span class="literal">Conv2D</span> and <span class="literal">MaxPooling2D</span> with calls to <span class="literal">Conv1D</span> and <span class="literal">MaxPooling1D</span>.</p>&#13;
<p class="indent">The code for the first model we’ll try is shown in <a href="ch15.xhtml#ch15lis9">Listing 15-9</a>.</p>&#13;
<p class="programs" id="ch15lis9">import keras<br/>&#13;
from keras.models import Sequential<br/>&#13;
from keras.layers import Dense, Dropout, Flatten<br/>&#13;
from keras.layers import Conv1D, MaxPooling1D<br/>&#13;
import numpy as np<br/>&#13;
<br/>&#13;
batch_size = 32<br/>&#13;
num_classes = 10<br/>&#13;
epochs = 16<br/>&#13;
nsamp = (882,1)<br/>&#13;
x_train = np.load("esc10_raw_train_audio.npy")<br/>&#13;
y_train = np.load("esc10_raw_train_labels.npy")<br/>&#13;
x_test  = np.load("esc10_raw_test_audio.npy")<br/>&#13;
y_test  = np.load("esc10_raw_test_labels.npy")<br/>&#13;
x_train = (x_train.astype('float32') + 32768) / 65536<br/>&#13;
x_test = (x_test.astype('float32') + 32768) / 65536<br/>&#13;
y_train = keras.utils.to_categorical(y_train, num_classes)<br/>&#13;
y_test = keras.utils.to_categorical(y_test, num_classes)<br/>&#13;
model = Sequential()<br/>&#13;
model.add(Conv1D(32, kernel_size=3, activation='relu',<br/>&#13;
                 input_shape=nsamp))<br/>&#13;
model.add(MaxPooling1D(pool_size=3))<br/>&#13;
model.add(Dropout(0.25))<br/>&#13;
model.add(Flatten())<br/>&#13;
model.add(Dense(512, activation='relu'))<br/>&#13;
model.add(Dropout(0.5))<br/>&#13;
<span epub:type="pagebreak" id="page_390"/>model.add(Dense(num_classes, activation='softmax'))<br/>&#13;
model.compile(loss=keras.losses.categorical_crossentropy,<br/>&#13;
              optimizer=keras.optimizers.Adam(),<br/>&#13;
              metrics=['accuracy'])<br/>&#13;
history = model.fit(x_train, y_train,<br/>&#13;
          batch_size=batch_size,<br/>&#13;
          epochs=epochs,<br/>&#13;
          verbose=1,<br/>&#13;
          validation_data=(x_test[:160], y_test[:160]))<br/>&#13;
score = model.evaluate(x_test[160:], y_test[160:], verbose=0)<br/>&#13;
print('Test accuracy:', score[1])</p>&#13;
<p class="figcap"><em>Listing 15-9: A 1D CNN in Keras</em></p>&#13;
<p class="indent">This model loads and preprocesses the dataset as before. This architecture, which we’ll call the <em>shallow</em> architecture, has a single convolutional layer of 32 filters with a kernel size of 3. We’ll vary this kernel size in the same way we tried different 2D kernel sizes for the MNIST models. Following the <span class="literal">Conv1D</span> layer is a single max-pooling layer with a pool kernel size of 3. <span class="literal">Dropout</span> and <span class="literal">Flatten</span> layers come next before a single <span class="literal">Dense</span> layer of 512 nodes with dropout. A softmax layer completes the architecture.</p>&#13;
<p class="indent">We’ll train for 16 epochs using a batch size of 32. We’ll keep the training history so we can examine the losses and validation performance as a function of epoch. There are 1,600 test samples. We’ll use 10 percent for the training validation and the remaining 90 percent for the overall accuracy. Finally, we’ll vary the <span class="literal">Conv1D</span> kernel size from 3 to 33 in an attempt to find one that works well with the training data.</p>&#13;
<p class="indent">Let’s define four other architectures. We’ll refer to them as <em>medium</em>, <em>deep0</em>, <em>deep1</em>, and <em>deep2</em>. With no prior experience working with this data, it makes sense to try multiple architectures. At present, there’s no way to know ahead of time what the best architecture is for a new dataset. All we have is our previous experience.</p>&#13;
<p class="indent"><a href="ch15.xhtml#ch15lis10">Listing 15-10</a> lists the specific architectures, separated by comments.</p>&#13;
<p class="programs" id="ch15lis10"># medium<br/>&#13;
model = Sequential() <br/>&#13;
model.add(Conv1D(32, kernel_size=3, activation='relu',<br/>&#13;
                 input_shape=nsamp))<br/>&#13;
model.add(Conv1D(64, kernel_size=3, activation='relu'))<br/>&#13;
model.add(Conv1D(64, kernel_size=3, activation='relu'))<br/>&#13;
model.add(MaxPooling1D(pool_size=3))<br/>&#13;
model.add(Dropout(0.25))<br/>&#13;
model.add(Flatten())<br/>&#13;
model.add(Dense(512, activation='relu'))<br/>&#13;
model.add(Dropout(0.5))<br/>&#13;
model.add(Dense(num_classes, activation='softmax'))<br/>&#13;
<br/>&#13;
# deep0<br/>&#13;
model = Sequential() <br/>&#13;
<span epub:type="pagebreak" id="page_391"/>model.add(Conv1D(32, kernel_size=3, activation='relu',<br/>&#13;
                 input_shape=nsamp))<br/>&#13;
model.add(Conv1D(64, kernel_size=3, activation='relu'))<br/>&#13;
model.add(Conv1D(64, kernel_size=3, activation='relu'))<br/>&#13;
model.add(MaxPooling1D(pool_size=3))<br/>&#13;
model.add(Dropout(0.25))<br/>&#13;
model.add(Conv1D(64, kernel_size=3, activation='relu'))<br/>&#13;
model.add(Conv1D(64, kernel_size=3, activation='relu'))<br/>&#13;
model.add(MaxPooling1D(pool_size=3))<br/>&#13;
model.add(Dropout(0.25))<br/>&#13;
model.add(Flatten())<br/>&#13;
model.add(Dense(512, activation='relu'))<br/>&#13;
model.add(Dropout(0.5))<br/>&#13;
model.add(Dense(num_classes, activation='softmax'))<br/>&#13;
<br/>&#13;
# deep1<br/>&#13;
model = Sequential() <br/>&#13;
model.add(Conv1D(32, kernel_size=3, activation='relu',<br/>&#13;
                 input_shape=nsamp))<br/>&#13;
model.add(Conv1D(64, kernel_size=3, activation='relu'))<br/>&#13;
model.add(Conv1D(64, kernel_size=3, activation='relu'))<br/>&#13;
model.add(MaxPooling1D(pool_size=3))<br/>&#13;
model.add(Dropout(0.25))<br/>&#13;
model.add(Conv1D(64, kernel_size=3, activation='relu'))<br/>&#13;
model.add(Conv1D(64, kernel_size=3, activation='relu'))<br/>&#13;
model.add(MaxPooling1D(pool_size=3))<br/>&#13;
model.add(Dropout(0.25))<br/>&#13;
model.add(Conv1D(64, kernel_size=3, activation='relu'))<br/>&#13;
model.add(Conv1D(64, kernel_size=3, activation='relu'))<br/>&#13;
model.add(MaxPooling1D(pool_size=3))<br/>&#13;
model.add(Dropout(0.25))<br/>&#13;
model.add(Flatten())<br/>&#13;
model.add(Dense(512, activation='relu'))<br/>&#13;
model.add(Dropout(0.5))<br/>&#13;
model.add(Dense(num_classes, activation='softmax'))<br/>&#13;
<br/>&#13;
# deep2<br/>&#13;
model = Sequential() <br/>&#13;
model.add(Conv1D(32, kernel_size=3, activation='relu',<br/>&#13;
                 input_shape=nsamp))<br/>&#13;
model.add(Conv1D(64, kernel_size=3, activation='relu'))<br/>&#13;
model.add(Conv1D(64, kernel_size=3, activation='relu'))<br/>&#13;
model.add(MaxPooling1D(pool_size=3))<br/>&#13;
model.add(Dropout(0.25))<br/>&#13;
model.add(Conv1D(64, kernel_size=3, activation='relu'))<br/>&#13;
model.add(Conv1D(64, kernel_size=3, activation='relu'))<br/>&#13;
model.add(MaxPooling1D(pool_size=3))<br/>&#13;
<span epub:type="pagebreak" id="page_392"/>model.add(Dropout(0.25))<br/>&#13;
model.add(Conv1D(64, kernel_size=3, activation='relu'))<br/>&#13;
model.add(Conv1D(64, kernel_size=3, activation='relu'))<br/>&#13;
model.add(MaxPooling1D(pool_size=3))<br/>&#13;
model.add(Dropout(0.25))<br/>&#13;
model.add(Conv1D(64, kernel_size=3, activation='relu'))<br/>&#13;
model.add(Conv1D(64, kernel_size=3, activation='relu'))<br/>&#13;
model.add(MaxPooling1D(pool_size=3))<br/>&#13;
model.add(Dropout(0.25))<br/>&#13;
model.add(Flatten())<br/>&#13;
model.add(Dense(512, activation='relu'))<br/>&#13;
model.add(Dropout(0.5))<br/>&#13;
model.add(Dense(num_classes, activation='softmax'))</p>&#13;
<p class="figcap"><em>Listing 15-10: Different 1D CNN architect</em></p>&#13;
<p class="indent">If we train multiple models, varying the first <span class="literal">Conv1D</span> kernel size each time, we get the results in <a href="ch15.xhtml#ch15tab1">Table 15-1</a>. We’ve highlighted the best-performing model for each architecture.</p>&#13;
<p class="tabcap" id="ch15tab1"><strong>Table 15-1:</strong> Test Set Accuracies by Convolutional Kernel Size and Model Architecture</p>&#13;
<table class="bordertb">&#13;
<colgroup>&#13;
<col style="width:25%"/>&#13;
<col style="width:15%"/>&#13;
<col style="width:15%"/>&#13;
<col style="width:15%"/>&#13;
<col style="width:15%"/>&#13;
<col style="width:15%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr class="borderb">&#13;
<th style="vertical-align: top"><p class="tab"><strong>Kernel size</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>Shallow</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>Medium</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>Deep0</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>Deep1</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>Deep2</strong></p></th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab">3</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>44.51</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">41.39</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>48.75</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>54.03</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">9.93</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">5</p></td>&#13;
<td style="vertical-align: top"><p class="tab">43.47</p></td>&#13;
<td style="vertical-align: top"><p class="tab">41.74</p></td>&#13;
<td style="vertical-align: top"><p class="tab">44.72</p></td>&#13;
<td style="vertical-align: top"><p class="tab">53.96</p></td>&#13;
<td style="vertical-align: top"><p class="tab">48.47</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab">7</p></td>&#13;
<td style="vertical-align: top"><p class="tab">38.47</p></td>&#13;
<td style="vertical-align: top"><p class="tab">40.97</p></td>&#13;
<td style="vertical-align: top"><p class="tab">46.18</p></td>&#13;
<td style="vertical-align: top"><p class="tab">52.64</p></td>&#13;
<td style="vertical-align: top"><p class="tab">49.31</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">9</p></td>&#13;
<td style="vertical-align: top"><p class="tab">41.46</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>43.06</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">46.88</p></td>&#13;
<td style="vertical-align: top"><p class="tab">48.96</p></td>&#13;
<td style="vertical-align: top"><p class="tab">9.72</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab">11</p></td>&#13;
<td style="vertical-align: top"><p class="tab">39.65</p></td>&#13;
<td style="vertical-align: top"><p class="tab">40.21</p></td>&#13;
<td style="vertical-align: top"><p class="tab">45.21</p></td>&#13;
<td style="vertical-align: top"><p class="tab">52.99</p></td>&#13;
<td style="vertical-align: top"><p class="tab">10.07</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">13</p></td>&#13;
<td style="vertical-align: top"><p class="tab">42.71</p></td>&#13;
<td style="vertical-align: top"><p class="tab">41.67</p></td>&#13;
<td style="vertical-align: top"><p class="tab">46.53</p></td>&#13;
<td style="vertical-align: top"><p class="tab">50.56</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>52.57</strong></p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab">15</p></td>&#13;
<td style="vertical-align: top"><p class="tab">40.00</p></td>&#13;
<td style="vertical-align: top"><p class="tab">42.78</p></td>&#13;
<td style="vertical-align: top"><p class="tab">46.53</p></td>&#13;
<td style="vertical-align: top"><p class="tab">50.14</p></td>&#13;
<td style="vertical-align: top"><p class="tab">47.08</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">33</p></td>&#13;
<td style="vertical-align: top"><p class="tab">27.57</p></td>&#13;
<td style="vertical-align: top"><p class="tab">42.22</p></td>&#13;
<td style="vertical-align: top"><p class="tab">41.39</p></td>&#13;
<td style="vertical-align: top"><p class="tab">48.75</p></td>&#13;
<td style="vertical-align: top"><p class="tab">9.86</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="indent">Looking at <a href="ch15.xhtml#ch15tab1">Table 15-1</a>, we see a general trend of accuracy improving as the model depth increases. However, at the deep2 model, things start to fall apart. Some of the models fail to converge, showing an accuracy equivalent to random guessing. The deep1 model is the best performing for all kernel sizes. When looking across by kernel size, the kernel with width 3 is the best performing for three of the five architectures. All of this implies that the best combination for the 1D CNNs is to use an initial kernel of width 3 and the deep1 architecture.</p>&#13;
<p class="indent">We trained this architecture for only 16 epochs. Will things improve if we train for more? Let’s train the deep1 model for 60 epochs and plot the training and validation loss and error to see how they converge (or don’t). Doing this produces <a href="ch15.xhtml#ch15fig2">Figure 15-2</a>, where we see the training and validation loss (top) and error (bottom) as a function of epoch.</p>&#13;
<div class="image" id="ch15fig2"><span epub:type="pagebreak" id="page_393"/><img src="Images/15fig02.jpg" alt="image" width="668" height="1009"/></div>&#13;
<p class="figcap"><em>Figure 15-2: Training and validation loss (top) and error (bottom) for the deep1 architecture</em></p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_394"/>Immediately, we should pick up on the explosion of the loss for the validation set. The training loss is continually decreasing until after about epoch 18 or so; then the validation loss goes up and becomes oscillatory. This is a clear example of overfitting. The likely source of this overfitting is our limited training set size, only 6,400 samples, even after data augmentation. The validation error remains more or less constant after initially decreasing. The conclusion is that we cannot expect to do much better than an overall accuracy of about 54 percent for this dataset using one-dimensional vectors.</p>&#13;
<p class="indent">If we want to improve, we need to be more expressive with our dataset. Fortunately for us, we have another preprocessing trick up our sleeves.</p>&#13;
<h3 class="h3" id="lev1_103">Spectrograms</h3>&#13;
<p class="noindent">Let’s return to our augmented set of audio files. To build the dataset, we took the sound samples, keeping only two seconds’ worth and only every 100th sample. The best we could do is an accuracy of a little more than 50 percent.</p>&#13;
<p class="indent">However, if we work with a small set of sound samples from an input audio file, say 200 milliseconds worth, we can use the vector of samples to calculate the <em>Fourier transform</em>. The Fourier transform of a signal measured at regular intervals tells us the frequencies that went into building the signal. Any signal can be thought of as the sum of many different sine and cosine waves. If the signal is composed of only a few waves, like the sound you might get from an instrument like the ocarina, then the Fourier transform will have essentially a few peaks at those frequencies. If the signal is complex, like speech or music, then the Fourier transform will have many different frequencies, leading to many different peaks.</p>&#13;
<p class="indent">The Fourier transform itself is complex-valued: each element has both a real and an imaginary component. You can write it as <em>a</em> + <em>bi</em>, where <em>a</em> and <em>b</em> are real numbers and <span class="middle"><img src="Images/394equ01.jpg" alt="Image" width="75" height="21"/></span>. If we use the absolute value of these quantities, we’ll get a real number representing the energy of a particular frequency. This is called the <em>power spectrum</em> of the signal. A simple tone might have energy in only a few frequencies, while something like a cymbal crash or white noise will have energy more or less evenly distributed among all frequencies. <a href="ch15.xhtml#ch15fig3">Figure 15-3</a> shows two power spectra.</p>&#13;
<div class="image" id="ch15fig3"><span epub:type="pagebreak" id="page_395"/><img src="Images/15fig03.jpg" alt="image" width="643" height="495"/></div>&#13;
<p class="figcap"><em>Figure 15-3: Power spectrum of an ocarina (top) and cymbal (bottom)</em></p>&#13;
<p class="indent">On the top is the spectrum of an ocarina, and on the bottom is a cymbal crash. As expected, the ocarina has energy in only a few frequencies, while the cymbal uses all the frequencies. The important point for us is that <em>visually</em> the spectra are quite different from each other. (The spectra were made with Audacity, an excellent open source audio processing tool.)</p>&#13;
<p class="indent">We could use these power spectra as feature vectors, but they represent only the spectra of tiny slices of time. The sound samples are five seconds long. Instead of using a spectrum, we will use a <em>spectrogram</em>. The spectrogram is an image made up of columns that represent individual spectra. This means that the x-axis represents time and the y-axis represents frequency. The color of a pixel is proportional to the energy in that frequency at that time.</p>&#13;
<p class="indent">In other words, a spectrogram is what we get if we orient the power spectra vertically and use color to represent intensity at a given frequency. With this approach, we can turn an entire sound sample into an image. For example, <a href="ch15.xhtml#ch15fig4">Figure 15-4</a> shows the spectrogram of a crying baby. Compare this to the feature vector of <a href="ch15.xhtml#ch15fig1">Figure 15-1</a>.</p>&#13;
<div class="image" id="ch15fig4"><span epub:type="pagebreak" id="page_396"/><img src="Images/15fig04.jpg" alt="image" width="532" height="367"/></div>&#13;
<p class="figcap"><em>Figure 15-4: Spectrogram of a crying baby</em></p>&#13;
<p class="indent">To create spectrograms of the augmented audio files, we need a new tool and a bit of code. The tool we need is called <span class="literal">sox</span>. It’s not a Python library, but a command line tool. Odds are that it is already installed if you are using our canonical Ubuntu Linux distribution. If not, you can install it:</p>&#13;
<p class="programs">$ <span class="codestrong1">sudo apt-get install sox</span></p>&#13;
<p class="indent">We’ll use <span class="literal">sox</span> from inside a Python script to produce the spectrogram images we want. Each sound file becomes a new spectrogram image.</p>&#13;
<p class="indent">The source code to process the training images is in <a href="ch15.xhtml#ch15lis11">Listing 15-11</a>.</p>&#13;
<p class="programs" id="ch15lis11">   import os<br/>&#13;
   import numpy as np<br/>&#13;
   from PIL import Image<br/>&#13;
<br/>&#13;
   rows = 100 <br/>&#13;
   cols = 160 <br/>&#13;
<span class="ent">❶</span> flist = [i[:-1] for i in open("augmented_train_filelist.txt")]<br/>&#13;
   N = len(flist)<br/>&#13;
   img = np.zeros((N,rows,cols,3), dtype="uint8")<br/>&#13;
   lbl = np.zeros(N, dtype="uint8")<br/>&#13;
   p = []<br/>&#13;
<br/>&#13;
   for i,f in enumerate(flist):<br/>&#13;
       src, c = f.split()<br/>&#13;
    <span class="ent">❷</span> os.system("sox %s -n spectrogram" % src)<br/>&#13;
       im = np.array(Image.open("spectrogram.png").convert("RGB"))<br/>&#13;
    <span class="ent">❸</span> im = im[42:542,58:858,:]<br/>&#13;
       im = Image.fromarray(im).resize((cols,rows))<br/>&#13;
       img[i,:,:,:] = np.array(im)<br/>&#13;
<span epub:type="pagebreak" id="page_397"/>       lbl[i] = int(c)<br/>&#13;
       p.append(os.path.abspath(src))<br/>&#13;
<br/>&#13;
   os.system("rm -rf spectrogram.png")<br/>&#13;
   p = np.array(p)<br/>&#13;
<span class="ent">❹</span> idx = np.argsort(np.random.random(N))<br/>&#13;
   img = img[idx]<br/>&#13;
   lbl = lbl[idx]<br/>&#13;
   p = p[idx]<br/>&#13;
   np.save("esc10_spect_train_images.npy", img)<br/>&#13;
   np.save("esc10_spect_train_labels.npy", lbl)<br/>&#13;
   np.save("esc10_spect_train_paths.npy", p)</p>&#13;
<p class="figcap"><em>Listing 15-11: Building the spectrograms</em></p>&#13;
<p class="indent">We start by defining the size of the spectrogram. This is the input to our model, and we don’t want it to be too big because we’re limited in the size of the inputs we can process. We’ll settle for 100×160 pixels. We then load the training file list <span class="ent">❶</span> and create NumPy arrays to hold the spectrogram images and associated labels. The list <span class="literal">p</span> will hold the pathname of the source for each spectrogram in case we want to get back to the original sound file at some point. In general, it’s a good idea to preserve information to get back to the source of derived datasets.</p>&#13;
<p class="indent">Then we loop over the file list. We get the filename and class label and then call <span class="literal">sox</span>, passing in the source sound filename <span class="ent">❷</span>. The <span class="literal">sox</span> application is sophisticated. The syntax here turns the given sound file into a spectrogram image with the name <em>spectrogram.png</em>. We immediately load the output spectrogram into <span class="literal">im</span>, making sure it’s an RGB file with no transparency layer (hence the call to <span class="literal">convert("RGB")</span>).</p>&#13;
<p class="indent">The spectrogram created by <span class="literal">sox</span> has a border with frequency and time information. We want only the spectrogram image portion, so we subset the image <span class="ent">❸</span>. We determined the indices we’re using empirically. It’s possible, but somewhat unlikely, that a newer version of <span class="literal">sox</span> will require tweaking these to avoid including any border pixels.</p>&#13;
<p class="indent">Next, we resize the spectrogram so that it fits in our 100×160 pixel array. This is downsampling, true, but hopefully enough characteristic information is still present to allow a model to learn the difference between classes. We keep the downsampled spectrogram and the associated class label and sound file path.</p>&#13;
<p class="indent">When we’ve generated all the spectrograms, the loop ends, and we remove the final extraneous spectrogram PNG file. We convert the list of sound file paths to a NumPy array so we can store it in the same manner as the images and labels. Finally, we randomize the order of the images as a precaution against any implicit sorting that might group classes <span class="ent">❹</span>. This is <span epub:type="pagebreak" id="page_398"/>so that minibatches extracted sequentially are representative of the mix of classes as a whole. To conclude, we write the images, labels, and pathnames to disk. We repeat this entire process for the test set.</p>&#13;
<p class="indent">Are we able to visually tell the difference between the spectrograms of different classes? If we can do that easily, then we have a good shot of getting a model to tell the difference, too. <a href="ch15.xhtml#ch15fig5">Figure 15-5</a> shows 10 spectrograms of the same class in each row.</p>&#13;
<div class="image" id="ch15fig5"><img src="Images/15fig05.jpg" alt="image" width="666" height="392"/></div>&#13;
<p class="figcap"><em>Figure 15-5: Sample spectrograms for each class in ESC-10. Each row shows 10 examples from the same class.</em></p>&#13;
<p class="indent">Visually, we can usually tell the spectra apart, which is encouraging. With our spectrograms in hand, we are ready to try some 2D CNNs to see if they do better than the 1D CNNs.</p>&#13;
<h3 class="h3" id="lev1_104">Classifying Spectrograms</h3>&#13;
<p class="noindent">To work with the spectrogram dataset, we need 2D CNNs. A possible starting point is to convert the shallow 1D CNN architecture to 2D by changing <span class="literal">Conv1D</span> to <span class="literal">Conv2D</span>, and <span class="literal">MaxPooling1D</span> to <span class="literal">MaxPooling2D</span>. However, if we do this, the resulting model has 30.7 million parameters, which is many more than we want to work with. Instead, let’s opt for a deeper architecture that has fewer parameters and then explore the effect of different first convolutional layer kernel sizes. The code is in <a href="ch15.xhtml#ch15lis12">Listing 15-12</a>.</p>&#13;
<p class="programs" id="ch15lis12">import keras<br/>&#13;
from keras.models import Sequential<br/>&#13;
from keras.layers import Dense, Dropout, Flatten<br/>&#13;
from keras.layers import Conv2D, MaxPooling2D<br/>&#13;
<span epub:type="pagebreak" id="page_399"/>import numpy as np<br/>&#13;
<br/>&#13;
batch_size = 16<br/>&#13;
num_classes = 10<br/>&#13;
epochs = 16<br/>&#13;
img_rows, img_cols = 100, 160 <br/>&#13;
input_shape = (img_rows, img_cols, 3)<br/>&#13;
x_train = np.load("esc10_spect_train_images.npy")<br/>&#13;
y_train = np.load("esc10_spect_train_labels.npy")<br/>&#13;
x_test = np.load("esc10_spect_test_images.npy")<br/>&#13;
y_test = np.load("esc10_spect_test_labels.npy")<br/>&#13;
x_train = x_train.astype('float32') / 255 <br/>&#13;
x_test = x_test.astype('float32') / 255 <br/>&#13;
y_train = keras.utils.to_categorical(y_train, num_classes)<br/>&#13;
y_test = keras.utils.to_categorical(y_test, num_classes)<br/>&#13;
<br/>&#13;
model = Sequential()<br/>&#13;
model.add(Conv2D(32, kernel_size=(3,3), activation='relu',<br/>&#13;
                 input_shape=input_shape))<br/>&#13;
model.add(Conv2D(64, (3, 3), activation='relu'))<br/>&#13;
model.add(MaxPooling2D(pool_size=(2, 2)))<br/>&#13;
model.add(Dropout(0.25))<br/>&#13;
model.add(Conv2D(64, (3, 3), activation='relu'))<br/>&#13;
model.add(MaxPooling2D(pool_size=(2, 2)))<br/>&#13;
model.add(Dropout(0.25))<br/>&#13;
model.add(Flatten())<br/>&#13;
model.add(Dense(128, activation='relu'))<br/>&#13;
model.add(Dropout(0.5))<br/>&#13;
model.add(Dense(num_classes, activation='softmax'))<br/>&#13;
<br/>&#13;
model.compile(loss=keras.losses.categorical_crossentropy,<br/>&#13;
              optimizer=keras.optimizers.Adam(),<br/>&#13;
              metrics=['accuracy'])<br/>&#13;
history = model.fit(x_train, y_train,<br/>&#13;
          batch_size=batch_size, epochs=epochs,<br/>&#13;
          verbose=0, validation_data=(x_test, y_test))<br/>&#13;
score = model.evaluate(x_test, y_test, verbose=0)<br/>&#13;
print('Test accuracy:', score[1])<br/>&#13;
model.save("esc10_cnn_deep_3x3_model.h5")</p>&#13;
<p class="figcap"><em>Listing 15-12: Classifying spectrograms</em></p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_400"/>Here we are using a minibatch size of 16 for 16 epochs along with the Adam optimizer. The model architecture has two convolutional layers, a max-pooling layer with dropout, another convolutional layer, and a second max-pooling layer with dropout. There is a single dense layer of 128 nodes before the softmax output.</p>&#13;
<p class="indent">We’ll test two kernel sizes for the first convolutional layer: 3 × 3 and 7 × 7. The 3 × 3 configuration is shown in <a href="ch15.xhtml#ch15lis12">Listing 15-12</a>. Replace <span class="literal">(3,3)</span> with <span class="literal">(7,7)</span> to alter the size. All the initial 1D convolutional runs used a single training of the model for evaluation. We know that because of random initialization, we’ll get slightly different results from training to training, even if nothing else changes. For the 2D CNNs, let’s train each model six times and present the overall accuracy as a mean ± standard error of the mean. Doing just this gives us the following overall accuracies:</p>&#13;
<table class="bordertb">&#13;
<colgroup>&#13;
<col style="width:50%"/>&#13;
<col style="width:50%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr class="borderb">&#13;
<th style="vertical-align: top"><p class="tab"><strong>Kernel size</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>Score</strong></p></th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab">3 × 3</p></td>&#13;
<td style="vertical-align: top"><p class="tab">78.78 ± 0.60%</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">7 × 7</p></td>&#13;
<td style="vertical-align: top"><p class="tab">78.44 ± 0.72%</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="noindent">This indicates that there is no meaningful difference between using a 3 × 3 initial convolutional layer kernel size or a 7 × 7. Therefore, we’ll stick with 3 × 3 going forward.</p>&#13;
<p class="indent"><a href="ch15.xhtml#ch15fig6">Figure 15-6</a> shows the training and validation loss (top) and error (bottom) for one run of the 2D CNN trained on the spectrograms. As we saw in the 1D CNN case, after only a few epochs, the validation error starts to increase.</p>&#13;
<p class="indent">The 2D CNN performs significantly better than the 1D CNN did: 79 percent accuracy versus only 54 percent. This level of accuracy is still not particularly useful for many applications, but for others, it might be completely acceptable. Nevertheless, we’d like to do better if we can. It’s worth noting that we have a few limitations in our data and, for that matter, our hardware, since we are restricting ourselves to a CPU-only approach, which limits the amount of time we are willing to wait for models to train. Here is where the some 25-fold increase in performance possible with GPUs would be helpful, assuming our use case allows for using GPUs. If we’re planning to run the model on an embedded system, for example, we might not have a GPU available, so we’d want to stick with a smaller model anyway.</p>&#13;
<div class="image" id="ch15fig6"><span epub:type="pagebreak" id="page_401"/><img src="Images/15fig06.jpg" alt="image" width="668" height="1009"/></div>&#13;
<p class="figcap"><em>Figure 15-6: Training and validation loss (top) and error (bottom) for the 2D CNN architecture</em></p>&#13;
<h4 class="h4" id="lev2_142"><span epub:type="pagebreak" id="page_402"/>Initialization, Regularization, and Batch Normalization</h4>&#13;
<p class="noindent">The literature tells us that there are other things we can try. We already augmented the dataset, a powerful technique, and we are using dropout, another powerful technique. We can try using a new initialization strategy, He initialization, which has been shown to often work better than Glorot initialization, the Keras default. We can also try applying L2 regularization, which Keras implements as weight decay per layer. See <a href="ch10.xhtml#ch10">Chapter 10</a> for a refresher on these techniques.</p>&#13;
<p class="indent">To set the layer initialization algorithm, we need to add the following keyword to the <span class="literal">Conv2D</span> and first <span class="literal">Dense</span> layer:</p>&#13;
<p class="programs">kernel_initializer="he_normal"</p>&#13;
<p class="indent">To add L2 regularization, we add the following keyword to the <span class="literal">Conv2D</span> and first <span class="literal">Dense</span> layer:</p>&#13;
<p class="programs">kernel_regularizer=keras.regularizers.l2(0.001)</p>&#13;
<p class="indent">Here <em>λ</em> = 0.001. Recall, <em>λ</em> is the L2 regularization scale factor.</p>&#13;
<p class="indent">We could test these together, but instead we’ve tested them individually to see what effect, if any, they have for this dataset. Training six models as before gives the following overall accuracies:</p>&#13;
<table class="bordertb">&#13;
<colgroup>&#13;
<col style="width:50%"/>&#13;
<col style="width:50%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr class="borderb">&#13;
<th style="vertical-align: top"><p class="tab"><strong>Regularizer</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>Score</strong></p></th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab">He initialization</p></td>&#13;
<td style="vertical-align: top"><p class="tab">78.5 ± 0.5%</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tab">L2 regularization</p></td>&#13;
<td style="vertical-align: top"><p class="tab">78.3 ± 0.4%</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="noindent">This is no different, statistically, from the previous results. In this case, these approaches are neither beneficial nor detrimental.</p>&#13;
<p class="indent">Batch normalization is another well-tested, go-to technique widely used by the machine learning community. We mentioned batch normalization briefly in <a href="ch12.xhtml#ch12">Chapter 12</a>. Batch normalization does just what its name suggests: it normalizes the inputs to a layer of the network, subtracting per feature means and dividing by the per feature standard deviations. The output of the layer multiplies the normalized input by a constant and adds an offset. The net effect is the input values are mapped to new output values by a two-step process: normalize the input and then apply a linear transform to get the output. The parameters of the linear transform are learned during backprop. At inference time, means and standard deviations learned from the dataset are applied to unknown inputs.</p>&#13;
<p class="indent">Batch normalization has shown itself time and again to be effective, especially in speeding up training. Machine learning researchers are still debating the exact reasons <em>why</em> it works as it does. To use it in Keras, you simply insert batch normalization after the convolutional and dense layers of the network (and after any activation function like ReLU used by those <span epub:type="pagebreak" id="page_403"/>layers). Batch normalization is known to not work well with dropout, so we’ll also remove the Dropout layers. The relevant architecture portion of the model code is shown in <a href="ch15.xhtml#ch15lis13">Listing 15-13</a>.</p>&#13;
<p class="programs" id="ch15lis13">from keras.layers import BatchNormalization<br/>&#13;
<br/>&#13;
model = Sequential()<br/>&#13;
model.add(Conv2D(32, kernel_size=(3, 3),<br/>&#13;
                 activation='relu', input_shape=input_shape))<br/>&#13;
model.add(BatchNormalization())<br/>&#13;
<br/>&#13;
model.add(Conv2D(64, (3, 3), activation='relu'))<br/>&#13;
model.add(BatchNormalization())<br/>&#13;
model.add(MaxPooling2D(pool_size=(2, 2)))<br/>&#13;
<br/>&#13;
model.add(Conv2D(64, (3, 3), activation='relu'))<br/>&#13;
model.add(BatchNormalization())<br/>&#13;
model.add(MaxPooling2D(pool_size=(2, 2)))<br/>&#13;
<br/>&#13;
model.add(Flatten())<br/>&#13;
model.add(Dense(128, activation='relu'))<br/>&#13;
model.add(BatchNormalization())<br/>&#13;
model.add(Dense(num_classes, activation='softmax'))</p>&#13;
<p class="figcap"><em>Listing 15-13: Adding in batch normalization</em></p>&#13;
<p class="indent">If we repeat our training process, six models with mean and standard error reporting of the overall accuracy, we get</p>&#13;
<p class="center">Batch normalization     75.56 ± 0.59%</p>&#13;
<p class="noindent">which is significantly less than the mean accuracy found without batch normalization but including dropout.</p>&#13;
<h4 class="h4" id="lev2_143">Examining the Confusion Matrix</h4>&#13;
<p class="noindent">We’ve seen in this section that our dataset is a tough one. Augmentation and dropout have been effective, but other things like ReLU-specific initialization, L2 regularization (weight decay), and even batch normalization have not improved things for us. That doesn’t mean these techniques are ineffective, just that they are not effective for this particular small dataset.</p>&#13;
<p class="indent">Let’s take a quick look at the confusion matrix generated by one of the models using our chosen architecture. We’ve seen previously how to calculate the matrix; we’ll show it here for discussion and for comparison with the confusion matrices we’ll make in the next section. <a href="ch15.xhtml#ch15tab2">Table 15-2</a> shows the matrix; as always, rows are the true class label, and columns are the model-assigned label.</p>&#13;
<p class="tabcap" id="ch15tab2"><span epub:type="pagebreak" id="page_404"/><strong>Table 15-2:</strong> Confusion Matrix for the Spectrogram Model</p>&#13;
<table class="bordertb">&#13;
<colgroup>&#13;
<col style="width:5%"/>&#13;
<col style="width:5%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr class="borderb">&#13;
<th style="vertical-align: top" class="borderr"><p class="tab"><strong>Class</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>0</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>1</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>2</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>3</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>4</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>5</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>6</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>7</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>8</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>9</strong></p></th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top" class="borderr"><p class="tab"><strong>0</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>85.6</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">5.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">5.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">3.1</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="borderr"><p class="tab"><strong>1</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>97.5</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.2</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top" class="borderr"><p class="tab"><strong>2</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">13.8</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>72.5</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">3.8</p></td>&#13;
<td style="vertical-align: top"><p class="tab">6.2</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.9</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="borderr"><p class="tab"><strong>3</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">25.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>68.1</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2.5</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2.5</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.2</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top" class="borderr"><p class="tab"><strong>4</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>84.4</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">6.2</p></td>&#13;
<td style="vertical-align: top"><p class="tab">5.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">3.8</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="borderr"><p class="tab"><strong>5</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>94.4</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">4.4</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top" class="borderr"><p class="tab"><strong>6</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.2</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">10.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>88.1</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="borderr"><p class="tab"><strong>7</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">9.4</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">15.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.9</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>63.8</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">7.5</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.2</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top" class="borderr"><p class="tab"><strong>8</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">18.1</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.9</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">5.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.2</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2.5</p></td>&#13;
<td style="vertical-align: top"><p class="tab">6.9</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>55.6</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">8.1</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="borderr"><p class="tab"><strong>9</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">7.5</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">8.1</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.9</p></td>&#13;
<td style="vertical-align: top"><p class="tab">10.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>71.2</strong></p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="indent">The three worst-performing classes are helicopter (8), fire (7), and waves (3). Both waves and helicopter are most often confused with rain (0), while fire is most often confused with clock (4) and rain. The best performing classes are rooster (1) and sneezing (5). These results make sense. A rooster’s crow and a person sneezing are distinct sounds; nothing really sounds like them. However, it is easy to see how waves and a helicopter could be confused with rain, or the crackle of a fire with the tick of a clock.</p>&#13;
<p class="indent">Does this mean we’re stuck at 78.8 percent accuracy? No, we have one more trick to try. We’ve been training and evaluating the performance of single models. Nothing is stopping us from training multiple models and combining their results. This is <em>ensembling</em>. We presented ensembles briefly in <a href="ch06.xhtml#ch06">Chapter 6</a> and again in <a href="ch09.xhtml#ch09">Chapter 9</a> when discussing dropout. Now, let’s use the idea directly to see if we can improve our sound sample classifier.</p>&#13;
<h3 class="h3" id="lev1_105">Ensembles</h3>&#13;
<p class="noindent">The core idea of an ensemble is to take the output of multiple models trained on the same, or extremely similar, dataset(s) and combine them. It embodies the “wisdom of the crowds” concept: one model might be better at certain classes or types of inputs for a particular class than another, so it makes sense that if they work together, they might arrive at a final result better than either one could do on its own.</p>&#13;
<p class="indent">Here, we’ll use the same machine learning architecture we used in the previous section. Our different models will be separate trainings of this architecture using the spectrograms as input. This is a weaker form of ensembling. Typically, the models in the ensemble are quite different from each other, either different architectures of neural networks, or completely different types of models like Random Forests and <em>k</em>-Nearest Neighbors. The variation between models here is due to the random initialization of the networks and the different parts of the loss landscape the network finds itself in when training stops.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_405"/>Our approach works like this:</p>&#13;
<ol>&#13;
<li class="noindent">Train multiple models (<em>n</em> = 6) using the spectrogram dataset.</li>&#13;
<li class="noindent">Combine the softmax output of these models on the test set in some manner.</li>&#13;
<li class="noindent">Use the resulting output from the combination to predict the assigned class label.</li>&#13;
</ol>&#13;
<p class="noindent">We hope that the set of class labels assigned after combining the individual model outputs is superior to the set assigned by the model architecture used alone. Intuitively, we feel that this approach should buy us something. It makes sense.</p>&#13;
<p class="indent">However, a question immediately arises: how do we best combine the outputs of the individual networks? We have total freedom in the answer to that question. What we are looking for is an <em>f</em> () such that</p>&#13;
<p class="center"><em>y</em><sub>predict</sub> = <em>f</em>(<em>y</em><sub>0</sub>, <em>y</em><sub>1</sub>, <em>y</em><sub>2</sub>, … , <em>y<sub>n</sub></em>)</p>&#13;
<p class="noindent">where <em>y</em><sub><em>i</em></sub>, <em>i</em> = 0, 1, …, <em>n</em> are the outputs of the <em>n</em> models in the ensemble and <em>f</em> () is some function, operation, or algorithm that best combines them into a single new prediction, <em>y</em><sub>predict</sub>.</p>&#13;
<p class="indent">Some combination approaches come readily to mind: we could average the outputs and select the largest, keep maximum per class output across the ensemble and then choose the largest of those, or use voting to decide which class label should be assigned. We’ll try all three of these.</p>&#13;
<p class="indent">Let’s start with the first three approaches. We already have the six ensemble models: they’re the models we trained in the previous section to give us the mean accuracy on the test set. This model architecture uses dropout, but no alternate initialization, L2 regularization, or batch normalization.</p>&#13;
<p class="indent">It’s straightforward enough to run the test set through each of the models trained in the previous section (<a href="ch15.xhtml#ch15lis14">Listing 15-14</a>):</p>&#13;
<p class="programs" id="ch15lis14">   import sys <br/>&#13;
   import numpy as np<br/>&#13;
   from keras.models import load_model<br/>&#13;
<br/>&#13;
   model = load_model(sys.argv[1])<br/>&#13;
   x_test = np.load("esc10_spect_test_images.npy")/255.0<br/>&#13;
   y_test = np.load("esc10_spect_test_labels.npy")<br/>&#13;
<span class="ent">❶</span> prob = model.predict(x_test)<br/>&#13;
<span class="ent">❷</span> p = np.argmax(prob, axis=1)<br/>&#13;
<br/>&#13;
   cc = np.zeros((10,10))<br/>&#13;
   for i in range(len(y_test)):<br/>&#13;
       cc[y_test[i],p[i]] += 1<br/>&#13;
<br/>&#13;
<span epub:type="pagebreak" id="page_406"/><span class="ent">❸</span> print(np.array2string(cc.astype("uint32")))<br/>&#13;
   cp = 100.0 * cc / cc.sum(axis=1)<br/>&#13;
<span class="ent">❹</span> print(np.array2string(cp, precision=1))<br/>&#13;
   print("Overall accuracy = %0.2f%%" % (100.0*np.diag(cc).sum()/cc.sum(),))<br/>&#13;
   np.save(sys.argv[2], prob)</p>&#13;
<p class="figcap"><em>Listing 15-14: Applying multiple models to the test set</em></p>&#13;
<p class="indent">This code expects the name of the trained model file as the first argument and the name of an output file to store the model predictions as the second argument. Then, it loads the model and spectrogram test data, applies the model to the test data <span class="ent">❶</span>, and predicts class labels by selecting the highest output value <span class="ent">❷</span>.</p>&#13;
<p class="indent">The code also calculates the confusion matrix and displays it twice, first as actual counts <span class="ent">❸</span> and again as a percentage of the actual class <span class="ent">❹</span>. Finally, it displays the overall accuracy and writes the probabilities to the disk. With this code, we can store the predictions of each of the six models.</p>&#13;
<p class="indent">Now that we have the predictions, let’s combine them in the first of the three ways mentioned previously. To calculate the average of the model predictions, we first load each model’s predictions, and then average and select the maximum per sample as shown in <a href="ch15.xhtml#ch15lis15">Listing 15-15</a>.</p>&#13;
<p class="programs" id="ch15lis15">p0 = np.load("prob_run0.npy")<br/>&#13;
p1 = np.load("prob_run1.npy")<br/>&#13;
p2 = np.load("prob_run2.npy")<br/>&#13;
p3 = np.load("prob_run3.npy")<br/>&#13;
p4 = np.load("prob_run4.npy")<br/>&#13;
p5 = np.load("prob_run5.npy")<br/>&#13;
y_test = np.load("esc10_spect_test_labels.npy")<br/>&#13;
prob = (p0+p1+p2+p3+p4+p5)/6.0<br/>&#13;
p = np.argmax(prob, axis=1)</p>&#13;
<p class="figcap"><em>Listing 15-15: Averaging the test set results</em></p>&#13;
<p class="indent">The resulting percentage confusion matrix is</p>&#13;
<table class="bordertb">&#13;
<colgroup>&#13;
<col style="width:5%"/>&#13;
<col style="width:5%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr class="borderb">&#13;
<th style="vertical-align: top" class="borderr"><p class="tab"><strong>Class</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>0</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>1</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>2</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>3</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>4</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>5</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>6</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>7</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>8</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>9</strong></p></th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top" class="borderr"><p class="tab"><strong>0</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>83.8</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">7.5</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">4.4</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">4.4</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="borderr"><p class="tab"><strong>1</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>97.5</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.9</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top" class="borderr"><p class="tab"><strong>2</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">10.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>78.1</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">3.1</p></td>&#13;
<td style="vertical-align: top"><p class="tab">6.2</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2.5</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="borderr"><p class="tab"><strong>3</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">9.4</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>86.2</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">3.1</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top" class="borderr"><p class="tab"><strong>4</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>83.1</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">5.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">5.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">5.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="borderr"><p class="tab"><strong>5</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>93.8</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">5.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top" class="borderr"><p class="tab"><strong>6</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">8.8</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>90.6</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="borderr"><p class="tab"><strong>7</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">8.1</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">17.5</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.9</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>64.4</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">7.5</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top" class="borderr"><p class="tab"><strong>8</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">6.2</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">7.5</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.9</p></td>&#13;
<td style="vertical-align: top"><p class="tab">4.4</p></td>&#13;
<td style="vertical-align: top"><p class="tab">8.8</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>66.2</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">5.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="borderr"><p class="tab"><strong>9</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">5.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">5.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.2</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.9</p></td>&#13;
<td style="vertical-align: top"><p class="tab">10.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>75.6</strong></p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="noindent">with an overall accuracy of 82.0 percent.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_407"/>This approach is helpful: we went from 79 percent to 82 percent in overall accuracy. The most significant improvements were in class 3 (waves) and class 8 (helicopter).</p>&#13;
<p class="indent">Our next approach, shown in <a href="ch15.xhtml#ch15lis16">Listing 15-16</a>, keeps the maximum probability across the six models for each class and then selects the largest to assign the class label.</p>&#13;
<p class="programs" id="ch15lis16"><span epub:type="pagebreak" id="page_408"/>p = np.zeros(len(y_test), dtype="uint8")<br/>&#13;
for i in range(len(y_test)):<br/>&#13;
    t = np.array([p0[i],p1[i],p2[i],p3[i],p4[i],p5[i]])<br/>&#13;
    p[i] = np.argmax(t.reshape(60)) % 10</p>&#13;
<p class="figcap"><em>Listing 15-16: Keeping the test set maximum</em></p>&#13;
<p class="indent">This code defines a vector, <span class="literal">p</span>, of the same length as the vector of actual labels, <span class="literal">y_test</span>. Then, for each test sample, we form <span class="literal">t</span>, a concatenation of all six models’ predictions for each class. We reshape <span class="literal">t</span> so that it is a one-dimensional vector of 60 elements. Why 60? We have 10 class predictions times 6 models. The maximum of this vector is the largest value, the index of which is returned by <span class="literal">argmax</span>. We really don’t want this index; instead, we want the class label this index maps to. Therefore, if we take this index modulo 10, we will get the proper class label, which we assign to <span class="literal">p</span>. With <span class="literal">p</span> and <span class="literal">y_test</span>, we can calculate the confusion matrix:</p>&#13;
<table class="bordertb">&#13;
<colgroup>&#13;
<col style="width:5%"/>&#13;
<col style="width:5%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr class="borderb">&#13;
<th style="vertical-align: top" class="borderr"><p class="tab"><strong>Class</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>0</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>1</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>2</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>3</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>4</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>5</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>6</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>7</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>8</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>9</strong></p></th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><strong>0</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>82.5</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">9.4</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">4.4</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">3.1</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="borderr"><p class="tab"><strong>1</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>95.0</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">4.4</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><strong>2</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">10.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>78.8</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">3.1</p></td>&#13;
<td style="vertical-align: top"><p class="tab">5.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2.5</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="borderr"><p class="tab"><strong>3</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">5.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>90.6</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2.5</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><strong>4</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.2</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>81.2</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">6.2</p></td>&#13;
<td style="vertical-align: top"><p class="tab">5.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">6.2</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="borderr"><p class="tab"><strong>5</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>93.8</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">5.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><strong>6</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">8.8</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>90.0</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="borderr"><p class="tab"><strong>7</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">8.8</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">16.2</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2.5</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>65.0</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">6.9</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><strong>8</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">8.1</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">6.2</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.9</p></td>&#13;
<td style="vertical-align: top"><p class="tab">4.4</p></td>&#13;
<td style="vertical-align: top"><p class="tab">9.4</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>63.1</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">6.9</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="borderr"><p class="tab"><strong>9</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">3.8</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">4.4</p></td>&#13;
<td style="vertical-align: top"><p class="tab">3.1</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.9</p></td>&#13;
<td style="vertical-align: top"><p class="tab">10.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>76.2</strong></p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="noindent">This gives us an overall accuracy of 81.6 percent.</p>&#13;
<p class="indent">Voting is the typical approach used to combine outputs from several models. To implement voting in this case, we’ll use <a href="ch15.xhtml#ch15lis17">Listing 15-17</a>.</p>&#13;
<p class="programs" id="ch15lis17">   t = np.zeros((6,len(y_test)), dtype="uint32")<br/>&#13;
<span class="ent">❶</span> t[0,:] = np.argmax(p0, axis=1)<br/>&#13;
   t[1,:] = np.argmax(p1, axis=1)<br/>&#13;
   t[2,:] = np.argmax(p2, axis=1)<br/>&#13;
   t[3,:] = np.argmax(p3, axis=1)<br/>&#13;
   t[4,:] = np.argmax(p4, axis=1)<br/>&#13;
   t[5,:] = np.argmax(p5, axis=1)<br/>&#13;
   p = np.zeros(len(y_test), dtype="uint8")<br/>&#13;
   for i in range(len(y_test)):<br/>&#13;
       q = np.bincount(t[:,i])<br/>&#13;
       p[i] = np.argmax(q)</p>&#13;
<p class="figcap"><em>Listing 15-17: Voting to select the best class label</em></p>&#13;
<p class="indent">We first apply <span class="literal">argmax</span> across the six model predictions to get the associated labels <span class="ent">❶</span>, storing them in a combined matrix, <span class="literal">t</span>. We then define <span class="literal">p</span> as before to hold the final assigned class label. We loop over each of the test samples, where we use a new NumPy function, <span class="literal">bincount</span>, to give us the number of times each class label occurs for the current test sample. The largest such count is the most often selected label, so we use <span class="literal">argmax</span> again to assign the proper output label to <span class="literal">p</span>. Note, this code works because our class labels are integers running consecutively from 0 through 9. This alone is a good enough reason to use such simple and ordered class labels.</p>&#13;
<p class="indent">Here is the confusion matrix produced by this voting procedure:</p>&#13;
<table class="bordertb">&#13;
<colgroup>&#13;
<col style="width:5%"/>&#13;
<col style="width:5%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
<col style="width:10%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr class="borderb">&#13;
<th style="vertical-align: top" class="borderr"><p class="tab"><strong>Class</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>0</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>1</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>2</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>3</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>4</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>5</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>6</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>7</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>8</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>9</strong></p></th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><strong>0</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>86.2</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">8.8</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">3.8</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.2</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="borderr"><p class="tab"><strong>1</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>98.1</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.2</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><strong>2</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">10.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>78.1</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">3.1</p></td>&#13;
<td style="vertical-align: top"><p class="tab">5.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">2.5</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="borderr"><p class="tab"><strong>3</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">14.4</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>81.2</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">3.1</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><strong>4</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>83.8</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">5.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">5.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">5.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="borderr"><p class="tab"><strong>5</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>94.4</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">5.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><strong>6</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.2</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">9.4</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>88.8</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="borderr"><p class="tab"><strong>7</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">8.8</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">18.1</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.9</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>65.6</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">5.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top"><p class="tab"><strong>8</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">7.5</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">6.9</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">3.1</p></td>&#13;
<td style="vertical-align: top"><p class="tab">3.8</p></td>&#13;
<td style="vertical-align: top"><p class="tab">8.8</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>67.5</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">2.5</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="borderr"><p class="tab"><strong>9</strong></p></td>&#13;
<td style="vertical-align: top"><p class="tab">5.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">6.2</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.2</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.6</p></td>&#13;
<td style="vertical-align: top"><p class="tab">0.0</p></td>&#13;
<td style="vertical-align: top"><p class="tab">1.9</p></td>&#13;
<td style="vertical-align: top"><p class="tab">11.2</p></td>&#13;
<td style="vertical-align: top"><p class="tab"><strong>73.1</strong></p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="noindent">This gives us an overall accuracy of 81.7 percent.</p>&#13;
<p class="indent">Each of these three ensemble approaches improved our results, almost identically. A simple combination of the model outputs gave us, essentially, an accuracy boost of 3 percent over the base model alone, thereby demonstrating the utility of ensemble techniques.</p>&#13;
<h3 class="h3" id="lev1_106">Summary</h3>&#13;
<p class="noindent">This chapter presented a case study, a new dataset, and the steps we need to take to work through building a useful model. We started by working with the dataset as given to us, as raw sound samples, which we were able to augment successfully. We noticed that we had a feature vector and attempted to use classical models. From there, we moved on to 1D convolutional neural networks. Neither of these approaches was particularly successful.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_409"/>Fortunately for us, our dataset allowed for a new representation, one that illustrated more effectively what composed the data and, especially important for us, introduced spatial elements so that we could work with 2D convolutional networks. With these networks, we improved quite a bit on the best 1D results, but we were still not at a level that was likely to be useful.</p>&#13;
<p class="indent">After exhausting our bag of CNN training tricks, we moved to ensembles of classifiers. With these, we discovered a modest improvement by using simple approaches to combining the base model outputs (for example, averaging).</p>&#13;
<p class="indent">We can show the progression of models and their overall accuracies to see how our case study evolved:</p>&#13;
<table class="bordertb">&#13;
<colgroup>&#13;
<col style="width:40%"/>&#13;
<col style="width:30%"/>&#13;
<col style="width:30%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr class="borderb">&#13;
<th style="vertical-align: top" class="borderr"><p class="tab"><strong>Model</strong></p></th>&#13;
<th style="vertical-align: top" class="borderr"><p class="tab"><strong>Data source</strong></p></th>&#13;
<th style="vertical-align: top"><p class="tab"><strong>Accuracy</strong></p></th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top" class="borderr"><p class="tab">Gaussian Naïve Bayes</p></td>&#13;
<td style="vertical-align: top" class="borderr"><p class="tab">1D sound sample</p></td>&#13;
<td style="vertical-align: top"><p class="tab">28.1%</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="borderr"><p class="tab">Random Forest (1,000 trees)</p></td>&#13;
<td style="vertical-align: top" class="borderr"><p class="tab">1D sound sample</p></td>&#13;
<td style="vertical-align: top"><p class="tab">34.4%</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top" class="borderr"><p class="tab">1D CNN</p></td>&#13;
<td style="vertical-align: top" class="borderr"><p class="tab">1D sound sample</p></td>&#13;
<td style="vertical-align: top"><p class="tab">54.0%</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="borderr"><p class="tab">2D CNN</p></td>&#13;
<td style="vertical-align: top" class="borderr"><p class="tab">Spectrogram</p></td>&#13;
<td style="vertical-align: top"><p class="tab">78.8%</p></td>&#13;
</tr>&#13;
<tr class="bg-g">&#13;
<td style="vertical-align: top" class="borderr"><p class="tab">Ensemble (average)</p></td>&#13;
<td style="vertical-align: top" class="borderr"><p class="tab">Spectrogram</p></td>&#13;
<td style="vertical-align: top"><p class="tab">82.0%</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="indent">This table shows the power of modern deep learning and the utility of combining it with well-proven classical approaches like ensembles.</p>&#13;
<p class="indent">This chapter concludes our exploration of machine learning. We started at the beginning, with data and datasets. We moved on to the classical machine learning models, and then dove into traditional neural networks so that we would have a solid foundation from which to understand modern convolutional neural networks. We explored CNNs in detail and concluded with a case study as an illustration of how you might approach a new dataset to build a successful model. Along the way, we learned about how to evaluate models. We became familiar with the metrics used by the community so that we can understand what people are talking about and presenting in their papers.</p>&#13;
<p class="indent">Of course, this entire book has been an introduction, and we have barely scratched the surface of the ever-expanding world that is machine learning. Our final chapter will serve as a jumping-off point—a guide to where you may want to wander next to expand your machine learning knowledge beyond the tight bounds we’ve been required to set for ourselves here.<span epub:type="pagebreak" id="page_410"/></p>&#13;
</div></body></html>
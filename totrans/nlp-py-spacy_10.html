<html><head></head><body>
<div id="sbo-rt-content"><h2 class="h2" id="ch10"><span epub:type="pagebreak" id="page_141"/><strong><span class="big">10</span><br/>TRAINING MODELS</strong></h2>&#13;
<div class="image1"><img src="../Images/comm1.jpg" alt="Image" width="191" height="191"/></div>&#13;
<p class="noindents">As you learned in <a href="../Text/ch01.xhtml#ch01">Chapter 1</a>, spaCy contains statistical neural network models trained to perform named entity recognition, part-of-speech tagging, syntactic dependency parsing, and semantic similarity prediction. But you’re not limited to using only pretrained, ready-to-use models. You can also train a model with your own training examples, tuning its pipeline components for your application’s requirements.</p>&#13;
<p class="indent">This chapter covers how to train spaCy’s named entity recognizer and dependency parser, the pipeline components that you most often need to customize to make the model you’re using specific to a particular use case. The reason is that a certain domain usually requires a specific set of entities and, sometimes, a certain way of parsing dependencies. You’ll learn how to <span epub:type="pagebreak" id="page_142"/>train an existing model with new examples and a blank one from scratch. You’ll also save a customized pipeline component to disk so you can load it later in another script or model.</p>&#13;
<h3 class="h3" id="lev130"><strong>Training a Model’s Pipeline Component</strong></h3>&#13;
<p class="noindent">You rarely have to train a model from scratch to satisfy your application’s specific requirements. Instead, you can use an existing model and update only the pipeline component you need to change. This process usually involves two steps: preparing <em>training examples</em> (sets of sentences with annotations that the model can learn from), and then exposing the pipeline component to the training examples, as shown in <a href="../Text/ch10.xhtml#ch10fig01">Figure 10-1</a>.</p>&#13;
<div class="image"><a id="ch10fig01"/><img src="../Images/fig10-1.jpg" alt="image" width="518" height="504"/></div>&#13;
<p class="figcap"><em>Figure 10-1: The training process for a pipeline component</em></p>&#13;
<p class="indent">To prepare training examples, you convert raw text data into a training example containing a sentence and each token’s annotations. During the training process, spaCy uses the training examples to correct the model’s weights: the goal is to minimize the error (called the <em>loss</em>) of the model prediction. Put simply, the algorithm calculates the relationship between the token and its annotation to determine the likelihood that a token should be assigned that annotation.</p>&#13;
<p class="indent">A real-world implementation might require hundreds or even thousands of training examples to efficiently teach a certain component of a model. Before you start training the component, you need to temporarily disable all the model’s other pipeline components to protect them from unnecessary alterations.</p>&#13;
<h3 class="h3" id="lev131"><span epub:type="pagebreak" id="page_143"/><strong>Training the Entity Recognizer</strong></h3>&#13;
<p class="noindent">Suppose you’re developing a chatbot app for a taxi company. The app must correctly recognize all the names referring to districts within the city and its surroundings. To accomplish this, you might need to update a model’s named entity recognition system with your own examples, making it recognize, for instance, the word “Solnce,” which refers to a neighborhood in a city, as a geopolitical entity. The following sections describe how you could complete this task.</p>&#13;
<h4 class="h4" id="lev132"><strong><em>Deciding Whether You Need to Train the Entity Recognizer</em></strong></h4>&#13;
<p class="noindent">Let’s begin by looking at how the existing named entity recognizer in the default English model (generally the <code>en_core_web_sm</code> model) recognizes the named entities of interest. It’s possible that you won’t need to update the named entity recognizer. For this task, you might use sentences common for booking a taxi, like this one:</p>&#13;
<pre>Could you pick me up at Solnce?</pre>&#13;
<p class="indent">To see how the recognizer will classify “Solnce” in the sentence, print the sentence’s named entities using the following script:</p>&#13;
<pre>import spacy<br/>&#13;
nlp = spacy.load('en')<br/>&#13;
doc = nlp(u'Could you pick me up at Solnce?')<br/>&#13;
  for ent in doc.ents:<br/>&#13;
    print(ent.text, ent.label_)</pre>&#13;
<p class="indent">In this example, “Solnce” is the only named entity, so the script generates the following single-line output:</p>&#13;
<pre>Solnce LOC</pre>&#13;
<p class="indent">Note that the output for this entity can vary depending on the model and sentence you’re using. To get the description for the <code>LOC</code> entity label in the output, you can use the <code>spacy.explain()</code> function:</p>&#13;
<pre>&gt;&gt;&gt; print(spacy.explain('LOC'))<br/>&#13;
'Non-GPE locations, mountain ranges, bodies of water'</pre>&#13;
<p class="indent">The result is that the named entity recognizer classified “Solnce” as a non-<code>GPE</code> location, which doesn’t match what you expect to see. To change this so the recognizer classifies “Solnce” as an entity of type <code>GPE</code>, you need to update the recognizer, as discussed in the following sections.</p>&#13;
<div class="note">&#13;
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>&#13;
<p class="notep"><em>For simplicity, we’re using a single-named entity in this example. But you can create more names for districts with which to train the recognizer.</em></p>&#13;
</div>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_144"/>Rather than updating the existing recognizer, you could replace it with a custom one. However, in that case, you’d need many more training examples to retain the functionality that isn’t related to <code>GPE</code> entities but you might still need.</p>&#13;
<h4 class="h4" id="lev133"><strong><em>Creating Training Examples</em></strong></h4>&#13;
<p class="noindent">Once you know you need to train the entity recognizer to satisfy your app’s needs, the next step is to create a set of appropriate training examples. For that, you need some relevant text.</p>&#13;
<p class="indent">Likely, the best data source for creating such a training set is real customer input that you gathered previously. Choose utterances that include the named entities you need to use for training. Typically, you’d log customer input in a file as plaintext. For example, a customer input log file for the taxi app might contain the following utterances:</p>&#13;
<pre>Could you send a taxi to Solnce? <br/>&#13;
Is there a flat rate to the airport from Solnce? <br/>&#13;
How long is the wait for a taxi right now?</pre>&#13;
<p class="indent">To create training examples from these utterances, you need to convert them into a list of tuples in which each training example represents a separate tuple, as shown here:</p>&#13;
<pre>train_exams = [<br/>&#13;
 <span class="ent">➊</span> ('Could you send a taxi to Solnce?', {<br/>&#13;
     <span class="ent">➋</span> 'entities': [(25, 32, 'GPE')]<br/>&#13;
    }),<br/>&#13;
    ('Is there a flat rate to the airport from Solnce?', {<br/>&#13;
        'entities': [(41, 48, 'GPE')]<br/>&#13;
    }),<br/>&#13;
    ('How long is the wait for a taxi right now?', {<br/>&#13;
        'entities': []<br/>&#13;
    })<br/>&#13;
]</pre>&#13;
<p class="indent">Each tuple consists of two values: the string representing an utterance <span class="ent">➊</span> and the dictionary for the annotations of the entities found in that utterance. The entity’s annotations include its start and end positions in terms of characters composing the utterance and the label to be assigned to the entity <span class="ent">➋</span>.</p>&#13;
<h4 class="h4" id="lev134"><strong><em>Automating the Example Creation Process</em></strong></h4>&#13;
<p class="noindent">As you’ve no doubt realized, creating a set of training examples manually can be time-consuming and error prone, especially if you have hundreds or thousands of utterances to process. You can automate this tedious task by using the following script, which quickly creates a set of training examples from the submitted text.</p>&#13;
<span epub:type="pagebreak" id="page_145"/><pre>   import spacy<br/>&#13;
   nlp = spacy.load('en')<br/>&#13;
<span class="ent">➊</span> doc = nlp(u'Could you send a taxi to Solnce? I need to get to Google. Could<br/>&#13;
   you send a taxi an hour later?')<br/>&#13;
<span class="ent">➋</span> #f = open("test.txt","rb")<br/>&#13;
   #contents =f.read()<br/>&#13;
   #doc = nlp(contents.decode('utf8'))<br/>&#13;
<span class="ent">➌</span> train_exams = []<br/>&#13;
<span class="ent">➍</span> districts = ['Solnce', 'Greenwal', 'Downtown']<br/>&#13;
   for sent in doc.sents:<br/>&#13;
     entities = [] <br/>&#13;
     for token in sent:<br/>&#13;
       if token.ent_type != 0: <br/>&#13;
        <span class="ent">➎</span> start = token.idx - sent.start_char<br/>&#13;
           if token.text in districts:<br/>&#13;
             entity = (start, start + len(token), 'GPE')<br/>&#13;
           else:<br/>&#13;
             entity = (start, start + len(token), token.ent_type_)<br/>&#13;
           entities.append(entity)<br/>&#13;
     tpl = (sent.text, {'entities': entities})<br/>&#13;
  <span class="ent">➏</span> train_exams.append(tpl)</pre>&#13;
<p class="indent">For readability, we pick up some utterances for processing in the usual way: by hardcoding them in the script <span class="ent">➊</span>. But the commented lines of code show how we might pick up utterances from a file instead <span class="ent">➋</span>.</p>&#13;
<p class="indent">Once we’ve obtained the utterances—either from a file or passed in to the doc explicitly—we can start generating a list of training examples from them. We begin by creating an empty list <span class="ent">➌</span>. Next, we need to define a list containing the names of entities that we want the model to recognize differently than it currently does <span class="ent">➍</span>. (This is the list of districts in this example.)</p>&#13;
<p class="indent">Remember that real customer input might include entities that the recognizer already correctly recognizes (say, Google or London), so we shouldn’t change the recognizer’s behavior when it classifies them. We create training examples for those entities and process all the entities presented in the utterances used for generating training examples, not only the new ones. A training set for a real implementation must include numerous examples for entities of different types. Depending on the application’s needs, the training set might include several hundred examples.</p>&#13;
<p class="indent">We iterate over the submitted utterances, creating a new empty entities list on each iteration. Then, to fill in this list, we loop over the tokens in the utterance, finding entities. For each found entity, we determine its start character index in the utterance <span class="ent">➎</span>. We then calculate the end index by adding <code>len(token)</code> to the start index.</p>&#13;
<p class="indent">Also, we must check whether the entity is in the list of entities to which we want to assign a new label. If so, we assign it the <code>GPE</code> label. Otherwise, the recognizer will use the current label in the entity annotations. After that, we can define a tuple representing the training example, and then append it to the training set <span class="ent">➏</span>.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_146"/>The script sends the training examples being generated to the <code>train_exams</code> list, which should look as follows after the script execution:</p>&#13;
<pre>&gt;&gt;&gt; train_exams<br/>&#13;
[<br/>&#13;
  <span class="ent">➊</span> ('Could you send a taxi to Solnce?', {'entities': [(25, 31, 'GPE')]}),<br/>&#13;
  <span class="ent">➋</span> ('I need to get to Google.', {'entities': [(17, 23, 'ORG')]}),<br/>&#13;
  <span class="ent">➌</span> ('Could you send a taxi an hour later?', {'entities': []})<br/>&#13;
]</pre>&#13;
<p class="indent">For simplicity, the training set we use here consists of just a few training examples. Notice that only the first one contains an entity from the list of entities we need to familiarize the recognizer with (the districts list in this example) <span class="ent">➊</span>. That doesn’t mean that the second and third training examples aren’t useful. The second training example <span class="ent">➋</span> mixes in another entity type, which prevents the recognizer from “forgetting” what it previously knew.</p>&#13;
<p class="indent">The third training example doesn’t contain any entity <span class="ent">➌</span>. To improve the learning results, we need to mix in not only examples of other entity types, but also examples that don’t contain any entities. The following section “<a href="../Text/ch10.xhtml#lev136">The Training Process</a>” discusses the details of the training process.</p>&#13;
<h4 class="h4" id="lev135"><strong><em>Disabling the Other Pipeline Components</em></strong></h4>&#13;
<p class="noindent">The spaCy documentation recommends disabling all the other pipeline components before you start training a certain pipeline component, so you modify only the component you want to update. The following code disables all the pipeline components except for the named entity recognizer. You need to either append this code to the script introduced in the preceding section or execute it in the same Python session after that script (we’ll append the final piece of code in the next section, which covers the training process):</p>&#13;
<pre>other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']<br/>&#13;
nlp.disable_pipes(*other_pipes)</pre>&#13;
<p class="indent">Now you’re ready to start training the named entity recognizer to teach it to find the new entities defined in the training examples.</p>&#13;
<h4 class="h4" id="lev136"><strong><em>The Training Process</em></strong></h4>&#13;
<p class="noindent">In the training process, you shuffle and loop over the training examples, adjusting the model with weights that more accurately reflect the relationships between the tokens and the annotations. Refer back to <a href="../Text/ch01.xhtml#ch01">Chapter 1</a> for a more detailed explanation of neural network models, including what weights are.</p>&#13;
<p class="indent">To improve accuracy, you can apply several techniques to a training loop. For example, the following code illustrates how to process your training examples in batches. This technique shows the training examples to the model in different representations to avoid generalizations found in the training corpus.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_147"/>Append the following code to the script that was first introduced in “<a href="../Text/ch10.xhtml#lev141">Creating Training Examples</a>” on <a href="../Text/ch10.xhtml#page_144">page 144</a> and that was modified in the preceding section.</p>&#13;
<pre>   import random<br/>&#13;
   from spacy.util import minibatch, compounding<br/>&#13;
<span class="ent">➊</span> optimizer = nlp.entity.create_optimizer()<br/>&#13;
   for i in range(25):<br/>&#13;
    <span class="ent">➋</span> random.shuffle(train_exams)<br/>&#13;
       max_batch_size = 3<br/>&#13;
    <span class="ent">➌</span> batch_size = compounding(2.0, max_batch_size, 1.001)<br/>&#13;
    <span class="ent">➍</span> batches = minibatch(train_exams, size=batch_size)<br/>&#13;
       for batch in batches:<br/>&#13;
           texts, annotations = zip(*batch)<br/>&#13;
        <span class="ent">➎</span> nlp.update(texts, annotations, sgd=optimizer)<br/>&#13;
<span class="ent">➏</span> ner = nlp.get_pipe('ner')<br/>&#13;
<span class="ent">➐</span> ner.to_disk('/usr/to/ner')</pre>&#13;
<p class="indent">Before we can begin training, we need to create an <em>optimizer</em> <span class="ent">➊</span>—a function that will be used during the training process to hold intermediate results between updates of the model weights. We could create an optimizer with the <code>nlp.begin_training()</code> method. But this method removes existing entity types. In this example, because we’re updating an existing model and don’t want it to “forget” the existing entity types, we use the <code>nlp.entity.create_optimizer()</code> method. This method creates an optimizer for the named entity recognizer without losing an existing set of entity types.</p>&#13;
<p class="indent">During the training process, the script shows the examples to the model in a loop, in random order, to avoid any generalizations that might come from the order of the examples <span class="ent">➋</span>. The script also batches the training examples, which the spaCy documentation suggests might improve the effectiveness of the training process when the number of training examples is large enough. To make the batch size vary on each step, we use the <code>compounding(</code><code>)</code> method, which yields a generator of batch sizes. In particular, it generates an infinite series of compounding values: it starts from the value specified as the first parameter and calculates the next value by multiplying the previous value by the compound rate specified as the third parameter, without exceeding the maximum value specified as the second parameter <span class="ent">➌</span>. Then we batch the training examples using the <code>minibatch()</code> method. Doing so sets its size parameter to the iterator generated with the <code>compounding()</code> method invoked in the preceding line of code <span class="ent">➍</span>.</p>&#13;
<p class="indent">Next, we iterate over the batches, updating the named entity recognizer model on each iteration. Each batch requires us to update the model by calling <code>nlp.update()</code> <span class="ent">➎</span>, which makes a prediction for each entity found in the examples included in the batch and then checks the annotations provided to see whether it was correct. If the prediction is wrong, the training process adjusts the weights in the underlying model so the correct prediction will score higher next time.</p>&#13;
<p class="indent">Finally, we need to serialize the updated named entity recognizer component to disk so we can load it in another script (or another Python <span epub:type="pagebreak" id="page_148"/>session) later. For that, we first must obtain the component from the pipeline <span class="ent">➏</span> and then save it to disk with its <code>to_disk()</code> method <span class="ent">➐</span>. Be sure you’ve created the <em>/usr/to</em> directory in your system.</p>&#13;
<h4 class="h4" id="lev137"><strong><em>Evaluating the Updated Recognizer</em></strong></h4>&#13;
<p class="noindent">Now you can test the updated recognizer. If you’re performing the example discussed in this chapter in a Python session, close it, open a new one, and enter the following code to make sure the model has made the correct generalizations. (If you’ve built a separate script from the code discussed in the previous sections and run it, you can run the following code either as a separate script or from within a Python session.)</p>&#13;
<pre>   import spacy<br/>&#13;
   from spacy.pipeline import EntityRecognizer<br/>&#13;
<span class="ent">➊</span> nlp = spacy.load('en', disable=['ner'])<br/>&#13;
<span class="ent">➋</span> ner = EntityRecognizer(nlp.vocab)<br/>&#13;
<span class="ent">➌</span> ner.from_disk('/usr/to/ner')<br/>&#13;
<span class="ent">➍</span> nlp.add_pipe(ner, "custom_ner")<br/>&#13;
<span class="ent">➎</span> print(nlp.meta['pipeline'])<br/>&#13;
<span class="ent">➏</span> doc = nlp(u'Could you pick me up at Solnce?')<br/>&#13;
   for ent in doc.ents:<br/>&#13;
     print(ent.text, ent.label_)</pre>&#13;
<p class="indent">We first load the pipeline components without the named entity recognizer component <span class="ent">➊</span>. The reason is that training an existing model’s pipeline component doesn’t permanently override the component’s original behavior. When we load a model, the original versions of the components composing the model’s pipeline load by default; so to use an updated version, we must explicitly load it from disk. This allows us to have several custom versions of the same pipeline component and load an appropriate one when necessary.</p>&#13;
<p class="indent">We create this new component in two steps: constructing a new pipeline instance from the <code>EntityRecognizer</code> class <span class="ent">➋</span>, and then loading the data into it from disk, specifying the directory in which we serialized the recognizer <span class="ent">➌</span>.</p>&#13;
<p class="indent">Next, we add the loaded named entity recognizer component to the current pipeline, optionally using a custom name <span class="ent">➍</span>. If we print out the names of the currently available pipeline components <span class="ent">➎</span>, we should see that custom name among the <code>'tagger'</code> and <code>'parser'</code> names.</p>&#13;
<p class="indent">The only task left is test the loaded named entity recognizer component. Be sure to use a different sentence than the one used in the training dataset <span class="ent">➏</span>.</p>&#13;
<p class="indent">As a result, we should see the following output:</p>&#13;
<pre>Available pipe components: ['tagger', 'parser', 'custom_ner']<br/>&#13;
Solnce GPE</pre>&#13;
<p class="indent">The updated named entity recognizer component can now recognize the custom entity names correctly.</p>&#13;
<h3 class="h3" id="lev138"><span epub:type="pagebreak" id="page_149"/><strong>Creating a New Dependency Parser</strong></h3>&#13;
<p class="noindent">In the following sections, you’ll learn how to create a custom dependency parser suitable for a specific task. In particular, you’ll train a parser that reveals semantic relations in a sentence rather than syntactic dependencies. <em>Semantic relations</em> are between the meanings of words and phrases in a sentence.</p>&#13;
<h4 class="h4" id="lev139"><strong><em>Custom Syntactic Parsing to Understand User Input</em></strong></h4>&#13;
<p class="noindent">Why would you need semantic relations? Well, suppose your chatbot app is supposed to understand a user’s request, expressed in plain English, and then transform it into a SQL query to be passed into a database. To achieve this, the app performs syntactic parsing to extract the meaning, shredding the input into pieces to use in building a database query. For example, imagine you have the following sentence to parse:</p>&#13;
<pre>Find a high paid job with no experience.</pre>&#13;
<p class="indent">A SQL query generated from this sentence might look like this:</p>&#13;
<pre>SELECT * FROM jobs WHERE salary = 'high' AND experience = 'no'</pre>&#13;
<p class="indent">To begin with, let’s look at how a regular dependency parser would process the sample sentence. For that, you might use the following script:</p>&#13;
<pre>import spacy<br/>&#13;
nlp = spacy.load('en')<br/>&#13;
doc = nlp(u'Find a high paid job with no experience.')<br/>&#13;
print([(t.text, t.dep_, t.head.text) for t in doc])</pre>&#13;
<p class="indent">The script outputs each token’s text, its dependency label, and its syntactic head. If you’re using the <code>en_core_web_sm</code> model, the result should look as follows:</p>&#13;
<pre>[<br/>&#13;
  ('Find', 'ROOT', 'Find'), <br/>&#13;
  ('a', 'det', 'job'),<br/>&#13;
  ('high', 'amod', 'job'),<br/>&#13;
  ('paid', 'amod', 'job'),<br/>&#13;
  ('job', 'dobj', 'Find'),<br/>&#13;
  ('with', 'prep', 'Find'),<br/>&#13;
  ('no', 'det', 'experience'),<br/>&#13;
  ('experience', 'pobj', 'with'),<br/>&#13;
  ('.', 'punct', 'Find')<br/>&#13;
]</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_150"/>Diagrammatically, this dependency parsing looks like <a href="../Text/ch10.xhtml#ch10fig02">Figure 10-2</a>.</p>&#13;
<div class="image"><a id="ch10fig02"/><img src="../Images/fig10-2.jpg" alt="image" width="636" height="288"/></div>&#13;
<p class="figcap"><em>Figure 10-2: The dependency parsing of the sample sentence</em></p>&#13;
<p class="indent">This syntactic parsing probably won’t help you generate the desired database query from the sentence. The SQL query shown earlier in this section uses the <code>SELECT</code> statement to select a job that satisfies the requirements “high paid” and “no experience.” In this logic, the word “job” should be connected with not only “high paid” but also “no experience,” but the syntactic parsing doesn’t connect “job” with “no experience.”</p>&#13;
<p class="indent">To meet your processing needs, you might want to change labeling in a way that will simplify the task of generating database queries. For that, you need to implement a custom parser that shows semantic relations rather than syntactic dependencies. In this case, that means you’d want an arc between the words “job” and “experience.” The following sections describe how to implement this.</p>&#13;
<h4 class="h4" id="lev140"><strong><em>Deciding on Types of Semantic Relations to Use</em></strong></h4>&#13;
<p class="noindent">First, you need to choose a set of relation types to use for labeling. The spaCy documentation contains an example of a custom message parser (<em><a href="https://spacy.io/usage/training/#intent-parser">https://spacy.io/usage/training/#intent-parser</a></em>) that uses the following semantic relations: <code>ROOT</code>, <code>PLACE</code>, <code>ATTRIBUTE</code>, <code>QUALITY</code>, <code>TIME</code>, and <code>LOCATION</code>. You might, for example, assign <code>PLACE</code> to a place at which some activity occurs, like “hotel” in the utterance, “I need a hotel in Berlin.” “Berlin” would be a <code>LOCATION</code> in this same utterance, allowing you to distinguish between geographical areas and smaller settings.</p>&#13;
<p class="indent">To comply with the semantics used in this example, you might add one more type to the list: <code>ACTIVITY</code>, which you could use to label the word “job” in the sample sentence. (Of course, you could just use the original set of relation types. After all, a job is typically associated with a workplace, for which you could use the type <code>PLACE</code>.)</p>&#13;
<h4 class="h4" id="lev141"><strong><em>Creating Training Examples</em></strong></h4>&#13;
<p class="noindent">As usual for the process of training a pipeline component, you start by preparing training examples. When training a parser, you need information <span epub:type="pagebreak" id="page_151"/>about each token’s dependency label and the head of each relation. In this example, you use only a couple of training examples to keep it short and simple. Of course, a real-world implementation would require many more to train a parser component.</p>&#13;
<pre>TRAINING_DATA = [<br/>&#13;
    ('find a high paying job with no experience', {<br/>&#13;
        'heads': [0, 4, 4, 4, 0, 7, 7, 4],<br/>&#13;
        'deps': ['ROOT', '-', 'QUALITY', 'QUALITY', 'ACTIVITY', '-', 'QUALITY', 'ATTRIBUTE']<br/>&#13;
    }),<br/>&#13;
    ('find good workout classes near home', {<br/>&#13;
        'heads': [0, 4, 4, 4, 0, 6, 4], <br/>&#13;
        'deps': ['ROOT', '-', 'QUALITY', 'QUALITY', 'ACTIVITY', 'QUALITY', 'ATTRIBUTE']<br/>&#13;
    })<br/>]</pre>&#13;
<p class="indent">Notice that the syntactically related words might not always be related semantically in the new parser. To see this clearly, you can perform the following test, which generates a list of the heads of the <em>syntactic</em> dependencies found in the sample sentence from the first training example in the <code>TRAINING_DATA</code> list:</p>&#13;
<pre>import spacy<br/>&#13;
nlp = spacy.load('en')<br/>&#13;
doc = nlp(u'find a high paying job with no experience')<br/>&#13;
heads = []<br/>&#13;
for token in doc:<br/>&#13;
    heads.append(token.head.i)<br/>&#13;
print(heads)</pre>&#13;
<p class="indent">Assuming you’re using the <code>en_core_web_sm</code> model, this code should output the following token head indexes:</p>&#13;
<pre>[0, 4, 4, 4, 0, 4, 7, 5]</pre>&#13;
<p class="indent">When you compare this list with the heads provided for this same sentence in the <code>TRAINING_DATA</code> list, you should notice discrepancies. For example, in the training example, the word “with” is a child of the word “experience,” whereas, according to standard syntactic rules, “with” is a child of “job” in this sentence. This deviation makes sense if we slightly change the sentence:</p>&#13;
<pre>find a high paying job without any experience</pre>&#13;
<p class="indent">In terms of semantics, “without” can be thought of as a modifier for “experience,” because “without” changes the meaning of “experience.” Modifiers, in turn, are always dependent on the word they modify. Therefore, considering “without” as the child in the without/experience pair in this example is quite reasonable when taking semantics into consideration.</p>&#13;
<h4 class="h4" id="lev142"><span epub:type="pagebreak" id="page_152"/><strong><em>Training the Parser</em></strong></h4>&#13;
<p class="noindent">The following script illustrates how to train a parser from scratch using a blank model. In this example, creating a brand-new parser is more reasonable than updating an existing one: the reason is that attempting to train an existing syntactic dependency parser to recognize semantic relations as well would be very difficult, because the two kinds of relations often conflict. But this doesn’t mean that you can’t use your custom parser with existing models. You can load it to any model to replace its original syntactic dependency parser.</p>&#13;
<p class="indent">To train the parser, the following script uses the training examples from the <code>TRAINING_DATA</code> list defined in the preceding section. Be sure to prepend the <code>TRAINING_DATA</code> list to the code that follows:</p>&#13;
<pre>   import spacy<br/>&#13;
<span class="ent">➊</span> nlp = spacy.blank('en')<br/>&#13;
<span class="ent">➋</span> parser = nlp.create_pipe('parser')<br/>&#13;
<span class="ent">➌</span> nlp.add_pipe(parser, first=True)<br/>&#13;
<span class="ent">➍</span> for text, annotations in TRAINING_DATA:<br/>&#13;
  <span class="ent">➎</span> for d in annotations.get('deps', []):<br/>&#13;
    <span class="ent">➏</span> parser.add_label(d)<br/>&#13;
<span class="ent">➐</span> optimizer = nlp.begin_training()<br/>&#13;
   import random<br/>&#13;
<span class="ent">➑</span> for i in range(25):<br/>&#13;
       <span class="ent">➒</span> random.shuffle(TRAINING_DATA)<br/>&#13;
       for text, annotations in TRAINING_DATA:<br/>&#13;
           nlp.update([text], [annotations], sgd=optimizer)<br/>&#13;
<span class="ent">➓</span> parser.to_disk('/home/oracle/to/parser')</pre>&#13;
<p class="indent">We start by creating a blank model <span class="ent">➊</span>. Then we create a blank parser component <span class="ent">➋</span> and add it to the model’s pipeline <span class="ent">➌</span>.</p>&#13;
<p class="indent">In this example, we derive the set of labels for the parser to use from the <code>TRAINING_DATA</code> list that we had to add to the code. We implement this operation in two loops. In the outer loop, we iterate over the training examples, extracting the tuple with the head and dependency annotations from each example <span class="ent">➍</span>. In the inner loop, we iterate over the tuple of annotations, extracting each label from the <code>deps</code> list <span class="ent">➎</span> and adding it to the parser <span class="ent">➏</span>.</p>&#13;
<p class="indent">Now we can start the training process. First, we acquire an optimizer <span class="ent">➐</span> and then implement a simple training loop <span class="ent">➑</span>, shuffling the training examples in a random order <span class="ent">➒</span>. Next, we iterate over the training examples, updating the parser model on each iteration.</p>&#13;
<p class="indent">Finally, we serialize the custom parser to disk so we can load and use it later in another script <span class="ent">➓</span>.</p>&#13;
<h4 class="h4" id="lev143"><strong><em>Testing Your Custom Parser</em></strong></h4>&#13;
<p class="noindent">You can load a custom parser from disk to an existing model’s pipeline using the following script:</p>&#13;
<pre>   import spacy<br/>&#13;
   from spacy.pipeline import DependencyParser<br/>&#13;
<span epub:type="pagebreak" id="page_153"/><span class="ent">➊</span>   nlp = spacy.load('en', disable=['parser'])<br/>&#13;
<span class="ent">➋</span> parser = DependencyParser(nlp.vocab)<br/>&#13;
<span class="ent">➌</span> parser.from_disk('/home/oracle/to/parser')<br/>&#13;
<span class="ent">➍</span> nlp.add_pipe(parser, "custom_parser")<br/>&#13;
   print(nlp.meta['pipeline'])<br/>&#13;
   doc = nlp(u'find a high paid job with no degree')<br/>&#13;
<span class="ent">➎</span> print([(w.text, w.dep_, w.head.text) for w in doc if w.dep_ != '-'])</pre>&#13;
<p class="indent">Notice that this script is similar to the script for loading a custom named entity recognizer shown earlier in “<a href="../Text/ch10.xhtml#lev137">Evaluating the Updated Recognizer</a>” on <a href="../Text/ch10.xhtml#page_148">page 148</a>. We load a regular model, disabling a certain component—the parser, in this example <span class="ent">➊</span>. Next, we create a parser <span class="ent">➋</span> and load it with the data previously serialized to disk <span class="ent">➌</span>. To make the parser available, we need to add it to the model’s pipeline <span class="ent">➍</span>. Then we can test it <span class="ent">➎</span>.</p>&#13;
<p class="indent">The script should produce the following output:</p>&#13;
<pre>['tagger', 'ner', 'custom_parser']<br/>&#13;
[<br/>&#13;
  ('find', 'ROOT', 'find'),<br/>&#13;
  ('high', 'QUALITY', 'job'),<br/>&#13;
  ('paid', 'QUALITY', 'job'),<br/>&#13;
  ('job', 'ACTIVITY', 'find'),<br/>&#13;
  ('no', 'QUALITY', 'degree'),<br/>&#13;
  ('degree', 'ATTRIBUTE', 'job')<br/>&#13;
]</pre>&#13;
<p class="indent">The original parser component has been replaced with the custom one in a regular model, whereas the other pipeline components remain the same. Later, we could reload the original component by loading the model using <code>spacy.load('en')</code>.</p>&#13;
<h4 class="h4" id="lev144"><strong><em>Try This</em></strong></h4>&#13;
<p class="noindent">Now that you have a custom parser trained to reveal semantic relations, you can put it to use. Continue with the example from this section by writing a script that generates a SQL statement from a plain English request. In that script, check the <code>ROOT</code> element of each request to determine whether you need to construct a <code>SELECT</code> statement. Then use the <code>ACTIVITY</code> element to refer to the database table against which the statement being generated will be executed. Use the <code>QUALITY</code> and <code>ATTRIBUTE</code> elements in the statement’s <code>WHERE</code> clause.</p>&#13;
<h3 class="h3" id="lev145"><strong>Summary</strong></h3>&#13;
<p class="noindent">You can download a set of pretrained statistical models from spaCy to use immediately. But these models might not always suit your purposes. You might want to improve a pipeline component in an existing model or create a new component in a blank model that will better suit your app’s needs.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_154"/>In this chapter, you learned how to train an existing named entity recognizer component to recognize an additional set of entities that weren’t labeled correctly by default. Then you learned how to train a custom parser component to predict a type of tree structure related to input text that shows semantic relations rather than syntactic dependencies.</p>&#13;
<p class="indent">In both cases, the first (and perhaps the most important and time-consuming) step is to prepare training data. Once you’ve done that, you’ll need only a few more lines of code to implement a training loop for your custom component.</p>&#13;
</div>&#13;
</body></html>
- en: '**11**'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**11**'
- en: '**SCALING AND ARCHITECTURE**'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**可扩展性与架构**'
- en: '![image](../images/common01.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/common01.jpg)'
- en: Sooner or later, your development process will have to consider resiliency and
    scalability. An application’s scalability, concurrency, and parallelism depend
    largely on its initial architecture and design. As we’ll see in this chapter,
    there are some paradigms—such as multithreading—that don’t apply correctly to
    Python, whereas other techniques, such as service-oriented architecture, work
    better.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 迟早，你的开发过程将不得不考虑弹性和可扩展性。一个应用程序的可扩展性、并发性和并行性在很大程度上取决于其最初的架构和设计。正如我们在本章中所看到的，有些范式——例如多线程——在
    Python 中并不适用，而其他技术，例如面向服务的架构，则效果更好。
- en: Covering scalability in its entirety would take an entire book, and has in fact
    been covered by many books. This chapter covers the essential scaling fundamentals,
    even if you’re not planning to build applications with millions of users.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 完整地涵盖可扩展性需要一本书，而事实上已经有很多书对此进行了详细讨论。本章涵盖了可扩展性的基本原则，即使你不打算构建有百万用户的应用程序。
- en: '**Multithreading in Python and Its Limitations**'
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**Python 中的多线程及其限制**'
- en: By default, Python processes run on only one thread, called the *main thread*.
    This thread executes code on a single processor. *Multithreading* is a programming
    technique that allows code to run concurrently inside a single Python process
    by running several threads simultaneously. This is the primary mechanism through
    which we can introduce concurrency in Python. If the computer is equipped with
    multiple processors, you can even use *parallelism*, running threads in parallel
    over several processors, to make code execution faster.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Python 进程只在一个线程上运行，这个线程被称为*主线程*。这个线程在单个处理器上执行代码。*多线程*是一种编程技术，允许代码通过同时运行多个线程在单个
    Python 进程内并发执行。这是我们在 Python 中引入并发的主要机制。如果计算机配备了多个处理器，你甚至可以使用*并行ism*，在多个处理器上并行运行线程，以加快代码执行速度。
- en: 'Multithreading is most commonly used (though not always appropriately) when:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 多线程最常用的场景（虽然不总是适用）是：
- en: You need to run background or I/O-oriented tasks without stopping your main
    thread’s execution. For example, the main loop of a graphical user interface is
    busy waiting for an event (e.g., a user click or keyboard input), but the code
    needs to execute other tasks.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你需要在不停止主线程执行的情况下运行后台或 I/O 导向的任务。例如，图形用户界面的主循环正在忙着等待一个事件（例如用户点击或键盘输入），但代码还需要执行其他任务。
- en: You need to spread your workload across several CPUs.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你需要将工作负载分配到多个 CPU 上。
- en: 'The first scenario is a good general case for multithreading. Though implementing
    multithreading in this circumstance would introduce extra complexity, controlling
    multithreading would be manageable, and performance likely wouldn’t suffer unless
    the CPU workload was intensive. The performance gain from using concurrency with
    workloads that are I/O intensive gets more interesting when the I/O has high latency:
    the more often you have to wait to read or write, the more beneficial it is to
    do something else in the meantime.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个场景是多线程的一个很好的通用案例。虽然在这种情况下实现多线程会引入额外的复杂性，但控制多线程是可管理的，除非 CPU 工作负载非常密集，否则性能通常不会受到影响。当工作负载是
    I/O 密集型时，使用并发的性能提升更为显著，特别是在 I/O 延迟较高时：你等待读取或写入的时间越长，做其他事情的好处就越大。
- en: In the second scenario, you might want to start a new thread for each new request
    instead of handling them one at a time. This may seem like a good use for multithreading.
    However, if you spread your workload out like this, you will encounter the Python
    *global interpreter lock (GIL),* a lock that must be acquired each time CPython
    needs to execute bytecode. The lock means that only one thread can have control
    of the Python interpreter at any one time. This rule was introduced originally
    to prevent race conditions, but it unfortunately means that if you try to scale
    your application by making it run multiple threads, you’ll always be limited by
    this global lock.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二种情况下，你可能希望为每个新请求启动一个新线程，而不是逐个处理它们。这看起来像是多线程的一个好用例。然而，如果你像这样分散工作负载，你将会遇到 Python
    的*全局解释器锁（GIL）*，它是每次 CPython 执行字节码时必须获得的锁。这个锁意味着在任何时候只有一个线程可以控制 Python 解释器。这个规则最初是为了防止竞争条件而引入的，但不幸的是，它意味着如果你试图通过让应用程序运行多个线程来扩展它，你将始终受到这个全局锁的限制。
- en: So, while using threads seems like the ideal solution, most applications running
    requests in multiple threads struggle to attain 150 percent CPU usage, or usage
    of the equivalent of 1.5 cores. Most computers have 4 or 8 cores, and servers
    offer 24 or 48 cores, but the GIL prevents Python from using the full CPU. There
    are some initiatives underway to remove the GIL, but the effort is extremely complex
    because it requires performance and backward compatibility trade-offs.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，虽然使用线程看似是理想的解决方案，但大多数在多个线程中运行请求的应用程序难以达到 150% 的 CPU 使用率，或者相当于 1.5 个核心的使用率。大多数计算机有
    4 或 8 个核心，服务器则提供 24 或 48 个核心，但 GIL 阻止了 Python 使用全部的 CPU。目前有一些移除 GIL 的计划，但这个努力非常复杂，因为它需要在性能和向后兼容性之间做出权衡。
- en: Although CPython is the most commonly used implementation of the Python language,
    there are others that do not have a GIL. *Jython*, for example, can efficiently
    run multiple threads in parallel. Unfortunately, projects such as Jython by their
    very nature lag behind CPython and so are not really useful targets; innovation
    happens in CPython, and the other implementations are just following in CPython’s
    footsteps.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 CPython 是 Python 语言中最常用的实现，但也有其他实现没有 GIL。例如，*Jython* 可以高效地并行运行多个线程。不幸的是，像
    Jython 这样的项目由于其自身的性质总是滞后于 CPython，因此并不是真正有用的目标；创新发生在 CPython 中，其他实现只是在追随 CPython
    的步伐。
- en: 'So, let’s revisit our two use cases with what we now know and figure out a
    better solution:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，让我们回顾一下现在所知道的两个用例，并找出一个更好的解决方案：
- en: When you need to run background tasks, you *can* use multithreading, but the
    easier solution is to build your application around an event loop. There are a
    lot of Python modules that provide for this, and the standard is now `asyncio`.
    There are also frameworks, such as Twisted, built around the same concept. The
    most advanced frameworks will give you access to events based on signals, timers,
    and file descriptor activity—we’ll talk about this later in the chapter in “[Event-Driven
    Architecture](ch11.xhtml#lev1sec63)” on [page 181](ch11.xhtml#page_181).
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你需要运行后台任务时，*可以*使用多线程，但更简单的解决方案是围绕事件循环构建应用程序。有很多 Python 模块可以实现这一点，现在的标准是`asyncio`。还有一些框架，如
    Twisted，也是围绕这个概念构建的。最先进的框架会让你通过信号、定时器和文件描述符活动来访问事件——我们将在本章的“[事件驱动架构](ch11.xhtml#lev1sec63)”中讨论这个问题，详见[第
    181 页](ch11.xhtml#page_181)。
- en: When you need to spread the workload, using multiple processes is the most efficient
    method. We’ll look at this technique in the next section.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你需要分担工作负载时，使用多个进程是最有效的方法。我们将在下一节中探讨这种技术。
- en: Developers should always think twice before using multithreading. As one example,
    I once used multithreading to dispatch jobs in rebuildd, a Debian-build daemon
    I wrote a few years ago. While it seemed handy to have a different thread to control
    each running build job, I very quickly fell into the threading-parallelism trap
    in Python. If I had the chance to begin again, I’d build something based on asynchronous
    event handling or multiprocessing and not have to worry about the GIL.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 开发人员在使用多线程时应该三思而后行。例如，我曾经在几年前使用多线程来分配任务，在我写的 Debian 构建守护进程 rebuildd 中。虽然为每个正在运行的构建任务分配一个线程看起来很方便，但我很快就陷入了
    Python 中线程并行性的陷阱。如果有机会重新开始，我会基于异步事件处理或多进程来构建，而不必担心 GIL。
- en: Multithreading is complex, and it’s hard to get multithreaded applications right.
    You need to handle thread synchronization and locking, which means there are a
    lot of opportunities to introduce bugs. Considering the small overall gain, it’s
    better to think twice before spending too much effort on it.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 多线程是复杂的，正确实现多线程应用程序很困难。你需要处理线程同步和锁定，这意味着有很多引入 bug 的机会。考虑到总体收益较小，最好在投入太多精力之前再三考虑。
- en: '**Multiprocessing vs. Multithreading**'
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**多进程与多线程**'
- en: Since the GIL prevents multithreading from being a good scalability solution,
    look to the alternative solution offered by Python’s *multiprocessing* package.
    The package exposes the same kind of interface you’d achieve using the multithreading
    module, except that it starts new *processes* (via `os.fork()`) instead of new
    system threads.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 GIL 阻止了多线程成为一个良好的可扩展性解决方案，因此可以考虑使用 Python 的*多进程*包提供的替代方案。该包提供了与多线程模块相同类型的接口，不同之处在于它启动的是新的*进程*（通过
    `os.fork()`），而不是新的系统线程。
- en: '[Listing 11-1](ch11.xhtml#ch11list1) shows a simple example in which one million
    random integers are summed eight times, with this activity spread across eight
    threads at the same time.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 11-1](ch11.xhtml#ch11list1)展示了一个简单的示例，其中一百万个随机整数被求和八次，这个活动在八个线程中同时进行。'
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '*Listing 11-1: Using multithreading for concurrent activity*'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '*示例 11-1：使用多线程实现并发活动*'
- en: In [Listing 11-1](ch11.xhtml#ch11list1), we create eight threads using the `threading.Thread`
    class and store them in the `workers` array. Those threads will execute the `compute()`
    function. They then use the `start()` method to start. The `join()` method only
    returns once the thread has terminated its execution. At this stage, the result
    can be printed.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在[示例 11-1](ch11.xhtml#ch11list1)中，我们使用`threading.Thread`类创建了八个线程，并将它们存储在`workers`数组中。这些线程将执行`compute()`函数。然后，它们使用`start()`方法开始执行。`join()`方法仅在线程执行完成后才会返回。此时，结果可以被打印出来。
- en: 'Running this program returns the following:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此程序会返回以下结果：
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This has been run on an idle four-core CPU, which means that Python could potentially
    have used up to 400 percent of CPU. However, these results show that it was clearly
    unable to do that, even with eight threads running in parallel. Instead, its CPU
    usage maxed out at 129 percent, which is just 32 percent of the hardware’s capabilities
    (129/400).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在一个空闲的四核CPU上运行的，这意味着Python最多可能使用400%的CPU。然而，这些结果表明，即使有八个线程并行运行，CPU使用率也明显未能达到这个数值。相反，CPU使用率达到了129%，仅占硬件能力的32%（129/400）。
- en: Now, let’s rewrite this implementation using *multiprocessing*. For a simple
    case like this, switching to multiprocessing is pretty straightforward, as shown
    in [Listing 11-2](ch11.xhtml#ch11list2).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用*多进程（multiprocessing）*重写这个实现。对于像这样简单的情况，切换到多进程非常直接，如[示例 11-2](ch11.xhtml#ch11list2)所示。
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '*Listing 11-2: Using multiprocessing for concurrent activity*'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '*示例 11-2：使用多进程实现并发活动*'
- en: The `multiprocessing` module offers a `Pool` object that accepts as an argument
    the number of processes to start. Its `map()` method works in the same way as
    the native `map()` method, except that a different Python process will be responsible
    for the execution of the `compute()` function.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '`multiprocessing`模块提供了一个`Pool`对象，它接受一个参数，表示要启动的进程数。它的`map()`方法与原生的`map()`方法作用相同，只是不同的Python进程将负责执行`compute()`函数。'
- en: 'Running the program in [Listing 11-2](ch11.xhtml#ch11list2) under the same
    conditions as [Listing 11-1](ch11.xhtml#ch11list1) gives the following result:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在相同条件下运行[示例 11-2](ch11.xhtml#ch11list2)程序，与[示例 11-1](ch11.xhtml#ch11list1)相比，得到以下结果：
- en: '[PRE3]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Multiprocessing reduces the exectution time by 60 percent. Moreover, we’ve been
    able to consume up to 363 percent of CPU power, which is more than 90 percent
    (363/400) of the computer’s CPU capacity.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 多进程将执行时间减少了60%。此外，我们已经能够消耗最多363%的CPU功率，这超过了计算机CPU容量的90%以上（363/400）。
- en: Each time you think that you can parallelize some work, it’s almost always better
    to rely on multiprocessing and to fork your jobs in order to spread the workload
    across several CPU cores. This wouldn’t be a good solution for very small execution
    times, as the cost of the `fork()` call would be too big, but for larger computing
    needs, it works well.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 每次你认为可以并行化某些工作时，几乎总是更好地依赖多进程，并将任务分叉到多个CPU核心上来分担负载。这对于非常短的执行时间不是一个好方案，因为`fork()`调用的成本太高，但对于更大的计算需求，它效果很好。
- en: '**Event-Driven Architecture**'
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**事件驱动架构**'
- en: '*Event-driven programming* is characterized by the use of events, such as user
    input, to dictate how control flows through a program, and it is a good solution
    for organizing program flow. The event-driven program listens for various events
    happening on a queue and reacts based on those incoming events.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '*事件驱动编程*的特点是通过事件（如用户输入）来决定程序的控制流，它是组织程序流程的一个好方法。事件驱动程序会监听队列上发生的各种事件，并根据这些传入的事件作出反应。'
- en: 'Let’s say you want to build an application that listens for a connection on
    a socket and then processes the connection it receives. There are basically three
    ways to approach the problem:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你想构建一个应用程序，它监听套接字上的连接，然后处理接收到的连接。基本上，有三种方法可以解决这个问题：
- en: Fork a new process each time a new connection is established, relying on something
    like the `multiprocessing` module.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每次建立新连接时，创建一个新进程，依赖像`multiprocessing`模块这样的工具。
- en: Start a new thread each time a new connection is established, relying on something
    like the `threading` module.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每当建立一个新连接时，就启动一个新线程，依赖于类似 `threading` 模块的东西。
- en: Add this new connection to your event loop and react to the event it will generate
    when it occurs.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将这个新连接添加到你的事件循环中，并对它发生时将产生的事件做出反应。
- en: Determining how a modern computer should handle tens of thousands of connections
    simultaneously is known as the *C10K problem*. Among other things, the C10K resolution
    strategies explain how using an event loop to listen to hundreds of event sources
    is going to scale much better than, say, a one-thread-per-connection approach.
    This doesn’t mean that the two techniques are not compatible, but it does mean
    that you can usually replace the multiple-threads approach with an event-driven
    mechanism.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 确定现代计算机如何同时处理成千上万的连接被称为 *C10K 问题*。C10K 解决方案策略解释了如何使用事件循环来监听数百个事件源，远比每个连接使用一个线程的方式更具可扩展性。这并不意味着这两种技术不兼容，但确实意味着你通常可以用事件驱动机制替代多线程方式。
- en: 'Event-driven architecture uses an event loop: the program calls a function
    that blocks execution until an event is received and ready to be processed. The
    idea is that your program can be kept busy doing other tasks while waiting for
    inputs and outputs to complete. The most basic events are “data ready to be read”
    and “data ready to be written.”'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 事件驱动架构使用事件循环：程序调用一个函数，直到接收到事件并准备好处理时才会阻塞执行。这个理念是，你的程序可以在等待输入输出完成时，继续忙于处理其他任务。最基本的事件是“数据准备好读取”和“数据准备好写入”。
- en: In Unix, the standard functions for building such an event loop are the system
    calls `select(2)` or `poll(2)`. These functions expect a list of file descriptors
    to listen for, and they will return as soon as at least one of the file descriptors
    is ready to be read from or written to.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Unix 中，用于构建此类事件循环的标准函数是系统调用 `select(2)` 或 `poll(2)`。这些函数期望接收一个文件描述符列表来进行监听，它们会在至少有一个文件描述符准备好进行读写操作时返回。
- en: 'In Python, we can access these system calls through the `select` module. It’s
    easy enough to build an event-driven system with these calls, though doing so
    can be tedious. [Listing 11-3](ch11.xhtml#ch11list3) shows an event-driven system
    that does our specified task: listening on a socket and processing any connections
    it receives.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Python 中，我们可以通过 `select` 模块访问这些系统调用。利用这些调用构建事件驱动的系统非常简单，尽管这样做可能有点繁琐。[Listing
    11-3](ch11.xhtml#ch11list3) 展示了一个执行我们指定任务的事件驱动系统：监听套接字并处理它接收到的任何连接。
- en: '[PRE4]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '*Listing 11-3: Event-driven program that listens for and processes connections*'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '*Listing 11-3：一个监听和处理连接的事件驱动程序*'
- en: In [Listing 11-3](ch11.xhtml#ch11list3), a server socket is created and set
    to *non-blocking*, meaning that any read or write operation attempted on that
    socket won’t block the program. If the program tries to read from the socket when
    there is no data ready to be read, the socket `recv()` method will raise an OSError
    indicating that the socket is not ready. If we did not call `setblocking(0)`,
    the socket would stay in blocking mode rather than raise an error, which is not
    what we want here. The socket is then bound to a port and listens with a maximum
    backlog of eight connections.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [Listing 11-3](ch11.xhtml#ch11list3) 中，创建了一个服务器套接字并将其设置为 *非阻塞*，意味着在该套接字上执行的任何读写操作都不会阻塞程序。如果程序在没有数据可读时尝试从套接字读取，套接字的
    `recv()` 方法会引发 OSError，指示套接字尚未准备好。如果我们没有调用 `setblocking(0)`，套接字将保持在阻塞模式，而不会引发错误，这不是我们希望的结果。然后，套接字会绑定到一个端口，并以最多八个连接的回退队列进行监听。
- en: The main loop is built using `select()`, which receives the list of file descriptors
    we want to read (the socket in this case), the list of file descriptors we want
    to write to (none in this case), and the list of file descriptors we want to get
    exceptions from (the socket in this case). The `select()` function returns as
    soon as one of the selected file descriptors is ready to read, is ready to write,
    or has raised an exception. The returned values are lists of file descriptors
    that match the requests. It’s then easy to check whether our socket is in the
    ready-to-be-read list and, if so, accept the connection and send a message.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 主循环是通过 `select()` 构建的，它接收我们希望读取的文件描述符列表（此例中为套接字），我们希望写入的文件描述符列表（此例中没有），以及我们希望获取异常的文件描述符列表（此例中为套接字）。`select()`
    函数会在其中一个被选中的文件描述符准备好读取、写入或引发异常时返回。返回值是符合请求条件的文件描述符列表。接下来，检查我们的套接字是否在准备读取的列表中，如果是，接受连接并发送消息。
- en: '**Other Options and asyncio**'
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**其他选项与 asyncio**'
- en: Alternatively, there are many frameworks, such as Twisted or Tornado, that provide
    this kind of functionality in a more integrated manner; Twisted has been the de
    facto standard for years in this regard. C libraries that export Python interfaces,
    such as `libevent`, `libev`, or `libuv`, also provide very efficient event loops.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，也有许多框架，如 Twisted 或 Tornado，它们提供了更为集成的此类功能；Twisted 在这方面多年来一直是事实上的标准。导出 Python
    接口的 C 库，如 `libevent`、`libev` 或 `libuv`，也提供了非常高效的事件循环。
- en: These options all solve the same problem. The downside is that, while there
    are a wide variety of choices, most of them are not interoperable. Many are also
    *callback based*, meaning that the program flow is not very clear when reading
    the code; you have to jump to a lot of different places to read through the program.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这些选项都解决了相同的问题。缺点是，尽管有多种选择，但大多数选项之间并不兼容。许多还采用 *回调机制*，这意味着在阅读代码时程序的流程并不十分清晰；你需要跳转到许多不同的地方才能通读程序。
- en: Another option would be the `gevent` or `greenlet` libraries, which avoid callback
    use. However, the implementation details include CPython x86–specific code and
    dynamic modification of standard functions at runtime, meaning you wouldn’t want
    to use and maintain code using these libraries over the long term.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种选择是使用 `gevent` 或 `greenlet` 库，它们避免使用回调。然而，它们的实现细节包括特定于 CPython x86 的代码和在运行时对标准函数的动态修改，这意味着你不愿意长期使用并维护使用这些库的代码。
- en: In 2012, Guido Van Rossum began work on a solution code-named *tulip*, documented
    under PEP 3156 (*[https://www.python.org/dev/peps/pep-3156](https://www.python.org/dev/peps/pep-3156)*).
    The goal of this package was to provide a standard event loop interface that would
    be compatible with all frameworks and libraries and be interoperable.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 2012 年，Guido Van Rossum 开始研究名为 *tulip* 的解决方案，并在 PEP 3156 中进行了文档说明（* [https://www.python.org/dev/peps/pep-3156](https://www.python.org/dev/peps/pep-3156)
    *）。该软件包的目标是提供一个标准的事件循环接口，能够与所有框架和库兼容，并具备互操作性。
- en: The tulip code has since been renamed and merged into Python 3.4 as the `asyncio`
    module, and it is now the de facto standard. Not all libraries are compatible
    with `asyncio`, and most existing bindings need to be rewritten.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 此后，tulip 代码被重命名并合并到 Python 3.4 中，成为 `asyncio` 模块，并且现在已成为事实上的标准。并非所有库都与 `asyncio`
    兼容，大多数现有的绑定需要重写。
- en: As of Python 3.6, `asyncio` has been so well integrated that it has its own
    `await` and `async` keywords, making it straightforward to use. [Listing 11-4](ch11.xhtml#ch11list4)
    shows how the `aiohttp` library, which provides an asynchronous HTTP binding,
    can be used with `asyncio` to run several web page retrievals concurrently.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 从 Python 3.6 开始，`asyncio` 已经如此完全集成，以至于它拥有了自己的 `await` 和 `async` 关键字，使得使用起来非常简便。[清单
    11-4](ch11.xhtml#ch11list4) 展示了如何使用提供异步 HTTP 绑定的 `aiohttp` 库与 `asyncio` 一起并发运行多个网页检索。
- en: '[PRE5]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '*Listing 11-4: Retrieving web pages concurrently with aiohttp*'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单 11-4：使用 aiohttp 并发地获取网页*'
- en: We define the `get()` function as asynchronous, so it is technically a coroutine.
    The `get()` function’s two steps, the connection and the page retrieval, are defined
    as asynchronous operations that yield control to the caller until they are ready.
    That makes it possible for `asyncio` to schedule another coroutine at any point.
    The module resumes the execution of a coroutine when the connection is established
    or the page is ready to be read. The eight coroutines are started and provided
    to the event loop at the same time, and it is `asyncio`’s job to schedule them
    efficiently.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将 `get()` 函数定义为异步函数，因此它本质上是一个协程。`get()` 函数的两个步骤——连接和页面检索——被定义为异步操作，在准备好之前将控制权交还给调用者。这使得
    `asyncio` 可以在任何时刻调度另一个协程。该模块在连接建立或页面准备好读取时会恢复协程的执行。这八个协程同时启动并交给事件循环，由 `asyncio`
    负责高效调度它们。
- en: The `asyncio` module is a great framework for writing asynchronous code and
    leveraging event loops. It supports files, sockets, and more, and a lot of third-party
    libraries are available to support various protocols. Don’t hesitate to use it!
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '`asyncio` 模块是编写异步代码和利用事件循环的一个优秀框架。它支持文件、套接字等，并且有许多第三方库支持各种协议。不要犹豫，尽管使用它！'
- en: '**Service-Oriented Architecture**'
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**面向服务的架构**'
- en: Circumventing Python’s scaling shortcomings can seem tricky. However, Python
    *is* very good at implementing *service-oriented architecture (SOA),* a style
    of software design in which different components provide a set of services through
    a communication protocol. For example, OpenStack uses SOA architecture in all
    of its components. The components use HTTP REST to communicate with external clients
    (end users) and an abstracted remote procedure call (RPC) mechanism that is built
    on top of the Advanced Message Queuing Protocol (AMQP).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 避开 Python 的扩展性缺陷可能看起来很棘手。然而，Python *确实*非常擅长实现 *面向服务的架构（SOA）*，这是一种软件设计风格，其中不同的组件通过通信协议提供一组服务。例如，OpenStack
    在其所有组件中都使用 SOA 架构。这些组件使用 HTTP REST 与外部客户端（最终用户）通信，并且构建在高级消息队列协议（AMQP）之上的抽象远程过程调用（RPC）机制。
- en: In your development situations, knowing which communication channels to use
    between those blocks is mainly a matter of knowing with whom you will be communicating.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的开发环境中，了解在这些模块之间使用哪些通信渠道，主要是了解你将与谁进行通信。
- en: When exposing a service to the outside world, the preferred channel is HTTP,
    especially for stateless designs such as REST-style (REpresentational State Transfer–style)
    architectures. These kinds of architectures make it easier to implement, scale,
    deploy, and comprehend services.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 当将服务暴露给外部世界时，首选的通道是 HTTP，特别是对于无状态设计，如 REST 风格（REpresentational State Transfer
    风格）架构。这种架构使得服务的实现、扩展、部署和理解变得更加容易。
- en: However, when exposing and using your API internally, HTTP may be not the best
    protocol. There are many other communication protocols and fully describing even
    one would likely fill an entire book.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在内部暴露和使用 API 时，HTTP 可能不是最佳协议。还有许多其他通信协议，甚至单独描述一种协议可能就会填满一本书。
- en: In Python, there are plenty of libraries for building RPC systems. Kombu is
    interesting because it provides an RPC mechanism on top of a lot of backends,
    AMQ protocol being the main one. It also supports Redis, MongoDB, Beanstalk, Amazon
    SQS, CouchDB, or ZooKeeper.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Python 中，有很多用于构建 RPC 系统的库。Kombu 很有意思，因为它提供了一个基于许多后端的 RPC 机制，其中 AMQ 协议是主要的支持协议。它还支持
    Redis、MongoDB、Beanstalk、Amazon SQS、CouchDB 或 ZooKeeper。
- en: In the end, you can indirectly gain a huge amount of performance from using
    such loosely coupled architecture. If we consider that each module provides and
    exposes an API, we can run multiple daemons that can also expose that API, allowing
    multiple processes—and therefore CPUs—to handle the workload. For example, *Apache
    httpd* would create a new `worker` using a new system process that handles new
    connections; we could then dispatch a connection to a different `worker` running
    on the same node. To do so, we just need a system for dispatching the work to
    our various `workers`, which this API provides. Each block will be a different
    Python process, and as we’ve seen previously, this approach is better than multithreading
    for spreading out your workload. You’ll be able to start multiple `workers` on
    each node. Even if stateless blocks are not strictly necessary, you should favor
    their use anytime you have the choice.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，通过使用这种松耦合的架构，你可以间接地获得大量的性能提升。如果我们认为每个模块都提供并暴露 API，那么我们可以运行多个守护进程，这些守护进程也可以暴露
    API，从而让多个进程——因此也让多个 CPU——来处理工作负载。例如，*Apache httpd* 会创建一个新的 `worker`，该 `worker`
    使用一个新的系统进程来处理新的连接；我们可以将连接分配给同一节点上运行的不同 `worker`。为了做到这一点，我们只需要一个系统来将工作分配给我们的各个
    `workers`，而这个 API 就提供了这样的功能。每个模块都会是一个不同的 Python 进程，正如我们之前所看到的，这种方法比多线程更适合分散工作负载。你将能够在每个节点上启动多个
    `workers`。即使无状态模块不是绝对必要的，在你有选择的情况下，你也应该偏向使用它们。
- en: '**Interprocess Communication with ZeroMQ**'
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**使用 ZeroMQ 的进程间通信**'
- en: As we’ve just discussed, a messaging bus is always needed when building distributed
    systems. Your processes need to communicate with each other in order to pass messages.
    `ZeroMQ` is a socket library that can act as a concurrency framework. [Listing
    11-5](ch11.xhtml#ch11list5) implements the same `worker` seen in [Listing 11-1](ch11.xhtml#ch11list1)
    but uses `ZeroMQ` as a way to dispatch work and communicate between processes.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们刚刚讨论的，构建分布式系统时总是需要一个消息总线。你的进程需要相互通信以传递消息。`ZeroMQ` 是一个可以作为并发框架的套接字库。[列表 11-5](ch11.xhtml#ch11list5)
    实现了与 [列表 11-1](ch11.xhtml#ch11list1) 中相同的 `worker`，但使用 `ZeroMQ` 作为分配工作和进程间通信的方式。
- en: '[PRE6]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '*Listing 11-5: workers using ZeroMQ*'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '*列表 11-5：使用 ZeroMQ 的工作进程*'
- en: We create two sockets, one to send the function `(work_sender)` ➊ and one to
    receive the job `(result_receiver)` ➋. Each `worker` started by `multiprocessing.Process`
    ➌ creates its own set of sockets and connects them to the master process. The
    `worker` then executes whatever function is sent to it and sends back the result.
    The master process just has to send eight jobs over its sender socket and wait
    for eight results to be sent back via the receiver socket ➍.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了两个套接字，一个用于发送函数`(work_sender)` ➊，另一个用于接收任务`(result_receiver)` ➋。每个由`multiprocessing.Process`启动的`worker`
    ➌都会创建自己的套接字，并将其连接到主进程。然后，`worker`执行传递给它的任何函数，并返回结果。主进程只需要通过发送套接字发送八个任务，并等待通过接收套接字返回八个结果
    ➍。
- en: As you can see, `ZeroMQ` provides an easy way to build communication channels.
    I’ve chosen to use the TCP transport layer here to illustrate the fact that we
    could run this over a network. It should be noted that `ZeroMQ` also provides
    an interprocess communication channel that works locally (without any network
    layer involved) by using Unix sockets. Obviously, the communication protocol built
    upon `ZeroMQ` in this example is very simple for the sake of being clear and concise,
    but it shouldn’t be hard to imagine building a more sophisticated communication
    layer on top of it. It’s also easy to imagine building an entirely distributed
    application communication with a network message bus such as ZeroMQ or AMQP.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，`ZeroMQ`提供了一种构建通信通道的简便方法。我选择在这里使用TCP传输层来说明我们可以通过网络运行这个。需要注意的是，`ZeroMQ`还提供了一种进程间通信通道，它通过使用Unix套接字在本地工作（不涉及任何网络层）。显然，为了简洁明了，本例中基于`ZeroMQ`构建的通信协议非常简单，但不难想象在其基础上构建一个更复杂的通信层。同样，也很容易想象构建一个完全分布式的应用程序，通过像ZeroMQ或AMQP这样的网络消息总线进行通信。
- en: 'Note that protocols such as HTTP, ZeroMQ, and AMQP are language agnostic: you
    can use different languages and platforms to implement each part of your system.
    While we all agree that Python is a good language, other teams might have other
    preferences, or another language might be a better solution for some part of a
    problem.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，诸如HTTP、ZeroMQ和AMQP之类的协议是语言无关的：你可以使用不同的语言和平台来实现系统的每个部分。虽然我们都认为Python是一个很好的语言，但其他团队可能有其他偏好，或者在解决某个问题的某个部分时，其他语言可能是更好的选择。
- en: In the end, using a transport bus to decouple your application into several
    parts is a good option. This approach allows you to build both synchronous and
    asynchronous APIs that can be distributed from one computer to several thousand.
    It doesn’t tie you to a particular technology or language, so you can evolve everything
    in the right direction.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，使用传输总线将应用程序解耦成多个部分是一个不错的选择。通过这种方法，你可以构建可以从一台计算机分发到数千台计算机的同步和异步API。它不会将你束缚于特定的技术或语言，因此你可以在正确的方向上发展一切。
- en: '**Summary**'
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**总结**'
- en: The rule of thumb in Python is to use threads only for I/O-intensive workloads
    and to switch to multiple processes as soon as a CPU-intensive workload is on
    the table. Distributing workloads on a wider scale—such as when building a distributed
    system over a network—requires external libraries and protocols. These are supported
    by Python, though provided externally.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Python中的经验法则是仅在I/O密集型工作负载下使用线程，并在CPU密集型工作负载出现时尽早切换到多进程。将工作负载分布到更广泛的范围——例如在网络上构建分布式系统——需要外部库和协议。Python支持这些内容，但它们是由外部提供的。

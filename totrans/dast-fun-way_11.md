# 11

缓存

![](img/chapterart.png)

本章介绍了*缓存*，一种数据结构，通过将一些数据存储在离计算更近的位置来缓解高数据访问成本。正如我们在前几章中所看到的，数据访问的成本是我们算法效率的一个关键因素。这不仅与我们如何组织存储中的数据有关，还与我们使用的存储类型有关。当数据存储得离处理器更近时，我们称之为*本地*数据，这样可以更快地进行处理。如果我们将一些数据从更昂贵、距离较远的位置复制到本地存储中，我们就可以显著加快数据的读取速度。

例如，我们可能会使用缓存来加速网页访问。加载一个网页的过程包括查询服务器获取页面上的信息，将这些数据传输到本地计算机，并将其以视觉形式呈现。如果网页包含大的元素，例如图片或视频，我们可能需要传输大量数据。为了减少这一成本，浏览器会缓存常用的数据。这样，我们每次访问网页时，不必重新下载我们最喜欢网站的 logo，浏览器会将这个图片保存在本地缓存中，以便从硬盘快速读取。

我们应该如何选择将哪些数据加载到缓存中呢？显然，我们不可能将所有东西都存储在缓存里。如果能这样做，我们根本不需要缓存——我们只需将整个数据集复制到最近的内存中。本章中，我们将结合之前探索过的数据结构，构建一种缓存策略——最少最近使用（LRU）缓存，它能大大提高我们最爱的咖啡店的运营效率。同时，我们也将简要讨论几种其他的缓存策略进行对比。

## 缓存介绍

到目前为止，我们把计算机的所有存储都视作相同的，像一个单一的书架，我们可以从中取出任何需要的物品，所需的努力大致相同。然而，数据存储并非如此简单。我们可以将存储想象成一个大型的多层图书馆。热门书籍的书架位于入口附近，以满足大多数顾客的需求，而那些发霉的老旧计算机科学期刊则被放置在地下室。我们甚至可能有一个远离现场的仓库，专门存储那些很少使用的书籍，直到顾客特意要求它们。想要找到关于 PILOT 编程语言的资料？很可能它不会出现在热门推荐区。

除了注意我们如何在程序中组织数据外，我们还需要考虑*数据存储的位置*。并非所有的数据存储方式都是相同的。实际上，对于不同的介质，存储容量、速度和成本之间通常存在权衡。CPU 内存（寄存器或本地缓存）非常快速，但只能存储非常有限的数量。计算机的随机存取存储器（RAM）提供了更大的存储空间，但速度较慢。硬盘的存储量比 RAM 大得多，但比 RAM 慢得多。调用网络可以访问海量存储，例如整个互联网，但也会带来相应的开销。处理非常大的数据集时，可能无法将整个数据集加载到内存中，这会对算法的性能产生重大影响。理解这些权衡如何影响算法性能非常重要。

将此与我们自己的早晨咖啡制作过程进行对比。虽然理想情况下我们可以随时得到成千上万种咖啡，但我们的公寓只能存储有限量的咖啡。街角有一家咖啡分销商，提供数百种咖啡品种，但我们真的想每次做咖啡时都走到那里去吗？相反，我们将少量我们喜欢的咖啡存放在公寓里。这种本地存储加快了我们早晨咖啡的制作速度，让我们在走出家门之前就能享受到第一杯咖啡。

缓存是访问昂贵数据之前的一个步骤，如图 11-1 所示。在调用远程服务器或访问本地硬盘之前，我们会检查数据是否已被存储在本地缓存中。如果有，我们直接从缓存中快速、便宜地访问数据。当我们在缓存中找到数据时，这就是一次*缓存命中*。我们可以停止查找，避免访问更昂贵的存储。如果数据不在缓存中，那就是*缓存未命中*。我们叹息一声，然后继续执行更昂贵的访问。

![缓存位于算法和昂贵数据存储之间。标有“查询”的箭头指向缓存和数据存储，标有“回复”的箭头指向相反方向。](img/f11001.png)

图 11-1：缓存位于算法和缓慢、昂贵的数据存储之间。

试想一下在一个繁忙的咖啡柜台上的场景。每日菜单包含 10 种咖啡，从极受欢迎的常规咖啡到很少有人购买的薄荷肉桂南瓜爆炸。柜台的另一端是一个咖啡站，站上有 10 个咖啡壶，每个壶上都有加热器。当收到订单时，咖啡师走到咖啡站，拿起适当的咖啡装入杯中。每天走了几英里后，咖啡师请求老板在收银台旁安装另一个加热器，这样他们可以让疲惫的双脚得到休息。老板同意了，但问道：“你打算将哪种咖啡放在收银台旁？”这个问题让咖啡师陷入沉思，他们尝试了一些策略。

咖啡师很快意识到，这不仅仅是选择哪种咖啡的问题，还要考虑何时该更换咖啡。他们可以根据一天中的不同时间在本地存储不同的咖啡。他们尝试将常规咖啡保持在缓存中整天，晚上将低咖啡因咖啡放得更近，当过去 10 分钟内没有顾客时，则将当前选择更换为常规咖啡。一些策略有效，而其他的，尤其是涉及缓存薄荷肉桂南瓜爆炸的策略，失败得很惨。如果咖啡师做出正确的选择，大多数订单会导致缓存命中，他们可以避免长时间走路。如果选择错误，本地咖啡对大多数订单都没用。

咖啡师可以进一步改善情况，在收银台旁安装第二个加热器。这样他们就可以不只存储一种咖啡口味，而是存储两种。然而，代价是这个第二个加热器占用了宝贵的柜台空间。无论是计算机还是咖啡店，都有有限的本地空间。我们不能把所有的咖啡都存放在收银台旁，也不能将整个互联网存储在电脑的 RAM 中。如果我们把缓存做得太大，就需要使用更慢的存储来存储它。这就是缓存的基本权衡——使用的内存与提供的加速之间的权衡。

当缓存满了，我们需要确定保留哪些数据，替换掉哪些数据。我们说被替换的数据是*从缓存中驱逐*出去的。也许在秋季早高峰时，三倍咖啡因的混合咖啡替代了低咖啡因咖啡。通过将低咖啡因咖啡从附近的加热器中驱逐，咖啡师节省了几个小时的路程去取更时髦的混合咖啡。不同的缓存方法使用不同的驱逐策略来确定替换哪些数据，从统计数据被访问的次数到预测这些数据是否会在不久的将来再次被使用。

## LRU 驱逐和缓存

*最近最少使用（LRU）缓存*存储最近使用的信息。LRU 缓存是一种简单而常见的做法，它很好地展示了我们在使用缓存时面临的各种权衡。这个缓存策略的直觉是：我们很可能会重新访问最近需要的信息，这与我们上面提到的浏览网页的例子非常契合。如果我们反复访问相同的一组网页，保存这些网页的一些（不变的）元素在本地是有好处的。我们不需要每次访问时重新请求网站的 logo。LRU 缓存由一组存储空间组成，存放最近访问的项目。当缓存满时，它会开始逐出较旧的项目——那些最近最少使用的项目。

如果我们的咖啡师决定将靠近收银台的加热器当作 LRU 缓存，他们会将最近点的咖啡放在那个加热器上。当他们收到不同的订单时，他们会将当前缓存的咖啡拿回咖啡站，放在那里的加热器上，并取回新咖啡。然后，他们将这杯新咖啡带回收银台，用来完成订单，并将其留在那里。

如果每个顾客点的都是不同的东西，那么这个策略就只会增加开销。咖啡师不再是拿着一杯咖啡走到柜台的尽头，而是拿着一壶咖啡走同样的路——可能会在心里抱怨柜台太长，或者在心里对顾客的口味进行评判：“谁会点薄荷肉桂南瓜爆炸味？”然而，如果大多数顾客点的咖啡相似，那么这个策略就会非常有效。三位顾客连续点普通咖啡就意味着节省了两趟来回的时间。随着顾客之间的互动效果，这个优势还会得到进一步的放大。在看到前面的人点了南瓜口味的混合咖啡后，下一位顾客做出了（值得怀疑的）决定，决定复制前者的选择，说：“我也要一样的。”

这正是我们在浏览自己最喜欢的网站时可能遇到的情况。我们从网站的一个页面跳转到同一网站的另一个页面。一些元素，如 logo，会在后续页面中重复出现，因此将这些元素保存在缓存中可以带来显著的节省。

### 构建 LRU 缓存

使用 LRU 逐出策略的缓存要求我们支持两个操作：查找任意元素和找到最近最少使用的元素（用于逐出）。我们必须能够快速执行这两个操作。毕竟，缓存的目的是加速查找。如果我们必须扫描整个未结构化的数据集来检查缓存是否命中，那么我们更可能增加开销而不是节省时间。

我们可以使用两个之前探讨过的组件来构建一个 LRU 缓存：哈希表和队列。哈希表使我们能够快速查找，高效地检索缓存中的任何项。队列是一个先进先出（FIFO）的数据结构，它允许我们追踪哪些项最近没有被使用。我们可以通过将队列中*最早*的项出队，而不是扫描每一项并检查时间戳，来高效地确定要移除的数据，如以下代码所示。

```py
LRUCache {
    HashTable: ht
    Queue: q
    Integer: max_size
    Integer: current_size
 }
```

哈希表中的每个条目都存储一个复合数据结构，其中包含至少三个条目：键、对应的值（或该条目的数据），以及指向缓存队列中相应节点的指针。最后一条信息至关重要，因为我们需要一种方法来查找和修改队列中的条目。正如在列表 11-1 中所示，我们将这些信息直接存储在哈希表节点的值条目中。

```py
CacheEntry {
    Type: key
    Type: value
    QueueListNode: node
}
```

列表 11-1：包含数据键、值和链接到队列节点的缓存条目的数据结构

图 11-2 展示了这些组件如何组合在一起的结果图。图看起来有点复杂，但当我们将其拆分成两部分时会变得更容易理解。左侧是哈希表。如同第十章所述，每个哈希值对应一个链表。链表中条目的值是列表 11-1 中的`CacheEntry`数据结构。右侧是队列数据结构，用来存储条目的键。一个单独的指针连接这些数据结构，将`CacheEntry`数据结构链接到队列中具有相应键的节点。

当然，计算机内存中图 11-2 中组件的实际布局比图示看起来更加混乱，因为节点并不真正彼此相邻。

![左侧的哈希表包含每个缓存项的条目，并指向一个额外的 CacheEntry 节点。每个 CacheEntry 节点有一个指针，指向右侧队列中的一个条目。](img/f11002.png)

图 11-2：作为哈希表和队列结合体实现的 LRU 缓存

在列表 11-2 中，我们定义了一个名为`CacheLookup`的查找函数，该函数返回给定查找键的值。如果是缓存命中，查找函数会直接返回该值，并更新数据最近的访问时间。如果是缓存未命中，函数将通过昂贵的查找获取数据，将其插入缓存中，并在必要时删除最旧的数据。

```py
CacheLookup(LRUCache: cache, Type: key):
  ❶ CacheEntry: entry = HashTableLookup(cache.ht, key)

    IF entry == null:
      ❷ IF cache.current_size >= cache.max_size:
            Type: key_to_remove = Dequeue(cache.q)
            HashTableRemove(cache.ht, key_to_remove)
            cache.current_size = cache.current_size - 1

      ❸ Type: data = retrieve data for the key from 
                     the slow data source.

      ❹ Enqueue(cache.q, key)
        entry = CacheEntry(key, data, cache.q.back)
      ❺ HashTableInsert(cache.ht, key, entry)
        cache.current_size = cache.current_size + 1
    ELSE:
        # Reset this key's location in the queue.
 ❻ RemoveNode(cache.q, entry.node)
      ❼ Enqueue(cache.q, key)

        # Update the CacheEntry's pointer.
      ❽ entry.node = cache.q.back
    return entry.value
```

列表 11-2：根据键查找项的代码

这段代码首先检查`key`是否出现在我们的缓存表中 ❶。如果是，我们就得到了缓存命中。否则，我们就是缓存未命中。

我们首先处理缓存未命中的情况。如果哈希表返回`null`，我们需要从更昂贵的数据存储中获取数据。我们将新检索到的值存储在缓存中，并从队列的前端驱逐（最旧的）项目。我们通过三步操作来完成这项工作。首先，如果缓存已满❷，我们从队列中出队最旧项的键，并使用它从哈希表中删除相应的条目。这样就完成了最旧项的驱逐。第二步，我们检索新的数据❸。第三步，我们将（`key`，`data`）对插入到缓存中。我们将`key`入队到队尾❹。然后，我们创建一个新的哈希表条目，包含新的`key`、`data`和指向队列中该键相应位置的指针（使用队列的`back`指针）。我们将此条目存储在哈希表中❺。

最后一段代码处理缓存命中的情况。当我们看到缓存命中时，我们希望将该键的元素从当前位置移动到队列的尾部。毕竟，我们刚刚看过它。现在它应该是我们最后一个想丢弃的元素。我们通过两步来移动该元素。首先，我们使用`RemoveNode`函数将其从队列中删除，使用指向该节点的指针❻。其次，我们将键重新入队到队尾❼，并更新指向该队列节点的指针❽。

我们可以将此更新操作想象成咖啡店排队的场景。如果有顾客离开排队，他们就失去了原本的位置。当他们将来重新加入队伍时，他们会排到队尾。

### 更新元素的最近性

为了支持在清单 11-2 中执行`RemoveNode`操作，我们需要修改队列以支持*更新*元素的位置。我们需要将最近访问的项目从当前队列位置移到队尾，以表明它们是最近访问的。首先，我们将第四章中的队列实现修改为使用双向链表，这将使我们能够高效地从队列中间删除项目：

```py
QueueListNode {
    Type: value
    QueueListNode: next
    QueueListNode: prev
}
```

如图 11-3 所示，`next`字段指向当前节点直接后面的节点（下一个出队的节点），而`prev`字段指向当前节点之前的节点。

![包含元素 31、41、5、92 和 65 的队列。每个节点包含一个数字，并且链接到队列中下一个和前一个数字。](img/f11003.png)

图 11-3：一个实现为双向链表的队列

接下来，我们相应地修改入队和出队操作。对于入队和出队，我们添加了额外的逻辑来更新前驱指针。与第四章的主要不同在于我们如何设置`prev`指针：

```py
Enqueue(Queue: q, Type: value):
    QueueListNode: node = QueueListNode(value)
    IF q.back == null:
        q.front = node
        q.back = node
    ELSE:
        q.back.next = node
      ❶ node.prev = q.back
        q.back = node
```

在入队操作中，代码需要将新节点的`prev`指针设置为前一个最后元素`q.back`❶。

```py
Dequeue(Queue: q):
    IF q.front == null:
        return null

    Type: value = q.front.value
    q.front = q.front.next
    IF q.front == null:
        q.back = null
    ELSE:
      ❶ q.front.prev = null
    return value
```

出队操作将新的队头节点的`prev`指针设置为`null`，表示它前面没有节点❶。

最后，我们添加了`RemoveNode`操作，它提供了从队列中间移除节点的功能。这时双向链表的使用就派上了用场。通过在两个方向上保持指针，我们无需扫描整个队列来找到当前节点前面的节点。`RemoveNode`的代码通过调整来自相邻节点的指针（`node.prev` 和 `node.next`）、队列前端的指针（`q.front`）和队列后端的指针（`q.back`），来完成这一操作。

```py
RemoveNode(Queue: q, QueueListNode: node):
    IF node.prev != null:
        node.prev.next = node.next
    IF node.next != null:
        node.next.prev = node.prev
    IF node == q.front:
       q.front = q.front.next
    IF node == q.back:
       q.back = q.back.prev
```

这段代码包含多个`IF`语句，用来处理从队列两端添加或移除元素的特殊情况。

还有一个问题需要解决：我们如何高效地找到我们想要移除和重新插入的元素？我们不能在搜索更新节点时扫描整个队列。支持缓存命中的前提是快速查找。在上面的缓存示例中，我们直接从缓存条目指向队列中的元素。这使得我们能够通过跟随指针，在常数时间内访问、移除和重新插入元素。

## 其他驱逐策略

让我们考虑三种替代的驱逐策略——最近使用、最少使用和预测驱逐——与 LRU 驱逐的比较。目标并不是深入分析这些方法，而是帮助你培养对选择缓存策略时所涉及的各种权衡的直觉。对于特定情境，最优的缓存策略将取决于该情境的具体情况。了解这些权衡将帮助你为你的使用场景选择最佳策略。

LRU 是一种有效的驱逐策略，适用于当我们看到某些缓存项的使用频繁出现突增，但预计缓存项的分布会随时间变化的情况。前面提到的靠近收银台的本地咖啡壶就是一个很好的例子。当有人点了一种新类型的咖啡时，咖啡师会走到柜台的另一端，拿走旧的咖啡混合物，取回新的混合物，并把咖啡壶放在收银台旁边。

让我们将其与逐出*最近使用（MRU）*元素进行对比。在电子书阅读器的情境下，可以想象它预取并缓存你可能喜欢的书籍。由于我们不太可能连续两次读同一本书，因此可能会合理地从缓存中丢弃最近阅读完的书籍，以腾出空间放入新的书籍。虽然 MRU 对于重复出现频率不高的项目来说是一种有效的方法，但这种驱逐策略会在我们的咖啡库中带来持续的麻烦。想象一下，如果每次我们煮咖啡时都被迫驱逐掉我们最喜欢的咖啡混合物，那该有多糟。

我们可以不考虑*最后一次访问*的时间，而是跟踪该项总共被访问了多少次。*最少频繁使用（LFU）*驱逐策略会丢弃访问次数最少的元素。当我们的缓存数据保持稳定时，这种方法非常有效，比如我们家里常备的经典咖啡品种。我们不会因为最近在当地咖啡店尝试了季节性咖啡豆就把三种常用的咖啡豆中的一种淘汰掉。缓存中的物品有着良好的历史记录，且通常会留在缓存中——至少在我们找到新的最爱之前。然而，当偏好发生变化时，新出现的热门物品可能需要一段时间才能积累足够的访问次数进入缓存。如果我们遇到一种比家里所有咖啡豆都更好的新咖啡，我们可能需要反复品尝许多杯咖啡，进行多次到咖啡店的拜访，才最终会为家里购买该咖啡豆。

*预测驱逐*策略提供了一种前瞻性的方式，尝试预测未来需要哪些元素。我们可以构建一个模型，预测哪些缓存条目最有可能在未来被访问，而不是依赖简单的计数或时间戳。如果我们有一个高度准确的模型，比如预测我们只会在十月和十一月之间从常用的咖啡豆切换到季节性的秋季咖啡豆，我们就可以大大提高命中率。然而，如果模型不准确，可能会错误地将每个月与去年那个时候我们喝的第一杯咖啡关联起来，这样我们可能会发现自己在八月再次犯下那个错误，喝着薄荷肉桂南瓜拿铁。预测驱逐的另一个缺点是，它增加了缓存本身的复杂性。现在，仅仅跟踪简单的计数或时间戳已经不够了；相反，缓存必须学习一个模型。

## 为什么这很重要

缓存可以在处理昂贵的存储介质时减轻一些访问成本。缓存将部分数据存储在更接近且更快速的地方，而不是每次都调用昂贵的存储。如果我们选择正确的缓存策略，就可以通过从缓存中获取数据而非从较慢的位置提取数据，节省大量时间。这使得缓存成为我们计算工具箱中常见且强大的工具。它们在现实世界中得到了广泛应用，从网页浏览器到图书馆书架，再到咖啡店。

缓存还展示了几个关键概念。首先，它们突出了在从不同媒介访问数据时需要考虑的潜在权衡。如果我们能将所有数据存储在最快的内存中，就不需要缓存了。不幸的是，这通常不可行；我们的算法将需要访问更大、更慢的数据存储，因此理解这一过程可能带来的成本是很有意义的。在下一章中，我们将介绍 B 树，一种基于树的数据结构，它减少了所需的数据访问次数。这种优化有助于降低在数据无法存放在附近的快速内存中时的整体成本。

其次，缓存重新审视了我们在前几章中看到的数据结构调整问题。缓存的大小和驱逐策略都是可能对缓存性能产生巨大影响的参数。考虑选择缓存大小的问题。如果缓存太小，它可能无法存储足够的数据以提供好处。我们咖啡馆里那只单独的咖啡壶帮忙也有限。另一方面，缓存过大将占用重要的内存资源，这些资源可能会被算法的其他部分所需要。

最后，也是对本书最重要的一点，缓存展示了我们如何将基本数据结构，如哈希表和队列，结合起来以提供更复杂和更具影响力的行为。在这种情况下，通过使用指针将哈希表条目与队列中的节点连接起来，我们可以高效地跟踪缓存中下一个应被移除的条目。

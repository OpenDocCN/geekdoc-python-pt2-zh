- en: '1'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Exploratory Data Analysis
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/book_art/chapterart.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This is a data science book, so let’s start by diving into some data. This
    is something you should get used to: the first step of every data science problem
    is exploring your data. Looking closely at its minutest details will help you
    understand it better and give you clearer ideas for next steps and more sophisticated
    analyses. It will also help you catch any errors or problems with your data as
    early as possible. These first steps in the data science process are referred
    to as *exploratory data analysis*.'
  prefs: []
  type: TYPE_NORMAL
- en: We’ll start this first chapter by introducing a business scenario and describing
    how data might be used to better run a business. We’ll talk about reading data
    in Python and checking basic summary statistics. We’ll then introduce some Python
    tools to create plots of data. We’ll go over simple exploratory analyses we can
    perform and talk about the questions they can answer for us. Finally, we’ll close
    with a discussion of how the analyses can help us improve business practices.
    The simple analyses that we’ll do in this chapter are the same types of analyses
    that you can do as a first step of working on any data science problem you ever
    encounter. Let’s begin!
  prefs: []
  type: TYPE_NORMAL
- en: Your First Day as CEO
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Imagine you receive a job offer to be the CEO of a company in Washington, DC,
    that provides bicycles that people can rent for short periods to ride around the
    city. Even though you don’t have any experience running bike-sharing companies,
    you accept the offer.
  prefs: []
  type: TYPE_NORMAL
- en: You show up to work on your first day and think about your business goals as
    a CEO. Some of the goals you might think about could be related to issues like
    customer satisfaction, employee morale, brand recognition, market share maximization,
    cost reduction, or revenue growth. How can you decide which of these goals you
    should pursue first, and how should you pursue it? For example, think about increasing
    customer satisfaction. Before focusing on that goal, you’d need to find out whether
    your customers are satisfied and, if not, discover what’s making satisfaction
    suffer and how it can be improved. Or suppose you’re more interested in working
    to increase revenue. You would need to know what your revenue is right now before
    figuring out how it could be increased. In other words, you won’t be able to choose
    your initial focus until you better understand your company.
  prefs: []
  type: TYPE_NORMAL
- en: If you want to understand your company, you need data. You might try to look
    at charts and reports that summarize your company’s data, but no prepared report
    can tell you as much as you’ll learn by diving into the data yourself.
  prefs: []
  type: TYPE_NORMAL
- en: Finding Patterns in Datasets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s look at some data from a real bike-sharing service and imagine that this
    is data from your company. You can download this data from [https://bradfordtuckfield.com/hour.csv](https://bradfordtuckfield.com/hour.csv).
    (This file is in a special format called *.csv*, which we’ll talk more about soon.)
    You can open this file in a spreadsheet editor like Microsoft Excel or LibreOffice
    Calc; you should see something that looks like [Figure 1-1](#figure1-1).
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/502888c01/f01001.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-1: Bike-sharing data, viewed in a spreadsheet'
  prefs: []
  type: TYPE_NORMAL
- en: 'This dataset is no different from many other datasets that you’ve probably
    seen before: a rectangular array of rows and columns. In this dataset, each row
    represents information about a particular hour between midnight on January 1,
    2011, and 11:59 PM on December 31, 2012—more than 17,000 hours total. The rows
    are arranged in order, so the first few rows give us information about the first
    few hours of 2011, and the last few rows relate to the last few hours of 2012.'
  prefs: []
  type: TYPE_NORMAL
- en: Each column contains a particular metric that has been measured for each of
    these hours. For example, the `windspeed` column gives us hourly measurements
    of wind speed at a particular weather-recording station in Washington, DC. Notice
    that this measurement isn’t in familiar units like miles per hour. Instead, the
    measurements have been transformed so that they’re always between 0 and 1; all
    we need to know is that 1 represents a fast wind speed and 0 represents no wind.
  prefs: []
  type: TYPE_NORMAL
- en: If you look at the first few rows, you’ll see that the `windspeed` value is
    `0` for each of these rows, meaning there was no measured wind for the first few
    hours of the bike-sharing service’s existence. On the seventh row (counting the
    heading as the first row), you can see that there was finally some wind, and its
    measured speed was 0.0896\. If you look at the `hr` column, you can see that this
    wind was recorded when `hr` = `5`, or at 5 AM. We know that this row gives us
    information about January 1 because the `dteday` column on the seventh row has
    the value `2011-01-01`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Just by looking at a few values in the data, we can already start to tell a
    story, albeit an unexciting one: a still New Year’s night that turned into a slightly
    less still New Year’s morning. If we want to know some stories about the bike-sharing
    company and its performance instead of just the weather, we’ll have to look at
    other, more relevant columns.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The columns with the most important information are the last three: `casual`,
    `registered`, and `count`. These columns indicate the number of people who used
    your company’s bikes each hour. People who register with your service to get discounts
    and benefits are registered users, and their bike use is recorded in the `registered`
    column. But people can also use your bikes without registering, and their bike
    use is recorded in the `casual` column. The sum of the `casual` and `registered`
    columns is the total count of users during each hour, and it’s recorded in the
    `count` column.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that you’re familiar with some of the more relevant columns in this dataset,
    you can learn a great deal just by glancing at their numbers. Looking at the first
    20 or so hours shown in [Figure 1-1](#figure1-1), for example, you can see that
    in most hours, you have more registered users than casual users (higher values
    in the `registered` column than the `casual` column). This is just a simple numeric
    fact, but as the CEO, you should think through its implications for your business.
    Having more registered than casual users might mean that you’re doing well at
    convincing people to register, but it also might mean that using your service
    casually without registering isn’t as easy as it should be. You’ll have to think
    about which segment of customers is more important for you to target: the regular,
    registered users, like daily commuters, or the casual, infrequent users, like
    sightseeing tourists.'
  prefs: []
  type: TYPE_NORMAL
- en: We can look more closely at the daily patterns of casual and registered users
    to see if we can learn more about them. Let’s look at the hours shown in [Figure
    1-1](#figure1-1) again. We see that casual users are sparse until the afternoon
    of the first day and peak around 1 PM. Registered users are relatively numerous
    even at 1 AM of the first day and peak at 2 PM. The differences between the behavior
    of registered and casual users are small but could be meaningful. For example,
    they could indicate demographic differences between these groups. This, in turn,
    could require using different marketing strategies targeted to each group.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider what we’ve done already: just by looking at a few columns of the first
    24 rows of our data, we’ve already learned several important things about the
    company and started to get some business ideas. Data science has a reputation
    for requiring arcane knowledge about sophisticated math and computer science,
    but simply glancing at a dataset, thinking a little, and applying common sense
    can go a long way toward improving any business scenario.'
  prefs: []
  type: TYPE_NORMAL
- en: Using .csv Files to Review and Store Data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s look even more closely at our data. If you open the data file (*hour.csv*)
    in a spreadsheet editor, it will look like [Figure 1-1](#figure1-1). However,
    you can also open this file in a text editor like Notepad (if you’re using Windows)
    or TextEdit (if you’re using macOS) or GNU Emacs or gedit (if you’re using Linux).
    When you open this file in a text editor, it will look like [Figure 1-2](#figure1-2).
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/502888c01/f01002.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-2: Bike-sharing data viewed as raw text'
  prefs: []
  type: TYPE_NORMAL
- en: This raw data (that is, every single text character) constitutes our *hour.csv*
    file, without the alignment of straight columns you’d see in a spreadsheet. Notice
    the many commas. This file’s extension, .*csv*, is short for *comma-separated
    values* because the numeric values in each row are separated from each other by
    commas.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you use a spreadsheet editor to open a .*csv* file, the editor will attempt
    to interpret every comma as a boundary between spreadsheet cells so that it can
    display the data in straight, aligned rows and columns. But the data itself is
    not stored that way: it’s just raw text with rows of values, with each value separated
    from other values by commas.'
  prefs: []
  type: TYPE_NORMAL
- en: The simplicity of *.csv* files means that they can be easily created, easily
    opened by many types of programs, and easily changed. That’s why data scientists
    commonly store their data in .*csv* format.
  prefs: []
  type: TYPE_NORMAL
- en: Displaying Data with Python
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Using Python will allow us to do more sophisticated analyses than are possible
    in text editors and spreadsheet programs. It will also allow us to automate our
    processes and run analyses more quickly. We can easily open *.csv* files in Python.
    The following three lines of Python code will read the *hour.csv* file into your
    Python session and display its first five rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: We’ll look more closely at the output of this snippet later. For now, let’s
    look at the code itself. Its purpose is to read and display our data. The second
    line reads the data by using the `read_csv()` method. A *method* is a unit of
    code that performs a single, well-defined function. As its name suggests, `read_csv()`
    is specifically designed to read data that’s stored in *.csv* files. After you
    run this line, the `hour` variable will contain all the data in the *hour.csv*
    file; then you can access this data in Python.
  prefs: []
  type: TYPE_NORMAL
- en: On the third line, we use the `print()` function to display (print) our data
    onscreen. We could change the third line to `print(hour)` to see the entire dataset
    printed out. But datasets can be very large and hard to read all at once. Therefore,
    we add the `head()` method because it returns only the dataset’s first five rows.
  prefs: []
  type: TYPE_NORMAL
- en: Both `read_csv()` and `head()` can be very useful to us. But they’re not part
    of the *Python standard library*—the standard Python capabilities installed by
    default. They are instead part of a package, a third-party body of code that’s
    optional to install and use in Python scripts.
  prefs: []
  type: TYPE_NORMAL
- en: 'These two methods are part of a popular package called *pandas*, which contains
    code for working with data. That’s why the first line of the previous snippet
    is `import pandas as pd`: this *imports*, or brings in, the pandas package so
    we can access it in our Python session. When we write `as pd`, this gives the
    package an *alias*, so every time we want to access a pandas capability, we can
    write `pd` instead of the full name pandas. So when we write `pd.read_csv()`,
    we’re accessing the `read_csv()` method that’s part of the pandas package.'
  prefs: []
  type: TYPE_NORMAL
- en: If you get an error when you run `import pandas as pd`, it’s possible that pandas
    is not installed on your computer. (Packages need to be installed before you can
    import them.) To install pandas, or any other Python package, you should use the
    standard Python package installer, called pip. You can find instructions for how
    to install pip and use it to install Python packages like pandas in this book’s
    introduction. Throughout this book, every time you import a package, you should
    make sure that you’ve first installed it on your computer by using pip.
  prefs: []
  type: TYPE_NORMAL
- en: 'You might get another error when you run this snippet. One of the most common
    errors will occur when Python isn’t able to find the *hour.csv* file. If that
    happens, Python will print out an error report. The last line of the error report
    might say this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Even if you’re not a Python expert, you can surmise what this means: Python
    tried to read the *hour.csv* file but wasn’t able to find it. This can be a frustrating
    error, but one that’s possible to resolve. First, make sure that you’ve downloaded
    the *hour.csv* file and that it has the name *hour.csv* on your computer. The
    filename on your computer needs to exactly match the filename in your Python code.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If the name *hour.csv* is spelled correctly in your Python code (entirely with
    lowercase letters), the problem is probably with the file’s location. Remember
    that every file on your computer has a unique filepath that specifies exactly
    where you need to navigate to get to it. A filepath might look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This filepath is in the format used in the Windows operating system. If you’re
    using Windows, try to make sure that your directories and filenames don’t use
    any special characters (like characters from non-English alphabets) because filepaths
    with special characters can lead to errors. The following is another example of
    a filepath, one that’s in the format used by Unix-style operating systems (including
    macOS and Linux):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'You’ll notice that Windows filepaths look different from macOS and Linux filepaths.
    In macOS and Linux, we use forward slashes exclusively, and we start with a slash
    (`/`) instead of a drive name like `C:\`. When you read a file into Python, the
    most straightforward way to avoid an error is to specify the full filepath, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'When you run this snippet, you can replace the filepath in the `read_csv()`
    method with the filepath on your own computer. When you run the previous snippet,
    with the filepath correctly specified to match the location of *hour.csv* on your
    computer, you should get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This output shows the first five rows of our data. You can see that the data
    is arranged by column, in a way that looks similar to our spreadsheet output.
    Just as in [Figure 1-1](#figure1-1), each row contains numeric values related
    to a particular hour of the bike-sharing company’s history.
  prefs: []
  type: TYPE_NORMAL
- en: Here, we see ellipses in place of some columns so that it’s easier to read onscreen
    and not too hard to read or copy and paste into text documents. (You might see
    all the columns instead of ellipses—your display will depend on the details of
    how Python and pandas are configured on your computer.) Just as we did when we
    opened the file in a spreadsheet editor, we can start looking at some of these
    numbers to discover stories about the company’s history and get ideas for running
    the business.
  prefs: []
  type: TYPE_NORMAL
- en: Calculating Summary Statistics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Besides just looking at our data, quantifying its important attributes will
    be helpful. We can start by calculating the mean of one of the columns, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Here, we access the `count` column of our `hour` dataset by using square brackets
    (`[]`) and the column name (`count`). If you run `print(hour['count'])` alone,
    you’ll see the entire column printed to your screen. But we want just the *mean*
    of the column, not the column itself, so we add the `mean()` method—yet another
    capability provided by pandas. We see that the mean is about 189.46\. This is
    interesting to know from a business perspective; it’s a rough measurement of the
    size of the business over the two years covered by the data.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to calculating the mean, we could calculate other important metrics
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Here, we calculate the median of the `count` column by using the `median()`
    method. We also use the `std()` method to calculate a standard deviation of our
    `count` variable. (You may already know that a *standard deviation* is a measurement
    of how far spread out a set of numbers is. It’s useful to help us understand the
    amount of variation that exists in ridership counts between hours in our data.)
    We also calculate the minimum and maximum of the `registered` variable, using
    the `min()` and `max()` methods, respectively. The number of registered users
    ranges from 0 to 886, and this tells us the hourly record you’ve set, and the
    record you’ll need to break if you want your business to do better than it ever
    has before.
  prefs: []
  type: TYPE_NORMAL
- en: These simple calculations are called *summary statistics*, and they’re useful
    to check for every dataset you ever work with. Checking the summary statistics
    of a dataset can help you better understand your data and, in this case, help
    you better understand your business.
  prefs: []
  type: TYPE_NORMAL
- en: As simple as these summary statistics might seem, many CEOs, if put on the spot,
    couldn’t even tell you their company’s exact number of customers. Knowing simple
    things like the mean number of customers on any hour of any day can help you understand
    how big your company is and how much room you have to grow.
  prefs: []
  type: TYPE_NORMAL
- en: These summary statistics can also be combined with other information to tell
    us even more. For example, if you look up how much your company charges for one
    hour of bike usage, you can multiply that by the mean of the `count` column to
    get your total revenue over the two years covered by the data.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can check summary statistics manually by using pandas methods like `mean()`
    and `median()` as we did previously. But another method makes summary statistics
    easy to check:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we use the `describe()` method to check the summary statistics of all
    variables in the dataset. The output looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: You can see that `describe()` provides an entire table to us, and this table
    contains several useful metrics, including the mean, minimum, and maximum of each
    of our variables. The output of `describe()` also contains percentiles. The `25%`
    row, for example, contains the 25th percentile of each variable in the `hour`
    data. We can see that the 25th percentile of the `count` variable is 40, meaning
    that 25 percent of the hours in our dataset had 40 users or fewer, while 75 percent
    had more than 40 users.
  prefs: []
  type: TYPE_NORMAL
- en: The table that we get from the `describe()` method is also useful to help us
    check for problems with the data. It’s common for datasets to contain major errors
    that can be spotted in the output of `describe()`. For example, if you run the
    `describe()` method on a dataset of people and see that their average age is 200,
    your data has errors. This may sound obvious, but that exact error (average ages
    greater than 200) was recently found in a well-known research paper published
    in a top academic journal—if only those researchers had used `describe()`! You
    should look at the output of `describe()` for every dataset you work with to make
    sure that all the values are at least plausible. If you find average ages over
    200, or other data that doesn’t look credible, you’ll have to locate the problems
    in the data and fix them.
  prefs: []
  type: TYPE_NORMAL
- en: 'At this stage, we can already start to use what we’ve learned from the data
    to get ideas for improving the business. For example, we’ve seen that in the first
    24 hours of our data, rider numbers at night are much lower than rider numbers
    during the day. We’ve also seen a wide variation in the hourly count of users:
    25 percent of hours have fewer than 40 riders, but one hour had 886 riders. As
    the CEO, you may want more hours that have closer to 886 riders and fewer hours
    that have fewer than 40 riders.'
  prefs: []
  type: TYPE_NORMAL
- en: You could pursue this goal in many ways. For example, you might lower prices
    during the night to get more customers at that time and therefore have fewer hours
    with low ridership. Just through simple exploration, you can continue to learn
    from the data and get ideas for improving the business.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing Subsets of Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We’ve checked summary statistics related to the full dataset, and then considered
    offering lower prices at night to increase nighttime ridership. If we really want
    to pursue this idea, we should check summary statistics related to just the nighttime.
  prefs: []
  type: TYPE_NORMAL
- en: Nighttime Data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We can start by using the `loc()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'This `loc()` method allows us to specify a subset of our full data. When we
    use `loc()`, we specify the subset we want to select by using square brackets
    with this pattern: `[<``row``>,<``column``>]`. Here, we specify `[3,''count'']`,
    indicating that we want to select row 3 of our data and the `count` column. The
    output we get from this is 13, and if you look at the data in [Figure 1-1](#figure1-1)
    or [Figure 1-2](#figure1-2), you can see that this is correct.'
  prefs: []
  type: TYPE_NORMAL
- en: One important thing to point out here is that the standard practice in Python,
    as well as in pandas, is to use *zero-based indexing*. We count from zero, so
    if our dataset has four rows, we label them row 0, row 1, row 2, and row 3\. The
    fourth row of your data is called row 3, or we say its index is 3\. Similarly,
    the third row of your data has index 2, the second row has index 1, and the first
    row has index 0\. That’s why when we run `print(hour.loc[3,'count'])`, we get
    13, which is the fourth value stored in the data (the value from the row with
    index 3), instead of 32, which is the third value stored in the data (the value
    from the row with index 2). Zero-based indexing doesn’t feel natural to many people,
    but with experience, you can get used to it and feel comfortable with it.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the previous snippet, we looked at a subset that consists of a single number
    (the `count` from a single row and a single column). But you may want to know
    about a subset that consists of multiple rows or multiple columns. By using a
    colon (`:`), we can specify a range of rows we want to look at:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'In this snippet, we specify that we want values of the `registered` variable.
    By specifying `2:4` in the square brackets, we indicate that we want all the rows
    between row 2 and row 4, so we get three numbers as output: 27, 10, and 1\. If
    you look at these rows, you can see that these observations are related to the
    hours 2 AM, 3 AM, and 4 AM. Instead of printing out all the data, we’re printing
    out just three rows. Since we are printing out only a subset, we can call this
    process *subsetting*—selecting subsets of data. This can be useful when exploring
    and analyzing data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead of looking at a few adjacent rows at a time, let’s look at all the
    nighttime observations in our data. We can use logical conditions with the `loc()`
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'This snippet uses `loc()` to access a subset of the data, just as we’ve done
    before. However, instead of specifying particular row numbers, it specifies a
    logical condition: `hour[''hr'']<5`, meaning that it will select every row in
    our data for which the value of the `hr` variable is less than 5\. This will give
    us a subset of the data corresponding to the earliest hours of the morning (midnight
    to 4 AM). We can specify multiple conditions for more complex logic. For example,
    we can check specifically for ridership counts on colder early mornings or warmer
    early mornings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Here, we specify multiple logical conditions, separated by an `&` character
    to mean *and*, which indicates that two things must be true simultaneously. The
    first line selects rows that have an `hr` value less than 5 *and* a `temp` value
    less than 0.50\. In this dataset, the `temp` variable records temperatures, but
    not on a Fahrenheit or Celsius scale that we’re familiar with. Instead, it uses
    a special scale that puts all temperatures between 0 and 1, where 0 represents
    a very cold temperature, and 1 represents a very warm temperature. Whenever you’re
    working with data, it’s important to make sure you know exactly which units are
    used for each variable. We specify `hour['temp']<.50` to select hours with colder
    temperatures and `hour['temp']>.50` to select hours with warmer temperatures.
    Together, these lines allow us to compare average ridership on cold early mornings
    with average ridership on warm early mornings.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also use the `|` symbol to signify *or*. This could be useful in an
    example like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: This line selects the mean readership count for rows with either high temperatures
    *or* high humidity—both aren’t required. Being able to select these complex conditions
    could help you choose ways to improve ridership during hours with uncomfortable
    weather.
  prefs: []
  type: TYPE_NORMAL
- en: Seasonal Data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A nighttime discount is not the only possible strategy for improving ridership
    and revenue. You could also consider specials during certain seasons or at certain
    times of the year. In our data, the `season` variable records 1 for winter, 2
    for spring, 3 for summer, and 4 for fall. We can use the `groupby()` method to
    find the mean number of users during each of these seasons:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Much of this snippet should look familiar. We’re using `print()` to look at
    metrics related to the `hour` data. We use the `mean()` method, indicating that
    we’re looking at averages. And we use `['count']` to access the `count` column
    of the data. So it’s already clear that we’re going to be looking at average ridership
    counts in our `hour` data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The only new part is `groupby([''season''])`. This is a method that splits
    the data into groups—in this case, one group for each unique value that appears
    in the `season` column. The output shows us the mean ridership counts for each
    individual season:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Interpreting this output is straightforward: in the first season (winter),
    average ridership per hour is about 111.115; in the second season (spring), average
    ridership per hour is about 208.344; and so on. A definite seasonal pattern exists:
    higher ridership in the spring and summer seasons, and lower ridership in the
    fall and winter. The `groupby()` method can also group on multiple columns, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we specify two columns to group on: `season` and `holiday`. This splits
    our hourly data into the four individual seasons, and then splits each season
    into holidays (denoted by 1s) and non-holidays (denoted by 0s). It shows us average
    ridership counts on holidays and non-holidays separately for each season. The
    result is that we can see the differences between holidays and non-holidays seasonally.
    It seems like holidays in the colder seasons have ridership that’s lower than
    that on non-holidays, and holidays in the warmer seasons have ridership that’s
    roughly equal to that on non-holidays. Understanding these differences can help
    you make decisions about how to run the business and might give you ideas about
    strategies you can pursue during different seasons or different holidays.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This dataset is big, and there’s no end to the different ways it can be examined.
    We’ve begun to look at a few subsets and started to get a few ideas. You should
    do much more: examine subsets related to all the columns and explore many perspectives
    on the data. Even without doing advanced statistics and machine learning, you
    can learn a great deal and get many useful ideas.'
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing Data with Matplotlib
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Summary statistics are valuable and useful for exploration. However, there’s
    an extremely important part of exploratory data analysis that we haven’t done
    yet: *plotting*, or visualizing the data in organized charts.'
  prefs: []
  type: TYPE_NORMAL
- en: Drawing and Displaying a Simple Plot
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You should plot your data early and often every time you’re doing data analysis.
    We’ll use a popular plotting package called *Matplotlib*. We can draw a simple
    plot of our data as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Here, we import the Matplotlib package, giving it the alias `plt`. Next, we
    create a figure, called `fig`, and an axis, called `ax`. The figure, `fig`, will
    contain all the information about whatever plot or group of plots we draw. The
    axis, `ax`, will give us access to useful methods for actually drawing plots.
    The `subplots()` method creates both of these for us, and inside that method,
    we can specify a figure size (`figsize`). In this case, we specify a figure size
    of `(10,6)`, meaning that our figure will have a width of 10 inches and a height
    of 6 inches.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we draw our plot by using the `scatter()` method. In `scatter()`, we specify
    `x=hour['instant']` so the x-axis will show the `instant` variable in our `hour`
    data. We specify `y=hour['count']` so the y-axis will show the `count` variable.
    Finally, we use `plt.show()` to display this plot onscreen. This snippet creates
    a plot that should look like [Figure 1-3](#figure1-3).
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/502888c01/f01003.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-3: Ridership counts every hour for two years'
  prefs: []
  type: TYPE_NORMAL
- en: In this plot, you can see that every single point is an hour whose information
    is recorded in the dataset. The first hour (the beginning of 2011) is the one
    that appears at the farthest left of the plot. The last hour (the end of 2012)
    is the one that appears at the farthest right, and all other hours proceed in
    order in between.
  prefs: []
  type: TYPE_NORMAL
- en: This plot, known as a *scatterplot*, is a good first plot to draw because it
    shows every observation in the data; it also makes relationships easy to visually
    identify. In this case, we can see a full representation of the seasonal variation
    that our `groupby()` statement previously gave us a hint about. We can also see
    the general growth of ridership over time.
  prefs: []
  type: TYPE_NORMAL
- en: Clarifying Plots with Titles and Labels
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The plot in [Figure 1-3](#figure1-3) shows the data, but it’s not as clearly
    presented as it should be. We can add titles and labels to our plot as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: This snippet uses `xlabel()` to add a label to our x-axis, `ylabel()` to add
    a label to our y-axis, and `title()` to add a title to the plot. You can specify
    any text in these methods to get any labels you like. The output should look like
    [Figure 1-4](#figure1-4).
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/502888c01/f01004.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-4: Ridership counts by hour, with axis labels and a title'
  prefs: []
  type: TYPE_NORMAL
- en: Our dataset is very large, and looking at all the data at once is hard. Let’s
    look at how to plot smaller subsets of our data.
  prefs: []
  type: TYPE_NORMAL
- en: Plotting Subsets of Data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We can use the subsetting we did previously to plot only a subset of the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Here, we define a new variable called `hour_first48`. This variable contains
    data related to row 0 through row 48 of the original data, corresponding roughly
    to the first two full days in the data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Notice that we select this subset by writing `hour.loc[0:48,:]`. This is the
    same `loc()` method that we’ve used before. We use `0:48` to specify that we want
    the rows with indexes up to 48, but we don’t specify any columns—we just write
    a colon (`:`) where we would normally specify column names to select. This is
    a useful shortcut: a colon alone placed there tells pandas that we want to select
    every column of the dataset, so we don’t need to write out each column name individually.
    The plot of this subset looks like [Figure 1-5](#figure1-5).'
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/502888c01/f01005.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-5: Ridership counts by hour for the first two days'
  prefs: []
  type: TYPE_NORMAL
- en: 'By plotting only two days instead of two years of data, we avoid the problem
    of points overlapping and hiding one another. We can see every observation much
    more clearly. When you have a big dataset, it’s a good idea to do both: plot the
    entire dataset at once (to understand the general, overall patterns) as well as
    plot smaller subsets of the data (to understand individual observations and smaller-scale
    patterns). In this case, we can see patterns within each day of the data in addition
    to the longer-term seasonal patterns within its years.'
  prefs: []
  type: TYPE_NORMAL
- en: Testing Different Plot Types
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We have many ways to change the appearance of a plot. Our `scatter()` function
    contains parameters that we can adjust to get different looks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Here, we use the `c` argument to specify a color for our plot points (red).
    We also specify a `marker` argument to change the *marker style*, or the shape
    of the points that are drawn. By specifying `+` for our marker argument, we get
    plot points that look like little pluses instead of little dots. [Figure 1-6](#figure1-6)
    shows the output.
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/502888c01/f01006.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-6: Ridership counts, with different style choices'
  prefs: []
  type: TYPE_NORMAL
- en: This book isn’t printed in color, so you will not see the specified red color
    displayed on this page. But you should see red points if you run this code at
    home.
  prefs: []
  type: TYPE_NORMAL
- en: 'Scatterplots are not the only type of plot we can draw. Let’s try a line plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: In this case, we use `ax.plot()` instead of `ax.scatter()` to draw the plot.
    The `ax.plot()` method allows us to draw a line plot. Here, we call `ax.plot()`
    twice to draw two lines on a single plot. This enables us to compare casual and
    registered users ([Figure 1-7](#figure1-7)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/502888c01/f01007.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-7: A line plot showing casual and registered riders over the first
    two days'
  prefs: []
  type: TYPE_NORMAL
- en: This plot shows that the number of casual riders is almost always lower than
    the number of registered riders. The plot’s legend indicates different colors
    for casual and registered users as well as the different line styles (solid for
    casual riders, dashed for registered riders). Run this code at home to see the
    colors and their contrast more clearly.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also try a different kind of plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'This time, we import a package called *seaborn*. This package is based on Matplotlib,
    so it includes all the capabilities of Matplotlib, plus more features that help
    create beautiful, informative plots quickly. We use seaborn’s `boxplot()` method
    to create a new kind of plot: a *box plot*. [Figure 1-8](#figure1-8) shows the
    box plots that this snippet creates.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/502888c01/f01008.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-8: Box plots showing ridership counts grouped by the hour of the day'
  prefs: []
  type: TYPE_NORMAL
- en: You can see 24 vertical box plots, drawn parallel to one another—each one representing
    information about a particular hour of the day. A box plot is a simple kind of
    plot, but one that gives a great deal of information. In a box plot, the upper
    and lower horizontal boundaries of each rectangle represent the 75th and 25th
    percentiles of the plotted data, respectively. The horizontal line inside the
    rectangle represents the median (or 50th percentile). The vertical lines extending
    from the top and bottom of each rectangle represent the full range of all observations
    that are not considered outliers. The individually drawn points beyond the ranges
    of the vertical lines are regarded as outliers.
  prefs: []
  type: TYPE_NORMAL
- en: Seeing the box plots together in [Figure 1-8](#figure1-8) enables you to compare
    ridership at different times of day. For example, the median ridership during
    hour 5 (around 5 AM) is quite low, but the median ridership at hour 6 (around
    6 AM) is much higher. At hour 7 (around 7 AM), the median ridership is higher
    still. High ridership occurs again around 5 PM and 6 PM; maybe these peaks indicate
    that many of your customers use your bikes to commute to and from work.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you might expect, we can draw many more types of plots. Another useful one
    is a *histogram*, which you can create as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: This snippet uses the `hist()` command to draw a histogram. [Figure 1-9](#figure1-9)
    shows the output.
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/502888c01/f01009.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-9: A histogram showing the frequency of each ridership count'
  prefs: []
  type: TYPE_NORMAL
- en: 'In a histogram, the height of every bar represents frequency. In this case,
    our histogram shows the frequencies of every ridership count. For example, if
    you look at the x-axis around 800, you’ll see bars that have a height close to
    0\. This means that very few hours in our dataset had around 800 riders. By contrast,
    at about 200 on the x-axis, you see higher bars, with height closer to 500\. This
    indicates that for close to 500 individual hours in our data, ridership was close
    to 200\. The pattern we see in this histogram is a common one for businesses:
    many hours have few customers, and few hours have many customers.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You could use this kind of histogram to think about the capacity of your company.
    For example, maybe your company has 1,000 bicycles available to rent today. You
    think that it might be good to save money by selling 200 of your bicycles—that
    way, you’ll earn some extra cash and won’t have to worry about maintenance and
    storage of superfluous bikes. This would leave you with 800 bicycles available
    to rent. By looking at the histogram, you can see exactly how much you would expect
    that change to impact your company: since only a small fraction of hours have
    demand higher than 800, this should have a relatively small impact on your capacity.
    You could look at the histogram to decide exactly how many of your bicycles you
    feel comfortable selling.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Another type of plot, a *pair plot*, draws every possible scatterplot for every
    possible pair of variables in your data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Here, we create a `thevariables` variable, which is a list of three variables
    we’ll plot. (We’re plotting only three instead of all variables because of the
    limited space in the book.) We also create `hour_first100`, which is a subset
    of our full data containing only the rows with index 100 or less in the `hour`
    dataset. Again, the seaborn package helps us by providing the `pairplot()` method
    that we can call to create our plot. The result, [Figure 1-10](#figure1-10), is
    a collection of plots, including both scatterplots and histograms.
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/502888c01/f01010.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-10: Pair plots showing relationships among selected variables'
  prefs: []
  type: TYPE_NORMAL
- en: The pair plot shows scatterplots for every possible combination of variables
    in the subset of the data we selected, as well as histograms for the individual
    variables we selected. A lot of data is plotted here, but the scatterplots don’t
    show much apparent relationship among the variables; these relationships appear
    to be essentially random.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes when we draw pair plots, we see more than just randomness. Instead,
    we can see clear relationships among variables. For example, if we had a measurement
    of snowfall in our data, we would see that as temperature goes up, snowfall levels
    go down, and vice versa. This type of clear relationship between variables is
    called *correlation*, and we’ll explore it in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring Correlations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Two variables are *correlated* if a change in one variable tends to occur together
    with a change in the other variable. We say that two variables are positively
    correlated if they change *together*: one variable tends to go up when the other
    goes up, and one variable tends to go down when the other goes down. We can find
    innumerable examples of positive correlations in the world. The number of domestic
    house cats in a city is positively correlated with the amount of cat food purchased
    in that city. If one of these variables is high, the other one also tends to be
    high, and if one of these variables is low, the other one also tends to be low.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also talk about negative correlations: two variables are negatively
    correlated if one tends to go up when the other goes down, or if one tends to
    go down when the other goes up. Negative correlations are also common in the world.
    For example, the average temperature of a city is negatively correlated with the
    average amount of money a typical resident spends on thick winter coats every
    year. In cities where one of these numbers is high, the other tends to be low,
    and in cities where one of these numbers is low, the other tends to be high.'
  prefs: []
  type: TYPE_NORMAL
- en: In the world of data science, it’s extremely important to find and understand
    correlations, both positive and negative ones. Your performance as CEO will improve
    if you can find and understand these correlations. For example, you might find
    that the count of riders is positively correlated with the temperature. If so,
    this means that ridership tends to be low when temperatures are low. You could
    even consider selling some of your bikes during seasons with low ridership to
    generate cash flow instead of letting many of your bikes sit idle. Exactly what
    you choose to do will depend on many other details of your situation, but understanding
    the data on a deep level will help you make the best possible business decisions.
  prefs: []
  type: TYPE_NORMAL
- en: Calculating Correlations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We can calculate correlations in Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Here, we use the `corr()` method, yet another capability provided by pandas.
    The `corr()` method calculates a number called the *correlation coefficient*.
    We can calculate many types of correlation coefficients, but by default, `corr()`
    calculates the Pearson correlation coefficient. This is the most commonly used
    correlation coefficient, so whenever we refer to a correlation coefficient in
    this book, we’ll be referring to the Pearson correlation coefficient.
  prefs: []
  type: TYPE_NORMAL
- en: The Pearson correlation coefficient is a number that’s always between –1 and
    1, and it’s often named with the variable *r*. It’s meant to describe the relationship
    between two variables; its sign describes the type of correlation, and its size
    describes the strength of the correlation. If the correlation coefficient *r*
    is a positive number, our two variables are positively correlated, and if *r*
    is a negative number, they’re negatively correlated. If the correlation coefficient
    is 0, or very close to 0, we say that the variables are *uncorrelated*.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, the first line of this snippet calculates the correlation coefficient
    describing the relationship between the `casual` and `registered` variables in
    our data. For these variables, *r* is about 0.51, a positive number that indicates
    a positive correlation.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Strong vs. Weak Correlations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In addition to noticing whether correlation coefficients are positive, negative,
    or 0, we pay attention to their exact *magnitude*, or size. If a correlation coefficient
    is large (far from 0 and close to either 1 or –1), we often say that the correlation
    is *strong*. Take a look at [Figure 1-11](#figure1-11) to see examples of correlations.
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/502888c01/f01011.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-11: Positively correlated variables'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, you can see two plots. The first plot shows the relationship between
    Fahrenheit and Celsius temperatures. You can see that Fahrenheit and Celsius are
    positively correlated: when one goes up, the other goes up, and vice versa. The
    second plot shows the relationship between casual and registered ridership in
    your company. Again, we see a positive correlation: when casual ridership goes
    up, registered ridership tends to go up as well, and vice versa.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The two correlations in [Figure 1-11](#figure1-11) are both positive, but we
    can see a qualitative difference between them. The relationship between Fahrenheit
    and Celsius is deterministic: knowing the Fahrenheit temperature allows us to
    know the Celsius temperature exactly, with no uncertainty or guesswork. This kind
    of deterministic positive correlation that appears as a straight line on a plot
    is also called a *perfect* correlation, and when we measure a correlation coefficient
    for a perfect positive correlation, we’ll find that *r* = 1.'
  prefs: []
  type: TYPE_NORMAL
- en: By contrast, the relationship between casual and registered ridership is *not*
    deterministic. Often a higher number of casual riders corresponds to a higher
    number of registered riders. But sometimes it doesn’t; we can’t perfectly predict
    one variable by using the other one. When two variables are correlated but don’t
    have a deterministic relationship, we say that the relationship between the two
    variables has “noise,” or randomness.
  prefs: []
  type: TYPE_NORMAL
- en: '*Randomness* is hard to define precisely, but you can think of it as unpredictability.
    When you know a Fahrenheit temperature, you can predict the Celsius temperature
    with perfect accuracy. By contrast, when you know the casual ridership, you can
    predict the registered ridership, but your prediction may not be perfectly accurate.
    When unpredictability like this exists, the two variables will have a correlation
    coefficient that’s less than 1\. In this case, we can calculate the correlation
    of casual and registered ridership and find that *r* = 0.51.'
  prefs: []
  type: TYPE_NORMAL
- en: You can think of the size of the correlation coefficient as a measure of the
    amount of randomness in the relationship between two variables. A larger correlation
    coefficient corresponds to less randomness (closer to a deterministic relationship,
    like the relationship between Fahrenheit and Celsius). A smaller correlation coefficient
    corresponds to more randomness and less predictability. You can think of a 0 correlation
    coefficient, indicating no relationship at all between variables, as an indication
    of pure randomness, or pure noise.
  prefs: []
  type: TYPE_NORMAL
- en: You can look at [Figure 1-12](#figure1-12) to see examples of negative correlations
    of different magnitudes.
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/502888c01/f01012a.png)![](image_fi/502888c01/f01012.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-12: Negatively correlated variables'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we see the same ideas as in [Figure 1-11](#figure1-11). The first plot
    shows a *perfect* negative correlation: this time, the deterministic relationship
    between pressure and volume. The correlation here is exactly *r* = –1, indicating
    that no randomness occurs in the relationship between the variables; each variable
    is perfectly predictable by using the other one.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The second plot shows the relationship between temperature and humidity in
    our data. These two variables also have a negative correlation, but with a much
    smaller coefficient: *r* is about –0.07\. Just as we did with the positive correlations
    in [Figure 1-11](#figure1-11), we can interpret these correlation coefficients
    as measurements of randomness: a correlation coefficient with a larger magnitude
    (meaning that it’s closer to 1 or –1) is a correlation that’s highly predictable
    and not very random, while a coefficient with a smaller magnitude (closer to 0)
    is a correlation that has more randomness. When we see *r* = –0.07 here, we interpret
    that to mean that temperature and humidity are negatively correlated, but their
    correlation is very weak—it’s not far from pure randomness.'
  prefs: []
  type: TYPE_NORMAL
- en: 'One important thing to remember when you look at correlations is a famous saying:
    “Correlation does not imply causation.” When we observe strong correlations, all
    we can be certain of is that two variables tend to change together; we can’t be
    certain that one causes the other.'
  prefs: []
  type: TYPE_NORMAL
- en: For example, suppose we study Silicon Valley startups and find that their monthly
    revenues are correlated with the number of Ping-Pong tables they purchase. We
    may hastily conclude from this correlation that Ping-Pong tables are causing revenue
    to increase; maybe the relaxation and camaraderie that they facilitate leads to
    higher productivity, or maybe the fun atmosphere they create leads to better retention
    and hiring success.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, these ideas may be completely mistaken, and maybe the causation
    flows in the opposite direction; companies that have success (totally independent
    of their Ping-Pong tables) have higher revenues, and since their budget has suddenly
    increased, they use some of their new extra money for a fun purchase like a Ping-Pong
    table. In that case, revenue would be causing Ping-Pong table purchases, not the
    other way around.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the correlation could be mere coincidence. Maybe Ping-Pong tables don’t
    lead to higher revenues, and revenues don’t lead to more Ping-Pong tables, but
    instead we’ve observed a *spurious correlation:* a correlation that occurs only
    by coincidence and does not indicate any causation or special relationship. A
    correlation could also be due to an *omitted variable*, something we haven’t observed
    but is independently causing revenue increases and Ping-Pong table purchases simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: In any case, the important thing is to always be cautious when you find and
    interpret correlations. Correlations mean that two variables tend to change together,
    and they can help us make predictions, but they don’t necessarily imply that one
    variable causes the other, or even that they have any real relationship.
  prefs: []
  type: TYPE_NORMAL
- en: Discovering and understanding correlation coefficients can help you in your
    CEO duties, especially when you find surprising correlations. For example, you
    may find a strong, positive correlation between the size of groups that rent bicycles
    together and their level of customer satisfaction after the rental. Maybe this
    can give you some ideas about encouraging people to rent bikes with their friends
    as a chance to get more satisfied customers. Finding correlations, and understanding
    the magnitude of correlations and what that tells you about predictability, can
    be valuable in business.
  prefs: []
  type: TYPE_NORMAL
- en: Finding Correlations Between Variables
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We can do more than calculate individual correlations between pairs of variables.
    We can go further by creating a *correlation matrix*, which is a matrix (or rectangular
    array) of numbers, each of whose elements is the correlation coefficient measuring
    the relationship between two particular variables. A correlation matrix will show
    the relationships among all of our variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we use the same `corr()` method that we’ve used before. When we use `corr()`
    without any arguments inside the parentheses, it creates a correlation matrix
    for all the variables in a dataset. In this case, we create a smaller correlation
    matrix that shows correlations among just three selected variables. The correlation
    matrix that we calculate here looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Here, we have a 3×3 matrix. Every entry in this matrix is a correlation coefficient.
    For example, in the second row, third column, you can see that the correlation
    between `windspeed` and `temp` is about *r* = –0.023\. Technically, this is a
    negative correlation, though it’s so close to 0 that we would typically describe
    the two variables as uncorrelated.
  prefs: []
  type: TYPE_NORMAL
- en: 'You also can see that three correlations in the matrix are equal to 1.0\. That’s
    expected: these perfect correlations are measuring the correlation of each variable
    with itself (the correlation of `hr` with `hr`, `temp` with `temp`, and `windspeed`
    with `windspeed`). Every variable will always have a perfect correlation with
    itself. Creating a correlation matrix can be a quick, simple way to find correlations
    among all the variables in your data and find any surprising positive or negative
    correlations.'
  prefs: []
  type: TYPE_NORMAL
- en: Creating Heat Maps
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'After creating a correlation matrix, we can create a plot of all these correlations
    to make the matrix more easily readable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Here, we create a heat map. In this type of plot, the color or darkness of a
    cell indicates the value of the number in that cell. The heat map in [Figure 1-13](#figure1-13)
    shows measurements of correlations between variables.
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/502888c01/f01013.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-13: Correlations shown in a heat map'
  prefs: []
  type: TYPE_NORMAL
- en: This heat map shows a collection of nine rectangles. As the legend on the right
    indicates, a darker fill in a rectangle indicates that a particular correlation
    is higher, and a lighter fill indicates that a particular correlation is lower.
    A heat map of a correlation matrix can provide an even quicker way to check for
    patterns and relationships among variables, since strong relationships will quickly
    catch the eye.
  prefs: []
  type: TYPE_NORMAL
- en: If you prefer a color plot instead of a grayscale one, you can change the `cmap='binary'`
    parameter in the `sns.heatmap()` method. This `cmap` parameter refers to the *color
    map* of the heat map, and by choosing a different `cmap` value, you can get different
    color schemes. For example, if you use `cmap='coolwarm'`, you’ll see a heat map
    in which higher values are represented by reddish colors and lower values are
    represented by bluish colors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Heat maps can be drawn for variables other than correlation matrices. For example,
    we can draw a heat map showing the number of riders at each hour throughout a
    week:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: To create this plot, we have to create a pivot table, a table of grouped values.
    If you’ve spent a lot of time working with Excel or other spreadsheet programs,
    you’ve likely encountered pivot tables before. Here, our pivot table has grouped
    values from our full dataset based on their day of the week and hour of the day.
    We have the average ridership for each hour (0 through 23) of each day (Sunday
    through Saturday). After creating a pivot table with data grouped in this way,
    we can use the same `heatmap()` method to create the heat map shown in [Figure
    1-14](#figure1-14).
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/502888c01/f01014.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-14: Ridership counts for each hour of every day'
  prefs: []
  type: TYPE_NORMAL
- en: This heat map contains darker rectangles for hours that had more riders and
    lighter rectangles for hours that had fewer riders. We can see commuters who spike
    in activity around 8 AM and 5 PM. We can also see weekend outings on Saturday
    and Sunday afternoons.
  prefs: []
  type: TYPE_NORMAL
- en: 'From a business perspective, this heat map could give us any number of business
    ideas. For instance, seeing the spike in ridership around 8 AM on weekdays could
    give you an idea for increasing your revenue. Just as we imagined providing discounts
    during times of low activity, we might also consider the mirror image strategy:
    surge pricing (temporarily higher prices) during especially active times. Other
    transportation companies like Uber, Lyft, and Grab use this surge pricing strategy,
    not only to increase revenue but also to ensure high availability of their products.'
  prefs: []
  type: TYPE_NORMAL
- en: Exploring Further
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far, we’ve looked at only one dataset, and we’ve done only a few of the infinite
    explorations that are possible with it. As you continue from your first morning
    as CEO to your first afternoon, then your second day, and further on, you will
    need to make many decisions about your business and the way it operates. The exploration
    that we’ve done in this chapter can be applied to any other business question
    you ever encounter. For example, you might consider bundling bike rentals with
    refreshing drinks and earning extra revenue that way (not to mention keeping your
    riders healthier and safer). Analyzing data related to your customers, their riding
    patterns, and how thirsty they get during bike rides could help you figure out
    whether this strategy is a good idea.
  prefs: []
  type: TYPE_NORMAL
- en: Other analyses could be related to the repairs your bikes need. How often are
    your bikes being repaired, and how much do repairs cost? You could check for the
    times of repairs and make sure they’re not being done during peak hours. You could
    check the costs of repairs of various types of bikes. You could check a histogram
    of the prices of repairs and check whether any outliers are increasing your costs
    too much. These explorations would help you better understand your business and
    help you get ideas for running it better.
  prefs: []
  type: TYPE_NORMAL
- en: So far, our analyses have not been extremely sophisticated; mostly we’ve calculated
    only summary statistics and drawn plots. But these simple calculations and plots,
    when combined with common sense, can be valuable as a first step in making business
    decisions. Some CEOs don’t look at data enough, and others want to look at data
    but depend on staff to provide reports to them, and those reports may be slow
    or imperfect. A CEO who can confidently check data related to their company is
    a CEO who can be effective. CEOs can become good at data, and this can combine
    with their business knowledge to make them even better at their jobs. Similarly,
    data scientists can become good at business, and when their data skills are combined
    with business acumen, they can really become a force to be reckoned with.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this chapter, we started with a simple business scenario: becoming a CEO
    and making decisions related to running a business better. We went over some ideas
    for what a CEO needs to do and how exploratory data analysis can be helpful. We
    covered how to read data into Python, calculate summary statistics, draw plots,
    and interpret results in a business context. In the next chapter, we’ll go over
    linear regression, a more sophisticated method that can be used not only for exploration
    but also for forecasting. Let’s continue!'
  prefs: []
  type: TYPE_NORMAL

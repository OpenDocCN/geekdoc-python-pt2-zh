- en: '**2'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: PROBABILITY**
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/common.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Probability affects every aspect of our lives, but in reality, we’re all pretty
    bad at it, as some of the examples in this chapter demonstrate. We need to study
    probability to get it right. And we need to get it right because deep learning
    deals extensively with ideas from probability theory. Probability appears everywhere,
    from the outputs of neural networks to how often different classes appear in the
    wild to the distributions used to initialize deep networks.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter aims to expose you to the sorts of probability-related ideas and
    terms you’ll frequently encounter in deep learning. We’ll start with basic ideas
    about probability and introduce the notion of a random variable. We’ll then jump
    to the rules of probability. These sections cover the basics that will put us
    in a position to talk about *joint and marginal probabilities*. You’ll encounter
    those terms over and over again as you explore deep learning. Once you understand
    how to use joint and marginal probabilities, I’ll explain the first of the two
    chain rules discussed in this book. The second is in [Chapter 6](ch06.xhtml#ch06)
    on differential calculus. We’ll continue our study of probability in [Chapter
    3](ch03.xhtml#ch03).
  prefs: []
  type: TYPE_NORMAL
- en: Basic Concepts
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A *probability* is a number between zero and one that measures how likely something
    is to happen. If there’s no chance the something will happen, its probability
    is zero. If it’s absolutely certain that it will happen, its probability is one.
    We’ll usually express probabilities this way, though in everyday use, people seem
    to dislike saying things like, “The chance of rain tomorrow is 0.25.” Instead,
    we say, “The chance of rain tomorrow is 25 percent.” In everyday speech, we convert
    the fractional probability to a percentage. We’ll do the same in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'The previous paragraph used multiple words associated with probability: *likely*,
    *chance*, and *certainty*. This is fine in casual use, and even somewhat in deep
    learning, but when we need to be explicit, we’ll stick with *probability* and
    express it numerically in the range zero to one, [0, 1]. The square brackets mean
    the upper and lower limit are included. If the limit isn’t included in the range,
    a normal parenthesis is used. For example, the NumPy function `np.random.random()`
    returns a pseudorandom floating-point number in the range [0, 1). So, it might
    return exactly zero, but it will never return exactly one.'
  prefs: []
  type: TYPE_NORMAL
- en: Next, I’ll introduce the foundational concepts of sample space, events, and
    random variables. I’ll close with some examples of how humans are bad at probability.
  prefs: []
  type: TYPE_NORMAL
- en: Sample Space and Events
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Put succinctly, a *sample space* is a discrete set or continuous range that
    represents all the possible outcomes of an event. An *event* is something that
    happens. Usually, it’s the outcome of some physical process, like the flipping
    of a coin or the roll of a die. All the possible events we’ve grouped together
    are the sample space we’re working with. Each event is a *sample* from the sample
    space, and the sample space represents *all* the possible events. Let’s look at
    a few examples.
  prefs: []
  type: TYPE_NORMAL
- en: The possible outcomes of a coin flip are heads (H) or tails (T); thus, the sample
    space for a coin flip is the set {H, T}. The sample space for the roll of a standard
    die is the set {1, 2, 3, 4, 5, 6} because, discounting the die perching itself
    on its edge, one of the six faces of the cube will be on top when the die stops
    moving. These are examples of discrete sample spaces. In deep learning, most sample
    spaces are continuous and they consist of floating-point numbers, not integers
    or elements of a set. For example, if a feature input to a neural network can
    take on any value in the range [0, 1], then [0, 1] is the sample space for that
    feature.
  prefs: []
  type: TYPE_NORMAL
- en: We can ask about the likelihood of certain events happening. For a coin, we
    can ask, what’s the likelihood the coin will land heads up when flipped? Intuitively,
    assuming the coin isn’t weighted so that one side is more likely to show up than
    the other, we say the likelihood of heads is 50 percent. The probability of getting
    heads is then 0.5 (50 percent as a percentage). We see that the probability of
    getting tails is also 0.5\. Finally, since heads and tails are the only possible
    outcomes, we see that the sum of the probabilities over all possible results is
    0.5 + 0.5 = 1.0\. Probabilities *always* sum to 1.0 over all possible values of
    the sample space.
  prefs: []
  type: TYPE_NORMAL
- en: What’s the probability of rolling a four with a six-sided die? Again, there
    is no reason to favor one face over another, and only one of the six faces has
    four dots, so the probability is one out of six, 1/6 ≈ 0.166666 . . . or about
    17 percent.
  prefs: []
  type: TYPE_NORMAL
- en: Random Variables
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Let’s denote the outcome of a coin flip by a variable, *X*. *X* is what’s called
    a *random variable*, a variable that takes on values from its sample space with
    a certain probability. Because here the sample space is discrete, *X* is a *discrete
    random variable*, which we denote with an uppercase letter. For the coin, the
    probability of *X* being heads equals the probability of *X* being tails, both
    0.5\. To write this formally, we use
  prefs: []
  type: TYPE_NORMAL
- en: '*P*(*X* = heads) = *P*(*X* = tails) = 0.5'
  prefs: []
  type: TYPE_NORMAL
- en: 'where *P* is universally used to indicate the probability of the event in parentheses
    for the specified random variable. A *continuous random variable* is a random
    variable from a continuous sample space, denoted with a lowercase letter, like
    *x*. We usually talk about the probability of the random variable being in some
    range of the sample space, not a particular real number. For example, if we use
    the NumPy `random` function to return a value in [0, 1), we can ask: What’s the
    probability that it will return a value in the range [0, 0.25)? Since any number
    is as likely to be returned as any other, we say that the probability of being
    in that range is 0.25 or 25 percent.'
  prefs: []
  type: TYPE_NORMAL
- en: Humans Are Bad at Probability
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We’ll dive into the math of probability in the next section. But before then,
    let’s look at two examples involving probability that show how bad humans can
    be at it. Both of these examples have stumped experts, not because the experts
    are somehow lacking, but because our intuitions about probability are often entirely
    incorrect, and even experts are thoroughly human.
  prefs: []
  type: TYPE_NORMAL
- en: The Monty Hall Dilemma
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This problem is a particular favorite of mine, as it confuses even mathematicians
    with advanced degrees. The dilemma is taken from an old American game show called
    *Let’s Make a Deal*. The original host of the show, Monty Hall, would select a
    member of the audience and show that person three large closed doors labeled 1,
    2, and 3\. Behind one of the doors was a new car. Behind the remaining two doors
    were joke prizes, such as a live goat.
  prefs: []
  type: TYPE_NORMAL
- en: 'The contestant was asked to pick a door. Then, Hall would ask that one of the
    doors the contestant *didn’t* pick be opened, naturally one that didn’t have a
    car behind it. After the audience stopped laughing at whatever joke prize was
    behind that door, Hall would ask the contestant if they wanted to keep the originally
    selected door, or if they would rather change their selection to the remaining
    door. The dilemma is simply that: do they keep their original guess, or do they
    switch to the remaining door?'
  prefs: []
  type: TYPE_NORMAL
- en: If you want to think about it for a while, please do. Put the book down, walk
    around, get out a pencil and some paper, make notes, then, when you have a solution
    (or give up), read on. . . .
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the right answer: change doors. If you do, you’ll win the car 2/3 of
    the time. If you don’t, you’ll only win the car 1/3 of the time, as that’s the
    probability of selecting the correct door initially: one correct choice out of
    three.'
  prefs: []
  type: TYPE_NORMAL
- en: When Marilyn vos Savant presented this problem in her *Parade* magazine column
    in 1990 and stated that the correct solution is to change doors, she was flooded
    with letters, many from mathematicians, some angry, insisting she was wrong. She
    wasn’t. One way to see that she was right is to use a computer program to simulate
    the game. We won’t develop the code for one here, but it isn’t too hard. If you
    write one and run it, you’ll see the probability of winning when changing doors
    converges on 2/3 as the number of simulated games increases. However, we can also
    use common sense and basic ideas about probability to see the solution.
  prefs: []
  type: TYPE_NORMAL
- en: First, if we don’t change doors, we know we have a 1/3 probability of winning
    the car. Now, consider what can happen when we change doors. If we change doors,
    the only way we can *lose* is if we happened to select the correct door in the
    first place. Why? Suppose we initially chose one of the joke prize doors instead.
    Hall, who knows full well which door the car is behind, will never open the door
    with the car. Since we selected one of the joke doors already, he’s forced to
    choose the remaining joke door and open it for us, thereby ensuring the car is
    behind the only remaining door. If we switch doors, we win. Since there are two
    doors without the car, our chance of selecting the wrong door initially is 2/3\.
    However, we just saw that if we choose the wrong door initially and switch when
    given the opportunity, we’ll win the car. Therefore, we have a 2/3 chance of winning
    the car by changing our guess. The 1/3 probability of losing by changing our initial
    guess is, of course, the case where we initially selected the correct door.
  prefs: []
  type: TYPE_NORMAL
- en: Cancer or Not?
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This example is found in several popular books about probability and statistics
    (for instance, *More Damned Lies and Statistics*, by Joel Best [UC Press, 2004],
    and *The Drunkard’s Walk*, by Leonard Mlodinow [Pantheon, 2008]). It’s based on
    an actual study. The task is to determine the probability that a woman in her
    40s has breast cancer if she has a positive mammogram. Note that the numbers that
    follow might have been accurate when the study was conducted, but they may not
    be valid now. Please consider them only as an example.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are told the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The probability that a randomly selected woman in her 40s has breast cancer
    is 0.8 percent (8 out of 1,000).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The probability that a woman with breast cancer will have a positive mammogram
    is 90 percent.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The probability that a woman *without* breast cancer will have a positive mammogram
    is 7 percent.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A woman comes to the clinic and is screened. The mammogram is positive. What’s
    the probability, based on what we’ve been told, that she actually has breast cancer?
  prefs: []
  type: TYPE_NORMAL
- en: 'From #1 above, we know that if we select 1,000 women in their 40s at random,
    8 of them will have breast cancer (on average). Therefore, of those 8, 90 percent
    of them (#2 above) will have a positive mammogram. This means 7 women with cancer
    will have a positive mammogram because 8 × 0.9 = 7.2\. This leaves 992 of the
    original 1,000 who don’t have breast cancer. From #3 above, 992 × 0.07 = 69.4,
    so 69 women without breast cancer will also have a positive mammogram, giving
    a total of 7 + 69 = 76 positive mammograms, of which 7 are actual cancer and 69
    are false-positive results. Therefore, the probability that a positive mammogram
    indicates cancer is 7 out of 76 or 7/76 = 0.092—about 9 percent.'
  prefs: []
  type: TYPE_NORMAL
- en: The median estimate that doctors presented with this problem gave was a probability
    of cancer of around 70 percent, with over one-third giving an estimate of 90 percent.
    Probabilities are hard for humans, even for those with a lot of training. The
    doctors’ mistake wasn’t properly accounting for the probability of a randomly
    selected woman in her 40s having breast cancer. We’ll see in [Chapter 3](ch03.xhtml#ch03)
    how to calculate this result using Bayes’ theorem, which does take this probability
    into account.
  prefs: []
  type: TYPE_NORMAL
- en: For now, let’s switch from intuition to mathematical formality.
  prefs: []
  type: TYPE_NORMAL
- en: The Rules of Probability
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s get started with the basic rules of probability. These are foundational
    rules that we’ll need for the remainder of the chapter and beyond. We’ll learn
    about the probability of events, the sum rule for probabilities, and what we mean
    by a conditional probability. After that, the product rule will let us tackle
    the birthday paradox. In the birthday paradox, we’ll see how to calculate the
    minimum number of people to have together in a room such that the probability
    of at least two of them sharing a birthday exceeds 50 percent. The answer is fewer
    than you might think.
  prefs: []
  type: TYPE_NORMAL
- en: Probability of an Event
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We mentioned earlier that the sum of all the probabilities for a sample space
    is one. This means that the chance of any event from the sample space is always
    less than or equal to one, since the event came from the sample space, and the
    sample space encompasses all possible events. This implies, for any event *A*,
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/02equ01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: and, for all events *A[i]* in the sample space,
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/02equ02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: where ∑ (sigma) means to sum over the expression on the right for each of the
    *i*’s. Think of a `for` loop in Python with the expression on the right as the
    body of the loop.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we roll a six-sided die, we intuitively (and correctly) understand that
    the probability of getting any value is the same: one out of six possibilities,
    or 1/6\. Therefore, [Equation 2.1](ch02.xhtml#ch02equ01) tells us that *P*(1),
    the probability of rolling a one, is between zero and one. This is true since
    ![image](Images/022equ01.jpg). Furthermore, [Equation 2.2](ch02.xhtml#ch02equ02)
    tells us that the sum of the probabilities of all events in the sample space must
    be one. This is also true for the six-sided die, since ![image](Images/022equ02.jpg)
    and ![image](Images/022equ03.jpg).'
  prefs: []
  type: TYPE_NORMAL
- en: If the probability of an event happening is *P(A)*, then the probability that
    event *A does not* happen is
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/02equ03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: with ![image](Images/022equ04.jpg) read as “not *A*.” ![image](Images/022equ04.jpg)
    is known as the *complement* of *A*. You’ll sometimes see ![image](Images/022equ04.jpg)
    written as *P*(¬*A*) using ¬, the logical symbol for “not.”
  prefs: []
  type: TYPE_NORMAL
- en: '[Equation 2.3](ch02.xhtml#ch02equ03) comes from [Equation 2.1](ch02.xhtml#ch02equ01)
    and [Equation 2.2](ch02.xhtml#ch02equ02) because the probability of an event is
    less than one and the probability of any event from the sample space happening
    is one, so the probability of events that aren’t *A* happening must be one minus
    the probability of event *A* happening.'
  prefs: []
  type: TYPE_NORMAL
- en: For example, when rolling a die, the probability of getting a value in [1, 6]
    is one, but the probability of getting a four is 1/6\. So, the chance of *not*
    rolling a four is all the probability that remains when the chance of rolling
    a four is removed,
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/022equ05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: meaning we have an 83 percent chance of not rolling a four.
  prefs: []
  type: TYPE_NORMAL
- en: What if we roll two dice and sum them? The sample space is the set of integers
    from 2 through 12\. However, each sum is not equally likely in this case, a situation
    that’s at the core of the casino game craps, for example. We calculate the probabilities
    of each sum by enumerating all the ways they can happen. By counting the ways
    events can happen and dividing by the total number of events, we can determine
    the probability. [Table 2-1](ch02.xhtml#ch02tab01) shows all the possible ways
    to generate each sum.
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 2-1:** The Number of Combinations of Two Dice Leading to Different
    Sums'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Sum** | **Combinations** | **Count** | **Probability** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 1 + 1 | 1 | 0.0278 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 1 + 2, 2 + 1 | 2 | 0.0556 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 1 + 3, 2 + 2, 3 + 1 | 3 | 0.0833 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 1 + 4, 2 + 3, 3 + 2, 4 + 1 | 4 | 0.1111 |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | 1 + 5, 2 + 4, 3 + 3, 4 + 2, 5 + 1 | 5 | 0.1389 |'
  prefs: []
  type: TYPE_TB
- en: '| 7 | 1 + 6, 2 + 5, 3 + 4, 4 + 3, 5 + 2, 6 + 1 | 6 | 0.1667 |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | 2 + 6, 3 + 5, 4 + 4, 5 + 3, 6 + 2 | 5 | 0.1389 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | 3 + 6, 4 + 5, 5 + 4, 6 + 3 | 4 | 0.1111 |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | 4 + 6, 5 + 5, 6 + 4 | 3 | 0.0833 |'
  prefs: []
  type: TYPE_TB
- en: '| 11 | 5 + 6, 6 + 5 | 2 | 0.0556 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | 6 + 6 | 1 | 0.0278 |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | 36 | 1.0000 |'
  prefs: []
  type: TYPE_TB
- en: 'In [Table 2-1](ch02.xhtml#ch02tab01), there are 36 possible combinations of
    the two dice. We see that the most likely sum is 7, since six combinations add
    to 7\. The least likely are 2 and 12; there’s only one way to get either. If there
    are six ways to get a sum of 7, then the probability of a 7 is “6 out of 36,”
    or 6/36 ≈ 0.1667\. We’ll return to [Table 2-1](ch02.xhtml#ch02tab01) later in
    the next chapter when we discuss probability distributions and Bayes’ theorem.
    [Table 2-1](ch02.xhtml#ch02tab01) illustrates a general rule: if we can enumerate
    the sample space, then we can calculate the probabilities of specific events.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As a final example, if you flip three coins simultaneously, what is the probability
    of getting no heads, one head, two heads, or three heads? We can enumerate the
    possible outcomes and see. We get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Heads** | **Combinations** | **Count** | **Probability** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | TTT | 1 | 0.125 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | HTT, THT, TTH | 3 | 0.375 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | HHT, HTH, THH | 3 | 0.375 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | HHH | 1 | 0.125 |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | 8 | 1.000 |'
  prefs: []
  type: TYPE_TB
- en: 'From this table, we claim that the probability of getting one or two heads
    in three coin flips is the same: 37.5 percent. Let’s test this with a bit of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The code runs 1,000,000 tests (`N`) simulating the flip of three coins (`M`).
    The number of times each test ends up with 0, 1, 2, or 3 heads is stored in `heads`.
    Each test selects three values in [0, 1] (`flips`) and counts how many heads (a
    zero) show up. We use `np.bincount` for this and throw away the number of tails.
    The number of heads is then tallied, and the next set of flips happens.
  prefs: []
  type: TYPE_NORMAL
- en: 'When all `N` simulations are complete, we convert the number of heads to probabilities
    by dividing by the number of simulations run (`prob`). Finally, we print the corresponding
    probabilities. For zero, one, two, or three heads, a single run returned the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: These are quite close to the probabilities we calculated above, so we have confidence
    that we’re correct.
  prefs: []
  type: TYPE_NORMAL
- en: Sum Rule
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We’ll start with a definition: two events *A* and *B* are said to be *mutually
    exclusive* if they can’t both happen; either one or the other happens. For example,
    a coin flip is either heads or tails; it can’t be heads *and* tails. Mutually
    exclusive events mean if event *A* happens, event *B* is excluded, and vice versa.
    Additionally, if the probabilities of two events happening are completely unrelated,
    meaning the probability of *A* is unaffected by whether *B* has happened, we say
    the two events are *independent*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The sum rule is concerned with the probability of more than one mutually exclusive
    event happening. It tells us the probability of either event happening. For example,
    what’s the probability of rolling a four or a five with a standard die? We know
    the probability of rolling a four is 1/6, as is the probability of rolling a five.
    Since the events are mutually exclusive, we can intuit that the probability of
    getting a four *or* a five is their sum, since four and five as outcomes are both
    parts of the sample space, and either one or the other happens or neither happens.
    So, we get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/02equ04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here ∪ means “or” or “union.” You’ll see ∪ often. For a standard die, the probability
    of rolling a four or a five is ![image](Images/024equ01.jpg), or about 33 percent.
  prefs: []
  type: TYPE_NORMAL
- en: 'The sample space of two coin flips is {HH, HT, TH, TT}; therefore, this is
    the probability of getting two heads or two tails:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/024equ02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: There’s more to the sum rule, but before we can see it, we need to consider
    the product rule.
  prefs: []
  type: TYPE_NORMAL
- en: Product Rule
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The sum rule tells us about the probability of events *A* or *B* happening.
    The product rule tells us the probability of events *A and B*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/02equ05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here ∩ means “and” or “intersection.”
  prefs: []
  type: TYPE_NORMAL
- en: If events *A* and *B* are mutually exclusive, we will immediately see that *P*(*A*
    ∩ *B*) = 0 because if event *A* happens with probability *P*(*A*), then event
    *B*’s probability is *P*(*B*) = 0, and their product is also zero. The same is
    true if event *B* happens; then *P*(*A*) = 0.
  prefs: []
  type: TYPE_NORMAL
- en: Not all events are mutually exclusive, of course. For example, assume 80 percent
    of the people in the world have brown eyes and 50 percent are female. What’s the
    probability of a randomly selected person being a female with brown eyes? Let’s
    use the product rule,
  prefs: []
  type: TYPE_NORMAL
- en: '*P*(female, brown-eyed) = *P*(female)*P*(brown-eyed) = 0.5(0.8) = 0.4'
  prefs: []
  type: TYPE_NORMAL
- en: to see there is a 40 percent chance of a randomly selected person being a brown-eyed
    female.
  prefs: []
  type: TYPE_NORMAL
- en: The product rule makes sense if we think about it a bit. Calculating the fraction
    of people, which is the probability, who are female won’t change the fraction
    of those females who are brown-eyed. One event, being female, has no impact on
    the other event, being brown-eyed.
  prefs: []
  type: TYPE_NORMAL
- en: 'The product rule isn’t limited to only two events. Consider the following.
    According to insurance companies, the probability of being struck by lightning
    in any given year, if you live in the US, is about 1/1,222,000, or 0.000082 percent.
    What’s the probability of being a brown-eyed female and being struck by lightning
    in any given year, assuming you live in the US? Again, we can use the product
    rule:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/025equ01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The population of the United States is about 331,000,000, of which 0.000033
    percent are brown-eyed females who’ll be struck by lightning this year: 109 people,
    by our calculation above. According to the US National Weather Service, about
    270 people will be struck by lightning in a given year. As we saw above, 40 percent
    of those people will be brown-eyed females, which yields 270(0.4) = 108\. So,
    our calculation is entirely believable.'
  prefs: []
  type: TYPE_NORMAL
- en: Sum Rule Revisited
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We stated above that there’s more to the sum rule. Let’s see now what we were
    missing above. [Equation 2.4](ch02.xhtml#ch02equ04) gives us the sum rule for
    mutually exclusive events *A* and *B*. What if the events aren’t mutually exclusive?
    In that case, the sum rule needs to be modified:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/02equ06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Let’s look at an example.
  prefs: []
  type: TYPE_NORMAL
- en: An archaeologist has discovered a small cache of 20 ancient coins. He notes
    that 12 of the coins are Roman and 8 are Greek. He also notes that 6 of the Roman
    coins and 3 of the Greek coins are silver. The remaining coins are bronze. What’s
    the probability of selecting a silver or Roman coin from the cache?
  prefs: []
  type: TYPE_NORMAL
- en: 'If we believe that silver and Roman are mutually exclusive, we’d be tempted
    to say the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/026equ01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: However, the sum of the two probabilities is ![image](Images/026equ02.jpg),
    and we *can’t* have a probability greater than one. Something is amiss.
  prefs: []
  type: TYPE_NORMAL
- en: 'The problem is that there are Roman coins in the cache that are made of silver.
    We counted them twice—once in *P* (silver) and again in *P*(Roman)—so now we need
    to subtract them from the overall sum. There are six silver Roman coins. So, the
    probability of being a silver Roman coin is *P*(silver and Roman)![image](Images/026equ03.jpg).
    Subtracting that part, we see that the probability of picking a silver coin or
    a Roman coin is 75 percent:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/026equ04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As with the sum rule, there’s more to the product rule, and we’ll get to that
    shortly. But first, let’s use the product rule to see if we can solve the birthday
    paradox.
  prefs: []
  type: TYPE_NORMAL
- en: The Birthday Paradox
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: On average, how many people do we need together in a room to have a higher than
    50 percent chance that two of them share the same birthday? This problem is known
    as the *birthday paradox*. Let’s see if we can use our knowledge of the product
    rule for probability to see what the solution is.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll ignore leap years and state that there are 365 days in a year. Intuitively,
    we see that the probability of randomly selected people sharing a birthday is
    one day (the shared birthday) out of 365 possible birthdays in a year. The sample
    space is 365 days, and the shared birthday is the one day in common. So, we get
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/027equ01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'They either share a birthday or they don’t: 1 – 1/365 = 365/365 – 1/365 = 364/365\.
    So we get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/027equ02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Of the 365 days in a year, there is one possible match, leaving 364 days that
    don’t match.
  prefs: []
  type: TYPE_NORMAL
- en: A 0.3 percent chance of randomly selected people sharing a birthday is pretty
    low. It means if you randomly choose pairs of people and ask if they share a birthday,
    on average you’ll get three matches in a thousand—not terribly likely.
  prefs: []
  type: TYPE_NORMAL
- en: For our calculation, we’ll look at things the other way. We’re looking for the
    number of people we need together so that the probability of *no* two people sharing
    a birthday is below 50 percent.
  prefs: []
  type: TYPE_NORMAL
- en: 'We know the probability that two randomly selected people *don’t* share a birthday:
    ![image](Images/027equ03.jpg). Therefore, if we select two pairs of people at
    random, the probability that both pairs do not share a birthday is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/027equ04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, we’re using the product rule. Similarly, with three people, *(A*, *B*,
    *C*), we can form three different pairs, *(A*, *B*), (*A*, *C*), and (*B*, *C*),
    so we calculate the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/027equ05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'For *n* comparisons, here’s the probability that none share a birthday:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/02equ07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Our task is to find the minimum number of comparisons, *n*, leading to a probability
    of no shared birthday < 50 percent, where *n* is a function of the number of people
    in the room, *m*. Why less than 50 percent? Because if we find an *n* leading
    to a less than 50 percent probability that there is no shared birthday, the probability
    that there *is* a shared birthday must then be > 50 percent.
  prefs: []
  type: TYPE_NORMAL
- en: If you pick three people at random, there are three pairs of people to check
    to see if they share a birthday. If you have four people, there are six pairs.
    So, the larger the group of people, the more pairs there are. Can we find a rule
    that maps the number of people, *m*, to the number of pairs to compare, *n*? If
    we have that, we can find the smallest *m* leading to an *n* where the probability
    of [Equation 2.7](ch02.xhtml#ch02equ07) is < 50 percent.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we have a set of *m* unique objects, like people in a room, and we select
    pairs of them, how many different pairs can we select? In other words, how many
    combinations of *m* things are there when taken two at a time? The formula to
    calculate the number of combinations of *m* things taken *k* at a time is this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/028equ01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: You’ll sometimes hear this referred to as “*m* choose *k*,” where, for us, *k*
    = 2\. Let’s find the number of comparisons we need, *n*, and use the number of
    combinations of things taken two at a time to find an *m* leading to at least
    *n* comparisons.
  prefs: []
  type: TYPE_NORMAL
- en: 'A straightforward loop in Python locates the *n* we need:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'We’re told *n* = 253\. So, we need to make, on average, 253 comparisons, 253
    pairs of people, to have a greater than 50 percent chance that one of those pairs
    shares a birthday. The final step is to find how many combinations of *m* people
    taken two at a time are at least 253\. A bit of brute force trial and error tells
    us this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/028equ02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: We need *m* = 23 people on average to have a higher than 50 percent chance at
    least two of them share a birthday. All thanks to the product rule.
  prefs: []
  type: TYPE_NORMAL
- en: 'Is our result reliable or just sleight of hand? Some code can tell us. First,
    let’s verify via simulation that the probability of randomly picking two people
    who share a birthday is 0.3 percent:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The code simulates 100,000 random pairs of people, where the random integer
    in [0, 364] represents the person’s birthday. If the two random birthdays match,
    `match` is incremented. After all simulations run, we print the probability. A
    run of this code produced the following, making our assertion of a 0.3 percent
    chance believable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'What about the number of people to get a > 50 percent chance of sharing a birthday?
    Here, we have two loops. The first is over the number of people in the room (`m`),
    and the second is over the number of simulations for that many people in the room
    (`n`). In code, that looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We let `m` range over 2 to 30 people. For each set of `m` people, we run 100,000
    simulations. For each simulation, we pick a set of birthdays for each person in
    the room (`b`) and then compare each person with every other person to see if
    there’s a matching birthday. If there is, we increment `match`. If we had at least
    one match, we increment `matches` and move to the next simulation. Finally, when
    all of the simulations for the current number of people in the room are complete,
    we print the probability of at least a single match.
  prefs: []
  type: TYPE_NORMAL
- en: If we run the code and plot the output, we get [Figure 2-1](ch02.xhtml#ch02fig01),
    where the dashed line is 50 percent. The first point above the dashed line is
    23 people, precisely as we calculated.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/02fig01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 2-1: The probability of a shared birthday as a function of the number
    of people in a room*'
  prefs: []
  type: TYPE_NORMAL
- en: It’s always satisfying to see the simulation line up with the math.
  prefs: []
  type: TYPE_NORMAL
- en: Conditional Probability
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Consider a bag of 10 marbles: 8 red and 2 blue. We know if we pick a marble
    at random from the bag, we have a 2 out of 10, or 20 percent, chance of picking
    a blue marble. Say we pick a blue marble. After admiring its pretty shade of blue,
    we put it back in the bag, shake the bag, and pull out another marble. What’s
    our chance of picking a blue marble a second time? Again, there are 2 blue marbles
    and 10 total, so it’s still 20 percent.'
  prefs: []
  type: TYPE_NORMAL
- en: If the fact that event *A* happened (here, picking a blue marble that we then
    returned to the bag) hasn’t affected the probability of a future event *B*, the
    two are independent events. Our chance of picking a blue marble a second time
    is in no way affected by the fact that we previously chose a blue marble. The
    same is true for a coin flip. The fact that we’ve landed heads up four times in
    a row has nothing to do with the probability of getting tails on the next flip,
    assuming it’s a fair coin, i.e., it’s not weighted on one side or two-headed (or
    two-tailed).
  prefs: []
  type: TYPE_NORMAL
- en: Now, consider an alternate scenario. We still have a bag with eight red and
    two blue marbles. We pick a marble—say it’s red this time—and because we like
    the color, we keep the marble and put it aside. Now, we pick another marble from
    the bag. What’s the probability of picking another red marble? Here, things have
    changed. There are nine marbles now, and seven of them are red. So, our chance
    of picking a second red marble is now 7 of 9, or 78 percent. The possibility of
    choosing a red marble initially was 8 of 10, or 80 percent. The fact that event
    *A* happened, picking a red marble we then kept, has altered the probability of
    a second event. The two events are no longer independent. The probability of the
    second event was changed by the first event happening. Notationally, we write
    *P**(B*|*A*) to mean the probability of event *B given* event *A* has happened.
    This is a *conditional probability* because it’s conditional on event *A* happening.
  prefs: []
  type: TYPE_NORMAL
- en: Here’s where we update the product rule. The version in [Equation 2.5](ch02.xhtml#ch02equ05)
    assumes that the two events are independent, like being female and having brown
    eyes. If we have a dependent situation, the rule becomes
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/02equ08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: meaning the probability of the two events both happening is the product of the
    probability of one given the other has happened and the probability of the other.
  prefs: []
  type: TYPE_NORMAL
- en: 'Looking back at our marble example above, we calculated the probability of
    picking a red marble after already picking and keeping a red marble to be 7 of
    9, or about 78 percent. That’s *P**(B*|*A*). For *P(A*), we need the probability
    of picking a red marble initially, which we said was 80 percent. Therefore, the
    probability of picking a red marble that we keep, *A*, and picking a red marble
    on a second draw, *B*, is 62 percent:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/031equ01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: If two events are mutually exclusive, *P**(B*|*A*) = *P*(*A*|*B*) = 0\. If events
    *A* and *B* are independent, then *P*(*A*|*B*) = *P*(*A*) and *P*(*B*|*A*) = *P*(*B*)
    because the conditional event happening or not has no influence on the later event.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, note that typically *P**(B*|*A*) ≠ *P*(*A*|*B*), and confusing the
    two conditional probabilities is a common and often serious error. As we’ll see
    in [Chapter 3](ch03.xhtml#ch03), something called Bayes’ theorem gives the proper
    relationship between the conditional probabilities. We’ll encounter conditional
    probability again when discussing the chain rule for probability.
  prefs: []
  type: TYPE_NORMAL
- en: Total Probability
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'If our sample space is separated into disjoint regions, *B[i]* (*B*[1], *B*[2],
    etc.) so that the totality of the sample space is covered by the collection of
    *B[i]*s and the *B*[i]s don’t overlap, we can calculate the probability of an
    event over all the partitions as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/031equ02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here *P**(A*|*B[i]*) is the probability of *A* given partition *B[i]* and *P*(*B[i]*)
    is the probability of partition *B[i]*, which is the amount of the sample space
    that *B[i]* represents. In this view, *P**(A*) is the *total probability* of *A*
    over the partitions, *B[i]*. Let’s see an example of how to use this law.
  prefs: []
  type: TYPE_NORMAL
- en: 'You have three cities, Kish, Kesh, and Kuara, and their populations are 2,000,
    1,000, and 3,000, respectively. Additionally, the percentages of people with blue
    eyes in these cities are 12 percent, 3 percent, and 21 percent, respectively.
    We want to know the probability that a randomly selected person from among the
    cities has blue eyes. The cities’ populations affect things, as the probability
    of having blue eyes varies by city and the cities vary in population. To find
    *P*(blue), we use the total probability:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/032equ01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here *P*(blue|Kish) is the probability of having blue eyes given you live in
    Kish, and *P* (Kish) is the probability of living in Kish, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'We know the necessary quantities to find the total probability. The probability
    of blue eyes per city is given above, and the probability of living in each city
    is found from its population and the total population of the three cities:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/032equ02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Therefore, *P*(blue) is
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/032equ03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'meaning there is a 15 percent chance a randomly selected inhabitant of the
    three cities will have blue eyes. Note the sum of the probabilities for selecting
    the cities: *P*(Kish) + *P*(Kesh) + *P*(Kuara) = 1\. This must be the case for
    the partitioning of the total sample space, all the inhabitants of the cities,
    to be covered by the partitioning into cities.'
  prefs: []
  type: TYPE_NORMAL
- en: Joint and Marginal Probability
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The *joint probability* of two variables, *P**(X* = *x*, *Y* = *y*), is the
    probability that random variable *X* will have the value *x* at the same time
    random variable *Y* is *y*. We’ve already seen an example of a joint probability.
    When we use “and” when calculating a probability, we’re calculating a joint probability.
    A joint probability is the probability of multiple conditions being true at the
    same time, which is “and.” The *marginal probability* is what we get when we calculate
    the probability of one or more of those conditions without caring about the value
    of the others; in other words, the probability of a subset of the random variables
    in the “and.”
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we’ll examine joint and marginal probabilities using simple
    tables. We’ll then introduce the chain rule for probability. This rule lets us
    break down a joint probability into the product of smaller joint probabilities
    and conditional probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Joint Probability Tables
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: According to Colour Blind Awareness (*[http://www.colourblindawareness.org/](http://www.colourblindawareness.org/)*),
    approximately 1 in 12 men and 1 in 200 women are color-blind. The difference comes
    from the fact that the affected gene is on the X chromosome, requiring a woman
    to inherit the recessive gene from both her mother and father. A man need only
    inherit the gene from one parent.
  prefs: []
  type: TYPE_NORMAL
- en: 'Pretend we survey 1,000 people. We can count the number of people who are male
    and color-blind, female and color-blind, male and not color-blind, and female
    and not color-blind. We do this and arrange the data in a table like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | **Color-blind** | **Not color-blind** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **Male** | 42 | 456 | 498 |'
  prefs: []
  type: TYPE_TB
- en: '| **Female** | 3 | 499 | 502 |'
  prefs: []
  type: TYPE_TB
- en: '|  | 45 | 955 | 1000 |'
  prefs: []
  type: TYPE_TB
- en: Tables like these are known as *contingency tables*. The tallied data is in
    the center 2 × 2 numerical portion of the table. The rightmost column is the sum
    across the rows, and the final row is the sum of the columns. The sum of the final
    row or column is in the last cell and, by necessity, sums to the 1,000 people
    we surveyed.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can turn the contingency table into a table of probabilities by dividing
    each cell by 1,000, the number of people surveyed. Doing this gives us the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | **Color-blind** | **Not color-blind** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **Male** | 0.042 | 0.456 | 0.498 |'
  prefs: []
  type: TYPE_TB
- en: '| **Female** | 0.003 | 0.499 | 0.502 |'
  prefs: []
  type: TYPE_TB
- en: '|  | 0.045 | 0.955 | 1.000 |'
  prefs: []
  type: TYPE_TB
- en: The table is now a joint probability table. With it, we can look up the probability
    of being male and color-blind. Notationally, we write
  prefs: []
  type: TYPE_NORMAL
- en: '*P*(sex = male, color-blind = yes) = 0.042'
  prefs: []
  type: TYPE_NORMAL
- en: and, similarly, we see that
  prefs: []
  type: TYPE_NORMAL
- en: '*P*(sex = female, color-blind = no) = 0.499'
  prefs: []
  type: TYPE_NORMAL
- en: Using the joint probability table, we can predict what we would expect to measure
    given a random sample of people. For example, if we have a sample of 20,000 people,
    then, based on our table, we’ll expect to find about 20000(0.042) = 840 color-blind
    men and about 20000(0.003) = 60 color-blind women.
  prefs: []
  type: TYPE_NORMAL
- en: What if we wanted to know the probability of being color-blind regardless of
    sex? For that, we sum the probabilities along the color-blind column and see that
    there is a 4.5 percent chance that a randomly selected person is color-blind.
    Likewise, summing along the row gives us an estimated probability of being female
    as 50.2 percent. We do need to bear in mind that our table was built from a sample
    of only 1,000 people. You might guess that if we had instead sampled 100,000 people,
    our split between male and female would be closer to 50/50, and you’d be right.
  prefs: []
  type: TYPE_NORMAL
- en: Calculating the probability of being color-blind or female from the joint probability
    table is calculating a marginal probability. In the first case, we summed along
    the column to remove the effect of sex, whereas in the second case, we summed
    along the row to remove the effect of color-blindness.
  prefs: []
  type: TYPE_NORMAL
- en: 'Mathematically, we get the marginal probabilities by summing across the variables
    we don’t want. If we have a joint probability table for two variables, like the
    example above, we get the marginal probabilities by summing:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/034equ01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Using the table above, we can write
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/034equ02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: where we sum across sex to remove its effect. Now, let’s explore another table,
    one with three variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sometime during the night of April 14, 1912, the RMS *Titanic* sank in the
    North Atlantic on its maiden voyage from England to New York City. Based on a
    sample of 887 people who were on board the *Titanic*, we can generate [Table 2-2](ch02.xhtml#ch02tab02)
    showing the joint probability for three variables: survival, sex, and cabin class.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 2-2:** Joint Probability Table for *Titanic* Passengers'
  prefs: []
  type: TYPE_NORMAL
- en: '|  |  | **Cabin1** | **Cabin2** | **Cabin3** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **Dead** | **Male** | 0.087 | 0.103 | 0.334 |'
  prefs: []
  type: TYPE_TB
- en: '| **Female** | 0.003 | 0.007 | 0.081 |'
  prefs: []
  type: TYPE_TB
- en: '| **Alive** | **Male** | 0.051 | 0.019 | 0.053 |'
  prefs: []
  type: TYPE_TB
- en: '| **Female** | 0.103 | 0.079 | 0.081 |'
  prefs: []
  type: TYPE_TB
- en: Let’s use [Table 2-2](ch02.xhtml#ch02tab02) to calculate some probabilities.
    Note, we’ll use the values in [Table 2-2](ch02.xhtml#ch02tab02), which are accurate
    to three decimals. As a result, the overall numbers will be slightly off from
    the probabilities we’d calculate from the counts, but doing this makes the link
    between the table and the equations more concrete.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we can read directly from the table for specific triplets of survived,
    sex, and cabin class. Here’s an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '*P*(dead, male, cabin3) = 0.334'
  prefs: []
  type: TYPE_NORMAL
- en: 'This means the probability of a randomly selected passenger being a man who
    was in a third-class cabin and didn’t survive is 33 percent. What about men in
    first class? That’s in the table too:'
  prefs: []
  type: TYPE_NORMAL
- en: '*P*(dead, male, cabin1) = 0.087'
  prefs: []
  type: TYPE_NORMAL
- en: This means that a selected passenger has a 9 percent chance of being a man in
    first class who died. We can see that class differences, in cabins and society,
    mattered quite a bit.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s use the table to calculate some other joint and marginal probabilities.
    First, what’s the probability of not surviving? To find it, we need to sum over
    sex and cabin:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/02equ09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here we’ve introduced a shorthand notation for male/female (*M*/*F*) and cabin
    class (1, 2, 3).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s calculate the probability of not surviving *given* the passenger was
    male, *P*(dead|*M*). To do this, we look back to [Equation 2.8](ch02.xhtml#ch02equ08),
    remembering that the “and” implies a joint probability. We rewrite [Equation 2.8](ch02.xhtml#ch02equ08)
    to solve for *P*(*B*|*A*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/035equ01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This is sometimes used to define the conditional probability in the first place.
    Note, *P**(A*, *B*) means *P*(*A* and *B*)—both are joint probabilities. Using
    this form, the probability of not surviving given the passenger is male is
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/036equ01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: where *P*(dead, *M*) is the joint probability of being dead and male, and *P*(*M*)
    is the probability of being male.
  prefs: []
  type: TYPE_NORMAL
- en: We need to be careful when thinking about the probabilities. *P*(dead, *M*)
    is not the probability of not surviving if the passenger is male. Instead, it’s
    the probability of a randomly selected passenger being a male who didn’t survive.
    What we want is *P*(dead|*M*), which is the probability of not surviving given
    a passenger was male.
  prefs: []
  type: TYPE_NORMAL
- en: 'To get *P*(dead, *M*), we need to sum over cabin class:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/02equ10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'To get *P*(*M*), we sum over survival and cabin class:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/02equ11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'To finally calculate *P*(dead|*M*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/036equ02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This tells us that 81 percent of the male passengers didn’t survive.
  prefs: []
  type: TYPE_NORMAL
- en: 'A similar calculation, shown below, tells us the probability of being female
    and surviving:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/036equ03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: We see that women were far more likely to survive than men. Here’s one instance
    where the phrase “women and children first” was actually the case. I leave it
    as an exercise for you to calculate the individual probabilities in *P*(alive|*F*).
  prefs: []
  type: TYPE_NORMAL
- en: We’ve calculated *P*(dead, *M*), the probability of being a male who did not
    survive; *P*(*M*), the probability of being male; and *P*(dead|*M*), the probability
    of not surviving given being a male. Let’s do one more calculation based on [Table
    2-2](ch02.xhtml#ch02tab02). Let’s find *P*(dead or *M*), the probability of not
    surviving, or being male.
  prefs: []
  type: TYPE_NORMAL
- en: '[Equation 2.6](ch02.xhtml#ch02equ06) tells us that this is the probability:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/037equ01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: If we look at [Equation 2.9](ch02.xhtml#ch02equ09) and [Equation 2.11](ch02.xhtml#ch02equ11),
    we see that both have the same terms, the very terms summed in [Equation 2.10](ch02.xhtml#ch02equ10).
    This is why we must subtract *P*(dead, *M*) from the calculation of *P*(dead or
    *M*) to avoid double-counting.
  prefs: []
  type: TYPE_NORMAL
- en: 'To summarize, then:'
  prefs: []
  type: TYPE_NORMAL
- en: The joint probability is the probability of two or more random variables having
    a specific set of values. The joint probability is often represented as a table.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The marginal probability for a random variable is found by summing over all
    the possible values of the other random variables.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The product rule with a conditional probability tells us how to calculate the
    joint probability given a conditional probability and an unconditional probability
    when we have two random variables. Let’s now see how to use the chain rule for
    probability to generalize that idea.
  prefs: []
  type: TYPE_NORMAL
- en: Chain Rule for Probability
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[Equation 2.8](ch02.xhtml#ch02equ08) tells us how to calculate the joint probability
    for two random variables in terms of the conditional probability. By using the
    *chain rule for probability*, we can expand [Equation 2.8](ch02.xhtml#ch02equ08)
    and calculate the joint probability for more than two random variables.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In its generic form, the chain rule for the joint probability of *n* random
    variables is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/02equ12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here ⋂ is used to indicate “and” for joint probabilities. [Equation 2.12](ch02.xhtml#ch02equ12)
    looks impressive, but it’s not hard to follow, as we’ll see with a few examples.
    I need to use ⋂ in the equation for the joint part of the conditional probabilities,
    but in the examples, I’ll use a comma, and you’ll see the pattern quickly enough.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s how the chain rule breaks up a joint probability with three random variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/038equ01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The first line says the probability of *X*, *Y*, and *Z* is the product of the
    probability of *X* given *Y* and *Z* and the probability of *Y* and *Z*. This
    is [Equation 2.8](ch02.xhtml#ch02equ08) with *X* for *B* and *Y*, *Z* for *A*.
    The second line applies the chain rule to *P*(*Y*, *Z*) to get *P*(*Y*|*Z*)*P*(*Z*).
    The rule can be applied in sequence, like a chain, hence the name.
  prefs: []
  type: TYPE_NORMAL
- en: 'What about a joint probability with four random variables? We get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/038equ02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Let’s work through an example that uses the chain rule. Say we’re very social
    and have 50 people at our party. Four of the 50 people have been to Boston in
    the fall. We pick three people at random. What’s the probability that *none* of
    them have been to Boston in the fall?
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll use *A[i]* to indicate the event of a person who has not been to Boston
    in the fall. Therefore, what we want to find is *P*(*A*[3], *A*[2], *A*[1]), the
    probability of three people all of whom have not been to Boston in the fall. The
    chain rule lets us break this probability up like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/038equ04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: We can work with the right-hand side of this equation intuitively. Look at *P*(*A*[1]).
    This is the probability of picking a random person in the room who has not been
    to Boston in the fall. Four of the people have, so 46 have not, and we see that
    *P*(*A*[1]) = 46/50\. Once we have a person picked, we need to know the probability
    of selecting a second person from the remaining 49, that’s *P*(*A*[2]|*A*[1])
    = 45/49\. There are only 49 people left, and we haven’t selected one of the four
    who has been to Boston in the fall. Finally, we have two people selected, so there
    are 48 people in the room, 44 of whom have not been to Boston in the fall. This
    means *P*(*A*[3]|*A*[2], *A*[1]) = 44/48.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are now ready to answer our initial question. The probability of selecting
    three people from the room with none of them having been to Boston in the fall
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/038equ03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: That’s slightly more than 77 percent.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can check if our calculation is reasonable by simulating many draws of three
    people. This is the code we need:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: We’ll run 100,000 simulations. Every time we select three people out of 50 who
    haven’t been to Boston in the fall, we’ll increment `nb`. We simulate selecting
    three people by choosing three random integers in the range [0, 50) and putting
    them in `s`. Then, we look at each of the three integers, asking if any are less
    than four. If any are, we say we selected a person who has been to Boston and
    set `fail` to `True`. If none of the three integers are less than four, we were
    successful with this simulation. When done, we print the fraction of simulations
    that did sample three people who never went to Boston in the fall.
  prefs: []
  type: TYPE_NORMAL
- en: Running this code produced
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: which is close enough to our calculated value to give us confidence that we
    found the correct answer.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This chapter introduced the fundamentals of probability. We explored basic concepts
    of probability, including sample spaces and random variables. We followed with
    some examples of how poor humans can be at probability. After that, we considered
    the rules of probability, with examples. The rules led us to joint and marginal
    probabilities and finally to the chain rule for probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter continues our tour of probability, starting with probability
    distributions and how to sample from them and ending with Bayes’ theorem, which
    shows us correct way to compare conditional probabilities.
  prefs: []
  type: TYPE_NORMAL

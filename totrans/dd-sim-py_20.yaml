- en: '16'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Asynchrony and Concurrency
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/book_art/chapterart.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You know the situation: you have to finish that TPS report for your boss, fix
    a bug that shipped to production, and figure out which of your co-workers borrowed
    your stapler (it’s Jeff again, isn’t it?), all before day’s end. How will you
    get it all done? You can’t make copies of yourself—and even if you could, the
    line for the copier is out the door—so you tackle these tasks with *concurrency*.'
  prefs: []
  type: TYPE_NORMAL
- en: It’s the same in Python. If your program needs to wait on user input, send data
    over a network, and crunch numbers, all while still updating the user interface,
    you can handle these tasks concurrently, thus improving your program’s responsiveness.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two options for achieving concurrency in Python: either threading
    (see Chapter 17), wherein the operating system manages the multitasking, or asynchrony,
    where Python handles it. This chapter focuses on the latter.'
  prefs: []
  type: TYPE_NORMAL
- en: Asynchrony in Python
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As mentioned, there are two ways to achieve concurrency in Python. *Threading*,
    also known as *pre-emptive multitasking*, involves letting the operating system
    manage the multitasking by running each task in a single flow of execution called
    a *thread*. These multiple threads still share the same system *process*, which
    is an instance of a running computer program. If you open the system monitor on
    your computer, you can see a list of running processes on your machine. Any one
    of those processes can have multiple threads.
  prefs: []
  type: TYPE_NORMAL
- en: Traditional threading has a number of pitfalls, which is why I’ll come back
    to it in Chapter 17. The alternative is *asynchrony*, also known as *cooperative
    multitasking*. It is the easiest way to achieve concurrency in Python—but that
    doesn’t make it easy! The operating system only sees your code as running in a
    single process, with a single thread; it is Python itself that manages the multitasking,
    with some help from you, thereby sidestepping some of the issues that crop up
    with threading. Still, writing good asynchronous code in Python requires some
    forethought and planning.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to keep in mind that asynchrony is not parallelism. In Python,
    a mechanism called the *Global Interpreter Lock (GIL)* ensures that any single
    Python process is constrained to a single CPU core, regardless of how many cores
    are available to the system. For this reason, parallelism cannot be achieved with
    either asynchrony or threading. This may sound like a design flaw, but efforts
    to eliminate the GIL from CPython have proven more technically challenging than
    imagined, and the results have had poorer performance thus far. As of this writing,
    progress has all but stalled on the most prominent of these efforts, Larry Hastings’s
    Gilectomy. The GIL makes things run smoother in Python.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchrony was originally possible in Python through third-party libraries,
    like Twisted. Later, Python 3.5 added syntax and functionality for natively achieving
    asynchrony. These features did not become stable until Python 3.7; as a result,
    many articles and online discussions about asynchrony are profoundly out-of-date.
    Your best source of information is always the official documentation. I’ve done
    my best to be up-to-date with Python 3.10.
  prefs: []
  type: TYPE_NORMAL
- en: 'Python makes asynchrony possible with two keywords borrowed from the C# language:
    `async` and `await`, as well as a special type of coroutine. (Many other languages
    implement similar syntax; these include JavaScript, Dart, and Scala.) Asynchronous
    execution is managed and run by an *event* loop, which is responsible for the
    multitasking. Python provides the *asyncio* module in the standard library for
    this purpose, and we’ll use it in this chapter’s examples.'
  prefs: []
  type: TYPE_NORMAL
- en: It’s worth noting that at the time of this writing, `asyncio` is dauntingly
    complicated beyond basic usage, even to some Python experts. For that reason,
    I’ll stick to the essential concepts universal to asynchrony and avoid explaining
    or using `asyncio` any more than is absolutely unavoidable. Most of what you’ll
    see are just plain asynchrony techniques; I’ll call out the exceptions.
  prefs: []
  type: TYPE_NORMAL
- en: When you’re ready to go further into this topic of asynchrony, pick up either
    the Trio or Curio library. Both are written to be user-friendly. They’re well
    documented, with the beginner in mind, and they regularly provide design cues
    to `asyncio`’s developers. Armed with the knowledge from this chapter, you should
    be able to learn either of those libraries from their documentation.
  prefs: []
  type: TYPE_NORMAL
- en: '*Curio* was developed by David Beazley, an expert in Python and concurrency,
    with the goal of making asynchrony in Python more approachable. The official documentation
    can be found at [https://curio.readthedocs.io/](https://curio.readthedocs.io/).
    That main page also has links to a number of excellent talks on Python asynchronous
    programming, including several talks that guide you through writing your *own*
    asynchrony module (although you likely won’t ever need to do this).'
  prefs: []
  type: TYPE_NORMAL
- en: '*Trio* is based on Curio, and it furthers the library’s goals of simplicity
    and usability. As of this writing, it’s considered somewhat experimental, but
    it is still stable enough to use in production. Python developers most often recommend
    using Trio. Find the official documentation at [https://trio.readthedocs.io/en/stable/](https://trio.readthedocs.io/en/stable/).'
  prefs: []
  type: TYPE_NORMAL
- en: Earlier in this section, I mentioned the *Twisted* library, which added asynchronous
    behavior to Python some 20 years before asynchrony was added to the core language.
    It uses a number of dated patterns, rather than the modern asynchronous workflow
    model, but it’s still an active and viable library with many use cases. A number
    of popular libraries use it under the hood. Learn more at [https://twistedmatrix.com/](https://twistedmatrix.com/).
  prefs: []
  type: TYPE_NORMAL
- en: The `asyncio` official documentation can be found at [https://docs.python.org/3/library/asyncio.xhtml](https://docs.python.org/3/library/asyncio.xhtml).
    I recommend digging into `asyncio` in more detail only once you’re comfortable
    with asynchronous programming via either Trio or Curio, as well as with the analogous
    concepts of threading (Chapter 17). Your grasp of the concepts and patterns of
    asynchrony and concurrency will help you make sense of the `asyncio` documentation.
  prefs: []
  type: TYPE_NORMAL
- en: In the midst of all this, remember that asynchrony is still in its relative
    infancy, both in Python and in the field of computer science as a whole. The asynchronous
    workflow model first appeared in the F# language in 2007, based on concepts introduced
    in Haskell around 1999 and several papers from the early 1990s. By contrast, the
    related concept of threading dates to the late 1960s. Many problems in asynchrony
    still don’t have clear or established solutions. Who knows—you might be the first
    to solve one of them!
  prefs: []
  type: TYPE_NORMAL
- en: 'The Example Scenario: Collatz Game, Synchronous Version'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To properly demonstrate how these concepts work, I’ll create a small program
    that would benefit from concurrency. Because of the complexity of the issues at
    hand, I’ll focus entirely on this one example for this chapter and the next, so
    you can get used to the working details.
  prefs: []
  type: TYPE_NORMAL
- en: I’ll start with a *synchronous* working version, so you’ll have a solid idea
    of what I’m doing. The complexity of this example will demonstrate some of the
    common issues involved in concurrency. Simplicity is the enemy of effectiveness
    for examples with these concepts.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the example, I’ll play with a strange phenomenon in math known as the *Collatz
    conjecture*, which works like this:'
  prefs: []
  type: TYPE_NORMAL
- en: Start with any positive integer *n*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If *n* is even, the next term in the sequence should be `n / 2`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If *n* is odd, the next term in the sequence should be `3 * n + 1`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If *n* is `1`, stop.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Even if you start with a fantastically large number, you’ll always wind up at
    `1` after relatively few steps. Starting with `942,488,749,153,153`, for example,
    the Collatz sequence arrives at `1` in only 1,863 steps.
  prefs: []
  type: TYPE_NORMAL
- en: There are all sorts of things you can do with the Collatz conjecture. For this
    example, I’ll create a simple game that challenges the user to guess how many
    Collatz sequences have a particular length. I’ll restrict the range of starting
    numbers to integers between `2` and `100,000` (which I can also represent as `10**5`).
  prefs: []
  type: TYPE_NORMAL
- en: For example, exactly 782 starting numbers will yield Collatz sequences with
    a length of exactly 42 values. To play the game in the example, the user would
    enter 42 (the target length) and then guess how many starting numbers would produce
    Collatz sequences of the target length. If the user guessed 782, they’d win. (Okay,
    yes, it’s a lousy game premise, but it works for demonstrating concurrency.)
  prefs: []
  type: TYPE_NORMAL
- en: 'At the top of my module, I’ll define a constant, `BOUND`, for the maximum starting
    number. Counting zeros in constants is an invitation to error, so I’ll define
    100,000 as a power of 10 instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-1: *collatz_sync.py:1*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next is the function for finding the number of steps in a single Collatz sequence:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-2: *collatz_sync.py:2*'
  prefs: []
  type: TYPE_NORMAL
- en: Nothing should surprise you here. This function follows the rules for calculating
    a Collatz sequence and returns the number of steps it took to reach `1`.
  prefs: []
  type: TYPE_NORMAL
- en: 'I need another function for tracking how many times a target sequence length
    is met:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-3: *collatz_sync.py:3*'
  prefs: []
  type: TYPE_NORMAL
- en: This function runs `collatz()` on every possible starting integer from `2` to
    `BOUND` and counts how many times a Collatz sequence had exactly `target` steps.
    It returns this count at the end.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, I create a function for getting a positive integer from the user, which
    I’ll need to do a couple of times in the program run, first to get the desired
    Collatz target length, and second to get the user’s guess of how many starting
    values produce Collatz sequences of the target length:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-4: *collatz_sync.py:4*'
  prefs: []
  type: TYPE_NORMAL
- en: This function should also look pretty familiar by now. I get a string from the
    user with `input()`, attempt to convert it to an integer, and ensure that integer
    is not negative. If anything goes wrong, I display a message for the user and
    let them try again.
  prefs: []
  type: TYPE_NORMAL
- en: 'Tying it all together is the main function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-5: *collatz_sync.py:5*'
  prefs: []
  type: TYPE_NORMAL
- en: I display the name of the program and ask the user to enter a target sequence
    length to search for. I perform the search for the sequence length with `length_counter()`
    and bind the result to `count`. Next, I get the user’s guess, which I bind to
    `guess`, and compare it to `count`, giving the user some feedback on how close
    their guess was.
  prefs: []
  type: TYPE_NORMAL
- en: 'Lastly, I need to execute the main function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-6: *collatz_sync.py:6*'
  prefs: []
  type: TYPE_NORMAL
- en: 'All in all, I’ve stuck with syntax and patterns you should be familiar with
    by now. But running this module shows why the program could do with some concurrency:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, the program hangs for several seconds, before continuing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: It works, but it doesn’t feel particularly responsive. What’s more, if I were
    to increase the value of `BOUND` by even one exponential value, to `10**6`, the
    delay would increase dramatically; on my system, it went from 7 to 63 seconds!
  prefs: []
  type: TYPE_NORMAL
- en: Thankfully, there are a number of ways I could make this program feel more responsive.
    Over the next two chapters, I’ll point these out to you and implement the changes.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchrony
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s see how asynchrony can help my Collatz program. First, notice that the
    several-second delay on running `length_counter()` is *CPU-bound*, as it relates
    to how long it takes the CPU to perform the math. That delay will remain until
    I apply parallelism in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'But there’s another source of delay in this program: the user. The program
    has to wait for an indefinite period of time until the user enters a valid number.
    This part of the program is *IO-bound*, because it is limited by the response
    time of something external, such as user input, a network response, or another
    program, rather than the working speed of the CPU.'
  prefs: []
  type: TYPE_NORMAL
- en: 'I can improve the program’s *perceived responsiveness*, how fast it seems to
    the user, by running the math concurrently with waiting for the user’s guess.
    The calculations themselves won’t actually happen any faster, but my users probably
    won’t realize that: they’ll be focusing on entering a guess while Python is running
    that heavy-duty math.'
  prefs: []
  type: TYPE_NORMAL
- en: 'I’ll use the built-in `asyncio` module to work with asynchrony in Python, so
    I import it at the start of my program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-7: *collatz_async.py:1a*'
  prefs: []
  type: TYPE_NORMAL
- en: As in [Listing 16-1](#listing16-1), I’m defining my `BOUND` constant here. Now
    I can begin rewriting my code to be asynchronous.
  prefs: []
  type: TYPE_NORMAL
- en: Native Coroutines
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In Chapter 10, I introduced simple coroutines, which are based on generators.
    Simple coroutines run until they hit a `yield` statement and then wait for data
    to be sent to the coroutine object with the `send()` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'I’ll make my game’s code asynchronous by turning some of my program’s functions
    into *native coroutines*. Also called *coroutine functions*, native coroutines
    build on the idea of simple coroutines: instead of waiting for data to be sent,
    they can be paused and resumed at specific places to achieve multitasking. In
    the rest of this chapter, I use the terms *coroutine function* and *native coroutine*
    somewhat interchangeably. Be advised that when most Python developers refer to
    coroutines, they almost always mean native coroutines, although it never hurts
    to clarify.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You declare a native coroutine by placing the `async` keyword in front of the
    definition, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: However, don’t get the idea that to implement asynchrony, you only need to put
    the `async` keyword in front of all your function definitions. This is only the
    first of many steps toward making the code asynchronous.
  prefs: []
  type: TYPE_NORMAL
- en: 'When called, a coroutine function returns a native coroutine object, which
    is a special kind of object called an *awaitable*. These are callables that can
    pause and resume mid-execution. Awaitables must be called using the `await` keyword,
    which acts much like `yield from`. Here, I use the `await` keyword to call the
    awaitable coroutine function `some_function()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'There’s another catch: the `await` keyword can only be used within an awaitable.
    When a native coroutine reaches an `await`, it pauses execution until the called
    awaitable is finished.'
  prefs: []
  type: TYPE_NORMAL
- en: A function should only be turned into a coroutine function when it calls another
    awaitable, performs an IO-bound task, or is specifically intended to run concurrently
    with another awaitable. In the Collatz game, I’ll need to make some decisions
    about which functions to turn into coroutine functions and which to leave as ordinary
    functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'To begin with, consider the synchronous `collatz()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-8: *collatz_async.py:2*'
  prefs: []
  type: TYPE_NORMAL
- en: This function will always return almost instantly, so it neither needs to call
    an awaitable nor run concurrently with another awaitable. It can remain as a normal
    function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Meanwhile, `length_counter()` is labor intensive and CPU-bound. I want it to
    run concurrently with the code that waits for the user to input a guess, so it’s
    a good candidate for a coroutine function. I’ll rewrite the synchronous version
    from [Listing 16-3](#listing16-3):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-9: *collatz_async.py:3*'
  prefs: []
  type: TYPE_NORMAL
- en: I turn this function into a coroutine function with `async` and use `await asyncio.sleep(0)`
    to tell Python where the coroutine function can pause and let something else work.
    If I don’t `await` something in the coroutine function, it will never be paused,
    which would defeat the purpose of making it a coroutine function in the first
    place. (Trio, Curio, and `asyncio` all offer a `sleep()` awaitable.)
  prefs: []
  type: TYPE_NORMAL
- en: I also want to turn the IO-bound `get_input()` function into a coroutine function,
    as the very nature of waiting for user input involves the ability to pause and
    resume. This first version of the coroutine function doesn’t yet await anything
    else; I’ll revisit that in a bit.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-10: *collatz_async.py:4a*'
  prefs: []
  type: TYPE_NORMAL
- en: 'There’s one critical limitation to `await`: it can only be called from within
    an awaitable, such as a coroutine function. I want to call `get_input()` from
    `main()`, so `main()` must also be a coroutine function, as you’ll see in [Listing
    16-11](#listing16-11).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Behind the scenes, native coroutines are still used in a strikingly similar
    manner to simple coroutines. Because `length_counter()` is a coroutine function,
    I can force it to be executed manually (and synchronously) the same as I would
    a simple coroutine. This is just a side example that runs the coroutine function
    synchronously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: I wouldn’t ever use this approach in production, as coroutine functions need
    to be run in a special way to be useful.
  prefs: []
  type: TYPE_NORMAL
- en: Tasks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now that `get_input()` and `length_counter()` are coroutine functions, I must
    call them using the `await` keyword. There are two different ways to invoke them,
    depending on how I want them to be run: by directly awaiting them or by scheduling
    them as *tasks*, which are special objects that run coroutine functions without
    blocking.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Both approaches require turning the Collatz example’s `main()` function into
    a coroutine function, so I’ll begin by doing that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '**Listing 16-11: *collatz_async.py:5a*'
  prefs: []
  type: TYPE_NORMAL
- en: Deciding how to call each awaitable requires some thought. First, before I can
    do anything else, I need to know what Collatz sequence length the user wants to
    search for. I call the `get_input()` coroutine function with the `await` keyword.
    Calling the coroutine function like this will block the program while literally
    awaiting the user input. This blocking is acceptable here, since we can’t do any
    math calculations (or, really, anything else) without that initial user input.
  prefs: []
  type: TYPE_NORMAL
- en: Once I have the input, I can start the calculation in `length_counter()`, which
    I want to run concurrently with getting the user guess via another call to `get_input()`.
    To do this, I schedule the native coroutines as tasks. Always schedule a `Task`
    object rather than instantiating it directly. `Here`, I use `asyncio.create_task()`
    to schedule a task.
  prefs: []
  type: TYPE_NORMAL
- en: The two native coroutines are now scheduled to run as soon as there’s an opening,
    that is, as soon as `main()` is awaiting something. I relinquish the `main()`
    coroutine function’s control of execution by calling `await` on one of my tasks—at
    the moment, it doesn’t matter which—thereby allowing another task to have a turn.
    Because both tasks are already scheduled, they’ll take turns until `length_counter_task`
    returns the value returned by the `length_counter()` coroutine function. Then
    the program waits on the other task, `guess_task`, until it, too, returns a value.
    Depending on how quickly the user entered input, `guess_task` may have been waiting
    to return a value even while `length_counter_task` was still running.
  prefs: []
  type: TYPE_NORMAL
- en: The Trio and Curio libraries have tasks, just like `asyncio` does, although
    they’re created a little differently. Consult the documentation for those libraries
    to learn more.
  prefs: []
  type: TYPE_NORMAL
- en: The Event Loop
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'At this point, it may seem like I’ve coded myself into a corner: coroutine
    functions and other awaitables must be called with `await`, but only coroutine
    functions can contain the `await` keyword. How can I start this program?'
  prefs: []
  type: TYPE_NORMAL
- en: 'The *event loop* is the heart of asynchrony. It manages the multitasking between
    awaitables and provides the means of calling the first awaitable in the stack.
    Every asynchrony module provides an event loop mechanism. You can even write your
    own if you’re feeling brave. In this example, I’ll employ the default event loop
    provided by `asyncio`, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-12: *collatz_async.py:6a*'
  prefs: []
  type: TYPE_NORMAL
- en: I acquire an event loop❶ and bind it to the name `loop`. An event loop object
    has a number of methods for controlling execution; in this case, I use `loop.run_until_complete()`
    to schedule and run the `main()` coroutine function ❷.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since this is the most common way to start an event loop, it’s not surprising
    that `asyncio` provides a shorter equivalent way to use the default event loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-13: *collatz_async.py:6b*'
  prefs: []
  type: TYPE_NORMAL
- en: I can now run my module, and it works.
  prefs: []
  type: TYPE_NORMAL
- en: 'Alternative asynchrony modules offer some important additional mechanisms for
    handling multiple tasks: Curio has `TaskGroup`, while Trio has (and requires use
    of) `Nursery`. See the documentation for those libraries to learn more. The `asyncio`
    module has no analogous structures yet, and implementing them is decidedly non-trivial.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you run this code, you’ll notice a remaining problem: *collatz_async.py*
    still hangs in the same place it did before! That’s not very practical.'
  prefs: []
  type: TYPE_NORMAL
- en: Making It (Actually) Asynchronous
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The code isn’t yet behaving concurrently because of this line from `get_input()`
    in [Listing 16-10](#listing16-10), which I warned you about earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: No matter how I write the rest of the program, `input()` is an IO-bound blocking
    function, so it will hog the process until the user inputs something, such as
    their guess. It doesn’t know how to take turns.
  prefs: []
  type: TYPE_NORMAL
- en: To get user input asynchronously, I must use a coroutine function equivalent
    to `input()`. There’s nothing of the sort in the standard library, but the third-party
    library `aioconsole` provides an asynchronous equivalent for `input()`, among
    a few other functions. I’ll need to install this package to my virtual environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once it’s installed, I import the `ainput` coroutine function I need:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-14: *collatz_async.py:1b*'
  prefs: []
  type: TYPE_NORMAL
- en: The `ainput` coroutine function works exactly like the built-in function `input()`,
    except that it’s an awaitable, so it will periodically relinquish control of the
    process, allowing other awaitables to run.
  prefs: []
  type: TYPE_NORMAL
- en: Conventionally, asynchronous equivalents to standard library functions and modules
    are prepended with an `a` (for `async`). This is helpful to know because there’s
    not much in the way of documentation for `aioconsole`, as of this writing. With
    any library of this sort, assume this naming convention and identical usage to
    the standard library equivalent, unless otherwise informed by documentation.
  prefs: []
  type: TYPE_NORMAL
- en: 'I adjust my `get_input()` coroutine function to use `ainput`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-15: *collatz_async.py:4b*'
  prefs: []
  type: TYPE_NORMAL
- en: Now, if I run the module, it works asynchronously. If I take more than a couple
    of seconds to input a valid guess, the results are printed immediately after I
    press enter. In contrast, if I input a valid guess immediately, the delay from
    the CPU-bound task can still be observed. As mentioned before, concurrency only
    improves the perceived responsiveness of the program, not the execution speed.
  prefs: []
  type: TYPE_NORMAL
- en: Scheduling and Asynchronous Execution Flow
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When you’re used to the execution flow of ordinary synchronous code, asynchrony
    can take more than a little bit of getting used to. To help reinforce the principles
    I’ve introduced, I’ll break down the call stack of the complete *collatz_async.py*
    file.
  prefs: []
  type: TYPE_NORMAL
- en: 'At the outset of execution, I start the event loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: This schedules the `main()` coroutine function as a task, which I’ll refer to
    as `main` throughout this section. Because it’s the only task scheduled, the event
    loop runs it immediately.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, the code needs some user input before it can logically do anything, so
    I `await` the return value of the coroutine function `get_input()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The `await` statement causes the `main` task to relinquish control to the event
    loop so something else can run. The coroutine function `get_input()` is scheduled
    as an event in the background, it runs, and the value is returned and assigned
    to `target`. With that fulfilled, the `main` task proceeds.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, I schedule the `get_input()` coroutine function as a task to get the
    user’s guess:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The task bound to `guess_task` is scheduled, but it does not immediately start.
    The `main` task still has control, and it hasn’t relinquished it yet.
  prefs: []
  type: TYPE_NORMAL
- en: 'I also schedule the `length_counter()` coroutine function in the same manner:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Now, `length_counter_task` is scheduled to run at some point in the future.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, this line is executed in the `main` task:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: This code causes `main` to relinquish control to the event loop, in that it
    pauses and waits for `length_counter_task` to have a value for return. The event
    loop now has control.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next scheduled task in the queue is `guess_task`, so that’s started next.
    The `get_input()` coroutine function runs up to the following line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Now, `get_input()` is waiting on another awaitable, `ainput()`, which is scheduled.
    Control is handed back to the event loop, which runs the next scheduled task,
    `length_counter_task`. The `length_counter()` coroutine function is started, and
    it runs up to its `await` command before returning control to the event loop.
  prefs: []
  type: TYPE_NORMAL
- en: Perhaps the user hasn’t yet input anything—only a few milliseconds have passed,
    after all—so the event loop checks in with `main` and `guess_task`, which are
    both still waiting. The event loop again checks `length_counter_task`, which does
    some more work before pausing again. Then, the event loop checks back with `ainput`
    to see if the user has entered anything yet.
  prefs: []
  type: TYPE_NORMAL
- en: Execution continues in this manner until something finishes.
  prefs: []
  type: TYPE_NORMAL
- en: Bear in mind that `await` isn’t a magical keyword that *itself* returns control
    to the event loop. Rather, some non-trivial logic under the hood determines which
    task is run next, but I won’t go into that here, in the interests of time and
    sanity.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the `length_counter_task` has completed and is ready to return a value,
    the `await` in `main` is fulfilled, and that returned value is assigned to `count`.
    The next line in the `main()` coroutine function is run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: For the purposes of this example, suppose the `guess_task` isn’t done yet. The
    `main` task must wait some more, so it hands control back to the event loop, which
    now checks in on `guess_task`—still waiting—before checking on `ainput`. Notice
    it doesn’t need to check on `length_counter_task` anymore, as that task is completed.
  prefs: []
  type: TYPE_NORMAL
- en: Once the user enters something, `ainput` has a value to return. The event loop
    checks in with the still-waiting `main` task and then allows `guess_task` to store
    the returned value from its await in `n` and continue its execution. There are
    no more `await` statements in the `get_input()` coroutine function, so aside from
    the event loop looking in on the napping `main` task, `guess_task` is able to
    return a value. With its `await` fulfilled and no other tasks in the queue, `main`
    is given priority again, and it finishes up.
  prefs: []
  type: TYPE_NORMAL
- en: 'There’s an important rule here: the order in which concurrent tasks complete
    is never guaranteed! As you’ll see in the next chapter, this can lead to some
    interesting problems.'
  prefs: []
  type: TYPE_NORMAL
- en: Simplifying the Code
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'I can use the `asyncio.gather()` coroutine function instead of the prior method
    to run two tasks concurrently. This won’t change the functionality of the program
    at all from what I’m already doing, but it will make the code cleaner:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-16: *collatz_async.py:5b*'
  prefs: []
  type: TYPE_NORMAL
- en: I pass the awaitables I want to run to `asyncio.gather()` in the order I want
    their values returned. While `asyncio.gather()` will create and schedule tasks
    for all native coroutines passed to it, remember not to depend on the order in
    which tasks will be started and run. The return values from the native coroutines
    are packed into a list, which is then returned from `asyncio.gather()`. In this
    case, I unpack the two values from the list into `guess` and `count`. The outcome
    is the same as that of [Listing 16-11](#listing16-11).
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous Iteration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Iterators work with asynchrony much the same as functions do: only iterators
    marked as `async` support the pause-and-resume behavior. By default, looping on
    an iterator is blocking, unless there’s an explicit `await` somewhere in the suite.
    This particular feature of asynchrony has evolved quite a lot in the last several
    versions of Python and has only achieved some modicum of API stability in 3.7,
    so older code you may find will likely use outdated techniques.'
  prefs: []
  type: TYPE_NORMAL
- en: To demonstrate this behavior, I’ll rework my Collatz example to use an asynchronously
    iterable class, instead of a coroutine function. Understand that this technique
    is overpowered for this use case. In production code, I’d have stuck with the
    simpler native coroutine and saved the asynchronous iterator class for more complex
    logic.
  prefs: []
  type: TYPE_NORMAL
- en: 'All the new concepts below are part of the core Python language and not from
    `asyncio`. I start simply enough by creating a `Collatz` class, setting the bound
    and starting values as before:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-17: *collatz_aiter.py:1*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, I’ll write a new coroutine function that will contain all the logic for
    counting the steps in a single Collatz sequence. This really isn’t much of a coroutine
    function, as it lacks a `yield`, but this approach will be convenient for the
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-18: *collatz_aiter.py:2*'
  prefs: []
  type: TYPE_NORMAL
- en: For an object to be an ordinary, synchronous iterator, it needs to implement
    the special methods `__iter__()` and `__next__()`. Similarly, to be an *asynchronous
    iterator*, it must implement the special methods `__aiter__()` and `__anext__()`.
    You can define an *asynchronous iterable* in the same manner, by implementing
    `__aiter__()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, I define the two special methods necessary to make Collatz an asynchronous
    iterator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-19: *collatz_aiter.py:3*'
  prefs: []
  type: TYPE_NORMAL
- en: The `__aiter__()` method must return an asynchronous iterator object, which
    is just `self` in this case. You will notice that this method is not made awaitable
    with `async`. It must be directly callable.
  prefs: []
  type: TYPE_NORMAL
- en: The `__anext__()` special method has a couple of differences from `__next__()`.
    First and most importantly, it is marked `async`, making it awaitable. Otherwise,
    iterating over the iterator object would be blocking. Second, when there are no
    more values to iterate over, I raise `StopAsyncIteration`, instead of `StopIteration`,
    as with ordinary iterators.
  prefs: []
  type: TYPE_NORMAL
- en: In my `__anext__()` coroutine function, I also chose to include an `await` statement,
    which allows the coroutine function to pause if necessary and hand control back
    to the event loop. (Here, I really only do this to demonstrate that it’s possible,
    especially since asynchronous iterators are particularly useful when a single
    iterative step is time consuming. However, since the execution time of the coroutine
    function is so brief in this example, I could have omitted it, as the mere usage
    of the asynchronous iterator involves an `await` under the hood.)
  prefs: []
  type: TYPE_NORMAL
- en: 'In my `length_counter()` coroutine function, I must use an `async for` to iterate
    over the asynchronous iterator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-20: *collatz_aiter.py:4*'
  prefs: []
  type: TYPE_NORMAL
- en: The `async for` compound statement is specifically for iterating over an asynchronous
    iterator, which in this case is a `Collatz` instance ❶.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to understand what’s happening under the hood here, take a look
    at the equivalent logic for the `async for` loop in the context of this function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Notice the use of the `await` keyword when calling `__anext__()` on the iterator.
    An `async for` loop will hand control back to the event loop on each iteration,
    but if a single iteration were to take a long time, I’d need the additional `await`
    statements in the `__anext__()` coroutine function to keep it from blocking.
  prefs: []
  type: TYPE_NORMAL
- en: As for the rest of this version of my code, I’m reusing Listings 16-16 and 16-13\.
    The output and behavior are the same as before.
  prefs: []
  type: TYPE_NORMAL
- en: As I mentioned, asynchronous iterators are definitely overpowered for my Collatz
    example. Most of the time, asynchronous iterators are only useful if iteration
    is either IO-blocking or computationally heavy enough to justify some sort of
    progress indicator, or perhaps for concurrency with another IO-blocking task.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous Context Managers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Context managers must also be written in a specific way to have them work with
    asynchrony. An asynchronous context manager has the special coroutine functions
    `__aenter__()` and `__aexit__()`, instead of the usual `__enter__()` and `__exit__()`
    special methods. Typically, you’d only write an asynchronous context manager if
    you needed to await something in `__aenter__()` or `__aexit__()`, such as a network
    connection.
  prefs: []
  type: TYPE_NORMAL
- en: An asynchronous context manager is used with `async with`, instead of `with`,
    but using it is otherwise the same as working with a regular context manager.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous Generators
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can also create *asynchronous generators*, which are identical in all manners
    to ordinary generators (discussed in Chapter 10), except for being compatible
    with asynchrony. They were introduced in Python 3.6 via PEP 525.
  prefs: []
  type: TYPE_NORMAL
- en: You define an asynchronous generator with `async def` but use `yield` statements
    as with regular generators. As these generators are asynchronous, you can use
    `await`, `async for`, and `async with` in their suites as needed. When the asynchronous
    generator is called as normal (without `await`), it produces an *asynchronous
    generator iterator*, which can be used just as you would an asynchronous iterator.
  prefs: []
  type: TYPE_NORMAL
- en: Other Asynchrony Concepts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are quite a number of other tools in your asynchrony toolkit: locks,
    pools, events, futures, and the like. Most of these concepts are borrowed from
    the older and considerably better-documented technique of threading, which I’ll
    cover in Chapter 17. The main reason I’ve skipped over these concepts in this
    chapter is that the exact usage of each one varies between asynchrony modules.
    If you’ve done any amount of work in concurrency before, you’ve also noticed that
    I skipped some important problems, including race conditions and deadlocks. I’ll
    introduce these issues in the next chapter as well.'
  prefs: []
  type: TYPE_NORMAL
- en: One other advanced concept relating to asynchrony that you should be aware of
    is *context variables*, or `contextvars`. These allow you to store different values
    in variables depending on a context, meaning two different tasks can work with
    the same apparent variables but in fact retrieve entirely distinct values. If
    you want to learn more about context variables, see the official documentation
    at [https://docs.python.org/3/library/contextvars.xhtml](https://docs.python.org/3/library/contextvars.xhtml).
    (The analogous threading concept is *thread-local storage*, which I won’t cover
    in this book.)
  prefs: []
  type: TYPE_NORMAL
- en: Anyone considering a dive into asynchrony should push onward into the next chapter,
    as the same problems experienced in threading and traditional concurrency can
    creep into asynchronous programming. The exact solutions vary from one asynchrony
    library to the next and may even require a bit of trailblazing. If you want to
    excel at asynchrony, become comfortable with threading, even if you never plan
    on using threads in production.
  prefs: []
  type: TYPE_NORMAL
- en: Wrapping Up
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The distinction between concurrency and asynchrony can be bewildering at first,
    so here’s a quick recap. Concurrency improves your program’s perceived responsiveness
    by allowing the code to do something else while waiting on an IO-bound process.
    It does not make your code faster, and it thus isn’t useful for CPU-bound processes
    where the delays come from the code itself. Asynchrony is a relatively new way
    of achieving concurrency entirely within the code, without needing to resort to
    the more complex techniques.
  prefs: []
  type: TYPE_NORMAL
- en: In Python, asynchronous programming is achieved with the `async`/`await` model,
    which introduces two keywords. Roughly, `async` means, “This structure can be
    used asynchronously,” and `await` means, “I’m waiting for a value, so you can
    do something else now, if you like.” The `await` keyword can only be used inside
    of a native coroutine (also known as a coroutine function), which is a function
    declared with `async def`.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous programming primarily consists of writing native coroutines and
    either awaiting them with `await` or scheduling them as tasks. The order in which
    current tasks will complete is never guaranteed.
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, asynchrony relies on an event loop to manage the execution of native
    coroutines and concurrent tasks. The Python standard library includes `asyncio`
    for this purpose, although this module is sometimes considered quite complex and
    obtuse. There are some much more intuitive alternatives, especially Trio. Alternatively,
    you could write your own custom event loop that’s fit to your particular purpose,
    if you’re feeling brave.**
  prefs: []
  type: TYPE_NORMAL

<html><head></head><body>
<div id="sbo-rt-content"><h2 class="h2" id="ch02"><span epub:type="pagebreak" id="page_15"/><strong><span class="big">2</span><br/>THE TEXT-PROCESSING PIPELINE</strong></h2>&#13;
<div class="image1"><img src="../Images/comm1.jpg" alt="Image" width="191" height="191"/></div>&#13;
<p class="noindents">Now that you understand the structure of an NLP application, it’s time to see these underlying concepts in action. In this chapter, you’ll install spaCy and set up your working environment. Then you’ll learn about the <em>text-processing pipeline</em>, a series of basic NLP operations you’ll use to determine the meaning and intent of a discourse. These operations include tokenization, lemmatization, part-of-speech tagging, syntactic dependency parsing, and named entity recognition.</p>&#13;
<h3 class="h3" id="lev13"><span epub:type="pagebreak" id="page_16"/><strong>Setting Up Your Working Environment</strong></h3>&#13;
<p class="noindent">Before you start using spaCy, you need to set up a working environment by installing the following software components on your machine:</p>&#13;
<ul>&#13;
<li class="noindent">Python 2.7 or later, or 3.4 or later</li>&#13;
<li class="noindent">The spaCy library</li>&#13;
<li class="noindent">A statistical model for spaCy</li>&#13;
</ul>&#13;
<p class="indent">You’ll need Python 2.7 or later, or 3.4 or later to use spaCy v2.0.<em>x</em>. Download it at <em><a href="https://www.python.org/downloads/">https://www.python.org/downloads/</a></em> and follow the instructions to set up a Python environment. Next, install spaCy in your Python environment using <span class="literal">pip</span> by running the following command:</p>&#13;
<p class="programs">$ pip install spacy</p>&#13;
<p class="indent">If you have more than one Python installation on your system, select the <span class="literal">pip</span> executable associated with the Python installation you want to use. For instance, if you want to use spaCy with Python 3.5, you’d run the following command:</p>&#13;
<p class="programs">$ pip3.5 install spacy</p>&#13;
<p class="indent">If you already have spaCy installed on your system, you might want to upgrade it to a new release. The examples in this book assume you use spaCy v2.0.<em>x</em> or later. You can verify which version of spaCy you have installed with the following command:</p>&#13;
<p class="programs">$ python -m spacy info</p>&#13;
<p class="indent">Once again, you might need to replace the <span class="literal">python</span> command with the command for the python executable used in your particular environment, say,<span class="literal"> python3.5</span>. From now on, we’ll use <span class="literal">python</span> and <span class="literal">pip</span> regardless of the executables your system uses.</p>&#13;
<p class="indent">If you decide to upgrade your installed spaCy package to the latest version, you can do this using the following <span class="literal">pip</span> command:</p>&#13;
<p class="programs">$ pip install -U spacy</p>&#13;
<h3 class="h3" id="lev14"><strong>Installing Statistical Models for spaCy</strong></h3>&#13;
<p class="noindent">The spaCy installation doesn’t include statistical models that you’ll need when you start using the library. The statistical models contain knowledge collected about the particular language from a set of sources. You must separately download and install each model you want to use.</p>&#13;
<p class="indent">Several pretrained statistical models are available for different languages. For English, for example, the following models are available for <span epub:type="pagebreak" id="page_17"/>download from spaCy’s website: <span class="literal">en_core_web_sm</span>, <span class="literal">en_core_web_md</span>, <span class="literal">en_core_web_lg</span>, and <span class="literal">en_vectors_web_lg</span>. The models use the following naming convention: <em>lang_type_genre_size</em>. <em>Lang</em> specifies the language. <em>Type</em> indicates the model’s capabilities (for example, core is a general-purpose model that includes vocabulary, syntax, entities, and vectors). <em>Genre</em> indicates the type of text the model has been trained on: web (such as Wikipedia or similar media resources) or news (news articles). <em>Size</em> indicates how large the model is: <span class="literal">lg</span> is large, <span class="literal">md</span> is medium, and <span class="literal">sm</span> is small. The larger the model is, the more disk space it requires. For example, the <span class="literal">en_vectors_web_lg-2.1.0</span> model takes 631MB, whereas <span class="literal">en_core_web_sm-2.1.0</span> takes only 10MB.</p>&#13;
<p class="indent">To follow along with the examples provided in this book, <span class="literal">en_core_web_sm</span> (the most lightweight model) will work fine. spaCy will choose it by default when you use spaCy’s download command:</p>&#13;
<p class="programs">$ python -m spacy download en</p>&#13;
<p class="indent">The <span class="literal">en</span> shortcut link in the command instructs spaCy to download and install the best-matching default model for the English language. The best-matching model, in this context, means the one that is generated for the specified language (English in this example), a general purpose model, and the most lightweight.</p>&#13;
<p class="indent">To download a specific model, you must specify its name, like this:</p>&#13;
<p class="programs">$ python -m spacy download en_core_web_md</p>&#13;
<p class="indent">Once installed, you can load the model using this same shortcut you specified during the installation:</p>&#13;
<p class="programs">nlp = spacy.load('en')</p>&#13;
<h3 class="h3" id="lev15"><strong>Basic NLP Operations with spaCy</strong></h3>&#13;
<p class="noindent">Let’s begin by performing a chain of basic NLP operations that we call a processing pipeline. spaCy does all these operations for you behind the scenes, allowing you to concentrate on your application’s specific logic. <a href="../Text/ch02.xhtml#ch02fig01">Figure 2-1</a> provides a simplified depiction of this process.</p>&#13;
<div class="image"><a id="ch02fig01"/><img src="../Images/fig2-1.jpg" alt="image" width="692" height="164"/></div>&#13;
<p class="figcap"><em>Figure 2-1: A high-level view of the processing pipeline</em></p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_18"/>The processing pipeline typically includes tokenization, lemmatization, part-of-speech tagging, syntactic dependency parsing, and named entity recognition. We’ll introduce each of these tasks in this section.</p>&#13;
<h4 class="h4" id="lev16"><strong><em>Tokenization</em></strong></h4>&#13;
<p class="noindent">The very first action any NLP application typically performs on a text is parsing that text into <em>tokens</em>, which can be words, numbers, or punctuation marks. Tokenization is the first operation because all the other operations require you to have tokens already in place.</p>&#13;
<p class="indent">The following code shows the tokenization process:</p>&#13;
<p class="programs"><span class="ent">➊</span> import spacy<br/>&#13;
<span class="ent">➋</span> nlp = spacy.load('en') <br/>&#13;
<span class="ent">➌</span> doc = nlp(u'I am flying to Frisco')<br/>&#13;
<span class="ent">➍</span> print([w.text for w in doc])</p>&#13;
<p class="indent">We start by importing the spaCy library <span class="ent">➊</span> to gain access to its functionality. Then, we load a model package using the <span class="literal">en</span> shortcut link <span class="ent">➋</span> to create an instance of spaCy’s Language class. A Language object contains the language’s vocabulary and other data from the statistical model. We call the Language object <span class="literal">nlp</span>.</p>&#13;
<p class="indent">Next, we apply the object just created <span class="ent">➌</span> to a sample sentence, creating a <em>Doc object</em> instance. A Doc object is a container for a sequence of Token objects. spaCy generates it implicitly based on the text you provide it.</p>&#13;
<p class="indent">At this point, with just three lines of code, spaCy has generated the grammatical structure for the sample sentence. How you’ll use it is entirely up to you. In this very simple example, you just print out the <em>text content</em> of each token from the sample sentence <span class="ent">➍</span>.</p>&#13;
<p class="indent">The script outputs the sample sentence’s tokens as a list:</p>&#13;
<p class="programs">['I', 'am', 'flying', 'to', 'Frisco']</p>&#13;
<p class="indent">The <em>text content</em>—the group of characters that compose the token, such as the letters “a” and “m” in the token “am”—is just one of many properties of a Token object. You can also extract various linguistic features assigned to a token, as you’ll see in the following examples.</p>&#13;
<h4 class="h4" id="lev17"><strong><em>Lemmatization</em></strong></h4>&#13;
<p class="noindent">A <em>lemma</em> is the base form of a token. You can think of it as the form in which the token would appear if it were listed in a dictionary. For example, the lemma for the token “flying” is “fly.” <em>Lemmatization</em> is the process of reducing word forms to their lemma. The following script provides a simple example of how to do lemmatization with spaCy:</p>&#13;
<p class="programs">import spacy<br/>&#13;
nlp = spacy.load('en')<br/>&#13;
<span epub:type="pagebreak" id="page_19"/>doc = nlp(u'this product integrates both libraries for downloading and<br/>applying patches')<br/>&#13;
for token in doc:<br/>&#13;
  print(<span class="ent">➊</span>token.text, <span class="ent">➋</span>token.lemma_)</p>&#13;
<p class="indent">The first three lines in the script are the same as those in the previous script. Recall that they import the spaCy library, load an English model using the <span class="literal">en</span> shortcut and create a text-processing pipeline, and apply the pipeline to a sample sentence—creating a Doc object through which you can access the grammatical structure of the sentence.</p>&#13;
<div class="note">&#13;
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>&#13;
<p class="notep"><em>In grammar, sentence structure is the arrangement of individual words, as well as phrases and clauses in a sentence. The grammatical meaning of a sentence depends on this structural organization.</em></p>&#13;
</div>&#13;
<p class="indent">Once you have a Doc object containing the tokens from your example sentence, you iterate over those tokens in a loop, and then print out a token’s text content <span class="ent">➊</span> along with its corresponding lemma <span class="ent">➋</span>. This script produces the following output (I’ve tabulated it to make it more readable):</p>&#13;
<p class="programs">&#13;
this        this<br/>&#13;
product     product<br/>&#13;
integrates  integrate<br/>&#13;
both        both<br/>&#13;
libraries   library<br/>&#13;
for         for<br/>&#13;
downloading download<br/>&#13;
and         and<br/>&#13;
applying    apply<br/>&#13;
patches     patch</p>&#13;
<p class="indent">The column on the left contains the tokens, and the column on the right contains their lemmas.</p>&#13;
<h4 class="h4" id="lev18"><strong><em>Applying Lemmatization for Meaning Recognition</em></strong></h4>&#13;
<p class="noindent">Lemmatization is an important step in the task of meaning recognition. To see how, let’s return to the sample sentence from the previous section:</p>&#13;
<p class="programs">I am flying to Frisco.</p>&#13;
<p class="indent">Suppose this sentence was submitted to an NLP application interacting with an online system that provides an API for booking tickets for trips. The application processes a customer’s request, extracting necessary information from it and then passing on that information to the underlying API. This design might look like the one depicted in <a href="../Text/ch02.xhtml#ch02fig02">Figure 2-2</a>.</p>&#13;
<span epub:type="pagebreak" id="page_20"/>&#13;
<div class="image"><a id="ch02fig02"/><img src="../Images/fig2-2.jpg" alt="image" width="564" height="325"/></div>&#13;
<p class="figcap"><em>Figure 2-2: Using lemmatization in the process of extracting necessary information from a customer’s request</em></p>&#13;
<p class="indent">The NLP application tries to get the following information from a customer’s request: a form of travel (plane, rail, bus, and so on) and a destination. The application needs to first determine whether the customer wants an air ticket, a railway ticket, or a bus ticket. To determine this, the application searches for a word that matches one of the keywords in the predefined list. An easy way to simplify the search for these keywords is to first convert all the words in a sentence being processed to their lemmas. In that case, the predefined list of keywords will be much shorter and clearer. For example, you won’t need to include all the word forms of the word fly (such as “fly,” “flying,” “flew,” and “flown”) to serve as an indicator that the customer wants an air ticket, reducing all possible variants to the base form of the word—that is, “fly.”</p>&#13;
<p class="indent">Lemmatization also comes in handy when the application tries to determine a destination from a submitted request. There are a lot of nicknames for the globe’s cities. But the system that books the tickets requires official names. Of course, the default Tokenizer that performs lemmatization won’t know the difference between nicknames and official names for cities, countries, and so on. To solve this problem, you can add special case rules to an existing Tokenizer instance.</p>&#13;
<p class="indent">The following script illustrates how you might implement lemmatization for the destination cities example. It prints out the lemmas of the words composing the sentence.</p>&#13;
<p class="programs">   import spacy<br/>&#13;
   from spacy.symbols import ORTH, LEMMA<br/>&#13;
   nlp = spacy.load('en')<br/>&#13;
   doc = nlp(u'I am flying to Frisco')<br/>&#13;
   print([w.text for w in doc])<br/>&#13;
<span class="ent">➊</span> special_case = [{ORTH: u'Frisco', LEMMA: u'San Francisco'}]<br/>&#13;
<span class="ent">➋</span> nlp.tokenizer.add_special_case(u'Frisco', special_case)<br/>&#13;
<span class="ent">➌</span> print([w.lemma_ for w in nlp(u'I am flying to Frisco')])</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_21"/>You define a <em>special case</em> for the word <span class="literal">Frisco</span> <span class="ent">➊</span> by replacing its default lemma with <span class="literal">San Francisco</span>. Then you add this special case to the Tokenizer instance <span class="ent">➋</span>. Once added, the Tokenizer instance will use this special case each time it’s asked for the lemma of <span class="literal">Frisco</span>. To make sure that everything works as expected, you print out the lemmas of the words in the sentence <span class="ent">➌</span>.</p>&#13;
<p class="indent">The script generates the following output:</p>&#13;
<p class="programs">['I', 'am', 'flying', 'to', 'Frisco']<br/>&#13;
['-PRON-', 'be', 'fly', 'to', 'San Francisco']</p>&#13;
<p class="indent">The output lists the lemmas for all words occurring in the sentence with the exception of <span class="literal">Frisco</span>, for which it lists <span class="literal">San Francisco</span>.</p>&#13;
<h4 class="h4" id="lev19"><strong><em>Part-of-Speech Tagging</em></strong></h4>&#13;
<p class="noindent">A <em>part-of-speech tag</em> tells you the part-of-speech (noun, verb, and so on) of a given word in a given sentence. (Recall from <a href="../Text/ch01.xhtml#ch01">Chapter 1</a> that a word can act as more than one part of speech depending on the context in which it appears.)</p>&#13;
<p class="indent">In spaCy, part-of-speech tags can include detailed information about a token. In the case of verbs, they might tell you the following features: tense (past, present, or future), aspect (simple, progressive, or perfect), person (1st, 2nd, or 3rd), and number (singular or plural).</p>&#13;
<p class="indent">Extracting these verb part-of-speech tags can help identify a user’s intent when tokenization and lemmatization alone aren’t sufficient. For instance, the lemmatization script for the ticket booking application in the preceding section won’t decide how the NLP application chooses words in a sentence to compose a request to the underlying API. In a real situation, doing so might be quite complicated. For example, a customer’s request might consist of more than one sentence:</p>&#13;
<p class="programs">I have flown to LA. Now I am flying to Frisco.</p>&#13;
<p class="indent">For these sentences, the results of lemmatization would be as follows:</p>&#13;
<p class="programs">['-PRON-', 'have', 'fly', 'to', 'LA', '.', 'now', '-PRON-', 'be', 'fly', 'to', 'San Francisco', '.']</p>&#13;
<p class="indent">Performing lemmatization alone isn’t enough here; the application might consider the lemmas “fly” and “LA” from the first sentence as the keywords, indicating that the customer intends to fly to LA when in fact the customer intends to fly to San Francisco. Part of the problem is that lemmatization changes verbs to their infinitive forms, making it hard to know the role they play in a sentence.</p>&#13;
<p class="indent">This is where part-of-speech tags come into play. In English, the core parts of speech include noun, pronoun, determiner, adjective, verb, adverb, preposition, conjunction, and interjection. (See the linguistic primer in the appendix for more information about these parts of speech.) In spaCy, these same categories—plus some additional ones for symbols, punctuation <span epub:type="pagebreak" id="page_22"/>marks, and others—are called <em>coarse-grained parts of speech</em> and are available as a fixed set of tags through the <span class="literal">Token.pos</span> (int) and <span class="literal">Token.pos_</span> (unicode) attributes.</p>&#13;
<p class="indent">Also, spaCy offers <em>fine-grained parts of speech</em> tags that provide more detailed information about a token, covering morphological features, such as verb tenses and types of pronouns. Naturally, the list of fine-grained parts of speech contains many more tags than the coarse-grained list. The fine-grained part-of-speech tags are available as the <span class="literal">Token.tag</span> (int) and <span class="literal">Token.tag_</span> (unicode) attributes.</p>&#13;
<p class="indent"><a href="../Text/ch02.xhtml#ch02tab01">Table 2-1</a> lists some of the common part-of-speech tags used in spaCy for English models.</p>&#13;
<p class="tabcap" id="ch02tab01"><strong>Table 2-1:</strong> Some Common spaCy Part-of-Speech Tags</p>&#13;
<table class="topbot-d">&#13;
<colgroup>&#13;
<col style="width:30%"/>&#13;
<col style="width:30%"/>&#13;
<col style="width:30%"/>&#13;
<col style="width:30%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table-h"><p class="tab_th"><strong>TAG (fine-grained part of speech)</strong></p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-h"><p class="tab_th"><strong>POS (coarse-grained part of speech)</strong></p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-h"><p class="tab_th"><strong>Morphology</strong></p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-h"><p class="tab_th"><strong>Description</strong></p>&#13;
</td>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table-v"><p class="taba"><span class="literal">NN</span></p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-v"><p class="taba">NOUN</p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-v"><p class="taba">Number=sing</p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-v"><p class="taba">Noun, singular</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table-b"><p class="taba"><span class="literal">NNS</span></p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-b"><p class="taba">NOUN</p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-b"><p class="taba">Number=plur</p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-b"><p class="taba">Noun, plural</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table-v"><p class="taba"><span class="literal">PRP</span></p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-v"><p class="taba">PRON</p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-v"><p class="taba">PronType=prs</p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-v"><p class="taba">Pronoun, personal</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table-b"><p class="taba"><span class="literal">PRP$</span></p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-b"><p class="taba">PRON</p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-b"><p class="taba">PronType=prs<br/>Poss=yes</p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-b"><p class="taba">Pronoun, possessive</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table-v"><p class="taba"><span class="literal">VB</span></p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-v"><p class="taba">VERB</p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-v"><p class="taba">VerbForm=inf</p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-v"><p class="taba">Verb, base form</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table-b"><p class="taba"><span class="literal">VBD</span></p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-b"><p class="taba">VERB</p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-b"><p class="taba">VerbForm=fin<br/>Tense=past</p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-b"><p class="taba">Verb, past tense</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table-v"><p class="taba"><span class="literal">VBG</span></p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-v"><p class="taba">VERB</p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-v"><p class="taba">VerbForm=part<br/>Tense=pres<br/>Aspect=prog</p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-v"><p class="taba">Verb, gerund, or present participle</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table-b"><p class="taba"><span class="literal">JJ</span></p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-b"><p class="taba">ADJ</p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-b"><p class="taba">Degree=pos</p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-b"><p class="taba">Adjective</p>&#13;
</td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<div class="note">&#13;
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>&#13;
<p class="notep"><em>You can find the entire list of the fine-grained part-of-speech tags used in spaCy in the “<a href="../Text/ch02.xhtml#lev19">Part-of-Speech Tagging</a>” section in the Annotation Specifications manual at</em> <em><a href="https://spacy.io/api/annotation#pos-tagging">https://spacy.io/api/annotation#pos-tagging</a></em>.</p>&#13;
</div>&#13;
<p class="indent">Tense and aspect are perhaps the most interesting properties of verbs for NLP applications. Together, they indicate a verb’s reference to a position in time. For example, we use the <em>present tense progressive aspect</em> form of a verb to describe what is happening right now or what will happen in the near future. To form the present tense progressive aspect verb, you add the present tense form of the verb “to be” before an -ing verb. For example, in the sentence “I am looking into it,” you add “am”—the form of the verb “to be” in the first person, present tense—before the -ing verb “looking.” In this example, “am” indicates the present tense and “looking” points to the progressive aspect.</p>&#13;
<h4 class="h4" id="lev20"><span epub:type="pagebreak" id="page_23"/><strong><em>Using Part-of-Speech Tags to Find Relevant Verbs</em></strong></h4>&#13;
<p class="noindent">The ticket booking application could use the fine-grained part-of speech tags available in spaCy to filter the verbs in the discourse, choosing only those that could be key to determining the customer’s intent.</p>&#13;
<p class="indent">Before moving onto the code for this process, let’s try to figure out what kind of utterances a customer might use to express their intention to book a plane ticket to, say, LA. We could start by looking at some sentences that contain the following combination of lemmas: “fly”, “to”, and “LA”. Here are some simple options:</p>&#13;
<p class="programs">I flew to LA.<br/>&#13;
I have flown to LA.<br/>&#13;
I need to fly to LA.<br/>&#13;
I am flying to LA.<br/>&#13;
I will fly to LA.</p>&#13;
<p class="indent">Notice that although all of these sentences would include the “fly to LA” combination if reduced to lemmas, only some of them imply the customer’s intent to book a plane ticket to LA. The first two definitely aren’t suitable.</p>&#13;
<p class="indent">A quick analysis reveals that the past and past perfect forms of the verb “fly”—the tenses used in the first two sentences—don’t imply the intent we’re looking for. Only the infinitive and present progressive forms are suitable. The following script illustrates how to find those forms in the sample discourse:</p>&#13;
<p class="programs">import spacy<br/>&#13;
nlp = spacy.load('en')<br/>&#13;
doc = nlp(u'I have flown to LA. Now I am flying to Frisco.')<br/>&#13;
print([w.text for w in doc if <span class="ent">➊</span>w.tag_== <span class="ent">➋</span>'VBG' or w.tag_== <span class="ent">➌</span>'VB'])</p>&#13;
<p class="indent">The <span class="literal">tag_</span> property <span class="ent">➊</span> of a Token object contains the fine-grained part-of-speech attribute assigned to that object. You use a loop performed over the tokens composing the discourse to check whether the fine-grained part-of-speech tag assigned to a token is <span class="literal">VB</span> (a verb in the base, or infinitive, form) <span class="ent">➌</span> or <span class="literal">VBG</span> (a verb in the present progressive form) <span class="ent">➋</span>.</p>&#13;
<p class="indent">In the sample discourse, only the verb “flying” in the second sentence meets the specified condition. So you should see the following output:</p>&#13;
<p class="programs">['flying']</p>&#13;
<p class="indent">Of course, fine-grained part-of-speech tags aren’t only assigned to verbs; they’re also assigned to the other parts of speech in a sentence. For example, spaCy would recognize LA and Frisco as proper nouns—nouns that are the names of individuals, places, objects, or organizations—and tag them with <span class="literal">PROPN</span>. If you wanted, you could add the following line of code to the previous script:</p>&#13;
<p class="programs">print([w.text for w in doc if w.pos_ == 'PROPN'])</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_24"/>Adding that code should output the following list:</p>&#13;
<p class="programs">['LA', 'Frisco']</p>&#13;
<p class="indent">The proper nouns from both sentences of the sample discourse are in the list.</p>&#13;
<h4 class="h4" id="lev21"><strong><em>Context Is Important</em></strong></h4>&#13;
<p class="noindent">Fine-grained part-of-speech tags might not always be enough to determine an utterance’s meaning. For this, you might still need to rely on context. As an example, consider the following utterance: “I am flying to LA.” The part-of-speech tagger will assign the <span class="literal">VBG</span> tag to the verb “flying” in this example, because it’s in the present progressive form. But because we use this verb form to describe either what is happening right now or what will happen in the near future, the utterance might mean either “I’m already in the sky, flying to LA.” or “I’m going to fly to LA.” When submitted to the ticket booking NLP application, the application should interpret only one of these sentences as “I need an air ticket to LA.” Similarly, consider the following discourse: “I am flying to LA. In the evening, I have to be back in Frisco.” This most likely implies that the speaker wants an air ticket from LA to Frisco for an evening flight. You’ll find more examples about recognizing meaning based on context in “<a href="../Text/ch06.xhtml#lev85">Using Context to Improve the Ticket-Booking Chatbot</a>” on <a href="../Text/ch06.xhtml#page_91">page 91</a>.</p>&#13;
<h4 class="h4" id="lev22"><strong><em>Syntactic Relations</em></strong></h4>&#13;
<p class="noindent">Now let’s combine the proper nouns with the verb that the part-of-speech tagger selected earlier. Recall that the list of verbs you could potentially use to identify the intent of the discourse contains only the verb “flying” in the second sentence. How can you get the verb/proper noun pair that best describes the intent behind the discourse? A human would obviously compose the verb/proper noun pairs from words found in the same sentence. Because the verb “flown” in the first sentence doesn’t meet the condition specified (remember that only infinitive and present progressive forms meet the condition), you’d be able to compose such a pair for the second sentence only: “flying, Frisco.”</p>&#13;
<p class="indent">To handle these situations programmatically, spaCy features a syntactic dependency parser that discovers syntactic relations between individual tokens in a sentence and connects syntactically related pairs of words with a single arc.</p>&#13;
<p class="indent">Like lemmas and part-of-speech tags discussed in the previous sections, <em>syntactic dependency labels</em> are linguistic features that spaCy assigns to the Token objects that make up a text contained in a Doc object. For example, the dependency label <span class="literal">dobj</span> stands for “direct object.” We could illustrate the syntactic relation it represents as an arrow arc, as shown in <a href="../Text/ch02.xhtml#ch02fig03">Figure 2-3</a>.</p>&#13;
<span epub:type="pagebreak" id="page_25"/>&#13;
<div class="box5">&#13;
<p class="boxtitle-c"><strong>HEAD AND CHILD</strong></p>&#13;
<p class="noindent">A syntactic dependency label describes the type of syntactic relation between two words in a sentence. In such a pair, one word is the syntactic governor (also called the head or parent) and the other is the dependent (also called the child). spaCy assigns a syntactic dependency label to the pair’s dependent. For example, in the pair “need, ticket,” extracted from the sentence “I need a plane ticket,” the word “ticket” is the child and word “need” is the head, because “need” is the verb in what’s called a verb phrase. In this same sentence, “a plane ticket” is a noun phrase: the noun “ticket” is the head, and “a” and “plane” are its children. To learn more, consult “<a href="../Text/app01.xhtml#lev173">Dependency Grammars vs. Phrase Structure Grammars</a>” on <a href="../Text/app01.xhtml#page_185">page 185</a>.</p>&#13;
<p class="indent">Each word in a sentence has exactly one head. Consequently, a word can be a child only to one head. The opposite is not always the case. The same word can act as a head in none, one, or several pairs. The latter means that the head has several children. This explains why a dependency label is always assigned to the child. </p>&#13;
</div>&#13;
<div class="image"><a id="ch02fig03"/><img src="../Images/fig2-3.jpg" alt="image" width="332" height="246"/></div>&#13;
<p class="figcap"><em>Figure 2-3: A graphical representation of a syntactic dependency arc</em></p>&#13;
<p class="indent">The <span class="literal">dobj</span> label is assigned to the word “ticket” because it’s the child of the relation. A dependency label is always assigned to the child. In your script, you can determine the head of a relation using the <span class="literal">Token.head</span> attribute.</p>&#13;
<p class="indent">You might also want to look at the other head/child relations in the sentence, like the ones shown in <a href="../Text/ch02.xhtml#ch02fig04">Figure 2-4</a>.</p>&#13;
<div class="image"><a id="ch02fig04"/><img src="../Images/fig2-4.jpg" alt="image" width="373" height="116"/></div>&#13;
<p class="figcap"><em>Figure 2-4: Head/child relations in an entire sentence</em></p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_26"/>As you can see, the same word in a sentence can participate in several syntactic relations. <a href="../Text/ch02.xhtml#ch02tab02">Table 2-2</a> lists some of the most commonly used English dependency labels.</p>&#13;
<p class="tabcap" id="ch02tab02"><strong>Table 2-2:</strong> Some Common Dependency Labels</p>&#13;
<table class="topbot-d">&#13;
<colgroup>&#13;
<col style="width:30%"/>&#13;
<col style="width:30%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table-h"><p class="tab_th"><strong>Dependency label</strong></p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-h"><p class="tab_th"><strong>Description</strong></p>&#13;
</td>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table-v"><p class="taba"><span class="literal">acomp</span></p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-v"><p class="taba">Adjectival complement</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table-b"><p class="taba"><span class="literal">amod</span></p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-b"><p class="taba">Adjectival modifier</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table-v"><p class="taba"><span class="literal">aux</span></p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-v"><p class="taba">Auxiliary</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table-b"><p class="taba"><span class="literal">compound</span></p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-b"><p class="taba">Compound</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table-v"><p class="taba"><span class="literal">dative</span></p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-v"><p class="taba">Dative</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table-b"><p class="taba"><span class="literal">det</span></p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-b"><p class="taba">Determiner</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table-v"><p class="taba"><span class="literal">dobj</span></p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-v"><p class="taba">Direct object</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table-b"><p class="taba"><span class="literal">nsubj</span></p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-b"><p class="taba">Nominal subject</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table-v"><p class="taba"><span class="literal">pobj</span></p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-v"><p class="taba">Object of preposition</p>&#13;
</td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table-ba"><p class="taba"><span class="literal">ROOT</span></p>&#13;
</td>&#13;
<td style="vertical-align: top;" class="table-ba"><p class="taba">Root</p>&#13;
</td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="indent">The <span class="literal">ROOT</span> label marks the token whose head is itself. Typically, spaCy assigns it to the main verb of the sentence (the verb that is at the heart of the predicate). Every complete sentence should have a verb with the <span class="literal">ROOT</span> tag and a subject with the <span class="literal">nsubj</span> tag. The other elements are optional.</p>&#13;
<div class="note">&#13;
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>&#13;
<p class="notep"><em>Most of the examples in this book will assume that the submitted text is a complete sentence and use the <span class="literal">ROOT</span> tag to locate the sentence’s main verb. Keep in mind that this won’t work for every possible input.</em></p>&#13;
</div>&#13;
<p class="indent">The following script illustrates how to access the syntactic dependency labels of the tokens in the discourse from the example in “<a href="../Text/ch02.xhtml#lev19">Part-of-Speech Tagging</a>” on <a href="../Text/ch02.xhtml#page_21">page 21</a>:</p>&#13;
<p class="programs">import spacy<br/>&#13;
nlp = spacy.load('en')<br/>&#13;
doc = nlp(u'I have flown to LA. Now I am flying to Frisco.')<br/>&#13;
for token in doc:<br/>&#13;
  print(token.text, <span class="ent">➊</span>token.pos_, <span class="ent">➋</span>token.dep_)</p>&#13;
<p class="indent">The script outputs the coarse-grained part-of-speech tags <span class="ent">➊</span> (see <a href="../Text/ch02.xhtml#ch02tab01">Table 2-1</a>) and dependency labels assigned to the tokens <span class="ent">➋</span> composing the sample discourse:</p>&#13;
<p class="programs">&#13;
I      PRON   nsubj<br/>&#13;
have   VERB   aux<br/>&#13;
flown  VERB   ROOT<br/>&#13;
to     ADP    prep<br/>&#13;
<span epub:type="pagebreak" id="page_27"/>LA     PROPN  pobj<br/>&#13;
.      PUNCT  punct<br/>&#13;
Now    ADV    advmod<br/>&#13;
I      PRON   nsubj<br/>&#13;
am     VERB   aux<br/>&#13;
flying VERB   ROOT<br/>&#13;
to     ADP    prep<br/>&#13;
Frisco PROPN  pobj<br/>&#13;
.      PUNCT  punct</p>&#13;
<p class="indent">But what it doesn’t show you is how words are related to each other in a sentence by means of the commonly called <em>dependency arcs</em> explained at the beginning of this section. To look at the dependency arcs in the sample discourse, replace the loop in the preceding script with the following one:</p>&#13;
<p class="programs">for token in doc:<br/>&#13;
  print(<span class="ent">➊</span>token.head.text, token.dep_, token.text)</p>&#13;
<p class="indent">The head property of a token object <span class="ent">➊</span> refers to the syntactic head of this token. When you print this line, you’ll see how words in the discourse sentences are connected to each other by syntactic dependencies. If they were presented graphically, you would see an arc for each line in the following output, except for the <span class="literal">ROOT</span> relation. The reason is that the word to which this label is assigned is the only word in a sentence that doesn’t have a head:</p>&#13;
<p class="programs">&#13;
flown  nsubj  I<br/>&#13;
flown  aux    have<br/>&#13;
flown  ROOT   flown<br/>&#13;
flown  prep   to<br/>&#13;
to     pobj   LA<br/>&#13;
flown  punct  .<br/>&#13;
flying advmod Now<br/>&#13;
flying nsubj  I<br/>&#13;
flying aux    am<br/>&#13;
flying ROOT   flying<br/>&#13;
flying prep   to<br/>&#13;
to     pobj   Frisco<br/>&#13;
flying punct  .</p>&#13;
<p class="indent">Looking at the earlier list of syntactic dependencies, let’s try to figure out what labels point to the tokens that could potentially best describe the customer’s intent: in other words, you need to find a pair that would alone appropriately describe the customer’s intent.</p>&#13;
<p class="indent">You might be interested in the tokens marked with the <span class="literal">ROOT</span> and <span class="literal">pobj</span> dependency labels, because in this example they’re key in intent recognition. As stated earlier, the <span class="literal">ROOT</span> label marks the main verb of the sentence, and <span class="literal">pobj</span>, in this example, marks the entity that—in conjunction with the verb—summarizes the meaning of the entire utterance.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_28"/>The following script locates words that are assigned to those two dependency labels:</p>&#13;
<p class="programs">   import spacy<br/>&#13;
   nlp = spacy.load('en')<br/>&#13;
   doc = nlp(u'I have flown to LA. Now I am flying to Frisco.')<br/>&#13;
<span class="ent">➊</span> for sent in doc.sents:<br/>&#13;
  <span class="ent">➋</span> print([w.text for w in sent <span class="ent">➌</span>if w.dep_ == 'ROOT' or w.dep_ == 'pobj'])</p>&#13;
<p class="indent">In this script, you <em>shred the discourse</em> <span class="ent">➊</span> to separate the sentences with the <span class="literal">doc.sents</span> property, which iterates over the sentences in the document. Shredding a text into separate sentences can be useful when you need to find, for example, certain parts of speech in each sentence of the discourse. (We’ll discuss <span class="literal">doc.sents</span> in the next chapter, where you’ll see an example of how to refer to the tokens in a document with sentence-level indices.) This allows you to create a list of potential keywords for each sentence based on specific dependency labels assigned to the tokens <span class="ent">➋</span>. The filter conditions used in this example are chosen based on the examination of the syntactically related pairs generated by the previous script. In particular, you pick up the tokens with <span class="literal">ROOT</span> and <span class="literal">pobj</span> dependency labels <span class="ent">➌</span>, because these tokens form the pairs you’re interested in.</p>&#13;
<p class="indent">The script’s output should look as follows:</p>&#13;
<p class="programs">['flown', 'LA']<br/>&#13;
['flying', 'Frisco']</p>&#13;
<p class="indent">In both sentence pairs, the output nouns are the ones labeled as <span class="literal">pobj</span>. You could use this in your ticket booking application to choose the noun that best belongs with the verb. In this case, that would be “flying,” which goes with “Frisco.”</p>&#13;
<p class="indent">This is a simplified example of information extraction using dependency labels. In the following chapters, you’ll be given more sophisticated examples of how to iterate over the dependency tree of a sentence or even an entire discourse, extracting necessary pieces of information.</p>&#13;
<h4 class="h4" id="lev23"><strong><em>Try This</em></strong></h4>&#13;
<p class="noindent">Now that you know how to take advantage of lemmatization, part-of-speech tags, and syntactic dependency labels, you can put them all together to do something useful. Try combining the examples from the preceding sections into a single script that correctly identifies a speaker’s intent to fly to San Francisco.</p>&#13;
<p class="indent">Your script should generate the following output:</p>&#13;
<p class="programs"> ['fly', 'San Francisco']</p>&#13;
<p class="indent">To achieve this, start with the latest script from this section and enhance the conditional clause in the loop, adding the conditions to <span epub:type="pagebreak" id="page_29"/>account for fine-grained part-of-speech tags, as discussed in “<a href="../Text/ch02.xhtml#lev19">Part-of-Speech Tagging</a>” on <a href="../Text/ch02.xhtml#page_21">page 21</a>. Then add the lemmatization functionality to your script, as discussed in “<a href="../Text/ch02.xhtml#lev17">Lemmatization</a>” on <a href="../Text/ch02.xhtml#page_18">page 18</a>.</p>&#13;
<h4 class="h4" id="lev24"><strong><em>Named Entity Recognition</em></strong></h4>&#13;
<p class="noindent">A <em>named entity</em> is a real object that you can refer to by a proper name. It can be a person, organization, location, or other entity. Named entities are important in NLP because they reveal the place or organization the user is talking about. The following script finds named entities in the sample discourse used in the previous examples:</p>&#13;
<p class="programs"> import spacy<br/>&#13;
 nlp = spacy.load('en')<br/>&#13;
 doc = nlp(u'I have flown to LA. Now I am flying to Frisco.')<br/>&#13;
 for token in doc:<br/>&#13;
<span class="ent">➊</span> if token.ent_type != 0:<br/>&#13;
    print(token.text, <span class="ent">➋</span>token.ent_type_)</p>&#13;
<p class="indent">If the <span class="literal">ent_type</span> attribute of a token is not set to 0 <span class="ent">➊</span>, then the token is a named entity. If so, you print the <span class="literal">ent_type_</span> attribute of a token <span class="ent">➋</span>, which contains the type of named entity in unicode. As a result, the script should output the following:</p>&#13;
<p class="programs">LA     GPE<br/>&#13;
Frisco GPE</p>&#13;
<p class="indent">Both <span class="literal">LA</span> and <span class="literal">Frisco</span> are marked as <span class="literal">GPE</span>, the acronym for “geopolitical entity” and includes countries, cities, states, and other place names.</p>&#13;
<h3 class="h3" id="lev25"><strong>Summary</strong></h3>&#13;
<p class="noindent">In this chapter, you set up a working environment for using spaCy. Then you learned simple scripts that illustrate how to use spaCy’s features to perform the basic NLP operations for extracting important information. These operations included tokenization, lemmatization, and identifying syntactic relations between individual tokens in a sentence. The examples provided in this chapter are simplified and don’t reflect real-world scenarios. To write a more sophisticated script using spaCy, you’ll need to implement an algorithm to derive the necessary tokens from a dependency tree, using the linguistic features assigned to tokens. We’ll return to extracting and using linguistic features in <a href="../Text/ch04.xhtml#ch04">Chapter 4</a>, and we’ll cover dependency trees in detail in <a href="../Text/ch06.xhtml#ch06">Chapter 6</a>.</p>&#13;
<p class="indent">In the next chapter, you’ll look at the key objects of spaCy’s API, including containers and processing pipeline components. Also, you’ll learn to use spaCy’s C-level data structures and interfaces to create Python modules capable of processing large amounts of text.<span epub:type="pagebreak" id="page_30"/></p>&#13;
</div>&#13;
</body></html>
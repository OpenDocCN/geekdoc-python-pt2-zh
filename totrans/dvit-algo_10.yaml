- en: '11'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '11'
- en: Forging Ahead
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 继续前进
- en: '![](Images/circleart.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/circleart.png)'
- en: You’ve made it through the dark forest of searching and sorting, across the
    frozen river of esoteric mathematics, over the treacherous mountain passes of
    gradient ascent, past the swamp of geometric despair, and you’ve conquered the
    dragon of slow runtimes. Congratulations. If you wish, you’re free to return to
    your comfortable home in a land free from algorithms. This chapter is for those
    who instead wish to continue the adventure after they close this book.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经穿越了搜索与排序的黑暗森林，越过了深奥数学的冰冻河流，攀越了梯度上升的危险山口，越过了几何绝望的沼泽，征服了慢运行时间的巨龙。恭喜你。如果你愿意，你可以回到你那无算法的舒适家园。本章是为那些希望在合上这本书后继续冒险的人准备的。
- en: 'No single book can contain everything about algorithms. There is too much to
    know, and more is being discovered all the time. This chapter is about three things:
    doing more with algorithms, using them in better and faster ways, and solving
    their deepest mysteries.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 没有一本书能够涵盖关于算法的所有内容。要了解的东西实在太多了，而且新的知识不断被发现。本章内容涉及三件事：用算法做更多的事情，利用算法更好更快地完成任务，以及解决算法的深层次谜题。
- en: In this chapter, we’ll build a simple chatbot that can talk to us about previous
    chapters of the book. Then we’ll discuss some of the hardest problems in the world
    and how we might make progress toward crafting algorithms to solve them. We’ll
    conclude by discussing some of the deepest mysteries of the world of algorithms,
    including detailed instructions on how to win a million dollars with advanced
    algorithmic theory.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将构建一个简单的聊天机器人，它能够与我们讨论书中的前几章内容。接着，我们将讨论一些世界上最困难的问题，以及我们如何向着制定解决这些问题的算法迈进。最后，我们将讨论一些算法世界中最深奥的谜题，包括如何通过高级算法理论赢得百万美元的详细说明。
- en: Doing More with Algorithms
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用算法做更多的事情
- en: The 10 previous chapters of this book covered algorithms that can perform a
    variety of tasks in many fields. But algorithms can do even more than we’ve seen
    here. If you wish to continue your adventure with algorithms, you should explore
    other fields and the important algorithms associated with them.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的前10章介绍了可以执行多种任务的算法，涵盖了多个领域。但算法能做的事情远不止我们在这里看到的。如果你希望继续你的算法冒险之旅，你应该探索其他领域及其相关的重要算法。
- en: For example, the many algorithms for information compression can store a long
    book in a coded form that is only a fraction of the size of the original, and
    they can compress a complex photograph or film file into a manageable size with
    either minimal or no loss of quality.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，许多信息压缩算法可以将一本长书存储为一种编码形式，其大小仅为原书的一个小部分，它们还能将复杂的照片或电影文件压缩成可管理的大小，且几乎不损失质量，甚至完全不损失质量。
- en: Our ability to communicate securely online, including confidently passing our
    credit card information to third parties, relies on cryptographic algorithms.
    Cryptography is great fun to study because it comes with a thrilling history of
    adventurers, spies, betrayals, and triumphant nerds who broke codes to win wars.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在线上安全沟通的能力，包括自信地将我们的信用卡信息传递给第三方，依赖于加密算法。学习密码学非常有趣，因为它伴随着一段惊险的历史，涉及冒险家、间谍、背叛者，以及那些通过破译密码来赢得战争的英雄书呆子。
- en: Recently, innovative algorithms have been developed to perform parallel distributed
    computing. Instead of performing one operation at a time, millions of times, distributed
    computing algorithms split up a dataset into many little parts and then send them
    to different computers, which perform the needed operation simultaneously and
    return the results, to be recompiled and presented as the final output. By working
    on all parts of the data concurrently instead of consecutively, parallel computing
    saves a huge amount of time. This is extremely useful for applications in machine
    learning, where there’s a need to process datasets that are extremely large or
    to perform a large number of simple computations simultaneously.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，创新的算法被开发出来用于执行并行分布式计算。与一次性执行一个操作、重复数百万次不同，分布式计算算法将一个数据集拆分成多个小部分，然后将它们发送到不同的计算机上，计算机同时执行所需操作并返回结果，结果再被重新组合并呈现为最终输出。通过并行处理数据的所有部分，而不是依次处理，並行计算节省了大量的时间。这对于机器学习中的应用非常有用，因为机器学习需要处理极其庞大的数据集，或者需要同时执行大量的简单计算。
- en: For decades, people have been excited about the potential of quantum computing.
    Quantum computers, if we can engineer them to work properly, have the potential
    to perform extremely difficult calculations (including the calculations needed
    to break state-of-the-art cryptography) in a tiny fraction of the time required
    on today’s nonquantum supercomputers. Since quantum computers are built with different
    architecture than standard computers, it’s possible to design new algorithms that
    take advantage of their different physical properties to perform tasks with extra
    speed. For now, this is more or less only an academic concern, since quantum computers
    are not yet in a state where they are used for practical purposes. But if the
    technology ever matures, quantum algorithms could become extremely important.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 几十年来，人们一直对量子计算的潜力感到兴奋。如果我们能将量子计算机工程化，使其正常工作，它们有潜力在今天的非量子超级计算机所需时间的极短时间内执行极其困难的计算（包括破解最先进加密技术所需的计算）。由于量子计算机与标准计算机的架构不同，因此有可能设计出新的算法，利用它们不同的物理特性，以更高的速度执行任务。目前，这更像是一个学术问题，因为量子计算机还没有进入可用于实际目的的状态。但如果技术成熟，量子算法可能会变得极为重要。
- en: When you learn about algorithms in these or many other fields, you will not
    be starting from scratch. By mastering the algorithms of this book, you’ve come
    to grasp they are, how they tend to function, and how to write code for them.
    Learning your first algorithm may have felt quite difficult, but learning your
    50th or 200th will be much easier, since your brain will be used to the general
    patterns of how they are constructed and how to think about them.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 当你学习这些或其他许多领域的算法时，你不会从零开始。通过掌握本书的算法，你已经了解它们是什么，它们的功能倾向以及如何为它们编写代码。学习第一个算法可能会感觉非常困难，但学习第50个或第200个算法会容易得多，因为你的大脑已经习惯了它们的构造模式和思考方式。
- en: To prove that you can now understand and code algorithms, we’ll explore a few
    algorithms that work together to provide the functionality of a chatbot. If you
    can pick up how they work and how to write code for them in the short introduction
    provided here, then you’re on your way to being able to pick up how any algorithm
    works in any field.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为了证明你现在能够理解并编写算法，我们将探索几个共同工作的算法，提供聊天机器人的功能。如果你能够理解它们如何工作，以及如何为它们编写代码，那么你就能在任何领域掌握任何算法的工作原理。
- en: Building a Chatbot
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建一个聊天机器人
- en: 'Let’s build a simple chatbot that can answer questions about the table of contents
    of this book. We’ll start by importing modules that will be important later:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们构建一个简单的聊天机器人，可以回答有关本书目录的问题。我们将首先导入一些稍后会用到的模块：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The next step we’ll take to create our chatbot is *text normalization*, the
    process of converting natural language text to standardized substrings; it enables
    easy comparison between superficially different texts. We want our bot to understand
    that *America* and *america* refer to the same thing, that *regeneration* expresses
    the same idea as *regenerate* (albeit a different part of speech), that *centuries*
    is the plural of *century*, and that *hello;* is not essentially different from
    *hello*. We want our chatbot to treat in the same way words that are from the
    same root, unless there is some reason not to.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 创建聊天机器人的下一步是进行*文本规范化*，即将自然语言文本转换为标准化子字符串的过程；它使得表面上不同的文本之间可以轻松进行比较。我们希望我们的机器人理解，*America*和*america*指的是同一件事，*regeneration*与*regenerate*表达的是相同的思想（尽管词性不同），*centuries*是*century*的复数形式，而且*hello;*本质上与*hello*没有什么不同。我们希望我们的聊天机器人对同根词汇进行相同的处理，除非有某些特殊原因。
- en: 'Say we have the following query:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有以下查询：
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The first thing we can do is convert all characters to lowercase. Python’s
    built-in `lower()` method accomplishes this:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们能做的第一件事是将所有字符转换为小写。Python的内置`lower()`方法可以完成这个任务：
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This outputs `i want to learn about geometry algorithms`.. Another thing we
    can do is remove punctuation. To do that, first we’ll create a Python object called
    a *dictionary*:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这将输出`i want to learn about geometry algorithms`。我们还可以做的另一件事是去除标点符号。为了做到这一点，首先我们将创建一个名为*字典*的Python对象：
- en: '[PRE3]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This snippet creates a dictionary that maps every standard punctuation mark
    to the Python object `None`, and it stores the dictionary in a variable called
    `remove_punctuation_map`. We then use this dictionary to remove punctuation like
    so:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这个代码片段创建了一个字典，将每个标准标点符号映射到Python对象`None`，并将字典存储在名为`remove_punctuation_map`的变量中。我们然后使用这个字典像这样去除标点：
- en: '[PRE4]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Here, we’ve used the `translate()` method to take all the punctuation marks
    we find in the query and replace them with nothing—or in other words, remove the
    punctuation marks. The output we get is the same as we saw before—`i want to learn
    about geometry algorithms`—but without the period at the end. Next, we can perform
    *tokenization*, which converts a text string to a list of coherent substrings:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用了`translate()`方法，将查询中找到的所有标点符号替换为空—换句话说，移除标点符号。我们得到的输出与之前看到的一样—`i want
    to learn about geometry algorithms`—但没有结尾的句号。接下来，我们可以执行*分词*，将文本字符串转换为一组连贯的子字符串：
- en: '[PRE5]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We used the `nltk`’s tokenization function to accomplish this, yielding this
    output: `[''i'', ''want'', ''to'', ''learn'', ''about'', ''geometry'', ''algorithms'']`.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了`nltk`的分词函数来实现这个功能，得到了如下输出：`['i', 'want', 'to', 'learn', 'about', 'geometry',
    'algorithms']`。
- en: 'Now we can do what’s called *stemming*. In English, we use the words *jump*,
    *jumps*, *jumping*, *jumped*, and other derived forms that are all different but
    share a *stem*:the verb *jump*. We don’t want our chatbot to be distracted by
    small differences in word derivation; we want to consider a sentence about jumping
    to be comparable to a sentence about a jumper, even though they are technically
    different words. Stemming removes the ends of derived words to convert them into
    standardized word stems. A function for stemming is available in Python’s `nltk`
    module, and we can use this function with a list comprehension as follows:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以进行所谓的*词干提取*。在英语中，我们使用单词*jump*、*jumps*、*jumping*、*jumped*和其他派生形式，它们虽然不同，但共享一个*词干*：动词*jump*。我们不希望我们的聊天机器人被词形变化的小差异分心；我们希望把关于跳跃的句子和关于跳高者的句子看作是相似的，尽管它们在技术上是不同的单词。词干提取会去掉派生词的结尾部分，将其转换为标准化的词干。Python的`nltk`模块中提供了词干提取的函数，我们可以通过列表推导式来使用这个函数，如下所示：
- en: '[PRE6]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'In this snippet, we’ve created a function called `stem_tokens()`. It takes
    a list of tokens and calls `nltk`’s `stemmer.stem()` function to turn them into
    stems:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个代码片段中，我们创建了一个名为`stem_tokens()`的函数。它接受一个标记（tokens）列表，并调用`nltk`的`stemmer.stem()`函数将它们转换为词干：
- en: '[PRE7]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The output is `[''i'', ''want'', ''to'', ''learn'', ''about'', ''geometri'',
    ''algorithm'']`. Our stemmer has converted *algorithms* to *algorithm* and *geometry*
    to *geometri*. It has replaced a word with what it regards as its stem: a singular
    word or word portion that will make text comparisons easier. Finally, we put our
    normalization steps together in one function, `normalize()`:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果是`['i', 'want', 'to', 'learn', 'about', 'geometri', 'algorithm']`。我们的词干提取器将*algorithms*转换为*algorithm*，将*geometry*转换为*geometri*。它用它认为的词干替换了单词：一个单数单词或词部分，便于文本比较。最后，我们将所有的标准化步骤合并在一个函数`normalize()`中：
- en: '[PRE8]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Text Vectorization
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 文本向量化
- en: Now you’re ready to learn how to convert texts to numeric vectors. It’s easier
    to make quantitative comparisons between numbers and vectors than between words,
    and we’ll need to make quantitative comparisons to make our chatbot work.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经准备好学习如何将文本转换为数字向量了。与单词相比，数字和向量之间的定量比较要容易得多，而我们将需要进行定量比较来让我们的聊天机器人正常工作。
- en: We’ll use a simple method called *TFIDF*,or *term frequency-inverse document
    frequency,* which converts documents into numeric vectors. Each document vector
    has one element for each term in a corpus. Each element is the product of the
    term frequency for a given term (a raw count of the number of times the term occurs
    in a particular document) and the inverse document frequency for a given term
    (a logarithm of a reciprocal of what proportion of documents the term appears
    in).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一种简单的方法，叫做*TFIDF*，即*词频-逆文档频率*，它将文档转换为数字向量。每个文档向量都有一个元素对应语料库中的每个词项。每个元素是给定词项的词频（即某个词在特定文档中出现的次数）和逆文档频率（即该词出现在文档中比例的倒数的对数）的乘积。
- en: 'For example, imagine that we are creating TFIDF vectors for biographies of
    US presidents. In the context of creating TFIDF vectors, we’ll refer to each biography
    as a document. In the biography of Abraham Lincoln, the word *representative*
    will probably appear at least once, since he served in the Illinois House of Representatives
    and the US House of Representatives. If *representative* appears three times in
    the biography, then we say its term frequency is 3\. More than a dozen presidents
    have served in the US House of Representatives, so maybe about 20 out of 44 total
    presidential biographies contain the term *representative*. We can then calculate
    the inverse document frequency as:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们正在为美国总统的传记创建TFIDF向量。在创建TFIDF向量的过程中，我们将每篇传记视作一个文档。在亚伯拉罕·林肯的传记中，词语*representative*可能至少出现一次，因为他曾在伊利诺伊州众议院和美国众议院任职。如果*representative*在传记中出现了三次，那么我们说它的词频是3。美国众议院曾有十几位总统任职，所以大约在44位总统的传记中，有20篇包含了词语*representative*。我们可以通过以下方式计算逆文档频率：
- en: '![c11eq001](Images/c11eq001.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![c11eq001](Images/c11eq001.png)'
- en: 'The final value we’re looking for is the term frequency times the inverse document
    frequency: 3 × 0.788 = 2.365\. Now consider the term *Gettysburg*. It may appear
    twice in Lincoln’s biography but never in any other, so the term frequency will
    be 2 and the inverse document frequency will be the following:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要找的最终值是词频乘以逆文档频率：3 × 0.788 = 2.365。现在考虑词语*Gettysburg*。它可能在林肯的传记中出现了两次，但在其他任何传记中都没有出现，因此词频将是2，逆文档频率将是：
- en: '![c11eq002](Images/c11eq002.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![c11eq002](Images/c11eq002.png)'
- en: The vector element associated with *Gettysburg* will be the term frequency times
    the inverse document frequency, which is 2 × 3.784 = 7.568\. The TFIDF value for
    each term should reflect its importance in a document. Soon, this will be important
    for our chatbot’s ability to determine user intent.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 与*Gettysburg*相关的向量元素将是词频乘以逆文档频率，即2 × 3.784 = 7.568。每个术语的TFIDF值应该反映它在文档中的重要性。很快，这对于我们的聊天机器人理解用户意图将变得至关重要。
- en: 'We don’t have to calculate TFIDF manually. We can use a function from the `scikit-learn`
    module:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不需要手动计算TFIDF。我们可以使用`scikit-learn`模块中的一个函数：
- en: '[PRE9]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This line has created a `TfidfVectorizer()` function, which is capable of creating
    TFIDF vectors from sets of documents. To create the vectorizer, we have to specify
    an `ngram_range`. This tells the vectorizer what to treat as a term. We specified
    `(1, 1)`, meaning that our vectorizer will treat only 1-grams (individual words)
    as terms. If we had specified `(1, 3)`, it would treat 1-grams (single words),
    2-grams (two-word phrases), and 3-grams (three-word phrases) as terms and create
    a TFIDF element for each of them. We also specified a `tokenizer`, for which we
    specified the `normalize()` function we created before. Finally, we have to specify
    `stop_words`, the words that we want to filter out because they’re not informative.
    In English, stop words include *the*, *and*, *of*, and other extremely common
    words. By specifying `stop_words = 'english'`, we’re telling our vectorizer to
    filter out the built-in set of English stop words and vectorize only less common,
    more informative words.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这一行创建了一个`TfidfVectorizer()`函数，它能够从文档集合中创建TFIDF向量。为了创建向量化器，我们需要指定一个`ngram_range`。这个参数告诉向量化器什么应该被视作一个术语。我们指定了`(1,
    1)`，这意味着我们的向量化器将只把1-gram（单个词）视作术语。如果我们指定`(1, 3)`，它将把1-gram（单个词）、2-gram（两词短语）和3-gram（三词短语）都视作术语，并为每个术语创建一个TFIDF元素。我们还指定了一个`tokenizer`，并且指定了我们之前创建的`normalize()`函数。最后，我们需要指定`stop_words`，即我们想要过滤掉的、没有信息量的词。在英语中，停用词包括*the*、*and*、*of*以及其他一些非常常见的词。通过指定`stop_words
    = 'english'`，我们告诉向量化器过滤掉内建的英语停用词集合，只对不太常见、信息量较大的词进行向量化。
- en: Now, let’s configure what our chatbot will be able to talk about. Here, it will
    be able to talk about the chapters of this book, so we’ll create a list that contains
    very simple descriptions of each chapter. In this context, each string will be
    one of our *documents*.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们配置一下我们的聊天机器人能讨论的内容。在这里，它将能够讨论本书的章节，因此我们将创建一个包含每个章节简单描述的列表。在这个上下文中，每个字符串将是我们一个*文档*。
- en: '[PRE10]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We’ll continue by *fitting* our TFIDF vectorizer to these chapter descriptions,
    which will do the document processing to get us ready to create TFIDF vectors
    whenever we wish. We don’t have to do this manually, since there’s a `fit()` method
    defined in the `scikit-learn` module:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将继续通过*拟合*我们的TFIDF向量器到这些章节描述，这将处理文档，使我们随时准备创建TFIDF向量。我们不需要手动完成这个过程，因为在`scikit-learn`模块中定义了一个`fit()`方法：
- en: '[PRE11]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now, we’ll create TFIDF vectors for our chapter descriptions and for a new
    query asking for a chapter about sorting and searching:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将为章节描述和一个新的查询创建TFIDF向量，查询要求关于排序和搜索的章节：
- en: '[PRE12]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Our new query is a natural English language text about searching. The next two
    lines use the built-in `translate()` and `todense()` methods to create the TFIDF
    vectors for the chapter descriptions and the query.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的新查询是关于搜索的自然英语文本。接下来的两行使用内置的`translate()`和`todense()`方法创建章节描述和查询的TFIDF向量。
- en: Now we have converted our chapter descriptions and query into numeric TFIDF
    vectors. Our simple chatbot will work by comparing the query TFIDF vector to the
    chapter description TFIDF vectors, concluding that the chapter the user is looking
    for is the one whose description vector most closely matches the query vector.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已将章节描述和查询转换为数字TFIDF向量。我们的简单聊天机器人将通过将查询的TFIDF向量与章节描述的TFIDF向量进行比较，得出用户正在寻找的章节是描述向量与查询向量最为接近的章节。
- en: Vector Similarity
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 向量相似度
- en: We’ll decide whether any two vectors are similar with a method called *cosine
    similarity*. If you’ve studied a lot of geometry, you’ll know that for any two
    numeric vectors, we can calculate the angle between them. The rules of geometry
    enable us to calculate angles between vectors not only in two and three dimensions,
    but also in four, five, or any number of dimensions. If the vectors are very similar
    to each other, the angle between them will be quite small. If the vectors are
    very different, the angle will be large. It’s strange to think that we can compare
    English language texts by finding the “angle” between them, but this is precisely
    why we created our numeric TFIDF vectors—so that we can use numeric tools like
    angle comparison for data that doesn’t start out numeric.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过一个名为*余弦相似度*的方法决定两个向量是否相似。如果你学过很多几何学，你会知道，对于任何两个数值向量，我们可以计算它们之间的角度。几何规则使我们能够计算向量之间的角度，不仅仅是在二维和三维空间中，还可以在四维、五维或任意维度中。如果向量之间非常相似，它们之间的角度将非常小。如果向量之间非常不同，角度将很大。很难想象我们可以通过计算“角度”来比较英文文本，但这正是我们创建数字TFIDF向量的原因——这样我们就可以使用像角度比较这样的数值工具来处理本来不是数值的文本数据。
- en: 'In practice, it’s easier to calculate the cosine of the angle between two vectors
    than it is to calculate the angle itself. This is not a problem, since we can
    conclude that if the cosine of the angle between two vectors is large, then the
    angle itself is small and vice versa. In Python the `scipy` module contains a
    submodule called `spatial`, which contains a function for calculating the cosines
    of angles between vectors. We can use the functionality in `spatial` to calculate
    cosines between each chapter description vector and query vector, by using a list
    comprehension:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，计算两个向量之间角度的余弦比计算角度本身更容易。这不是问题，因为我们可以得出结论，如果两个向量之间角度的余弦值很大，那么角度本身很小，反之亦然。在Python中，`scipy`模块包含一个名为`spatial`的子模块，里面有一个计算向量之间角度余弦的函数。我们可以使用`spatial`中的功能，通过列表推导计算每个章节描述向量和查询向量之间的余弦：
- en: '[PRE13]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'When we print out the `row_similarities` variable, we see the following vector:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们打印出`row_similarities`变量时，我们看到以下向量：
- en: '[PRE14]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'In this case, only the fourth element is greater than zero, meaning that only
    the fourth chapter description vector has any angular proximity to our query vector.
    In general, we can automatically find which row has the highest cosine similarity:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，只有第四个元素大于零，意味着只有第四个章节描述向量与我们的查询向量有任何角度接近。通常，我们可以自动找出哪个行的余弦相似度最高：
- en: '[PRE15]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This gives us the chapter the chatbot thinks we’re looking for:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这给出了聊天机器人认为我们在寻找的章节：
- en: '[PRE16]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[Listing 11-1](#listing11-1) puts the chatbot’s simple functionality into a
    function.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表 11-1](#listing11-1) 将聊天机器人的简单功能放入一个函数中。'
- en: '[PRE17]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[Listing 11-1:](#listinganchor11-1) A simple chatbot function that takes a
    query and returns the document that’s most similar to it'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表 11-1:](#listinganchor11-1) 一个简单的聊天机器人功能，接受查询并返回与之最相似的文档'
- en: '[Listing 11-1](#listing11-1) does not contain anything new; all of it is code
    that we’ve seen before. Now we can call the chatbot with a query about where to
    find something:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[Listing 11-1](#listing11-1)并没有包含任何新内容；所有的代码我们之前都已经见过。现在我们可以使用聊天机器人进行查询，询问在哪里可以找到某些内容：'
- en: '[PRE18]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The output will tell us to go to Chapter 5:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将告诉我们去第5章：
- en: '[PRE19]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Now that you’ve seen how the whole chatbot works, you can understand why we
    needed to do the normalization and vectorization. By normalizing and stemming
    words, we can make sure that the term *mathematics* will prompt the bot to return
    the Chapter 5 description, even though that exact word does not appear in it.
    By vectorizing, we enable the cosine similarity metric that tells us which chapter
    description is the best match.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经看到了整个聊天机器人的工作原理，你可以理解为什么我们需要进行归一化和向量化。通过归一化和词干提取，我们可以确保“mathematics”这个词会促使机器人返回第5章的描述，即使该词并未直接出现在其中。通过向量化，我们启用了余弦相似性度量，它告诉我们哪一章的描述最匹配。
- en: We’ve completed our chatbot, which required stitching together a few different
    smallish algorithms (algorithms for normalizing, stemming, and numerically vectorizing
    text; an algorithm for calculating cosines of angles between vectors; and the
    overarching algorithm of providing chatbot answers based on query/document vector
    similarity). You may have noticed that we didn’t manually do many of the calculations—the
    actual calculation of TFIDF or cosines was done by modules that we imported. In
    practice, you often don’t need to truly understand the guts of an algorithm in
    order to import it and use it in your programs. This can be a blessing, in that
    it can accelerate our work and put amazingly sophisticated tools at our command
    when we need them. It can also be a curse because it causes people to misuse algorithms
    they don’t understand; for example, an article in *Wired* magazine claimed that
    the misapplication of a particular financial algorithm (a method to use Gaussian
    copula functions to predict risks) was responsible for “kill[ing] Wall Street”
    and “swallow[ing] up trillions of dollars” and was a major cause of the Great
    Recession (*[https://www.wired.com/2009/02/wp-quant/](https://www.wired.com/2009/02/wp-quant/)*).
    I encourage you to study the deep theory of algorithms even when the ease of importing
    a Python module makes such study seem unnecessary; it can always make you a better
    academic or practitioner.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经完成了我们的聊天机器人，它需要将几个不同的小型算法结合在一起（用于文本归一化、词干提取和数值化向量化的算法；用于计算向量之间夹角余弦的算法；以及基于查询/文档向量相似性提供聊天机器人回答的总体算法）。你可能已经注意到，我们并没有手动做很多计算——实际上，TFIDF或余弦的计算是由我们导入的模块完成的。在实践中，你通常不需要真正理解一个算法的内部实现就可以导入它并在你的程序中使用。这有时是个福音，因为它可以加速我们的工作，并在需要时提供令人惊叹的复杂工具供我们使用。但它也可能是一个诅咒，因为它会导致人们误用他们不了解的算法；例如，《Wired》杂志中的一篇文章称，某个特定金融算法（使用高斯copula函数预测风险的方法）的误用导致了“摧毁华尔街”和“吞噬数万亿美元”，并且是大衰退的主要原因之一（*
    [https://www.wired.com/2009/02/wp-quant/](https://www.wired.com/2009/02/wp-quant/)*）。我鼓励你研究算法的深层理论，即使导入Python模块的便利性让这种研究看起来似乎不必要；这总能让你成为一个更好的学者或实践者。
- en: 'This is perhaps the simplest possible chatbot, and it answers only questions
    related to chapters in this book. You could add so many enhancements to improve
    it: make the chapter descriptions more specific and thus more likely to match
    a broad range of queries; find a vectorization method that performs better than
    TFIDF; add more documents so that it could answer more queries. But although our
    chatbot is not the most advanced, we can be proud of it because it’s ours and
    because we built it ourselves. If you can comfortably build a chatbot, you can
    consider yourself a competent designer and implementer of algorithms—congratulations
    for this culminating achievement in your journey through this book.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能是最简单的聊天机器人，它只回答与本书章节相关的问题。你可以为它添加许多增强功能来改进它：使章节描述更具体，从而更容易匹配广泛的查询；找到一个比TFIDF表现更好的向量化方法；添加更多文档，让它能够回答更多问题。但是，尽管我们的聊天机器人不是最先进的，我们依然可以为它感到骄傲，因为它是我们的，并且是我们自己构建的。如果你能轻松地构建一个聊天机器人，你可以认为自己是一个合格的算法设计师和实施者——祝贺你在这本书的学习旅程中取得这一终极成就。
- en: Becoming Better and Faster
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 变得更好、更快
- en: You can do more with algorithms than you could when you started the book. But
    every serious adventurer will also want to be able to do things better and faster.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在能做的事情，比刚开始读这本书时多得多。但每个认真的冒险者也会希望能够做得更好、更快。
- en: 'Many things can make you better at designing and implementing algorithms. Think
    about how each algorithm we implemented in this book relied on some understanding
    of a non-algorithmic topic. Our baseball-catching algorithm relies on an understanding
    of physics and even a little psychology. Russian peasant multiplication relies
    on an understanding of exponents and on deep properties of arithmetic, including
    binary notation. Chapter 7’s geometry algorithms rely on insights into how points,
    lines, and triangles relate and fit together. The deeper your understanding of
    the field you’re trying to write algorithms for, the easier it will be for you
    to design and implement algorithms. Thus, the way to get better at algorithms
    is easy: just understand everything perfectly.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 许多事情都可以让您在设计和实现算法方面变得更好。思考一下本书中我们实现的每个算法是如何依赖于对非算法主题的理解的。我们的棒球接球算法依赖于对物理学甚至是一点心理学的理解。俄罗斯农民乘法依赖于对指数和算术的深层次理解，包括二进制表示法。第7章的几何算法依赖于对点、线和三角形如何相关和拟合的深刻见解。您对您试图为其编写算法的领域的理解越深入，设计和实现算法就会越容易。因此，变得更擅长算法的方法很简单：只需完美理解一切。
- en: Another natural next step for a budding algorithmic adventurer is to polish
    and repolish your raw programming skills. Remember that Chapter 8 introduced list
    comprehensions as a Pythonic tool that enables us to write language algorithms
    that are concise and perform well. As you learn more programming languages and
    master their features, you’ll be able to write code that’s better organized, more
    compact, and more powerful. Even skilled programmers can benefit from going back
    to the basics and mastering fundamentals until they’re second nature. Many talented
    programmers write disorganized, badly documented, or inefficient code and think
    they can get away with it because it “works.” But remember that code doesn’t usually
    succeed on its own—it is almost always part of a broader program, some team effort
    or grand business project that relies on cooperation between people and over time.
    Because of this, even soft skills like planning, oral and written communication,
    negotiation, and team management can improve your chances of success in the world
    of algorithms.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个自然的下一步，是对您原始编程技能进行打磨和再打磨。记住，第8章介绍了列表推导作为Pythonic工具，使我们能够编写简洁且性能良好的语言算法。随着您学习更多的编程语言并掌握它们的特性，您将能够编写更加组织良好、更加紧凑和更加强大的代码。即使是熟练的程序员也可以通过回归基础和掌握基本原理来受益。许多有才华的程序员编写混乱、文档不佳或效率低下的代码，并认为他们可以凭借它“运行”。但请记住，代码通常不会单独成功——它几乎总是作为更广泛的程序的一部分存在，依赖于人们之间的合作和时间。因此，甚至像计划、口头和书面沟通、谈判以及团队管理等软技能也可以提高您在算法世界中的成功机会。
- en: If you enjoy creating perfectly optimal algorithms and pushing them to their
    highest efficiency, you’re in luck. For a huge number of computer science problems,
    there is no known efficient algorithm that runs much faster than brute force.
    In the next section, we sketch a few of these problems and discuss what’s so hard
    about them. If you, dear adventurer, create an algorithm that solves any of these
    problems quickly, you could have fame, fortune, and worldwide gratitude for the
    rest of your life. What are we waiting for? Let’s look at some of these challenges
    for the most courageous among us.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您喜欢创建完美的最优算法并将其推向最高效率，那么您很幸运。对于大量计算机科学问题来说，没有已知的高效算法能够比暴力算法快得多。在接下来的部分中，我们将概述其中的一些问题，并讨论它们的难点所在。如果您，亲爱的冒险家，能够快速解决这些问题的算法，那么您可能会一生享有名誉、财富和全世界的感激之情。我们还在等什么？让我们来看看我们中最勇敢的人面临的一些挑战。
- en: Algorithms for the Ambitious
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 雄心勃勃的算法
- en: Let’s consider a relatively simple problem related to chess. Chess is played
    on an 8×8 board, and two opponents take turns moving differently styled pieces.
    One piece, the queen, can move any number of squares along the row, column, or
    diagonal where it is placed. Usually, a player possesses only one queen, but it’s
    possible for a player to have up to nine queens in a standard chess game. If a
    player has more than one queen, it may be that two or more queens “attack” each
    other—in other words, they are placed on the same row, column, or diagonal. The
    *eight queens puzzle* challenges us to place eight queens on a standard chessboard
    such that no pair of queens is on the same row, column, or diagonal. [Figure 11-1](#figure11-1)
    shows one solution to the eight queens puzzle.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个与国际象棋相关的相对简单的问题。国际象棋在一个 8×8 的棋盘上进行，两位对手轮流移动不同样式的棋子。一个棋子，皇后，可以沿着它所在的行、列或对角线移动任意数量的格子。通常，每个玩家只有一个皇后，但在标准的国际象棋比赛中，一个玩家最多可以有九个皇后。如果一个玩家有多个皇后，可能会出现两个或更多皇后互相“攻击”的情况——换句话说，它们被放置在同一行、同一列或同一对角线上。*八皇后问题*要求我们在标准棋盘上放置八个皇后，使得没有一对皇后处于同一行、同一列或同一对角线。[图
    11-1](#figure11-1) 展示了八皇后问题的一个解法。
- en: '![figure_11_1_lighter](Images/figure_11_1_lighter.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![figure_11_1_lighter](Images/figure_11_1_lighter.png)'
- en: '[Figure 11-1:](#figureanchor11-1) A solution to the eight queens puzzle (source:
    Wikimedia Commons)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 11-1：](#figureanchor11-1) 八皇后问题的一个解法（来源：Wikimedia Commons）'
- en: 'None of the queens on this board attacks any of the other queens. The easiest
    possible way to solve the eight queens puzzle is to simply memorize a solution,
    like the one in [Figure 11-1](#figure11-1), and repeat it whenever you’re asked
    to solve the puzzle. However, a couple of extra twists to the puzzle make memorization
    infeasible. One twist is to increase the number of queens and the size of the
    board. The *n queens problem* asks us to place *n* queens on an *n*×*n* chessboard
    such that no queen attacks any of the others; *n* could be any natural number,
    no matter how high. Another twist is the *n queens completion problem*: your opponent
    starts by placing some of the queens, maybe in places that will make it difficult
    for you to place the rest, and you have to place the rest of the *n* queens so
    that none attack any others. Can you design an algorithm that will run very quickly
    and solve this problem? If so, you could earn a million dollars (see “Solving
    the Deepest Mysteries” on page 212).'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这个棋盘上的任何一个皇后都不会攻击其他皇后。解决八皇后问题的最简单方法就是简单地记住一个解法，比如 [图 11-1](#figure11-1) 中的解法，并在每次被要求解决这个谜题时重复使用。然而，几个额外的难题使得记忆解法变得不可行。一个难题是增加皇后的数量和棋盘的大小。*n
    皇后问题*要求我们在一个 *n*×*n* 的棋盘上放置 *n* 个皇后，使得没有一个皇后攻击任何其他皇后；*n* 可以是任何自然数，不管有多大。另一个难题是
    *n 皇后完成问题*：你的对手首先放置一些皇后，可能是放置在一些位置，这会让你很难放置剩余的皇后，然后你需要将剩下的 *n* 个皇后放置到棋盘上，使得没有任何皇后会攻击其他皇后。你能设计一个运行非常快速并能解决这个问题的算法吗？如果能，你可能会赚到一百万美元（见第
    212 页的“解决最深奥的谜题”）。
- en: '[Figure 11-1](#figure11-1) may remind you of sudoku, since it involves checking
    for the uniqueness of symbols in rows and columns. In sudoku, the goal is to fill
    in the numbers 1 through 9 such that each row, column, and 3×3 block contains
    exactly one instance of each number ([Figure 11-2](#figure11-2)). Sudoku first
    gained popularity in Japan, and indeed a sudoku puzzle is reminiscent of the Japanese
    magic squares we explored in Chapter 2.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 11-1](#figure11-1) 可能会让你联想到数独，因为它涉及到检查行和列中符号的唯一性。在数独中，目标是填入数字 1 到 9，使得每一行、每一列和每个
    3×3 的小方块都包含每个数字的唯一一个实例 ([图 11-2](#figure11-2))。数独首先在日本流行起来，事实上，数独谜题让人想起我们在第 2
    章中探讨的日本魔方阵。'
- en: '![Figure_11_2](Images/figure_11-2.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![图 11-2](Images/figure_11-2.png)'
- en: '[Figure 11-2:](#figureanchor11-2) An uncompleted sudoku grid (source: Wikimedia
    Commons)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 11-2：](#figureanchor11-2) 一个未完成的数独网格（来源：Wikimedia Commons）'
- en: 'It’s an interesting exercise to think about how to write an algorithm that
    could solve sudoku puzzles. The simplest, slowest possible algorithm would rely
    on brute force: just try every possible combination of numbers and repeatedly
    check whether they constitute a correct solution, repeating until the solution
    is found. This would work, but it lacks elegance, and it could take an extremely
    long time. It doesn’t seem intuitively right that filling in 81 numbers in a grid
    according to rules that anyone could easily follow should stretch the limits of
    our world’s computing resources. More sophisticated solutions could rely on logic
    to cut down the required runtime.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 想一想如何编写一个算法来解决数独难题是一个有趣的练习。最简单、最慢的算法是依靠暴力破解：尝试每一种可能的数字组合，并反复检查它们是否构成一个正确的解法，直到找到解法。这是可行的，但缺乏优雅，且可能需要极长的时间。直观上看，把81个数字填入一个网格，按照任何人都能轻松遵循的规则，似乎不应该突破我们世界计算资源的极限。更复杂的解法可以依靠逻辑来减少所需的运行时间。
- en: 'The *n* queens completion problem and sudoku share another important trait:
    solutions are very easy to check. That is, if I show you a chessboard with queens
    on it, it will probably take you only a few moments to check whether you’re looking
    at a solution to the *n* queens completion problem, and if I show you a grid of
    81 numbers, you can easily tell whether you’re looking at a correct sudoku solution.
    The ease with which we can check solutions is, tragically, not matched by the
    ease of generating solutions—it can take hours to solve a difficult sudoku puzzle
    that then takes only seconds to verify. This generation/verification effort mismatch
    is common in many areas of life: I can tell with very little effort whether a
    meal is delicious, but creating a wonderful meal takes a much greater investment
    of time and resources. Similarly, I can check whether a painting is beautiful
    in much less time than it takes to create a beautiful painting, and I can verify
    whether a plane can fly with much less effort than it takes to build a flying
    plane.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '*n*皇后问题和数独有另一个重要的共同特征：解法非常容易检查。也就是说，如果我给你看一个有皇后的棋盘，你可能只需几秒钟就能检查出它是否是*n*皇后问题的解法；如果我给你看一个81个数字的网格，你也能轻松判断它是否是一个正确的数独解法。我们可以轻松检查解法的便捷性，然而，遗憾的是，生成解法的便捷性远不及验证解法的便捷性——解决一个困难的数独难题可能需要几个小时，而验证它则只需几秒钟。生成与验证的努力不匹配在生活中的许多领域都很常见：我只需要很少的努力就能判断一顿饭是否好吃，但制作一顿美味的饭菜需要投入更多的时间和资源。同样，我检查一幅画是否美丽的时间远少于创作一幅美丽画作所需要的时间，而我验证一架飞机能否飞行所需的努力远少于制造一架能飞行的飞机所需的努力。'
- en: Problems that are difficult to solve algorithmically but whose solutions are
    easy to verify are extremely important in theoretical computer science, and they
    are the deepest and most pressing mystery in the field. Especially courageous
    adventurers may dare to plunge into these mysteries—but beware the perils awaiting
    you there.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在理论计算机科学中，那些算法上难以解决但解法容易验证的问题是极其重要的，它们是该领域最深奥、最紧迫的谜团。尤其是那些勇敢的冒险者，可能会敢于深入这些谜团——但要小心那里潜伏的危险。
- en: Solving the Deepest Mysteries
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解开最深的谜团
- en: When we say that sudoku solutions are easy to verify but hard to generate, what
    we mean in more formal terms is that solutions can be verified in *polynomial
    time*; in other words, the number of steps required for solution verification
    is some polynomial function of the size of the sudoku board. If you think back
    to Chapter 4 and our discussion of runtimes, you’ll remember that even though
    polynomials like *x*² and *x*³ can grow fast, they are quite slow compared to
    exponential functions like *e*^x. If we can verify an algorithmic solution to
    a problem in polynomial time, we regard that verification as easy, but if the
    generation of a solution takes exponential time, we regard it as hard.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们说数独解法容易验证但难以生成时，正式的说法是解法可以在*多项式时间*内验证；换句话说，验证解法所需的步骤数是数独棋盘大小的某个多项式函数。如果你回想一下第4章我们讨论的运行时间，你会记得，即使像*x*²和*x*³这样的多项式增长得很快，它们与像*e*^x这样的指数函数相比，增长速度要慢得多。如果我们能够在多项式时间内验证一个问题的算法解法，我们认为验证是容易的，但如果解法的生成需要指数时间，我们就认为它是困难的。
- en: 'There’s a formal name for the class of problems whose solutions can be verified
    in polynomial time: the *NP complexity class*. (Here, NP stands for *nondeterministic
    polynomial time*, for reasons that would require a long digression into theoretical
    computer science that would not be useful here.) NP is one of the two most fundamental
    complexity classes in computer science. The second is called *P*, for polynomial
    time. The P complexity class of problems contains all problems whose solutions
    can be found by an algorithm that runs in polynomial time. For P problems, we
    can *find*full solutions in polynomial time, while for NP problems, we can *verify*
    solutions in polynomial time, but it may take exponential time to find those solutions.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个正式的名称来表示那些其解答可以在多项式时间内验证的问题类别：*NP 复杂性类*。（在这里，NP 代表 *非确定性多项式时间*，原因涉及到理论计算机科学，需要一个较长的讨论，这里不做展开。）NP
    是计算机科学中两个最基本的复杂性类之一。第二个是 *P* 类，代表多项式时间。P 复杂性类包含所有可以通过在多项式时间内运行的算法找到解答的问题。对于 P
    类问题，我们可以在多项式时间内 *找到* 完整的解答，而对于 NP 类问题，我们可以在多项式时间内 *验证* 解答，但找到这些解答可能需要指数级的时间。
- en: We know that sudoku is an NP problem—it is easy to verify a proposed sudoku
    solution in polynomial time. Is sudoku also a P problem? That is, is there an
    algorithm that can solve any sudoku puzzle in polynomial time? No one has ever
    found one, and no one appears to be close to finding one, but we don’t feel certain
    that it’s impossible.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道数独是 NP 问题——在多项式时间内，验证一个给定的数独解是很容易的。那么，数独是否也是 P 问题呢？也就是说，是否存在一个算法能够在多项式时间内解决任何数独谜题？至今没有人找到过这样的算法，也没有人看起来接近找到它，但我们并不确定这是否是不可能的。
- en: The list of problems that we know are in NP is extremely long. Some versions
    of the traveling salesman problem are in NP. So is the optimal solution to the
    Rubik’s cube, as well as important mathematical problems like integer linear programming.
    Just as with sudoku, we wonder whether these problems are also in P—can we find
    solutions for them in polynomial time? One way to phrase this question is, Does
    P = NP?
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已知的属于 NP 类的问题列表非常长。一些旅行商问题的版本也属于 NP 类。魔方的最优解也是如此，还有像整数线性规划这样的重要数学问题。就像数独一样，我们不禁会想，这些问题是否也属于
    P 类——我们能否在多项式时间内找到它们的解？可以这样提问：P 是否等于 NP？
- en: In 2000, the Clay Mathematics Institute published a list called the Millennium
    Prize Problems. It announced that any person who published a verified solution
    to one of the problems would receive a million dollars. The list was meant to
    be seven of the world’s most important problems related to mathematics, and the
    question of whether P = NP is one of them; no one has claimed its prize yet. Will
    one of the noble adventurers reading these words eventually break the Gordian
    knot and solve this most crucial of algorithmic problems? I sincerely hope so
    and wish each of you luck, strength, and joy on the journey.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 2000年，克莱数学研究所发布了一份名为千年奖问题的清单。它宣布，任何人如果发布一个已验证的解决方案，就能获得一百万美元的奖金。这个清单包含了七个与数学相关的世界上最重要的问题，而
    P 是否等于 NP 也是其中之一；至今还没有人领取过这一奖项。是否会有某个高贵的冒险家在阅读这些文字后最终解开这个最关键的算法难题呢？我真诚地希望如此，并祝愿你们在这段旅程中好运、力量和快乐。
- en: 'If there is ever a solution, it will be a proof of one of the following two
    assertions: either that P = NP or that P ≠ NP. A proof that P = NP could be relatively
    simple, since all that would be required is a polynomial-time algorithmic solution
    to an NP-complete problem. *NP-complete* problems are a special type of NP problem
    defined by the feature that every single NP problem can be quickly reduced to
    an NP-complete problem; in other words, if you can solve one NP-complete problem,
    you can solve every NP problem. If you can solve any single NP-complete problem
    in polynomial time, you can solve every NP problem in polynomial time, which would
    prove that P = NP. As it happens, sudoku and the n-queens completion problem are
    both NP-complete. This means that finding a polynomial-time algorithmic solution
    to either of them would not only solve every existing NP problem but also earn
    you a million dollars and worldwide, lifelong fame (not to mention the power to
    beat everyone you know in friendly sudoku competitions).'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 如果存在解决方案，它将证明以下两个论断之一：要么P = NP，要么P ≠ NP。证明P = NP可能相对简单，因为所需要的只是一个多项式时间算法来解决一个NP完全问题。*NP完全*问题是一种特殊的NP问题，其特征是每个NP问题都可以快速简化为一个NP完全问题；换句话说，如果你能解决一个NP完全问题，就能解决所有NP问题。如果你能在多项式时间内解决任何一个NP完全问题，你就能在多项式时间内解决每个NP问题，这将证明P
    = NP。事实上，数独和n皇后问题都是NP完全问题。这意味着找到一个多项式时间的算法来解决其中任何一个问题，不仅能解决所有现有的NP问题，还能为你赢得一百万美元和全球终身的声誉（更不用说在友好的数独比赛中击败你认识的每一个人）。
- en: A proof that P ≠ NP would probably not be as straightforward as a solution to
    sudoku. The notion that P ≠ NP means that there are NP problems that cannot be
    solved by any algorithm with polynomial runtime. Proving this amounts to proving
    a negative, and it is conceptually much harder to prove that something cannot
    exist than it is to point to an example of something. Making progress in a proof
    that P ≠ NP will require extended study in theoretical computer science beyond
    the scope of this book. Though this path is harder, it seems to be the consensus
    among researchers that P ≠ NP, and that if there is ever a resolution to the P
    versus NP question, it will probably be a proof that P ≠ NP.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 证明P ≠ NP可能不像解决数独那样直接。P ≠ NP的概念意味着存在一些NP问题，它们无法通过任何具有多项式运行时间的算法解决。证明这一点等同于证明一个否定命题，从概念上讲，证明某个事物无法存在，比指出一个事物的例子要难得多。要在证明P
    ≠ NP的过程中取得进展，将需要深入研究理论计算机科学，超出本书的范围。虽然这条路更为艰难，但研究人员的共识似乎是P ≠ NP，如果P与NP问题最终有解决方案，它很可能是证明P
    ≠ NP。
- en: 'The P versus NP question is not the only deep mystery related to algorithms,
    although it is the most immediately lucrative one. Every aspect of the field of
    algorithm design has wide-open fields for adventurers to charge into. There are
    not only theoretical and academic questions, but also practical ones related to
    how to implement algorithmically sound practices in business contexts. Waste no
    time: remember what you have learned here and sally forth anon, carrying your
    new skills with you to the utmost bounds of knowledge and practice, on your lifelong
    algorithmic adventure. Friends, adieu.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: P与NP问题并不是唯一与算法相关的深刻谜题，尽管它是最直接能带来丰厚回报的那个。算法设计领域的每一个方面都有广阔的领域，供冒险者进军。这里不仅有理论和学术问题，还有一些实际问题，涉及如何在商业环境中实施算法上可靠的实践。不要浪费时间：记住你在这里学到的知识，继续前进，带着你的新技能，走向知识和实践的极限，开始你一生的算法冒险。朋友们，再见。

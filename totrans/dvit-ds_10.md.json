["```py\nsword = [10,1,5,1]\nknife = [10,1,5,9]\nherring = [2,2,2,6]\n```", "```py\nimport numpy as np\ndef euclidean(vec1,vec2):\n    distance=np.array(vec1)-np.array(vec2)\n    squared_sum=np.sum(distance**2)\n    return np.sqrt(squared_sum)\n```", "```py\nprint(euclidean(sword,knife))\nprint(euclidean(sword,herring))\nprint(euclidean(knife,herring))\n```", "```py\nimport gensim.downloader as api\n```", "```py\nvectors = api.load('word2vec-google-news-300')\n```", "```py\nprint(vectors['sword'])\n```", "```py\nprint(euclidean(vectors['sword'],vectors['knife']))\nprint(euclidean(vectors['sword'],vectors['herring']))\nprint(euclidean(vectors['car'],vectors['van']))\n```", "```py\n>>> **print(euclidean(vectors['sword'],vectors['knife']))**\n3.2766972\n>>> **print(euclidean(vectors['sword'],vectors['herring']))**\n4.9384727\n>>> **print(euclidean(vectors['car'],vectors['van']))**\n2.608656\n```", "```py\ndef dot_product(vector1,vector2):\n    thedotproduct=np.sum([vector1[k]*vector2[k] for k in range(0,len(vector1))])\n    return(thedotproduct)\n\ndef vector_norm(vector):\n    thenorm=np.sqrt(dot_product(vector,vector))\n    return(thenorm)\n\ndef cosine_similarity(vector1,vector2):\n    thecosine=0\n    thedotproduct=dot_product(vector1,vector2)\n    thecosine=thedotproduct/(vector_norm(vector1)*vector_norm(vector2))\n    thecosine=np.round(thecosine,4)\n    return(thecosine)\n```", "```py\nprint(cosine_similarity(vectors['sword'],vectors['knife']))\nprint(cosine_similarity(vectors['sword'],vectors['herring']))\nprint(cosine_similarity(vectors['car'],vectors['van']))\n```", "```py\n>>> **print(cosine_similarity(vectors['sword'],vectors['knife']))**\n0.5576\n>>> **print(cosine_similarity(vectors['sword'],vectors['herring']))**\n0.0529\n>>> **print(cosine_similarity(vectors['car'],vectors['van']))**\n0.6116\n```", "```py\nking = vectors['king']\nqueen = vectors['queen']\nman = vectors['man']\nwoman = vectors['woman']\n```", "```py\nnewvector = king-man+woman\n```", "```py\nprint(cosine_similarity(newvector,queen))\nprint(euclidean(newvector,queen))\n```", "```py\nprint(cosine_similarity(vectors['fish'],vectors['herring']))\nprint(euclidean(vectors['fish'],vectors['herring']))\n```", "```py\nprint(cosine_similarity(vectors['the'],vectors['the']))\nprint(euclidean(vectors['having'],vectors['having']))\n```", "```py\nprint(cosine_similarity(vectors['trouble'],vectors['problem']))\nprint(euclidean(vectors['come'],vectors['approach']))\nprint(cosine_similarity(vectors['put'],vectors['insert']))\n```", "```py\n>>> **print(cosine_similarity(vectors['trouble'],vectors['problem']))**\n0.5327\n>>> **print(euclidean(vectors['come'],vectors['approach']))**\n2.9844923\n>>> **print(cosine_similarity(vectors['put'],vectors['insert']))**\n0.3435\n```", "```py\nSentences = [\n    \"The trouble with having an open mind, of course, is that people will insist on coming along and trying to put things in it.\",\\\n    \"The problem with having an open mind is that people will insist on approaching and trying to insert things into your mind.\",\\\n    \"To be or not to be, that is the question\",\\\n    \"Call me Ishmael\"\n]\n```", "```py\nimport tensorflow_hub as hub\nembed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")\n```", "```py\nembeddings = embed(Sentences)\n```", "```py\nprint(embeddings[0])\n```", "```py\n>>> **print(embeddings[0])**\ntf.Tensor(\n[ 9.70209017e-04 -5.99743128e-02 -2.84200953e-03  7.49062840e-03\n  7.74949566e-02 -1.00521010e-03 -7.75496066e-02  4.12207991e-02\n -1.55476958e-03 -1.11693323e-01  2.58275736e-02 -1.15299867e-02\n -3.84882478e-05 -4.07184102e-02  3.69430222e-02  6.66357949e-02\n```", "```py\nprint(cosine_similarity(embeddings[0],embeddings[1]))\n```", "```py\nSentences = [\n    \"The corn and cheese are delicious when they're roasted together\",\n    \"Several of the scenes have rich settings but weak characterization\",\n    \"Consider adding extra seasoning to the pork\",\n    \"The prose was overwrought and pretentious\",\n    \"There are some nice brisket slices on the menu\",\n    \"It would be better to have a chapter to introduce your main plot ideas\",\n    \"Everything was cold when the waiter brought it to the table\",\n    \"You can probably find it at a cheaper price in bookstores\"\n]\n```", "```py\nembeddings = embed(Sentences)\n```", "```py\narrays=[]\nfor i in range(len(Sentences)):\n    arrays.append(np.array(embeddings[i]))\n\nsentencematrix = np.empty((len(Sentences),512,), order = \"F\")\n\nfor i in range(len(Sentences)):\n    sentencematrix[i]=arrays[i]\n\nimport pandas as pd\npandasmatrix=pd.DataFrame(sentencematrix)\n```", "```py\nfrom sklearn.cluster import KMeans\nm = KMeans(2)\nm.fit(pandasmatrix)\n\npandasmatrix['topic'] = m.labels_\n\npandasmatrix['sentences']=Sentences\n```", "```py\nprint(pandasmatrix.loc[pandasmatrix['topic']==0,'sentences'])\nprint(pandasmatrix.loc[pandasmatrix['topic']==1,'sentences'])\n```", "```py\n>>> **print(pandasmatrix.loc[pandasmatrix['topic']==0,'sentences'])**\n0    The corn and cheese are delicious when they're...\n2          Consider adding extra seasoning to the pork\n4       There are some nice brisket slices on the menu\n6    Everything was cold when the waiter brought it...\nName: sentences, dtype: object\n>>> **print(pandasmatrix.loc[pandasmatrix['topic']==1,'sentences'])**\n1    Several of the scenes have rich settings but w...\n3            The prose was overwrought and pretentious\n5    It would be better to have a chapter to introd...\n7    You can probably find it at a cheaper price in...\nName: sentences, dtype: object\n```"]
- en: '**9'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**9  '
- en: WRITING HAIKU WITH MARKOV CHAIN ANALYSIS**
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 使用马尔可夫链分析写俳句**
- en: '![image](../images/common01.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/common01.jpg)'
- en: Computers can write poetry by rearranging existing poems. This is basically
    what humans do. You and I didn’t invent the language we speak—we learned it. To
    talk or write, we just recombine existing words—and rarely in a truly original
    manner. As Sting once said about writing music, “I don’t think there’s such a
    thing as composition in pop music. I think what we do in pop music is collate
    . . . I’m a good collator.”
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机可以通过重新排列现有的诗歌来写诗。这基本上就是人类所做的事。你和我没有发明我们使用的语言——我们是学习的。为了说话或写作，我们只是重新组合现有的词汇——而且很少以一种真正原创的方式。正如Sting曾经谈到创作音乐时所说：“我不认为流行音乐中有所谓的创作。我认为我们在流行音乐中做的是整理……我是一个很好的整理者。”
- en: In this chapter, you’re going to write a program that puts the “best words in
    the best order” in the form of haiku. But to do this, Python needs good examples,
    so you’ll need to provide a training corpus of haiku by the Japanese masters.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将编写一个程序，用马尔可夫链的方式把“最好的词按最好的顺序”排成俳句。但要做到这一点，Python需要良好的示例，因此你需要提供日本大师们的俳句训练语料库。
- en: To rearrange these words in a meaningful manner, you will use *Markov chains*,
    named after Russian mathematician Andrey Markov. *Markov chain analysis*, an important
    part of probability theory, is a process that attempts to predict the subsequent
    state based on the properties of the current state. Modern-day applications include
    speech and handwriting recognition, computer performance evaluation, spam filtering,
    and Google’s PageRank algorithm for searching the web.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 为了以有意义的方式重新排列这些词，你将使用*马尔可夫链*，这个名字来自俄罗斯数学家安德烈·马尔可夫。*马尔可夫链分析*是概率论中的一个重要部分，它是一种基于当前状态的特性来预测下一个状态的过程。现代应用包括语音和手写识别、计算机性能评估、垃圾邮件过滤以及谷歌的PageRank算法。
- en: With Markov chain analysis, a training corpus, and the syllable-counting program
    from [Chapter 8](ch08.xhtml#ch08), you’ll be able to produce new haiku that follow
    the syllabic rules of the genre and stay “on subject” to a large degree. You’ll
    also learn how to use Python’s `logging` module to help monitor the behavior of
    your program with easy on-and-off feedback. And in “[Challenge Projects](ch09.xhtml#lev215)”
    on [page 184](ch09.xhtml#page_184), you can enlist your friends on social media
    to see if they can distinguish your simulated haiku from the real thing.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 通过马尔可夫链分析、训练语料库和第[8章](ch08.xhtml#ch08)中的音节计数程序，你将能够创作出符合音节规则的俳句，并且在很大程度上保持“主题一致”。你还将学习如何使用Python的`logging`模块来帮助监控程序的行为，提供简单的开关反馈。同时，在[第184页](ch09.xhtml#page_184)的“[挑战项目](ch09.xhtml#lev215)”中，你可以邀请朋友们通过社交媒体来看看他们能否分辨出你模拟的俳句与真正的俳句之间的区别。
- en: '**Project #16: Markov Chain Analysis**'
  id: totrans-7
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**项目 #16：马尔可夫链分析**'
- en: Like the genetic algorithms in [Chapter 7](ch07.xhtml#ch07), Markov chain analysis
    sounds impressive but is easy to implement. You do it every day. If you hear some
    one say, “Elementary, my dear . . . ,” you automatically think, “Watson.” Every
    time your brain has heard this phrase, it has taken a sample. Based on the number
    of samples, it can predict the answer. On the other hand, if you heard someone
    say, “I want to go to . . . ,” you might think “the bathroom” or “the movies”
    but probably not “Houma, Louisiana.” There are many possible solutions, but some
    are more likely than others.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 就像第[7章](ch07.xhtml#ch07)中的遗传算法一样，马尔可夫链分析听起来很复杂，但实际上很容易实现。你每天都在做这件事。如果你听到有人说：“Elementary,
    my dear . . . ,”你会自然而然地想：“Watson。”每当你的大脑听到这个短语时，它都会进行一次样本采集。根据样本数量，它就能预测出答案。另一方面，如果你听到有人说：“I
    want to go to . . . ,”你可能会想“厕所”或者“电影院”，但大概率不会想到“路易斯安那州的霍马”。有许多可能的答案，但有些答案的可能性更高。
- en: Back in the 1940s, Claude Shannon pioneered the use of Markov chains to statistically
    model the sequences of letters in a body of text. For example, for every occurrence
    of the digram *th* in an English-language book, the next most likely letter is
    *e*.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在20世纪40年代，Claude Shannon开创了使用马尔可夫链来统计建模文本中字母序列的方式。例如，在一本英文书籍中，每次出现字母组合*th*时，下一个最可能出现的字母是*e*。
- en: But you don’t just want to know what the most likely letter is; you want to
    know the actual probability of getting that letter, as well as the odds of getting
    every other letter, which is a problem tailor-made for a computer. To solve this
    problem, you need to map each two-letter digram in a piece of text to the letter
    that immediately follows it. This is a classic dictionary application, with the
    digrams as the keys and the letters as the values.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 但你不仅仅想知道最可能的字母是什么；你还想知道获得该字母的实际概率，以及获得其他每个字母的概率，这是一个非常适合计算机解决的问题。为了解决这个问题，你需要将文本中的每个二字母对映射到它后面紧接着的字母。这是一个经典的字典应用，二字母对作为键，字母作为值。
- en: 'When applied to letters in words, a *Markov model* is a mathematical model
    that calculates a letter’s probability of occurrence based on the previous *k*
    consecutive letters, where *k* is an integer. A *model of order 2* means that
    the probability of a letter occurring depends on the two letters that precede
    it. A *model of order 0* means that each letter is independent. And this same
    logic applies to words. Consider these two haiku examples:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 当应用于单词中的字母时，*马尔可夫模型*是一个数学模型，它根据前面连续的*k*个字母计算一个字母的出现概率，其中*k*是一个整数。*二阶模型*意味着字母出现的概率取决于其前面的两个字母。*零阶模型*意味着每个字母是独立的。这个逻辑同样适用于单词。考虑以下两个俳句示例：
- en: '| A break in the clouds | Glorious the moon |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| A break in the clouds | Glorious the moon |'
- en: '| The moon a bright mountaintop | Therefore our thanks dark clouds come |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| The moon a bright mountaintop | Therefore our thanks dark clouds come |'
- en: '| Distant and aloof | To rest our tired necks |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| Distant and aloof | To rest our tired necks |'
- en: 'A Python dictionary that maps each haiku word to each subsequent word looks
    like this:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 一个将每个俳句单词映射到其后续单词的Python字典如下所示：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Since there are only two haiku, most of the dictionary keys have only one value.
    But look at *the* near the bottom of the list: *moon* occurs twice. This is because
    the Markov model stores every occurrence of a word as a separate, duplicate value.
    So, for the key *the*, if you choose a value at random, the odds of selecting
    *moon* versus *clouds* are 2:1\. Conversely, the model will automatically screen
    out extremely rare or impossible combinations. For example, many words can potentially
    follow *the*, but not another *the*!'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这里只有两个俳句，因此大多数字典键只有一个值。但请看一下列表底部的*the*：*moon*出现了两次。这是因为马尔可夫模型将每个单词的出现存储为一个单独的重复值。因此，对于键*the*，如果你随机选择一个值，选择*moon*与*clouds*的概率是2:1。相反，模型会自动筛选掉极为罕见或不可能的组合。例如，许多单词可以接在*the*后面，但不能再接另一个*the*！
- en: The following dictionary maps every *pair* of words to the word immediately
    after; that means it’s a model of order 2.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 以下字典将每一对单词映射到其后面紧接着的单词；这意味着它是一个二阶模型。
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Note that the mapping continues from the first haiku to the second so the dictionary
    contains the items `''and aloof'': [''glorious'']` and `''aloof glorious'': [''the'']`.
    This behavior means your program can jump from one haiku to another and is not
    restricted to just the word pairs within a single haiku. It is free to form new
    word pairs that the masters may never have conceived.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '请注意，映射是从第一个俳句到第二个俳句的，因此字典中包含项`''and aloof'': [''glorious'']`和`''aloof glorious'':
    [''the'']`。这种行为意味着你的程序可以从一个俳句跳转到另一个，而不仅仅局限于单一俳句中的单词对。它可以自由地形成新的单词对，即使这些单词对是大师们从未设想到的。'
- en: Because of the very short training corpus, *the moon* is the only word pair
    with multiple values. For all the others, you are “locked in” to a single outcome.
    In this example, the size of the training corpus greatly determines the number
    of values per key, but with a larger corpus, the value of *k* in the Markov model
    will have a larger influence.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 由于训练语料非常短，*the moon*是唯一具有多个值的单词对。对于其他所有单词对，你都“锁定”在单一的结果中。在这个例子中，训练语料的大小极大地决定了每个键的值的数量，但随着语料库的增大，马尔可夫模型中的*k*值将产生更大的影响。
- en: The size of *k* determines whether you produce poppycock, commit plagiarism,
    or produce a perspicuous piece of originality. If *k* equals 0, then you’ll be
    choosing words at random based on that word’s overall frequency in the corpus,
    and you’ll likely produce a lot of gibberish. If *k* is large, the results will
    be tightly constrained, and you’ll begin to reproduce the training text verbatim.
    So small values of *k* promote creativity, and large values promote duplication.
    The challenge is finding the proper balance between the two.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '*k*的大小决定了你是会生成胡言乱语、抄袭，还是创作出一篇清晰的原创作品。如果*k*等于0，那么你将根据单词在语料库中的整体频率随机选择词汇，你很可能会生成大量的废话。如果*k*值很大，结果会受到严格限制，你会开始逐字复述训练文本。所以，较小的*k*值促进创造力，较大的*k*值则促使重复。挑战在于找到两者之间的适当平衡。'
- en: 'To illustrate, if you use a Markov model of order 3 on the previous haiku,
    all the resulting keys will have one value. The two values associated with the
    word pair *the moon* are lost because the former word pair becomes two keys, each
    with a unique value:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 举例来说，如果你在之前的俳句上使用一个三阶马尔可夫模型，所有生成的键都会有一个值。与词对*月亮*相关的两个值将会丢失，因为前一个词对变成了两个键，每个键都有一个唯一的值：
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Since haiku are short—only 17 syllables long—and available training corpora
    are relatively small, using a *k* of 2 should be sufficient to enforce *some*
    order while still allowing for creative word substitutions in your program.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 由于俳句较短——仅17个音节——且可用的训练语料库相对较小，使用*k*值为2应该足以强制执行*某种*秩序，同时仍能允许程序中进行创造性的词汇替换。
- en: '**THE OBJECTIVE**'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**目标**'
- en: Write a program that generates haiku using Markov chain analysis. Allow the
    user to modify the haiku by independently regenerating lines two and three.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 编写一个程序，使用马尔可夫链分析生成俳句。允许用户通过独立重新生成第二行和第三行来修改俳句。
- en: '**The Strategy**'
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**策略**'
- en: Your general strategy for simulating haiku will be to build Markov models of
    orders 1 and 2 with a training corpus of haiku written by humans. You’ll then
    use those models and the *count_syllables.py* program from [Chapter 8](ch08.xhtml#ch08)
    to generate novel haiku that meet the required syllabic structure of 5-7-5 for
    the three lines of the haiku.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 模拟俳句的总体策略是，基于人类写的俳句训练语料库，建立一阶和二阶马尔可夫模型。接着，你将使用这些模型和[第8章](ch08.xhtml#ch08)中的*count_syllables.py*程序生成符合俳句音节结构5-7-5的创新俳句。
- en: The program should build the haiku one word at a time, initiating (or *seeding*)
    the haiku with a random word drawn from the corpus; selecting the haiku’s second
    word using a Markov model of order 1; and then selecting each subsequent word
    with the order 2 model.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 程序应当逐个生成俳句的每个词，首先从语料库中随机选择一个词来初始化（或*播种*）俳句；使用一阶马尔可夫模型选择俳句的第二个词；然后用二阶模型选择每一个后续的词。
- en: Each word is derived from a *prefix*—a word or word pair that determines which
    word will be picked to go in the haiku; the key in the word-mapping dictionaries
    represents the prefix. As a consequence, the word that the prefix determines is
    the *suffix*.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 每个词汇都来源于一个*前缀*——一个确定要选择哪个词汇进入俳句的词或词对；词汇映射字典中的键表示前缀。因此，前缀决定的词就是*后缀*。
- en: '***Choosing and Discarding Words***'
  id: totrans-32
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***选择和舍弃词汇***'
- en: When the program selects a word, it first counts the word’s syllables, and if
    the word doesn’t fit, it chooses a new word. If there are no possible words based
    on the prefix in the poem, then the program resorts to what I call a *ghost prefix*,
    which is a prefix that doesn’t occur in the haiku. For example, if a word pair
    in a haiku is *temple gong*, and all the words that follow in the Markov model
    have too many syllables to complete the line, the program selects a new word pair
    at random and uses it to pick the next word in the haiku. The new word-pair prefix
    *should not be included in the line*—that is, *temple gong* will not be replaced.
    Although you could choose a suitable new word in a number of ways, I prefer this
    technique because it allows you to simplify by maintaining a consistent process
    throughout the program.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当程序选择一个词时，它首先计算该词的音节数，如果该词不合适，就会选择一个新词。如果基于诗句中的前缀没有合适的词语，程序就会求助于我所称之为*幽灵前缀*，即在俳句中没有出现的前缀。例如，如果俳句中的词对是*寺庙钟*，且根据马尔可夫模型，所有跟随的词音节数过多，无法完成这一行，程序将随机选择一对新词，并用它来选择俳句中的下一个词。新的词对前缀*不应包含在该行中*——也就是说，*寺庙钟*将不会被替换。尽管你可以通过多种方式选择合适的新词，但我更喜欢这种技术，因为它可以通过保持程序中的一致性简化整个过程。
- en: You can accomplish these steps with the functions in [Figures 9-1](ch09.xhtml#ch09fig1)
    and [9-2](ch09.xhtml#ch09fig2). Assuming you’re working on a five-syllable line,
    [Figure 9-1](ch09.xhtml#ch09fig1) is an example of what will happen, at a high
    level, if all the chosen words match the syllable target.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过[图 9-1](ch09.xhtml#ch09fig1)和[图 9-2](ch09.xhtml#ch09fig2)中的函数完成这些步骤。假设你正在处理一个五音节的句子，[图
    9-1](ch09.xhtml#ch09fig1)展示了如果所有选择的词汇都符合音节目标，会发生的高层次情况。
- en: '![image](../images/f0165-01.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/f0165-01.jpg)'
- en: '*Figure 9-1: High-level graphical pseudocode for a five-syllable haiku line*'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 9-1：五音节俳句行的高层图形伪代码*'
- en: The program randomly selects the seed word *the* from the corpus, and then counts
    its syllables. Next, it chooses *bright* from the model of order 1, based on the
    prefix *the*. Then it counts the number of syllables in *bright* and adds that
    number to the number of syllables in the line. Since the sum of syllables doesn’t
    exceed five, the program adds *bright* to the line, moves on to select *autumn*
    from the model of order 2 based on the prefix *The bright*, and then repeats the
    syllable-counting process. Finally, the program selects *moon* based on the prefix
    *bright autumn*, counts the syllables, and—since the line’s total number of syllables
    is equal to five—adds moon to the line, completing it.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 程序从语料库中随机选择种子词*the*，然后计算它的音节数。接下来，它基于前缀*the*从一阶模型中选择*bright*。然后它计算*bright*的音节数，并将该音节数加到句子的音节总数中。由于音节总和不超过五，程序将*bright*添加到句子中，继续从二阶模型中基于前缀*The
    bright*选择*autumn*，然后重复音节计数过程。最后，程序基于前缀*bright autumn*选择*moon*，计算音节数，并且由于句子的音节总数正好为五，程序将*moon*加入句子，完成整个句子。
- en: '[Figure 9-2](ch09.xhtml#ch09fig2) demonstrates a case where the program needs
    to utilize a ghost prefix to successfully complete a five-syllable line.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 9-2](ch09.xhtml#ch09fig2)展示了程序需要利用一个幽灵前缀来成功完成一个五音节句子的情况。'
- en: '![image](../images/f0166-01.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/f0166-01.jpg)'
- en: '*Figure 9-2: Choosing a new suffix with a randomly selected ghost prefix (*full
    white*)*'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 9-2：选择带有随机选择的幽灵前缀（*full white*）的新后缀*'
- en: Let’s assume that the only word that follows the prefix *temple gong* in the
    Markov model is *glorious*. This word has too many syllables for the line, so
    the program selects a ghost prefix, *full white*, at random. The word *moon* follows
    the ghost prefix and satisfies the remaining syllable count in the line, so the
    program adds it to the line. The program then discards the *full white* prefix,
    and the line is complete. With this ghost prefix technique, you can’t guarantee
    that the new suffix will make sense contextually, but at the same time, this is
    one way to incorporate creativity into the process.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 假设在马尔可夫模型中，跟随前缀*temple gong*的唯一词是*glorious*。这个词的音节数对句子来说太多，因此程序随机选择一个幽灵前缀*full
    white*。词*moon*跟随幽灵前缀，并满足句子剩余的音节数，因此程序将其添加到句子中。程序然后丢弃*full white*前缀，句子完成了。通过这个幽灵前缀技巧，你不能保证新后缀在语境上完全合适，但同时，这是将创造力融入过程的一种方式。
- en: '***Continuing from One Line to Another***'
  id: totrans-42
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***从一行到另一行的延续***'
- en: 'The Markov model is the “special sauce” that allows you to imbue the haiku
    with context and meaning that continue from one line to another. The Japanese
    masters *generally* wrote haiku in which each line is a stand-alone phrase but
    the contextual thread continues across lines, as in this haiku from Bon Cho:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 马尔可夫模型是让你将俳句注入上下文和意义的“特殊酱汁”，使得每一行能够从一行延续到另一行。日本大师们*通常*写作的俳句每行是一个独立的短语，但上下文的联系贯穿整首诗，如本朝的这首俳句：
- en: In silent midnight
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在寂静的午夜
- en: Our old scarecrow topples down
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的老稻草人倒下了
- en: Weird hollow echo
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 奇怪的空洞回响
- en: '*—Bon Cho*'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '*—本朝*'
- en: 'Even though the masters preferred that each line of a haiku represent a complete
    thought, they didn’t strictly follow the rule. Here’s an example in Buson’s haiku:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 即使大师们偏好每一行俳句都代表一个完整的思想，他们也并不严格遵循这一规则。以下是芭村俳句中的一个例子：
- en: My two plum trees are
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我的两棵梅树
- en: So gracious see, they flower
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如此优雅，看看它们开花
- en: One now, one later
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 现在一行，之后一行
- en: '*—Buson*'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '*—芭村*'
- en: The first line of Buson’s haiku is not grammatical on its own, so the reader
    must continue to the next line without a break. When a phrase in poetry moves
    from one line to the next without a pause or syntactic break, it is said to be
    *enjambed*. According to Charles Hartman, author of *Virtual Muse*, enjambment
    is what gives metrical lines much of their supple liveliness. That’s a good thing,
    since it’s very hard to get an algorithm to write a coherent poem without some
    grammatical spillover from line to line. To get your program to continue a “thought”
    through multiple lines, you need to use the word pair from the end of the previous
    line as the starting prefix for the current line.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 芭蕉的俳句第一行单独来看并不符合语法，因此读者必须不间断地继续读到下一行。当诗句从一行延续到下一行时，没有停顿或语法断裂，这种现象称为*跨行连贯*。根据《虚拟缪斯》作者查尔斯·哈特曼的说法，跨行连贯使得音步行在诗歌中充满了活力和柔韧性。这是件好事，因为如果没有语法上的延续，很难让算法写出连贯的诗歌。为了让程序在多行之间保持“思路”的延续，你需要使用上一行结尾的词对作为当前行的起始前缀。
- en: Finally, you should give the user the opportunity to not only build the poem
    but also to edit it interactively by regenerating lines two and three. Most of
    writing is rewriting, and it would be unconscionable to leave the user hanging
    with two perfect lines and no way to throw the dice again on an uncooperative
    line.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你应该给用户提供一个机会，不仅可以构建诗歌，还能通过重新生成第二行和第三行与诗歌进行互动编辑。写作大部分时间是重写，若留下两行完美的诗句，却没有办法重新“投掷骰子”来修改不合适的行，那将是无法容忍的。
- en: '**The Pseudocode**'
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**伪代码**'
- en: 'If you follow the strategy I’ve just laid out, your high-level pseudocode should
    look like this:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你遵循我刚才所提到的策略，你的高级伪代码应该像这样：
- en: '[PRE3]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '**The Training Corpus**'
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**训练语料库**'
- en: Markov models are built from a corpus, so they are unique to that corpus. A
    model built from the complete works of Edgar Rice Burroughs will be different
    and distinguishable from one built from the works of Anne Rice. We all have a
    signature style, or *voice*, and given a large enough sample, a Markov approach
    can produce a statistical model of your style. Like fingerprints, this model can
    link you to a document or manuscript.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 马尔可夫模型是从语料库构建的，因此它们是独特的，取决于该语料库。从埃德加·赖斯·巴勒斯的完整作品中构建的模型，将不同于从安妮·赖斯的作品中构建的模型。每个人都有自己的独特风格，或者说是*声音*，只要样本足够大，马尔可夫方法可以生成一个统计模型来表示你的风格。就像指纹一样，这个模型可以将你与某份文档或手稿联系起来。
- en: To build the Markov models, the corpus you’ll use is a text file consisting
    of almost 300 ancient and modern haiku, more than 200 of which were written by
    the masters. Ideally, your training corpus would consist of thousands of haiku,
    all by the same author (for a consistent voice), but these are difficult to find,
    particularly since many of the old Japanese haiku don’t obey the syllabic rules,
    either intentionally or as a result of translation into English.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建马尔可夫模型，你将使用一个文本文件，该文件包含近300首古今俳句，其中200多首是由大师们创作的。理想情况下，你的训练语料库应该由成千上万首同一作者创作的俳句组成（以保持一致的“声音”），但这些作品很难找到，尤其是许多古老的日本俳句在音节规则上并不严格遵守，无论是故意的，还是翻译成英语时造成的。
- en: To increase the number of values per key in the Markov model, the haiku in the
    initial corpus were duplicated 18 times and randomly distributed throughout the
    file. This has no impact on word associations *within* haiku but increases the
    interactions *between* haiku.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 为了增加马尔可夫模型中每个键的值的数量，初始语料库中的俳句被复制了18次，并随机分布在文件中。这对俳句内部的单词关联没有影响，但增加了俳句之间的互动。
- en: 'To illustrate, assume the word pair at the end of the following haiku is unique,
    mapping only to the starting word of the second haiku; this results in the fairly
    useless key/value pair of `''hollow frog'': [''mirror-pond'']`:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '举例来说，假设下面这首俳句的结尾词对是独特的，仅与第二首俳句的起始词相对应；这将导致一个相当无用的键值对`''hollow frog'': [''mirror-pond'']`：'
- en: Open mouth reveals
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 张开嘴巴，露出
- en: Your whole wet interior
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 你整个湿润的内心
- en: Silly **hollow frog**!
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 傻傻的**空心青蛙**！
- en: '**Mirror-pond** of stars'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**镜面池塘**的星星'
- en: Suddenly a summer shower
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 突如其来的夏日阵雨
- en: Dimples the water
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 水面泛起涟漪
- en: 'If you duplicate and shuffle the haiku, you may introduce a preposition into
    the mix, greatly increasing the odds of linking the odd *hollow frog* to something
    sensible:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你复制并打乱这首俳句，你可能会引入一个介词，从而大大增加将奇怪的*空心青蛙*与某些有意义的事物连接的几率：
- en: Open mouth reveals
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 张开嘴巴，露出
- en: Your whole wet interior
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 你整个湿润的内心
- en: Silly **hollow frog**!
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 傻傻的**空心青蛙**！
- en: '**In** the city fields'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**在**城市田野中'
- en: Contemplating cherry trees
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 沉思樱花树
- en: Strangers are like friends
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 陌生人如同朋友
- en: 'The Markov model now assigns two values to `''hollow frog''`: `''mirror-pond''`
    and `''in''`. And each time you duplicate the haiku, you’ll see an increase in
    the number of values per key for haiku-ending words or word pairs. But this is
    helpful only to a point; after a while, diminishing returns set in, and you start
    adding the same values over and over again, gaining nothing.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 马尔可夫模型现在将两个值分配给`'hollow frog'`：`'mirror-pond'`和`'in'`。每当你复制俳句时，你会看到每个关键字对应的值的数量增加，但这仅在一定程度上有用；过一段时间后，收益递减开始显现，你会一遍又一遍地添加相同的值，却没有任何新的收获。
- en: '**Debugging**'
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**调试**'
- en: Debugging is the process of finding and fixing errors (bugs) in computer hardware
    and software. When you’re trying to code a solution to a complex problem, you
    need to keep a tight rein on your program in order to find the source of an issue
    when something unexpected arises. For example, if you end up with seven syllables
    rather than five in the first line of your haiku, you’ll want to know if the syllable-counting
    function failed, if there was a problem mapping words to words, or if the program
    thought it was on line two. To find out what went wrong, you need to monitor what
    your program is returning at each key step, and this calls for either *scaffolding*
    or *logging*. I’ll discuss each of these techniques in the following two sections.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 调试是找出并修复计算机硬件和软件中的错误（bug）的过程。当你在为复杂问题编写解决方案时，你需要密切关注程序的执行，以便在出现意外情况时找出问题的根源。例如，如果你在俳句的第一行中得到了七个音节，而不是五个，你想知道音节计数函数是否失败，还是映射单词时出了问题，或者程序是否认为它在第二行。为了找出问题出在哪里，你需要监控程序在每个关键步骤返回的内容，这就需要使用临时代码或日志记录。我将在接下来的两节中讨论这两种技术。
- en: '***Building the Scaffolding***'
  id: totrans-79
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***构建临时代码***'
- en: '*Scaffolding*, as defined here, is temporary code you write to help develop
    your programs, then delete when you’re done. The name is an allusion to the scaffolding
    used in construction—necessary, but nobody wants it around forever.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这里定义的*临时代码*是你为了帮助开发程序而编写的临时代码，完成后会删除。这个名字来源于建筑中的脚手架——是必要的，但没有人希望它永远存在。
- en: One common piece of scaffolding is a `print()` statement that checks what a
    function or calculation returns. The user doesn’t need to see the output, so you
    delete it after you confirm the program is working properly.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 一种常见的临时代码是`print()`语句，用于检查函数或计算的返回值。用户不需要看到输出，因此在确认程序正常工作后，你会删除它。
- en: Useful scaffolding output includes things like the type of a value or variable,
    the length of a dataset, and the results of incremental calculations. To quote
    Allen Downey in *Think Python*, “Time you spend building scaffolding can reduce
    the time you spend debugging.”
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 有用的临时代码输出包括值或变量的类型、数据集的长度以及增量计算的结果。正如Allen Downey在《*Think Python*》中所说，“花时间构建临时代码可以减少你调试时所花的时间。”
- en: The downside to using `print()` statements for debugging is that you have to
    go back and delete (or comment out) all these statements later, and you risk accidentally
    removing a `print()` statement that’s useful to the end user. Fortunately, there’s
    an alternative to scaffolding that lets you avoid these problems. It’s called
    the `logging` module.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`print()`语句进行调试的缺点是，你必须在之后返回并删除（或注释掉）所有这些语句，并且你有可能不小心删除对最终用户有用的`print()`语句。幸运的是，有一种替代方案可以避免这些问题，它叫做`logging`模块。
- en: '***Using the logging Module***'
  id: totrans-84
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***使用 logging 模块***'
- en: 'The `logging` module is part of the Python Standard Library (*[https://docs.python.org/3/library/logging.html](https://docs.python.org/3/library/logging.html)*).
    With `logging`, you can get a customized report on what your program is doing
    at any location you choose. You can even write the reports to a permanent logfile.
    The following interactive shell example uses `logging` to check that a vowel-counting
    program is working correctly:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '`logging`模块是Python标准库的一部分（*[https://docs.python.org/3/library/logging.html](https://docs.python.org/3/library/logging.html)*）。使用`logging`，你可以在任何你选择的位置获取程序正在做什么的定制报告。你甚至可以将报告写入永久的日志文件。以下交互式Shell示例使用`logging`检查一个元音计数程序是否正常工作：'
- en: '[PRE4]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: To use the `logging` module, first import it ➊. Then set up what debugging information
    you want to see and in what format ➋. The `DEBUG` level is the lowest level of
    information and is used for diagnosing the details. Note that the output uses
    string formatting with `%s`. You can include more information—for example, the
    date and time are shown using `format='%(asctime)s'`—but for this snippet of code,
    all you really need to check is whether the program is counting vowels correctly.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 `logging` 模块，首先导入它 ➊。然后设置你想要查看的调试信息以及显示格式 ➋。`DEBUG` 级别是最低的信息级别，用于诊断详细信息。请注意，输出使用了字符串格式化
    `'%s'`。你可以包含更多的信息——例如，日期和时间可以通过 `format='%(asctime)s'` 显示——但对于这段代码，你真正需要检查的只是程序是否正确计数元音。
- en: For each letter evaluated, enter the custom text message to display along with
    the variable values. Note that you have to convert nonstring objects, such as
    integers and lists, to strings ➌. The `logging` output follows. You can see the
    cumulative count, along with which letters actually change the count.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个评估的字母，输入自定义文本消息以显示变量值。请注意，你必须将非字符串对象（如整数和列表）转换为字符串 ➌。接下来是 `logging` 输出。你可以看到累计计数，并且可以查看哪些字母实际上改变了计数。
- en: 'Like scaffolding, `logging` is for the developer, not the user. And like the
    `print()` function, `logging` can slow down your program. To disable the `logging`
    messages, simply insert the `logging.disable(logging.CRITICAL)` call after you
    import the module, as follows:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 像脚手架一样，`logging` 是为开发者而不是用户设计的。就像 `print()` 函数一样，`logging` 也会使程序变慢。要禁用 `logging`
    消息，只需在导入模块后插入 `logging.disable(logging.CRITICAL)` 调用，如下所示：
- en: '[PRE5]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Placing the disable call near the top of the program will allow you to find
    it easily and toggle messages on and off. The `logging.disable()` function will
    suppress all messages at the designated level or lower. Since `CRITICAL` is the
    highest level, passing it to the `logging.disable()` function turns all messages
    off. This is a far better solution than manually finding and commenting out `print()`
    statements!
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 将禁用调用放在程序的顶部，可以让你轻松找到它，并切换消息的开启和关闭。`logging.disable()` 函数将会抑制指定级别或更低级别的所有消息。由于
    `CRITICAL` 是最高级别，传递它给 `logging.disable()` 函数会关闭所有消息。这比手动查找并注释掉 `print()` 语句要好得多！
- en: '**The Code**'
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**代码**'
- en: The *markov_haiku.py* code in this section will take a training corpus called
    *train.txt*, prepare Markov models as dictionaries, and generate a haiku one word
    at a time. The *count_syllables.py* program and *missing_words.json* file from
    [Chapter 8](ch08.xhtml#ch08) will ensure *markov_haiku.py* uses the correct number
    of syllables for each line. You can download all these files from *[https://www.nostarch.com/impracticalpython/](https://www.nostarch.com/impracticalpython/)*
    ([Chapter 9](ch09.xhtml#ch09) folder). Be sure to keep them together in the same
    directory.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中的 *markov_haiku.py* 代码将使用名为 *train.txt* 的训练语料库，准备 Markov 模型作为字典，并一字一字地生成俳句。[第8章](ch08.xhtml#ch08)
    中的 *count_syllables.py* 程序和 *missing_words.json* 文件将确保 *markov_haiku.py* 为每行使用正确的音节数。你可以从
    *[https://www.nostarch.com/impracticalpython/](https://www.nostarch.com/impracticalpython/)*（[第9章](ch09.xhtml#ch09)
    文件夹）下载所有这些文件。务必将它们放在同一目录中。
- en: '***Setting Up***'
  id: totrans-94
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***设置***'
- en: '[Listing 9-1](ch09.xhtml#ch09list1) imports the necessary modules, then loads
    and prepares external files.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '[清单 9-1](ch09.xhtml#ch09list1) 导入必要的模块，然后加载和准备外部文件。'
- en: '*markov_haiku.py,* part 1'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '*markov_haiku.py,* 第 1 部分'
- en: '[PRE6]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '*Listing 9-1: Imports, loads, and prepares the training corpus*'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单 9-1：导入、加载和准备训练语料库*'
- en: Start with the imports listed on separate lines ➊. You’ll need `logging` in
    order to receive debugging messages, and `defaultdict` will help you build a dictionary
    from a list by creating a new key automatically, rather than throwing an error.
    You also import the `count_syllables` function from the *count_syllables.py* program
    you wrote in [Chapter 8](ch08.xhtml#ch08). You should be familiar with the rest
    of these imports.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 从单独的行开始列出导入项 ➊。你需要 `logging` 来接收调试消息，而 `defaultdict` 将帮助你通过自动创建新键来从列表构建字典，而不是抛出错误。你还会从
    [第8章](ch08.xhtml#ch08) 中你编写的 *count_syllables.py* 程序中导入 `count_syllables` 函数。你应该已经熟悉这些导入。
- en: Put the statement to disable `logging` right after the imports so you can find
    it easily. To see logging messages, you need to comment out this statement ➋.
    The following statement configures what you will see, as described in the previous
    section. I chose to omit the level designation from the display.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在导入语句后紧跟禁用`logging`的语句，这样你可以轻松找到它。要查看日志信息，你需要注释掉这个语句 ➋。以下语句配置了你将看到的内容，如前一节所述。我选择从显示中省略级别指定。
- en: Next, define a function to load the training-corpus text file ➌. Use the built-in
    `read()` function to read the data as a string that the program can prepare before
    converting it to a list ➍. Return this string for use in the next function.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，定义一个函数来加载训练语料库的文本文件 ➌。使用内置的`read()`函数将数据作为字符串读取，程序可以在将其转换为列表之前进行准备 ➍。返回该字符串，以供下一个函数使用。
- en: The `prep_training()` function ➎ takes the output from the `load_training_file()`
    function as an argument. It then replaces newline characters with spaces and splits
    the words into list items based on spaces. Finally, the function returns the corpus
    as a list.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '`prep_training()`函数 ➎接收来自`load_training_file()`函数的输出作为参数。然后，它将换行符替换为空格，并根据空格将单词拆分成列表项。最后，函数将语料库作为列表返回。'
- en: '***Building Markov Models***'
  id: totrans-103
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***构建马尔可夫模型***'
- en: The Markov models are simply Python dictionaries that use a word or word pair
    as a key and the word that immediately follows them as a value. The statistical
    frequency of trailing words is captured by repetition of the trailing word in
    the list of values—similar to sets, dictionaries can’t have duplicate *keys*,
    but they can have duplicate *values*.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 马尔可夫模型实际上是 Python 字典，使用单词或单词对作为键，紧随其后的单词作为值。通过重复尾部单词在值列表中的出现，捕获尾部单词的统计频率——类似于集合，字典不能有重复的*键*，但可以有重复的*值*。
- en: '[Listing 9-2](ch09.xhtml#ch09list2) defines two functions. Both functions take
    the corpus as an argument and return a Markov model.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表 9-2](ch09.xhtml#ch09list2)定义了两个函数。这两个函数都以语料库作为参数，并返回一个马尔可夫模型。'
- en: '*markov_haiku.py,* part 2'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '*markov_haiku.py,* 第2部分'
- en: '[PRE7]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '*Listing 9-2: Defines functions that build Markov models of order 1 and 2*'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '*列表 9-2：定义了构建一阶和二阶马尔可夫模型的函数*'
- en: First, define a function to map every single word to its trailing word ➊. The
    program will use this function only to select the haiku’s second word from the
    seed word. Its only parameter is the corpus list that the `prep_training()` function
    returns.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，定义一个函数，将每个单词映射到其尾部单词 ➊。该程序只会使用此函数从种子词中选择俳句的第二个单词。它的唯一参数是`prep_training()`函数返回的语料库列表。
- en: Set a limit so you can’t pick the last word in the corpus ➋, because doing so
    would result in an index error. Now initialize a dictionary using `defaultdict`
    ➌. You want the dictionary values to be lists that hold all the suffixes you find,
    so use `list` as the argument.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 设置一个限制，以便不能选择语料库中的最后一个单词 ➋，因为这样会导致索引错误。现在，使用`defaultdict` ➌初始化一个字典。你希望字典的值是列表，用于存储你找到的所有后缀，因此将`list`作为参数传递。
- en: Start looping through every word in the corpus, using `enumerate` to turn each
    word’s index into an object ➍. Use a conditional and the `limit` variable to prevent
    choosing the last word as a key. Assign a variable named `suffix` that will represent
    the trailing word ➎. The value will be the index location of the current word
    plus 1—the next word in the list. Append this variable to the dictionary as a
    value of the current word.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 开始遍历语料库中的每个单词，使用`enumerate`将每个单词的索引转换为对象 ➍。使用条件判断和`limit`变量来防止选择最后一个单词作为键。定义一个名为`suffix`的变量，表示尾部单词
    ➎。其值将是当前单词的索引位置加 1——即列表中的下一个单词。将这个变量作为当前单词的值添加到字典中。
- en: To check that everything is working as planned, use `logging` to show the results
    *for a single key* ➏. There are thousands of words in the corpus, so you’re not
    going to want to print them all. Choose a word that you know is in the corpus,
    like *sake*. Note that you are using the old string formatting with `%`, as it
    fits the current design of the logger. Finish by returning the dictionary ➐.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检查一切是否按计划工作，使用`logging`显示*单个键*的结果 ➏。语料库中有成千上万的单词，因此你不想打印出所有单词。选择一个你知道在语料库中存在的单词，比如*sake*。请注意，你使用的是旧的字符串格式化方法`%`，因为它适合当前日志记录器的设计。最后返回字典
    ➐。
- en: The next function, `map_2_words_to_word()`, is basically the same function,
    except it uses two consecutive words as the key and maps to trailing single words
    ➑. Important changes are to set the limit two words back from the end of the corpus
    ➒, make the key consist of two words with a space between them ➓, and add 2 to
    the index for the `suffix`.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个函数`map_2_words_to_word()`基本上与前一个函数相同，只是它使用两个连续的单词作为键，并映射到后续的单个单词➑。重要的变化是将限制设定为距语料库结尾两个单词的地方➒，使得键由两个单词组成，并且中间有空格➓，并且对`suffix`的索引加2。
- en: '***Choosing a Random Word***'
  id: totrans-114
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***选择随机单词***'
- en: The program won’t be able to utilize a Markov model without a key, so either
    the user or the program must supply the first word in a simulated haiku. [Listing
    9-3](ch09.xhtml#ch09list3) defines a function that picks a first word at random,
    facilitating automated seeding.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 没有关键字，程序无法利用Markov模型，因此用户或程序必须提供模拟俳句中的第一个单词。[列表 9-3](ch09.xhtml#ch09list3)定义了一个函数，随机选择一个第一个单词，方便自动化种子生成。
- en: '*markov_haiku.py,* part 3'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '*markov_haiku.py*，第3部分'
- en: '[PRE8]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '*Listing 9-3: Randomly chooses a seed word to initiate the haiku*'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '*列表 9-3：随机选择一个种子单词以启动俳句*'
- en: Define the function and pass it the `corpus` list ➊. Then assign a `word` variable
    and use the `random` `choice()` method to pick a word from the corpus ➋.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 定义该函数并将`corpus`列表传递给它➊。然后分配一个`word`变量，并使用`random`的`choice()`方法从语料库中选择一个单词➋。
- en: Use the `count_syllables()` function from the `count_syllables` module to count
    the syllables in the word; store the count in the `num_syls` variable ➌. I’m not
    a fan of single-word lines in haiku, so don’t allow the function to choose a word
    with more than four syllables (recall that the shortest haiku lines have five
    syllables). If this occurs, call the `random_word()` function recursively until
    you get an acceptable word ➍. Note that Python has a default maximum recursion
    depth of 1,000, but as long as you’re using a proper haiku-training corpus, there’s
    little chance you’ll exceed that prior to finding a suitable word. If that were
    not the case, you could address this condition later by calling the function using
    a `while` loop.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`count_syllables()`函数，该函数来自`count_syllables`模块，用于计算单词的音节数；将计算结果存储在`num_syls`变量中➌。我不喜欢在俳句中使用单一单词的行，所以不允许该函数选择音节数超过四个的单词（记住，最短的俳句行有五个音节）。如果发生这种情况，请递归调用`random_word()`函数，直到找到一个合适的单词➍。请注意，Python的默认最大递归深度为1,000，但只要使用的是合适的俳句训练语料库，找到合适单词之前几乎不可能超过这个限制。如果情况并非如此，你可以稍后通过使用`while`循环调用该函数来处理这个条件。
- en: If the word has fewer than five syllables, use `logging` to display the word
    and its syllable count ➎; then return the word and syllable count as a tuple.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 如果单词的音节数少于五个，请使用`logging`显示单词及其音节数➎；然后将单词和音节数作为元组返回。
- en: '***Applying the Markov Models***'
  id: totrans-122
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***应用Markov模型***'
- en: To choose the single word that follows the seed word, use the Markov model of
    order 1\. After that, the program should select all subsequent words using the
    order 2 model, which uses word pairs as keys. [Listing 9-4](ch09.xhtml#ch09list4)
    defines a separate function for each of these actions.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 为了选择紧跟种子单词的单个单词，请使用Markov模型的1阶。之后，程序应使用2阶模型选择所有后续单词，该模型使用单词对作为键。[列表 9-4](ch09.xhtml#ch09list4)为每个这些操作定义了一个单独的函数。
- en: '*markov_haiku.py,* part 4'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '*markov_haiku.py*，第4部分'
- en: '[PRE9]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '*Listing 9-4: Two functions that select a word given a prefix, Markov model,
    and syllable count*'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '*列表 9-4：两个根据前缀、Markov模型和音节数选择单词的函数*'
- en: Define a function named `word_after_single()` to select the next word in the
    haiku based on the preceding single seed word. For arguments, this function takes
    the preceding word, the Markov order 1 model, the current syllable count, and
    the target syllable count ➊.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 定义一个名为`word_after_single()`的函数，用于根据前一个单一的种子单词选择俳句中的下一个单词。该函数的参数包括前一个单词、Markov
    1阶模型、当前音节数和目标音节数➊。
- en: Start an empty list to hold the acceptable words, which are the words that both
    follow the prefix and whose syllable count doesn’t exceed the syllable target
    ➋. Call these trailing words `suffixes` and use the dictionary `get()` method,
    which returns a dictionary value given a key, to assign them to the variable ➌.
    Rather than raising a `KeyError`, the `get()` method will return `None` if you
    request a key that isn’t in the dictionary.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 开始一个空列表，用于存储符合条件的单词，这些单词既跟随前缀，又没有超出音节目标的音节数➋。将这些后续单词命名为`suffixes`，并使用字典的`get()`方法，该方法根据键返回字典值，将这些单词分配给变量➌。如果请求一个字典中不存在的键，`get()`方法不会引发`KeyError`，而是返回`None`。
- en: There is the extremely rare chance that the prefix will be the last word in
    a corpus and that it will be unique. In that case, there will be no suffixes.
    Use an `if` statement to anticipate this ➍. If there are no suffixes, the function
    that calls `word_after_single()`, which you’ll define in the next section, chooses
    a new prefix.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '存在一个极为罕见的情况，即前缀可能是语料库中的最后一个单词，并且该单词是唯一的。在这种情况下，将没有后缀。使用 `if` 语句来预见这种情况 ➍。如果没有后缀，调用
    `word_after_single()` 的函数——你将在下一部分定义——将选择一个新的前缀。  '
- en: Each of the suffixes represents a *candidate* word for the haiku, but the program
    hasn’t yet determined whether a candidate will “fit.” So use a `for` loop, the
    `count_syllables` module, and an `if` statement to determine whether adding the
    word to the line violates the target number of syllables per line ➎. If the target
    isn’t exceeded, append the word to the list of accepted words ➏. Display the acceptable
    words in a `logging` message and then return it ➐.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '每个后缀都代表一个*候选*单词，但程序尚未确定该候选词是否“合适”。因此，使用 `for` 循环、`count_syllables` 模块和 `if`
    语句来判断将该单词添加到行中是否会违反每行的目标音节数➎。如果目标音节数未超出，则将该单词添加到已接受单词列表中➏。通过 `logging` 消息显示这些可接受的单词，然后返回它们➐。  '
- en: The next function, `word_after_double()`, is like the previous function except
    that you pass it word pairs and the Markov order 2 model (`suffix_map_2`) ➑ and
    get the suffixes from this dictionary ➒. But just like the `word_after_single()`
    function, `word_after_double()` returns a list of acceptable words ➓.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '下一个函数 `word_after_double()` 和之前的函数类似，不同之处在于它接收的是单词对以及马尔可夫二阶模型（`suffix_map_2`）➑，并从该字典中获取后缀➒。但和
    `word_after_single()` 函数一样，`word_after_double()` 返回的是一个可接受单词的列表➓。  '
- en: '***Generating the Haiku Lines***'
  id: totrans-132
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***生成俳句行***  '
- en: 'With all the helper functions ready, you can define the function that actually
    writes the lines of the haiku. The function can build either the whole haiku or
    just update lines two or three. There are two paths to take: one to use when the
    program has at most a one-word suffix to work with and another for every other
    situation.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '准备好所有辅助函数后，你可以定义实际编写俳句行的函数。该函数可以构建完整的俳句或仅更新第二行或第三行。有两条路径可以选择：一种是在程序只有一个词的后缀时使用，另一种则适用于其他所有情况。  '
- en: '**Building the First Line**'
  id: totrans-134
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**构建第一行**  '
- en: '[Listing 9-5](ch09.xhtml#ch09list5) defines the function that writes haiku
    lines and initiates the haiku’s first line.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '[清单9-5](ch09.xhtml#ch09list5) 定义了写入俳句行并初始化俳句第一行的函数。'
- en: '*markov_haiku.py,* part 5'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '*markov_haiku.py,* 第5部分  '
- en: '[PRE10]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '*Listing 9-5: Defines the function that writes haiku lines and initiates the
    first line*'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单9-5：定义了写入俳句行并初始化第一行的函数*  '
- en: Define a function that takes as arguments both Markov models, the training corpus,
    the last word pair from the end of the preceding line, and the target number of
    syllables for the current line ➊. Immediately use a variable to specify which
    haiku lines are being simulated ➋. Most of the processing will be for lines two
    and three (and possibly the last part of line one), where you will be working
    with an existing word-pair prefix, so let these represent the base case. After
    this, start a counter for the running total of syllables in the line and start
    an empty list to hold the words in the current line.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '定义一个函数，接受两个马尔可夫模型、训练语料库、上一行最后一个单词对以及当前行的目标音节数➊。立即使用一个变量来指定正在模拟的是哪一行俳句➋。大多数处理将针对第二行和第三行（以及可能是第一行的最后一部分），这时你会使用已有的单词对前缀，因此将这些作为基础情况。之后，开始一个计数器来统计当前行的音节总数，并初始化一个空列表来存放当前行的单词。  '
- en: Use an `if` statement that’s `True` under the condition that the `end_prev_line`
    parameter’s length—the number of syllables in the previous line’s last two words—is
    0, meaning there was no preceding line and you are on line one ➌. The first statement
    in that `if` block changes the `line` variable to 1 ➍.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '使用一个 `if` 语句，当 `end_prev_line` 参数的长度——上一行最后两个单词的音节数为0时，表示没有前一行，此时你就在第一行➌。该
    `if` 块中的第一条语句将 `line` 变量设置为1 ➍。  '
- en: Choose the initial seed word and get its syllable count by calling the `random_word()`
    function ➎. By assigning the `word` and `num_syls` variables together, you are
    “unpacking” the `(word, num_sylls)` tuple that the `random_word()` function returns.
    Functions end at `return` statements, so returning tuples is a great way to return
    multiple variables. In a more advanced version of this program, you could use
    generator functions with the `yield` keyword, as `yield` returns a value without
    relinquishing control of execution.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 选择初始种子词，并通过调用`random_word()`函数 ➎获取其音节数。通过将`word`和`num_syls`变量一起赋值，你实际上是在“解包”`random_word()`函数返回的`(word,
    num_sylls)`元组。函数在`return`语句处结束，因此返回元组是返回多个变量的好方法。在这个程序的更高级版本中，你可以使用带有`yield`关键字的生成器函数，因为`yield`返回一个值而不放弃执行控制。
- en: Next, append the `word` to `current_line` and add the `num_syls` to the running
    total. Now that you have a seed, collect all the seed’s possible suffixes with
    the `word_after_single()` function ➏.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，将`word`附加到`current_line`并将`num_syls`加到运行总数中。现在你已经有了种子，使用`word_after_single()`函数
    ➏收集该种子的所有可能后缀。
- en: If there are no acceptable words, start a `while` loop to handle this situation.
    This loop will continue until a non-empty list of acceptable word choices has
    been returned ➐. The program will choose a new prefix—a ghost prefix—using the
    `random` module’s `choice` method. (Remember that this prefix will not become
    part of the haiku but is used only to reaccess the Markov model.) Inside the `while`
    loop, a `logging` message will let you know which ghost prefix has been chosen.
    Then the program will call `word_after_single()` function once more.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有可接受的单词，启动一个`while`循环来处理这种情况。该循环将持续进行，直到返回一个非空的可接受单词列表 ➐。程序将选择一个新的前缀——一个幽灵前缀——使用`random`模块的`choice`方法。（记住，这个前缀不会成为俳句的一部分，而仅仅是用于重新访问马尔可夫模型。）在`while`循环内部，一条`logging`消息将告诉你选择了哪个幽灵前缀。然后程序将再次调用`word_after_single()`函数。
- en: Once the list of acceptable words is built, use `choice` again to select a word
    from the `word_choices` list ➑. Because the list may include duplicate words,
    this is where you see the statistical impact of the Markov model. Follow by counting
    the syllables in the word and `logging` the results.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦可接受的单词列表构建完成，再次使用`choice`从`word_choices`列表中选择一个单词 ➑。因为列表可能包含重复的单词，所以这就是你看到马尔可夫模型统计影响的地方。接下来，计算单词的音节数并`logging`结果。
- en: Add the syllable count to the line’s running total and append the word to the
    `current_line` list ➒.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 将音节计数加到该行的运行总数，并将单词附加到`current_line`列表 ➒。
- en: If the number of syllables in the first two words equals 5 ➓, name a variable
    `end_prev_line` and assign it the last two words of the previous line; this variable
    is the prefix for line two. Finally, return the whole line and the `end_prev_line`
    variable.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 如果前两个词的音节数等于 5 ➓，则定义一个变量`end_prev_line`并将其赋值为上一行的最后两个词；这个变量是第二行的前缀。最后，返回整行和`end_prev_line`变量。
- en: If the target number of syllables for the first line hasn’t been reached, the
    program will jump to the `while` loop in the next section to complete the line.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 如果第一行的目标音节数还没有达到，程序将跳转到下一部分的`while`循环以完成这一行。
- en: '**Building the Remaining Lines**'
  id: totrans-148
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**构建剩余的行**'
- en: In [Listing 9-6](ch09.xhtml#ch09list6), the last part of the `haiku_line()`
    function addresses the case where the haiku already contains a word-pair prefix
    that the program can use in the Markov order 2 model. The program uses it to complete
    line one—assuming the first two words didn’t already total five syllables—and
    to build lines two and three. The user will also be able to regenerate lines two
    or three, after a complete haiku has been written.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在[列表 9-6](ch09.xhtml#ch09list6)中，`haiku_line()`函数的最后部分处理了这样一种情况，即俳句已经包含了一个词对前缀，程序可以在马尔可夫模型2中使用它。程序利用这个前缀来完成第一行——假设前两个词还没有总共五个音节——并构建第二行和第三行。用户还可以在完整的俳句写完后重新生成第二行或第三行。
- en: '*markov_haiku.py,* part 6'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '*markov_haiku.py,* 第6部分'
- en: '[PRE11]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '*Listing 9-6: Uses a Markov order 2 model to complete the function that writes
    haiku lines*'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '*列表 9-6：使用马尔可夫模型2来完成写俳句行的函数*'
- en: Start with an `else` statement that’s executed if there is a suffix ➊. Since
    the last part of the `haiku_line()` function has to handle line one as well as
    lines two and three, use a trick where you add the `end_prev_line` list (built
    outside the conditional at step ➑) to the `current_line` list ➋. Later, when you
    add the finalized line to the haiku, you’ll discard this leading word pair.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '从一个`else`语句开始，只有在存在后缀时才会执行 ➊。由于`haiku_line()`函数的最后部分必须处理第一行以及第二行和第三行，因此使用一个技巧，在步骤➑的条件外，将`end_prev_line`列表（在步骤➑外部构建）添加到`current_line`列表中
    ➋。稍后，当你将最终的行添加到俳句中时，你将丢弃这个前导单词对。  '
- en: 'Start a `while` loop that continues until the target syllable count for the
    line has been reached ➌. The start of each iteration begins with a debugging message
    that informs you of the path the loop is evaluating: `''1''` or `''2/3''`.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '启动一个`while`循环，直到该行的目标音节数达到为止 ➌。每次迭代的开始都包含一条调试信息，告诉你当前循环正在评估的路径：`''1''`或`''2/3''`。  '
- en: With the last two words of the previous line added to the start of the current
    line, the last two words of the current line will always be the prefix ➍.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '将上一行的最后两个单词添加到当前行的开头时，当前行的最后两个单词将始终是前缀 ➍。  '
- en: Using the Markov order 2 model, create a list of acceptable words ➎. In the
    event the list is empty, the program uses the ghost prefix process ➏.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '使用马尔科夫顺序2模型，创建一个可接受的单词列表 ➎。若该列表为空，程序将使用幽灵前缀过程 ➏。  '
- en: Evaluate what to do next using the syllable count ➐. If there are too many syllables,
    use a `continue` statement to restart the `while` loop. If there aren’t enough
    syllables, append the word and add its syllable count to the line’s syllable count.
    Otherwise, append the word and end the loop.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '使用音节数来评估接下来该做什么 ➐。如果音节过多，使用`continue`语句重新开始`while`循环。如果音节不足，将单词附加到当前行，并将其音节数加到该行的音节数中。否则，将单词附加到行中并结束循环。  '
- en: Assign the last two words in the line to the `end_prev_line` variable so the
    program can use it as a prefix for the next line ➑. If the current path is line
    `'1'`, copy the current line to a variable called `final_line`; if the path is
    line `'2/3'`, use index slicing to exclude the first two words before assigning
    to `final_line` ➒. This is how you remove the initial `end_prev_line` word pair
    from lines two or three.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '将行中的最后两个单词赋值给`end_prev_line`变量，以便程序将其作为下一行的前缀 ➑。如果当前路径是行`''1''`，将当前行复制到名为`final_line`的变量中；如果路径是行`''2/3''`，使用索引切片排除前两个单词，然后赋值给`final_line`
    ➒。这就是如何从第二行或第三行中移除初始的`end_prev_line`单词对。  '
- en: '***Writing the User Interface***'
  id: totrans-159
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***编写用户界面***  '
- en: '[Listing 9-7](ch09.xhtml#ch09list7) defines the *markov_haiku.py* program’s
    `main()` function, which runs the setup functions and the user interface. The
    interface presents the user with a menu of choices and displays the resulting
    haiku.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '[清单9-7](ch09.xhtml#ch09list7)定义了*markov_haiku.py*程序的`main()`函数，该函数运行设置功能和用户界面。界面向用户呈现一个选项菜单，并显示生成的俳句。'
- en: '*markov_haiku.py,* part 7'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '*markov_haiku.py*，第7部分  '
- en: '[PRE12]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '*Listing 9-7: Starts the program and presents a user interface*'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单9-7：启动程序并呈现用户界面*  '
- en: After the introduction message, load and prep the training corpus and build
    the two Markov models. Then create an empty list to hold the final haiku ➊. Next,
    name a `choice` variable and set it to `None`. Start a `while` loop that continues
    until the user chooses choice 0 ➋. By entering `0`, the user has decided to quit
    the program.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '在介绍信息之后，加载并准备训练语料库，并构建两个马尔科夫模型。然后创建一个空列表来存储最终的俳句 ➊。接下来，命名一个`choice`变量并将其设置为`None`。启动一个`while`循环，直到用户选择0
    ➋。通过输入`0`，用户决定退出程序。  '
- en: Use a `print()` statement with triple quotes to display a menu ➌, and then get
    the user’s choice ➍. If the user chooses 0, exit and say goodbye ➎. If the user
    chooses 1, they want the program to generate a new haiku, so reinitialize the
    `final` list and the `end_prev_line` variable ➏. Then call the `haiku_line()`
    function for all three lines and pass it the correct arguments—including the target
    syllable count for each line. Note that the `end_prev_line` variable name changes
    with each line; for example, `end_prev_line2` holds the final two words of line
    two. The last variable, `end_prev_line3`, is just a placeholder so you can reuse
    the function; in other words, it is never put to use. Each time the `haiku_line()`
    function is called, it returns a line that you need to append to the `final` list.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 使用带三引号的 `print()` 语句来显示菜单 ➌，然后获取用户的选择 ➍。如果用户选择 0，退出并说再见 ➎。如果用户选择 1，他们希望程序生成一个新的俳句，所以重新初始化
    `final` 列表和 `end_prev_line` 变量 ➏。然后为三行调用 `haiku_line()` 函数，并传递正确的参数——包括每行的目标音节数。请注意，`end_prev_line`
    变量名会随每行变化；例如，`end_prev_line2` 存储第二行的最后两个词。最后一个变量 `end_prev_line3` 只是一个占位符，以便你可以重用函数；换句话说，它从未被实际使用。每次调用
    `haiku_line()` 函数时，它都会返回一行，你需要将其附加到 `final` 列表中。
- en: If the user chooses 2, the program regenerates the second line ➐. There needs
    to be a full haiku before the program can rebuild a line, so use an `if` statement
    to handle the user jumping the gun. Then call the `haiku_line()` function, making
    sure to pass it the `end_prev_line1` variable to link it to the preceding line,
    and set the syllable target to seven syllables. Insert the rebuilt line in the
    `final` list at index 1.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 如果用户选择 2，程序会重新生成第二行 ➐。在程序重新构建一行之前，需要有一首完整的俳句，因此需要使用 `if` 语句来处理用户提前操作的情况。然后调用
    `haiku_line()` 函数，并确保传递 `end_prev_line1` 变量，将其与前一行连接，并将音节目标设置为七个音节。将重建的行插入到 `final`
    列表的索引 1 位置。
- en: Repeat the process if the user chooses 3, only make the syllable target `5`
    and pass `end_prev_line2` to the `haiku_line()` function ➑. Insert the line at
    index 2 in `final`.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 如果用户选择 3，重复此过程，只不过将音节目标设置为 `5`，并将 `end_prev_line2` 传递给 `haiku_line()` 函数 ➑。将这一行插入到
    `final` 列表的索引 2 位置。
- en: If the user enters anything not on the menu, let them know and then continue
    the loop ➒. Finish by displaying the haiku. Use the `join()` method and `file=sys.stderr`
    for an attractive printout in the shell ➓.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 如果用户输入菜单中没有的选项，提醒他们并继续循环 ➒。最后显示俳句。使用 `join()` 方法和 `file=sys.stderr` 来在 shell
    中打印出漂亮的输出 ➓。
- en: End the program with the standard code for running the program as a module or
    in stand-alone mode.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 使用标准代码结束程序，以便将程序作为模块或独立模式运行。
- en: '**The Results**'
  id: totrans-170
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**结果**'
- en: 'To evaluate a poetry-writing program, you need a way to measure something subjective—whether
    or not poems are “good”—using objective criteria. For the *markov_haiku.py* program,
    I propose the following categories based on two criteria, originality and humanness:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 要评估一个写诗程序，你需要用客观标准来衡量一些主观的东西——诗歌是否“好”。对于 *markov_haiku.py* 程序，我提出以下基于原创性和人性化两个标准的分类：
- en: '**Duplicate** Verbatim duplication of a haiku in the training corpus.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '**重复** 训练语料库中的俳句逐字重复。'
- en: '**Good** A haiku that is—at least to some people—indistinguishable from a haiku
    written by a human poet. It should represent the initial result or the result
    of regenerating line two or three a few times.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '**好** 一首俳句——至少对某些人来说——与人类诗人写的俳句几乎无法区分。它应该代表初步结果，或是第二行或第三行经过几次重生后的结果。'
- en: '**Seed** A haiku that has merit but that many would suspect was written by
    a computer, or a haiku that you could transform into a good haiku by changing
    or repositioning no more than two words (described in more detail later). It may
    require multiple regenerations of lines two or three.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '**种子** 一首有一定价值的俳句，但许多人可能会怀疑它是由计算机写的，或者一首你可以通过更改或重新排列不超过两个词来转变为一首好俳句的作品（稍后会更详细说明）。这可能需要对第二行或第三行进行多次重生。'
- en: '**Rubbish** A haiku that is clearly a random amalgam of words and has no merit
    as a poem.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '**垃圾** 一首明显是随机拼凑的词汇组合，毫无诗意可言。'
- en: If you use the program to generate a large number of haiku and place the results
    in these categories, you’ll probably end up with the distribution in [Figure 9-3](ch09.xhtml#ch09fig3).
    About 5 percent of the time, you’ll duplicate an existing haiku in the training
    corpus; 10 percent of the time, you’ll produce a good haiku; around 25 percent
    will be passable or fixable haiku; and the rest will be rubbish.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用程序生成大量俳句，并将结果归入这些类别，你可能会得到[图9-3](ch09.xhtml#ch09fig3)中的分布情况。大约5%的时间，你会重复训练语料库中的现有俳句；10%的时间，你会生成一首好俳句；约25%会是及格或可修正的俳句；其余的则是垃圾。
- en: '![image](../images/f0181-01.jpg)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/f0181-01.jpg)'
- en: '*Figure 9-3: Subjective results of generating 500 haiku using* markov_haiku.py'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '*图9-3：使用* markov_haiku.py *生成500个俳句的主观结果*'
- en: Considering how simple the Markov process is, the results in [Figure 9-3](ch09.xhtml#ch09fig3)
    are impressive. To quote Charles Hartman once again, “Here is language creating
    itself out of nothing, out of mere statistical noise. . . . We can watch sense
    evolve and meaning stagger up onto its own miraculous feet.”
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到马尔可夫过程的简单性，[图9-3](ch09.xhtml#ch09fig3)中的结果令人印象深刻。再引用查尔斯·哈特曼的话，“这里是语言从无到有，从纯粹的统计噪声中自我创造出来……我们可以看着意义逐渐演化，意识慢慢站立在自己奇迹般的双腿上。”
- en: '***Good Haiku***'
  id: totrans-180
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***好俳句***'
- en: The following are some examples of simulated haiku classified as “good.” In
    the first example, the program has subtly—you might say “skillfully,” if you didn’t
    know an algorithm was responsible—altered my haiku from [Chapter 8](ch08.xhtml#ch08)
    to produce a new haiku with the same meaning.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些被归类为“好”的模拟俳句的示例。在第一个示例中，程序巧妙地——如果你不知道是算法的功劳，你甚至可以说是“巧妙地”——改变了我在[第8章](ch08.xhtml#ch08)中的俳句，生成了一个具有相同含义的新俳句。
- en: Cloudbanks that I let
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 我所放任的云层
- en: Myself pretend are distant
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我自己假装远离
- en: Mountains faraway
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 遥远的山脉
- en: 'In the next example, the program has managed to duplicate a common theme in
    traditional haiku: the juxtaposition of images or ideas.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个示例中，程序成功地复制了传统俳句中的常见主题：图像或思想的并置。
- en: The mirror I stare
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我凝视着的镜子
- en: Into shows my father’s face
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 显示的是我父亲的面容
- en: An old silent pond
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 一池古老寂静的池塘
- en: In this case, you find out that the mirror is really the surface of a still
    pond, though you may interpret the face itself as the pond.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，你会发现镜子其实就是静止池塘的表面，尽管你可以将脸本身解读为池塘。
- en: 'Running the program is a little like panning for gold: sometimes you find a
    nugget. The haiku on the left was written by Ringai over 300 years ago. In the
    haiku on the right, the program has made subtle changes so that the poem now evokes
    images of a late spring freeze—a setback for the progress of the season.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 运行程序有点像淘金：有时你会找到一块金块。左边的俳句是300多年前由Ringai创作的。在右边的俳句中，程序做了微妙的修改，使得诗句现在唤起了晚春霜冻的画面——这是季节进程中的一次倒退。
- en: '| In these dark watersDrawn up from my frozen wellGlittering of Spring                    —*Ringai*
    | Waters drawn up fromMy frozen well glitteringOf Spring standing still                         —*Python*
    |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| 在这黑暗的水中从我冰冻的井中汲起闪闪发光的春天            —*Ringai* | 从我的冰冻井中汲起闪闪发光的春天站立不动                         —*Python*
    |'
- en: The following are examples of a few more “good” haiku. The first one is remarkable
    since it was built from three separate haiku in the training corpus, yet maintains
    a clear contextual thread throughout.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是更多“好”俳句的示例。第一个俳句尤为突出，因为它是由训练语料库中的三个独立俳句组成的，但在整个过程中保持了清晰的上下文联系。
- en: As I walk the path
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 当我走在小路上
- en: Eleven brave knights canter
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 十一位勇敢的骑士在风暴中疾驰
- en: Through the stormy woods
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 通过风雨中的树林
- en: A line flip-flapping
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 一条摇摆的线
- en: Across the dark crimson sky
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 穿越黑暗的深红色天空
- en: On this winter pond
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个冬日的池塘上
- en: Such a thing alive
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的一种生命
- en: Rusted gate screeches open
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 生锈的门吱吱作响
- en: Even things feel pain
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 连事物都感受到痛苦
- en: The stone bridge! Sitting
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 石桥！坐着
- en: Quietly doing nothing
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 静静地什么也不做
- en: Yet Spring comes grass grows
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 然而春天来临，草长
- en: Dark sky oh! Autumn
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 黑暗的天空，哦！秋天
- en: Snowflakes! A rotting pumpkin
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 雪花！一只腐烂的南瓜
- en: Collapsed and covered
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 崩塌且被覆盖
- en: Desolate moors fray
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 荒凉的沼泽变得模糊
- en: Black cloudbank, broken, scatters
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 黑色的云层破碎，四散开来
- en: In the pines, the graves
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在松树中，坟墓
- en: '***Seed Haiku***'
  id: totrans-211
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***种子俳句***'
- en: The concept of computers helping humans write poetry has been around for some
    time. Poets often “prime the pump” by imitating earlier poems, and there’s no
    reason a computer can’t provide first drafts as part of a cyber-partnership. Even
    a fairly poor computer creation has the potential to “seed” the creative process
    and help a human overcome writer’s block.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机协助人类写诗的概念已经存在一段时间。诗人通常通过模仿早期的诗歌来“启发灵感”，没有理由认为计算机不能作为网络合作的一部分，提供初稿。即使是相当糟糕的计算机创作，也有可能为创作过程“播种”，并帮助人类克服创作障碍。
- en: The following are three examples of seed haiku from the *markov_haiku.py* program.
    On the left is the not-quite-right computer-generated haiku. On the right is the
    version that I adjusted. I changed only a single word, highlighted in bold, in
    each.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是*markov_haiku.py*程序生成的三个种子俳句示例。左侧是计算机生成的略显不准确的俳句，右侧是我调整后的版本。我在每个版本中只更改了一个单词，并将其加粗显示。
- en: '| My life must end likeAnother flower what aHungry wind **it** is | My life
    must end likeAnother flower what aHungry wind is **death** |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| 我的生命必须像另一个花朵一样结束，什么饥饿的风**它**是 | 我的生命必须像另一个花朵一样结束，什么饥饿的风是**死亡** |'
- en: '|  |  |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '|  |  |'
- en: '| The dock floating inThe hot caressing night justBefore the dawn **old** |
    The dock floating inThe hot caressing night justBefore the dawn **rain** |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| 码头漂浮在热烈抚摸的夜晚中，正是在黎明前**老** | 码头漂浮在热烈抚摸的夜晚中，正是在黎明前**雨** |'
- en: '|  |  |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '|  |  |'
- en: '| Moonrise on the graveAnd my old sadness a sharpShovel thrust **the** stars
    | Moonrise on the graveAnd my old sadness a sharpShovel thrust **of** stars |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| 月升在坟墓上，我的旧悲伤一把锋利的铲子刺**入**星星 | 月升在坟墓上，我的旧悲伤一把锋利的铲子刺**向**星星 |'
- en: 'The last has cryptic meaning but seems to work, as it is filled with natural
    associations (moon and stars, grave and shovel, grave and sadness). At any rate,
    you shouldn’t fret too much over meaning. To paraphrase T.S. Eliot: meaning is
    like the meat the burglar throws the dog, to keep the mind diverted while the
    poem does its work!'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 最后的句子含义隐晦，但似乎有效，因为它充满了自然的联想（如月亮与星星、坟墓与铲子、坟墓与悲伤）。无论如何，你不必过于纠结其含义。用T.S. 艾略特的话来说：意义就像是小偷给狗的肉，用来分散注意力，让诗歌完成它的工作！
- en: '**Summary**'
  id: totrans-220
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**总结**'
- en: It took two chapters, but you now have a program that can simulate Japanese
    haiku written by the masters—or at least provide a useful starting point for a
    human poet. In addition, you applied the `logging` module to monitor what the
    program was doing at key steps.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 经过两章的学习，你现在已经有了一个能够模拟由大师创作的日本俳句的程序——至少能为人类诗人提供一个有用的起点。此外，你还应用了`logging`模块来监控程序在关键步骤中的操作。
- en: '**Further Reading**'
  id: totrans-222
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**进一步阅读**'
- en: '*Virtual Muse: Experiments in Computer Poetry* (Wesleyan University Press,
    1996) by Charles O. Hartman is an engaging look at the early collaboration between
    humans and computers to write poetry.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '*虚拟缪斯：计算机诗歌实验*（Wesleyan University Press，1996年）由查尔斯·O·哈特曼（Charles O. Hartman）编著，是一本引人入胜的书，探讨了人类与计算机早期合作创作诗歌的过程。'
- en: 'If you want to know more about Claude Shannon, check out *A Mind at Play: How
    Claude Shannon Invented the Information Age* (Simon & Schuster, 2017) by Jimmy
    Soni and Rod Goodman.'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多关于克劳德·香农的信息，可以阅读吉米·索尼（Jimmy Soni）和罗德·古德曼（Rod Goodman）编著的*玩转思维：克劳德·香农如何发明信息时代*（Simon
    & Schuster，2017年）。
- en: 'You can find a digital version of *Japanese Haiku: Two Hundred Twenty Examples
    of Seventeen-Syllable Poems* (The Peter Pauper Press, 1955), translated by Peter
    Beilenson, online at Global Grey (*[https://www.globalgreyebooks.com/](https://www.globalgreyebooks.com/)*).'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在Global Grey网站（*[https://www.globalgreyebooks.com/](https://www.globalgreyebooks.com/)）找到*日本俳句：二百二十首十七音节诗*（The
    Peter Pauper Press，1955年） 的数字版，译者为彼得·贝伦森（Peter Beilenson）。
- en: 'In the paper “Gaiku: Generating Haiku with Word Association Norms” (Association
    for Computational Linguistics, 2009), Yael Netzer and coauthors explore the use
    of word association norms (WANs) to generate haiku. You can build WAN corpora
    by submitting trigger words to people and recording their immediate responses
    (for example, *house* to *fly*, *arrest*, *keeper*, and so on). This results in
    the kind of tightly linked, intuitive relationships characteristic of human-generated
    haiku. You can find the paper online at *[http://www.cs.brandeis.edu/~marc/misc/proceedings/naacl-hlt-2009/CALC-09/pdf/CALC-0905.pdf](http://www.cs.brandeis.edu/~marc/misc/proceedings/naacl-hlt-2009/CALC-09/pdf/CALC-0905.pdf)*.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 在论文《Gaiku：利用词汇联想规范生成俳句》（计算语言学协会，2009）中，Yael Netzer及其合著者探讨了使用词汇联想规范（WANs）生成俳句的方法。你可以通过向人们提交触发词并记录他们的即时反应（例如，将*house*与*fly*、*arrest*、*keeper*等联想）来建立WAN语料库。这会产生类似人类生成的俳句中紧密联系、直觉性的关系。你可以在网上找到这篇论文，网址是*[http://www.cs.brandeis.edu/~marc/misc/proceedings/naacl-hlt-2009/CALC-09/pdf/CALC-0905.pdf](http://www.cs.brandeis.edu/~marc/misc/proceedings/naacl-hlt-2009/CALC-09/pdf/CALC-0905.pdf)*。
- en: '*Automate the Boring Stuff with Python* (No Starch Press, 2015) by Al Sweigart
    has a useful overview chapter on debugging techniques, including `logging`.'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 《*用Python自动化无聊的事*》（No Starch Press, 2015）由Al Sweigart编写，其中有一章关于调试技巧的有用概述，包括`logging`。
- en: '**Challenge Projects**'
  id: totrans-228
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**挑战项目**'
- en: I’ve described some suggestions for spin-off projects in this section. As with
    all challenge projects, you’re on your own—no solutions are provided.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 我在这一部分中描述了一些衍生项目的建议。与所有挑战项目一样，你将独立完成——不会提供解决方案。
- en: '***New Word Generator***'
  id: totrans-230
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***新词生成器***'
- en: In his award-winning 1961 sci-fi novel, *Stranger in a Strange Land*, author
    Robert A. Heinlein invented the word *grok* to represent deep, intuitive understanding.
    This word moved into the popular culture—especially the culture of computer programming—and
    is now in the *Oxford English Dictionary*.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 在他1961年获奖的科幻小说《*陌生的土地*》中，作家Robert A. Heinlein创造了词汇*grok*，表示深刻的直觉理解。这个词进入了流行文化——特别是计算机编程文化——现在已被收入*牛津英语词典*。
- en: Coming up with a new word that sounds legitimate is not easy, in part because
    humans are so anchored to the words we already know. But computers don’t suffer
    from this affliction. In *Virtual Muse*, Charles Hartman observed that his poetry-writing
    program would sometimes create intriguing letter combinations, such as *runkin*
    or *avatheformitor*, that could easily represent new words.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 想出一个听起来合法的新词并不容易，部分原因是人类对我们已经知道的词汇有很强的依赖性。但是计算机不受这种困扰。在《*虚拟缪斯*》中，Charles Hartman观察到，他的诗歌创作程序有时会生成一些有趣的字母组合，例如*runkin*或*avatheformitor*，这些组合很容易代表新的词汇。
- en: Write a program that recombines letters using Markov order 2, 3, and 4 models
    and use the program to generate interesting new words. Give them a definition
    and start applying them. Who knows—you may coin the next *frickin*, *frabjous*,
    *chortle*, or *trill*!
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 编写一个程序，使用马尔科夫顺序2、3和4模型重新组合字母，并使用该程序生成有趣的新词。给它们定义一个意思并开始使用它们。谁知道呢——你可能会创造出下一个*frickin*、*frabjous*、*chortle*或*trill*！
- en: '***Turing Test***'
  id: totrans-234
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***图灵测试***'
- en: According to Alan Turing, “A computer would deserve to be called intelligent
    if it could deceive a human into believing that it was human.” Use your friends
    to test haiku generated by the *markov_haiku.py* program. Mix the computer haiku
    with a few haiku written by the masters or yourself. Since computer haiku are
    often enjambed, be careful to choose human haiku that are also enjambed in order
    to deny your cleverer friends a free ride. Using lowercase letters and minimal
    punctuation for all the haiku also helps. I’ve provided an example, using Facebook,
    in [Figure 9-4](ch09.xhtml#ch09fig4).
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 根据Alan Turing的说法：“如果一台计算机能够欺骗一个人，让他相信它是人类，那么它就应该被称为智能。”利用你的朋友测试*markov_haiku.py*程序生成的俳句。将计算机生成的俳句与一些大师或你自己写的俳句混合。由于计算机生成的俳句往往是断句的，因此要小心选择人类的俳句，这些俳句也需要是断句的，以防聪明的朋友轻松识破。使用小写字母和最少的标点符号也有助于此。我在[图9-4](ch09.xhtml#ch09fig4)中提供了一个例子，使用了Facebook。
- en: '![image](../images/f0185-01.jpg)'
  id: totrans-236
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/f0185-01.jpg)'
- en: '*Figure 9-4: Example Turing test experiment post on Facebook*'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '*图9-4：Facebook上的图灵测试实验示例*'
- en: '***Unbelievable! This Is Unbelievable! Unbelievable!***'
  id: totrans-238
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***难以置信！这简直太难以置信了！难以置信！***'
- en: 'President Trump is famous for speaking in short, simple sentences that use
    “the best words,” and short, simple sentences are great for haiku. In fact, the
    *Washington Post* published some inadvertent haiku found in some of his campaign
    speeches. Among these were:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 特朗普总统以简短、简单的句子著称，他的句子使用“最好的词汇”，而简短、简单的句子非常适合俳句。事实上，*华盛顿邮报*曾刊登过他一些竞选演讲中无意间形成的俳句。以下是其中的一些：
- en: He’s a great, great guy.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 他是个非常棒的人。
- en: I saw him the other day.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 我前几天见过他。
- en: On television.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在电视上。
- en: They want to go out.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 他们想外出。
- en: They want to lead a good life.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 他们想过上好生活。
- en: They want to work hard.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 他们想努力工作。
- en: We have to do it.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须做到这一点。
- en: And we need the right people.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要合适的人选。
- en: So Ford will come back.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 所以福特会回归。
- en: Use online transcripts of Donald Trump’s speeches to build a new training corpus
    for the *markov_haiku.py* program. Remember that you’ll need to revisit [Chapter
    8](ch08.xhtml#ch08) and build a new “missing words” dictionary for any words not
    in the *Carnegie Mellon University Pronouncing Dictionary*. Then rerun the program
    and generate haiku that capture this moment in history. Save the best ones and
    revisit the Turing test challenge to see if your friends can separate your haiku
    from true Trump quotes.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 使用唐纳德·特朗普演讲的在线文字稿，为*markov_haiku.py*程序构建一个新的训练语料库。记得你需要重新访问[第8章](ch08.xhtml#ch08)，并为*卡内基梅隆大学发音词典*中没有的单词构建一个新的“缺失词汇”字典。然后重新运行程序，生成能够捕捉这个历史时刻的俳句。保存最好的作品，并重新挑战图灵测试，看看你的朋友能否分辨出你的俳句和真正的特朗普名言。
- en: '***To Haiku, or Not to Haiku***'
  id: totrans-250
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***写俳句，还是不写俳句***'
- en: William Shakespeare wrote many famous phrases that fit the syllabic structure
    of haiku, such as “all our yesterdays,” “dagger of the mind,” and “parting is
    such sweet sorrow.” Use one or more of the Bard’s plays as a training corpus for
    the *markov_haiku.py* program. The big challenge here will be counting the syllables
    for all that olde English.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 威廉·莎士比亚写了许多符合俳句音节结构的著名短语，如“我们的昨日”，“心灵之刃”，以及“离别是如此甜蜜的悲伤”。使用一部或多部莎士比亚的剧作作为*markov_haiku.py*程序的训练语料库。这里的最大挑战是计算那些古老英语的音节。
- en: '***Markov Music***'
  id: totrans-252
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***马尔可夫音乐***'
- en: If you’re musically inclined, perform an online search for “composing music
    with Markov chains.” You should find a wealth of material on using Markov chain
    analysis to compose music, using the notes from existing songs as a training corpus.
    The resulting “Markov music” is used like our seed haiku—as inspiration for human
    songwriters.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有音乐天赋，可以在线搜索“用马尔可夫链作曲”。你应该能找到很多关于如何使用马尔可夫链分析作曲的资料，方法是使用现有歌曲的音符作为训练语料库。生成的“马尔可夫音乐”就像我们的种子俳句——为人类词曲作者提供灵感。

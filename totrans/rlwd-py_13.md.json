["```py\npractice_hound_dispersion.py\n\"\"\"Use NLP (nltk) to make dispersion plot.\"\"\"\nimport nltk\nimport file_loader\n\ncorpus = file_loader.text_to_string('hound.txt')\ntokens = nltk.word_tokenize(corpus)\ntokens = nltk.Text(tokens)  # NLTK wrapper for automatic text analysis.\ndispersion = tokens.dispersion_plot(['Holmes',\n                                     'Watson',\n                                     'Mortimer',\n                                     'Henry',\n                                     'Barrymore', \n                                     'Stapleton',\n                                     'Selden',\n                                     'hound'])\n```", "```py\npractice_heatmap_semicolon.py\n\"\"\"Make a heatmap of punctuation.\"\"\"\nimport math\nfrom string import punctuation\nimport nltk\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nimport seaborn as sns\n\n# Install seaborn using: pip install seaborn.\n\nPUNCT_SET = set(punctuation)\n\ndef main():  \n    # Load text files into dictionary by author.\n    strings_by_author = dict()\n    strings_by_author['doyle'] = text_to_string('hound.txt')\n    strings_by_author['wells'] = text_to_string('war.txt')\n    strings_by_author['unknown'] = text_to_string('lost.txt')\n\n    # Tokenize text strings preserving only punctuation marks.\n    punct_by_author = make_punct_dict(strings_by_author)\n\n    # Convert punctuation marks to numerical values and plot heatmaps.\n    plt.ion()\n    for author in punct_by_author:\n        heat = convert_punct_to_number(punct_by_author, author)\n        arr = np.array((heat[:6561])) # trim to largest size for square array\n        arr_reshaped = arr.reshape(int(math.sqrt(len(arr))),\n                                   int(math.sqrt(len(arr))))\n        fig, ax = plt.subplots(figsize=(7, 7))\n        sns.heatmap(arr_reshaped,\n                    cmap=ListedColormap(['blue', 'yellow']),\n                    square=True,\n                    ax=ax)\n        ax.set_title('Heatmap Semicolons {}'.format(author))\n    plt.show()    \n\ndef text_to_string(filename):\n    \"\"\"Read a text file and return a string.\"\"\"\n    with open(filename) as infile:\n        return infile.read()\n\ndef make_punct_dict(strings_by_author):\n    \"\"\"Return dictionary of tokenized punctuation by corpus by author.\"\"\"\n    punct_by_author = dict()\n    for author in strings_by_author:\n        tokens = nltk.word_tokenize(strings_by_author[author])\n        punct_by_author[author] = ([token for token in tokens\n                                    if token in PUNCT_SET])\n        print(\"Number punctuation marks in {} = {}\"\n              .format(author, len(punct_by_author[author])))\n    return punct_by_author  \n\ndef convert_punct_to_number(punct_by_author, author):\n    \"\"\"Return list of punctuation marks converted to numerical values.\"\"\"\n    heat_vals = []\n    for char in punct_by_author[author]:\n        if char == ';':\n            value = 1\n        else:\n            value = 2\n        heat_vals.append(value)\n    return heat_vals\n\nif __name__ == '__main__':\n    main()\n```", "```py\npractice_barchart.py\n\"\"\"Plot barchart of characters in text file.\"\"\"\nimport sys\nimport os\nimport operator\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\ndef load_file(infile):\n    \"\"\"Read and return text file as string of lowercase characters.\"\"\"\n    with open(infile) as f:\n        text = f.read().lower()\n    return text\ndef main():\n    infile = 'lost.txt'\n    if not os.path.exists(infile):\n        print(\"File {} not found. Terminating.\".format(infile),\n              file=sys.stderr)\n        sys.exit(1)\n\n    text = load_file(infile)\n\n    # Make bar chart of characters in text and their frequency.\n    char_freq = Counter(text)\n    char_freq_sorted = sorted(char_freq.items(),\n                              key=operator.itemgetter(1), reverse=True)\n    x, y = zip(*char_freq_sorted)  # * unpacks iterable.\n    fig, ax = plt.subplots()\n    ax.bar(x, y)\n    fig.show()\n\nif __name__ == '__main__':\n    main()\n```", "```py\npractice_WWII_words.py\n\"\"\"Book code using the novel The Lost World\n\nFor words not in book, spell-out with first letter of words.\nFlag 'first letter mode' by bracketing between alternating\n'a a' and 'the the'.\n\ncredit: Eric T. Mortenson\n\"\"\"\nimport sys\nimport os\nimport random\nimport string\nfrom collections import defaultdict, Counter\n\ndef main():\n    message = input(\"Enter plaintext or ciphertext: \") \n    process = input(\"Enter 'encrypt' or 'decrypt': \")  \n    shift = int(input(\"Shift value (1-365) = \"))\n    infile = input(\"Enter filename with extension: \")\n\n    if not os.path.exists(infile):\n        print(\"File {} not found. Terminating.\".format(infile), file=sys.stderr)\n        sys.exit(1)        \n    word_list = load_file(infile)\n    word_dict = make_dict(word_list, shift)\n    letter_dict = make_letter_dict(word_list)\n\n    if process == 'encrypt':\n        ciphertext = encrypt(message, word_dict, letter_dict)          \n        count = Counter(ciphertext)        \n        encryptedWordList = []\n        for number in ciphertext:\n            encryptedWordList.append(word_list[number - shift])\n\n        print(\"\\nencrypted word list = \\n {} \\n\"\n              .format(' '.join(encryptedWordList)))           \n        print(\"encrypted ciphertext = \\n {}\\n\".format(ciphertext))\n\n        # Check the encryption by decrypting the ciphertext.\n        print(\"decrypted plaintext = \")\n        singleFirstCheck = False\n        for cnt, i in enumerate(ciphertext):\n            if word_list[ciphertext[cnt]-shift] == 'a' and \\\n               word_list[ciphertext[cnt+1]-shift] == 'a':\n                continue\n            if word_list[ciphertext[cnt]-shift] == 'a' and \\\n               word_list[ciphertext[cnt-1]-shift] == 'a':\n                singleFirstCheck = True\n                continue\n            if singleFirstCheck == True and cnt<len(ciphertext)-1 and \\\n               word_list[ciphertext[cnt]-shift] == 'the' and \\\n                             word_list[ciphertext[cnt+1]-shift] == 'the':\n                continue\n            if singleFirstCheck == True and \\\n               word_list[ciphertext[cnt]-shift] == 'the' and \\\n                             word_list[ciphertext[cnt-1]-shift] == 'the':\n                singleFirstCheck = False\n                print(' ', end='', flush=True)\n                continue\n            if singleFirstCheck == True:\n                print(word_list[i - shift][0], end = '', flush=True)\n            if singleFirstCheck == False:\n                print(word_list[i - shift], end=' ', flush=True)\n\n    elif process == 'decrypt':\n        plaintext = decrypt(message, word_list, shift)\n        print(\"\\ndecrypted plaintext = \\n {}\".format(plaintext))\n\ndef load_file(infile):\n    \"\"\"Read and return text file as a list of lowercase words.\"\"\"\n    with open(infile, encoding='utf-8') as file:\n        words = [word.lower() for line in file for word in line.split()]\n        words_no_punct = [\"\".join(char for char in word if char not in \\\n                                 string.punctuation) for word in words]\n    return words_no_punct\n\ndef make_dict(word_list, shift):\n    \"\"\"Return dictionary of characters as keys and shifted indexes as values.\"\"\"\n    word_dict = defaultdict(list)\n    for index, word in enumerate(word_list):\n        word_dict[word].append(index + shift)\n    return word_dict\n\ndef make_letter_dict(word_list):\n    firstLetterDict = defaultdict(list)\n    for word in word_list:\n        if len(word) > 0:\n            if word[0].isalpha():\n                firstLetterDict[word[0]].append(word)\n    return firstLetterDict\n\ndef encrypt(message, word_dict, letter_dict):\n    \"\"\"Return list of indexes representing characters in a message.\"\"\"\n    encrypted = []\n    # remove punctuation from message words\n    messageWords = message.lower().split()\n    messageWordsNoPunct = [\"\".join(char for char in word if char not in \\\n                                 string.punctuation) for word in messageWords]    \n    for word in messageWordsNoPunct:\n        if len(word_dict[word]) > 1:\n            index = random.choice(word_dict[word])\n        elif len(word_dict[word]) == 1:  # Random.choice fails if only 1 choice.\n            index = word_dict[word][0]\n        elif len(word_dict[word]) == 0:  # Word not in word_dict.\n            encrypted.append(random.choice(word_dict['a']))\n            encrypted.append(random.choice(word_dict['a']))\n\n            for letter in word:\n                if letter not in letter_dict.keys():\n                    print('\\nLetter {} not in letter-to-word dictionary.'\n                          .format(letter), file=sys.stderr)\n                    continue\n                if len(letter_dict[letter])>1:\n                    newWord =random.choice(letter_dict[letter])\n                else:\n                    newWord = letter_dict[letter][0]\n                if len(word_dict[newWord])>1:\n                    index = random.choice(word_dict[newWord])\n                else:\n                    index = word_dict[newWord][0]\n                encrypted.append(index)\n\n            encrypted.append(random.choice(word_dict['the']))\n            encrypted.append(random.choice(word_dict['the']))\n            continue\n        encrypted.append(index)\n    return encrypted\n\ndef decrypt(message, word_list, shift):\n    \"\"\"Decrypt ciphertext string and return plaintext word string.\n    This shows how plaintext looks before extracting first letters.\n    \"\"\"\n    plaintextList = []\n    indexes = [s.replace(',', '').replace('[', '').replace(']', '')\n               for s in message.split()]\n    for count, i in enumerate(indexes):\n        plaintextList.append(word_list[int(i) - shift])\n    return ' '.join(plaintextList)\n\ndef check_for_fail(ciphertext):\n    \"\"\"Return True if ciphertext contains any duplicate keys.\"\"\"\n    check = [k for k, v in Counter(ciphertext).items() if v > 1]\n    if len(check) > 0:\n        print(check)\n        return True\n\nif __name__ == '__main__':\n    main()\n```", "```py\npractice_orbital_path.py\nimport os\nfrom pathlib import Path\nimport cv2 as cv\n\nPAD = 5  # Ignore pixels this distance from edge\n\ndef find_transient(image, diff_image, pad):\n    \"\"\"Takes image, difference image, and pad value in pixels and returns\n       boolean and location of maxVal in difference image excluding an edge\n       rind. Draws circle around maxVal on image.\"\"\"\n    transient = False\n    height, width = diff_image.shape\n    cv.rectangle(image, (PAD, PAD), (width - PAD, height - PAD), 255, 1)\n    minVal, maxVal, minLoc, maxLoc = cv.minMaxLoc(diff_image)\n    if pad < maxLoc[0] < width - pad and pad < maxLoc[1] < height - pad:\n        cv.circle(image, maxLoc, 10, 255, 0)\n        transient = True\n    return transient, maxLoc\n\ndef main():\n    night1_files = sorted(os.listdir('night_1_registered_transients'))\n    night2_files = sorted(os.listdir('night_2'))             \n    path1 = Path.cwd() / 'night_1_registered_transients'\n    path2 = Path.cwd() / 'night_2'\n    path3 = Path.cwd() / 'night_1_2_transients'\n\n    # Images should all be the same size and similar exposures.    \n    for i, _ in enumerate(night1_files[:-1]):  # Leave off negative image   \n        img1 = cv.imread(str(path1 / night1_files[i]), cv.IMREAD_GRAYSCALE)\n        img2 = cv.imread(str(path2 / night2_files[i]), cv.IMREAD_GRAYSCALE)\n        # Get absolute difference between images.\n        diff_imgs1_2 = cv.absdiff(img1, img2)\n        cv.imshow('Difference', diff_imgs1_2)\n        cv.waitKey(2000)        \n\n        # Copy difference image and find and circle brightest pixel.\n        temp = diff_imgs1_2.copy()\n        transient1, transient_loc1 = find_transient(img1, temp, PAD)\n\n        # Draw black circle on temporary image to obliterate brightest spot.\n        cv.circle(temp, transient_loc1, 10, 0, -1)\n\n        # Get location of new brightest pixel and circle it on input image.        \n        transient2, transient_loc2 = find_transient(img1, temp, PAD)\n\n        if transient1 or transient2:\n            print('\\nTRANSIENT DETECTED between {} and {}\\n'\n                  .format(night1_files[i], night2_files[i]))\n            font = cv.FONT_HERSHEY_COMPLEX_SMALL\n            cv.putText(img1, night1_files[i], (10, 25),\n                       font, 1, (255, 255, 255), 1, cv.LINE_AA)\n            cv.putText(img1, night2_files[i], (10, 55),\n                       font, 1, (255, 255, 255), 1, cv.LINE_AA)\n            if transient1 and transient2:\n                cv.line(img1, transient_loc1, transient_loc2, (255, 255, 255),\n                        1, lineType=cv.LINE_AA)\n\n            blended = cv.addWeighted(img1, 1, diff_imgs1_2, 1, 0)\n            cv.imshow('Surveyed', blended)\n            cv.waitKey(2500)  # Keeps window open 2.5 seconds.\n            out_filename = '{}_DECTECTED.png'.format(night1_files[i][:-4])\n            cv.imwrite(str(path3 / out_filename), blended)  # Will overwrite!\n        else:\n            print('\\nNo transient detected between {} and {}\\n'\n                  .format(night1_files[i], night2_files[i]))\n\nif __name__ == '__main__':\n    main()\n```", "```py\npractice_montage_aligner.py\nimport numpy as np\nimport cv2 as cv\n\nMIN_NUM_KEYPOINT_MATCHES = 150\n\nimg1 = cv.imread('montage_left.JPG', cv.IMREAD_COLOR)  # queryImage\nimg2 = cv.imread('montage_right.JPG', cv.IMREAD_COLOR) # trainImage\nimg1 = cv.cvtColor(img1, cv.COLOR_BGR2GRAY)  # Convert to grayscale.\nimg2 = cv.cvtColor(img2, cv.COLOR_BGR2GRAY)\n\norb = cv.ORB_create(nfeatures=700) \n\n# Find the keypoints and descriptions with ORB.\nkp1, desc1 = orb.detectAndCompute(img1, None)\nkp2, desc2 = orb.detectAndCompute(img2, None)\n\n# Find keypoint matches using Brute Force Matcher.\nbf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)\nmatches = bf.match(desc1, desc2, None)\n\n# Sort matches in ascending order of distance.\nmatches = sorted(matches, key=lambda x: x.distance)\n\n# Draw best matches.\nimg3 = cv.drawMatches(img1, kp1, img2, kp2, \n                       matches[:MIN_NUM_KEYPOINT_MATCHES],\n                       None)\n\ncv.namedWindow('Matches', cv.WINDOW_NORMAL)\nimg3_resize = cv.resize(img3, (699, 700))\ncv.imshow('Matches', img3_resize)\ncv.waitKey(7000)  # Keeps window open 7 seconds.\ncv.destroyWindow('Matches')\n\n# Keep only best matches.\nbest_matches = matches[:MIN_NUM_KEYPOINT_MATCHES]\n\nif len(best_matches) >= MIN_NUM_KEYPOINT_MATCHES:\n    src_pts = np.zeros((len(best_matches), 2), dtype=np.float32)\n    dst_pts = np.zeros((len(best_matches), 2), dtype=np.float32)\n\n    for i, match in enumerate(best_matches):\n        src_pts[i, :] = kp1[match.queryIdx].pt\n        dst_pts[i, :] = kp2[match.trainIdx].pt\n\n    M, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC)\n\n    # Get dimensions of image 2.\n    height, width = img2.shape\n    img1_warped = cv.warpPerspective(img1, M, (width, height))\n\n    cv.imwrite('montage_left_registered.JPG', img1_warped)\n    cv.imwrite('montage_right_gray.JPG', img2)\n\nelse:\n    print(\"\\n{}\\n\".format('WARNING: Number of keypoint matches < 10!'))\n```", "```py\npractice_montage_difference_finder.py\nimport cv2 as cv\n\nfilename1 = 'montage_left.JPG'\nfilename2 = 'montage_right_gray.JPG'\n\nimg1 = cv.imread(filename1, cv.IMREAD_GRAYSCALE)\nimg2 = cv.imread(filename2, cv.IMREAD_GRAYSCALE)\n\n# Absolute difference between image 2 & 3:\ndiff_imgs1_2 = cv.absdiff(img1, img2)\n\ncv.namedWindow('Difference', cv.WINDOW_NORMAL)\ndiff_imgs1_2_resize = cv.resize(diff_imgs1_2, (699, 700))\ncv.imshow('Difference', diff_imgs1_2_resize)\n\ncrop_diff = diff_imgs1_2[10:2795, 10:2445]  # x, y, w, h = 10, 10, 2790, 2440\n\n# Blur to remove extraneous noise.\nblurred = cv.GaussianBlur(crop_diff, (5, 5), 0)\n\n(minVal, maxVal, minLoc, maxLoc2) = cv.minMaxLoc(blurred)\ncv.circle(img2, maxLoc2, 100, 0, 3)\nx, y = int(img2.shape[1]/4), int(img2.shape[0]/4)\nimg2_resize = cv.resize(img2, (x, y))\ncv.imshow('Change', img2_resize)\n```", "```py\npractice_search_pattern.py\nimport time\nimport random\nimport turtle\n\nSA_X = 600  # Search area width.\nSA_Y = 480  # Search area height.\nTRACK_SPACING = 40  # Distance between search tracks.\n\n# Setup screen. \nscreen = turtle.Screen()\nscreen.setup(width=SA_X, height=SA_Y)\nturtle.resizemode('user')\nscreen.title(\"Search Pattern\")\nrand_x = random.randint(0, int(SA_X / 2)) * random.choice([-1, 1])\nrand_y = random.randint(0, int(SA_Y / 2)) * random.choice([-1, 1])\n\n# Set up turtle images.\nseaman_image = 'seaman.gif'\nscreen.addshape(seaman_image)\ncopter_image_left = 'helicopter_left.gif'\ncopter_image_right = 'helicopter_right.gif'\nscreen.addshape(copter_image_left)\nscreen.addshape(copter_image_right)\n\n# Instantiate seaman turtle.\nseaman = turtle.Turtle(seaman_image)\nseaman.hideturtle()\nseaman.penup()\nseaman.setpos(rand_x, rand_y)\nseaman.showturtle()\n\n# Instantiate copter turtle.\nturtle.shape(copter_image_right)\nturtle.hideturtle()\nturtle.pencolor('black')\nturtle.penup()\nturtle.setpos(-(int(SA_X / 2) - TRACK_SPACING), int(SA_Y / 2) - TRACK_SPACING)\nturtle.showturtle()\nturtle.pendown()\n\n# Run search pattern and announce discovery of seaman.\nfor i in range(int(SA_Y / TRACK_SPACING)):     \n    turtle.fd(SA_X - TRACK_SPACING * 2)\n    turtle.rt(90)\n    turtle.fd(TRACK_SPACING / 2)\n    turtle.rt(90)\n    turtle.shape(copter_image_left)\n    turtle.fd(SA_X - TRACK_SPACING * 2)\n    turtle.lt(90)\n    turtle.fd(TRACK_SPACING / 2)\n    turtle.lt(90)\n    turtle.shape(copter_image_right)\n    if turtle.ycor() - seaman.ycor() <= 10:\n        turtle.write(\"      Seaman found!\",\n                     align='left',\n                     font=(\"Arial\", 15, 'normal', 'bold', 'italic'))\n        time.sleep(3)\n\n        break\n```", "```py\npractice_grav _assist_stationary.py\n\"\"\"gravity_assist_stationary.py\n\nMoon approaches stationary ship, which is swung around and flung away.\n\nCredit: Eric T. Mortenson\n\"\"\"\nfrom turtle import Shape, Screen, Turtle, Vec2D as Vec\nimport turtle\nimport math\n\n# User input:\nG = 8  # Gravitational constant used for the simulation.\nNUM_LOOPS = 4100  # Number of time steps in simulation.\nRo_X = 0  # Ship starting position x coordinate.\nRo_Y = -50  # Ship starting position y coordinate.\nVo_X = 0  # Ship velocity x component.\nVo_Y = 0  # Ship velocity y component.\n\nMOON_MASS = 1_250_000\n\nclass GravSys():\n    \"\"\"Runs a gravity simulation on n-bodies.\"\"\"\n\n    def __init__(self):\n        self.bodies = []\n        self.t = 0\n        self.dt = 0.001\n\n    def sim_loop(self):\n        \"\"\"Loop bodies in a list through time steps.\"\"\"\n        for _ in range(NUM_LOOPS):\n            self.t += self.dt\n            for body in self.bodies:\n                body.step()\n\nclass Body(Turtle):\n    \"\"\"Celestial object that orbits and projects gravity field.\"\"\"\n    def __init__(self, mass, start_loc, vel, gravsys, shape):\n        super().__init__(shape=shape)\n        self.gravsys = gravsys\n        self.penup()\n        self.mass=mass\n        self.setpos(start_loc)\n        self.vel = vel\n        gravsys.bodies.append(self)\n        self.pendown()  # uncomment to draw path behind object\n\n    def acc(self):\n        \"\"\"Calculate combined force on body and return vector components.\"\"\"\n        a = Vec(0,0)\n        for body in self.gravsys.bodies:\n            if body != self:\n                r = body.pos() - self.pos()\n                a += (G * body.mass / abs(r)**3) * r  # units dist/time^2\n        return a\n    def step(self):\n        \"\"\"Calculate position, orientation, and velocity of a body.\"\"\"\n        dt = self.gravsys.dt\n        a = self.acc()\n        self.vel = self.vel + dt * a\n        xOld, yOld = self.pos()  # for orienting ship\n        self.setpos(self.pos() + dt * self.vel)\n        xNew, yNew = self.pos()  # for orienting ship\n        if self.gravsys.bodies.index(self) == 1: # the CSM\n            dir_radians = math.atan2(yNew-yOld,xNew-xOld)  # for orienting ship\n            dir_degrees = dir_radians * 180 / math.pi  # for orienting ship\n            self.setheading(dir_degrees+90)  # for orienting ship\n\ndef main():\n    # Setup screen\n    screen = Screen()\n    screen.setup(width=1.0, height=1.0)  # for fullscreen\n    screen.bgcolor('black')\n    screen.title(\"Gravity Assist Example\")\n\n    # Instantiate gravitational system\n    gravsys = GravSys()\n\n    # Instantiate Planet\n    image_moon = 'moon_27x27.gif'\n    screen.register_shape(image_moon)\n    moon = Body(MOON_MASS, (500, 0), Vec(-500, 0), gravsys, image_moon)\n    moon.pencolor('gray')\n\n    # Build command-service-module (csm) shape\n    csm = Shape('compound')\n    cm = ((0, 30), (0, -30), (30, 0))\n    csm.addcomponent(cm, 'red', 'red')\n    sm = ((-60,30), (0, 30), (0, -30), (-60, -30))\n    csm.addcomponent(sm, 'red', 'black')\n    nozzle = ((-55, 0), (-90, 20), (-90, -20))\n    csm.addcomponent(nozzle, 'red', 'red')\n    screen.register_shape('csm', csm)\n\n    # Instantiate Apollo 8 CSM turtle\n    ship = Body(1, (Ro_X, Ro_Y), Vec(Vo_X, Vo_Y), gravsys, \"csm\")\n    ship.shapesize(0.2)\n    ship.color('red') # path color\n    ship.getscreen().tracer(1, 0)\n    ship.setheading(90)\n\n    gravsys.sim_loop()\n\nif __name__=='__main__':\n    main()\n```", "```py\npractice_grav_assist_intersecting.py\n\"\"\"gravity_assist_intersecting.py\n\nMoon and ship cross orbits and moon slows and turns ship.\n\nCredit: Eric T. Mortenson\n\"\"\"\n\nfrom turtle import Shape, Screen, Turtle, Vec2D as Vec\nimport turtle\nimport math\nimport sys\n\n# User input:\nG = 8  # Gravitational constant used for the simulation.\nNUM_LOOPS = 7000  # Number of time steps in simulation.\nRo_X = -152.18  # Ship starting position x coordinate.\nRo_Y = 329.87  # Ship starting position y coordinate.\nVo_X = 423.10  # Ship translunar injection velocity x component.\nVo_Y = -512.26  # Ship translunar injection velocity y component.\n\nMOON_MASS = 1_250_000\n\nclass GravSys():\n    \"\"\"Runs a gravity simulation on n-bodies.\"\"\"\n\n    def __init__(self):\n        self.bodies = []\n        self.t = 0\n        self.dt = 0.001\n\n    def sim_loop(self):\n        \"\"\"Loop bodies in a list through time steps.\"\"\"\n        for index in range(NUM_LOOPS): # stops simulation after while \n            self.t += self.dt\n            for body in self.bodies:\n                body.step()\n\nclass Body(Turtle):\n    \"\"\"Celestial object that orbits and projects gravity field.\"\"\"\n    def __init__(self, mass, start_loc, vel, gravsys, shape):\n        super().__init__(shape=shape)\n        self.gravsys = gravsys\n        self.penup()\n        self.mass=mass\n        self.setpos(start_loc)\n        self.vel = vel\n        gravsys.bodies.append(self)\n        self.pendown()  # uncomment to draw path behind object\n\n    def acc(self):\n        \"\"\"Calculate combined force on body and return vector components.\"\"\"\n        a = Vec(0,0)\n        for body in self.gravsys.bodies:\n            if body != self:\n                r = body.pos() - self.pos()\n                a += (G * body.mass / abs(r)**3) * r  # units dist/time^2\n        return a\n\n    def step(self):\n        \"\"\"Calculate position, orientation, and velocity of a body.\"\"\"\n        dt = self.gravsys.dt\n        a = self.acc()\n        self.vel = self.vel + dt * a\n        xOld, yOld = self.pos()  # for orienting ship\n        self.setpos(self.pos() + dt * self.vel)\n        xNew, yNew = self.pos()  # for orienting ship\n        if self.gravsys.bodies.index(self) == 1:  # the CSM\n            dir_radians = math.atan2(yNew-yOld,xNew-xOld)  # for orienting ship\n            dir_degrees = dir_radians * 180 / math.pi  # for orienting ship\n            self.setheading(dir_degrees+90)  # for orienting ship\n\ndef main():\n    # Setup screen\n    screen = Screen()\n    screen.setup(width=1.0, height=1.0)  # for fullscreen\n    screen.bgcolor('black')\n    screen.title(\"Gravity Assist Example\")\n    # Instantiate gravitational system\n    gravsys = GravSys()\n\n    # Instantiate Planet\n    image_moon = 'moon_27x27.gif'\n    screen.register_shape(image_moon)\n    moon = Body(MOON_MASS, (-250, 0), Vec(500, 0), gravsys, image_moon)\n    moon.pencolor('gray')\n\n    # Build command-service-module (csm) shape\n    csm = Shape('compound')\n    cm = ((0, 30), (0, -30), (30, 0))\n    csm.addcomponent(cm, 'red', 'red')\n    sm = ((-60,30), (0, 30), (0, -30), (-60, -30))\n    csm.addcomponent(sm, 'red', 'black')\n    nozzle = ((-55, 0), (-90, 20), (-90, -20))\n    csm.addcomponent(nozzle, 'red', 'red')\n    screen.register_shape('csm', csm)\n\n    # Instantiate Apollo 8 CSM turtle\n    ship = Body(1, (Ro_X, Ro_Y), Vec(Vo_X, Vo_Y), gravsys, \"csm\")\n    ship.shapesize(0.2)\n    ship.color('red')  # path color\n    ship.getscreen().tracer(1, 0)\n    ship.setheading(90)\n    gravsys.sim_loop()\n\nif __name__=='__main__':\n    main()\n```", "```py\npractice_confirm_drawing_part_of_image.py\n\"\"\"Test that drawings become part of an image in OpenCV.\"\"\"\nimport numpy as np\nimport cv2 as cv\n\nIMG = cv.imread('mola_1024x501.png', cv.IMREAD_GRAYSCALE)\n\nul_x, ul_y = 0, 167\nlr_x, lr_y = 32, 183\nrect_img = IMG[ul_y : lr_y, ul_x : lr_x]\n\ndef run_stats(image):\n    \"\"\"Run stats on a numpy array made from an image.\"\"\"\n    print('mean = {}'.format(np.mean(image)))\n    print('std = {}'.format(np.std(image)))\n    print('ptp = {}'.format(np.ptp(image)))\n    print()\n    cv.imshow('img', IMG)\n    cv.waitKey(1000)    \n\n# Stats with no drawing on screen:\nprint(\"No drawing\")\nrun_stats(rect_img)\n\n# Stats with white rectangle outline:\nprint(\"White outlined rectangle\")\ncv.rectangle(IMG, (ul_x, ul_y), (lr_x, lr_y), (255, 0, 0), 1)\nrun_stats(rect_img)\n\n# Stats with rectangle filled with white:\nprint(\"White-filled rectangle\")\ncv.rectangle(IMG, (ul_x, ul_y), (lr_x, lr_y), (255, 0, 0), -1)\nrun_stats(rect_img)\n```", "```py\npractice_profile_olympus.py\n\"\"\"West-East elevation profile through Olympus Mons.\"\"\"\nfrom PIL import Image, ImageDraw\nfrom matplotlib import pyplot as plt\n\n# Load image and get x and z values along horiz profile parallel to y _coord.\ny_coord = 202\nim = Image.open('mola_1024x512_200mp.jpg').convert('L')\nwidth, height = im.size\nx_vals = [x for x in range(width)]\nz_vals = [im.getpixel((x, y_coord)) for x in x_vals]\n\n# Draw profile on MOLA image.\ndraw = ImageDraw.Draw(im)\ndraw.line((0, y_coord, width, y_coord), fill=255, width=3)\ndraw.text((100, 165), 'Olympus Mons', fill=255)\nim.show()    \n\n# Make profile plot.\nfig, ax = plt.subplots(figsize=(9, 4))\naxes = plt.gca()\naxes.set_ylim(0, 400)\nax.plot(x_vals, z_vals, color='black')\nax.set(xlabel='x-coordinate',\n       ylabel='Intensity (height)',\n       title=\"Mars Elevation Profile (y = 202)\")\nratio = 0.15  # Reduces vertical exaggeration in profile.\nxleft, xright = ax.get_xlim()\nybase, ytop = ax.get_ylim()\nax.set_aspect(abs((xright-xleft)/(ybase-ytop)) * ratio)\nplt.text(0, 310, 'WEST', fontsize=10)\nplt.text(980, 310, 'EAST', fontsize=10)\nplt.text(100, 280, 'Olympus Mons', fontsize=8)\n##ax.grid()\nplt.show()\n```", "```py\npractice_3d_plotting.py\n\"\"\"Plot Mars MOLA map image in 3D.  Credit Eric T. Mortenson.\"\"\"\nimport numpy as np\nimport cv2 as cv\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits import mplot3d\n\nIMG_GRAY = cv.imread('mola_1024x512_200mp.jpg', cv.IMREAD_GRAYSCALE)\n\nx = np.linspace(1023, 0, 1024)\ny = np.linspace(0, 511, 512)\n\nX, Y = np.meshgrid(x, y)\nZ = IMG_GRAY[0:512, 0:1024]\n\nfig = plt.figure()\nax = plt.axes(projection='3d')\nax.contour3D(X, Y, Z, 150, cmap='gist_earth')  # 150=number of contours\nax.auto_scale_xyz([1023, 0], [0, 511], [0, 500])\nplt.show()\n```", "```py\npractice_geo_map_step_1of2.py\n\"\"\"Threshold a grayscale image using pixel values and save to file.\"\"\"\nimport cv2 as cv\n\nIMG_GEO = cv.imread('Mars_Global_Geology_Mariner9_1024.jpg', \n                     cv.IMREAD_GRAYSCALE)\ncv.imshow('map', IMG_GEO)\ncv.waitKey(1000)\nimg_copy = IMG_GEO.copy()\nlower_limit = 170  # Lowest grayscale value for volcanic deposits\nupper_limit = 185  # Highest grayscale value for volcanic deposits\n\n# Using 1024 x 512 image\nfor x in range(1024):\n    for y in range(512):\n        if lower_limit <= img_copy[y, x] <= upper_limit:\n            img_copy[y, x] = 1  # Set to 255 to visualize results.\n        else:\n            img_copy[y, x] = 0\n\ncv.imwrite('geo_thresh.jpg', img_copy)\ncv.imshow('thresh', img_copy)\ncv.waitKey(0)\n```", "```py\npractice_geo_map_step_2of2.py\n\"\"\"Select Martian landing sites based on surface smoothness and geology.\"\"\"\nimport tkinter as tk\nfrom PIL import Image, ImageTk\nimport numpy as np\nimport cv2 as cv\n\n# CONSTANTS: User Input:\nIMG_GRAY = cv.imread('mola_1024x512_200mp.jpg', cv.IMREAD_GRAYSCALE)\nIMG_GEO = cv.imread('geo_thresh.jpg', cv.IMREAD_GRAYSCALE)\nIMG_COLOR = cv.imread('mola_color_1024x506.png')\nRECT_WIDTH_KM = 670  # Site rectangle width in kilometers.\nRECT_HT_KM = 335  # Site rectangle height in kilometers.\nMIN_ELEV_LIMIT = 60  # Intensity values (0-255).\nMAX_ELEV_LIMIT = 255\nNUM_CANDIDATES = 20  # Number of candidate landing sites to display.\n\n#------------------------------------------------------------------------------\n# CONSTANTS: Derived and fixed:\nIMG_GRAY_GEO = IMG_GRAY * IMG_GEO\nIMG_HT, IMG_WIDTH = IMG_GRAY.shape\nMARS_CIRCUM = 21344  # Circumference in kilometers.\nPIXELS_PER_KM = IMG_WIDTH / MARS_CIRCUM\nRECT_WIDTH = int(PIXELS_PER_KM * RECT_WIDTH_KM)\nRECT_HT = int(PIXELS_PER_KM * RECT_HT_KM)\nLAT_30_N = int(IMG_HT / 3)\nLAT_30_S = LAT_30_N * 2\nSTEP_X = int(RECT_WIDTH / 2)  # Dividing by 4 yields more rect choices\nSTEP_Y = int(RECT_HT / 2)  # Dividing by 4 yields more rect choices\n\n# Create tkinter screen and drawing canvas\nscreen = tk.Tk()\ncanvas = tk.Canvas(screen, width=IMG_WIDTH, height=IMG_HT + 130)\n\nclass Search():\n    \"\"\"Read image and identify landing sites based on input criteria.\"\"\"   \n\n    def __init__(self, name):\n        self.name = name\n        self.rect_coords = {}\n        self.rect_means = {}\n        self.rect_ptps = {}\n        self.rect_stds = {}\n        self.ptp_filtered = []\n        self.std_filtered = []\n        self.high_graded_rects = []\n\n    def run_rect_stats(self):\n        \"\"\"Define rectangular search areas and calculate internal stats.\"\"\"\n        ul_x, ul_y = 0, LAT_30_N \n        lr_x, lr_y = RECT_WIDTH, LAT_30_N + RECT_HT\n        rect_num = 1\n\n        while True:\n            rect_img = IMG_GRAY_GEO[ul_y : lr_y, ul_x : lr_x]\n            self.rect_coords[rect_num] = [ul_x, ul_y, lr_x, lr_y]\n            if MAX_ELEV_LIMIT >= np.mean(rect_img) >= MIN_ELEV_LIMIT:\n                self.rect_means[rect_num] = np.mean(rect_img)\n                self.rect_ptps[rect_num] = np.ptp(rect_img)\n                self.rect_stds[rect_num] = np.std(rect_img)\n            rect_num += 1\n\n           # Move the rectangle.\n            ul_x += STEP_X\n            lr_x = ul_x + RECT_WIDTH\n            if lr_x > IMG_WIDTH:\n                ul_x = 0\n                ul_y += STEP_Y\n                lr_x = RECT_WIDTH\n                lr_y += STEP_Y\n            if lr_y > LAT_30_S + STEP_Y:\n                break\n\n    def draw_qc_rects(self):\n        \"\"\"Draw overlapping search rectangles on image as a check.\"\"\"\n        img_copy = IMG_GRAY_GEO.copy()\n        rects_sorted = sorted(self.rect_coords.items(), key=lambda x: x[0])\n        print(\"\\nRect Number and Corner Coordinates (ul_x, ul_y, lr_x, lr_y):\")\n        for k, v in rects_sorted:\n            print(\"rect: {}, coords: {}\".format(k, v))\n            cv.rectangle(img_copy,\n                         (self.rect_coords[k][0], self.rect_coords[k][1]),\n                         (self.rect_coords[k][2], self.rect_coords[k][3]),\n                         (255, 0, 0), 1)\n        cv.imshow('QC Rects {}'.format(self.name), img_copy)\n        cv.waitKey(3000)\n        cv.destroyAllWindows()        \n\n    def sort_stats(self):  \n        \"\"\"Sort dictionaries by values and create lists of top N keys.\"\"\"\n        ptp_sorted = (sorted(self.rect_ptps.items(), key=lambda x: x[1]))\n        self.ptp_filtered = [x[0] for x in ptp_sorted[:NUM_CANDIDATES]]\n        std_sorted = (sorted(self.rect_stds.items(), key=lambda x: x[1]))\n        self.std_filtered = [x[0] for x in std_sorted[:NUM_CANDIDATES]]\n\n        # Make list of rects where filtered std & ptp coincide.\n        for rect in self.std_filtered:\n            if rect in self.ptp_filtered:\n                self.high_graded_rects.append(rect)   \n\n    def draw_filtered_rects(self, image, filtered_rect_list):\n        \"\"\"Draw rectangles in list on image and return image.\"\"\"\n        img_copy = image.copy()\n        for k in filtered_rect_list: \n            cv.rectangle(img_copy,\n                         (self.rect_coords[k][0], self.rect_coords[k][1]),\n                         (self.rect_coords[k][2], self.rect_coords[k][3]),\n                         (255, 0, 0), 1)\n            cv.putText(img_copy, str(k),\n                       (self.rect_coords[k][0] + 1, self.rect_coords[k][3]- 1),\n                       cv.FONT_HERSHEY_PLAIN, 0.65, (255, 0, 0), 1)\n\n        # Draw latitude limits.\n        cv.putText(img_copy, '30 N', (10, LAT_30_N - 7),\n                   cv.FONT_HERSHEY_PLAIN, 1, 255)\n        cv.line(img_copy, (0, LAT_30_N), (IMG_WIDTH, LAT_30_N),\n                (255, 0, 0), 1)\n        cv.line(img_copy, (0, LAT_30_S), (IMG_WIDTH, LAT_30_S),\n                (255, 0, 0), 1)\n        cv.putText(img_copy, '30 S', (10, LAT_30_S + 16),\n                   cv.FONT_HERSHEY_PLAIN, 1, 255)\n\n        return img_copy\n\n    def make_final_display(self):\n        \"\"\"Use Tk to show map of final rects & printout of their statistics.\"\"\"\n        screen.title('Sites by MOLA Gray STD & PTP {} Rect'.format(self.name))\n        # Draw the high-graded rects on the colored elevation map.        \n        img_color_rects = self.draw_filtered_rects(IMG_COLOR,\n                                                   self.high_graded_rects)\n        # Convert image from CV BGR to RGB for use with Tkinter.\n        img_converted = cv.cvtColor(img_color_rects, cv.COLOR_BGR2RGB)\n        img_converted = ImageTk.PhotoImage(Image.fromarray(img_converted))    \n        canvas.create_image(0, 0, image=img_converted, anchor=tk.NW)\n        # Add stats for each rectangle at bottom of canvas.\n        txt_x = 5\n        txt_y = IMG_HT + 15\n        for k in self.high_graded_rects:\n            canvas.create_text(txt_x, txt_y, anchor='w', font=None,\n                               text=\n                               \"rect={}  mean elev={:.1f}  std={:.2f}  ptp={}\"\n                               .format(k, self.rect_means[k], \n                                       self.rect_stds[k],\n                                       self.rect_ptps[k]))\n            txt_y += 15\n            if txt_y >= int(canvas.cget('height')) - 10:\n                txt_x += 300\n                txt_y = IMG_HT + 15                \n        canvas.pack()\n        screen.mainloop()\n\ndef main():\n    app = Search('670x335 km')\n    app.run_rect_stats()\n    app.draw_qc_rects()\n    app.sort_stats()\n    ptp_img = app.draw_filtered_rects(IMG_GRAY_GEO, app.ptp_filtered)\n    std_img = app.draw_filtered_rects(IMG_GRAY_GEO, app.std_filtered)\n    # Display filtered rects on grayscale map.\n    cv.imshow('Sorted by ptp for {} rect'.format(app.name), ptp_img)\n    cv.waitKey(3000)\n    cv.imshow('Sorted by std for {} rect'.format(app.name), std_img)\n    cv.waitKey(3000)\n\n    app.make_final_display()  # includes call to mainloop()\n\nif __name__ == '__main__':\n    main()\n```", "```py\npractice_tabbys_star.py\n\"\"\"Simulate transit of alien array and plot light curve.\"\"\"\nimport numpy as np\nimport cv2 as cv\nimport matplotlib.pyplot as plt\n\nIMG_HT = 400\nIMG_WIDTH = 500\nBLACK_IMG = np.zeros((IMG_HT, IMG_WIDTH), dtype='uint8')\nSTAR_RADIUS = 165\nEXO_START_X = -250\nEXO_START_Y = 150 \nEXO_DX = 3\nNUM_FRAMES = 500\n\ndef main():\n    intensity_samples = record_transit(EXO_START_X, EXO_START_Y)\n    rel_brightness = calc_rel_brightness(intensity_samples)\n    plot_light_curve(rel_brightness)\n\ndef record_transit(exo_x, exo_y):\n    \"\"\"Draw array transiting star and return list of intensity changes.\"\"\"\n    intensity_samples = []\n    for _ in range(NUM_FRAMES):\n        temp_img = BLACK_IMG.copy()\n        # Draw star:\n        cv.circle(temp_img, (int(IMG_WIDTH / 2), int(IMG_HT / 2)),\n                  STAR_RADIUS, 255, -1)\n        # Draw alien array:\n        cv.rectangle(temp_img, (exo_x, exo_y),\n                     (exo_x + 20, exo_y + 140), 0, -1)\n        cv.rectangle(temp_img, (exo_x - 360, exo_y),\n                     (exo_x + 10, exo_y + 140), 0, 5)\n        cv.rectangle(temp_img, (exo_x - 380, exo_y),\n                     (exo_x - 310, exo_y + 140), 0, -1)\n        intensity = temp_img.mean()\n        cv.putText(temp_img, 'Mean Intensity = {}'.format(intensity), (5, 390),\n                   cv.FONT_HERSHEY_PLAIN, 1, 255)\n        cv.imshow('Transit', temp_img)\n        cv.waitKey(10)\n        intensity_samples.append(intensity)\n        exo_x += EXO_DX\n    return intensity_samples\n\ndef calc_rel_brightness(intensity_samples):\n    \"\"\"Return list of relative brightness from list of intensity values.\"\"\"\n    rel_brightness = []\n    max_brightness = max(intensity_samples)\n    for intensity in intensity_samples:\n        rel_brightness.append(intensity / max_brightness)\n    return rel_brightness\n\ndef plot_light_curve(rel_brightness):\n    \"\"\"Plot changes in relative brightness vs. time.\"\"\"\n    plt.plot(rel_brightness, color='red', linestyle='dashed',\n             linewidth=2)\n    plt.title('Relative Brightness vs. Time')\n    plt.xlim(-150, 500)\n    plt.show()\n\nif __name__ == '__main__':\n    main()\n```", "```py\npractice _asteroids.py\n\"\"\"Simulate transit of asteroids and plot light curve.\"\"\"\nimport random\nimport numpy as np\nimport cv2 as cv\nimport matplotlib.pyplot as plt\n\nSTAR_RADIUS = 165\nBLACK_IMG = np.zeros((400, 500, 1), dtype=\"uint8\")\nNUM_ASTEROIDS = 15\nNUM_LOOPS = 170\n\nclass Asteroid():\n    \"\"\"Draws a circle on an image that represents an asteroid.\"\"\"\n\n    def __init__(self, number):\n        self.radius = random.choice((1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3))\n        self.x = random.randint(-30, 60)\n        self.y = random.randint(220, 230)\n        self.dx = 3  \n\n    def move_asteroid(self, image):\n        \"\"\"Draw and move asteroid object.\"\"\"\n        cv.circle(image, (self.x, self.y), self.radius, 0, -1)\n        self.x += self.dx\n\ndef record_transit(start_image):\n    \"\"\"Simulate transit of asteroids over star and return intensity list.\"\"\"\n    asteroid_list = []\n    intensity_samples = []\n\n    for i in range(NUM_ASTEROIDS):\n        asteroid_list.append(Asteroid(i))\n\n    for _ in range(NUM_LOOPS):\n        temp_img = start_image.copy()\n        # Draw star.  \n        cv.circle(temp_img, (250, 200), STAR_RADIUS, 255, -1)\n        for ast in asteroid_list:\n            ast.move_asteroid(temp_img)\n        intensity = temp_img.mean()\n        cv.putText(temp_img, 'Mean Intensity = {}'.format(intensity),\n                   (5, 390), cv.FONT_HERSHEY_PLAIN, 1, 255)\n        cv.imshow('Transit', temp_img)\n        intensity_samples.append(intensity)\n        cv.waitKey(50)\n    cv.destroyAllWindows()\n    return intensity_samples\n\ndef calc_rel_brightness(image):\n    \"\"\"Calculate and return list of relative brightness samples.\"\"\"\n    rel_brightness = record_transit(image)\n    max_brightness = max(rel_brightness)\n    for i, j in enumerate(rel_brightness):\n        rel_brightness[i] = j / max_brightness\n    return rel_brightness\n\ndef plot_light_curve(rel_brightness):\n    \"Plot light curve from relative brightness list.\"\"\"\n    plt.plot(rel_brightness, color='red', linestyle='dashed',\n             linewidth=2, label='Relative Brightness')\n    plt.legend(loc='upper center')\n    plt.title('Relative Brightness vs. Time')\n    plt.show()\n\nrelative_brightness = calc_rel_brightness(BLACK_IMG)\nplot_light_curve(relative_brightness)\n```", "```py\npractice_limb_darkening.py\n\"\"\"Simulate transit of exoplanet, plot light curve, estimate planet radius.\"\"\"\nimport cv2 as cv\nimport matplotlib.pyplot as plt\n\nIMG_HT = 400\nIMG_WIDTH = 500\nBLACK_IMG = cv.imread('limb_darkening.png', cv.IMREAD_GRAYSCALE)\nEXO_RADIUS = 7\nEXO_START_X = 40\nEXO_START_Y = 230 \nEXO_DX = 3\nNUM_FRAMES = 145\n\ndef main():\n    intensity_samples = record_transit(EXO_START_X, EXO_START_Y)\n    relative_brightness = calc_rel_brightness(intensity_samples)\n    plot_light_curve(relative_brightness)\n\ndef record_transit(exo_x, exo_y):\n    \"\"\"Draw planet transiting star and return list of intensity changes.\"\"\"\n    intensity_samples = []\n    for _ in range(NUM_FRAMES):\n        temp_img = BLACK_IMG.copy()\n        # Draw exoplanet:\n        cv.circle(temp_img, (exo_x, exo_y), EXO_RADIUS, 0, -1)\n        intensity = temp_img.mean()\n        cv.putText(temp_img, 'Mean Intensity = {}'.format(intensity), (5, 390),\n                   cv.FONT_HERSHEY_PLAIN, 1, 255)\n        cv.imshow('Transit', temp_img)\n        cv.waitKey(30)\n        intensity_samples.append(intensity)\n        exo_x += EXO_DX\n    return intensity_samples\n\ndef calc_rel_brightness(intensity_samples):\n    \"\"\"Return list of relative brightness from list of intensity values.\"\"\"\n    rel_brightness = []\n    max_brightness = max(intensity_samples)\n    for intensity in intensity_samples:\n        rel_brightness.append(intensity / max_brightness)\n    return rel_brightness\n\ndef plot_light_curve(rel_brightness):\n    \"\"\"Plot changes in relative brightness vs. time.\"\"\"\n    plt.plot(rel_brightness, color='red', linestyle='dashed',\n             linewidth=2, label='Relative Brightness')\n    plt.legend(loc='upper center')\n    plt.title('Relative Brightness vs. Time')\n##    plt.ylim(0.995, 1.001)\n    plt.show()\n\nif __name__ == '__main__':\n    main()\n```", "```py\npractice_alien_armada.py\n\"\"\"Simulate transit of alien armada with light curve.\"\"\"\nimport random\nimport numpy as np\nimport cv2 as cv\nimport matplotlib.pyplot as plt\n\nSTAR_RADIUS = 165\nBLACK_IMG = np.zeros((400, 500, 1), dtype=\"uint8\")\nNUM_SHIPS = 5\nNUM_LOOPS = 300  # Number of simulation frames to run\n\nclass Ship():\n    \"\"\"Draws and moves a ship object on an image.\"\"\"\n    def __init__(self, number):\n        self.number = number\n        self.shape = random.choice(['>>>|==H[X)',\n                                    '>>|==H[XX}=))-',\n                                    '>>|==H[XX]=(-'])\n        self.size = random.choice([0.7, 0.8, 1])\n        self.x = random.randint(-180, -80)\n        self.y = random.randint(80, 350)\n        self.dx = random.randint(2, 4)\n\n    def move_ship(self, image):\n        \"\"\"Draws and moves ship object.\"\"\"\n        font = cv.FONT_HERSHEY_PLAIN\n        cv.putText(img=image, \n                   text=self.shape,\n                   org=(self.x, self.y),\n                   fontFace=font,\n                   fontScale=self.size,\n                   color=0,\n                   thickness=5) \n        self.x += self.dx\n\ndef record_transit(start_image):\n    \"\"\"Runs simulation and returns list of intensity measurements per frame.\"\"\"\n    ship_list = []\n    intensity_samples = []\n\n    for i in range(NUM_SHIPS):\n        ship_list.append(Ship(i))\n\n    for _ in range(NUM_LOOPS):\n        temp_img = start_image.copy()\n        cv.circle(temp_img, (250, 200), STAR_RADIUS, 255, -1)  # The star.\n        for ship in ship_list:\n            ship.move_ship(temp_img)\n        intensity = temp_img.mean()\n        cv.putText(temp_img, 'Mean Intensity = {}'.format(intensity),\n                   (5, 390), cv.FONT_HERSHEY_PLAIN, 1, 255)\n        cv.imshow('Transit', temp_img)\n        intensity_samples.append(intensity)\n        cv.waitKey(50)\n    cv.destroyAllWindows()\n    return intensity_samples\n\ndef calc_rel_brightness(image):\n    \"\"\"Return list of relative brightness measurments for planetary transit.\"\"\"\n    rel_brightness = record_transit(image)\n    max_brightness = max(rel_brightness)\n    for i, j in enumerate(rel_brightness):\n        rel_brightness[i] = j / max_brightness\n    return rel_brightness\n\ndef plot_light_curve(rel_brightness):\n    \"\"\"Plots curve of relative brightness vs. time.\"\"\"\n    plt.plot(rel_brightness, color='red', linestyle='dashed',\n             linewidth=2, label='Relative Brightness')\n    plt.legend(loc='upper center')\n    plt.title('Relative Brightness vs. Time')\n    plt.show()\n\nrelative_brightness = calc_rel_brightness(BLACK_IMG)\nplot_light_curve(relative_brightness)\n```", "```py\npractice_planet_moon.py\n\"\"\"Moon animation credit Eric T. Mortenson.\"\"\"\nimport math\nimport numpy as np\nimport cv2 as cv\nimport matplotlib.pyplot as plt\n\nIMG_HT = 500\nIMG_WIDTH = 500\nBLACK_IMG = np.zeros((IMG_HT, IMG_WIDTH, 1), dtype='uint8')\nSTAR_RADIUS = 200\nEXO_RADIUS = 20\nEXO_START_X = 20\nEXO_START_Y = 250\nMOON_RADIUS = 5\nNUM_DAYS = 200  # number days in year\n\ndef main():\n    intensity_samples = record_transit(EXO_START_X, EXO_START_Y)\n    relative_brightness = calc_rel_brightness(intensity_samples)\n    print('\\nestimated exoplanet radius = {:.2f}\\n'\n          .format(STAR_RADIUS * math.sqrt(max(relative_brightness)\n                                          -min(relative_brightness))))\n    plot_light_curve(relative_brightness)\n\ndef record_transit(exo_x, exo_y):\n    \"\"\"Draw planet transiting star and return list of intensity changes.\"\"\"\n    intensity_samples = []\n    for dt in range(NUM_DAYS):\n        temp_img = BLACK_IMG.copy()\n        # Draw star:\n        cv.circle(temp_img, (int(IMG_WIDTH / 2), int(IMG_HT/2)),\n                  STAR_RADIUS, 255, -1)\n        # Draw exoplanet\n        cv.circle(temp_img, (int(exo_x), int(exo_y)), EXO_RADIUS, 0, -1)\n        # Draw moon\n        if dt != 0:\n            cv.circle(temp_img, (int(moon_x), int(moon_y)), MOON_RADIUS, 0, -1)\n        intensity = temp_img.mean()\n        cv.putText(temp_img, 'Mean Intensity = {}'.format(intensity), (5, 10),\n                   cv.FONT_HERSHEY_PLAIN, 1, 255)\n        cv.imshow('Transit', temp_img)\n        cv.waitKey(10)        \n        intensity_samples.append(intensity)\n        exo_x = IMG_WIDTH / 2 - (IMG_WIDTH / 2 - 20) * \\\n                math.cos(2 * math.pi * dt / (NUM_DAYS)*(1 / 2))\n        moon_x = exo_x + \\\n                 3 * EXO_RADIUS * math.sin(2 * math.pi * dt / NUM_DAYS *(5))\n        moon_y = IMG_HT / 2 - \\\n                 0.25 * EXO_RADIUS * \\\n                 math.sin(2 * math.pi * dt / NUM_DAYS * (5))\n    cv.destroyAllWindows()\n\n    return intensity_samples\n\ndef calc_rel_brightness(intensity_samples):\n    \"\"\"Return list of relative brightness from list of intensity values.\"\"\"\n    rel_brightness = []\n    max_brightness = max(intensity_samples)\n    for intensity in intensity_samples:\n        rel_brightness.append(intensity / max_brightness)\n    return rel_brightness\n\ndef plot_light_curve(rel_brightness):\n    \"\"\"Plot changes in relative brightness vs. time.\"\"\"\n    plt.plot(rel_brightness, color='red', linestyle='dashed',\n             linewidth=2, label='Relative Brightness')\n    plt.legend(loc='upper center')\n    plt.title('Relative Brightness vs. Time')\n    plt.show()\n\nif __name__ == '__main__':\n    main()\n```", "```py\npractice_length _of_day.py\n\"\"\"Read-in images, calculate mean intensity, plot relative intensity vs time.\"\"\"\nimport os\nfrom statistics import mean\nimport cv2 as cv\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import signal  # See Chap. 1 to install scipy.\n\n# Switch to the folder containing images.\nos.chdir('br549_pixelated')\nimages = sorted(os.listdir())\nintensity_samples = []\n\n# Convert images to grayscale and make a list of mean intensity values.\nfor image in images:\n    img = cv.imread(image, cv.IMREAD_GRAYSCALE)    \n    intensity = img.mean()\n    intensity_samples.append(intensity)\n\n# Generate a list of relative intensity values.\nrel_intensity = intensity_samples[:]\nmax_intensity = max(rel_intensity)\nfor i, j in enumerate(rel_intensity):\n    rel_intensity[i] = j / max_intensity\n\n# Plot relative intensity values vs frame number (time proxy).\nplt.plot(rel_intensity, color='red', marker='o', linestyle='solid',\n         linewidth=2, markersize=0, label='Relative Intensity')\nplt.legend(loc='upper center')\nplt.title('Exoplanet BR549 Relative Intensity vs. Time')\nplt.ylim(0.8, 1.1)\nplt.xticks(np.arange(0, 50, 5))\nplt.grid()\nprint(\"\\nManually close plot window after examining to continue program.\")\nplt.show()\n\n# Find period / length of day.\n# Estimate peak height and separation (distance) limits from plot.\n# height and distance parameters represent >= limits.\npeaks = signal.find_peaks(rel_intensity, height=0.95, distance=5)\nprint(f\"peaks = {peaks}\")\nprint(\"Period = {}\".format(mean(np.diff(peaks[0]))))\n```", "```py\npractice_blur.py\nimport cv2 as cv\n\npath = \"C:/Python372/Lib/site-packages/cv2/data/\"\nface_cascade = cv.CascadeClassifier(path + 'haarcascade_frontalface_alt.xml')\n\ncap = cv.VideoCapture(0)\n\nwhile True:\n    _, frame = cap.read()\n    face_rects = face_cascade.detectMultiScale(frame, scaleFactor=1.2,\n                                               minNeighbors=3)    \n    for (x, y, w, h) in face_rects:\n        face = cv.blur(frame[y:y + h, x:x + w], (25, 25))\n        frame[y:y + h, x: x + w] = face\n        cv.rectangle(frame, (x,y), (x+w, y+h), (0, 255, 0), 2)\n\n    cv.imshow('frame', frame)\n    if cv.waitKey(1) & 0xFF == ord('q'):\n        break\n\ncap.release()\ncv.destroyAllWindows()\n```", "```py\nchallenge_video_recognize.py\n\"\"\"Recognize Capt. Demming's face in video frame.\"\"\"\nimport cv2 as cv\n\nnames = {1: \"Demming\"}\n\n# Set up path to OpenCV's Haar Cascades\npath = \"C:/Python372/Lib/site-packages/cv2/data/\"\ndetector = cv.CascadeClassifier(path + 'haarcascade_frontalface_default.xml')\n\n# Set up face recognizer and load trained data.\nrecognizer = cv.face.LBPHFaceRecognizer_create()\nrecognizer.read('lbph_trainer.yml')\n\n# Prepare webcam.\ncap = cv.VideoCapture(0)\nif not cap.isOpened(): \n    print(\"Could not open video device.\")\n##cap.set(3, 320)  # Frame width.\n##cap.set(4, 240)  # Frame height.\n\nwhile True:\n    _, frame = cap.read()\n    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n    face_rects = detector.detectMultiScale(gray, \n                                           scaleFactor=1.2,\n                                           minNeighbors=5)\n\n    for (x, y, w, h) in face_rects:\n        # Resize input so it's closer to training image size.\n        gray_resize = cv.resize(gray[y:y + h, x:x + w],\n                                (100, 100),\n                                cv.INTER_LINEAR)\n        predicted_id, dist = recognizer.predict(gray_resize)\n        if predicted_id == 1 and dist <= 110:\n            name = names[predicted_id]\n        else:\n            name = 'unknown'    \n        cv.rectangle(frame, (x, y), (x + w, y + h), (255, 255, 0), 2)\n        cv.putText(frame, name, (x + 1, y + h -5),\n                   cv.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)\n        cv.imshow('frame', frame)\n\n    if cv.waitKey(1) & 0xFF == ord('q'):\n        break\n\ncap.release()\ncv.destroyAllWindows()\n```"]
- en: '5'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '5'
- en: FINDING PLUTO
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 发现冥王星
- en: '![Image](../images/common.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/common.jpg)'
- en: According to Woody Allen, 80 percent of success is just showing up. This certainly
    describes the success of Clyde Tombaugh, an untrained Kansas farm boy growing
    up in the 1920s. With a passion for astronomy but no money for college, he took
    a stab in the dark and mailed his best astronomical sketches to Lowell Observatory.
    To his great surprise, he was hired as an assistant. A year later, he had discovered
    Pluto and gained eternal glory!
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 根据伍迪·艾伦的说法，成功的80%仅仅是出现在场。这无疑描述了克莱德·汤博的成功，一个没有受过训练的堪萨斯农场男孩，在1920年代长大。由于对天文学充满热情却没有上大学的钱，他尝试了一下，邮寄了自己最好的天文素描给洛威尔天文台。令他大吃一惊的是，他被聘为助手。一年后，他发现了冥王星，并因此获得了永恒的荣耀！
- en: Percival Lowell, the famous astronomer and founder of Lowell Observatory, had
    postulated the presence of Pluto based on perturbations in the orbit of Neptune.
    His calculations were wrong, but by pure coincidence, he correctly predicted Pluto’s
    orbital path. Between 1906 and his death in 1916, he had photographed Pluto twice.
    Both times, his team failed to notice it. Tombaugh, on the other hand, photographed
    *and* recognized Pluto in January 1930, after only a year of searching ([Figure
    5-1](ch05.xhtml#ch05fig1)).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 费尔西瓦尔·洛威尔，这位著名的天文学家和洛威尔天文台的创始人，基于海王星轨道的扰动提出了冥王星的存在。他的计算是错误的，但纯粹巧合的是，他正确预测了冥王星的轨道路径。在1906年到他1916年去世之间，他曾两次拍摄冥王星。每次，他的团队都未能注意到它。而汤博则在1930年1月，经过仅一年寻找，拍摄并识别出了冥王星（[图5-1](ch05.xhtml#ch05fig1)）。
- en: '![Image](../images/fig05_01.jpg)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/fig05_01.jpg)'
- en: 'Figure 5-1: Discovery plates for Pluto, indicated by the arrow'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 图5-1：冥王星的发现底片，箭头指示的位置
- en: What Tombaugh accomplished was extraordinary. Without computers, the methodology
    he followed was impractical, tedious, and demanding. He had to photograph and
    re-photograph small parts of the sky night after night, usually in a freezing
    cold dome shaken by icy winds. He then developed and sifted through all the negatives,
    searching for the faintest signs of movement within crowded star fields.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 汤博所取得的成就非凡。在没有计算机的情况下，他所遵循的方法论既不切实际，又繁琐且要求极高。他必须一夜又一夜地拍摄并重新拍摄天空的某些小部分，通常是在一个冰冷的圆顶下，圆顶被刺骨的寒风吹动。然后，他需要冲洗并筛选所有底片，寻找在星星密集区域中任何微弱的运动迹象。
- en: Although he lacked a computer, he did have a state-of-the-art device, known
    as a *blink comparator*, that let him rapidly switch between negatives from successive
    nights. As viewed through the blink comparator, the stars remained stationary,
    but Pluto, a moving object, flashed on and off like a beacon.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然他没有计算机，但他确实拥有一台先进的设备，叫做*闪烁比较器*，这使他能够快速在连续几晚的底片之间切换。在通过闪烁比较器观察时，恒星保持静止，但冥王星作为一个移动物体，像信标一样闪烁。
- en: In this chapter, you’ll first write a Python program that replicates an early
    20th-century blink comparator. Then you’ll move into the 21st century and write
    a program that automates the detection of moving objects using modern computer
    vision techniques.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将首先编写一个Python程序，复制20世纪初期的闪烁比较器。接着，你将进入21世纪，编写一个程序，利用现代计算机视觉技术自动检测运动物体。
- en: '**NOTE**'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*In 2006, the International Astronomical Union reclassified Pluto as a dwarf
    planet. This was based on the discovery of other Pluto-sized bodies in the Kuiper
    Belt, including one—Eris—that is volumetrically smaller but 27 percent more massive
    than Pluto.*'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '*2006年，国际天文学联合会将冥王星重新分类为矮行星。这是基于在柯伊伯带中发现了其他与冥王星相似的天体，包括一个——厄里斯——它的体积较小，但质量比冥王星大27%。*'
- en: '**Project #7: Replicating a Blink Comparator**'
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**项目#7：复制闪烁比较器**'
- en: Pluto may have been photographed with a telescope, but it was found with a microscope.
    The blink comparator ([Figure 5-2](ch05.xhtml#ch05fig2)), also called the *blink
    microscope*, lets the user mount two photographic plates and rapidly switch from
    looking at one to the other. During this “blinking,” any object that changes position
    between photographs will appear to jump back and forth.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 冥王星可能是用望远镜拍摄的，但它是用显微镜发现的。闪烁比较器（[图5-2](ch05.xhtml#ch05fig2)），也叫做*闪烁显微镜*，允许用户安装两张照片板并快速切换查看其中一张到另一张。在这种“闪烁”过程中，任何在两张照片之间发生位置变化的物体都会显得来回跳动。
- en: '![Image](../images/fig05_02.jpg)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/fig05_02.jpg)'
- en: 'Figure 5-2: A blink comparator'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图5-2：闪烁比较器
- en: For this technique to work, the photos need to be taken with the same exposure
    and under similar viewing conditions. Most importantly, the stars in the two images
    must line up perfectly. In Tombaugh’s day, technicians achieved this through painstaking
    manual labor; they carefully guided the telescope during the hour-long exposures,
    developed the photographic plates, and then shifted them in the blink comparator
    to fine-tune the alignment. Because of this exacting work, it would sometimes
    take Tombaugh a week to examine a single pair of plates.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使该技术有效，照片需要在相同的曝光条件下拍摄，并且具有相似的观看条件。最重要的是，两张图像中的星星必须完全对齐。在汤博（Tombaugh）时代，技术人员通过艰苦的手工劳动来完成这一过程；他们在长达一个小时的曝光过程中小心引导望远镜，显影胶片后，再通过闪烁比较器进行微调对齐。正因为这项精细的工作，汤博有时需要花费一周的时间来检查一对胶片。
- en: In this project, you’ll digitally duplicate the process of aligning the plates
    and blinking them on and off. You’ll work with bright and dim objects, see the
    impact of different exposures between photos, and compare the use of positive
    images to the negative ones that Tombaugh used.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，你将数字化复制对齐胶片并进行闪烁显示的过程。你将处理明亮和昏暗的物体，观察不同曝光下照片的影响，并比较使用正片与汤博所用的负片的效果。
- en: THE OBJECTIVE
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**目标**'
- en: Write a Python program that aligns two nearly identical images and displays
    each one in rapid succession in the same window.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 编写一个Python程序，将两张几乎相同的图像对齐，并在同一窗口中快速交替显示它们。
- en: '***The Strategy***'
  id: totrans-20
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***策略***'
- en: The photos for this project are already taken, so all you need to do is align
    them and flash them on and off. Aligning images is often referred to as image
    *registration*. This involves making a combination of vertical, horizontal, or
    rotational transformations to one of the images. If you’ve ever taken a panorama
    with a digital camera, you’ve seen registration at work.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 该项目的照片已经拍摄完成，因此你只需要将它们对齐并进行闪烁显示。图像对齐通常被称为图像*配准*。这涉及对其中一张图像进行垂直、水平或旋转的变换。如果你曾用数码相机拍摄过全景照片，那么你一定见过配准技术的应用。
- en: 'Image registration follows these steps:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图像配准按照以下步骤进行：
- en: Locate distinctive features in each image.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在每张图像中定位出独特的特征。
- en: Numerically describe each feature.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用数字描述每个特征。
- en: Use the numerical descriptors to match identical features in each image.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用数字描述符匹配每张图像中相同的特征。
- en: Warp one image so that matched features share the same pixel locations in both
    images.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将一张图像进行扭曲，使得匹配的特征在两张图像中的像素位置相同。
- en: For this to work well, the images should be the same size and cover close to
    the same area.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得良好的效果，图像应该具有相同的大小，并覆盖几乎相同的区域。
- en: Fortunately, the OpenCV Python package ships with algorithms that perform these
    steps. If you skipped [Chapter 1](ch01.xhtml), you can read about OpenCV on [page
    6](ch01.xhtml#page_6).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，OpenCV Python 包附带了可以执行这些步骤的算法。如果你跳过了[第1章](ch01.xhtml)，你可以在[第6页](ch01.xhtml#page_6)阅读关于OpenCV的内容。
- en: Once the images are registered, you’ll need to display them in the same window
    so that they overlay exactly and then loop through the display a set number of
    times. Again, you can easily accomplish this with the help of OpenCV.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦图像完成配准，你需要将它们显示在同一个窗口中，使其精确重叠，然后循环显示若干次。再次强调，你可以借助OpenCV轻松实现这一点。
- en: '***The Data***'
  id: totrans-30
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***数据***'
- en: The images you’ll need are in the *Chapter_5* folder in the book’s supporting
    files, downloadable from *[https://nostarch.com/real-world-python/](https://nostarch.com/real-world-python/)*.
    The folder structure should look like [Figure 5-3](ch05.xhtml#ch05fig3). After
    downloading the folders, don’t change this organizational structure or the folder
    contents and names.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要的图像位于书籍支持文件中的*Chapter_5*文件夹，可以从*[https://nostarch.com/real-world-python/](https://nostarch.com/real-world-python/)*下载。文件夹结构应如[图5-3](ch05.xhtml#ch05fig3)所示。下载文件夹后，请不要更改此组织结构或文件夹内容和名称。
- en: '![Image](../images/fig05_03.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/fig05_03.jpg)'
- en: 'Figure 5-3: The folder structure for Project 7'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图5-3：项目7的文件夹结构
- en: The *night_1* and *night_2* folders contain the input images you’ll use to get
    started. In theory, these would be images of the same region of space taken on
    different nights. The ones used here are the same star field image to which I’ve
    added an artificial *transient*. A transient, short for *transient astronomical
    event*, is a celestial object whose motion is detectable over relatively short
    time frames. Comets, asteroids, and planets can all be considered transients,
    as their movement is easily detected against the more static background of the
    galaxy.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 5-1](ch05.xhtml#ch05table1) briefly describes the contents of the *night_1*
    folder. This folder contains files with *left* in their filenames, which means
    they should go on the left side of a blink comparator. The images in the *night_2*
    folder contain *right* in the filenames and should go on the other side.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 5-1:** Files in the *night_1* folder'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '| Filename | Description |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
- en: '| *1_bright_transient_left.png* | Contains a large, bright transient |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
- en: '| *2_dim_transient_left.png* | Contains a dim transient a single pixel in diameter
    |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
- en: '| *3_diff_exposures_left.png* | Contains a dim transient with an overexposed
    background |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
- en: '| *4_single_transient_left.png* | Contains a bright transient in left image
    only |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
- en: '| *5_no_transient_left.png* | Star field with no transient |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
- en: '| *6_bright_transient_neg_left.png* | A negative of the first file to show
    the type of image Tombaugh used |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
- en: '[Figure 5-4](ch05.xhtml#ch05fig4) is an example of one of the images. The arrow
    points to the transient (but isn’t part of the image file).'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/fig05_04.jpg)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5-4: 1_bright_transient_left.png with an arrow indicating the transient'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: To duplicate the difficulty in perfectly aligning a telescope from night to
    night, I’ve slightly shifted the images in the *night_2* folder with respect to
    those in *night_1*. You’ll need to loop through the contents of the two folders,
    registering and comparing each pair of photos. For this reason, the number of
    files in each folder should be the same, and the naming convention should ensure
    that the photos are properly paired.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '***The Blink Comparator Code***'
  id: totrans-49
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The following *blink_comparator.py* code will digitally duplicate a blink comparator.
    Find this program in the *Chapter_5* folder from the website. You’ll also need
    the folders described in the previous section. Keep the code in the folder above
    the *night_1* and *night_2* folders.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '**Importing Modules and Assigning a Constant**'
  id: totrans-51
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[Listing 5-1](ch05.xhtml#ch05list1) imports the modules you’ll need to run
    the program and assigns a constant for the minimum number of keypoint matches
    to accept. Also called interest points, *keypoints* are interesting features in
    an image that you can use to characterize the image. They’re usually associated
    with sharp changes in intensity, such as corners or, in this case, stars.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Listing 5-1: Importing modules and assigning a constant for keypoint matches'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: Start by importing the operating system module, which you’ll use to list the
    contents of folders. Then import pathlib, a handy module that simplifies working
    with files and folders. Finish by importing NumPy and cv (OpenCV) for working
    with images. If you skipped [Chapter 1](ch01.xhtml), you can find installation
    instructions for NumPy on [page 8](ch01.xhtml#page_8).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 首先导入操作系统模块，使用它来列出文件夹中的内容。接着导入pathlib，一个简化处理文件和文件夹的有用模块。最后导入NumPy和cv（OpenCV）用于处理图像。如果你跳过了[第1章](ch01.xhtml)，你可以在[第8页](ch01.xhtml#page_8)找到NumPy的安装说明。
- en: Assign a constant variable for the minimum number of keypoint matches to accept.
    For efficiency, you ideally want the smallest value that will yield an acceptable
    registration result. In this project, the algorithm runs so quickly that you can
    increase this value without a significant cost.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 为接受的最小关键点匹配数量分配一个常量变量。为了提高效率，你最好选择一个能够产生可接受配准结果的最小值。在这个项目中，算法运行非常快，因此可以增加这个值，而不会产生显著的成本。
- en: '**Defining the main() Function**'
  id: totrans-57
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**定义main()函数**'
- en: '[Listing 5-2](ch05.xhtml#ch05list2) defines the first part of the main() function,
    used to run the program. These initial steps create lists and directory paths
    used to access the various image files.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[清单 5-2](ch05.xhtml#ch05list2)定义了main()函数的第一部分，用于运行程序。这些初步步骤创建了列表和目录路径，用于访问各种图像文件。'
- en: '[PRE1]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Listing 5-2: Defining the first part of main(), used to manipulate files and
    folders'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 清单 5-2：定义main()的第一部分，用于操作文件和文件夹
- en: 'Start by defining main() and then use the os module’s listdir() method to create
    a list of the filenames in the *night_1* and *night_2* folders. For the *night_1*
    folder, listdir() returns the following:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 首先定义main()函数，然后使用os模块的listdir()方法来创建*night_1*和*night_2*文件夹中所有文件名的列表。对于*night_1*文件夹，listdir()返回以下内容：
- en: '[PRE2]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Note that os.listdir() does not impose an order on the files when they’re returned.
    The underlying operating system determines the order, meaning macOS will return
    a different list than Windows! To ensure that the lists are consistent and the
    files are paired correctly, wrap os.listdir() with the built-in sorted() function.
    This function will return the files in numerical order, based on the first character
    in the filename.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，os.listdir()在返回文件时并不对文件进行排序。底层操作系统决定了排序顺序，这意味着macOS返回的列表将与Windows不同！为了确保列表一致且文件正确配对，可以用内建的sorted()函数包装os.listdir()。该函数会基于文件名的第一个字符返回按数字顺序排列的文件。
- en: Next, assign path names to variables using the pathlib Path class. The first
    two variables will point to the two input folders, and the third will point to
    an output folder to hold the registered images.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，使用pathlib的Path类将路径名分配给变量。前两个变量将指向两个输入文件夹，第三个变量将指向一个输出文件夹，用于存放配准后的图像。
- en: The pathlib module, introduced in Python 3.4, is an alternative to os.path for
    handling file paths. The os module treats paths as strings, which can be cumbersome
    and requires you to use functionality from across the Standard Library. Instead,
    the pathlib module treats paths as objects and gathers the necessary functionality
    in one place. The official documentation for pathlib is at *[https://docs.python.org/3/library/pathlib.html](https://docs.python.org/3/library/pathlib.html)*.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: pathlib模块是Python 3.4引入的，它是os.path的替代方案，用于处理文件路径。os模块将路径视为字符串，这可能会很麻烦，并且需要你使用标准库中的多个功能。相反，pathlib模块将路径视为对象，并将所需的功能集中在一个地方。pathlib的官方文档位于*
    [https://docs.python.org/3/library/pathlib.html](https://docs.python.org/3/library/pathlib.html)
    *。
- en: For the first part of the directory path, use the cwd() class method to get
    the current working directory. If you have at least one Path object, you can use
    a mix of objects and strings in the path designation. You can join the string,
    representing the folder name, with the / symbol. This is similar to using os.path.join(),
    if you’re familiar with the os module.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 对于目录路径的第一部分，使用cwd()类方法获取当前工作目录。如果你至少有一个Path对象，你可以在路径指定中混合使用对象和字符串。你可以将表示文件夹名称的字符串与/符号连接起来。这与使用os.path.join()类似，如果你熟悉os模块的话。
- en: Note that you will need to execute the program from within the project directory.
    If you call it from elsewhere in the filesystem, it will fail.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，你需要在项目目录内执行程序。如果从文件系统的其他地方调用它，将会失败。
- en: '**Looping in main()**'
  id: totrans-68
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**在main()中的循环**'
- en: '[Listing 5-3](ch05.xhtml#ch05list3), still in the main() function, runs the
    program with a big for loop. This loop will take a file from each of the two “night”
    folders, load them as grayscale images, find matching keypoints in each image,
    use the keypoints to warp (or *register*) the first image to match the second,
    save the registered image, and then compare (or *blink*) the registered first
    image with the original second image. I’ve also included a few optional quality
    control steps that you can comment out once you’re satisfied with the results.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Listing 5-3: Running the program loop in main()'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: Begin the loop by enumerating the night1_files list. The enumerate() built-in
    function adds a counter to each item in the list and returns this counter along
    with the item. Since you only need the counter, use a single underscore (_) for
    the list item. By convention, the single underscore indicates a temporary or insignificant
    variable. It also keeps code-checking programs, such as Pylint, happy. Were you
    to use a variable name here, such as infile, Pylint would complain about an *unused
    variable*.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Next, load the image, along with its pair from the night2_files list, using
    OpenCV. Note that you have to convert the path to a string for the imread() method.
    You’ll also want to convert the image to grayscale. This way, you’ll need to work
    with only a single channel, which represents intensity. To keep track of what’s
    going on during the loop, print a message to the shell indicating which files
    are being compared.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, find the keypoints and their best matches ➊. The find_best_matches() function,
    which you’ll define later, will return these values as three variables: kp1, which
    represents the keypoints for the first loaded image; kp2, which represents the
    keypoints for the second; and best_matches, which represents a list of the matching
    keypoints.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: So you can visually check the matches, draw them on img1 and img2 using OpenCV’s
    drawMatches() method. As arguments, this method takes each image with its keypoints,
    the list of best matching keypoints, and an output image. In this case, the output
    image argument is set to None, as you’re just going to look at the output, not
    save it to a file.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: To distinguish between the two images, draw a vertical white line down the right
    side of img1. First get the height and width of the image using shape. Next, call
    OpenCV’s line() method and pass it the image on which you want to draw, the start
    and end coordinates, the line color, and the thickness. Note that this is a color
    image, so to represent white, you need the full BGR tuple (255, 255, 255) rather
    than the single intensity value (255) used in grayscale images.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: Now, call the quality control function—which you’ll define later—to display
    the matches ➋. [Figure 5-5](ch05.xhtml#ch05fig5) shows an example output. You
    may want to comment out this line after you confirm the program is behaving correctly.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/fig05_05.jpg)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5-5: Example output of the QC_best_matches() function'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5-5：QC_best_matches() 函数的示例输出
- en: With the best keypoint matches found and checked, it’s time to register the
    first image to the second. Do this with a function you’ll write later. Pass the
    function the two images, the keypoints, and the list of best matches.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 找到并检查了最佳关键点匹配后，是时候将第一张图像注册到第二张图像了。使用稍后编写的函数来执行此操作。将两张图像、关键点和最佳匹配列表传递给该函数。
- en: The blink comparator, named blink(), is another function that you’ll write later.
    Call it here to see the effect of the registration process on the first image.
    Pass it the original and registered images, a name for the display window, and
    the number of blinks you want to perform ➌. The function will flash between the
    two images. The amount of “wiggle” you see will depend on the amount of warping
    needed to match img2. This is another line you may want to comment out after you’ve
    confirmed that the program runs as intended.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: Blink 比较器（名为 blink()）是你稍后将编写的另一个函数。在这里调用它，查看注册过程对第一张图像的影响。传递给它原始图像和注册后的图像、显示窗口的名称以及你希望执行的闪烁次数
    ➌。该函数将在两张图像之间闪烁。你看到的“摇晃”程度将取决于匹配 img2 所需的扭曲量。确认程序按预期运行后，可能想注释掉这一行。
- en: Next, save the registered image into a folder named *night_1_registered*, which
    the path3 variable points to. Start by assigning a filename variable that references
    the original filename, with *_registered.png* appended to the end. So you don’t
    repeat the file extension in the name, use index slicing ([:-4]) to remove it
    before adding the new ending. Finish by using imwrite() to save the file. Note
    that this will overwrite existing files with the same name without warning.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，将注册后的图像保存到名为 *night_1_registered* 的文件夹中，该文件夹路径由 path3 变量指向。首先，分配一个文件名变量，引用原始文件名，并在末尾附加
    *_registered.png*。为了避免在名称中重复文件扩展名，使用索引切片（[:-4]）将其去除，然后再添加新的结尾。最后，使用 imwrite()
    保存文件。请注意，这将覆盖具有相同名称的现有文件，而不会发出警告。
- en: You’ll want an uncluttered view when you start looking for transients, so call
    the method to destroy all the current OpenCV windows. Then call the blink() function
    again, passing it the registered image, the second image, a window name, and the
    number of times to loop through the images. The first images are shown side by
    side in [Figure 5-6](ch05.xhtml#ch05fig6). Can you find the transient?
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始寻找瞬时变化时，你需要一个干净的视图，因此调用方法销毁所有当前的 OpenCV 窗口。然后再次调用 blink() 函数，将注册后的图像、第二张图像、窗口名称以及循环图像的次数传递给它。第一张图像将并排显示在
    [图 5-6](ch05.xhtml#ch05fig6) 中。你能找到瞬时变化吗？
- en: '![Image](../images/fig05_06.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/fig05_06.jpg)'
- en: 'Figure 5-6: Blink Comparator windows for first image in night_1_registered
    and night_2 folders'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5-6：night_1_registered 和 night_2 文件夹中第一张图像的 Blink Comparator 窗口
- en: '**Finding the Best Keypoint Matches**'
  id: totrans-87
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**查找最佳关键点匹配**'
- en: Now it’s time to define the functions used in main(). [Listing 5-4](ch05.xhtml#ch05list4)
    defines the function that finds the best keypoint matches between each pair of
    images extracted from the *night_1* and *night_2* folders. It should locate, describe,
    and match keypoints, generate a list of the matches, and then truncate that list
    by the constant for the minimum number of acceptable keypoints. The function returns
    the list of keypoints for each image and the list of best matches.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候定义主函数中使用的函数了。[列表 5-4](ch05.xhtml#ch05list4)定义了一个函数，用于查找从 *night_1* 和 *night_2*
    文件夹中提取的每对图像之间的最佳关键点匹配。它应该定位、描述并匹配关键点，生成匹配列表，然后通过最小可接受关键点数的常量截断该列表。该函数返回每张图像的关键点列表和最佳匹配列表。
- en: '[PRE5]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Listing 5-4: Defining the function to find the best keypoint matches'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5-4：定义用于查找最佳关键点匹配的函数
- en: Start by defining the function, which takes two images as arguments. The main()
    function will pick these images from the input folders with each run of the for
    loop.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 首先定义该函数，该函数以两张图像作为参数。主函数（main()）将在每次运行 for 循环时从输入文件夹中选择这些图像。
- en: 'Next, create an orb object using OpenCV’s ORB_create() method. ORB is an acronym
    of nested acronyms: *O*riented FAST and *R*otated *B*RIEF.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，使用 OpenCV 的 ORB_create() 方法创建一个 orb 对象。ORB 是嵌套首字母缩写词的缩写：*O*riented FAST
    和 *R*otated *B*RIEF。
- en: FAST, short for *F*eatures from *A*ccelerated *S*egment *T*est, is a fast, efficient,
    and free algorithm for *detecting* keypoints. To *describe* the keypoints so that
    you can compare them across different images, you need BRIEF. Short for *B*inary
    *R*obust *I*ndependent *E*lementary *F*eatures, BRIEF is also fast, compact, and
    open source.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: ORB combines FAST and BRIEF into a matching algorithm that works by first detecting
    distinctive regions in an image, where pixel values change sharply, and then recording
    the position of these distinctive regions as *keypoints*. Next, ORB describes
    the feature found at the keypoint using numerical arrays, or *descriptors*, by
    defining a small area, called a *patch*, around a keypoint. Within the image patch,
    the algorithm uses a pattern template to take regular samples of intensity. It
    then compares preselected pairs of samples and converts them into binary strings
    called *feature vectors* ([Figure 5-7](ch05.xhtml#ch05fig7)).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: A *vector* is a series of numbers. A *matrix* is a rectangular array of numbers
    in rows and columns that’s treated as a single entity and manipulated according
    to rules. A *feature vector* is a matrix with one row and multiple columns. To
    build one, the algorithm converts the sample pairs into a binary series by concatenating
    a 1 to the end of the vector if the first sample has the largest intensity and
    a 0 if the reverse is true.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/fig05_07.jpg)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5-7: Cartoon example of how ORB generates keypoint descriptors'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: Some example feature vectors are shown next. I’ve shortened the list of vectors,
    because ORB usually compares and records 512 pairs of samples!
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: These descriptors act as digital fingerprints for features. OpenCV uses additional
    code to compensate for rotation and scale changes. This allows it to match similar
    features even if the feature sizes and orientations are different (see [Figure
    5-8](ch05.xhtml#ch05fig8)).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/fig05_08.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5-8: OpenCV can match keypoints despite differences in scale and orientation.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: When you create the ORB object, you can specify the number of keypoints to examine.
    The method defaults to 500, but 100 will be more than enough for the image registration
    needed in this project.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: Next, using the orb.detectAndCompute() method ➊, find the keypoints and their
    descriptors. Pass it img1 and then repeat the code for img2.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: With the keypoints located and described, the next step is to find the keypoints
    common to both images. Start this process by creating a BFMatcher object that
    includes a distance measurement. The brute-force matcher takes the descriptor
    of one feature in the first image and compares it to all the features in the second
    image using the Hamming distance. It returns the closest feature.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: 'For two strings of equal length, the *Hamming distance* is the number of positions,
    or indexes, at which the corresponding values are different. For the following
    feature vectors, the positions that don’t match are shown in bold, and the Hamming
    distance is 3:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The bf variable will be a BFMatcher object. Call the match() method and pass
    it the descriptors for the two images ➋. Assign the returned list of DMatch objects
    to a variable named matches.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: The best matches will have the lowest Hamming distance, so sort the objects
    in ascending order to move these to the start of the list. Note that you use a
    lambda function along with the object’s distance attribute. A *lambda function*
    is a small, one-off, unnamed function defined on the fly. Words and characters
    that directly follow lambda are parameters. Expressions come after the colon,
    and returns are automatic.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: Since you only need the minimum number of keypoint matches defined at the start
    of the program, create a new list by slicing the matches list. The best matches
    are at the start, so slice from the start of matches up to the value specified
    in MIN_NUM_KEYPOINT_MATCHES.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, you’re still dealing with arcane objects, as shown here:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Fortunately, OpenCV knows how to handle these. Complete the function by returning
    the two sets of keypoints and the list of best matching objects.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: '**Checking the Best Matches**'
  id: totrans-114
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[Listing 5-5](ch05.xhtml#ch05list5) defines a short function to let you visually
    check the keypoint matches. You saw the results of this function in [Figure 5-5](ch05.xhtml#ch05fig5).
    By encapsulating these tasks in a function, you can reduce the clutter in main()
    and allow the user to turn off the functionality by commenting out a single line.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Listing 5-5: Defining a function to check the best keypoint matches'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: 'Define the function with one parameter: the matched image. This image was generated
    by the main() function in [Listing 5-3](ch05.xhtml#ch05list3). It consists of
    the left and right images with the keypoints drawn as colored circles and with
    colored lines connecting corresponding keypoints.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: Next, call OpenCV’s imshow() method to display the window. You can use the format()
    method when naming the window. Pass it the constant for the number of minimum
    keypoint matches.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: Complete the function by giving the user 2.5 seconds to view the window. Note
    that the waitKey() method doesn’t destroy the window; it just suspends the program
    for the allocated amount of time. After the wait period, new windows will appear
    as the program resumes.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '**Registering Images**'
  id: totrans-121
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[Listing 5-6](ch05.xhtml#ch05list6) defines the function to register the first
    image to the second image.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Listing 5-6: Defining a function to register one image to another'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: Define a function that takes the two input images, their keypoint lists, and
    the list of DMatch objects returned from the find_best_matches() function as arguments.
    Next, load the location of the best matches into NumPy arrays. Start with a conditional
    to check that the list of best matches equals or exceeds the MIN_NUM_KEYPOINT_MATCHES
    constant. If it does, then initialize two NumPy arrays with as many rows as there
    are best matches.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: 'The np.zeros() NumPy method returns a new array of a given shape and data type,
    filled with zeros. For example, the following snippet produces a zero-filled array
    three rows tall and two columns wide:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: In the actual code, the arrays will be at least 50×2, since you stipulated a
    minimum of 50 matches.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: Now, enumerate the matches list and start populating the arrays with actual
    data ➊. For the source points, use the queryIdx.pt attribute to get the index
    of the descriptor in the list of descriptors for kp1. Repeat this for the next
    set of points, but use the trainIdx.pt attribute. The query/train terminology
    is a bit confusing but basically refers to the first and second images, respectively.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: The next step is to apply *homography*. Homography is a transformation, using
    a 3×3 matrix, that maps points in one image to corresponding points in another
    image. Two images can be related by a homography if both are viewing the same
    plane from a different angle or if both images are taken from the same camera
    rotated around its optical axis with no shift. To run correctly, homography needs
    at least four corresponding points in two images.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: Homography assumes that the matching points really are corresponding points.
    But if you look carefully at [Figures 5-5](ch05.xhtml#ch05fig5) and [5-8](ch05.xhtml#ch05fig8),
    you’ll see that the feature matching isn’t perfect. In [Figure 5-8](ch05.xhtml#ch05fig8),
    around 30 percent of the matches are incorrect!
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, OpenCV includes a findHomography() method with an outlier detector
    called *random sample consensus* (RANSAC). RANSAC takes random samples of the
    matching points, finds a mathematical model that explains their distribution,
    and favors the model that predicts the most points. It then discards outliers.
    For example, consider the points in the “Raw data” box in [Figure 5-9](ch05.xhtml#ch05fig9).
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/fig05_09.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5-9: Example line fit using RANSAC to ignore outliers'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, you want to fit a line through the true data points (called
    the *inliers*) and ignore the smaller number of spurious points (the *outliers*).
    Using RANSAC, you randomly sample a subset of the raw data points, fit a line
    to these, and then repeat this process a set number of times. Each line-fit equation
    would then be applied to all the points. The line that passes through the most
    points is used for the final line fit. In [Figure 5-9](ch05.xhtml#ch05fig9), this
    would be the line in the rightmost box.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: To run findHomography(), pass it the source and destination points and call
    the RANSAC method. This returns a NumPy array and a mask. The mask specifies the
    inlier and outlier points or the good matches and bad matches, respectively. You
    can use it to do tasks like draw only the good matches.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: The final step is to warp the first image so that it perfectly aligns with the
    second. You’ll need the dimensions of the second image, so use shape() to get
    the height and width of img2 ➋. Pass this information, along with img1 and the
    homography h_array, to the warpPerspective() method. Return the registered image,
    which will be a NumPy array.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: If the number of keypoint matches is less than the minimum number you stipulated
    at the start of the program, the image *may not* be properly aligned. So, print
    a warning and return the original, nonregistered image. This will allow the main()
    function to continue looping through the folder images uninterrupted. If the registration
    is poor, the user will be aware something is wrong as the problem pair of images
    won’t be properly aligned in the blink comparator window. An error message will
    also appear in the shell.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '**Building the Blink Comparator**'
  id: totrans-140
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[Listing 5-7](ch05.xhtml#ch05list7) defines a function to run the blink comparator
    and then calls main() if the program is run in stand-alone mode. The blink() function
    loops through a specified range, showing first the registered image and then the
    second image, both in the same window. It shows each image for only one-third
    of a second, Clyde Tombaugh’s preferred frequency when using a blink comparator.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Listing 5-7: Defining a function to blink images on and off'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: 'Define the blink() function with four parameters: two image files, a window
    name, and the number of blinks to perform. Start a for loop with a range set to
    the number of blinks. Since you don’t need access to the running index, use a
    single underscore (_) to indicate the use of an insignificant variable. As mentioned
    previously in this chapter, this will prevent code-checking programs from raising
    an “unused variable” warning.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: Now call OpenCV’s imshow() method and pass it the window name and the first
    image. This will be the *registered* first image. Then pause the program for 330
    milliseconds, the amount of time recommended by Clyde Tombaugh himself.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: Repeat the previous two lines of code for the second image. Because the two
    images are aligned, the only thing that will change in the window are transients.
    If only one image contains a transient, it will appear to blink on and off. If
    both images capture the transient, it will appear to dance back and forth.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: End the program with the standard code that lets it run in stand-alone mode
    or be imported as a module.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '***Using the Blink Comparator***'
  id: totrans-148
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Before you run *blink_comparator.py*, dim your room lights to simulate looking
    through the device’s eyepieces. Then launch the program. You should first see
    two obvious bright dots flashing near the center of the image. In the next pair
    of images, the same dots will become very small—only a pixel across—but you should
    still be able to detect them.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: The third loop will show the same small transient, only this time the second
    image will be brighter overall than the first. You should still be able to find
    the transient, but it will be much more difficult. This is why Tombaugh had to
    carefully take and develop the images to a consistent exposure.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: The fourth loop contains a single transient, shown in the left image. It should
    blink on and off rather than dance back and forth as in the previous images.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: 'The fifth image pair represents control images with no transients. This is
    what the astronomer would see almost all the time: disappointing static star fields.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: The final loop uses negative versions of the first image pair. The bright transient
    appears as flashing black dots. This is the type of image Clyde Tombaugh used,
    as it saved time. Since a black dot is as easy to spot as a white one, he felt
    no need to print positive images for each negative.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: If you look along the left side of the registered negative image, you’ll see
    a black stripe that represents the amount of translation needed to align the images
    ([Figure 5-10](ch05.xhtml#ch05fig10)). You won’t notice this on the positive images
    because it blends in with the black background.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/fig05_10.jpg)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5-10: The negative image, 6_bright_transient_neg_left_registered.png'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: 'In all the loops, you may notice a dim star blinking in the upper-left corner
    of each image pair. This is not a transient but a false positive caused by an
    *edge artifact*. An edge artifact is a change to an image caused by image misalignment.
    An experienced astronomer would ignore this dim star because: it occurs very close
    to the edge of the image, and the possible transient doesn’t move between images
    but just dims.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: You can see the cause of this false positive in [Figure 5-11](ch05.xhtml#ch05fig11).
    Because only part of a star is captured in the first frame, its brightness is
    reduced relative to the same star in the second image.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/fig05_11.jpg)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5-11: Registering a truncated star in Image 1 results in a noticeably
    dimmer star than in Image 2'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: Humans can handle edge effects intuitively, but computers require explicit rules.
    In the next project, you’ll address this issue by excluding the edges of images
    when searching for transients.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: '**Project #8: Detecting Astronomical Transients with Image Differencing**'
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Blink comparators, once considered as important as telescopes, now sit idly
    gathering dust in museums. Astronomers no longer need them, as modern image-differencing
    techniques are much better at detecting moving objects than human eyes. Today,
    every part of Clyde Tombaugh’s work would be done by computers.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: In this project, let’s pretend you’re a summer intern at an observatory. Your
    job is to produce a digital workflow for an ancient astronomer still clinging
    to his rusty blink comparator.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: THE OBJECTIVE
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: Write a Python program that takes two registered images and highlights any differences
    between them.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: '***The Strategy***'
  id: totrans-167
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Instead of an algorithm that blinks the images, you now want one that automatically
    finds the transients. This process will still require registered images, but for
    convenience, just use the ones already produced in Project 7.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: Detecting differences between images is a common enough practice that OpenCV
    ships with an absolute difference method, absdiff(), dedicated to this purpose.
    It takes the per-element difference between two arrays. But just detecting the
    differences isn’t enough. Your program will need to recognize that a difference
    exists and show the user only the images containing transients. After all, astronomers
    have more important things to do, like demoting planets!
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: Because the objects you’re looking for rest on a black background and matching
    bright objects are removed, any bright object remaining after differencing is
    worth noting. And since the odds of having more than one transient in a star field
    are astronomically low, flagging one or two differences should be enough to get
    an astronomer’s attention.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: '***The Transient Detector Code***'
  id: totrans-171
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The following *transient_detector.py* code will automate the process of detecting
    transients in astronomical images. Find it in the *Chapter_5* folder from the
    website. To avoid duplicating code, the program uses the images already registered
    by *blink_comparator.py*, so you’ll need the *night_1_registered_transients* and
    *night_2* folders in the directory for this project (see [Figure 5-3](ch05.xhtml#ch05fig3)).
    As in the previous project, keep the Python code in the folder *above* these two
    folders.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: '**Importing Modules and Assigning a Constant**'
  id: totrans-173
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[Listing 5-8](ch05.xhtml#ch05list8) imports the modules needed to run the program
    and assigns a pad constant to manage edge artifacts (see [Figure 5-11](ch05.xhtml#ch05fig11)).
    The pad represents a small distance, measured perpendicular to the image’s edges,
    that you want to exclude from the analysis. Any objects detected between the edge
    of the image and the pad will be ignored.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Listing 5-8: Importing modules and assigning a constant to manage edge effects'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: You’ll need all the modules used in the previous project except for NumPy, so
    import them here. Set the pad distance to 5 pixels. This value may change slightly
    with different datasets. Later, you’ll draw a rectangle around the edge space
    within the image so you can see how much area this parameter is excluding.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: '**Detecting and Circling Transients**'
  id: totrans-178
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[Listing 5-9](ch05.xhtml#ch05list9) defines a function you’ll use to find and
    circle up to two transients in each image pair. It will ignore transients in the
    padded area.'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Listing 5-9: Defining a function to detect and circle transients'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: 'The find_transient() function has three parameters: the input image, an image
    representing the difference between the first and second input images (representing
    the *difference map*), and the PAD constant. The function will find the location
    of the brightest pixel in the difference map, draw a circle around it, and return
    the location along with a Boolean indicating that an object was found.'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: Begin the function by setting a variable, named transient, to False. You’ll
    use this variable to indicate whether a transient has been discovered. As transients
    are rare in real life, its base state should be False.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: To apply the PAD constant and exclude the area near the edge of the image, you’ll
    need the limits of the image. Get these with the shape attribute, which returns
    a tuple of the image’s height and width.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: Use the height and width variables and the PAD constant to draw a white rectangle
    on the image variable using OpenCV’s rectangle() method. Later, this will show
    the user which parts of the image were ignored.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: The diff_image variable is a NumPy array representing pixels. The background
    is black, and any “stars” that changed position (or appeared out of nowhere) between
    the two input images will be gray or white (see [Figure 5-12](ch05.xhtml#ch05fig12)).
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/fig05_12.jpg)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5-12: Difference image derived from the “bright transient” input images'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: To locate the brightest transient present, use OpenCV’s minMaxLoc() method,
    which returns the minimum and maximum pixel values in the image, along with their
    location tuple. Note that I’m naming the variables to be consistent with OpenCV’s
    mixed-case naming scheme (evident in names such as maxLoc). If you want to use
    something more acceptable to Python’s PEP8 style guide (*[https://www.python.org/dev/peps/pep-0008/](https://www.python.org/dev/peps/pep-0008/)*),
    feel free to use names like max_loc in place of maxLoc.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: You may have found a maximum value near the edge of the image, so run a conditional
    to exclude this case by ignoring values found in the area delimited by the PAD
    constant ➊. If the location passes, circle it on the image variable. Use a white
    circle with a radius of 10 pixels and a line width of 0.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: If you’ve drawn a circle, then you’ve found a transient, so set the transient
    variable to True. This will trigger additional activity later in the program.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: End the function by returning the transient and maxLoc variables.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: '*The minMaxLoc() method is susceptible to noise, such as false positives, as
    it works on individual pixels. Normally, you would first run a preprocessing step,
    like blurring, to remove spurious pixels. This can cause you to miss dim astronomical
    objects, however, which can be indistinguishable from noise in a single image.*'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: '**Preparing Files and Folders**'
  id: totrans-195
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[Listing 5-10](ch05.xhtml#ch05list10) defines the main() function, creates
    lists of the filenames in the input folders, and assigns the folder paths to variables.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Listing 5-10: Defining main(), listing the folder contents, and assigning path
    variables'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: Define the main() function. Then, just as you did in [Listing 5-2](ch05.xhtml#ch05list2)
    on [page 100](ch05.xhtml#page_100), list the contents of the folders containing
    the input images and assign their paths to variables. You’ll use an existing folder
    to hold images containing identified transients.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: '**Looping Through Images and Calculating Absolute Difference**'
  id: totrans-200
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[Listing 5-11](ch05.xhtml#ch05list11) starts the for loop through the image
    pairs. The function reads corresponding image pairs as grayscale arrays, calculates
    the difference between the images, and shows the result in a window. It then calls
    the find_transient() function on the difference image.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Listing 5-11: Looping through the images and finding the transients'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: Start a for loop that iterates through the images in the *night1_files* list.
    The program is designed to work on *positive* images, so use image slicing ([:-1])
    to exclude the negative image. Use enumerate() to get a counter; name it i, rather
    than _, since you’ll use it as an index later.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: To find the differences between images, just call the cv.absdiff() method and
    pass it the variables for the two images. Show the results for two seconds before
    continuing the program.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: Since you’re going to blank out the brightest transient, first make a copy of
    diff_imgs1_2. Name this copy temp, for temporary. Now, call the find_transient()
    function you wrote earlier. Pass it the first input image, the difference image,
    and the PAD constant. Use the results to update the transient variable and to
    create a new variable, transient_loc1, that records the location of the brightest
    pixel in the difference image.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: The transient may or may not have been captured in both images taken on successive
    nights. To see if it was, obliterate the bright spot you just found by covering
    it with a black circle. Do this on the temp image by using black as the color
    and a line width of –1, which tells OpenCV to fill the circle. Continue to use
    a radius of 10, though you can reduce this if you’re concerned the two transients
    will be very close together.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: Call the find_transient() function again but use a single underscore for the
    location variable, as you won’t be using it again. It’s unlikely there’ll be more
    than two transients present, and finding even one will be enough to open the images
    up to further scrutiny, so don’t bother looking for more.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: '**Revealing the Transient and Saving the Image**'
  id: totrans-209
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[Listing 5-12](ch05.xhtml#ch05list12), still in the for loop of the main()
    function, displays the first input image with any transients circled, posts the
    names of the image files involved, and saves the image with a new filename. You’ll
    also print a log of the results for each image pair in the interpreter window.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Listing 5-12: Showing the circled transients, logging the results, and saving
    the results'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: 'Start a conditional that checks whether a transient was found. If this evaluates
    to True, print a message in the shell. For the four images evaluated by the for
    loop, you should get this result:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Posting a negative outcome shows that the program is working as expected and
    leaves no doubt that the images were compared.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: Next, post the names of the two images with a positive response on the img1
    array. Start by assigning a font variable for OpenCV ➊. For a listing of available
    fonts, search for *HersheyFonts* at *[https://docs.opencv.org/4.3.0/](https://docs.opencv.org/4.3.0/)*.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: Now call OpenCV’s putText() method and pass it the first input image, the filename
    of the image, a position, the font variable, a size, a color (white), a thickness,
    and a line type. The LINE_AA attribute creates an anti-aliased line. Repeat this
    code for the second image.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: If you found two transients, you can show them both on the same image using
    OpenCV’s addWeighted() method. This method calculates the weighted sum of two
    arrays. The arguments are the first image and a weight, the second image and a
    weight, and a scalar that’s added to each sum. Use the first input image and the
    difference image, set the weights to 1 so that each image is used fully, and set
    the scalar to 0. Assign the result to a variable named blended.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: Show the blended image in a window named Surveyed. [Figure 5-13](ch05.xhtml#ch05fig13)
    shows an example outcome for the “bright” transient.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/fig05_13.jpg)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5-13: Example output window of transient_detector.py with the pad rectangle
    indicated by the arrow'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: Note the white rectangle near the edges of the image. This represents the PAD
    distance. Any transients outside this rectangle were ignored by the program.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: Save the blended image using the filename of the current input image plus “DETECTED”
    ➋. The dim transient in [Figure 5-13](ch05.xhtml#ch05fig13) would be saved as
    *1_bright_transient_left_registered_DECTECTED.png*. Write it to the *night_1_2_transients*
    folder, using the path3 variable.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: If no transients were found, document the result in the shell window. Then end
    the program with the code to run it as a module or in stand-alone mode.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: '***Using the Transient Detector***'
  id: totrans-225
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Imagine how happy Clyde Tombaugh would’ve been with your transient detector.
    It’s truly set-it-and-forget-it. Even the changing brightness between the third
    pair of images, so problematic with the blink comparator, is no challenge for
    this program.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: '**Summary**'
  id: totrans-227
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this chapter, you replicated an old-time blink comparator device and then
    updated the process using modern computer vision techniques. Along the way, you
    used the pathLib module to simplify working with directory paths, and you used
    a single underscore for insignificant, unused variable names. You also used OpenCV
    to find, describe, and match interesting features in images, align the features
    with homography, blend the images together, and write the result to a file.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: '**Further Reading**'
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Out of the Darkness: The Planet Pluto* (Stackpole Books, 2017), by Clyde Tombaugh
    and Patrick Moore, is the standard reference on the discovery of Pluto, told in
    the discoverer’s own words.'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: '*Chasing New Horizons: Inside the Epic First Mission to Pluto* (Picador, 2018),
    by Alan Stern and David Grinspoon, records the monumental effort to finally send
    a spacecraft—which, incidentally, contained Clyde Tombaugh’s ashes—to Pluto.'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: '**Practice Project: Plotting the Orbital Path**'
  id: totrans-232
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Edit the *transient_detector.py* program so that if the transient is present
    in both input image pairs, OpenCV draws a line connecting the two transients.
    This will reveal the transient’s orbital path against the background stars.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: This kind of information was key to the discovery of Pluto. Clyde Tombaugh used
    the distance Pluto traveled in the two discovery plates, along with the time between
    exposures, to verify that the planet was near Lowell’s predicted path and not
    just some asteroid orbiting closer to Earth.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: You can find a solution, *practice_orbital_path.py*, in the appendix and in
    the *Chapter_5* folder.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: '**Practice Project: What’s the Difference?**'
  id: totrans-236
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The feature matching you did in this chapter has broad-reaching applications
    beyond astronomy. For example, marine biologists use similar techniques to identify
    whale sharks by their spots. This improves the accuracy of the scientists’ population
    counts.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: In [Figure 5-14](ch05.xhtml#ch05fig14), something has changed between the left
    and right photos. Can you spot it? Even better, can you write Python programs
    that align and compare the two images and circle the change?
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/fig05_14.jpg)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5-14: Spot the difference between the left and right images.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: The starting images can be found in the *montages* folder in the *Chapter_5*
    folder, downloadable from the book’s website. These are color images that you’ll
    need to convert to grayscale and align prior to object detection. You can find
    solutions, *practice_montage_aligner.py* and *practice_montage_difference_finder.py*,
    in the appendix and in the *montages* folder.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: '**Challenge Project: Counting Stars**'
  id: totrans-242
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: According to *Sky and Telescope* magazine, there are 9,096 stars visible to
    the naked eye from both hemispheres (*[https://www.skyandtelescope.com/astronomy-resources/how-many-stars-night-sky-09172014/](https://www.skyandtelescope.com/astronomy-resources/how-many-stars-night-sky-09172014/)*).
    That’s a lot on its own, but if you look through a telescope, the number increases
    exponentially.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: To estimate large numbers of stars, astronomers survey small regions of the
    sky, use a computer program to count the stars, and then extrapolate the results
    to larger areas. For this challenge project, pretend you’re an assistant at Lowell
    Observatory and you’re on a survey team. Write a Python program that counts the
    number of stars in the image *5_no_transient_left.png*, used in Projects 7 and
    8.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: For hints, search online for *how to count dots in an image with Python and
    OpenCV*. For a solution using Python and SciPy, see *[http://prancer.physics.louisville.edu/astrowiki/index.php/Image_processing_with_Python_and_SciPy](http://prancer.physics.louisville.edu/astrowiki/index.php/Image_processing_with_Python_and_SciPy)*.
    You may find your results improve if you divide the image into smaller parts.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL

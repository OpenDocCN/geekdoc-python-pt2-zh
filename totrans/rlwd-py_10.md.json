["```py\n1_capture.py, part 1\n   import os\n   import pyttsx3\n   import cv2 as cv\n   from playsound import playsound\n\n   engine = pyttsx3.init()\n➊ engine.setProperty('rate', 145)\n   engine.setProperty('volume', 1.0)\n\n   root_dir = os.path.abspath('.')\n   tone_path = os.path.join(root_dir, 'tone.wav')\n\n➋ path = \"C:/Python372/Lib/site-packages/cv2/data/\"\n   face_detector = cv.CascadeClassifier(path + \n                                        'haarcascade_frontalface_default.xml')\n   cap = cv.VideoCapture(0)\n   if not cap.isOpened(): \n       print(\"Could not open video device.\")\n➌ cap.set(3, 640)  # Frame width.\n   cap.set(4, 480)  # Frame height.\n\n   engine.say(\"Enter your information when prompted on screen. \\\n              Then remove glasses and look directly at webcam. \\\n              Make multiple faces including normal, happy, sad, sleepy. \\\n              Continue until you hear the tone.\")\n   engine.runAndWait()\n\n➍ name = input(\"\\nEnter last name: \")\n   user_id = input(\"Enter assigned ID Number: \")\n   print(\"\\nCapturing face. Look at the camera now!\")\n```", "```py\n1_capture.py, part 2\nif not os.path.isdir('trainer'):\n    os.mkdir('trainer')\nos.chdir('trainer')\n\nframe_count = 0\n\nwhile True:\n    # Capture frame-by-frame for total of 30 frames.\n    _, frame = cap.read()\n    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n ➊ face_rects = face_detector.detectMultiScale(gray, scaleFactor=1.2,\n                                                minNeighbors=5)     \n    for (x, y, w, h) in face_rects:\n        frame_count += 1\n        cv.imwrite(str(name) + '.' + str(user_id) + '.'\n                   + str(frame_count) + '.jpg', gray[y:y+h, x:x+w])\n        cv.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n        cv.imshow('image', frame)\n        cv.waitKey(400)\n ➋ if frame_count >= 30:\n        break\n\nprint(\"\\nImage collection complete. Exiting...\")\nplaysound(tone_path, block=False)\ncap.release()\ncv.destroyAllWindows()\n```", "```py\n2_train.py\n   import os\n   import numpy as np\n   import cv2 as cv\n\n   cascade_path = \"C:/Python372/Lib/site-packages/cv2/data/\"\n   face_detector = cv.CascadeClassifier(cascade_path +\n                                       'haarcascade_frontalface_default.xml')\n\n➊ train_path = './demming_trainer'  # Use for provided Demming face.   \n   #train_path = './trainer'  # Uncomment to use your face.\n   image_paths = [os.path.join(train_path, f) for f in os.listdir(train_path)]\n   images, labels = [], []\n\n   for image in image_paths:\n       train_image = cv.imread(image, cv.IMREAD_GRAYSCALE)\n    ➋ label = int(os.path.split(image)[-1].split('.')[1])\n       name = os.path.split(image)[-1].split('.')[0]\n       frame_num = os.path.split(image)[-1].split('.')[2]\n    ➌ faces = face_detector.detectMultiScale(train_image)\n       for (x, y, w, h) in faces:\n           images.append(train_image[y:y + h, x:x + w])\n           labels.append(label)\n           print(f\"Preparing training images for {name}.{label}.{frame_num}\")\n           cv.imshow(\"Training Image\", train_image[y:y + h, x:x + w])\n           cv.waitKey(50) \n\n   cv.destroyAllWindows()\n\n➍ recognizer = cv.face.LBPHFaceRecognizer_create()\n   recognizer.train(images, np.array(labels))\n   recognizer.write('lbph_trainer.yml')\n   print(\"Training complete. Exiting...\")\n```", "```py\n>>> import os\n>>> path = 'C:\\demming_trainer\\demming.1.5.jpg'\n>>> os.path.split(path)\n('C:\\\\demming_trainer', 'demming.1.5.jpg')\n```", "```py\n>>> os.path.split(path)[-1].split('.')\n['demming', '1', '5', 'jpg']\n```", "```py\n>>> os.path.split(path)[-1].split('.')[1]\n'1'\n```", "```py\n3_predict.py, part 1\n   import os\n   from datetime import datetime\n   import cv2 as cv\n\n   names = {1: \"Demming\"}\n   cascade_path = \"C:/Python372/Lib/site-packages/cv2/data/\"\n   face_detector = cv.CascadeClassifier(cascade_path +\n                                        'haarcascade_frontalface_default.xml')\n\n➊ recognizer = cv.face.LBPHFaceRecognizer_create()\n   recognizer.read('lbph_trainer.yml')\n\n   #test_path = './tester'\n➋ test_path = './demming_tester'\n   image_paths = [os.path.join(test_path, f) for f in os.listdir(test_path)]\n```", "```py\n3_predict.py, part 2\nfor image in image_paths:\n    predict_image = cv.imread(image, cv.IMREAD_GRAYSCALE)\n    faces = face_detector.detectMultiScale(predict_image,\n                                          scaleFactor=1.05,\n                                          minNeighbors=5)\n    for (x, y, w, h) in faces:\n        print(f\"\\nAccess requested at {datetime.now()}.\")\n ➊ face = cv.resize(predict_image[y:y + h, x:x + w], (100, 100))   \n    predicted_id, dist = recognizer.predict(face)\n ➋ if predicted_id == 1 and dist <= 95:\n        name = names[predicted_id]\n        print(\"{} identified as {} with distance={}\"\n              .format(image, name, round(dist, 1)))\n     ➌ print(f\"Access granted to {name} at {datetime.now()}.\",\n              file=open('lab_access_log.txt', 'a'))\n    else:\n        name = 'unknown'\n        print(f\"{image} is {name}.\")\n\n    cv.rectangle(predict_image, (x, y), (x + w, y + h), 255, 2)\n    cv.putText(predict_image, name, (x + 1, y + h - 5),\n               cv.FONT_HERSHEY_SIMPLEX, 0.5, 255, 1)        \n    cv.imshow('ID', predict_image)        \n    cv.waitKey(2000)\n    cv.destroyAllWindows()\n```", "```py\nAccess granted to Demming at 2020-01-20 09:31:17.415802.\nAccess granted to Demming at 2020-01-20 09:31:19.556307.\nAccess granted to Demming at 2020-01-20 09:31:21.644038.\nAccess granted to Demming at 2020-01-20 09:31:23.691760.\n--snip--\n```"]
- en: INTRODUCTION
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: '![Image](Images/common.jpg)'
  id: totrans-1
  prefs: []
  type: TYPE_IMG
  zh: '![Image](Images/common.jpg)'
- en: When I was in high school, I wanted to write a tic-tac-toe program that the
    user would play against a computer. At the time, I was blissfully unaware of how
    real computer scientists approached such a problem. I had only my own thoughts,
    and those were to implement a lot of rules using the crude if-then statements
    and gotos supported by unstructured Applesoft BASIC. It was a lot of rules—a few
    hundred lines’ worth.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 当我上高中时，我想编写一个井字游戏程序，让用户与计算机对战。当时，我对计算机科学家如何解决这种问题一无所知。我只有自己的想法，那就是利用未经结构化的Applesoft
    BASIC中支持的简单if-then语句和go to语句来实现大量规则。这是很多规则——大约几百行。
- en: In the end, the program worked well enough, until I found the sequence of moves
    that my rules didn’t cover and was able to win every time. I felt certain that
    there must be a way to teach a computer how to do things by showing it examples
    instead of brute-force code and rules—a way to make the computer learn on its
    own.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，程序的运行效果还不错，直到我发现了一个我的规则没有涵盖的走法，并能够每次都获胜。我确信，必定有一种方法可以通过展示示例来教计算机做事情，而不是靠暴力编写代码和规则——一种让计算机自主学习的方法。
- en: As an undergraduate student in the later 1980s, I was excited to sign up for
    a course in artificial intelligence. The course finally answered my question about
    how to write a tic-tac-toe playing program, but the computer wasn’t learning;
    it was still just using a clever algorithm. Incidentally, the same course assured
    us that while it was expected that someday a computer would beat the world’s best
    chess player, which happened in 1997, it was impossible for a computer to beat
    the best human at a game like Go. In March 2016, the AlphaGo deep learning program
    did just that.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 作为上世纪80年代后期的本科生，我很高兴能够报名参加一门人工智能课程。这门课程最终解答了我如何编写一个井字游戏程序的问题，但计算机并没有学习，它仍然只是在使用一个巧妙的算法。顺便提一下，同一门课程曾经向我们保证，虽然人们预计有一天计算机会战胜世界顶级的国际象棋棋手（这一点在1997年实现了），但计算机不可能在围棋这样的游戏中击败最强的人类棋手。然而，在2016年3月，AlphaGo深度学习程序做到了这一点。
- en: 'In 2003, while working as a consultant for a scientific computing company,
    I was assigned to a project with a major medical device manufacturer. The goal
    was to classify, in real time, intravascular ultrasound images of coronary arteries
    by using *machine learning*: a subfield of artificial intelligence that learns
    from data on its own, developing models that were not explicitly programmed by
    a human. This was what I was waiting for!'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 2003年，在为一家科学计算公司担任顾问时，我被分配到一个与一家大型医疗设备制造商合作的项目中。目标是使用*机器学习*：一种从数据中自主学习的人工智能子领域，实时分类冠状动脉的血管内超声图像，开发出不是由人类显式编程的模型。这正是我一直在等待的！
- en: I was vaguely aware of machine learning and that there were strange beasts called
    neural networks that could do some interesting things, but for the most part,
    machine learning was simply a small research area and not something the average
    computer science person paid much attention to. However, during the project, I
    fell in love with the idea of training a machine to do something useful without
    explicitly writing a lot of code. I kept learning on my own, even after the project
    ended.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我模糊地知道机器学习的存在，并且知道有一些叫做神经网络的奇怪生物能够做一些有趣的事情，但大多数时候，机器学习只是一个小范围的研究领域，并不是普通计算机科学工作者关注的重点。然而，在这个项目中，我爱上了通过训练机器来做一些有用的事情，而不是显式地编写大量代码的想法。即使项目结束后，我依然在自学。
- en: Circa 2010, I was involved with another machine learning project, and the timing
    was perfect. People were just beginning to discuss a new approach to machine learning
    called *deep learning*, which revived the old neural networks. When 2012 rolled
    around, the flood-gates opened. I was fortunate enough to be in the room at the
    ICML 2012 conference in Edinburgh, Scotland when Google presented its initial
    breakthrough deep learning results that responded to cats in YouTube videos. The
    room was crowded. After all, there were a whopping 800 people at the conference.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 大约在2010年，我参与了另一个机器学习项目，时机恰到好处。人们刚开始讨论一种叫做*深度学习*的机器学习新方法，它复兴了旧的神经网络。到了2012年，局面一发不可收拾。我很幸运能够出席2012年在苏格兰爱丁堡举办的ICML会议，并在现场亲眼见证了Google展示其初步突破性深度学习成果，该成果能够识别YouTube视频中的猫。会场人满为患。毕竟，当时会议有多达800人参加。
- en: 'It’s now 2020, and the machine learning conference I recently went to had over
    13,000 attendees. Machine learning has exploded: it’s not a fad that will disappear.
    Machine learning has profoundly affected our lives and will continue to do so.
    It would be nice to know something about it, to get past the oftentimes hyped-up
    presentations down to the essential core, which is interesting enough, no hype
    needed. That is why this book exists, to help you learn the essentials of machine
    learning. Specifically, we’ll be focusing on the approach known as deep learning.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是2020年，我最近参加的机器学习会议有超过13,000名与会者。机器学习已经爆炸式发展：它不是一个会消失的潮流。机器学习已经深刻影响了我们的生活，并将继续影响。了解一些机器学习知识会很有益，能够从那些经常被夸大的展示中走出来，去接触到实质性的核心内容，这本身就足够有趣，不需要任何炒作。这也是本书存在的原因，帮助你学习机器学习的基本要领。具体来说，我们将重点关注被称为深度学习的方法。
- en: Who Is This Book For?
  id: totrans-9
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本书适合谁阅读？
- en: I wrote this book for readers who have no background in machine learning, but
    who are curious and willing to experiment with things. I’ve kept the math to a
    minimum. My goal is to help you understand core concepts and build intuition you
    can use going forward.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我写这本书是为那些没有机器学习背景，但对机器学习充满好奇并愿意尝试的人准备的。我尽量将数学内容保持在最低限度。我的目标是帮助你理解核心概念，并建立可以在未来使用的直觉。
- en: At the same time, I didn’t want to write a book that simply instructed you on
    *how* to use existing toolkits but was devoid of any real substance as to the
    *why* of things. It’s true that if all you care about is the *how*, you can build
    useful models. But without the *why*, you’ll only be parroting, not understanding,
    let alone eventually moving the field forward with your own contributions.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，我不想写一本仅仅教你*如何*使用现有工具包的书，而是要让你理解背后的*为什么*。确实，如果你只关心*如何*，你可以构建有用的模型。但没有*为什么*，你只是在模仿，而不是理解，更不要说最终用自己的贡献推动领域的发展。
- en: As far as assumptions on my part, I assume you have some familiarity with computer
    programming, in any language. The language of choice for machine learning, whether
    you are a student or a major corporation, is Python, so that’s the language we’ll
    use. I’ll also assume you’re familiar with high school math but not calculus.
    A little calculus will creep in anyway, but you should be able to follow the ideas,
    even if the technique is unfamiliar. I’ll also assume you know a bit of statistics
    and basic probability. If you’ve forgotten those topics since high school, don’t
    worry—you’ll find relevant sections in [Chapter 1](ch01.xhtml#ch01) that give
    you enough of a background to follow the narrative.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 就我个人的假设而言，我假设你对计算机编程有所了解，无论是哪种语言。机器学习的首选语言，无论你是学生还是大公司，都是Python，所以我们将使用这种语言。我还假设你熟悉高中数学，但不一定会微积分。虽然有一点微积分的内容会出现，但即使这些技巧对你来说不熟悉，你也应该能够理解这些思想。我还假设你知道一些统计学和基础概率学。如果你从高中以来忘记了这些知识，不用担心——你会在[第1章](ch01.xhtml#ch01)中找到相关内容，帮助你提供足够的背景，跟上叙述。
- en: What Can You Expect to Learn?
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你可以期待学到什么？
- en: 'If you work through this book in its entirety, you can expect to learn about
    the following:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你完整地学习这本书，你可以期待学到以下内容：
- en: How to build a good training dataset. This is a dataset that will let your model
    be successful when used “in the wild.”
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何构建一个良好的训练数据集。这个数据集将使你的模型在实际应用中取得成功。
- en: 'How to work with two of the leading machine learning toolkits: scikit-learn
    and Keras.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用两个领先的机器学习工具包：scikit-learn 和 Keras。
- en: How to evaluate the performance of a model once you’ve trained and tested it.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何评估训练并测试后的模型性能。
- en: How to use several classical machine learning models like *k*-Nearest Neighbors,
    Random Forests, or Support Vector Machines.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用几种经典的机器学习模型，如 *k*-最近邻、随机森林或支持向量机。
- en: How neural networks work and are trained.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经网络如何工作并进行训练。
- en: How to develop models using convolutional neural networks.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用卷积神经网络开发模型。
- en: How to start with a given set of data and develop a successful model from scratch.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何从一组给定的数据开始，并从零开发出一个成功的模型。
- en: About This Book
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本书简介
- en: This book is about machine learning. Machine learning is about building models
    that take input data and arrive at some conclusion from that data. That conclusion
    might be a label placing the object into a particular class of objects, like a
    certain kind of dog, or a continuous output value, say the price one should ask
    for a house with the given set of amenities. The key here is that the model learns
    from the data on its own. In effect, the model learns by example.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 本书是关于机器学习的。机器学习是通过构建模型来处理输入数据，并从数据中得出某些结论。这个结论可能是将对象归类到特定类别的标签，比如某种类型的狗，或者是一个连续的输出值，比如根据给定的设施条件，为一栋房子定价。关键在于，模型能够从数据中自主学习。实际上，模型通过示例学习。
- en: You can think of the model as a mathematical function, *y* = *f* (*x*), where
    *y* is the output, the class label, or the continuous value, and *x* is the set
    of *features* representing the unknown input. Features are measurements or information
    about the input that the model can use to learn what output to generate. For example,
    *x* might be a vector representing the length, width, and weight of a fish, where
    each of those measurements is a feature. Our goal is to find *f*, a mapping between
    *x* and *y* that we’ll be able to use on new instances of *x*, for which we do
    not know *y*.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将模型看作是一个数学函数，*y* = *f* (*x*)，其中 *y* 是输出，类别标签或连续值，*x* 是代表未知输入的 *特征* 集合。特征是关于输入的测量或信息，模型可以利用这些特征来学习生成什么样的输出。例如，*x*
    可能是一个向量，表示一条鱼的长度、宽度和重量，每个测量值都是一个特征。我们的目标是找到 *f*，即一个 *x* 和 *y* 之间的映射，我们可以在新的 *x*
    实例上使用这个映射，而我们并不知道 *y*。
- en: 'The standard way to learn *f* is to give our model (or algorithm) known data,
    and have the model learn the parameters it needs to make *f* a useful mapping.
    This is why it’s called *machine learning*: the machine is learning the parameters
    of the model. We’re not thinking of the rules ourselves and cementing them in
    code. Indeed, for some model types like neural networks, it’s not even clear *what*
    the model has learned, only that the model is now performing at a useful level.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 学习 *f* 的标准方式是给我们的模型（或算法）提供已知数据，并让模型学习它所需的参数，以使 *f* 成为一个有用的映射。这就是为什么它被称为*机器学习*：机器正在学习模型的参数。我们不是自己思考规则并将其固化在代码中。实际上，对于一些模型类型，如神经网络，甚至不清楚模型学到了*什么*，只知道模型现在的表现达到了一个有用的水平。
- en: 'There are three main branches to machine learning: *supervised learning*, *unsupervised
    learning*, and *reinforcement learning*. The process we just described falls under
    supervised learning. We supervised the training of the model with a set of known
    *x* and *y* values, the *training set*. We call a dataset like this a *labeled*
    dataset because we know the *y* that goes with each *x*. Unsupervised learning
    attempts to learn the parameters used by the model using only *x*. We won’t discuss
    unsupervised learning here, but you can transfer a lot of our discussion of supervised
    learning if you want to explore that area on your own later.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习有三个主要分支：*监督学习*、*无监督学习*和*强化学习*。我们刚才描述的过程属于监督学习。我们通过一组已知的 *x* 和 *y* 值来监督模型的训练，这就是*训练集*。我们将这样的数据集称为*标注数据集*，因为我们知道每个
    *x* 对应的 *y*。无监督学习试图仅使用 *x* 来学习模型所需的参数。我们在这里不会讨论无监督学习，但如果你想自己以后探索该领域，可以参考我们对监督学习的讨论。
- en: Reinforcement learning trains models to perform tasks, like playing chess or
    Go. The model learns a set of actions to take given the current state of its world.
    This is an important area of machine learning, and it has recently achieved a
    high level of success on tasks previously thought to be solely the domain of humans.
    Sadly, compromises had to be made to make this book manageable, so we’ll ignore
    reinforcement learning altogether.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习训练模型执行任务，比如下棋或围棋。模型根据当前世界的状态学习一组动作。这是机器学习中的一个重要领域，最近它在一些曾被认为是人类专属的任务上取得了显著的成功。遗憾的是，为了使本书内容可管理，我们将完全忽略强化学习。
- en: 'One quick note on terminology. In the media, a lot of what we’re talking about
    in this book is referred to as *artificial intelligence*, or *AI*. While this
    is not wrong, it’s somewhat misleading: machine learning is one subfield of the
    broader field of artificial intelligence. Another term you’ll often hear is *deep
    learning*. This term is a bit nebulous, but for our purposes, we’ll use it to
    mean machine learning with neural networks, in particular, neural networks with
    many layers (hence *deep*). [Figure 1](introduction.xhtml#introfig1) shows the
    relationship between these terms.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 关于术语的一个简短说明。在媒体中，我们书中讨论的许多内容被称为*人工智能*或*AI*。虽然这并不错误，但它有些误导：机器学习是人工智能这一更广泛领域的一个子领域。另一个你经常听到的术语是*深度学习*。这个术语有些模糊，但在我们的讨论中，我们将它用来指代具有神经网络的机器学习，特别是具有多层的神经网络（因此称为*深度*）。[图1](introduction.xhtml#introfig1)展示了这些术语之间的关系。
- en: '![image](Images/00fig01.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/00fig01.jpg)'
- en: '*Figure 1: The relationship between artificial intelligence, machine learning,
    and deep learning*'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '*图1：人工智能、机器学习和深度学习之间的关系*'
- en: Of course, within the fields of machine learning and deep learning, there’s
    considerable variety. We’ll encounter a number of models throughout this book.
    We could arrange them in what we’ll call “the tree of machine learning,” pictured
    in [Figure 2](introduction.xhtml#introfig2).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，在机器学习和深度学习领域中，有相当多的变种。我们将在本书中遇到许多模型。我们可以将它们安排在我们所称的“机器学习树”中，如[图2](introduction.xhtml#introfig2)所示。
- en: '![image](Images/00fig02.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/00fig02.jpg)'
- en: '*Figure 2: The tree of machine learning*'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '*图2：机器学习树*'
- en: 'The tree shows the growth from traditional machine learning at the root to
    modern deep learning at the top of the tree. Consider this a preview of what’s
    to come: we’ll look at each of these models in this book.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这棵树展示了从传统机器学习到现代深度学习的成长过程，根基是传统机器学习，顶端是现代深度学习。可以把它看作是对未来内容的预览：我们将在本书中讨论这些模型。
- en: Along those same lines, we’ll end this introduction with a quick synopsis of
    each chapter.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 基于这个思路，我们将以每章的快速概述结束本引言部分。
- en: '**[Chapter 1: Getting Started](ch01.xhtml#ch01)** This chapter tells you how
    to set up our assumed working environment. It also includes sections about vectors,
    matrices, probability, and statistics that you can use as refreshers or for background.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第1章：入门](ch01.xhtml#ch01)** 本章告诉你如何设置我们假定的工作环境。它还包括关于向量、矩阵、概率和统计的内容，你可以用来复习或作为背景知识。'
- en: '**[Chapter 2: Using Python](ch02.xhtml#ch02)** This chapter will get you started
    on Python.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第2章：使用Python](ch02.xhtml#ch02)** 本章将帮助你入门Python。'
- en: '**[Chapter 3: Using NumPy](ch03.xhtml#ch03)** NumPy is an extension to Python.
    It’s what makes Python useful for machine learning. If you are not familiar with
    it, peruse this chapter.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第3章：使用NumPy](ch03.xhtml#ch03)** NumPy是Python的一个扩展，它使得Python在机器学习中变得非常有用。如果你不熟悉它，可以浏览一下本章内容。'
- en: '**[Chapter 4: Working with Data](ch04.xhtml#ch04)** Bad datasets lead to bad
    models; we’ll teach you what makes a good one.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第4章：数据处理](ch04.xhtml#ch04)** 不良的数据集会导致糟糕的模型；我们将教你如何区分好的数据集。'
- en: '**[Chapter 5: Building Datasets](ch05.xhtml#ch05)** We’ll build the datasets
    used throughout the book. You’ll also learn how to augment datasets.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第5章：构建数据集](ch05.xhtml#ch05)** 我们将构建本书中使用的所有数据集。你还将学习如何增强数据集。'
- en: '**[Chapter 6: Classical Machine Learning](ch06.xhtml#ch06)** To understand
    where you are going, sometimes it’s good to know where you came from. Here we’ll
    cover some of the original machine learning models.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第6章：经典机器学习](ch06.xhtml#ch06)** 要理解你要去的地方，有时了解你来自哪里会有所帮助。这里我们将介绍一些原始的机器学习模型。'
- en: '**[Chapter 7: Experiments with Classical Models](ch07.xhtml#ch07)** This chapter
    shows the strengths and weaknesses of the old-school approach to machine learning.
    We’ll refer to these results for comparison purposes throughout the book.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第7章：经典模型实验](ch07.xhtml#ch07)** 本章展示了老派机器学习方法的优缺点。我们将在全书中将这些结果用于比较目的。'
- en: '**[Chapter 8: Introduction to Neural Networks](ch08.xhtml#ch08)** Modern deep
    learning is all about neural networks; we’ll introduce them here.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第8章：神经网络简介](ch08.xhtml#ch08)** 现代深度学习完全围绕神经网络展开；我们将在这里介绍它们。'
- en: '**[Chapter 9: Training a Neural Network](ch09.xhtml#ch09)** This challenging
    chapter gives you the knowledge you need to understand how neural networks are
    trained. Some basic calculus slipped into this chapter, but don’t panic—it’s discussed
    at a high level to give you intuition, and the notation isn’t as frightening as
    it might seem at first.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第9章：神经网络训练](ch09.xhtml#ch09)** 本章内容具有挑战性，提供了理解神经网络如何训练所需的知识。一些基础的微积分知识被引入到本章，但别慌——这些内容以高层次的方式讨论，旨在帮助你获得直觉，而且符号表示并不像看起来那么可怕。'
- en: '**[Chapter 10: Experiments with Neural Networks](ch10.xhtml#ch10)** Here we
    run experiments to build intuition and get a feel for actually working with data.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第10章：神经网络实验](ch10.xhtml#ch10)** 在本章中，我们将进行实验，以建立直觉并感受如何实际操作数据。'
- en: '**[Chapter 11: Evaluating Models](ch11.xhtml#ch11)** To understand the results
    presented in machine learning papers, talks, and lectures, we need to understand
    how to evaluate models. This chapter will take you through the process.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第11章：评估模型](ch11.xhtml#ch11)** 要理解机器学习论文、演讲和讲座中呈现的结果，我们需要了解如何评估模型。本章将引导你完成这一过程。'
- en: '**[Chapter 12: Introduction to Convolutional Neural Networks](ch12.xhtml#ch12)**
    The deep learning we will focus on in this book is embodied in the idea of a convolutional
    neural network, or CNN. This chapter discusses the basic building blocks of these
    networks.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第12章：卷积神经网络简介](ch12.xhtml#ch12)** 本书中我们将重点讨论的深度学习体现在卷积神经网络（CNN）的理念中。本章将讨论这些网络的基本构建模块。'
- en: '**[Chapter 13: Experiments with Keras and MNIST](ch13.xhtml#ch13)** Here we’ll
    explore how CNNs work by experimenting with the MNIST dataset, the workhorse of
    deep learning.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第13章：使用Keras和MNIST的实验](ch13.xhtml#ch13)** 在这里，我们将通过使用MNIST数据集来探索CNN的工作原理，MNIST是深度学习中的常用数据集。'
- en: '**[Chapter 14: Experiments with CIFAR-10](ch14.xhtml#ch14)** The MNIST dataset,
    useful as it is, is a simple one for CNNs to master. Here we explore another workhorse
    dataset, CIFAR-10, which consists of actual images and will challenge our models.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第14章：使用CIFAR-10的实验](ch14.xhtml#ch14)** 尽管MNIST数据集对CNN来说是一个简单的任务，但在这里我们将探索另一个常用数据集CIFAR-10，它包含真实图像，将挑战我们的模型。'
- en: '**[Chapter 15: A Case Study: Classifying Audio Samples](ch15.xhtml#ch15)**
    We’ll conclude with a case study. We start with a new dataset, one not in widespread
    use, and work through the process of building a good model for it. This chapter
    uses everything we studied in the book, from building and augmenting data to classical
    models, traditional neural networks, CNNs, and ensembles of models.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第15章：案例研究：音频样本分类](ch15.xhtml#ch15)** 本章以一个案例研究作为结尾。我们从一个新的数据集开始，这个数据集并不广泛使用，然后一步步建立一个合适的模型。本章涵盖了本书中的所有学习内容，从数据构建和增强，到经典模型、传统神经网络、CNN和模型集成。'
- en: '**[Chapter 16: Going Further](ch16.xhtml#ch16)** No book is complete. This
    one won’t even try to be. This chapter points out some of what we’ve neglected
    and helps you sift through the mountains of resources around you related to machine
    learning so you can focus on what you should study next.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第16章：深入探讨](ch16.xhtml#ch16)** 没有一本书能做到面面俱到，本书也不会尝试做到这一点。本章指出了我们忽略的一些内容，并帮助你筛选周围关于机器学习的大量资源，帮助你集中精力学习下一步该学的内容。'
- en: 'All the code in the book, organized by chapter, can be found here: *[https://nostarch.com/practical-deep-learning-python/](https://nostarch.com/practical-deep-learning-python/)*.
    Let’s now take a look at setting up our operating environment.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的所有代码，按章节整理，可以在这里找到：*[https://nostarch.com/practical-deep-learning-python/](https://nostarch.com/practical-deep-learning-python/)*。接下来，让我们看看如何设置我们的操作环境。

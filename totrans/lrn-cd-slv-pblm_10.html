<html><head></head><body><div id="sbo-rt-content"><h2 class="h2" id="ch10"><span epub:type="pagebreak" id="page_265"/><span class="big">10</span><br/>BIG O AND PROGRAM EFFICIENCY</h2>&#13;&#13;
<div class="imagec"><img src="Images/common.jpg" alt="image" width="150" height="150"/></div>&#13;&#13;
<p class="noindents">In the first seven chapters of this book, we focused on writing programs that were correct: for any valid input, we wanted our program to produce the desired output. In addition to correct code, though, we generally want efficient code, code that runs quickly even in the face of huge amounts of input. You may have received the occasional time limit exceeded error when working through the first seven chapters, but our first formal foray into program efficiency wasn’t until <a href="ch08.xhtml#ch08">Chapter 8</a>, when we solved Email Addresses. We saw there that sometimes we need to make our programs more efficient so that they can finish within a given time limit.</p>&#13;&#13;
<p class="indent">In this chapter, we’ll first learn how programmers think and communicate about program efficiency. Then, we’ll study two problems where we’ll need to write efficient code: determining the most desired piece of a scarf and painting a ribbon.</p>&#13;&#13;
<p class="indent">For each problem, we’ll see that our initial ideas lead to an algorithm that would not be efficient enough. But we’ll keep at it until we design a <span epub:type="pagebreak" id="page_266"/>faster algorithm for the same problem, one that’s dramatically more efficient than before. This exemplifies a common workflow for programmers: first, come up with a correct algorithm; then, only if needed, make it faster.</p>&#13;&#13;
<h3 class="h3" id="ch10lev1sec1">The Problem with Timing</h3>&#13;&#13;
<p class="noindent">Each competitive programming problem that we solve in this book has a time limit on how long our program will be allowed to run. (I began including time limits in the problem descriptions of <a href="ch08.xhtml#ch08">Chapter 8</a>, when we started running into programming problems where efficiency is a serious concern.) If our program exceeds the time limit, then the judge terminates our program with a time limit exceeded error. A time limit is designed to prevent solutions that are too slow from passing the test cases. For example, perhaps we come up with a complete-search solution but the author of the problem has worked out a solution that’s much faster. That faster solution may be a variation of complete search, as it was when we solved the Cow Baseball problem in <a href="ch09.xhtml#ch09">Chapter 9</a>, or it may be a different approach entirely. Regardless, the time limit may be set such that our complete-search solution will not finish in time. As such, in addition to being correct, we may need our programs to be fast.</p>&#13;&#13;
<p class="indent">We can run a program to explore whether it is efficient enough. For example, think back to “Efficiency of Searching a List” in <a href="ch08.xhtml#ch08">Chapter 8</a> when we tried to solve Email Addresses using a list. We ran code that used bigger and bigger lists to get a sense of the amount of time taken by list operations. This kind of testing can give us some understanding of the efficiency of our programs. If our program is too slow, according to the time limit for the problem, then we know that we need to optimize the current code or find a wholly new approach.</p>&#13;&#13;
<p class="indent">The amount of time taken by a program depends on the computer it is being run on. We don’t know what kind of computer the judge is using, but running the program on our own computer is still informative because the judge is probably using a computer that’s at least as fast as ours. Say that we run our program on our laptop and it takes 30 seconds on some small test case. If the problem time limit is three seconds, we can be confident that our program is simply not fast enough.</p>&#13;&#13;
<p class="indent">An exclusive focus on time limits, however, is limiting. Think about our first solution to Cow Baseball in <a href="ch09.xhtml#ch09">Chapter 9</a>. We didn’t need to run that code to determine how slow it would be. That’s because we were able to characterize the program in terms of the amount of work that it would do if we did run it. For example, in “Efficiency of Our Program” on <a href="ch09.xhtml#ch09lev2sec16">page 253</a>, we said that for <em>n</em> cows, our program processes <em>n</em><sup>3</sup> triples of cows. Notice that our focus here is not on the number of seconds our program would take to run, but on how much work it does in terms of the amount of input <em>n</em>.</p>&#13;&#13;
<p class="indentb">There are significant advantages to this kind of analysis compared to running our programs and recording execution times. Here are five:</p>&#13;&#13;
<p class="uln-indent"><strong>Execution time depends on the computer</strong> Timing our program tells us only how long our program takes on one computer. That’s very <span epub:type="pagebreak" id="page_267"/>specific information, and it gives us little in the way of understanding what to expect when the program is run on other computers. When working through the book, you may have also noticed that the time taken by a program varies from run to run, even on the same computer. For example, you might run a program on a test case and find that it takes three seconds; you might then run it again, on the same test case, and find that it takes two-and-a-half seconds or three-and-a-half seconds. The reason for this difference is that your operating system is managing your computing resources, shunting them around to different tasks as needed. The decisions that your operating system makes influence the runtime of your program.</p>&#13;&#13;
<p class="uln-indent"><strong>Execution time depends on the test case</strong> Timing our program on a test case tells us only how long our program takes on that test case. Suppose that our program takes three seconds to run on a small test case. That may seem fast, but here’s the truth about small test cases: every reasonable solution for a problem will quickly be able to solve those. If I ask you to tell me the number of unique email addresses among 10 email addresses, or the number of triples of cows among 10 cows, you can quickly do it with the first correct idea that you have. What’s interesting, then, are large test cases. They are the ones where algorithmic ingenuity pays off. How long will our program take on a large test case or on a huge test case? We don’t know. We’d have to run our program on those test cases, too. Even if we did that, there could be specific kinds of test cases that trigger poorer performance. We may be led to believe that our program is faster than it is.</p>&#13;&#13;
<p class="uln-indent"><strong>The program requires implementation</strong> We can’t time something that we don’t implement. Suppose that we’re thinking about a problem and come up with an idea for how to solve it. Is it fast? Although we could implement it to find out, it would be nice to know, in advance, whether or not the idea is likely to lead to a fast program. You would not implement a program that you knew, at the outset, would be incorrect. It would similarly be nice to know, at the outset, that a program would be too slow.</p>&#13;&#13;
<p class="uln-indent"><strong>Timing doesn’t explain slowness</strong> If we find that our program is too slow, then our next task is to design a faster one. However, simply timing a program gives us no insight into why our program is slow. It just is. Further, if we manage to think up a possible improvement to our program, we’d need to implement it to see whether or not it helps.</p>&#13;&#13;
<p class="uln-indent"><strong>Execution time is not easily communicated</strong> For many of the reasons listed, it’s difficult to use execution time to talk to other people about the efficiency of algorithms. Execution time is too specific: it depends on the computer, operating system, test case, programming language, and particular implementation that’s used. We’d have to provide all of this information to others interested in the efficiency of our algorithm.</p>&#13;&#13;
<p class="indenta">Not to worry: computer scientists have devised a notation that addresses these shortcomings of timing. It’s independent of the computer, independent <span epub:type="pagebreak" id="page_268"/>of test case, and independent of a particular implementation. It signals why a slow program is slow. It’s easily communicated. It’s called <em>big O</em>, and it’s coming right up.</p>&#13;&#13;
<h3 class="h3" id="ch10lev1sec2">Big O</h3>&#13;&#13;
<p class="noindent">Big O is a notation that computer scientists use to concisely describe the efficiency of algorithms. The key concept here is the <em>efficiency class</em>, which tells you how fast an algorithm is or, equivalently, how much work it does. The faster an algorithm, the less work it does; the slower an algorithm, the more work it does. Each algorithm belongs to an efficiency class; the efficiency class tells you how much work that algorithm does relative to the amount of input that it must process. To understand big O, we need to understand these efficiency classes. We’re now going to study seven of the most common ones. We’ll see those that do the least amount of work, the ones you’ll hope your algorithms fit into. We’ll also see those that do considerably more work, the ones whose algorithms will probably give you time limit exceeded errors.</p>&#13;&#13;
<h4 class="h4" id="ch10lev2sec1">Constant Time</h4>&#13;&#13;
<p class="noindent">The most desirable algorithms are those that don’t do more work as the amount of input increases. No matter the problem instance, such an algorithm takes about the same number of steps. These are called <em>constant-time</em> algorithms.</p>&#13;&#13;
<p class="indent">This is hard to believe, right? An algorithm that does about the same amount of work, no matter what? Indeed, solving a problem with such an algorithm is rare. But when you can do it, rejoice: you can’t do any better than that.</p>&#13;&#13;
<p class="indent">We’ve managed to solve a few problems in this book using constant-time algorithms. Think back to the Telemarketers problem in <a href="ch02.xhtml#ch02">Chapter 2</a>, where we had to determine whether the provided phone number belongs to a telemarketer. I’ve reproduced our solution from <a href="ch02.xhtml#ch02ex02">Listing 2-2</a> here:</p>&#13;&#13;
<p class="programs">num1 = int(input())<br/>&#13;&#13;
num2 = int(input())<br/>&#13;&#13;
num3 = int(input())<br/>&#13;&#13;
num4 = int(input())<br/>&#13;&#13;
<br/>&#13;&#13;
if ((num1 == 8 or num1 == 9) and<br/>&#13;&#13;
        (num4 == 8 or num4 == 9) and<br/>&#13;&#13;
        (num2 == num3)):<br/>&#13;&#13;
    print('ignore')<br/>&#13;&#13;
else:<br/>&#13;&#13;
    print('answer')</p>&#13;&#13;
<p class="indent">Our solution does the same amount of work no matter what the four digits of the phone number are. The code starts by reading the input. Then <span epub:type="pagebreak" id="page_269"/>it makes some comparisons with <span class="literal">num1</span>, <span class="literal">num2</span>, <span class="literal">num3</span>, and <span class="literal">num4</span>. If the phone number belongs to a telemarketer, we output something; if it doesn’t belong to a telemarketer, we output something else. There’s no input that can make our program do more work than this.</p>&#13;&#13;
<p class="indent">Earlier in <a href="ch02.xhtml#ch02">Chapter 2</a>, we solved Winning Team. Did we solve that one in constant time, too? We did! Here’s the solution from <a href="ch02.xhtml#ch02ex01">Listing 2-1</a>:</p>&#13;&#13;
<p class="programs">apple_three = int(input())<br/>&#13;&#13;
apple_two = int(input())<br/>&#13;&#13;
apple_one = int(input())<br/>&#13;&#13;
<br/>&#13;&#13;
banana_three = int(input())<br/>&#13;&#13;
banana_two = int(input())<br/>&#13;&#13;
banana_one = int(input())<br/>&#13;&#13;
<br/>&#13;&#13;
apple_total = apple_three * 3 + apple_two * 2 + apple_one<br/>&#13;&#13;
banana_total = banana_three * 3 + banana_two * 2 + banana_one<br/>&#13;&#13;
<br/>&#13;&#13;
if apple_total &gt; banana_total:<br/>&#13;&#13;
    print('A')<br/>&#13;&#13;
elif banana_total &gt; apple_total:<br/>&#13;&#13;
    print('B')<br/>&#13;&#13;
else:<br/>&#13;&#13;
    print('T')</p>&#13;&#13;
<p class="indent">We read the input, compute the total points for the Apples, compute the total points for the Bananas, compare those totals, and output a message. It doesn’t matter how many points the Apples or Bananas have—our program always does the same amount of work.</p>&#13;&#13;
<p class="indent">Hold on—what if the Apples scored zillions and zillions of three-point shots? Surely, it takes longer for the computer to work with ginormous numbers than small numbers like 10 or 50? While that’s true, we don’t have to worry about that here. The problem description states that each team scores at most 100 of each type of play. We’re therefore working with small numbers, and it’s fair to say that the computer can read or operate on these numbers in a constant number of steps. In general, you can think of numbers up to a few billion as “small.”</p>&#13;&#13;
<p class="indent">In big O notation, we say that a constant-time algorithm is <em>O</em>(1). The 1 doesn’t mean that you’re stuck performing only one step in a constant-time algorithm. If you perform a fixed number of steps, like 10 or even 10,000, it’s still constant time. But don’t write <em>O</em>(10) or <em>O</em>(10000)—all constant-time algorithms are denoted <em>O</em>(1).</p>&#13;&#13;
<h4 class="h4" id="ch10lev2sec2">Linear Time</h4>&#13;&#13;
<p class="noindent">Most algorithms are not constant-time algorithms. Instead, they do an amount of work that depends on the amount of input. For example, they do more work to process 1,000 values than they do to process 10 values. What <span epub:type="pagebreak" id="page_270"/>distinguishes these algorithms from each other is the relationship between the amount of input and the amount of work that the algorithm does.</p>&#13;&#13;
<p class="indent">A <em>linear-time</em> algorithm is one with a linear relationship between the amount of input and the amount of work done. Suppose we run a linear-time algorithm on an input with 50 values, and then we run it again on an input with 100 values. The algorithm will do about twice as much work on the 100 values compared with on the 50 values.</p>&#13;&#13;
<p class="indent">For an example, let’s look at the Three Cups problem from <a href="ch03.xhtml#ch03">Chapter 3</a>. We solved that problem in <a href="ch03.xhtml#ch03ex01">Listing 3-1</a>, and I’ve reproduced our solution here:</p>&#13;&#13;
<p class="programs">   swaps = input()<br/>&#13;&#13;
<br/>&#13;&#13;
   ball_location = 1<br/>&#13;&#13;
<br/>&#13;&#13;
<span class="ent">❶</span> for swap_type in swaps:<br/>&#13;&#13;
       if swap_type == 'A' and ball_location == 1:<br/>&#13;&#13;
           ball_location = 2<br/>&#13;&#13;
       elif swap_type == 'A' and ball_location == 2:<br/>&#13;&#13;
           ball_location = 1<br/>&#13;&#13;
       elif swap_type == 'B' and ball_location == 2:<br/>&#13;&#13;
           ball_location = 3<br/>&#13;&#13;
       elif swap_type == 'B' and ball_location == 3:<br/>&#13;&#13;
           ball_location = 2<br/>&#13;&#13;
       elif swap_type == 'C' and ball_location == 1:<br/>&#13;&#13;
           ball_location = 3<br/>&#13;&#13;
       elif swap_type == 'C' and ball_location == 3:<br/>&#13;&#13;
           ball_location = 1<br/>&#13;&#13;
<br/>&#13;&#13;
   print(ball_location)</p>&#13;&#13;
<p class="indent">There’s a <span class="literal">for</span> loop <span class="ent">❶</span>, and the amount of work that it does depends linearly on the amount of input. If there are five swaps to process, then the loop iterates five times. If there are 10 swaps to process, then the loop iterates 10 times. Each iteration of the loop performs a constant number of comparisons and may change what <span class="literal">ball_location</span> refers to. Therefore, the amount of work that this algorithm does is directly proportional to the number of swaps.</p>&#13;&#13;
<p class="indent">We typically use <em>n</em> to refer to the amount of input provided to a problem. Here, <em>n</em> is the number of swaps. If there are 5 swaps that we need to perform, then <em>n</em> is 5; if there are 10 swaps that we need to perform, then <em>n</em> is 10.</p>&#13;&#13;
<p class="indent">If there are <em>n</em> swaps, then our program does about <em>n</em> work. That’s because the <span class="literal">for</span> loop performs <em>n</em> iterations, each of which performs a constant number of steps. We don’t care how many steps it performs on each iteration, as long as it’s a constant number. Whether the algorithm performs a total of <em>n</em> steps or 10<em>n</em> steps or 10,000<em>n</em> steps, it’s a linear-time algorithm. In big O notation, we say that this algorithm is <em>O</em>(<em>n</em>).</p>&#13;&#13;
<p class="indent"><span epub:type="pagebreak" id="page_271"/>When using big O notation, we don’t include numbers in front of <em>n</em>. For example, an algorithm that takes 10<em>n</em> steps is written <em>O</em>(<em>n</em>), not <em>O</em>(10<em>n</em>). This helps us focus on the fact that the algorithm is linear time and away from the specifics of the linear relationship.</p>&#13;&#13;
<p class="indent">What if an algorithm takes 2<em>n</em> + 8 steps—what kind of algorithm is this? This is still linear time! The reason is that the linear term (2<em>n</em>) will come to dominate the constant term (8) as soon as <em>n</em> is big enough. For example, if <em>n</em> is 5,000, then 8<em>n</em> is 40,000. The number 8 is so small compared to 40,000 that we may as well ignore it. In big O notation, we ignore everything except the dominant terms.</p>&#13;&#13;
<p class="indent">Many Python operations take constant time to do their work. For example, appending to a list, adding to a dictionary, or indexing a sequence or dictionary all take constant time.</p>&#13;&#13;
<p class="indent">But some Python operations take linear time to do their work. Be careful to count them as linear time and not constant time. For example, using the Python <span class="literal">input</span> function to read a long string takes linear time, because Python has to read each character on the line of input. Any operation that examines each character of a string or value in a list takes linear time as well.</p>&#13;&#13;
<p class="indent">If an algorithm reads <em>n</em> values and processes each value in a constant number of steps, then it is a linear-time algorithm.</p>&#13;&#13;
<p class="indent">We don’t need to go far to see another linear-time algorithm—our solution to Occupied Spaces in <a href="ch03.xhtml#ch03">Chapter 3</a> is another such example. I’ve reproduced our solution from <a href="ch03.xhtml#ch03ex03">Listing 3-3</a> here:</p>&#13;&#13;
<p class="programs">n = int(input())<br/>&#13;&#13;
yesterday = input()<br/>&#13;&#13;
today = input()<br/>&#13;&#13;
<br/>&#13;&#13;
occupied = 0<br/>&#13;&#13;
<br/>&#13;&#13;
for i in range(len(yesterday)):<br/>&#13;&#13;
    if yesterday[i] == 'C' and today[i] == 'C':<br/>&#13;&#13;
        occupied = occupied + 1<br/>&#13;&#13;
<br/>&#13;&#13;
print(occupied)</p>&#13;&#13;
<p class="indent">We let <em>n</em> be the number of parking spaces. The pattern is the same as for Three Cups: we read the input and then perform a constant number of steps for each parking space.</p>&#13;&#13;
<div class="sidebar">&#13;&#13;
<p class="sb-title"><strong>CONCEPT CHECK</strong></p>&#13;&#13;
<p class="sidebarp">In <a href="ch01.xhtml#ch01ex01">Listing 1-1</a>, we solved the Word Count problem. Here’s the code for that solution.</p>&#13;&#13;
<p class="programs"><span epub:type="pagebreak" id="page_272"/>line = input()<br/>&#13;&#13;
total_words = line.count(' ') + 1<br/>&#13;&#13;
print(total_words)</p>&#13;&#13;
<p class="sidebarp">What is the big O efficiency of our algorithm?</p>&#13;&#13;
<p class="alphat">A. <em>O</em>(1)</p>&#13;&#13;
<p class="alpha">B. <em>O</em>(<em>n</em>)</p>&#13;&#13;
<p class="sb-noindent1">Answer: B. It’s tempting to think that this algorithm is <em>O</em>(1). After all, there’s no loop anywhere, and it looks like the algorithm is performing just three steps: read the input, call <span class="literal">count</span> to count the number of words, and output the number of words.</p>&#13;&#13;
<p class="sidebarp">But this algorithm is <em>O</em>(<em>n</em>), where <em>n</em> is the number of characters in the input. It takes linear time for the <span class="literal">input</span> function to read the input, because it has to read the input character by character. Using the <span class="literal">count</span> method also takes linear time, because it has to process each character of the string to find matches. So this algorithm performs a linear amount of work to read the input and a linear amount of work to count the words. That’s a linear amount of work overall.</p>&#13;&#13;
</div>&#13;&#13;
<div class="sidebar">&#13;&#13;
<p class="sb-title"><strong>CONCEPT CHECK</strong></p>&#13;&#13;
<p class="sidebarp">In <a href="ch01.xhtml#ch01ex02">Listing 1-2</a>, we solved the Cone Volume problem. I’ve reproduced that solution here:</p>&#13;&#13;
<p class="programs">PI = 3.141592653589793<br/>&#13;&#13;
<br/>&#13;&#13;
<br/>&#13;&#13;
radius = int(input())<br/>&#13;&#13;
height = int(input())<br/>&#13;&#13;
<br/>&#13;&#13;
volume = (PI * radius ** 2 * height) / 3<br/>&#13;&#13;
<br/>&#13;&#13;
print(volume)</p>&#13;&#13;
<p class="sidebarp">What is the big O efficiency of our algorithm? (Recall that the maximum value for the radius and height is 100.)</p>&#13;&#13;
<p class="alphat">A. <em>O</em>(1)</p>&#13;&#13;
<p class="alpha">B. <em>O</em>(<em>n</em>)</p>&#13;&#13;
<p class="sb-noindent1"><span epub:type="pagebreak" id="page_273"/>Answer: A. We’re dealing with small numbers here, so reading them from the input takes constant time. Calculating the volume takes constant time, too: it’s just a few mathematical operations. All we’re doing here, then, is a few constant-time steps. That’s a constant amount of work overall.</p>&#13;&#13;
</div>&#13;&#13;
<div class="sidebar">&#13;&#13;
<p class="sb-title"><strong>CONCEPT CHECK</strong></p>&#13;&#13;
<p class="sidebarp">In <a href="ch03.xhtml#ch03ex04">Listing 3-4</a>, we solved the Data Plan problem. I’ve reproduced that solution here:</p>&#13;&#13;
<p class="programs">monthly_mb = int(input())<br/>&#13;&#13;
n = int(input())<br/>&#13;&#13;
<br/>&#13;&#13;
excess = 0<br/>&#13;&#13;
<br/>&#13;&#13;
for i in range(n):<br/>&#13;&#13;
    used = int(input())<br/>&#13;&#13;
    excess = excess + monthly_mb - used<br/>&#13;&#13;
<br/>&#13;&#13;
print(excess + monthly_mb)</p>&#13;&#13;
<p class="sidebarp">What is the big O efficiency of our algorithm?</p>&#13;&#13;
<p class="alphat">A. <em>O</em>(1)</p>&#13;&#13;
<p class="alpha">B. <em>O</em>(<em>n</em>)</p>&#13;&#13;
<p class="sb-noindent1">Answer: B. The pattern for this algorithm is similar to that of our solution to Three Cups or Occupied Spaces, except that it interleaves reading the input with processing it. We let <em>n</em> be the number of monthly megabyte values. The program performs a constant number of steps for each of these <em>n</em> input values. This is therefore an <em>O</em>(<em>n</em>) algorithm.</p>&#13;&#13;
</div>&#13;&#13;
<h4 class="h4" id="ch10lev2sec3">Quadratic Time</h4>&#13;&#13;
<p class="noindent">So far we’ve discussed constant-time algorithms (those that don’t do more work as the amount of input increases) and linear-time algorithms (those that do more work linearly as the amount of input increases). Like a linear-time algorithm, a <em>quadratic-time</em> algorithm does more work as the amount of input increases; for example, it does more work to process 1,000 values than 10 values. Whereas we can get away with using a linear-time algorithm on relatively large amounts of input, we’ll be restricted to much smaller amounts of input on quadratic-time algorithms. We’ll see why next.</p>&#13;&#13;
<h5 class="h5" id="ch10lev3sec1"><span epub:type="pagebreak" id="page_274"/>Typical Form</h5>&#13;&#13;
<p class="noindent">A typical linear-time algorithm looks like this:</p>&#13;&#13;
<p class="programs">for i in range(n):<br/>&#13;&#13;
    <span class="codeitalic1">&lt;process input</span> i <span class="codeitalic1">in a constant number of steps&gt;</span></p>&#13;&#13;
<p class="indent">In contrast, a typical quadratic-time algorithm looks like this:</p>&#13;&#13;
<p class="programs">for i in range(n):<br/>&#13;&#13;
    for j in range(n):<br/>&#13;&#13;
        <span class="codeitalic1">&lt;process inputs</span> i <span class="codeitalic1">and</span> j <span class="codeitalic1">in a constant number of steps&gt;</span></p>&#13;&#13;
<p class="indent">For an input of <em>n</em> values, how many values does each algorithm process? The linear-time algorithm processes <em>n</em> values, one on each iteration of the <span class="literal">for</span> loop. The quadratic-time algorithm, in contrast, processes <em>n</em> values <em>on each iteration</em> of the outer <span class="literal">for</span> loop.</p>&#13;&#13;
<p class="indent">On the first iteration of the outer <span class="literal">for</span> loop, <em>n</em> values are processed (one on each iteration of the inner <span class="literal">for</span> loop); on the second iteration of the outer <span class="literal">for</span> loop, <em>n</em> more values are processed (one on each iteration of the inner <span class="literal">for</span> loop); and so on. As the outer <span class="literal">for</span> loop iterates <em>n</em> times, the total number of values that are processed is <em>n</em> * <em>n</em>, or <em>n</em><sup>2</sup>. Two nested loops, each of which depends on <em>n</em>, gives rise to a quadratic-time algorithm. In big O notation, we say that a quadratic-time algorithm is <em>O</em>(<em>n</em><sup>2</sup>).</p>&#13;&#13;
<p class="indent">Let’s compare the amount of work done by linear-time and quadratic-time algorithms. Suppose that we’re processing an input of 1,000 values, meaning that <em>n</em> is 1,000. A linear-time algorithm that takes <em>n</em> steps would take 1,000 steps. A quadratic-time algorithm that takes <em>n</em><sup>2</sup> steps would take 1,000<sup>2</sup> = 1,000,000 steps. A million is way more than a thousand. But who cares: computers are really, really fast, right? Well, yes, and for an input of 1,000 values, we’re probably okay if we use a quadratic-time algorithm. In “Efficiency of Our Program” on <a href="ch09.xhtml#ch09lev2sec16">page 253</a>, I gave a conservative rule claiming that we can perform about five million steps per second. A million steps, then, should be doable in all but the strictest time limits.</p>&#13;&#13;
<p class="indent">But any optimism for a quadratic-time algorithm is short-lived. Watch what happens if we crank the number of input values up from 1,000 to 10,000. The linear-time algorithm takes only 10,000 steps. The quadratic-algorithm takes 10,000<sup>2</sup> = 100,000,000 steps. Hmmm . . . if we’re using a quadratic-time algorithm, now our computer isn’t looking so fast. While the linear-time algorithm still runs in milliseconds, the quadratic-time algorithm will take at least a few seconds. Time limit exceeded there, no question.</p>&#13;&#13;
<div class="sidebar">&#13;&#13;
<p class="sb-title"><strong>CONCEPT CHECK</strong></p>&#13;&#13;
<p class="sidebarp">What is the big O efficiency of the following algorithm?</p>&#13;&#13;
<p class="programs"><span epub:type="pagebreak" id="page_275"/>for i in range(10):<br/>&#13;&#13;
    for j in range(n):<br/>&#13;&#13;
        <span class="codeitalic1">&lt;process inputs</span> i <span class="codeitalic1">and</span> j <span class="codeitalic1">in a constant number of steps&gt;</span></p>&#13;&#13;
<p class="alphat">A. <em>O</em>(1)</p>&#13;&#13;
<p class="alpha">B. <em>O</em>(<em>n</em>)</p>&#13;&#13;
<p class="alpha">C. <em>O</em>(<em>n</em><sup><em>2</em></sup>)</p>&#13;&#13;
<p class="sb-noindent1">Answer: B. There are two nested loops here, so your first instinct might be to claim that this is a quadratic-time algorithm. Be careful, though, because the outer <span class="literal">for</span> loop iterates only 10 times, independent of the value of <em>n</em>. The total number of steps in this algorithm, therefore, is <em>10n</em>. There’s no <em>n</em><sup><em>2</em></sup> here; <em>10n</em> is linear, just like <em>n</em>. So, this is a linear-time algorithm, not a quadratic-time algorithm. We’d write its efficiency as <em>O</em>(<em>n</em>).</p>&#13;&#13;
</div>&#13;&#13;
<div class="sidebar">&#13;&#13;
<p class="sb-title"><strong>CONCEPT CHECK</strong></p>&#13;&#13;
<p class="sidebarp">What is the big O efficiency of the following algorithm?</p>&#13;&#13;
<p class="programs">for i in range(n):<br/>&#13;&#13;
    <span class="codeitalic1">&lt;process input</span> i <span class="codeitalic1">in a constant number of steps&gt;</span><br/>&#13;&#13;
for j in range(n):<br/>&#13;&#13;
    <span class="codeitalic1">&lt;process input</span> j <span class="codeitalic1">in a constant number of steps&gt;</span></p>&#13;&#13;
<p class="alphat">A. <em>O</em>(1)</p>&#13;&#13;
<p class="alpha">B. <em>O</em>(<em>n</em>)</p>&#13;&#13;
<p class="alpha">C. <em>O</em>(<em>n</em><sup><em>2</em></sup>)</p>&#13;&#13;
<p class="sb-noindent1">Answer: B. We have two loops here, and they both depend on <em>n</em>. Isn’t this quadratic time, then?</p>&#13;&#13;
<p class="sidebarp">No! These two loops are sequential, not nested. The first loop takes <em>n</em> steps, and the second also takes <em>n</em> steps, for a total of <em>2n</em> steps. This is therefore a linear-time algorithm.</p>&#13;&#13;
</div>&#13;&#13;
<h5 class="h5" id="ch10lev3sec2">Alternate Form</h5>&#13;&#13;
<p class="noindent">When you see two nested loops where each depends on <em>n</em>, it’s a good bet that you’re looking at a quadratic-time algorithm. But it’s possible for a <span epub:type="pagebreak" id="page_276"/>quadratic-time algorithm to arise even in the absence of such nested loops. We can find such an example in our first solution to the Email Addresses problem, <a href="ch08.xhtml#ch08ex02">Listing 8-2</a>. I’ve reproduced that solution here:</p>&#13;&#13;
<p class="programs"># clean function not shown<br/>&#13;&#13;
<br/>&#13;&#13;
for dataset in range(10):<br/>&#13;&#13;
    n = int(input())<br/>&#13;&#13;
    addresses = []<br/>&#13;&#13;
    for i in range(n):<br/>&#13;&#13;
        address = input()<br/>&#13;&#13;
     <span class="ent">❶</span> address = clean(address)<br/>&#13;&#13;
     <span class="ent">❷</span> if not address in addresses:<br/>&#13;&#13;
            addresses.append(address)<br/>&#13;&#13;
<br/>&#13;&#13;
    print(len(addresses))</p>&#13;&#13;
<p class="indent">We’ll let <em>n</em> be the maximum number of email addresses that we see in our 10 test cases. The outer <span class="literal">for</span> loop iterates 10 times; the inner <span class="literal">for</span> loop iterates at most <em>n</em> times. We’re therefore processing at most 10<em>n</em> email addresses, which is linear in <em>n</em>.</p>&#13;&#13;
<p class="indent">Cleaning an email address <span class="ent">❶</span> takes a constant number of steps, so we don’t need to worry about that. But this is still <em>not</em> a linear-time algorithm, because each iteration of the inner <span class="literal">for</span> loop takes more than a constant number of steps. Specifically, checking whether an email address is already in our list <span class="ent">❷</span> takes work proportional to the number of email addresses already in the list, because Python has to search through the list. That’s a linear-time operation on its own! So we’re processing 10<em>n</em> email addresses, each of which requires <em>n</em> work, for a total of 10<em>n</em><sup>2</sup>, or quadratic-time, work. This quadratic-time performance is precisely why we received a time limit exceeded error with this code, leading us to use a set rather than a list.</p>&#13;&#13;
<h4 class="h4" id="ch10lev2sec4">Cubic Time</h4>&#13;&#13;
<p class="noindent">If one loop can lead to linear time, and two nested loops can lead to quadratic time, then what about three nested loops? Three nested loops, each of which depends on <em>n</em>, leads to a <em>cubic-time</em> algorithm. In big O notation, we say that a cubic-time algorithm is <em>O</em>(<em>n</em><sup>3</sup>).</p>&#13;&#13;
<p class="indent">If you thought quadratic-time algorithms were slow, wait till you see how slow cubic-time algorithms are. Suppose that <em>n</em> is 1,000. We already know that a linear-time algorithm will take about 1,000 steps and that a quadratic-time algorithm will take about 1,000<sup>2</sup> = 1,000,000 steps. A cubic-time algorithm will take 1,000<sup>3</sup> = 1,000,000,000 steps. A billion steps! But it gets worse. For example, if <em>n</em> is 10,000, which is still a small amount of input, then a cubic-time algorithm will take 1,000,000,000,000 (that’s one trillion) steps. One trillion steps would take many minutes of computing time. No joke: a cubic-time algorithm is almost never good enough.</p>&#13;&#13;
<p class="indent"><span epub:type="pagebreak" id="page_277"/>It certainly wasn’t good enough when we tried to use a cubic-time algorithm to solve Cow Baseball in <a href="ch09.xhtml#ch09ex05">Listing 9-5</a>. I’ve reproduced that solution here:</p>&#13;&#13;
<p class="programs">   input_file = open('baseball.in', 'r')<br/>&#13;&#13;
   output_file = open('baseball.out', 'w')<br/>&#13;&#13;
<br/>&#13;&#13;
   n = int(input_file.readline())<br/>&#13;&#13;
<br/>&#13;&#13;
   positions = []<br/>&#13;&#13;
<br/>&#13;&#13;
   for i in range(n):<br/>&#13;&#13;
       positions.append(int(input_file.readline()))<br/>&#13;&#13;
<br/>&#13;&#13;
   total = 0<br/>&#13;&#13;
<br/>&#13;&#13;
<span class="ent">❶</span> for position1 in positions:<br/>&#13;&#13;
    <span class="ent">❷</span> for position2 in positions:<br/>&#13;&#13;
           first_two_diff = position2 - position1<br/>&#13;&#13;
           if first_two_diff &gt; 0:<br/>&#13;&#13;
               low = position2 + first_two_diff<br/>&#13;&#13;
               high = position2 + first_two_diff * 2<br/>&#13;&#13;
<br/>&#13;&#13;
            <span class="ent">❸</span> for position3 in positions:<br/>&#13;&#13;
                   if position3 &gt;= low and position3 &lt;= high:<br/>&#13;&#13;
                       total = total + 1<br/>&#13;&#13;
<br/>&#13;&#13;
   output_file.write(str(total) + '\n')<br/>&#13;&#13;
<br/>&#13;&#13;
   input_file.close()<br/>&#13;&#13;
   output_file.close()</p>&#13;&#13;
<p class="indent">You’ll see the telltale of cubic time in this code: three nested loops <span class="ent">❶</span> <span class="ent">❷</span> <span class="ent">❸</span>, each of which depends on the amount of input. As you’ll recall, the time limit for that problem was four seconds, and we could have up to 1,000 cows. A cubic-time algorithm, processing a billion triples, is way too slow.</p>&#13;&#13;
<h4 class="h4" id="ch10lev2sec5">Multiple Variables</h4>&#13;&#13;
<p class="noindent">In <a href="ch05.xhtml#ch05">Chapter 5</a>, we solved the Baker Bonus problem. I’ve reproduced our solution from <a href="ch05.xhtml#ch05ex06">Listing 5-6</a> here:</p>&#13;&#13;
<p class="programs">for dataset in range(10):<br/>&#13;&#13;
    lst = input().split()<br/>&#13;&#13;
    franchisees = int(lst[0])<br/>&#13;&#13;
    days = int(lst[1])<br/>&#13;&#13;
<br/>&#13;&#13;
    grid = []<br/>&#13;&#13;
<br/>&#13;&#13;
<span epub:type="pagebreak" id="page_278"/> <span class="ent">❶</span> for i in range(days):<br/>&#13;&#13;
        row = input().split()<br/>&#13;&#13;
        for j in range(franchisees):<br/>&#13;&#13;
            row[j] = int(row[j])<br/>&#13;&#13;
        grid.append(row)<br/>&#13;&#13;
<br/>&#13;&#13;
    bonuses = 0<br/>&#13;&#13;
<br/>&#13;&#13;
 <span class="ent">❷</span> for row in grid:<br/>&#13;&#13;
        total = sum(row)<br/>&#13;&#13;
        if total % 13 == 0:<br/>&#13;&#13;
            bonuses = bonuses + total // 13<br/>&#13;&#13;
<br/>&#13;&#13;
 <span class="ent">❸</span> for col_index in range(franchisees):<br/>&#13;&#13;
        total = 0<br/>&#13;&#13;
        for row_index in range(days):<br/>&#13;&#13;
            total = total + grid[row_index][col_index]<br/>&#13;&#13;
        if total % 13 == 0:<br/>&#13;&#13;
            bonuses = bonuses + total // 13<br/>&#13;&#13;
<br/>&#13;&#13;
    print(bonuses)</p>&#13;&#13;
<p class="indent">What is the big O efficiency of this algorithm? There are some nested loops in here, so a first guess is that this algorithm is <em>O</em>(<em>n</em><sup>2</sup>). But what is <em>n</em>?</p>&#13;&#13;
<p class="indent">In the problems we’ve discussed to this point in the chapter, we used the single variable <em>n</em> to represent the amount of input: <em>n</em> could be the number of swaps or the number of parking spaces or the number of email addresses or the number of cows. But in the Baker Bonus problem, we’re dealing with two-dimensional input, so we need <em>two</em> variables to represent its amount. We’ll call the first variable <em>d</em>, the number of days; we’ll call the second <em>f</em>, the number of franchisees. More formally, because there are multiple test cases per input, we’ll let <em>d</em> be the maximum number of days and <em>f</em> the maximum number of franchisees. We need to give the big O efficiency in terms of <em>both d</em> and <em>f</em>.</p>&#13;&#13;
<p class="indent">Our algorithm consists of three major components: reading the input, calculating the number of bonuses from the rows, and calculating the number of bonuses from the columns. Let’s take a look at each of these.</p>&#13;&#13;
<p class="indent">To read the input <span class="ent">❶</span>, we perform <em>d</em> iterations of the outer loop. On each of these iterations we read a row and call <span class="literal">split</span>, which takes about <em>f</em> steps. We take another <em>f</em> steps to loop through the values and convert them to integers. In total, then, each of the <em>d</em> iterations performs a number of steps proportional to <em>f</em>. Reading the input therefore takes <em>O</em>(<em>df</em>) time.</p>&#13;&#13;
<p class="indent">Now for the row bonuses <span class="ent">❷</span>. The outer loop here loops <em>d</em> times. Each of these iterations calls <span class="literal">sum</span>, which takes <em>f</em> steps because it has to add up <em>f</em> values. Like reading the input, then, this part of the algorithm is <em>O</em>(<em>df</em>).</p>&#13;&#13;
<p class="indent"><span epub:type="pagebreak" id="page_279"/>Finally, let’s look at the code for the column bonuses <span class="ent">❸</span>. The outer loop loops <em>f</em> times. Each of those iterations leads to the inner loop iterating <em>d</em> times. The total here, again, is <em>O</em>(<em>df</em>).</p>&#13;&#13;
<p class="indent">Each component of this algorithm is <em>O</em>(<em>df</em>). Adding three <em>O</em>(<em>df</em>) components together yields an <em>O</em>(<em>df</em>) algorithm overall.</p>&#13;&#13;
<div class="sidebar">&#13;&#13;
<p class="sb-title"><strong>CONCEPT CHECK</strong></p>&#13;&#13;
<p class="sidebarp">What is the big O efficiency of the following algorithm?</p>&#13;&#13;
<p class="programs">for i in range(m):<br/>&#13;&#13;
    <span class="codeitalic1">&lt;do something that takes one step&gt;</span><br/>&#13;&#13;
for j in range(n):<br/>&#13;&#13;
    <span class="codeitalic1">&lt;do something that takes one step&gt;</span></p>&#13;&#13;
<p class="alphat">A. <em>O</em>(1)</p>&#13;&#13;
<p class="alpha">B. <em>O</em>(<em>n</em>)</p>&#13;&#13;
<p class="alpha">C. <em>O</em>(<em>n</em><sup><em>2</em></sup>)</p>&#13;&#13;
<p class="alpha">D. <em>O</em>(<em>m</em>+<em>n</em>)</p>&#13;&#13;
<p class="alpha">E. <em>O</em>(<em>mn</em>)</p>&#13;&#13;
<p class="sb-noindent1">Answer: D. The first loop depends on <em>m</em>, and the second depends on <em>n</em>. The loops are sequential, not nested, so their work is added rather than multiplied.</p>&#13;&#13;
</div>&#13;&#13;
<h4 class="h4" id="ch10lev2sec6">Log Time</h4>&#13;&#13;
<p class="noindent">In “Efficiency of Our Program” on <a href="ch09.xhtml#ch09lev2sec18">page 255</a>, we discussed the difference between linear search and binary search. A linear search finds a value in a list by searching the list from beginning to end. That’s an <em>O</em>(<em>n</em>) algorithm. It works whether or not the list is sorted. A binary search, by contrast, works only on a sorted list. But if you have a sorted list, then binary search is blazingly fast.</p>&#13;&#13;
<p class="indent">Binary search works by comparing the value we’re searching for to the value at the middle of the list. If the value at the middle of the list is larger than the value we’re searching for, we continue searching in the left half of the list. If the value at the middle of the list is smaller than the value we’re searching for, we continue searching in the right half of the list. We keep doing this, ignoring half of the list each time, until we find the value that we’re looking for.</p>&#13;&#13;
<p class="indent">Suppose we use binary search to find a value in a list of 512 values. How many steps does it take? Well, after one step, we’ve ignored half the list, so we’re left with about 512 / 2 = 256 values. (It doesn’t matter whether our value is larger than half of the values in the list or smaller than half the <span epub:type="pagebreak" id="page_280"/>values in the list; in each case, we ignore one half of the list.) After two steps, we’re left with 256 / 2 = 128 values. After three steps, we’re left with 128 / 2 = 64 values. Continuing, after four steps we have 32 values, after five steps we have 16 values, after six steps we have 8 values, after seven steps we have 4 values, after eight steps we have 2 values, and after nine steps we have only 1 value.</p>&#13;&#13;
<p class="indent">Nine steps—that’s it! That’s way better than taking up to 512 steps using linear search. Binary search does far less work than a linear-time algorithm. But what kind of algorithm is it? It’s not constant time: while it takes very few steps, the number of steps does increase a little as the amount of input increases.</p>&#13;&#13;
<p class="indent">Binary search is an example of a <em>logarithmic-time</em> or <em>log-time</em> algorithm. In big O notation, we say that a logarithmic-time algorithm is <em>O</em>(log <em>n</em>).</p>&#13;&#13;
<p class="indent">Logarithmic-time refers to the logarithm function in mathematics. Given a number, this function tells you the number of times you have to divide that number by a base to get to 1 or less. The base we typically use in computer science is 2, so we’re looking for the number of times you have to divide a number by 2 to get to 1 or less. For example, it takes 9 divisions by 2 to take 512 down to 1. We write this as log<sub>2</sub> 512 = 9.</p>&#13;&#13;
<p class="indent">The logarithm function is the inverse of the exponential function, the latter of which may be more familiar to you. Another way to calculate log<sub>2</sub> 512 is to find the power <em>p</em> so that 2<em><sup>p</sup></em> = 512. Since 2<sup>9</sup> = 512, we confirm that log<sub>2</sub> 512 = 9.</p>&#13;&#13;
<p class="indent">It’s shocking how slowly the logarithm function grows. For example, consider a list of one million values. How many steps would binary search take to search that? It takes log<sub>2</sub> 1,000,000 steps, which is only about 20. Logarithmic-time is much closer to constant-time than it is to linear-time. It’s a huge win any time you can replace a linear-time algorithm by a logarithmic-time one.</p>&#13;&#13;
<h4 class="h4" id="ch10lev2sec7">n log n Time</h4>&#13;&#13;
<p class="noindent">In <a href="ch05.xhtml#ch05">Chapter 5</a>, we solved the Village Neighborhood problem. I’ve reproduced our solution from <a href="ch05.xhtml#ch05ex01">Listing 5-1</a> here:</p>&#13;&#13;
<p class="programs">   n = int(input())<br/>&#13;&#13;
<br/>&#13;&#13;
   positions = []<br/>&#13;&#13;
<br/>&#13;&#13;
<span class="ent">❶</span> for i in range(n):<br/>&#13;&#13;
       positions.append(int(input()))<br/>&#13;&#13;
<br/>&#13;&#13;
<span class="ent">❷</span> positions.sort()<br/>&#13;&#13;
<br/>&#13;&#13;
   left = (positions[1] - positions[0]) / 2<br/>&#13;&#13;
   right = (positions[2] - positions[1]) / 2<br/>&#13;&#13;
   min_size = left + right<br/>&#13;&#13;
<span epub:type="pagebreak" id="page_281"/><span class="ent">❸</span> for i in range(2, n - 1):<br/>&#13;&#13;
       left = (positions[i] - positions[i - 1]) / 2<br/>&#13;&#13;
       right = (positions[i + 1] - positions[i]) / 2<br/>&#13;&#13;
       size = left + right<br/>&#13;&#13;
       if size &lt; min_size: <br/>&#13;&#13;
           min_size = size<br/>&#13;&#13;
<br/>&#13;&#13;
   print(min_size)</p>&#13;&#13;
<p class="indent">Looks like a linear-time algorithm, eh? I mean, there’s a linear-time loop to read the input <span class="ent">❶</span> and another linear-time loop to find the minimum size <span class="ent">❸</span>. Is this code <em>O</em>(<em>n</em>), then?</p>&#13;&#13;
<p class="indent">It’s too early to tell! The reason is that we haven’t yet taken into account that we sort the positions <span class="ent">❷</span>. We can’t just ignore that; we need to know about the efficiency of sorting. As we’ll see, sorting is slower than linear time. So, since sorting is the slowest step here, whatever the efficiency is of sorting will be the efficiency overall.</p>&#13;&#13;
<p class="indent">Programmers and computer scientists have devised many sorting algorithms, and these algorithms can roughly be divided into two groups. The first group consists of algorithms that take <em>O</em>(<em>n</em><sup>2</sup>) time. The three most famous of these sorting algorithms are bubble sort, selection sort, and insertion sort. You can learn more about these sorting algorithms on your own if you like, but we won’t need to know anything about them to continue here. All we have to keep in mind is that <em>O</em>(<em>n</em><sup>2</sup>) can be quite slow. For example, to sort a list of 10,000 values, an <em>O</em>(<em>n</em><sup>2</sup>) sorting algorithm would take about 10,000<sup>2</sup> = 100,000,000 steps. As we know, this would take any computer at least a few seconds. That’s pretty disappointing: sorting 10,000 values feels like something computers should be able to do almost instantly.</p>&#13;&#13;
<p class="indent">Enter the second group of sorting algorithms. This group consists of algorithms that take only <em>O</em>(<em>n</em> log <em>n</em>) time. There are two famous sorting algorithms in this group: quick sort and merge sort. Again, you’re free to look them up if you like, but we don’t need the details here.</p>&#13;&#13;
<p class="indent">What does <em>O</em>(<em>n</em> log <em>n</em>) mean? Don’t let the notation confuse you. It’s just the multiplication of <em>n</em> by log <em>n</em>. Let’s try this out on a list of 10,000 values. Here, we have 10,000 * log 10,000 steps, which is only about 132,877. This is a very small number of steps, especially compared to the 100,000,000 steps taken by the <em>O</em>(<em>n</em><sup>2</sup>) sorting algorithms.</p>&#13;&#13;
<p class="indent">Now we can ask the question we really care about: what sorting algorithm is Python using when we ask it to sort a list? Answer: an <em>O</em>(<em>n</em> log <em>n</em>) one! (It’s called Timsort. If you’d like to learn more, start with merge sort, because Timsort is a souped-up merge sort.) No slow <em>O</em>(<em>n</em><sup>2</sup>) sorting here. In general, sorting is so fast—so close to linear time—that we can use it without affecting our efficiency too much.</p>&#13;&#13;
<p class="indent">Returning to Village Neighborhood, now we see that its efficiency is not <em>O</em>(<em>n</em>) but, because of the sort, <em>O</em>(<em>n</em> log <em>n</em>). In practice, an <em>O</em>(<em>n</em> log <em>n</em>) algorithm only does a little more work than an <em>O</em>(<em>n</em>) algorithm and far less than an <em>O</em>(<em>n</em><sup>2</sup>) algorithm. If your goal is to design an <em>O</em>(<em>n</em>) algorithm, designing one that’s <em>O</em>(<em>n</em> log <em>n</em>) is probably good enough.</p>&#13;&#13;
<h4 class="h4" id="ch10lev2sec8"><span epub:type="pagebreak" id="page_282"/>Handling Function Calls</h4>&#13;&#13;
<p class="noindent">Starting in <a href="ch06.xhtml#ch06">Chapter 6</a>, we wrote our own functions to help us design larger programs. In our big O analysis, we need to be careful to include the work done when we call these functions.</p>&#13;&#13;
<p class="indent">Let’s revisit the Card Game problem from <a href="ch06.xhtml#ch06">Chapter 6</a>. We solved it in <a href="ch06.xhtml#ch06ex01">Listing 6-1</a>, and part of our solution involved calling our <span class="literal">no_high</span> function. I’ve reproduced that solution here:</p>&#13;&#13;
<p class="programs">   NUM_CARDS = 52<br/>&#13;&#13;
<br/>&#13;&#13;
<br/>&#13;&#13;
<span class="ent">❶</span> def no_high(lst):<br/>&#13;&#13;
       """<br/>&#13;&#13;
       lst is a list of strings representing cards.<br/>&#13;&#13;
<br/>&#13;&#13;
       Return True if there are no high cards in lst, False otherwise.<br/>&#13;&#13;
       """<br/>&#13;&#13;
       if 'jack' in lst:<br/>&#13;&#13;
           return False<br/>&#13;&#13;
       if 'queen' in lst:<br/>&#13;&#13;
           return False<br/>&#13;&#13;
       if 'king' in lst:<br/>&#13;&#13;
           return False<br/>&#13;&#13;
       if 'ace' in lst:<br/>&#13;&#13;
           return False<br/>&#13;&#13;
       return True<br/>&#13;&#13;
<br/>&#13;&#13;
<br/>&#13;&#13;
   deck = []<br/>&#13;&#13;
<br/>&#13;&#13;
<span class="ent">❷</span> for i in range(NUM_CARDS):<br/>&#13;&#13;
       deck.append(input())<br/>&#13;&#13;
<br/>&#13;&#13;
   score_a = 0<br/>&#13;&#13;
   score_b = 0<br/>&#13;&#13;
   player = 'A'<br/>&#13;&#13;
<br/>&#13;&#13;
<span class="ent">❸</span> for i in range(NUM_CARDS):<br/>&#13;&#13;
       card = deck[i]<br/>&#13;&#13;
       points = 0<br/>&#13;&#13;
       remaining = NUM_CARDS - i - 1<br/>&#13;&#13;
       if card == 'jack' and remaining &gt;= 1 and no_high(deck[i+1:i+2]):<br/>&#13;&#13;
           points = 1<br/>&#13;&#13;
       elif card == 'queen' and remaining &gt;= 2 and no_high(deck[i+1:i+3]):<br/>&#13;&#13;
           points = 2<br/>&#13;&#13;
       elif card == 'king' and remaining &gt;= 3 and no_high(deck[i+1:i+4]):<br/>&#13;&#13;
           points = 3<br/>&#13;&#13;
<span epub:type="pagebreak" id="page_283"/>       elif card == 'ace' and remaining &gt;= 4 and no_high(deck[i+1:i+5]):<br/>&#13;&#13;
           points = 4<br/>&#13;&#13;
<br/>&#13;&#13;
       if points &gt; 0:<br/>&#13;&#13;
           print(f'Player {player} scores {points} point(s).')<br/>&#13;&#13;
<br/>&#13;&#13;
       if player == 'A':<br/>&#13;&#13;
           score_a = score_a + points<br/>&#13;&#13;
           player = 'B'<br/>&#13;&#13;
       else:<br/>&#13;&#13;
           score_b = score_b + points<br/>&#13;&#13;
           player = 'A'<br/>&#13;&#13;
<br/>&#13;&#13;
   print(f'Player A: {score_a} point(s).')<br/>&#13;&#13;
   print(f'Player B: {score_b} point(s).')</p>&#13;&#13;
<p class="indent">We’ll use <em>n</em> to represent the number of cards. The <span class="literal">no_high</span> function <span class="ent">❶</span> takes a list and uses <span class="literal">in</span> on it, so we might conclude that it is <em>O</em>(<em>n</em>) time. (<span class="literal">in</span> may have to search the whole list to find what it’s looking for, after all.) However, we only ever call <span class="literal">no_high</span> with lists of constant size—maximum four cards—so we can treat each call of <span class="literal">no_high</span> as <em>O</em>(1) time.</p>&#13;&#13;
<p class="indent">Now that we understand the efficiency of <span class="literal">no_high</span>, we can determine the big O efficiency of the complete program. We begin with a loop that takes <em>O</em>(<em>n</em>) time to read the cards <span class="ent">❷</span>. We then enter another loop that iterates <em>n</em> times <span class="ent">❸</span>. Each iteration takes just a constant number of steps, possibly including a call of <span class="literal">no_high</span> that takes a constant number of steps. This loop, then, takes <em>O</em>(<em>n</em>) time. The program therefore consists of two <em>O</em>(<em>n</em>) pieces, so it is <em>O</em>(<em>n</em>) overall.</p>&#13;&#13;
<p class="indent">Be careful to accurately judge the amount of work performed when a function is called. As you just saw with <span class="literal">no_high</span>, this may involve looking at both the function itself and the context in which it is called.</p>&#13;&#13;
<div class="sidebar">&#13;&#13;
<p class="sb-title"><strong>CONCEPT CHECK</strong></p>&#13;&#13;
<p class="sidebarp">What is the big O efficiency of the following algorithm?</p>&#13;&#13;
<p class="programs">def f(lst):<br/>&#13;&#13;
    for i in range(len(lst)):<br/>&#13;&#13;
        lst[i] = lst[i] + 1<br/>&#13;&#13;
<br/>&#13;&#13;
<br/>&#13;&#13;
# Assume that lst refers to a list of numbers<br/>&#13;&#13;
for i in range(len(lst)):<br/>&#13;&#13;
    f(lst)</p>&#13;&#13;
<p class="alphat"><span epub:type="pagebreak" id="page_284"/>A. <em>O</em>(1)</p>&#13;&#13;
<p class="alpha">B. <em>O</em>(<em>n</em>)</p>&#13;&#13;
<p class="alpha">C. <em>O</em>(<em>n</em><sup><em>2</em></sup>)</p>&#13;&#13;
<p class="sb-noindent1">Answer: C. The loop in the main program iterates <em>n</em> times. On each iteration, we call function <span class="literal">f</span>, which itself has a loop that iterates <em>n</em> times.</p>&#13;&#13;
</div>&#13;&#13;
<h4 class="h4" id="ch10lev2sec9">Summary</h4>&#13;&#13;
<p class="noindent">The algorithms that do the least work are <em>O</em>(1), followed by <em>O</em>(log <em>n</em>), followed by <em>O</em>(<em>n</em>), followed by <em>O</em>(<em>n</em> log <em>n</em>). Have you solved a problem using one of these four? If so, you’re probably done. If not, then depending on the time limit, you may have more work to do.</p>&#13;&#13;
<p class="indent">We’re now going to look at two problems where a straightforward solution will not be efficient enough—it won’t run within the time limit. Using what we just learned about big O, we’ll be able to predict this inefficiency even without implementing the code! We’ll then work on a faster solution and implement it to solve the problem within the time limit.</p>&#13;&#13;
<h3 class="h3a" id="ch10lev1sec3"><span class="h3aa">Problem #24: Longest Scarf</span></h3>&#13;&#13;
<p class="noindent">In this problem, we’ll determine the longest desired scarf that we can produce by cutting an initial scarf. After reading the following description, pause: how would you solve it? Can you come up with multiple algorithms whose efficiency you’d like to investigate?</p>&#13;&#13;
<p class="indent">This is DMOJ problem <span class="literal">dmopc20c2p2</span>.</p>&#13;&#13;
<h4 class="h4" id="ch10lev2sec10">The Challenge</h4>&#13;&#13;
<p class="noindent">You have a scarf whose length is <em>n</em> feet, and each foot has a specific color.</p>&#13;&#13;
<p class="indent">You also have <em>m</em> relatives. Each relative indicates what their desired scarf looks like by specifying the color of its first foot and last foot.</p>&#13;&#13;
<p class="indent">Your goal is to cut your original scarf in such a way as to produce the longest desired scarf for one of your relatives.</p>&#13;&#13;
<h4 class="h4" id="ch10lev2sec11">Input</h4>&#13;&#13;
<p class="noindent">The input consists of the following lines:</p>&#13;&#13;
<ul>&#13;&#13;
<li class="noindent">A line containing the integer scarf length <em>n</em> and integer number of relatives <em>m</em>, separated by a space. <em>n</em> and <em>m</em> are each between 1 and 100,000.&#13;&#13;
<span epub:type="pagebreak" id="page_285"/>&#13;&#13;
</li>&#13;&#13;
<li class="noindent">A line containing <em>n</em> integers separated by spaces. Each integer specifies the color of one foot of scarf in order from the first foot to the last foot. Each integer is between 1 and 1,000,000.</li>&#13;&#13;
<li class="noindent"><em>m</em> lines, one per relative, containing two integers separated by a space. These numbers describe the relative’s desired scarf: the first integer is the desired color of the first foot, and the second integer is the desired color of the last foot.</li>&#13;&#13;
</ul>&#13;&#13;
<h4 class="h4" id="ch10lev2sec12">Output</h4>&#13;&#13;
<p class="noindent">Output the length of the longest desired scarf that can be produced by cutting your original scarf.</p>&#13;&#13;
<p class="indent">The time limit for solving the test cases is 0.4 seconds.</p>&#13;&#13;
<h3 class="h3" id="ch10lev1sec4">Exploring a Test Case</h3>&#13;&#13;
<p class="noindent">Let’s make sure we know exactly what is being asked by working through a small test case. Here it is:</p>&#13;&#13;
<p class="programs">6 3<br/>&#13;&#13;
18 4 4 2 1 2<br/>&#13;&#13;
1 2<br/>&#13;&#13;
4 2<br/>&#13;&#13;
18 4</p>&#13;&#13;
<p class="indent">We have a scarf that’s 6 feet long and three relatives. The color of each foot of the scarf is 18, 4, 4, 2, 1, and 2. What’s the longest desired scarf we can make?</p>&#13;&#13;
<p class="indent">The first relative wants a scarf whose first foot is color 1 and whose last foot is color 2. The best we can do is give this relative a 2-foot scarf: the 2 feet (colors 1 and 2) at the end of the scarf.</p>&#13;&#13;
<p class="indent">The second relative wants a scarf whose first foot is color 4 and whose last foot is color 2. We can give them a 5-foot scarf: 4, 4, 2, 1, 2.</p>&#13;&#13;
<p class="indent">The third relative wants a scarf whose first foot is color 18 and whose last foot is color 4. We can give them a 3-foot scarf: 18, 4, 4.</p>&#13;&#13;
<p class="indent">The maximum length of a desired scarf that we can make is 5, so that’s the answer for this test case.</p>&#13;&#13;
<h3 class="h3" id="ch10lev1sec5">Algorithm 1</h3>&#13;&#13;
<p class="noindent">The way we just processed that test case might immediately suggest to you an algorithm that we can use to solve this problem. Namely, we should be able to go through the relatives and figure out the maximum length of a desired scarf for each one. For example, the maximum length for the first relative might be 2, so we remember that. The maximum length for the second relative might be 5. That’s longer than 2, so we remember the 5. The maximum length for the third relative might be 3. This isn’t greater than 5—no change <span epub:type="pagebreak" id="page_286"/>here. If this reminds you of a complete-search algorithm (<a href="ch09.xhtml#ch09">Chapter 9</a>): good, because it is one!</p>&#13;&#13;
<p class="indent">There are <em>m</em> relatives. If we knew how long it would take us to process each relative, then we’d be able to work out the big O efficiency we’d be dealing with.</p>&#13;&#13;
<p class="indent">Here’s an idea: for each relative, let’s find the leftmost index of the color of the first foot and the rightmost index of the color of the last foot. Once we had these indices, then no matter how long the scarf, we could use these indices to quickly determine the length of the longest desired scarf for this relative. For example, if the leftmost index of the color of the first foot is 100 and the rightmost index of the color of the last foot is 110, then their longest desired scarf is 110 – 100 + 1 = 11.</p>&#13;&#13;
<p class="indent">Depending on how we try to find these indices, we might be lucky and find them quickly. For example, we might scan from the left for the leftmost index of the color of the first foot and scan from the right for the rightmost index of the color of the last foot. Then, if the color of the first foot is near the beginning of the scarf and the color of the last foot is near the end, we’ll discover these indices very quickly.</p>&#13;&#13;
<p class="indent">We might not be lucky, though. Finding one or both of the indices could take up to <em>n</em> steps. For example, suppose that a relative wants a scarf whose first foot is a color that shows up right at the end of the scarf or that doesn’t show up in the scarf at all. We will have to check the entire <em>n</em> feet of the scarf, one foot at a time, to figure this out.</p>&#13;&#13;
<p class="indent">So, about <em>n</em> steps per relative. That’s linear time, and we know that linear time is fast. Are we good? No, because in this case the linear-time work is far more menacing than it may appear. Remember that we’d be doing this <em>O</em>(<em>n</em>) work for each of the <em>m</em> relatives. We therefore have an <em>O</em>(<em>mn</em>) algorithm overall. <em>m</em> and <em>n</em> can be as big as 100,000. So, <em>mn</em> can be as big as 100,000 <em>*</em> 100,000 = 10,000,000,000. That’s 10 billion! Given that we can do about five million operations per second and that our time limit is 0.4 seconds . . . yeah, we’re not even close. There’s no need to implement this algorithm. We’re certain that it will time out on large test cases. We may as well move on and spend our time implementing something else. (If you’re nevertheless curious about the code, please see the online resources associated with the book. Just remember that without even looking at the code, we already figured out that it would be too slow. The power of big O analysis is in helping us understand whether an algorithm is doomed even before we implement it.)</p>&#13;&#13;
<h3 class="h3" id="ch10lev1sec6">Algorithm 2</h3>&#13;&#13;
<p class="noindent">We’re going to have to somehow process each of the relatives—there’s no getting around that. What we’ll focus on optimizing, then, is the amount of work that we do per relative. Unfortunately, processing a relative in the way we did in the previous section may cause us to check over a huge portion of the scarf. It’s this searching through the scarf, once per relative, that’s crushing us. We need to get that searching under control.</p>&#13;&#13;
<p class="indent"><span epub:type="pagebreak" id="page_287"/>Suppose that we could look through the scarf only once, up-front, before we knew anything about what the relatives wanted. We could remember two things about each color in the scarf: its leftmost index and its rightmost index. Then, no matter what each relative wants, we could figure out the maximum length of their desired scarf using the left and right indices that we had already stored.</p>&#13;&#13;
<p class="indent">For example, assume we have this scarf:</p>&#13;&#13;
<p class="programs">18 4 4 2 1 2</p>&#13;&#13;
<p class="indent">We would store the following information for it:</p>&#13;&#13;
<table class="bordertb">&#13;&#13;
<colgroup>&#13;&#13;
<col style="width:30%"/>&#13;&#13;
<col style="width:30%"/>&#13;&#13;
<col style="width:40%"/>&#13;&#13;
</colgroup>&#13;&#13;
<thead>&#13;&#13;
<tr>&#13;&#13;
<td style="vertical-align: top" class="table-h"><p class="tab"><strong>Color</strong></p></td>&#13;&#13;
<td style="vertical-align: top" class="table-h"><p class="tab"><strong>Leftmost index</strong></p></td>&#13;&#13;
<td style="vertical-align: top" class="table-h"><p class="tab"><strong>Rightmost index</strong></p></td>&#13;&#13;
</tr>&#13;&#13;
</thead>&#13;&#13;
<tbody>&#13;&#13;
<tr>&#13;&#13;
<td style="vertical-align: top"><p class="tab">1</p></td>&#13;&#13;
<td style="vertical-align: top"><p class="tab">4</p></td>&#13;&#13;
<td style="vertical-align: top"><p class="tab">4</p></td>&#13;&#13;
</tr>&#13;&#13;
<tr>&#13;&#13;
<td style="vertical-align: top"><p class="tab">2</p></td>&#13;&#13;
<td style="vertical-align: top"><p class="tab">3</p></td>&#13;&#13;
<td style="vertical-align: top"><p class="tab">5</p></td>&#13;&#13;
</tr>&#13;&#13;
<tr>&#13;&#13;
<td style="vertical-align: top"><p class="tab">4</p></td>&#13;&#13;
<td style="vertical-align: top"><p class="tab">1</p></td>&#13;&#13;
<td style="vertical-align: top"><p class="tab">2</p></td>&#13;&#13;
</tr>&#13;&#13;
<tr>&#13;&#13;
<td style="vertical-align: top"><p class="tab">18</p></td>&#13;&#13;
<td style="vertical-align: top"><p class="tab">0</p></td>&#13;&#13;
<td style="vertical-align: top"><p class="tab">0</p></td>&#13;&#13;
</tr>&#13;&#13;
</tbody>&#13;&#13;
</table>&#13;&#13;
<p class="indent">Suppose that a relative wants a scarf whose first foot is color 1 and whose last foot is color 2. We look up the leftmost index for color 1, which is 4, and the rightmost index for color 2, which is 5. We then calculate 5 – 4 + 1 = 2, and that’s the length of the longest desired scarf for this relative.</p>&#13;&#13;
<p class="indent">Amazing: no matter how long the scarf, we can just do a quick calculation for each relative. No more running through the scarf over and over. The only tricky thing here is how to calculate all the leftmost and rightmost indices for the colors and to do so by looking through the scarf only once.</p>&#13;&#13;
<p class="indent">The code is presented in <a href="ch10.xhtml#ch10ex01">Listing 10-1</a>. Try to figure out how the <span class="literal">leftmost_index</span> and <span class="literal">rightmost_index</span> dictionaries are constructed before you continue reading my explanation that follows.</p>&#13;&#13;
<p class="programs">   lst = input().split()<br/>&#13;&#13;
   n = int(lst[0])<br/>&#13;&#13;
   m = int(lst[1])<br/>&#13;&#13;
<br/>&#13;&#13;
   scarf = input().split()<br/>&#13;&#13;
   for i in range(n):<br/>&#13;&#13;
       scarf[i] = int(scarf[i])<br/>&#13;&#13;
<br/>&#13;&#13;
<span class="ent">❶</span> leftmost_index = {}<br/>&#13;&#13;
<span class="ent">❷</span> rightmost_index = {}<br/>&#13;&#13;
<br/>&#13;&#13;
<span class="ent">❸</span> for i in range(n):<br/>&#13;&#13;
       color = scarf[i]<br/>&#13;&#13;
    <span class="ent">❹</span> if not color in leftmost_index:<br/>&#13;&#13;
           leftmost_index[color] = i<br/>&#13;&#13;
           rightmost_index[color] = i<br/>&#13;&#13;
    <span class="ent">❺</span> else:<br/>&#13;&#13;
<span epub:type="pagebreak" id="page_288"/>           rightmost_index[color] = i<br/>&#13;&#13;
<br/>&#13;&#13;
   max_length = 0<br/>&#13;&#13;
<br/>&#13;&#13;
   for i in range(m):<br/>&#13;&#13;
       relative = input().split()<br/>&#13;&#13;
       first = int(relative[0])<br/>&#13;&#13;
       last = int(relative[1])<br/>&#13;&#13;
       if first in leftmost_index and last in leftmost_index:<br/>&#13;&#13;
        <span class="ent">❻</span> length = rightmost_index[last] - leftmost_index[first] + 1<br/>&#13;&#13;
           if length &gt; max_length:<br/>&#13;&#13;
               max_length = length<br/>&#13;&#13;
<br/>&#13;&#13;
   print(max_length)</p>&#13;&#13;
<p class="ex-caption" id="ch10ex01"><em>Listing 10-1: Solving Longest Scarf, algorithm 2</em></p>&#13;&#13;
<p class="indent">This solution uses two dictionaries: one to keep track of the leftmost index for each color <span class="ent">❶</span> and one to keep track of the rightmost index for each color <span class="ent">❷</span>.</p>&#13;&#13;
<p class="indent">As promised, we look at each foot of the scarf just once <span class="ent">❸</span>. Here’s how we keep the <span class="literal">leftmost_index</span> and <span class="literal">rightmost_index</span> dictionaries up-to-date:</p>&#13;&#13;
<ul>&#13;&#13;
<li class="noindent">If the color of the current foot has never been seen before <span class="ent">❹</span>, then the current index serves as both the leftmost and rightmost index for this color.</li>&#13;&#13;
<li class="noindent">Otherwise, the color of the current foot has been seen before <span class="ent">❺</span>. We don’t want to update the leftmost index for this color, because the current index is to the right of the old one. We <em>do</em> want to update the rightmost index, though, because we have found an index to the right of the old one.</li>&#13;&#13;
</ul>&#13;&#13;
<p class="indent">Now for the payoff: for each relative, we can simply look up the leftmost and rightmost indices from these dictionaries <span class="ent">❻</span>. The maximum length of the desired scarf is the rightmost index of the color of the last foot, minus the leftmost index of the color of the first foot, plus one.</p>&#13;&#13;
<p class="indent">As I’ll argue now, this algorithm is far better than algorithm 1. Reading the scarf takes <em>O</em>(<em>n</em>) time, as does processing the scarf ’s feet. That’s <em>O</em>(<em>n</em>) time so far. We then take a constant number of steps to process each relative (not <em>n</em> steps like before!), so that’s <em>O</em>(<em>m</em>) time. In total, we have an <em>O</em>(<em>m</em> + <em>n</em>) algorithm, rather than an <em>O</em>(<em>mn</em>) algorithm. Given that <em>m</em> and <em>n</em> can be at most 100,000, we’re doing only about 100,000 + 100,000 = 200,000 steps, easily done within the time limit. You can submit our code to the judge to prove it!</p>&#13;&#13;
<h3 class="h3a" id="ch10lev1sec7"><span class="h3aa">Problem #25: Ribbon Painting</span></h3>&#13;&#13;
<p class="noindent">Here’s another problem where the first algorithm that we might come up with is too slow. We won’t waste much time on that algorithm, though, because our big O analysis will tell us all we need to know before we consider <span epub:type="pagebreak" id="page_289"/>implementing the code. We’ll then spend our time designing a faster algorithm.</p>&#13;&#13;
<p class="indent">This is DMOJ problem <span class="literal">dmopc17c4p1</span>.</p>&#13;&#13;
<h4 class="h4" id="ch10lev2sec13">The Challenge</h4>&#13;&#13;
<p class="noindent">You have a purple ribbon whose length is <em>n</em> units. The first unit goes from position 0 up to but not including position 1, the second unit goes from position 1 up to but not including position 2, and so on. You then carry out <em>q</em> paint strokes, each of which colors a segment of the ribbon blue.</p>&#13;&#13;
<p class="indent">Your goal is to determine the number of units of the ribbon that are still purple and the number of units of the ribbon that are now blue.</p>&#13;&#13;
<h4 class="h4" id="ch10lev2sec14">Input</h4>&#13;&#13;
<p class="noindent">The input consists of the following lines:</p>&#13;&#13;
<ul>&#13;&#13;
<li class="noindent">A line containing the integer ribbon length <em>n</em> and integer number of paint strokes <em>q</em>, separated by a space. <em>n</em> and <em>q</em> are each between 1 and 100,000.</li>&#13;&#13;
<li class="noindent"><em>q</em> lines, one per paint stroke, containing two integers separated by a space. The first integer gives the starting position of the paint stroke; the second gives the ending position of the paint stroke. The starting position is guaranteed to be less than the ending position; each integer is between 0 and <em>n</em>. The paint stroke goes from the starting position up to but not including the ending position. As a quick example here, if a paint stroke has a starting position of 5 and an ending position of 12, then the stroke paints the ribbon from position 5 up to but not including position 12.</li>&#13;&#13;
</ul>&#13;&#13;
<h4 class="h4" id="ch10lev2sec15">Output</h4>&#13;&#13;
<p class="noindent">Output the number of units of the ribbon that are still purple, a space, and the number of units of the ribbon that are now blue.</p>&#13;&#13;
<p class="indent">The time limit for solving the test cases is 2 seconds.</p>&#13;&#13;
<h3 class="h3" id="ch10lev1sec8">Exploring a Test Case</h3>&#13;&#13;
<p class="noindent">Let’s look at a small test case. This test case will not only ensure that we’ve interpreted the problem correctly but also highlight the perils of a naive algorithm. Here it is:</p>&#13;&#13;
<p class="programs">20 4<br/>&#13;&#13;
18 19<br/>&#13;&#13;
4 16<br/>&#13;&#13;
4 14<br/>&#13;&#13;
5 12</p>&#13;&#13;
<p class="indent"><span epub:type="pagebreak" id="page_290"/>Our ribbon’s length is 20, and there are four paint strokes. How much of the ribbon do our paint strokes turn blue?</p>&#13;&#13;
<p class="indent">The first paint stroke paints one unit blue, the one that starts at position 18.</p>&#13;&#13;
<p class="indent">The second paint stroke paints the units of ribbon starting at positions 4, 5, 6, 7, and so on, all the way up to position 15. That’s 12 units painted blue by this stroke, and 13 blue units in total.</p>&#13;&#13;
<p class="indent">The third paint stroke paints 10 units blue. But all of those units are already blue from the second paint stroke! It would be a colossal waste of time indeed if we spent time “painting” anything with this paint stroke. Whatever algorithm we come up with better not fall into this time-wasting trap.</p>&#13;&#13;
<p class="indent">The fourth paint stroke paints 7 units blue. But again: all of these units are already blue!</p>&#13;&#13;
<p class="indent">Now we’re done painting, and we have 13 blue units. There are 20 – 13 = 7 remaining purple units, so the correct output for this test case is:</p>&#13;&#13;
<p class="programs">7 13</p>&#13;&#13;
<h3 class="h3" id="ch10lev1sec9">Solving the Problem</h3>&#13;&#13;
<p class="noindent">The maximum length of the ribbon is 100,000, and the maximum number of paint strokes is 100,000. Recall algorithm 1 from when we solved Longest Scarf, where we learned that an <em>O</em>(<em>mn</em>) algorithm was too slow with these bounds. Similarly, here, an <em>O</em>(<em>nq</em>) algorithm would be inadequate, as it would not finish within the time limit on large test cases.</p>&#13;&#13;
<p class="indent">This means that we cannot afford to process each unit that is painted by each paint stroke. It would be nice if we could more easily focus on only the <em>new</em> units that are painted blue by a paint stroke. Then we could go through each paint stroke and add up the number of blue units that it contributes.</p>&#13;&#13;
<p class="indent">Fair enough, but how can we determine the contribution of each paint stroke? That’s tricky, because bits and pieces of the next paint stroke may have already been painted blue by previous paint strokes.</p>&#13;&#13;
<p class="indent">This situation is made much simpler, however, if we sort the paint strokes first. Remember from “n log n Time” earlier in this chapter that sorting is extremely fast, taking only <em>O</em>(<em>n</em> log <em>n</em>) time. There’s no efficiency concern in using sorting, so let’s understand why sorting helps us here.</p>&#13;&#13;
<p class="indent">Sorting the paint strokes from the test case in the prior section gives us the following list of paint strokes:</p>&#13;&#13;
<p class="programs">4 14<br/>&#13;&#13;
4 16<br/>&#13;&#13;
5 12<br/>&#13;&#13;
18 19</p>&#13;&#13;
<p class="indent">Now that the paint strokes are sorted, we can efficiently process them. As we do so, we’ll store the rightmost position of any paint stroke that we’ve processed so far. We’ll start this rightmost position off at 0 to indicate that we haven’t painted anything.</p>&#13;&#13;
<p class="indent"><span epub:type="pagebreak" id="page_291"/>Our first paint stroke paints 14 – 4 = 10 units blue. Now our stored rightmost position is 14.</p>&#13;&#13;
<p class="indent">Our second paint stroke paints 12 units blue, yes, but how many of those 12 does it turn from purple to blue? After all, it overlaps the previous paint stroke, so some of these units were blue already. We can calculate the number of new blue units by subtracting 14, our stored rightmost position, from 16, the ending position of the current paint stroke. This is how we ignore the units already painted blue by previous paint strokes. So, there are 16 – 14 = 2 new blue units and 12 blue units in total. Crucially, we just figured this out without processing the individual units of this paint stroke. Before we continue, don’t forget to update our stored rightmost position to 16.</p>&#13;&#13;
<p class="indent">Our third paint stroke is like the second in that it starts prior to our stored rightmost position. Unlike the second paint stroke, however, its ending position does not extend past our stored rightmost position at all. So, this paint stroke adds no new blue units, and our stored rightmost position is still 16. Again, we figured this out without grinding through each of this paint stroke’s positions!</p>&#13;&#13;
<p class="indent">Be careful with the fourth paint stroke. It does <em>not</em> add 19 – 16 = 3 new blue units. We have to treat this paint stroke differently because its starting position is to the right of our stored rightmost position. In this case, we don’t use the stored rightmost position at all, calculating instead 19 – 18 = 1 new blue unit, and 13 blue units in total. We also update our stored rightmost position to 19.</p>&#13;&#13;
<p class="indent">The only question is how we sort the paint strokes in our Python code. We need to sort them by their starting position; if multiple paint strokes have the same starting position, then we want to sort those by their ending position.</p>&#13;&#13;
<p class="indent">That is, we want to take a list like this:</p>&#13;&#13;
<p class="programs">[[18, 19], [4, 16], [4, 14], [5, 12]]</p>&#13;&#13;
<p class="noindent">and produce this:</p>&#13;&#13;
<p class="programs">[[4, 14], [4, 16], [5, 12], [18, 19]]</p>&#13;&#13;
<p class="indent">Happily, as we discovered in “Task 4: Sort Boxes” in <a href="ch06.xhtml#ch06">Chapter 6</a>, the list <span class="literal">sort</span> method works in exactly this way. When given a list of lists, <span class="literal">sort</span> sorts using the first values in each list; when those values are tied, the lists are further sorted using the second values. Check it out:</p>&#13;&#13;
<p class="programs">&gt;&gt;&gt; <span class="codestrong1">strokes = [[18, 19], [4, 16], [4, 14], [5, 12]]</span><br/>&#13;&#13;
&gt;&gt;&gt; <span class="codestrong1">strokes.sort()</span><br/>&#13;&#13;
&gt;&gt;&gt; <span class="codestrong1">strokes</span><br/>&#13;&#13;
[[4, 14], [4, 16], [5, 12], [18, 19]]</p>&#13;&#13;
<p class="indent">Algorithm: check. Sorting: check. We’re in great shape! Just one more thing we’d like to know before we see the code: what will be its big O efficiency? We need to read the <em>q</em> queries; that takes <em>O</em>(<em>q</em>) time. Then we need to sort the queries; that takes <em>O</em>(<em>q</em> log <em>q</em>) time. Finally, we need to process the <span epub:type="pagebreak" id="page_292"/>queries; that takes <em>O</em>(<em>q</em>) time. The slowest of these is the <em>O</em>(<em>q</em> log <em>q</em>) time for the sorting, so that’s our overall big O efficiency.</p>&#13;&#13;
<p class="indent">Now we have everything we need for a speedy solution. Check it out in <a href="ch10.xhtml#ch10ex02">Listing 10-2</a>.</p>&#13;&#13;
<p class="programs">   lst = input().split()<br/>&#13;&#13;
   n = int(lst[0])<br/>&#13;&#13;
   q = int(lst[1])<br/>&#13;&#13;
<br/>&#13;&#13;
   strokes = []<br/>&#13;&#13;
<br/>&#13;&#13;
   for i in range(q):<br/>&#13;&#13;
       stroke = input().split()<br/>&#13;&#13;
    <span class="ent">❶</span> strokes.append([int(stroke[0]), int(stroke[1])])<br/>&#13;&#13;
<br/>&#13;&#13;
<span class="ent">❷</span> strokes.sort()<br/>&#13;&#13;
<br/>&#13;&#13;
   rightmost_position = 0<br/>&#13;&#13;
<br/>&#13;&#13;
   blue = 0<br/>&#13;&#13;
<br/>&#13;&#13;
   for stroke in strokes:<br/>&#13;&#13;
       stroke_start = stroke[0]<br/>&#13;&#13;
       stroke_end = stroke[1]<br/>&#13;&#13;
    <span class="ent">❸</span> if stroke_start &lt;= rightmost_position:<br/>&#13;&#13;
           if stroke_end &gt; rightmost_position:<br/>&#13;&#13;
            <span class="ent">❹</span> blue = blue + stroke_end - rightmost_position<br/>&#13;&#13;
               rightmost_position = stroke_end<br/>&#13;&#13;
    <span class="ent">❺</span> else:<br/>&#13;&#13;
        <span class="ent">❻</span> blue = blue + stroke_end - stroke_start<br/>&#13;&#13;
           rightmost_position = stroke_end<br/>&#13;&#13;
<br/>&#13;&#13;
   print(n - blue, blue)</p>&#13;&#13;
<p class="ex-caption" id="ch10ex02"><em>Listing 10-2: Solving Ribbon Painting</em></p>&#13;&#13;
<p class="indent">We read each paint stroke, appending it as a list of two values to our <span class="literal">strokes</span> list <span class="ent">❶</span>. We then sort all of the paint strokes <span class="ent">❷</span>.</p>&#13;&#13;
<p class="indent">We next need to process each paint stroke from left to right. There are two key variables that drive this processing: variable <span class="literal">rightmost_position</span> stores the rightmost position that we have painted so far, and variable <span class="literal">blue</span> stores the number of units that we have painted blue so far.</p>&#13;&#13;
<p class="indent">To process a paint stroke, we need to know whether it starts before or after our stored rightmost position. Let’s think about each of these cases in turn.</p>&#13;&#13;
<p class="indent">First: what do we do when the paint stroke starts before our stored rightmost position <span class="ent">❸</span>? This paint stroke might give us some new blue units, but only if it extends past our stored rightmost position. If it does, then the new <span epub:type="pagebreak" id="page_293"/>blue units are those between the stored rightmost position and the ending position of the paint stroke <span class="ent">❹</span>.</p>&#13;&#13;
<p class="indent">Second: what do we do when the paint stroke starts after our stored rightmost position <span class="ent">❺</span>? This time, the paint stroke is completely separate from the painting we have done so far; this entire paint stroke is a new blue segment. As such, the new blue units are those between the ending position and starting position of this paint stroke <span class="ent">❻</span>.</p>&#13;&#13;
<p class="indent">Notice in each case that we also correctly update our stored rightmost position so that we’re ready to process any further paint strokes.</p>&#13;&#13;
<p class="indent">That’s a wrap! Guided by our big O analysis, we were able to dismiss an algorithm whose implementation we knew would be too slow. We then thought about a second algorithm—and before implementing it, we knew it would be plenty fast. It’s time to submit our code to the judge and bask in our success.</p>&#13;&#13;
<h3 class="h3" id="ch10lev1sec10">Summary</h3>&#13;&#13;
<p class="noindent">In this chapter, we learned about big O analysis. Big O is an important efficiency building block for further study of algorithm design. You’ll see it everywhere: in tutorials, in books, probably in your next job interview!</p>&#13;&#13;
<p class="indent">We also solved two problems where we needed to design very efficient algorithms. Not only were we able to do that, but we were also able to use big O to obtain a satisfying understanding of exactly why our code was so efficient.</p>&#13;&#13;
<h3 class="h3" id="ch10lev1sec11">Chapter Exercises</h3>&#13;&#13;
<p class="noindent">Here are some exercises for you to try. For each, use big O to determine whether your proposed algorithm is efficient enough to solve the problem within the time limit. You might also like to implement algorithms that you know are going to be too slow. That would give you extra practice solidifying your Python knowledge and confirm that your big O analysis was spot-on!</p>&#13;&#13;
<p class="indent">Some of these problems are quite challenging. There are two reasons. First, you might agree based on your work throughout the book that coming up with <em>any</em> algorithm can be tough. Coming up with a faster algorithm can be even tougher. Second, this is the end of our time together, but only the beginning of the study of algorithms. I hope that these problems both help you appreciate what you’ve accomplished and offer evidence that there’s a lot more beyond this book if you want it.</p>&#13;&#13;
<ol>&#13;&#13;
<li class="noindent">DMOJ problem <span class="literal">dmopc17c1p1</span>, Fujo Neko (The problem talks about using fast input/output. Don’t ignore that!)</li>&#13;&#13;
<li class="noindent">DMOJ problem <span class="literal">coci10c1p2</span>, Profesor</li>&#13;&#13;
<li class="noindent">DMOJ problem <span class="literal">coci19c4p1</span>, Pod starim krovovima (Hint: to maximize the number of empty glasses, you want to put as much liquid as possible in the biggest glasses.)</li>&#13;&#13;
<li class="noindent">DMOJ problem <span class="literal">dmopc20c1p2</span>, Victor’s Moral Dilemma&#13;&#13;
</li>&#13;&#13;
<li class="noindent"><span epub:type="pagebreak" id="page_294"/>DMOJ problem <span class="literal">avocadotrees</span>, Avocado Trees!</li>&#13;&#13;
<li class="noindent">DMOJ problem <span class="literal">coci11c5p2</span>, Eko (Hint: the maximum number of trees is far fewer than the maximum number of heights. Consider each tree from tallest to shortest.)</li>&#13;&#13;
<li class="noindent">DMOJ problem <span class="literal">wac6p2</span>, Cheap Christmas Lights (Hint: don’t try flipping a switch each second—how would you know which one to flip? Instead, store them up, and use them all as soon as you can shut off all the lights that are on.)</li>&#13;&#13;
<li class="noindent">DMOJ problem <span class="literal">ioi98p3</span>, Party Lamps (Hint: all that matters for each button is whether it is pressed an even or odd number of times.)</li>&#13;&#13;
</ol>&#13;&#13;
<h3 class="h3" id="ch10lev1sec12">Notes</h3>&#13;&#13;
<p class="noindent">Longest Scarf is originally from the DMOPC ’14 March Contest. Ribbon Painting is originally from the DMOPC ’20 November Contest.</p>&#13;&#13;
</div></body></html>
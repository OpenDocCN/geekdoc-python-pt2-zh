["```py\nCould you pick me up at Solnce?\n```", "```py\nimport spacy\n\nnlp = spacy.load('en')\n\ndoc = nlp(u'Could you pick me up at Solnce?')\n\n  for ent in doc.ents:\n\n    print(ent.text, ent.label_)\n```", "```py\nSolnce LOC\n```", "```py\n>>> print(spacy.explain('LOC'))\n\n'Non-GPE locations, mountain ranges, bodies of water'\n```", "```py\nCould you send a taxi to Solnce? \n\nIs there a flat rate to the airport from Solnce? \n\nHow long is the wait for a taxi right now?\n```", "```py\ntrain_exams = [\n\n ➊ ('Could you send a taxi to Solnce?', {\n\n     ➋ 'entities': [(25, 32, 'GPE')]\n\n    }),\n\n    ('Is there a flat rate to the airport from Solnce?', {\n\n        'entities': [(41, 48, 'GPE')]\n\n    }),\n\n    ('How long is the wait for a taxi right now?', {\n\n        'entities': []\n\n    })\n\n]\n```", "```py\n   import spacy\n\n   nlp = spacy.load('en')\n\n➊ doc = nlp(u'Could you send a taxi to Solnce? I need to get to Google. Could\n\n   you send a taxi an hour later?')\n\n➋ #f = open(\"test.txt\",\"rb\")\n\n   #contents =f.read()\n\n   #doc = nlp(contents.decode('utf8'))\n\n➌ train_exams = []\n\n➍ districts = ['Solnce', 'Greenwal', 'Downtown']\n\n   for sent in doc.sents:\n\n     entities = [] \n\n     for token in sent:\n\n       if token.ent_type != 0: \n\n        ➎ start = token.idx - sent.start_char\n\n           if token.text in districts:\n\n             entity = (start, start + len(token), 'GPE')\n\n           else:\n\n             entity = (start, start + len(token), token.ent_type_)\n\n           entities.append(entity)\n\n     tpl = (sent.text, {'entities': entities})\n\n  ➏ train_exams.append(tpl)\n```", "```py\n>>> train_exams\n\n[\n\n  ➊ ('Could you send a taxi to Solnce?', {'entities': [(25, 31, 'GPE')]}),\n\n  ➋ ('I need to get to Google.', {'entities': [(17, 23, 'ORG')]}),\n\n  ➌ ('Could you send a taxi an hour later?', {'entities': []})\n\n]\n```", "```py\nother_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n\nnlp.disable_pipes(*other_pipes)\n```", "```py\n   import random\n\n   from spacy.util import minibatch, compounding\n\n➊ optimizer = nlp.entity.create_optimizer()\n\n   for i in range(25):\n\n    ➋ random.shuffle(train_exams)\n\n       max_batch_size = 3\n\n    ➌ batch_size = compounding(2.0, max_batch_size, 1.001)\n\n    ➍ batches = minibatch(train_exams, size=batch_size)\n\n       for batch in batches:\n\n           texts, annotations = zip(*batch)\n\n        ➎ nlp.update(texts, annotations, sgd=optimizer)\n\n➏ ner = nlp.get_pipe('ner')\n\n➐ ner.to_disk('/usr/to/ner')\n```", "```py\n   import spacy\n\n   from spacy.pipeline import EntityRecognizer\n\n➊ nlp = spacy.load('en', disable=['ner'])\n\n➋ ner = EntityRecognizer(nlp.vocab)\n\n➌ ner.from_disk('/usr/to/ner')\n\n➍ nlp.add_pipe(ner, \"custom_ner\")\n\n➎ print(nlp.meta['pipeline'])\n\n➏ doc = nlp(u'Could you pick me up at Solnce?')\n\n   for ent in doc.ents:\n\n     print(ent.text, ent.label_)\n```", "```py\nAvailable pipe components: ['tagger', 'parser', 'custom_ner']\n\nSolnce GPE\n```", "```py\nFind a high paid job with no experience.\n```", "```py\nSELECT * FROM jobs WHERE salary = 'high' AND experience = 'no'\n```", "```py\nimport spacy\n\nnlp = spacy.load('en')\n\ndoc = nlp(u'Find a high paid job with no experience.')\n\nprint([(t.text, t.dep_, t.head.text) for t in doc])\n```", "```py\n[\n\n  ('Find', 'ROOT', 'Find'), \n\n  ('a', 'det', 'job'),\n\n  ('high', 'amod', 'job'),\n\n  ('paid', 'amod', 'job'),\n\n  ('job', 'dobj', 'Find'),\n\n  ('with', 'prep', 'Find'),\n\n  ('no', 'det', 'experience'),\n\n  ('experience', 'pobj', 'with'),\n\n  ('.', 'punct', 'Find')\n\n]\n```", "```py\nTRAINING_DATA = [\n\n    ('find a high paying job with no experience', {\n\n        'heads': [0, 4, 4, 4, 0, 7, 7, 4],\n\n        'deps': ['ROOT', '-', 'QUALITY', 'QUALITY', 'ACTIVITY', '-', 'QUALITY', 'ATTRIBUTE']\n\n    }),\n\n    ('find good workout classes near home', {\n\n        'heads': [0, 4, 4, 4, 0, 6, 4], \n\n        'deps': ['ROOT', '-', 'QUALITY', 'QUALITY', 'ACTIVITY', 'QUALITY', 'ATTRIBUTE']\n\n    })\n]\n```", "```py\nimport spacy\n\nnlp = spacy.load('en')\n\ndoc = nlp(u'find a high paying job with no experience')\n\nheads = []\n\nfor token in doc:\n\n    heads.append(token.head.i)\n\nprint(heads)\n```", "```py\n[0, 4, 4, 4, 0, 4, 7, 5]\n```", "```py\nfind a high paying job without any experience\n```", "```py\n   import spacy\n\n➊ nlp = spacy.blank('en')\n\n➋ parser = nlp.create_pipe('parser')\n\n➌ nlp.add_pipe(parser, first=True)\n\n➍ for text, annotations in TRAINING_DATA:\n\n  ➎ for d in annotations.get('deps', []):\n\n    ➏ parser.add_label(d)\n\n➐ optimizer = nlp.begin_training()\n\n   import random\n\n➑ for i in range(25):\n\n       ➒ random.shuffle(TRAINING_DATA)\n\n       for text, annotations in TRAINING_DATA:\n\n           nlp.update([text], [annotations], sgd=optimizer)\n\n➓ parser.to_disk('/home/oracle/to/parser')\n```", "```py\n   import spacy\n\n   from spacy.pipeline import DependencyParser\n\n➊   nlp = spacy.load('en', disable=['parser'])\n\n➋ parser = DependencyParser(nlp.vocab)\n\n➌ parser.from_disk('/home/oracle/to/parser')\n\n➍ nlp.add_pipe(parser, \"custom_parser\")\n\n   print(nlp.meta['pipeline'])\n\n   doc = nlp(u'find a high paid job with no degree')\n\n➎ print([(w.text, w.dep_, w.head.text) for w in doc if w.dep_ != '-'])\n```", "```py\n['tagger', 'ner', 'custom_parser']\n\n[\n\n  ('find', 'ROOT', 'find'),\n\n  ('high', 'QUALITY', 'job'),\n\n  ('paid', 'QUALITY', 'job'),\n\n  ('job', 'ACTIVITY', 'find'),\n\n  ('no', 'QUALITY', 'degree'),\n\n  ('degree', 'ATTRIBUTE', 'job')\n\n]\n```"]
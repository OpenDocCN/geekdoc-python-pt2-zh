["```py\norders_2022_02_04 = [\n (9423517, '2022-02-04', 9001),\n (4626232, '2022-02-04', 9003),\n (9423534, '2022-02-04', 9001)\n]\norders_2022_02_05 = [\n (9423679, '2022-02-05', 9002),\n (4626377, '2022-02-05', 9003),\n (4626412, '2022-02-05', 9004)\n]\norders_2022_02_06 = [\n (9423783, '2022-02-06', 9002),\n (4626490, '2022-02-06', 9004)\n]\n```", "```py\norders = orders_2022_02_04 + orders_2022_02_05 + orders_2022_02_06\n```", "```py\n[\n (9423517, '2022-02-04', 9001),\n (4626232, '2022-02-04', 9003),\n (9423534, '2022-02-04', 9001),\n (9423679, '2022-02-05', 9002),\n (4626377, '2022-02-05', 9003),\n (4626412, '2022-02-05', 9004),\n (9423783, '2022-02-06', 9002),\n (4626490, '2022-02-06', 9004)\n]\n```", "```py\nextra_fields_9423517 = {\n  'ShippingInstructions' : { 'name'   : 'John Silver',\n                             'Phone' :  [{ 'type' : 'Office', 'number' : '809-123-9309' },\n                                         { 'type' : 'Mobile', 'number' : '417-123-4567' }\n                                        ]}\n}\n```", "```py\norder_9423517 = {'OrderNo':9423517, 'Date':'2022-02-04', 'Empno':9001}\n```", "```py\norder_9423517 = {**order_9423517, **extra_fields_9423517}\n```", "```py\n{\n 'OrderNo': 9423517,\n 'Date': '2022-02-04',\n 'Empno': 9001,\n 'ShippingInstructions': {'name': 'John Silver',\n                          'Phone': [{'type': 'Office', 'number': '809-123-9309'},\n                                    {'type': 'Mobile', 'number': '417-123-4567'}\n                                   ]}\n}\n```", "```py\ndetails = [\n (9423517, 'Jeans', 'Rip Curl', 87.0, 1),\n (9423517, 'Jacket', 'The North Face', 112.0, 1),\n (4626232, 'Socks', 'Vans', 15.0, 1),\n (4626232, 'Jeans', 'Quiksilver', 82.0, 1),\n (9423534, 'Socks', 'DC', 10.0, 2),\n (9423534, 'Socks', 'Quiksilver', 12.0, 2),\n (9423679, 'T-shirt', 'Patagonia', 35.0, 1),\n (4626377, 'Hoody', 'Animal', 44.0, 1),\n (4626377, 'Cargo Shorts', 'Animal', 38.0, 1),\n (4626412, 'Shirt', 'Volcom', 78.0, 1),\n (9423783, 'Boxer Shorts', 'Superdry', 30.0, 2),\n (9423783, 'Shorts', 'Globe', 26.0, 1),\n (4626490, 'Cargo Shorts', 'Billabong', 54.0, 1),\n (4626490, 'Sweater', 'Dickies', 56.0, 1)\n]\n```", "```py\n❶ orders_details = []\n❷ for o in orders:\n  for d in details:\n  ❸ if d[0] == o[0]:\n      orders_details.append(o + ❹ d[1:])\n```", "```py\norders_details =  [[o for o in orders if d[0] == o[0]][0] + d[1:] for d in details]\n```", "```py\n[\n (9423517, '2022-02-04', 9001, 'Jeans', 'Rip Curl', 87.0, 1),\n (9423517, '2022-02-04', 9001, 'Jacket', 'The North Face', 112.0, 1),\n (4626232, '2022-02-04', 9003, 'Socks', 'Vans', 15.0, 1),\n (4626232, '2022-02-04', 9003, 'Jeans', 'Quiksilver', 82.0, 1),\n (9423534, '2022-02-04', 9001, 'Socks', 'DC', 10.0, 2),\n (9423534, '2022-02-04', 9001, 'Socks', 'Quiksilver', 12.0, 2),\n (9423679, '2022-02-05', 9002, 'T-shirt', 'Patagonia', 35.0, 1),\n (4626377, '2022-02-05', 9003, 'Hoody', 'Animal', 44.0, 1),\n (4626377, '2022-02-05', 9003, 'Cargo Shorts', 'Animal', 38.0, 1),\n (4626412, '2022-02-05', 9004, 'Shirt', 'Volcom', 78.0, 1),\n (9423783, '2022-02-06', 9002, 'Boxer Shorts', 'Superdry', 30.0, 2),\n (9423783, '2022-02-06', 9002, 'Shorts', 'Globe', 26.0, 1),\n (4626490, '2022-02-06', 9004, 'Cargo Shorts', 'Billabong', 54.0, 1),\n (4626490, '2022-02-06', 9004, 'Sweater', 'Dickies', 56.0, 1)\n]\n```", "```py\ndetails.append((4626592, 'Shorts', 'Protest', 48.0, 1))\n```", "```py\norders_details = [[o for o in orders if d[0] == o][0] + d[1:] for d in details]\n```", "```py\nIndexError: list index out of range\n```", "```py\norders_details = [[o for o in orders if d[0] in o][0] + d[1:] for d in details\n                ❶ if d[0] in [o[0] for o in orders]]\n```", "```py`` What you want to implement in this case is a right join, assuming the `orders` list is on the left side of the relationship and the `details` list is on the right. Recall that a right join returns all rows from the right dataset and only the matched rows from the left dataset. Update the previous list comprehension as follows:    ```", "```py    Here, you add an `else` clause ❶ to the `if` clause assigned to the `for d in details` loop. This `else` clause works for any `details` row that doesn’t have a matching row in `orders`. It creates a new tuple containing the order number plus two `None` entries to take the place of the missing `orders` fields, and it concatenates that tuple with the row from `details`, yielding a row with the same structure as all the others. So, the generated dataset will include the `details` row that doesn’t have a matched row in `orders` in addition to all the matching rows:    ```", "```py    Now that you have the `orders_details_right` list (the right join of the `orders` and `details` lists), you can total up all the orders and compare the result with the total of just those orders included in the `orders` list. You add up the total of all the orders with Python’s built-in `sum()` function:    ```", "```py    The `for` loop passed as a parameter to `sum()` is somewhat similar to the loop used in a list comprehension in that it allows you to take only the necessary elements with each iteration of the loop. In this particular example, all you need to find with each iteration is `pr*qt`, the multiplication of the Price and Quantity values from the tuple at hand. Since you’re not actually interested in the other values of each tuple, you use `_` placeholders for them in the clause after the `for` keyword.    If you’ve followed the steps presented in this chapter so far, the preceding call will return:    ```", "```py    You can calculate the totals of only those orders that are in the `orders` list with a modified version of the `sum()` call:    ```", "```py    Here you add an `if` clause to the loop to filter out orders that weren’t in the `orders` list ❶. You ignore rows where the Date (`dt`) field contains `None`, indicating that the row’s order information wasn’t retrieved from `orders`. The generated sum will be:    ```", "```py    ## Concatenating NumPy Arrays    Unlike with lists, you can’t use the `+` operator to concatenate NumPy arrays. This is because, as discussed in Chapter 3, NumPy reserves the `+` operator for performing element-wise addition operations on multiple arrays. To concatenate two NumPy arrays, you instead use the `numpy.concatenate()` function.    To demonstrate, we’ll use the `base_salary` array from “Creating a NumPy Array” in Chapter 3, which was created as follows (here, we’ll call it `base_salary1`):    ```", "```py    Recall that each row in the array contains three months’ worth of base salary data for a particular employee. Now suppose you have salary information for two more employees in another array, `base_salary2`:    ```", "```py    You want to store the salary information for all five employees in the same array. To do so, you concatenate `base_salary1` and `base_salary2` using `numpy.concatenate()`, as follows:    ```", "```py    The first parameter is a tuple containing the arrays to be concatenated. The second parameter, `axis`, is critical: it specifies whether the arrays should be concatenated horizontally or vertically, or in other words whether the second array will be added as new rows or new columns. The first axis (axis 0) runs vertically. Thus, `axis=0` instructs the `concatenate()` function to append the rows of `base_salary2` beneath those of `base_salary1`. The resulting array will look as follows:    ```", "```py    Now imagine that the salary information for the next month has come in. You might put these new figures in another NumPy array, as follows:    ```", "```py    If you print the array, you’ll see the following output:    ```", "```py    You need to add this `new_month_salary` array to the `base_salary` array as an extra column. Assuming the order of employees is the same in both arrays, you can use `concatenate()` for this as follows:    ```", "```py    Since axis 1 runs horizontally across the columns, `axis=1` instructs the `concatenate()` function to append the `new_month_salary` array as a column to the right of the `base_salary` array’s columns. Now `base_salary` will look like this:    ```", "```py    ## Combining pandas Data Structures    In Chapter 3, we covered some basic techniques for combining pandas data structures. You saw examples of how Series objects can be combined into a DataFrame and how two DataFrames can be joined on their indexes. You also learned about the different types of joins you can create when merging two DataFrames into a single one, by passing the `how` parameter in to the pandas `join()` or `merge()` method. In this section, you’ll see more examples of how to use this parameter to create nondefault DataFrame joins, such as a right join. Before that, however, you’ll learn to concatenate two DataFrames along a particular axis.    ### Concatenating DataFrames    Like with NumPy arrays, you might need to concatenate two DataFrames along a particular axis, appending either the rows or the columns of one DataFrame to the other. The examples in this section show how to do this with the pandas `concat()` function. Before proceeding to the examples, you’ll need to create two DataFrames to be concatenated.    Using the `jeff_salary`, `nick_salary`, and `tom_salary` lists from earlier in this chapter, you can create a DataFrame using a dictionary, like so:    ```", "```py    Each list becomes a value in the dictionary, which in turn becomes a column in the new DataFrame. The dictionary’s keys, which are the corresponding employee names, become the column labels. Each row of the DataFrame contains all the salary data for a single month. By default the rows are indexed numerically, but it would be more meaningful to index them by month. You can update the indices as follows:    ```", "```py    The `salary_df1` DataFrame will now look like this:    ```", "```py    You may find it more convenient to view the salary data of an employee as a row rather than a column. You make this change with the DataFrame’s `T` property, which is a shorthand for the `DataFrame.``transpose()` method:    ```", "```py    This statement *transposes* the DataFrame, turning its columns into rows and vice versa. The DataFrame is now indexed by employee name and looks as follows:    ```", "```py    Now you need to create another DataFrame with the same columns to be concatenated with `salary_df1`. Following in line with the example of concatenating NumPy arrays, here you create a DataFrame that holds salary data for two more employees:    ```", "```py    You create the DataFrame, set the index, and transpose the rows and columns all in a single statement. The newly created DataFrame will look as follows:    ```", "```py    Now that you’ve created both DataFrames, you’re ready to concatenate them.    #### Concatenation Along Axis 0    The pandas `concat()` function concatenates pandas objects along a certain axis. By default, this function uses axis 0, meaning the rows of the DataFrame that appears second in the argument list will be appended below the rows of the DataFrame that appears first. Thus, to concatenate the `salary_df1` and `salary_df2` DataFrames in this manner, you can call `concat()` without passing the `axis` argument explicitly. All you have to do is specify the names of the DataFrames within square brackets:    ```", "```py    This will generate the following DataFrame:    ```", "```py    As you can see, the `maya` and `john` rows from the second DataFrame have been added beneath the rows from the first DataFrame.    #### Concatenation Along Axis 1    When concatenating along axis 1, the `concat()` function will append the columns of the second DataFrame to the right of the columns of the first one. To illustrate this, you can use `salary_df` from the preceding section as the first DataFrame. For the second DataFrame, create the following structure, which holds two more months’ worth of salary data:    ```", "```py    Now call `concat()`, passing in the two DataFrames and specifying `axis=1` to ensure the concatenation is horizontal:    ```", "```py    The resulting DataFrame will look as follows:    ```", "```py    The salary data from the second DataFrame appears as new columns to the right of the salary data from the first DataFrame.    #### Removing Columns/Rows from a DataFrame    After combining DataFrames, you may need to remove some unnecessary rows or columns. Let’s say, for example, you want to remove the `September` and `October` columns from the `salary_df` DataFrame. You can do this with the `DataFrame.``drop()` method, as follows:    ```", "```py    The first argument takes the names of the columns or rows to be deleted from the DataFrame. Then you use the `axis` argument to specify whether they’re rows or columns. In this example you’re deleting columns, because `axis` is set to `1`.    With `drop()`, you aren’t limited to only deleting the last columns/rows of a DataFrame. You can pass in an arbitrary list of columns or rows to be deleted, as shown here:    ```", "```py    After performing the two previous operations, `salary_df` will appear as follows:    ```", "```py    You’ve removed the columns for September and October and the rows for Nick and Maya.    #### Concatenating DataFrames with a Hierarchical Index    So far you’ve seen examples of concatenating DataFrames with simple indexes. Now let’s consider how to concatenate DataFrames with a MultiIndex. The following example uses the `df_date_region` DataFrame introduced in “Grouping and Aggregating the Data” in Chapter 6. The DataFrame was created as a result of several successive operations and looked as follows:    ```", "```py    To re-create this DataFrame, you don’t have to follow the steps from Chapter 6. Instead, execute the following statement:    ```", "```py    Now you’ll need another DataFrame that’s also indexed by `Date` and `Region`. Create it like this:    ```", "```py    The second DataFrame features the same three dates as the first but has data for a new region, `South`. The challenge when concatenating these two DataFrames is to keep the result sorted by date rather than simply appending the second DataFrame beneath the first one. Here’s how you can do this:    ```", "```py    You start with a `concat()` call that looks the same as it would if it were concatenating DataFrames with single-column indexes. You identify the DataFrames to be combined, and since you omit the `axis` parameter, they’ll be concatenated vertically by default. To sort the rows in the resulting DataFrame by date and region, you then have to call the `sort_index()` method. As a result, you’ll get the following DataFrame:    ```", "```py    As you can see, the rows from the second DataFrame have been integrated among the rows from the first DataFrame, maintaining the top-level grouping by date.    ### Joining Two DataFrames    When you join two DataFrames, you combine each row from one dataset with the matching row(s) from the other, rather than simply appending one DataFrame’s rows or columns beneath or beside the other’s. To review the basics of joining DataFrames, refer back to “Combining DataFrames” in Chapter 3, which covers the different types of joins you can implement. In this section, you’ll go beyond what you learned in Chapter 3 by implementing a right join and a join based on a many-to-many relationship.    #### Implementing a Right Join    A right join takes all the rows from a second DataFrame and combines them with any matching rows from a first DataFrame. As you’ll see, this type of join comes with the possibility that some rows in the resulting DataFrame will have undefined fields, which can lead to unexpected challenges.    To demonstrate, you’ll perform a right join of the `df_orders` and `df_details` DataFrames created from the `orders` and `details` lists introduced in Chapter 6, which you used in the examples in the opening section of this chapter. Create the DataFrames from these lists as follows:    ```", "```py    Recall that each row in the original `details` list has a matching row in the `orders` list. Therefore, the same is true for the `df_details` and `df_orders` DataFrames. To properly illustrate a right join, you need to add one or more new rows to `df_details` that don’t have matches in `df_orders`. You can add a row using the `DataFrame.``append()` method, which takes the row being appended either as a dictionary or a Series.    If you followed along with the example in “Implementing Different Types of Joins for Lists” earlier in this chapter, you’ve already added the following row to the `details` list, and therefore it should already appear in the `df_details` DataFrame. In that case, you can ignore the following append operation. Otherwise, append this row to `df_details` as a dictionary. Note that the value of the new row’s `OrderNo` field can’t be found among the values of the `OrderNo` column in the `df_orders` DataFrame:    ```", "```py    You must set the `ignore_index` parameter to `True` ❶, or you won’t be able to append a dictionary to a DataFrame. Setting this parameter to `True` also resets the DataFrame’s index, maintaining continuous index values (`0, 1, ...`) for the rows.    Next, you join the `df_orders` and `df_details` DataFrames using the `merge()` method. As discussed in Chapter 3, `merge()` provides a convenient way of joining two DataFrames with a common column:    ```", "```py    You use the `how` parameter to specify the type of join—in this example, a right join ❶. With the `left_on` and `right_on` parameters, you specify the columns to join on from the `df_orders` and `df_details` DataFrames, respectively ❷.    The resulting DataFrame will look as follows:    ```", "```py    Since the row newly appended to `df_details` has no matching row in `df_orders`, the corresponding row in the resulting DataFrame contains `NaN` (the default missing value marker) in the `Date` and `Empno` fields. However, this causes a problem: `NaN`s can’t be stored in integer columns, so pandas automatically converts an integer column into a float column when a `NaN` is being inserted. For this reason, the values in the `Empno` column have been converted into floats. You can confirm this using the `df_orders_details_right` DataFrame’s `dtypes` property, which shows the type of each column:    ```", "```py    This will give you the following output:    ```", "```py    As you can see, the `Empno` column is of type `float64`. If you similarly check the `dtypes` property of `df_orders`, you’ll see that the `Empno` column was originally of type `int64`.    Obviously this conversion from integers to floats isn’t desirable behavior: the employee numbers shouldn’t have decimal points! Is there a way to convert the `Empno` column back to integers? One workaround is to replace `NaN`s in this columns with some integer value, say `0`. As long as `0` isn’t someone’s employee ID, this replacement can be perfectly acceptable. Here’s how to implement the change:    ```", "```py    You use the DataFrame’s `fillna()` method, which replaces `NaN`s in the specified column(s) with a specified value. The column and replacement value are defined as a dictionary. In this particular example, you replace ``NaNs in the `Empno` column with `0`s. Then, you convert the type of the column to `int64` using the `astype()` method. Once again, the column and new type are specified as a key-value pair in a dictionary.``   ```", "```py  OrderNo        Date  Empno          Item           Brand  Price  Quantity 0   9423517  2022-02-04   9001         Jeans        Rip Curl   87.0         1 1   9423517  2022-02-04   9001        Jacket  The North Face  112.0         1 `--snip--` 14  4626592         NaN      0        Shorts         Protest   48.0         1 ```", "```py import pandas as pd books = pd.DataFrame({'book_id': ['b1', 'b2', 'b3'],                       'title': ['Beautiful Coding', 'Python for Web                                  Development', 'Pythonic Thinking'],                       'topic': ['programming', 'Python, Web', 'Python']}) authors = pd.DataFrame({'author_id': ['jsn', 'tri', 'wsn'],                         'author': ['Johnson', 'Treloni', 'Willson']}) ```", "```py matching = pd.DataFrame({'author_id': ['jsn', 'jsn','tri', 'wsn'],                            'book_id': ['b1', 'b2', 'b2', 'b3']}) ```", "```py  author_id book_id 0       jsn      b1 1       jsn      b2 2       tri      b2 3       wsn      b3 ```", "```py authorship = books.merge(matching).merge(authors)[['title','topic','author']] ```", "```py  title        topic   author 0            Beautiful Coding  programming  Johnson 1  Python for Web Development  Python, Web  Johnson 2  Python for Web Development  Python, Web  Treloni 3           Pythonic Thinking       Python  Willson ```", "```py` ```"]
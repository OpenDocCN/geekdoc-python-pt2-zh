["```py\nToday, robots can talk to humans using natural language, and they’re getting smarter. Even so, very few people understand how these robots work or how they might use these technologies in their own projects.\n\nNatural language processing (NLP) – a branch of artificial intelligence that helps machines understand and respond to human language – is the key technology that lies at the heart of any digital assistant product.\n```", "```py\n❶ path = \"`/path/to/excerpt.txt`\"\nwith open(❷ path, ❸ \"r\") as ❹ f:\n❺ content = f.read()\nprint(content)\n```", "```py`Using the `with` keyword with `open()` ensures that the `file` object is properly closed when you’re done with it even if an exception has been raised. Otherwise, you would need to call `f.close()` to close the file object and free up the system resources it consumes.    The following snippet reads in the same `/path/to/excerpt.txt` file content line by line, printing out only nonempty lines:    ```", "```py    In this example, you add line numbers to each line with the `enumerate()` function ❶. Then you filter out empty lines with the `strip()` method ❷, which removes any whitespace from the start and end of the string object in each line. The blank second line of the text file contains only one character, a newline, which `strip()` removes. The second line thus becomes an empty string, which the `if` statement will evaluate as false and skip over. The output appears as follows. As you can see, there’s no `Line 1`:    ```", "```py    Rather than print the lines, you can send them to a list by using a list comprehension:    ```", "```py    Each nonempty line will be a separate item in the list.    ### Tabular Data Files    A *tabular* data file is a file in which the data is structured into rows. Each row typically contains information about someone or something, as shown here:    ```", "```py    This is an example of a *flat file*, the most common type of tabular data file. The name comes from the structure: flat files contain simple-structured (flat) records, meaning the records do not contain nested structures, or subrecords. Typically, a flat file is a plaintext file in CSV or tab-separated values (TSV) format, containing one record per line. In *.csv* files, values in a record are separated by commas, while *.tsv* files use tabs as separators. Both formats are widely supported and are often used in data exchange to move tabular data between different applications.    The following is an example of data in CSV format, where the first line contains headers that describe the content of the lines below it. The header descriptions are used as *keys* to the data in the lines that follow. Copy this data into a text editor and save it as *cars.csv*:    ```", "```py    Python’s `open()` function can open *.csv* files in text mode. Then you can load the data into a Python object using a reader function from the `csv` module, as illustrated here:    ```", "```py    The `open()` function returns a `file` object ❶, which you pass to a reader from the `csv` module. In this case, you use `DictReader()` ❷, which maps the data in each row to a dictionary using the corresponding headers from the first line as keys. You append these dictionaries to a list ❸. The resulting list of dictionaries looks like this:    ```", "```py    Alternatively, you might use the `csv` module’s `reader()` method to turn the *.csv* file into a list of lists, where each inner list represents a row, including the header row:    ```", "```py    Here is the output:    ```", "```py    The `csv.DictReader()` and `csv.reader()` methods have an optional `delimiter` parameter, allowing you to specify the character that separates fields in your tabular data file. This parameter defaults to a comma, which is perfect for *.csv* files. However, by setting the parameter to `delimiter = \"\\t\"`, you can read in the tab-separated data of *.tsv* files instead.    ### Binary Files    Text files are not the only types of files you may have to deal with. There are also executable (*.exe*) and image files (*.jpeg*, *.bmp*, and so on), which contain data in binary format, represented as a sequence of bytes. Since these bytes are typically intended to be interpreted as something other than text characters, you can’t open a binary file in text mode to access and manipulate its content. Instead, you must use the `open()` function’s binary mode.    The following example shows how to open an image file in binary mode. An attempt to do this in text mode would result in an error. You can run this code with any *.jpg* file on your computer:    ```", "```py    You instruct the `open()` function to open a file for reading in binary mode by passing in `\"``rb\"` as the second parameter ❶. The retrieved object, like an object retrieved in text mode, has the `read()` method to get the file’s content ❷. Here, the content is retrieved as a `bytes` object. In this example, you simply determine the number of bytes read from the file ❸.    ## Exporting Data to Files    After some processing, you may need to store data to a file so that you can use the data during the next execution of the script or import it into other scripts or applications. You may also need to store information in a file so that you or others can view it. For example, you may want to log information about the errors and exceptions generated by your application for later review.    You can create a new file from your Python script and write data to it, or you can write over the data in an existing file. We’ll explore an example of the latter here. Returning to the example from “Tabular Data Files,” suppose you need to modify a row in the *cars.csv* file, changing the price of a certain car. Recall that the data was read from the *cars.csv* file into a list of dictionaries named `cars`. To see the values of each dictionary in that list, you can run the following loop:    ```", "```py    In the loop body, you call the `values()` method on each dictionary in the list, thus converting the dictionary’s values into a `dict_values` object that can be easily converted into a list. Each list represents a row from the original *.csv* file, as shown here:    ```", "```py    Suppose you need to update the `Price` field in the second row (for the Chevy Venture) and store this change in the original *cars.csv* file. You can make the change as follows:    ```", "```py    First, you need a way to identify the row to be updated. You create a list called `to_update`, including enough of the row’s fields to uniquely identify the row ❶. Then, you specify the new value for the field to be changed as `new_price` ❷. Next, you open the file for writing, passing in the `'w'` flag to the `open()` function ❸. The `w` mode used here will overwrite the existing content of the file. You therefore must define the field names to be sent to the file ❹. These are the names of the keys used in a dictionary representing a car row.    Using the `csv.DictWriter()` function ❺, you create a writer object that will map the dictionaries from the `cars` list onto the output rows to be sent to the *cars.csv* file. In a loop over the dictionaries in the `cars` list ❻, you check if each row matches your specified identifier. If so, you update the row’s `Price` field. Finally, still within the loop, you write each row to the file using the `writer.writerow()` method.    Here’s what you will see in the *cars.csv* file after executing the script:    ```", "```py    As you can see, it looks like the original content, but the value of the `Price` field in the second row has been changed.    ## Accessing Remote Files and APIs    Several third-party Python libraries, including urllib3 and Requests, let you get data from a URL-accessible remote file. You can also use the libraries to send requests to HTTP APIs (those that use HTTP as their transfer protocol), many of which return the requested data in JSON format. Both urllib3 and Requests work by formulating custom HTTP requests based on information you input.    *HTTP (HyperText Transfer Protocol)*, the client/server protocol that forms the foundation of data exchange over the web, is structured as a series of requests and responses. The HTTP messages sent by a client are *requests*, while the answer messages returned by the server are *responses*. For example, whenever you click a link in your browser, the browser, acting as the client, sends an HTTP request to fetch the desired web page from the appropriate web server. You can do the same thing from a Python script. The script, acting as the client, obtains the requested data in the form of a JSON or XML document.    ### How HTTP Requests Work    There are several types of HTTP requests. The most common ones include `GET`, `POST`, `PUT`, and `DELETE`. These are also known as *HTTP request methods*, *HTTP commands*, or just *HTTP verbs*. The HTTP command in any HTTP request defines the action to be performed for a specified resource. For example, a `GET` request retrieves data from a resource, while a `POST` request pushes data to a destination.    An HTTP request also includes the request *target*, usually comprising a URL, and *headers*, the latter being fields that pass additional information along with the request. Some requests also include a *body*, which carries actual request data, such as a form submission. `POST` requests typically include a body, while `GET` requests don’t.    As an example, consider the following HTTP request:    ```", "```py    This request uses the `GET` HTTP command ❶ to retrieve data from the given server (indicated as `Host` ❸) using the specified URI ❷. The remaining lines include other headers specifying additional information. The `User-Agent` request header identifies the application making the request and its version ❹. The `Accept` headers advertise which content types the client is able to understand ❺. The `Connection` header, set to `keep-alive` ❻, instructs the server to establish a persistent connection to the client, which allows for subsequent requests to be made.    In Python, you don’t have to fully understand the internal structure of HTTP requests to send them and receive responses. As you’ll learn in the following sections, libraries like Requests and urllib3 let you manipulate HTTP requests easily and efficiently, just by calling an appropriate method and passing the required parameters in to it.    With the help of the Requests library, the preceding HTTP request can be generated by a simple Python script as follows:    ```", "```py    We’ll discuss the Requests library in detail shortly. For now, notice that the library saves you from having to set the headers of a request manually. It sets the default values behind the scenes, automatically generating a fully formatted HTTP request on your behalf based on just a few lines of code.    ### The urllib3 Library    urllib3 is a URL-handling library that lets you access and manipulate URL-accessible resources such as HTTP APIs, websites, and files. The library is designed to efficiently manipulate HTTP requests, using thread-safe connection pooling to minimize the resources needed on your server’s end. Compared to the Requests library, which we’ll discuss next, urllib3 requires more manual work, but it also gives you more direct control over the requests you prepare, which is useful when, for example, you need to customize pool behavior or explicitly decode HTTP responses.    #### Installing urllib3    Since urllib3 is a dependency of many popular Python packages, like Requests and `pip`, chances are you have it already installed in your Python environment. To check this, try to import it in a Python session. If you get a `ModuleNotFoundError`, you can install it explicitly with this command:    ```", "```py    #### Accessing Files with urllib3    To see how to load data from a URL-accessible file with urllib3, you can use the *excerpt.txt* file you created earlier. To make this file accessible via a URL, you might put it into the document folder of an HTTP server running on your local host. Alternatively, use the following URL to obtain it from the GitHub repository accompanying this book: [https://github.com/pythondatabook/sources/blob/main/ch4/excerpt.txt](https://github.com/pythondatabook/sources/blob/main/ch4/excerpt.txt).    Run the following code, replacing the URL if necessary:    ```", "```py    First you create a `PoolManager` instance ❶, which is how urllib3 makes requests. After that, you make an HTTP request to the specified URL with the `request()` method of `PoolManager` ❷. The `request()` method returns an `HTTPResponse` object. You access the requested data through the `data` attribute of this object ❸. Then you output only nonempty lines, enumerating them at the beginning of each line ❹.    #### API Requests with urllib3    You can also use urllib3 to make requests to HTTP APIs. In the following example, you make a request to the News API ([https://newsapi.org](https://newsapi.org)), which searches for articles from a wide range of news sources, finding those that are most relevant to your request. Like many other APIs today, it requires you to pass in an API key with each request. You can get a developer API key for free at [https://newsapi.org/register](https://newsapi.org/register) after filling in a simple registration form. Then use this code to search for articles about the Python programming language:    ```", "```py    You pass in the search phrase as the `q` parameter in the request URL ❶. The only other required parameter to specify in the request URL is `apiKey` ❷, where you pass in your API key. There are also many other optional parameters. For example, you can specify the news sources or blogs you want articles from. In this particular example, you use `pageSize` to set the number of articles being retrieved to five ❸. The entire list of supported parameters can be found in the News API documentation at [https://newsapi.org/docs](https://newsapi.org/docs).    The `data` attribute of the `HTTPResponse` object returned by `request()` is a JSON document in the form of a `bytes` object. You decode it to a string, which you then pass to the `json.loads()` method to convert it into a dictionary ❹. To see how the data is structured in this dictionary, you might output it, but this step is omitted in this listing. If you looked at the output, you’d see that information about the articles can be found in the list called `articles` within the returned document, and each record in this list has the fields `title`, `publishedAt`, and `url`.    Using that information, you can print the retrieved list of articles in a more readable format, producing something like this:    ```", "```py    This example illustrated how to integrate the News API into a Python application using direct HTTP requests via the urllib3 library. An alternative would be to use the unofficial Python client library covered at [https://newsapi.org/docs/client-libraries/python](https://newsapi.org/docs/client-libraries/python).    ### The Requests Library    Requests is another popular URL-handling library that allows you to easily send HTTP requests. Requests uses urllib3 under the hood and makes it even easier to make requests and retrieve data. You can install the Requests library with the `pip` command:    ```", "```py    HTTP verbs are implemented as the library’s methods (for example, `requests.get()` for an HTTP `GET` request). Here’s how to remotely access *excerpt.txt* with Requests. Replace the URL with the file’s GitHub link if necessary:    ```", "```py    You make an HTTP `GET` request using the `requests.get()` method, passing the file’s URL as the parameter ❶. The method returns a `Response` object that includes the retrieved content in the `text` attribute ❷. Requests automatically decodes the retrieved content, making knowledgeable guesses about the encoding, so you don’t have to do it manually. Just as in the urllib3 example, you output only nonempty lines, adding a line number at the beginning of each ❸.    ## Moving Data to and from a DataFrame    pandas comes with a range of reader methods, each of which is designed to load data in a certain format and/or from a certain type of source. These methods allow you to load tabular data into a DataFrame with the help of a single call, thus making the imported dataset immediately ready for analysis. pandas also has methods for converting DataFrame data into other formats, such as JSON. This section explores examples of these methods for moving data to or from a DataFrame. We’ll also consider the pandas-datareader library, which is helpful for loading data from various online sources into pandas DataFrames.    ### Importing Nested JSON Structures    Since JSON has become the de facto standard for data interchange between applications, it’s important to have a way to quickly import a JSON document and convert it to a Python data structure. In the previous chapter, you saw an example of loading a simple, non-nested JSON structure into a DataFrame with the pandas `read_json()` reader. In this section, you’ll learn how to load a more complex, nested JSON document, like this one:    ```", "```py    As you can see, each entry in the JSON document begins with a simple-structured key-value pair with the key `Emp`, followed by a nested structure with the key `POs`. You can convert that hierarchical JSON structure into a tabular pandas DataFrame using the pandas library’s `json_normalize()` reader method, which takes a nested structure and flattens, or *normalizes*, it into a simple table. Here’s how:    ```", "```py    Apart from the JSON sample ❶ to be processed by `json_normalize()`, you also specify `POs` as the nested array to be flattened ❷ and `Emp` as the field to be used as part of the complex index in the resulting table ❸. In the same line of code, you set two columns as the index: `Emp` and `Pono` ❹. As a result, you will see the following pandas DataFrame:    ```", "```py    ### Converting a DataFrame to JSON    In practice, you may often need to perform the reverse operation, converting a pandas DataFrame into JSON. The following code converts our DataFrame back to the JSON sample from which it was originally generated:    ```", "```py    You start by dropping the two-column index of the DataFrame to make `Emp` and `Pono` regular columns ❶. Then, you use a composite one-liner to convert the DataFrame to a JSON document. First you apply a `groupby` operation to the DataFrame, grouping the rows by the `Emp` column ❷. You use `groupby()` in combination with `apply()` to apply a lambda function to each record in each group ❸. In the lambda expression, you specify the list of fields that you want to see in a row of the nested array associated with each `Emp` record. You use the `DataFrame.to_dict()` method with the `records` parameter to format the fields in the array as follows: `[{``column``:``value``}, ... , {``column``:``value``}]`, where each dictionary represents an order associated with a given employee.    At this point, you have a Series object with the index `Emp` and a column containing an array of orders associated with an employee. To give this column a name (in this case, `POs`), you need to convert the Series to a DataFrame. One simple way to do this is with `reset_index()` ❹. In addition to converting the Series to a DataFrame, `reset_index()` changes `Emp` from an index to a regular column, which will be important when you convert the DataFrame to JSON format. Finally, you explicitly set the name of the column containing the nested array (`POs`) using the DataFrame’s `rename()` method ❺ and turn the revised DataFrame into JSON ❻.    The content of `json_doc` looks as follows:    ```", "```py    To improve readability, you might print it out using the following command:    ```", "```py    ### Loading Online Data into a DataFrame with pandas-datareader    Several third-party libraries come with pandas-compatible reader methods for accessing data from a variety of online sources, such as Quandl ([https://data.nasdaq.com](https://data.nasdaq.com)) and Stooq ([https://stooq.com](https://stooq.com)). The most popular of these is pandas-datareader. At the time of writing, this library included 70 methods, each designed to load data from a certain source into a pandas DataFrame. Many of the library’s methods are wrappers for finance APIs, allowing you to easily get financial data in pandas format.    #### Installing pandas-datareader    Enter this command to install pandas-datareader:    ```", "```py    For descriptions of the library’s reader methods, consult the pandas-datareader documentation at [https://pandas-datareader.readthedocs.io/en/latest/remote_data.html](https://pandas-datareader.readthedocs.io/en/latest/remote_data.html). You can also print a list of the available methods with Python’s `dir()` function:    ```", "```py    #### Obtaining Data from Stooq    In the following example, you use the `get_data_stooq()` method to obtain S&P 500 index data for a specified period:    ```", "```py    The `get_data_stooq()` method obtains data from Stooq, a free site that provides information on a number of market indexes. Pass in the ticker of the market index you want as the first parameter. The available options can be found at [https://stooq.com/t](https://stooq.com/t).    The obtained S&P 500 index data will typically appear in this format:    ```", "```py    The `Date` column is set as the DataFrame’s index by default.    ## Summary    In this chapter, you learned how to obtain data from different sources and bring it into your Python scripts for further processing. In particular, you saw how to import data from files using Python’s built-in functions, how to send HTTP requests from your Python scripts to online APIs, and how to take advantage of pandas readers to acquire different forms of data from various sources. You also learned how to export data to files and how to convert DataFrame data into JSON.```"]
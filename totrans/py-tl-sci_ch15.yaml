- en: '**15'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**15**'
- en: THE SCIENTIFIC LIBRARIES**
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: THE SCIENTIFIC LIBRARIES**
- en: '![image](../images/common.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/common.jpg)'
- en: In this chapter, we’ll look at high-level summaries of the core Python libraries
    for mathematics, data analysis, machine learning, deep learning, computer vision,
    language processing, web scraping, and parallel processing ([Table 15-1](ch15.xhtml#ch015tab1)).
    We’ll also look at some guidelines for choosing among competing products. In subsequent
    chapters, we’ll dive deeper into the functionality of several of these libraries
    and then apply them in real-world applications.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将概述Python中用于数学、数据分析、机器学习、深度学习、计算机视觉、语言处理、网页抓取和并行处理的核心库的高级总结（见[表15-1](ch15.xhtml#ch015tab1)）。我们还将探讨一些选择竞争产品的指南。在接下来的章节中，我们将深入研究这些库的功能，并将其应用于实际应用中。
- en: '[Table 15-1](ch15.xhtml#ch015tab1) organizes these libraries into subcategories,
    lists their websites, and provides a brief description of each. As these are popular
    and, in many cases, mature libraries, you should have no problem finding additional
    guidance for each online and in bookstores.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[表15-1](ch15.xhtml#ch015tab1) 将这些库组织为子类别，列出它们的网站，并提供简短的描述。由于这些是流行且在许多情况下成熟的库，你应该能轻松找到每个库的更多指导，既可以在线查阅，也可以在书店找到相关书籍。'
- en: '**Table 15-1:** Essential Python Scientific Libraries for Python'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '**表15-1：** Python的科学计算库'
- en: '| **Task** | **Library** | **Description** | **Website** |'
  id: totrans-6
  prefs: []
  type: TYPE_TB
  zh: '| **任务** | **库** | **描述** | **网站** |'
- en: '| --- | --- | --- | --- |'
  id: totrans-7
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Math and data analysis | NumPy | Numerical computing tools for arrays | *[https://numpy.org/](https://numpy.org/)*
    |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
  zh: '| Math and data analysis | NumPy | 数组的数值计算工具 | *[https://numpy.org/](https://numpy.org/)*
    |'
- en: '| SciPy Library | Friendly and efficient numerical routines | *[https://www.scipy.org/](https://www.scipy.org/)*
    |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| SciPy Library | 友好且高效的数值例程 | *[https://www.scipy.org/](https://www.scipy.org/)*
    |'
- en: '| SymPy | Symbolic math/computer algebra tools | *[https://www.sympy.org/](https://www.sympy.org/)*
    |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| SymPy | 符号数学/计算机代数工具 | *[https://www.sympy.org/](https://www.sympy.org/)*
    |'
- en: '| Pandas | Data manipulation, analysis, and visualization tools | *[http://pandas.pydata.org/](http://pandas.pydata.org/)*
    |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| Pandas | 数据操作、分析和可视化工具 | *[http://pandas.pydata.org/](http://pandas.pydata.org/)*
    |'
- en: '| Machine and deep learning | Scikit-learn | General-purpose machine learning
    toolkit | *[https://scikit-learn.org/](https://scikit-learn.org/)* |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| Machine and deep learning | Scikit-learn | 通用机器学习工具包 | *[https://scikit-learn.org/](https://scikit-learn.org/)*
    |'
- en: '| TensorFlow | Symbolic math library for deep learning neural nets | *[https://www.tensorflow.org/](https://www.tensorflow.org/)*
    |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| TensorFlow | 深度学习神经网络的符号数学库 | *[https://www.tensorflow.org/](https://www.tensorflow.org/)*
    |'
- en: '| Keras | Friendlier wrapper for TensorFlow | *[https://keras.io/](https://keras.io/)*
    |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| Keras | 更友好的TensorFlow封装 | *[https://keras.io/](https://keras.io/)* |'
- en: '| PyTorch | Fast and efficient artificial neural networks | *[https://pytorch.org/](https://pytorch.org/)*
    |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| PyTorch | 快速高效的人工神经网络 | *[https://pytorch.org/](https://pytorch.org/)* |'
- en: '| Image processing | OpenCV | Real-time computer vision library | *[https://opencv.org/](https://opencv.org/)*
    |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| Image processing | OpenCV | 实时计算机视觉库 | *[https://opencv.org/](https://opencv.org/)*
    |'
- en: '| Scikit-image | Scientific image processing and analysis tools | *[https://scikit-image.org/](https://scikit-image.org/)*
    |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| Scikit-image | 科学图像处理和分析工具 | *[https://scikit-image.org/](https://scikit-image.org/)*
    |'
- en: '| Pillow | Basic image processing tools | *[https://python-pillow.org/](https://python-pillow.org/)*
    |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| Pillow | 基本图像处理工具 | *[https://python-pillow.org/](https://python-pillow.org/)*
    |'
- en: '| Language processing | NLTK | Symbolic and statistical language processing
    library | *[http://www.nltk.org/](http://www.nltk.org/)* |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| Language processing | NLTK | 符号和统计语言处理库 | *[http://www.nltk.org/](http://www.nltk.org/)*
    |'
- en: '| spaCy | Fast production grade language processing library | *[https://spacy.io/](https://spacy.io/)*
    |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| spaCy | 快速的生产级语言处理库 | *[https://spacy.io/](https://spacy.io/)* |'
- en: '| Helper libraries | requests | Webscraper for HTTP requests | *[https://pypi.org/project/requests/](https://pypi.org/project/requests/)*
    |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| Helper libraries | requests | HTTP请求的网页抓取工具 | *[https://pypi.org/project/requests/](https://pypi.org/project/requests/)*
    |'
- en: '| BeautifulSoup | Tools to extract text from HTML and XML files | *[https://www.crummy.com/software/](https://www.crummy.com/software/)*
    |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| BeautifulSoup | 从HTML和XML文件中提取文本的工具 | *[https://www.crummy.com/software/](https://www.crummy.com/software/)*
    |'
- en: '| re | Library for working with regular expressions | *[https://docs.python.org/3/library/re.html](https://docs.python.org/3/library/re.html)*
    |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| re | 正则表达式库 | *[https://docs.python.org/3/library/re.html](https://docs.python.org/3/library/re.html)*
    |'
- en: '| Dask | Library for parallel computing with Python | *[https://dask.org/](https://dask.org/)*
    |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| Dask | 用于 Python 的并行计算库 | *[https://dask.org/](https://dask.org/)* |'
- en: '| Spark | “Heavier” alternative to Dask for Big Data | *[https://spark.apache.org/](https://spark.apache.org/)*
    |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| Spark | 针对大数据的“更重”替代 Dask | *[https://spark.apache.org/](https://spark.apache.org/)*
    |'
- en: '**The SciPy Stack**'
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**SciPy 堆栈**'
- en: The SciPy stack of open source libraries comes preinstalled on Anaconda and
    includes NumPy, the SciPy library, Matplotlib, IPython, SymPy, and pandas ([Figure
    15-1](ch15.xhtml#ch015fig1)). These have been called “the bedrock of number-crunching
    and visualization in Python” and are among the most used scientific libraries.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: SciPy 开源库栈预先安装在 Anaconda 中，并包含 NumPy、SciPy 库、Matplotlib、IPython、SymPy 和 pandas（见[图
    15-1](ch15.xhtml#ch015fig1)）。这些被称为“Python 数值计算和可视化的基石”，并且是使用最广泛的科学库之一。
- en: '![Image](../images/15fig01.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/15fig01.jpg)'
- en: '*Figure 15-1: The core components of the SciPy ecosystem (courtesy of [https://SciPy.org](https://SciPy.org))*'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 15-1：SciPy 生态系统的核心组件（图片来源：[https://SciPy.org](https://SciPy.org))*'
- en: In the following sections, we take a high-level look at these libraries. Then,
    in later chapters, we take deeper dives into NumPy, Matplotlib, and pandas.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将对这些库进行高层次的介绍。然后，在后续章节中，我们将深入探讨 NumPy、Matplotlib 和 pandas。
- en: '***NumPy***'
  id: totrans-31
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***NumPy***'
- en: Short for *Numerical Python*, NumPy is Python’s dedicated library for performing
    numerical calculations. It supports the creation of large, multidimensional arrays
    and matrices and provides a large collection of high-level mathematical functions
    to operate on these arrays. NumPy is considered a basic package for scientific
    computing with Python, but I would also call it *foundational* because many other
    important libraries such as pandas, Matplotlib, SymPy, and OpenCV are built on
    top of it.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy 是 *Numerical Python*（数值 Python）的缩写，是 Python 专门用于执行数值计算的库。它支持创建大型的多维数组和矩阵，并提供了大量用于操作这些数组的高级数学函数。NumPy
    被认为是 Python 科学计算的基础包，但我也会称其为 *基础性* 因为许多其他重要库，如 pandas、Matplotlib、SymPy 和 OpenCV，都是建立在它之上的。
- en: NumPy includes data structures, algorithms, and “glue” needed for most scientific
    applications involving numerical data. Operations in NumPy are faster and more
    efficient than competing functionality in the Standard Library that ships with
    Python. Having knowledge of NumPy is important to being able to use most, if not
    all, scientific Python packages, so we’ll take a closer look at it in [Chapter
    18](ch18.xhtml).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy 包含了大多数涉及数值数据的科学应用所需的数据结构、算法和“粘合剂”。NumPy 中的操作比 Python 自带标准库中的同类功能更快、更高效。掌握
    NumPy 知识对使用大多数（如果不是全部的话）科学 Python 包至关重要，因此我们将在[第18章](ch18.xhtml)中对其进行更详细的探讨。
- en: '***SciPy***'
  id: totrans-34
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***SciPy***'
- en: The scientific library *SciPy* is designed for mathematics, science, and engineering,
    and addresses many standard problem domains in scientific computing. It’s built
    on and supplements NumPy and provides many user-friendly and efficient numerical
    routines, such as routines for numerical integration, interpolation, optimization,
    linear algebra, statistics, fast Fourier transforms, signal and image processing,
    and the solving of differential equations. It extends the linear algebra routines
    and matrix decompositions provided in NumPy and provides access to many physical
    constants and conversion factors.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 科学库 *SciPy* 旨在解决数学、科学和工程领域的问题，涵盖了科学计算中许多标准问题领域。它是建立在 NumPy 之上并对其进行了扩展，提供了许多用户友好且高效的数值例程，如数值积分、插值、优化、线性代数、统计学、快速傅里叶变换、信号与图像处理以及求解微分方程等功能。它扩展了
    NumPy 提供的线性代数例程和矩阵分解功能，并提供了对许多物理常数和转换因子的访问。
- en: '***SymPy***'
  id: totrans-36
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***SymPy***'
- en: '*SymPy* is an open source library for symbolic mathematics. Its goal is to
    be a full-featured *computer algebra system (CAS)*.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '*SymPy* 是一个用于符号数学的开源库。它的目标是成为一个功能齐全的 *计算机代数系统（CAS）*。'
- en: Whereas most computer algebra systems invent their own language, SymPy is written
    and executed in Python. This makes it easier for those familiar with Python to
    use. It also allows you to use it as a library. So, in addition to using SymPy
    in an interactive environment, you can import it into your own Python application,
    where you can automate or extend it.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然大多数计算机代数系统发明了自己的语言，但 SymPy 是用 Python 编写和执行的。这使得熟悉 Python 的人可以更轻松地使用它。它还允许你将其作为库使用。因此，除了在交互式环境中使用
    SymPy 之外，你还可以将它导入到你自己的 Python 应用程序中，进行自动化或扩展。
- en: SymPy gives you the ability to do all sorts of computations symbolically. It
    can simplify expressions; compute derivatives, integrals, and limits; solve equations;
    work with matrices, and more. It includes packages for plotting, printing (including
    pretty printed output of math formulas or LaTeX), code generation, physics, statistics,
    combinatorics, number theory, geometry, logic, and more.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: SymPy让你能够以符号的方式进行各种计算。它可以简化表达式；计算导数、积分和极限；解方程；处理矩阵等等。它包括用于绘图、打印（包括数学公式或LaTeX的漂亮打印输出）、代码生成、物理学、统计学、组合数学、数论、几何学、逻辑学等方面的软件包。
- en: 'A simple way to appreciate SymPy is to consider the irrational number √8, calculated
    with Python’s basic `math` library:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 以一种简单的方式理解SymPy，可以考虑使用Python的基本`math`库计算无理数√8：
- en: '[PRE0]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The output is a truncated numeric answer, as √8 can’t be represented by a finite
    number. With SymPy, the square roots of numbers that are not perfect squares are
    left unevaluated by default; thus, the symbolic results are symbolically simplified
    by default (as 2 × √2):'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一个截断的数字答案，因为√8不能用有限的数字表示。使用SymPy时，对于非完美平方的数字，默认不对其进行计算；因此，符号结果默认会进行符号化简化（例如2
    × √2）：
- en: '[PRE1]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: As stated previously, SymPy includes lots of useful methods, such as for solving
    equations. For example, to solve *x*2 – 2 = 0
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，SymPy包含许多有用的方法，例如解方程。例如，解*x*² - 2 = 0。
- en: '[PRE2]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'SymPy conveniently comes with its own plotting modules:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: SymPy方便地提供了自己的绘图模块：
- en: '[PRE3]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![Image](../images/f0403-01.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0403-01.jpg)'
- en: To see more of SymPy’s capability, go to *[https://docs.sympy.org/latest/tutorial/index.html](https://docs.sympy.org/latest/tutorial/index.html)*.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看更多SymPy的功能，请访问*[https://docs.sympy.org/latest/tutorial/index.html](https://docs.sympy.org/latest/tutorial/index.html)*。
- en: You might be wondering, why use SymPy when there’s NumPy and the SciPy Library?
    The short answer is that SymPy is for working with algebra and doing theoretical
    math or physics; NumPy and SciPy are for performing analyses on actual data.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会问，既然已经有NumPy和SciPy库，为什么还要使用SymPy？简短的回答是，SymPy用于处理代数和进行理论数学或物理学计算；而NumPy和SciPy用于对实际数据进行分析。
- en: '***pandas***'
  id: totrans-51
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***pandas***'
- en: The *Python Data Analysis* library is the most popular open source library for
    data science. Called *pandas* for short, it contains data structures and manipulation
    tools designed to facilitate data extraction, cleaning, analysis, and visualization.
    It adopts significant parts of NumPy and works well with other libraries like
    SciPy, statsmodels, scikit-learn, and Matplotlib.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python数据分析*库是最流行的开源数据科学库。简称*pandas*，它包含了旨在促进数据提取、清洗、分析和可视化的数据结构和操作工具。它采用了NumPy的许多重要部分，并与其他库如SciPy、statsmodels、scikit-learn和Matplotlib兼容。'
- en: In addition, pandas is very useful for working with tabular data and common
    data sources, such as SQL relational databases and Excel spreadsheets. It’s especially
    well suited for handling time-indexed data and incorporates plotting functionality—based
    on Python’s core visualization library, Matplotlib—that makes it easy to visualize
    your data.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，pandas对于处理表格数据和常见数据源，如SQL关系型数据库和Excel电子表格，非常有用。它尤其适用于处理时间索引数据，并包含基于Python核心可视化库Matplotlib的绘图功能，方便你可视化数据。
- en: 'The most common data structure in pandas is the *DataFrame*, a tabular format
    similar to a spreadsheet, with columns, rows, and data. You can construct DataFrames
    from many types of input, in the case shown in the following example, from a list
    of lists using Jupyter Notebook:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: pandas中最常见的数据结构是*DataFrame*，它是一种类似于电子表格的表格格式，包含列、行和数据。你可以从多种类型的输入构建DataFrame，在以下示例中，通过使用Jupyter
    Notebook从列表列表构建：
- en: '[PRE4]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '|  | Element | Symbol | Atomic # |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '|  | 元素 | 符号 | 原子序数 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 0 | Carbon | C | 6 |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 碳 | C | 6 |'
- en: '| 1 | Nitrogen | N | 7 |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 氮 | N | 7 |'
- en: '| 2 | Oxygen | O | 8 |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 氧 | O | 8 |'
- en: With DataFrames, you have the equivalent of an Excel spreadsheet or SQL table
    in Python. DataFrames, however, tend to be faster, easier to use, and more powerful
    because they’re an integral part of the Python and NumPy ecosystems.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 使用DataFrame时，你可以在Python中拥有类似Excel电子表格或SQL表格的功能。然而，DataFrame通常更快、更易用且更强大，因为它们是Python和NumPy生态系统的核心组成部分。
- en: The pandas library is one of the most important for scientists, who, as the
    old joke goes, spend 80 percent of their time finding and preparing data and the
    other 20 percent complaining about it! Mastering pandas is therefore essential,
    and you’ll get a good start in [Chapter 20](ch20.xhtml), which covers some of
    the basics.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: pandas 库是科学家们最重要的库之一，正如古谚所说，他们花费80%的时间寻找和准备数据，另外20%的时间抱怨它！因此，掌握 pandas 是至关重要的，您将在
    [第20章](ch20.xhtml) 中获得良好的起点，该章节涵盖了一些基础知识。
- en: '**NOTE**'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*Other libraries are beginning to challenge pandas by preserving its simplicity
    while addressing some of its efficiency issues such as the inability to scale
    projects through use of multicore processing, GPU processing, or cluster computing.
    Modin provides full drop-in replacement for pandas, letting you use pandas with
    more access to optimizations. Vaex ([https://vaex.io/](https://vaex.io/)) helps
    you to explore and visualize large datasets on normal hardware by using efficient
    lazy evaluation and clever memory mapping. Dask ([https://dask.org/](https://dask.org/))
    implements many of the same methods of pandas and offers more functionality than
    Modin or Vaex. Dask is more complex to use but helps you handle huge datasets
    and use computer clusters for improved processing speeds.*'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '*其他库开始挑战 pandas，保持其简单性的同时解决了一些效率问题，如无法通过多核处理、GPU处理或集群计算来扩展项目。Modin 提供了完整的 pandas
    替代方案，让您可以更多地优化使用 pandas。Vaex ([https://vaex.io/](https://vaex.io/)) 使用高效的惰性评估和巧妙的内存映射，帮助您在普通硬件上探索和可视化大型数据集。Dask
    ([https://dask.org/](https://dask.org/)) 实现了许多与 pandas 相同的方法，并提供比 Modin 或 Vaex
    更多的功能。Dask 使用更复杂，但可以帮助您处理大型数据集，并利用计算集群提高处理速度。*'
- en: '**A General Machine Learning Library: scikit-learn**'
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**通用机器学习库：scikit-learn**'
- en: Part of data analysis is the construction and validation of *predictive models*
    that use known results to forecast future outcomes or explain past behaviors.
    This falls under the category of *machine learning*, itself a category of artificial
    intelligence ([Figure 15-2](ch15.xhtml#ch015fig2)). Machine learning deals with
    methods for pattern recognition in datasets, making it possible for machine learning
    algorithms to improve automatically through experience. These algorithms build
    *supervised* models based on training data, and *unsupervised* models, in which
    the model “discovers” patterns on its own. The algorithms can use these models
    to make decisions without being explicitly programmed to do so.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 数据分析的一部分是构建和验证*预测模型*，这些模型利用已知结果预测未来结果或解释过去行为。这属于*机器学习*范畴，本身又是人工智能的一个类别（[图 15-2](ch15.xhtml#ch015fig2)）。机器学习涉及数据集中模式识别的方法，使得机器学习算法能够通过经验自动改进。这些算法根据训练数据构建*监督*模型，以及*无监督*模型，在后者中，模型可以自行“发现”模式。这些算法可以利用这些模型做出决策，而无需显式编程。
- en: The open source scikit-learn library is built on NumPy, SciPy, and Matplotlib.
    Considered the premier general-purpose machine learning toolkit for Python programmers,
    scikit-learn has been critical for enabling Python to be a productive data science
    tool. Preinstalled on Anaconda, scikit-learn is also easy to use, making it a
    great entry point to machine learning.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 开源的 scikit-learn 库建立在 NumPy、SciPy 和 Matplotlib 的基础之上。被认为是Python程序员的首选通用机器学习工具包，scikit-learn
    对使Python成为高效的数据科学工具至关重要。在 Anaconda 上预安装的 scikit-learn 也很易于使用，使其成为机器学习的良好起点。
- en: '![Image](../images/15fig02.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/15fig02.jpg)'
- en: '*Figure 15-2: Some of the branches of artificial intelligence*'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 15-2：一些人工智能分支*'
- en: As shown in [Figure 15-3](ch15.xhtml#ch015fig3), the scikit-learn library includes
    packages for predictive data analysis, including classification (support for vector
    machines, random forests, nearest neighbors, and so on), regression, clustering
    (*k*-means, spectral, and so forth), dimensionality reduction (principal component
    analysis, matrix factorization, feature selection, and more), preprocessing (feature
    extraction and normalization), and model selection (metrics, cross-validation,
    and grid search). Both supervised and unsupervised methods are addressed. You
    can get a feel for how scikit-learn works in [Chapter 20](ch20.xhtml).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如 [图 15-3](ch15.xhtml#ch015fig3) 所示，scikit-learn 库包括用于预测数据分析的软件包，包括分类（支持向量机、随机森林、最近邻等）、回归、聚类（*k*-means、谱聚类等）、降维（主成分分析、矩阵分解、特征选择等）、预处理（特征提取和归一化）以及模型选择（度量、交叉验证和网格搜索）。既涵盖了监督方法也涵盖了无监督方法。您可以在
    [第20章](ch20.xhtml) 中了解 scikit-learn 的工作原理。
- en: '![Image](../images/15fig03.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/15fig03.jpg)'
- en: '*Figure 15-3: Examples of regression, classification, and clustering analysis
    using scikit-learn (courtesy of [https://scikit-learn.org/](https://scikit-learn.org/))*'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '*图15-3：使用scikit-learn进行回归、分类和聚类分析的示例（由[https://scikit-learn.org/](https://scikit-learn.org/)提供）*'
- en: '**NOTE**'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*Complementing scikit-learn is a library called statsmodels ([https://www.statsmodels.org/](https://www.statsmodels.org/)),
    which contains algorithms for classical statistics and economics. Whereas scikit-learn
    is more concerned with predictions, statsmodels is more about statistical inference,
    p-values, and uncertainty estimates.*'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '*作为scikit-learn的补充，有一个名为statsmodels的库（[https://www.statsmodels.org/](https://www.statsmodels.org/)），其中包含经典统计和经济学算法。而scikit-learn更关注预测，statsmodels则更关注统计推断、p值和不确定性估计。*'
- en: '**The Deep Learning Frameworks**'
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**深度学习框架**'
- en: '*Deep learning* is a branch of machine learning that goes beyond the methods
    incorporated in scikit-learn. Rather than modify parameters of a fixed model through
    structured training sets *intended* for learning, deep learning networks are capable
    of learning *unsupervised* from data that is unstructured or unlabeled. Thus,
    deep learning systems imitate the nonlinear workings of the human brain in processing
    data and creating patterns for use in decision making.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '*深度学习*是机器学习的一个分支，超越了包含在scikit-learn中的方法。与通过结构化训练集修改固定模型的参数不同，深度学习网络能够从未经处理或未标记的数据中进行*无监督*学习。因此，深度学习系统模仿人脑在处理数据和生成决策模式时的非线性工作方式。'
- en: The best-known of these systems are referred to as *artificial neural networks
    (ANNs)*. These networks generally require very complex mathematical operations
    with millions to billions of parameters and are only possible thanks to the speed
    and efficiency of graphics processing units (GPUs) developed for videogames. Example
    applications include self-driving cars and Google Translate.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这些系统中最知名的被称为*人工神经网络（ANNs）*。这些网络通常需要进行非常复杂的数学运算，涉及百万到数十亿个参数，仅有得益于为视频游戏开发的图形处理单元（GPUs）的速度和效率才有可能实现。示例应用包括自动驾驶汽车和谷歌翻译。
- en: 'Python libraries designed for deep learning are referred to as deep learning
    *frameworks*. These interfaces abstract away the details of the underlying algorithms,
    allowing you to define models quickly and easily using collections of prebuilt
    and optimized components. Of the many frameworks available, three dominate: TensorFlow,
    Keras, and PyTorch.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 专为深度学习设计的Python库被称为深度学习*框架*。这些接口抽象了底层算法的细节，允许您使用预构建和优化的组件快速轻松地定义模型。在众多可用的框架中，TensorFlow、Keras和PyTorch三者占据主导地位。
- en: Although these three systems are still evolving, they already have good documentation,
    training sets, tutorials, and support, and you can count on all three to provide
    robust deep learning solutions.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这三个系统仍在不断发展，它们已经拥有了良好的文档、训练集、教程和支持，您可以信赖它们提供强大的深度学习解决方案。
- en: '***TensorFlow***'
  id: totrans-80
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***TensorFlow***'
- en: The oldest, most popular deep learning framework for Python is an open source
    library called *TensorFlow*. Created by Google to support its large-scale applications,
    TensorFlow is an end-to-end platform for multiple machine learning tasks. Thanks
    to its large user base, good documentation, and ability to run on all major operating
    systems, TensorFlow is popular in industry and academia, across a variety of domains.
    You can find many articles on the web to help you implement solutions to complex
    problems. You can also complete a certification program online.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: Python的最古老、最流行的深度学习框架是一个名为*TensorFlow*的开源库。由谷歌创建以支持其大规模应用，TensorFlow是一个用于多个机器学习任务的端到端平台。由于其庞大的用户群体、良好的文档和在所有主要操作系统上的运行能力，TensorFlow在工业和学术界广受欢迎，跨越各种领域。您可以在网上找到许多文章来帮助您实现复杂问题的解决方案。您还可以在线完成认证程序。
- en: TensorFlow is very powerful and can handle large datasets efficiently by distributing
    the computations across hundreds of mutli-GPU servers. It provides lots of functionality,
    including a tool called *TensorBoard* that helps you to create beautiful visualizations
    that are easy to understand and from which you can derive useful analytics.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow非常强大，能够通过在数百个多GPU服务器上分布计算高效处理大型数据集。它提供了许多功能，包括一个名为*TensorBoard*的工具，帮助您创建易于理解的漂亮可视化，并从中获得有用的分析。
- en: '***Keras***'
  id: totrans-83
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***Keras***'
- en: Although TensorFlow is well documented and comes with walkthroughs to guide
    you, it’s still considered one of the most challenging deep learning frameworks,
    with an intricate interface and a steep learning curve. Fortunately, François
    Challet, a Google engineer, has written another library, *Keras*, that acts as
    an interface for TensorFlow. Although it’s now part of TensorFlow’s core application
    programming interface (API), you can also use Keras in a stand-alone manner.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然TensorFlow有丰富的文档并附带操作指南，但它仍然被认为是最具挑战性的深度学习框架之一，界面复杂且学习曲线陡峭。幸运的是，谷歌工程师François
    Challet编写了另一个库*Keras*，它作为TensorFlow的接口。虽然它现在是TensorFlow核心应用编程接口（API）的一部分，但你也可以独立使用Keras。
- en: Like TensorFlow, Keras is open source and works on all platforms. Unlike TensorFlow,
    Keras is written in Python, which makes it more user friendly. Designed for quick
    prototyping and fast experimentation on smaller datasets, its lightweight, simplistic
    interface takes a minimalist approach, making it easy to construct neural networks
    that can work with TensorFlow. And because Keras can act as a wrapper, you can
    always “drop down” into TensorFlow when you need to use a feature not included
    in Keras’s simpler interface.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 与TensorFlow类似，Keras是开源的并且可以在所有平台上运行。不同于TensorFlow，Keras是用Python编写的，使其更易于使用。Keras旨在快速原型开发和小数据集上的快速实验，其轻量级、简洁的界面采用极简主义设计，使得构建可以与TensorFlow配合工作的神经网络变得容易。而且，因为Keras可以作为封装层，你在需要使用Keras简洁接口中不包含的功能时，可以随时“降级”到TensorFlow。
- en: Keras runs seamlessly on both CPUs and GPUs. It is primarily used for classification,
    speech recognition, and text generation, summarization, and tagging. By minimizing
    actions and making models easy to understand, Keras is a great deep learning tool
    for beginners.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: Keras可以在CPU和GPU上无缝运行。它主要用于分类、语音识别、文本生成、摘要和标签。通过简化操作并使模型易于理解，Keras成为初学者非常好的深度学习工具。
- en: '***PyTorch***'
  id: totrans-87
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***PyTorch***'
- en: '*PyTorch*, developed by Facebook’s AI Research Lab, is a direct competitor
    to TensorFlow. PyTorch works on all platforms and has recently incorporated *Caffe*,
    a popular deep learning framework developed at Berkeley and geared toward the
    image processing field. PyTorch comes preinstalled on Anaconda.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '*PyTorch*，由Facebook的人工智能研究实验室开发，是TensorFlow的直接竞争对手。PyTorch可以在所有平台上运行，并且最近集成了*Caffe*，这是一种在伯克利开发的流行深度学习框架，主要面向图像处理领域。PyTorch在Anaconda中预安装。'
- en: PyTorch is becoming the preferred framework for academic research, though it’s
    still widely used among industry giants such as Facebook, Microsoft, and Wells
    Fargo. It excels at prototyping and is great for projects that have more of a
    non-production implementation. Among its strengths are flexibility, debugging
    capabilities, and short training durations.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch正在成为学术研究的首选框架，尽管它在Facebook、Microsoft和Wells Fargo等行业巨头中仍被广泛使用。它在原型设计方面表现出色，适合那些更多处于非生产实现阶段的项目。它的优势包括灵活性、调试能力和较短的训练时间。
- en: Unlike TensorFlow, PyTorch is described as feeling more “native” to Python,
    making it easy to develop and implement machine learning models. Its syntax and
    application are very Pythonic, and it integrates seamlessly with essential libraries
    like NumPy. Although Keras seems to hold the upper hand with respect to ease of
    use, especially for those new to deep learning, PyTorch is faster, more flexible,
    and has better memory optimization.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 与TensorFlow不同，PyTorch被描述为对Python更加“本地化”，使得开发和实现机器学习模型变得更为容易。其语法和应用非常符合Python风格，并且与NumPy等重要库无缝集成。尽管Keras在易用性方面似乎占据优势，尤其对于深度学习新手而言，PyTorch在速度、灵活性和内存优化方面更胜一筹。
- en: Another strength of PyTorch is debugging. Keras hides a lot of the nitty-gritty
    details of building a neural network through encapsulation into various functions.
    This means that you can build an artificial neural network with only a few lines
    of code. With PyTorch, you need to specify a lot more details explicitly in your
    code; thus, finding an error becomes a much simpler task. It’s also simpler to
    change weights, biases, and network layers and rerun the model.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch的另一个优势是调试。Keras通过封装到各种函数中隐藏了构建神经网络的许多细节。这意味着你只需几行代码就能构建一个人工神经网络。而在PyTorch中，你需要在代码中明确指定更多细节；因此，找出错误变得更加简单。同时，修改权重、偏置和网络层并重新运行模型也变得更加容易。
- en: Overall, PyTorch is considered easier to use than TensorFlow, but harder to
    use than Keras. TensorFlow’s visualization capabilities are also held in higher
    esteem.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，PyTorch被认为比TensorFlow更容易使用，但比Keras更难使用。TensorFlow的可视化功能也受到更高的评价。
- en: '**CHOOSING A DEEP LEARNING FRAMEWORK**'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '**选择深度学习框架**'
- en: 'According to Mark Twain, “All generalizations are wrong including this one.”
    Many personal and project-related issues can affect which deep learning framework
    you choose. Still, if you search the internet enough, you can find some general
    guidelines for the selection of a deep learning framework:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 根据马克·吐温的说法，“所有的概括都是错误的，包括这条。” 许多个人和项目相关的问题可能会影响你选择哪种深度学习框架。不过，如果你足够搜索互联网上的资源，你还是可以找到一些关于深度学习框架选择的通用指南：
- en: If you’re brand new to deep learning, consider Keras, followed by PyTorch.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你是深度学习的初学者，考虑选择Keras，其次是PyTorch。
- en: If you’re new and part of a research community, consider PyTorch.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你是新手并且是研究社区的一部分，考虑使用PyTorch。
- en: If you’re an experienced researcher, you’ll probably prefer PyTorch.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你是经验丰富的研究人员，你可能会更喜欢PyTorch。
- en: Developers wanting a quick plug-and-play framework will prefer Keras.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 想要一个快速即插即用框架的开发者会更喜欢Keras。
- en: If you’re experienced and want an industry job, consider TensorFlow.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你有经验并且希望从事工业界工作，考虑使用TensorFlow。
- en: If you’re working with large datasets and need speed and performance, choose
    either PyTorch or TensorFlow.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你处理的是大规模数据集，并且需要速度和性能，选择PyTorch或TensorFlow。
- en: If debugging is a concern, use PyTorch, as standard Python debuggers can be
    used (though with Keras, debugging is seldom needed due to the simple interface).
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果调试是个问题，使用PyTorch，因为可以使用标准的Python调试器（尽管使用Keras时，由于界面简单，调试的需求很少）。
- en: If you need multiple backend support, choose Keras or TensorFlow.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你需要多个后端支持，选择Keras或TensorFlow。
- en: Keras and TensorFlow provide more deployment options and simplify model export
    to the web; with PyTorch you must use Flask or Django as the backend server.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Keras和TensorFlow提供更多的部署选项，并简化了模型导出到Web的过程；而在PyTorch中，你必须使用Flask或Django作为后端服务器。
- en: For fast prototyping, use Keras, followed by PyTorch.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于快速原型设计，使用Keras，其次是PyTorch。
- en: If visualization is a priority, choose Keras or TensorFlow.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果可视化是优先考虑的，选择Keras或TensorFlow。
- en: If you’re already working with Keras or TensorFlow, use Keras for deep neural
    networks and TensorFlow for machine learning applications.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你已经在使用Keras或TensorFlow，使用Keras进行深度神经网络设计，使用TensorFlow进行机器学习应用。
- en: '**The Computer Vision Libraries**'
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**计算机视觉库**'
- en: Computer vision is a branch of artificial intelligence focused on training computers
    to see and process digital images and videos in much the same way as human vision.
    The goal is for computers to gain a high-level understanding of the state of the
    world from images and return appropriate outputs. For example, a self-driving
    car should detect when you’ve drifted out of your lane and either warn you or
    automatically steer the car back. This requires detecting, tracking, and classifying
    features in images. In addition to autonomous cars, common applications include
    face detection and recognition, skin cancer diagnoses, event detection, and camera
    autofocusing.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉是人工智能的一个分支，专注于训练计算机像人类视觉一样看和处理数字图像和视频。其目标是让计算机通过图像获取世界状态的高层次理解，并返回适当的输出。例如，自动驾驶汽车应该检测到你已经偏离车道，并警告你或自动将车轮转回。这需要在图像中检测、跟踪和分类特征。除了自动驾驶汽车，常见的应用还包括面部检测和识别、皮肤癌诊断、事件检测以及相机自动对焦。
- en: There are quite a few Python libraries dedicated to computer vision and image
    manipulation, but three, OpenCV, scikit-image, and Pillow, should easily cover
    most of your needs. Let’s take a quick look at these in the following sections.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多专门用于计算机视觉和图像处理的Python库，但有三个库，OpenCV、scikit-image和Pillow，基本上可以满足你大多数的需求。让我们在接下来的章节中快速了解一下这三个库。
- en: '***OpenCV***'
  id: totrans-110
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***OpenCV***'
- en: '*OpenCV*, short for *Open-Source Computer Vision*, is the world’s most popular
    open source computer vision library. Its key focus is on real-time applications,
    like identifying faces in streaming video, but it can do everything from simple
    image editing to machine learning applications. OpenCV is written in C++ for speed
    but has a Python wrapper that works on Windows, Linux, Android, and macOS.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '*OpenCV*，即*开源计算机视觉*，是全球最流行的开源计算机视觉库。它的主要关注点是实时应用程序，例如在流媒体视频中识别面孔，但它可以做从简单图像编辑到机器学习应用的所有事情。OpenCV是用C++编写的，以提高速度，但它有一个Python封装器，支持Windows、Linux、Android和macOS平台。'
- en: OpenCV has a modular structure that includes thousands of optimized algorithms,
    including ones for simple image processing, video analysis, 2D feature framework,
    object detection, object tracking, camera calibration, 3D reconstruction and more.
    OpenCV converts images into efficient NumPy arrays and, because it’s written in
    optimized C/C++, it can take advantage of fast multicore processing.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV具有模块化结构，包括数千个优化的算法，涵盖了简单的图像处理、视频分析、2D特征框架、物体检测、物体跟踪、相机标定、3D重建等多个领域。OpenCV将图像转换为高效的NumPy数组，并且由于其采用优化的C/C++编写，能够利用快速的多核处理。
- en: OpenCV has been around for more than 20 years and has a large and supportive
    user base. Many major companies such as Google, Yahoo, Microsoft, Intel, IBM,
    Sony, and Honda actively use OpenCV. Thanks to its maturity and popularity, you
    can find many books and online tutorials to help you use the library.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV已经存在了超过20年，拥有一个庞大且支持的用户群体。许多大型公司如Google、Yahoo、Microsoft、Intel、IBM、Sony和Honda都在积极使用OpenCV。由于其成熟和受欢迎，你可以找到许多书籍和在线教程来帮助你使用这个库。
- en: '***scikit-image***'
  id: totrans-114
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***scikit-image***'
- en: The open-source *scikit-image* library is the image processing toolbox for SciPy.
    Its mission is to be *the* reference library for scientific image analysis in
    Python. It comes preinstalled with Anaconda.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 开源的 *scikit-image* 库是SciPy的图像处理工具箱。其使命是成为Python中科学图像分析的*权威*库。它预装在Anaconda中。
- en: The scikit-image library includes lots of algorithms and utilities for use in
    industry, research, and education. It’s written in Python and, like OpenCV, uses
    NumPy arrays as image objects by transforming the original pictures. Although
    it lacks some of the sophisticated OpenCV algorithms for working with images in
    real time, it still has a lot of algorithms useful for scientists, including feature
    and blob detection. It also contains a few algorithm implementations that OpenCV
    does not.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-image库包含许多行业、研究和教育中常用的算法和工具。它是用Python编写的，像OpenCV一样，通过转换原始图像来使用NumPy数组作为图像对象。尽管它缺乏一些OpenCV中用于实时图像处理的复杂算法，但它仍然拥有许多对科学家有用的算法，包括特征和斑点检测。它还包含一些OpenCV没有的算法实现。
- en: The library is fairly easy to use and well documented with lots of examples
    and use cases. All of the code is peer reviewed and of high quality. It provides
    a consistent interface to many machine-learning models, making it relatively easy
    to learn a new model. It also provides many options—with sensible defaults—for
    tuning the models for optimal performance. You can find a gallery of examples
    at *[https://scikit-image.org/docs/stable/auto_examples/](https://scikit-image.org/docs/stable/auto_examples/)*.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 该库使用起来相当简便，并且有丰富的文档和大量示例与使用案例。所有代码都经过同行评审，质量很高。它为许多机器学习模型提供了一致的接口，使得学习新模型相对容易。它还提供了许多可选项——并且具有合理的默认设置——用于调优模型以获得最佳性能。你可以在
    *[https://scikit-image.org/docs/stable/auto_examples/](https://scikit-image.org/docs/stable/auto_examples/)*
    找到示例库。
- en: '***PIL/Pillow***'
  id: totrans-118
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***PIL/Pillow***'
- en: '*Pillow* is the “friendly” fork of the *Python Image Library (PIL)*, one of
    the oldest core libraries for image manipulation in Python. Pillow runs on all
    major operating systems, comes preinstalled on Anaconda, and is primarily designed
    for basic image processing.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '*Pillow* 是 *Python图像库（PIL）*的“友好”分支，它是Python中最古老的核心图像处理库之一。Pillow可以在所有主要操作系统上运行，并且预装在Anaconda中，主要用于基本的图像处理。'
- en: If you don’t need functionality from OpenCV or scikit-image, Pillow is widely
    used for image transformations in web projects given that it is more lightweight
    and usable. It supports a large selection of image file types and predefined image
    enhancement filters for sharpening, blurring, contouring, smoothing, finding edges,
    resizing, manipulating pixels, and more. It’s especially useful for automatically
    processing large numbers of images.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不需要OpenCV或scikit-image的功能，Pillow因其轻量级和易用性，在Web项目中被广泛用于图像转换。它支持多种图像文件格式，并提供预定义的图像增强滤镜，包括锐化、模糊、轮廓、平滑、边缘检测、调整大小、像素操作等。它尤其适合用于自动处理大量图像。
- en: '**CHOOSING AN IMAGE MANIPULATION LIBRARY**'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '**选择图像处理库**'
- en: Here are some tips for choosing a library for manipulating images. Only open
    source libraries are considered.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是选择图像处理库的一些建议。这里只考虑开源库。
- en: If your job or research involves computer-vision applications in *real time*,
    you’ll want to learn OpenCV.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你的工作或研究涉及 *实时* 计算机视觉应用，那么你需要学习OpenCV。
- en: If your datasets include a mixture of static images and streaming video, you
    should consider both OpenCV and scikit-image. Some of the latter’s methods and
    utilities can complement OpenCV. For a short example of how these two can work
    together, visit Adrian Rosebrock’s tutorial on detecting low-contrast images (*[https://www.pyimagesearch.com/2021/01/25/detecting-low-contrast-images-with-opencv-scikit-image-and-python/](https://www.pyimagesearch.com/2021/01/25/detecting-low-contrast-images-with-opencv-scikit-image-and-python/)*).
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你的数据集包含静态图像和流媒体视频的混合，你应该同时考虑使用OpenCV和scikit-image。后者的一些方法和工具可以补充OpenCV。关于这两者如何协同工作的简短示例，请访问Adrian
    Rosebrock的教程，了解如何检测低对比度图像 (*[https://www.pyimagesearch.com/2021/01/25/detecting-low-contrast-images-with-opencv-scikit-image-and-python/](https://www.pyimagesearch.com/2021/01/25/detecting-low-contrast-images-with-opencv-scikit-image-and-python/)*).
- en: If you mainly work with static images, scikit-image or Pillow should suffice
    and save you all the “overhead” of OpenCV. Between the two, scikit-image will
    be more appropriate if you regularly work with images and perform fairly sophisticated
    analyses and manipulations.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你主要处理静态图像，scikit-image或Pillow应该足够，并且可以避免OpenCV带来的“开销”。在这两者之间，如果你经常处理图像并进行较为复杂的分析和操作，scikit-image会更为合适。
- en: For basic image manipulation, such as loading images, cropping images, or simple
    filtering, Pillow should be sufficient. Likewise, you can realize a large number
    of simple operations directly within NumPy and SciPy’s `ndimage` module.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于基本的图像处理，比如加载图像、裁剪图像或简单的过滤，Pillow应该足够使用。同样，你也可以直接在NumPy和SciPy的`ndimage`模块中实现许多简单的操作。
- en: '**The Natural Language Processing Libraries**'
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**自然语言处理库**'
- en: '*Natural language processing (NLP)* is a branch of linguistics and artificial
    intelligence concerned with giving computers the ability to derive meaning from
    written and spoken words. Some familiar applications of NLP include speech recognition;
    text-to-speech conversion; machine translations; chatbots; spam detection; word
    segmentation (called tokenization); sentiment analysis, optical character recognition
    (OCR), in which an image of handwriting or printed text is converted into digital
    text; and, of course, Amazon’s Alexa.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '*自然语言处理（NLP）*是语言学和人工智能的一个分支，旨在赋予计算机从书面和口头语言中提取意义的能力。一些常见的NLP应用包括语音识别；语音转文本；机器翻译；聊天机器人；垃圾邮件检测；词语分割（称为标记化）；情感分析；光学字符识别（OCR），将手写或印刷文本的图像转换为数字文本；当然，还有亚马逊的Alexa。'
- en: Among the more popular NLP libraries are NLTK, spaCy, Gensim, Pattern, and TextBlob.
    NLTK and spaCy are all-purpose NLP libraries and are discussed in more detail
    in the sections that follow. Others, like Gensim, are more specialized and focus
    on subdisciplines such as semantic analysis (detecting the meaning of words),
    topic modeling (determining a document’s meaning based on word statistics), and
    text mining.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 更受欢迎的NLP库包括NLTK、spaCy、Gensim、Pattern和TextBlob。NLTK和spaCy是通用的NLP库，接下来的章节将详细讨论这两个库。其他库如Gensim则更为专业，专注于子领域如语义分析（检测单词的意义）、主题建模（根据单词统计确定文档的含义）和文本挖掘。
- en: '***NLTK***'
  id: totrans-130
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***NLTK***'
- en: The *Natural Language Tool Kit*, or *NLTK* for short, is one of the oldest,
    most powerful, and most popular NLP libraries for Python. NLTK is open source
    and works on Windows, macOS, and Linux. Created in 2001 as part of a computational
    linguistics course at the University of Pennsylvania, it has continued to develop
    and expand with the help of dozens of contributors. NLTK comes preinstalled on
    Anaconda.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '*自然语言工具包*，简称*NLTK*，是Python中最古老、最强大、最受欢迎的NLP库之一。NLTK是开源的，可以在Windows、macOS和Linux上使用。它于2001年作为宾夕法尼亚大学计算语言学课程的一部分创建，并在几十位贡献者的帮助下不断发展壮大。NLTK已在Anaconda中预装。'
- en: Because it’s designed by and for an academic research audience, NLTK is versatile
    but can be somewhat slow for quick-paced production usage. It’s also considered
    a bit difficult to learn, though this is mitigated to a fair degree by the free
    and useful online textbook, *Natural Language Processing with Python* (*[http://www.nltk.org/book/](http://www.nltk.org/book/)*),
    written by its developers.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 因为NLTK是为学术研究群体设计的，它功能强大，但在快速生产环境中的使用可能稍显缓慢。它也被认为有些难以学习，尽管这一点通过开发者编写的免费且有用的在线教科书《Python自然语言处理》（*Natural
    Language Processing with Python*）（*[http://www.nltk.org/book/](http://www.nltk.org/book/)*）在一定程度上得到了缓解。
- en: A strength of NLTK is that it comes packaged with lots of corpora (bodies of
    text) and pretrained models. As a result, it can be considered the de facto standard
    library for academic researchers in NLP.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: NLTK的一个优势是它包含了大量的语料库（文本集）和预训练模型。因此，它可以被认为是学术界自然语言处理（NLP）领域的事实标准库。
- en: '***spaCy***'
  id: totrans-134
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***spaCy***'
- en: The *spaCy* library is younger than NLTK and designed to work well with machine
    learning frameworks like scikit-learn, TensorFlow, PyTorch, and other NLP libraries
    like Gensim. It’s advertised as being “industrial strength,” meaning that it’s
    scalable, optimized, and very fast for production applications. Like NLTK, it
    has great documentation and comes prepackaged with useful language models. Its
    support community is not as large as that for NLTK but it’s growing rapidly and
    may someday overtake NLTK in popularity.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '*spaCy*库比NLTK年轻，且设计上能够很好地与像scikit-learn、TensorFlow、PyTorch等机器学习框架以及其他NLP库（如Gensim）协同工作。它被宣传为“工业级”，意味着它是可扩展的、经过优化的，并且在生产应用中非常快速。像NLTK一样，它有很好的文档，并且预装了有用的语言模型。它的支持社区虽然不如NLTK庞大，但正在快速增长，未来可能会超越NLTK的受欢迎程度。'
- en: '**CHOOSING AN NLP LIBRARY**'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '**选择NLP库**'
- en: 'Although there are dozens of libraries in the NLP stack, you need to know only
    a few to be proficient in the field. Some guidelines for choosing an NLP library
    are presented here:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管NLP领域有数十种库，但你只需掌握其中几个，就能在该领域达到熟练水平。以下是选择NLP库的一些指导原则：
- en: If you’re in academia or otherwise doing research, you’ll probably want to take
    the time to learn NLTK.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你从事学术研究或其他研究工作，你可能会想花时间学习NLTK。
- en: The spaCy library will be useful for mixing NLP with machine learning models.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: spaCy库在将NLP与机器学习模型结合使用时会非常有用。
- en: If you need highly optimized performance, consider spaCy.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你需要高效优化的性能，可以考虑spaCy。
- en: If all you plan to do is scrape websites and analyze the results, consider *Pattern*
    (*[https://github.com/clips/pattern/](https://github.com/clips/pattern/)*), a
    specialized web miner with basic NLP capabilities.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你计划做的是抓取网站并分析结果，可以考虑*Pattern* (*[https://github.com/clips/pattern/](https://github.com/clips/pattern/)*)，它是一个具有基本NLP功能的专用网页挖掘工具。
- en: If you’re a beginner or plan to use NLP lightly in your work, consider *TextBlob*
    (*[https://textblob.readthedocs.io/en/dev/](https://textblob.readthedocs.io/en/dev/)*).
    TextBlob is a user-friendly frontend to the NLTK and Pattern libraries, wrapping
    both in high-level, easy-to-use interfaces. It’s good for learning and for quick
    prototyping, and as you become more confident, you can add functionality to refine
    your prototypes.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你是初学者或计划在工作中轻度使用NLP，可以考虑*TextBlob* (*[https://textblob.readthedocs.io/en/dev/](https://textblob.readthedocs.io/en/dev/)*)。TextBlob是一个用户友好的前端接口，封装了NLTK和Pattern库，提供高层次、易于使用的界面。它适合学习和快速原型设计，随着你经验的积累，你可以添加功能来优化你的原型。
- en: If you’re into topic modeling and statistical semantics (analyzing and scoring
    documents on their similarity), you may want to consider *Gensim* (*[https://radimrehurek.com/gensim/](https://radimrehurek.com/gensim/)*).
    Gensim can handle very large file sizes by streaming documents to its analysis
    engine and performing unsupervised learning on them incrementally. Its memory
    optimization and fast processing speed are achieved through the use of the NumPy
    library. Gensim is a specialized tool, and not for general-purpose NLP.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你对主题建模和统计语义学（分析和评分文档的相似性）感兴趣，可以考虑*Gensim* (*[https://radimrehurek.com/gensim/](https://radimrehurek.com/gensim/)*)。Gensim通过将文档流式传输到其分析引擎，并对其进行增量式无监督学习，能够处理非常大的文件。它的内存优化和快速处理速度是通过使用NumPy库实现的。Gensim是一个专用工具，不适用于通用NLP任务。
- en: If you want to perform NLP on multiple languages at once, consider *Polyglot
    ([https://polyglot.readthedocs.io/en/latest/index.html](https://polyglot.readthedocs.io/en/latest/index.html)*).
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你想同时处理多种语言的NLP，可以考虑*Polyglot* (*[https://polyglot.readthedocs.io/en/latest/index.html](https://polyglot.readthedocs.io/en/latest/index.html)*)。
- en: '**The Helper Libraries**'
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**辅助库**'
- en: '*Helper libraries* assist you in using the scientific libraries discussed in
    this chapter. The ones discussed here help you download data, prepare it for use,
    and analyze it as quickly as possible.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '*辅助库*帮助你使用本章讨论的科学库。这里讨论的那些库可以帮助你快速下载数据、准备数据并进行分析。'
- en: '***Requests***'
  id: totrans-147
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***Requests***'
- en: '*Data wrangling* (or *munging*) refers to the process of transforming data
    from its “raw” form into a more usable format for analysis. This involves processes
    such as checking, correcting, remapping, and so on. You can do a lot of this with
    the pandas library, discussed previously, but first you need to get your hands
    on the data.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '*数据整理*（或 *数据清理*）指的是将数据从“原始”形式转化为更适合分析的格式的过程。这包括检查、修正、重新映射等过程。你可以通过之前讨论的 pandas
    库做很多这方面的工作，但首先你需要获取数据。'
- en: Given that the lion’s share of human knowledge is available online, you’re probably
    going to need a way to pull data off the World Wide Web. Note that I’m not talking
    about simply downloading an Excel spreadsheet from an online database, which is
    easy enough, or about manually copying and pasting text from a web page. I’m referring
    to automatically extracting and processing content, a process called *web scraping*.
    Let’s look at two open source libraries to help with this, requests and Beautiful
    Soup, and a third, re, that helps you clean and correct the data.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 由于大量的人类知识都可以在线获取，你很可能需要一种方法从全球信息网上提取数据。请注意，我并不是在说简单地从在线数据库下载一个 Excel 表格，这很容易，或者手动复制并粘贴网页上的文本。我指的是自动提取和处理内容的过程，这个过程称为
    *网页抓取*。让我们来看两个开源库来帮助实现这一点，requests 和 Beautiful Soup，以及第三个库 re，它帮助你清理和修正数据。
- en: The popular and trusted requests library is designed to make *HyperText Transfer
    Protocol (HTTP)* requests simpler and more human friendly. HTTP is the foundation
    of data communication for the World Wide Web, where hypertext documents include
    hyperlinks to other resources that users can easily access with, for example,
    a mouse click or by tapping the screen in a web browser. The requests library
    comes preinstalled with Anaconda.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 流行且可靠的 requests 库旨在使 *超文本传输协议 (HTTP)* 请求变得更加简单和用户友好。HTTP 是全球信息网（World Wide Web）数据通信的基础，其中的超文本文档包含指向其他资源的超链接，用户可以通过点击鼠标或在网页浏览器中点击屏幕轻松访问这些资源。requests
    库在 Anaconda 中是预安装的。
- en: 'Let’s look at an example where you scrape Dr. Martin Luthor King, Jr.’s “I
    Have a Dream” speech from a website (*[http://www.analytictech.com/mb021/mlk.htm](http://www.analytictech.com/mb021/mlk.htm)*)
    using Jupyter Notebook:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个例子，在 Jupyter Notebook 中使用爬虫从网站上抓取马丁·路德·金博士的《我有一个梦想》演讲（* [http://www.analytictech.com/mb021/mlk.htm](http://www.analytictech.com/mb021/mlk.htm)
    *）：
- en: '[PRE5]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: After importing requests, you provide the `url` address as a string. You can
    copy and paste this from the website from which you want to extract text. The
    requests library abstracts the complexities of making HTTP requests in Python.
    The `get()` method retrieves the `url` and assigns the output to a `page` variable,
    which references the `Response` object the web page returned for the request.
    This object’s text attribute holds the web page, including the speech, as a readable
    text string.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在导入 requests 库后，您需要将 `url` 地址作为字符串提供。您可以从希望提取文本的网站复制并粘贴这个地址。requests 库抽象化了在
    Python 中发起 HTTP 请求的复杂性。`get()` 方法获取 `url` 并将输出赋值给 `page` 变量，该变量引用了网页返回的 `Response`
    对象。此对象的文本属性包含网页内容，包括演讲稿，以可读文本字符串的形式呈现。
- en: 'At this point, the data is in *HyperText Markup Language (HTML)*, the standard
    format used to create web pages:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，数据是以 *超文本标记语言 (HTML)* 的形式存在的，这是创建网页的标准格式：
- en: '[PRE6]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: As you can see, HTML has a lot of *tags* such as `<head>` and `<p>` that let
    your browser know how to format the web page. The text between starting and closing
    tags is called an *element*. For example, the text “Martin Luther King Jr.’s 1962
    Speech” is a title element sandwiched between the starting tag `<title>` and the
    closing tag `</title>`. Paragraphs are formatted using `<p>` and `</p>` tags.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，HTML 中有很多 *标签*，如 `<head>` 和 `<p>`，它们告诉浏览器如何格式化网页。在开始标签和结束标签之间的文本被称为
    *元素*。例如，“马丁·路德·金博士 1962 年的演讲”是一个标题元素，位于开始标签 `<title>` 和结束标签 `</title>` 之间。段落使用
    `<p>` 和 `</p>` 标签格式化。
- en: Because these tags are not part of the original text, they should be removed
    prior to any further analysis, such as natural language processing. To remove
    the tags, you’ll need the Beautiful Soup library.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 因为这些标签不是原始文本的一部分，所以在进行进一步分析（如自然语言处理）之前应该将它们移除。要移除这些标签，你需要使用 Beautiful Soup 库。
- en: '***Beautiful Soup***'
  id: totrans-158
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***Beautiful Soup***'
- en: '*Beautiful Soup* is an open source Python library for extracting readable data
    from HTML and XML files. It comes preinstalled with Anaconda.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '*Beautiful Soup* 是一个开源 Python 库，用于从 HTML 和 XML 文件中提取可读数据。它在 Anaconda 中是预安装的。'
- en: 'Let’s use Beautiful Soup (simplified as *bs4*) on the HTML file returned by
    requests in the previous section:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在上一节中通过请求返回的HTML文件上使用Beautiful Soup（简写为 *bs4*）：
- en: '[PRE7]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'After importing bs4, we call the `bs4.BeautifulSoup()` method and pass it the
    string containing the HTML. The `soup` variable now references a `BeautifulSoup`
    object, which means that you can use the `find_all()` method to locate the speech
    buried in the HTML document between paragraph tags (`<p>`). This makes a list,
    which you can turn into a continuous text string by joining the paragraph elements
    on a space (`'' ''`). The (truncated) printed results follow:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在导入bs4后，我们调用`bs4.BeautifulSoup()`方法，并将包含HTML的字符串传递给它。`soup`变量现在引用一个`BeautifulSoup`对象，这意味着你可以使用`find_all()`方法来定位HTML文档中被段落标签（`<p>`）包裹的文本。这将生成一个列表，你可以通过在空格（`'
    '`）上连接段落元素，将它变成一个连续的文本字符串。以下是（截断的）打印结果：
- en: '[PRE8]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: You now have text that you can easily read as well as analyze with Python’s
    many language processing tools.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你拥有了可以轻松阅读并用Python的多种语言处理工具进行分析的文本。
- en: '***Regex***'
  id: totrans-165
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***正则表达式***'
- en: No matter where you get your raw data, it will probably contain spelling errors,
    formatting issues, missing values, and other problems that will keep you from
    using it immediately. You’ll need to process it in some way, such as reformatting,
    replacing, or removing certain parts, and you’ll want to do it in *bulk*. Fortunately,
    *regular expressions* provide you with a wide variety of tools for parsing raw
    text and performing these tasks.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你从哪里获取原始数据，它可能都包含拼写错误、格式问题、缺失的值以及其他阻碍你立即使用的数据问题。你需要以某种方式处理它，例如重新格式化、替换或删除某些部分，而且你希望能够
    *批量* 处理。幸运的是，*正则表达式* 为你提供了多种工具来解析原始文本并执行这些任务。
- en: A regular (or *rational*) expression, usually shortened to *regex*, is a sequence
    of characters that specifies a *search pattern*. You’re probably familiar with
    these patterns if you’ve ever used “find” or “find and replace” operations in
    a text editor. Using pattern matching, regex helps you to isolate and extract
    text you want from text you don’t want.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 正则表达式（或 *有理* 表达式），通常简写为 *regex*，是一个字符序列，用来指定一个 *搜索模式*。如果你曾经在文本编辑器中使用过“查找”或“查找和替换”功能，那么你可能对这些模式很熟悉。通过模式匹配，正则表达式帮助你从不需要的文本中提取出你想要的内容。
- en: Regex can do tedious but important things that you’d normally assign to an assistant
    or technician. For example, it can scan text for information related to your field
    of study. If you’re a seismologist interested in earthquakes, you can write programs
    that scan news feeds for reports on these events, grab the data, format it, and
    store it in a database.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 正则表达式可以做一些繁琐但重要的事情，这些事情通常是你会委派给助理或技术人员的。例如，它可以扫描文本，寻找与你研究领域相关的信息。如果你是一名研究地震的地震学家，你可以编写程序扫描新闻信息，获取有关这些事件的报告，抓取数据、格式化并存储到数据库中。
- en: 'Python has a built-in module called re which you can use to work with regular
    expressions. Let’s look at an example in which you’re searching texts for 10-digit
    phone numbers. Within this database, people have entered phone numbers in multiple
    ways, such as with the area code in parentheses, using dashes, using spaces, and
    so on, but you want to use 10 consecutive numbers with no spaces. Here’s how re
    and Python can help you to extract and format the numbers:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: Python有一个内建模块叫做re，你可以用它来处理正则表达式。我们来看一个例子，在这个例子中，你正在搜索文本中的10位电话号码。在这个数据库中，人们以多种方式输入电话号码，例如带区号的括号、使用破折号、使用空格等等，但你希望使用没有空格的10个连续数字。以下是re和Python如何帮助你提取和格式化这些数字的方式：
- en: '[PRE9]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'After importing re and entering the data, you assign a variable, named `nums`,
    and call the `re.findall()` method. This diabolical syntax looks like some kind
    of code, pun intended, and like any code you must know the key. Without going
    into the gory details, you’re basically telling the `findall()` method the following:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在导入re并输入数据后，你会分配一个名为`nums`的变量，并调用`re.findall()`方法。这种复杂的语法看起来像是某种代码，双关语有意而为之，就像任何代码一样，你必须知道关键所在。不展开细节，你基本上是在告诉`findall()`方法以下内容：
- en: The matched text string might start with the `(`symbol or the number one to
    nine `[\(]?[1-9].`
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 匹配的文本字符串可能以`(`符号或数字一到九`[\(]?[1-9]`开始。
- en: There can be a number, space, period, dash, or parentheses in between `[0-9\
    \.\-\(\)].`
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其中可以有数字、空格、句点、破折号或括号`[0-9\ \.\-\(\)]`。
- en: The matched string must contain at least 10 characters `{10,}.`
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 匹配的字符串必须至少包含10个字符`{10,}`。
- en: Finally, it must end with a number between zero and nine `[0-9].`
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最终，它必须以零到九之间的数字`[0-9]`结束。
- en: 'This first attempt finds all the input numbers:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 这个第一次尝试会找到所有输入的数字：
- en: '[PRE10]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Next, you need to remove the non-number characters using the `re.sub()` method,
    which substitutes a character you provide for the targeted characters. The `^`
    tells the method to find everything but digits between zero and nine and replace
    them with nothing, signified by `''''`:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你需要使用 `re.sub()` 方法删除非数字字符，该方法会用你提供的字符替换目标字符。`^` 告诉方法查找除了零到九的数字以外的所有内容，并将它们替换为空，表示为
    `''`：
- en: '[PRE11]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This produces a continuous string of numbers:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 这会生成一个连续的数字字符串：
- en: '[PRE12]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'You can now use list comprehension to loop through this string and extract
    the 10-digit groupings you desire:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在可以使用列表推导式遍历这个字符串，并提取你所需的 10 位数字分组：
- en: '[PRE13]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This yields a list of numbers (as strings) in the format you desire:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成你所需格式的数字列表（以字符串形式表示）：
- en: '[PRE14]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This simple example demonstrates both the power of regex and the daunting nature
    of its syntax. In fact, regex is probably the most unPythonic thing in Python.
    Fortunately, because just about everyone struggles with the syntax, there are
    a lot of tools, tutorials, books, and cheat sheets available to help you use it.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简单的例子展示了正则表达式的强大功能，也暴露了它语法的复杂性。事实上，正则表达式可能是 Python 中最“不 Pythonic”的东西。幸运的是，由于几乎每个人都在与其语法作斗争，因此有很多工具、教程、书籍和备忘单可供帮助你使用它。
- en: You can find a nice “how to” tutorial at *[https://docs.python.org/3/howto/regex.html](https://docs.python.org/3/howto/regex.html)*
    and at *[https://realpython.com/regex-python/](https://realpython.com/regex-python/)*.
    [Chapter 7](ch07.xhtml) of Al Sweigart’s book, *Automate the Boring Stuff with
    Python*, 2nd edition (No Starch Press, 2019), provides a high-level overview of
    pattern matching with regular expressions, and Jeffrey Friedl’s *Mastering Regular
    Expressions* (O’Reilly, 2006) covers them in-depth. You can find cheat sheets
    with examples in many places online, including *[https://learnbyexample.github.io/python-regex-cheatsheet/](https://learnbyexample.github.io/python-regex-cheatsheet/)*.
    Other websites such as *[https://regexr.com/](https://regexr.com/)* and *[https://www.regexpal.com/](https://www.regexpal.com/)*
    let you play with regular expressions to learn how they work.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 *[https://docs.python.org/3/howto/regex.html](https://docs.python.org/3/howto/regex.html)*
    和 *[https://realpython.com/regex-python/](https://realpython.com/regex-python/)*
    上找到很好的“如何使用”教程。[Al Sweigart](ch07.xhtml) 的《用 Python 自动化无聊的工作》第二版（No Starch Press，2019）第7章提供了正则表达式模式匹配的概述，而
    Jeffrey Friedl 的《正则表达式精通》（O'Reilly，2006）则深入讲解了它们。你还可以在许多网站上找到带有示例的备忘单，包括 *[https://learnbyexample.github.io/python-regex-cheatsheet/](https://learnbyexample.github.io/python-regex-cheatsheet/)*。其他网站，如
    *[https://regexr.com/](https://regexr.com/)* 和 *[https://www.regexpal.com/](https://www.regexpal.com/)*
    允许你玩转正则表达式，以学习它们是如何工作的。
- en: If you have to wrangle a lot of text, regular expressions will dramatically
    reduce the amount of code that you need to write, saving you both time and frustration.
    With a little effort, you’ll achieve complete mastery over your data, solve problems,
    and automate things you probably never realized could be automated.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要处理大量文本，正则表达式将显著减少你需要编写的代码量，从而节省时间并减少挫败感。只需稍加努力，你就能完全掌握你的数据，解决问题，并自动化一些你可能从未意识到可以自动化的任务。
- en: '***Dask***'
  id: totrans-189
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***Dask***'
- en: '*Dask* is an open source library for parallel computing written in Python.
    It was developed to scale Python ecosystem libraries such as pandas, NumPy, scikit-learn,
    Matplotlib, Jupyter Notebook, and so on, from a single computer to multicore machines
    and distributed clusters. Dask comes preinstalled on Anaconda.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '*Dask* 是一个用 Python 编写的开源并行计算库。它被开发用来将 Python 生态系统库（如 pandas、NumPy、scikit-learn、Matplotlib、Jupyter
    Notebook 等）从单台计算机扩展到多核机器和分布式集群。Dask 在 Anaconda 中是预安装的。'
- en: To understand the benefits Dask provides, let’s talk terminology for a moment.
    A *thread* is the smallest sequence of programmed instructions that can be managed
    independently by a scheduler. *Parallel processing* refers to dividing different
    parts of a computing task—the threads—among two or more processors for the purpose
    of accelerating program execution.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解 Dask 所提供的好处，先让我们简单了解一些术语。*线程*是可以被调度器独立管理的最小程序指令序列。*并行处理*指的是将计算任务的不同部分——线程——分配到两个或多个处理器上，以加速程序执行。
- en: In the old days, the central processing unit (CPU) of computers had a single
    microprocessor, or *core*, that executed code one step at a time, like an army
    marching in single file. Nowadays, computers come with at least a dual-core CPU
    consisting of a chip with two complete microprocessors that share a single path
    to memory and peripherals. High-end workstations can have eight or more cores.
    So, theoretically, your programs no longer need to walk single file; they can
    run abreast. That is, if there are non-dependent threads, they can run simultaneously,
    saving lots of time.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去，计算机的中央处理单元（CPU）只有一个微处理器，或者说是 *核心*，它一次执行一步代码，就像一支军队单列行进。如今，计算机至少配备双核 CPU，包含两个完整的微处理器，它们共享通往内存和外设的单一路径。高端工作站甚至可以有八个或更多核心。因此，理论上，你的程序不再需要单列行进；它们可以并肩运行。也就是说，如果存在独立的线程，它们可以同时运行，从而节省大量时间。
- en: But Python has limitations when it comes to parallel computing. Even though
    computers now have more than one CPU, Python uses *Global Interpreter Lock (GIL)*
    to boost the performance of single threads by encouraging only a single thread
    to execute at a time. This hinders the use of multiple CPU cores for speedier
    computing.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 但是 Python 在并行计算方面有其局限性。即使现在计算机有多个 CPU，Python 仍然使用 *全局解释器锁（GIL）* 来提高单线程的性能，鼓励一次只执行一个线程。这限制了多个
    CPU 核心的使用，无法提高计算速度。
- en: With Dask, you can use Python and perform parallel computations locally on a
    multicored machine or remotely across thousands of machines. And Dask does it
    efficiently, as well, by managing memory at the same time. To maintain a low-memory
    footprint, it stores large datasets on disk and copies off chunks of data for
    processing. It also discards intermediate values as soon as possible after they
    are generated. As a result, Dask permits manipulation of datasets of 100GB and
    larger on laptops, and larger than 1TB on workstations.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Dask，你可以用 Python 在多核机器上本地进行并行计算，或者跨上千台机器远程计算。Dask 还非常高效地执行这些任务，同时进行内存管理。为了保持较低的内存占用，它将大数据集存储在磁盘上，并复制数据块进行处理。它还会尽可能快地丢弃中间值。因此，Dask
    允许在笔记本电脑上操作大于 100GB 的数据集，在工作站上操作大于 1TB 的数据集。
- en: 'Dask is composed of two parts: distributed data structures, with APIs similar
    to pandas DataFrames and NumPy arrays, and a task grapher/scheduler ([Figure 15-4](ch15.xhtml#ch015fig4)).
    It implements many of the same methods as pandas, which means that it can fully
    replace it in many cases. Dask also offers NumPy and scikit-learn replacements
    and has the capability to scale *any* Python code.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: Dask 由两部分组成：分布式数据结构，提供类似于 pandas DataFrame 和 NumPy 数组的 API，以及任务图和调度器（[图 15-4](ch15.xhtml#ch015fig4)）。它实现了许多与
    pandas 相同的方法，这意味着在许多情况下它可以完全替代 pandas。Dask 还提供 NumPy 和 scikit-learn 的替代品，并具备扩展
    *任何* Python 代码的能力。
- en: '![Image](../images/15fig04.jpg)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/15fig04.jpg)'
- en: '*Figure 15-4: Dask collections generate graphs that are executed by schedulers
    (courtesy of [https://dask.org/](https://dask.org/)).*'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 15-4：Dask 集合生成由调度器执行的图（图片来源：[https://dask.org/](https://dask.org/)）。*'
- en: Dask will add extra complexity to your projects, thus you should use it mainly
    when you have huge datasets and need to use cluster computing. Documentation for
    Dask is excellent, and there are many tutorials available online to help you use
    the library.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: Dask 会给你的项目增加额外的复杂性，因此你应该主要在处理巨大数据集并需要使用集群计算时使用它。Dask 的文档非常优秀，并且网上有很多教程可以帮助你使用这个库。
- en: '**NOTE**'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*You might hear about Apache Spark, a more mature and “heavier” alternative
    to Dask that has become a dominant and well-trusted tool in the Big Data enterprise
    world. It’s an all-in-one project that has its own ecosystem and is written in
    Scala with some support for Python. You can find a comparison of the two libraries
    at [https://docs.dask.org/en/latest/spark.html](https://docs.dask.org/en/latest/spark.html).
    In general, if you’re already using Python and associated libraries like NumPy
    and pandas, you’ll probably prefer working with Dask.*'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '*你可能听说过 Apache Spark，这是一个比 Dask 更成熟、更“重”的替代方案，已经成为大数据企业界的主流工具，并且深受信赖。它是一个一体化项目，拥有自己的生态系统，主要使用
    Scala 编写，并支持部分 Python。你可以在 [https://docs.dask.org/en/latest/spark.html](https://docs.dask.org/en/latest/spark.html)
    找到这两个库的对比。一般来说，如果你已经在使用 Python 及其相关库，如 NumPy 和 pandas，你可能会更倾向于使用 Dask。*'
- en: '**Summary**'
  id: totrans-201
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**总结**'
- en: Python supports scientific work through its easy-to-use core language and the
    many libraries built upon it. Not only are these packages free, but they’re also
    robust, reliable, and well documented, thanks to the enormous and active user
    community.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: Python通过其易于使用的核心语言和构建在其上的众多库，支持科学工作。这些包不仅免费，而且由于庞大且活跃的用户社区，它们也非常稳健、可靠且文档齐全。
- en: You learned about some of the most important and popular libraries for science,
    including NumPy and SciPy, for numerical and array calculations; pandas, for data
    analysis; scikit-learn, for machine learning; Tensorflow, Keras, and PyTorch,
    for neural networks; OpenCV, for computer vision; and NLTK, for language processing.
    In [Chapter 16](ch16.xhtml) and [Chapter 17](ch17.xhtml), we cover libraries for
    working with geographic data and creating visualizations. In [Chapters 18](ch18.xhtml),
    [19](ch19.xhtml), [20](ch20.xhtml), and [21](ch21.xhtml), we dive deeper into
    NumPy, Matplotlib, pandas, and scikit-learn.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 你了解了一些最重要且最受欢迎的科学库，包括用于数值和数组计算的NumPy和SciPy；用于数据分析的pandas；用于机器学习的scikit-learn；用于神经网络的Tensorflow、Keras和PyTorch；用于计算机视觉的OpenCV；以及用于语言处理的NLTK。在[第16章](ch16.xhtml)和[第17章](ch17.xhtml)中，我们介绍了处理地理数据和创建可视化的库。在[第18章](ch18.xhtml)、[第19章](ch19.xhtml)、[第20章](ch20.xhtml)和[第21章](ch21.xhtml)中，我们更深入地探讨了NumPy、Matplotlib、pandas和scikit-learn。

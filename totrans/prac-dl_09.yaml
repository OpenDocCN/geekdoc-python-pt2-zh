- en: '**9'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**9**'
- en: TRAINING A NEURAL NETWORK**
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**训练神经网络**'
- en: '![image](Images/common.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/common.jpg)'
- en: 'In this chapter, we’ll discuss how to train a neural network. We’ll look at
    the standard approaches and tricks being used in the field today. There will be
    some math, some hand-waving, and a whole host of new terms and concepts. But you
    don’t need to follow the math at a deep level: we’ll gloss over things as needed
    to get the main point across.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论如何训练神经网络。我们将看看当前领域中使用的标准方法和技巧。会有一些数学内容，也会有一些不太详细的讨论，以及一系列新的术语和概念。但你不需要深刻理解数学内容：我们会适当地跳过一些细节，以便传达主要观点。
- en: This chapter is perhaps the most challenging in the book, at least conceptually.
    It certainly is mathematically. While it’s crucially important to building intuition
    and understanding, sometimes we get impatient and like to dive into things first
    to test the waters. Thanks to preexisting libraries, we can do that here. If you
    want to play around with neural networks before learning how they work, jump to
    [Chapter 10](ch10.xhtml#ch10) before coming back here to fill in the theory. But
    do come back.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章可能是本书中最具挑战性的部分，至少在概念上是如此。数学上肯定是这样。虽然它对建立直觉和理解至关重要，但有时我们会变得不耐烦，喜欢先跳进实际操作来试探一下。得益于现有的库，我们在这里可以这么做。如果你想在了解它们如何工作之前先玩玩神经网络，可以跳到[第10章](ch10.xhtml#ch10)，然后再回来补充理论。但一定要回来。
- en: It’s possible to learn to use powerful toolkits like sklearn and Keras without
    understanding how they work. That approach should not satisfy anyone, though the
    temptation is real. Understanding how these algorithms work is well worth your
    time.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 其实可以在不理解如何工作的情况下，学习使用像 sklearn 和 Keras 这样的强大工具包。尽管这种方法有其诱惑，但它不应令任何人满足。理解这些算法是非常值得花时间的。
- en: A High-Level Overview
  id: totrans-6
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 高级概述
- en: Let’s begin this chapter with an overview of the concepts we’ll discuss. Read
    it, but don’t fret if the concepts are unclear. Instead, try to get a feel for
    the overall process.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以本章将要讨论的概念概述开始。先阅读它，但如果这些概念不清楚也不必担心。相反，试着感受一下整体的过程。
- en: The first step in training a neural network is selecting intelligent initial
    values for the weights and biases. We then use *gradient descent* to modify these
    weights and biases so that we reduce the error over the training set. We’ll use
    the average value of the loss function to measure the error, which tells us how
    wrong the network currently is. We know if the network is right or wrong because
    we have the expected output for each input sample in the training set (the class
    label).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 训练神经网络的第一步是为权重和偏置选择智能的初始值。然后我们使用*梯度下降*来调整这些权重和偏置，从而减少训练集上的误差。我们将使用损失函数的平均值来衡量误差，它告诉我们网络当前的错误有多大。我们知道网络是对还是错，因为我们在训练集中对每个输入样本都有期望的输出（类别标签）。
- en: Gradient descent is an algorithm that requires gradients. For now, think of
    gradients as measures of steepness. The larger the gradient, the steeper the function
    is at that point. To use gradient descent to search for the smallest value of
    the loss function, we need to be able to find gradients. For that, we’ll use *backpropagation*.
    This is the fundamental algorithm of neural networks, the one that allows them
    to learn successfully. It gives us the gradients we need by starting at the output
    of the network and moving back through the network toward the input. Along the
    way, it calculates the gradient value for each weight and bias.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度下降是一种需要梯度的算法。目前，可以将梯度视为陡峭度的度量。梯度越大，函数在该点的陡峭程度越高。为了使用梯度下降寻找损失函数的最小值，我们需要能够找到梯度。为此，我们将使用*反向传播*。这是神经网络的基本算法，它使神经网络能够成功地进行学习。它通过从网络的输出开始，沿着网络向输入方向反向传播，计算每个权重和偏置的梯度值。
- en: With the gradient values, we can use the gradient descent algorithm to update
    the weights and biases so that the next time we pass the training samples through
    the network, the average of the loss function will be less than it was before.
    In other words, our network will be less wrong. This is the goal of training,
    and we hope it results in a network that has learned general features of the data.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 有了梯度值，我们可以使用梯度下降算法来更新权重和偏置，这样当我们下次将训练样本通过网络时，损失函数的平均值就会比之前小。换句话说，我们的网络会减少错误。这就是训练的目标，我们希望它能导致一个已经学习到数据一般特征的网络。
- en: Learning general features of the dataset requires *regularization*. There are
    many approaches to regularization, and we’ll discuss the main ones. Without regularization,
    the training process is in danger of overfitting, and we could end up with a network
    that doesn’t generalize. But with regularization, we can be successful and get
    a useful model.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 学习数据集的一般特征需要进行*正则化*。正则化有很多方法，我们将讨论其中的主要方法。没有正则化，训练过程可能会导致过拟合，最终得到一个无法泛化的网络。但通过正则化，我们可以取得成功，得到一个有用的模型。
- en: So, the following sections introduce gradient descent, backpropagation, loss
    functions, weight initialization, and, finally, regularization. These are the
    main components of successful neural network training. We don’t need to understand
    these in all their gory mathematical details; instead, we need to understand them
    conceptually so we can build an intuitive approach to what it means to train a
    neural network. With this intuition, we’ll be able to make meaningful use of the
    parameters that sklearn and Keras give us for training.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的章节将介绍梯度下降、反向传播、损失函数、权重初始化，最后是正则化。这些是成功训练神经网络的主要组成部分。我们不需要理解它们所有的复杂数学细节；相反，我们需要从概念上理解它们，这样才能建立直观的理解，了解训练神经网络的含义。有了这种直觉，我们就能充分利用sklearn和Keras为训练提供的参数。
- en: Gradient Descent
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 梯度下降
- en: The standard way to train a neural network is to use gradient descent.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 训练神经网络的标准方法是使用梯度下降。
- en: 'Let’s parse the phrase *gradient descent*. We already know what the word *descent*
    means. It means to go down from somewhere higher up. What about *gradient*? The
    short answer is that a gradient indicates how quickly something changes with respect
    to how fast something else changes. Measuring how much one thing changes as another
    changes is something we’re all familiar with. We all know about speed, which is
    how position changes as time changes. We even say it in words: *miles per hour*
    or *kilometers per hour*.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来解析一下短语*梯度下降*。我们已经知道“*下降*”是什么意思，指的是从更高的地方下降。那么“*梯度*”呢？简短的答案是，梯度表示某个事物随另一个事物变化的速度。衡量一个事物变化的程度与另一个事物变化的速度之间的关系，是我们都熟悉的。我们都知道速度，它表示位置随时间的变化程度。我们甚至用词语表示：*英里每小时*或*千米每小时*。
- en: You’re probably already familiar with the gradient in another context. Consider
    the equation of a line
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经在另一个上下文中熟悉梯度。考虑一下直线的方程
- en: '*y* = *mx* + *b*'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '*y* = *mx* + *b*'
- en: where *m* is the slope and *b* is the y-axis intercept. The slope is how quickly
    the line’s *y* position changes with each change in the *x* position. If we know
    two points that are on the line, (*x*[0],*y*[0]) and (*x*[1],*y*[1]), then we
    can calculate the slope as
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *m* 是斜率，*b* 是y轴截距。斜率表示直线的*y*位置随*x*位置变化的速度。如果我们知道直线上两个点（*x*[0],*y*[0]）和（*x*[1],*y*[1]），那么我们可以计算出斜率为
- en: '![image](Images/191equ01.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/191equ01.jpg)'
- en: 'which, in words, we might say as “*y*’s per *x*.” It’s a measure of how steep
    or shallow the line is: its gradient. In mathematics, we often talk about a change
    in a variable, and the notation for that is to put a Δ (delta) in front. So, we
    might write the slope of a line as'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 用文字表达时，我们可以说“*y* 每 *x*”。这衡量了直线的陡峭程度或平缓程度：即它的梯度。在数学中，我们经常讨论变量的变化，而表示变化的符号是在前面加上一个Δ（delta）。因此，我们可以将直线的斜率写作
- en: '![image](Images/191equ02.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/191equ02.jpg)'
- en: to drive home the point that the slope is the change in *y* for each change
    in *x*. Fortunately for us, it turns out that not only do lines have a slope at
    each point, but also most functions have a slope at each point. However, except
    for straight lines, this slope changes from point to point. A picture will help
    here. Consider [Figure 9-1](ch09.xhtml#ch9fig1).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 旨在强调斜率是每次*x*变化时*y*的变化量。幸运的是，事实证明，不仅直线在每个点都有斜率，大多数函数在每个点也有斜率。然而，除了直线以外，这个斜率会随点的不同而变化。这里用图示更能帮助理解。请参考[图
    9-1](ch09.xhtml#ch9fig1)。
- en: '![image](Images/09fig01.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/09fig01.jpg)'
- en: '*Figure 9-1: A function with several tangent lines indicated*'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 9-1：表示多个切线的函数*'
- en: The graph in [Figure 9-1](ch09.xhtml#ch9fig1) is of a polynomial. Notice the
    lines drawn on the figure that are just touching the function. These are *tangent*
    lines. And as lines, they have a slope we can see in the plot. Now imagine moving
    one of the lines over the function so that it continues to touch the function
    at only one point; imagine how the slope of the line changes as it moves.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 9-1](ch09.xhtml#ch9fig1)中的图形是一个多项式函数。注意图中画出的与函数相切的线。这些是 *切线*。作为直线，它们有一个可以在图中看到的斜率。现在想象将其中一条线移动到函数上，使其继续只在一个点与函数相切；想象一下，随着这条线的移动，其斜率是如何变化的。'
- en: It turns out that how the slope changes over the function is itself a function,
    and it’s called the *derivative*. Given a function and *x* value, the derivative
    tells us the slope of the function at that point, *x*. The fact that functions
    have derivatives is a fundamental insight of calculus, and of fundamental importance
    to us.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 事实证明，斜率如何随着函数的变化而变化本身就是一个函数，它叫做 *导数*。给定一个函数和 *x* 值，导数告诉我们该点 *x* 处的函数斜率。函数具有导数这一事实是微积分的一个基本洞察，对于我们至关重要。
- en: The notion of a derivative is essential because for single variable functions,
    the derivative at the point *x* is the gradient at *x*; it’s the direction in
    which the function is changing. If we want to find the minimum of the function,
    the *x* that gives us the smallest *y*, we want to move in the direction *opposite*
    to the gradient as that will move us in the direction of the minimum.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 导数的概念非常重要，因为对于单变量函数，*x* 处的导数就是该点的梯度；它是函数变化的方向。如果我们想找到函数的最小值，即给我们最小 *y* 的 *x*
    值，我们需要沿着与梯度方向 *相反* 的方向移动，因为这将把我们带到最小值的方向。
- en: The derivative is written in many different ways, but the way that echoes the
    idea of the slope, how *y* changes for a change in *x*, is
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 导数有许多不同的表示方式，但最能体现斜率概念的方式是，*y* 如何随着 *x* 的变化而变化。
- en: '![image](Images/192equ01.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/192equ01.jpg)'
- en: We’ll return to this form next when discussing the backpropagation algorithm.
    That’s it for the gradient; now let’s take a closer look at descent.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们讨论反向传播算法时，接下来会回到这种形式。梯度部分就讲到这里；现在让我们更仔细地看看下降过程。
- en: Finding Minimums
  id: totrans-31
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 寻找最小值
- en: Since we want a model that makes few mistakes, we need to find the set of parameters
    that lead to a small value for the loss function. In other words, we need to find
    a *minimum* of the loss function.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们希望模型尽量减少错误，我们需要找到一组参数，使得损失函数的值最小。换句话说，我们需要找到损失函数的 *最小值*。
- en: 'Look again at [Figure 9-1](ch09.xhtml#ch9fig1). The minimum is on the right,
    where tangent line C is. We can see it’s the minimum, and notice that the gradient
    is 0 there. This tells us we’re at a minimum (or maximum). If we start at B, we
    see that the slope of the tangent line is negative (down and to the right). Therefore,
    we need to move to an *x* value in the positive direction because this is opposite
    to the sign of the gradient. Doing this will take us closer to the minimum at
    C. Similarly, if we start at D, the slope of the tangent line is positive (up
    and to the right) meaning we need to move in the negative *x* direction, again
    toward C, to move closer to the minimum. All of this hints at an algorithm for
    finding the minimum of a function: pick a starting point (an *x* value) and use
    the gradient to move to a lower point.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 再次查看[图 9-1](ch09.xhtml#ch9fig1)。最小值位于右侧，就是切线 C 所在的位置。我们可以看到它是最小值，并且注意到此处梯度为
    0。这告诉我们我们处于一个最小值（或最大值）。如果我们从 B 开始，我们会看到切线的斜率为负（向下和向右）。因此，我们需要朝着 *x* 的正方向移动，因为这与梯度的符号相反。这样做会让我们离
    C 处的最小值更近。类似地，如果我们从 D 开始，切线的斜率为正（向上和向右），意味着我们需要朝着负 *x* 方向移动，再次朝 C 方向移动，以接近最小值。所有这些都暗示了一个寻找函数最小值的算法：选择一个起始点（一个
    *x* 值），然后利用梯度向较低的点移动。
- en: For simple functions of just *x*, like those of [Figure 9-1](ch09.xhtml#ch9fig1),
    this approach will work nicely, assuming we start in a good place like B or D.
    When we move to more than one dimension, it turns out that this approach will
    still work nicely provided we start in a good place with our initial guess.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 对于仅含有 *x* 的简单函数，如[图 9-1](ch09.xhtml#ch9fig1)中的那些函数，这种方法会很好地工作，前提是我们从像 B 或 D
    这样的合适位置开始。当我们进入更高维度时，事实证明，只要我们从一个合适的位置开始进行初步猜测，这种方法依然有效。
- en: Working still with [Figure 9-1](ch09.xhtml#ch9fig1) and assuming we’re starting
    at B, we see that the gradient tells us to move to the right, toward C. But how
    do we select the next *x* value to consider, to move us closer to C? This is the
    step size, and it tells us how big a jump we make from one *x* position to the
    next. Step size is a parameter we have to choose, and in practice this value,
    called the *learning rate*, is often fluid and gets smaller and smaller as we
    move, under the assumption that as we move, we get closer and closer to the minimum
    value and therefore need smaller and smaller steps.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 继续参考[图9-1](ch09.xhtml#ch9fig1)，假设我们从B开始，我们看到梯度告诉我们向右移动，朝C的方向。那么我们如何选择下一个要考虑的*x*值，从而使我们更接近C呢？这就是步长，它告诉我们从一个*x*位置跳跃到下一个位置的大小。步长是我们必须选择的一个参数，实际上，这个值被称为*学习率*，它通常是流动的，并且随着我们的移动逐渐变小，因为随着我们接近最小值，我们需要的步伐也越来越小。
- en: This is all well and good, even intuitive, but we have a small problem. What
    if instead of starting at B or D, we start at A? The gradient at A is pointing
    us to the left, not the right. In this case, our simple algorithm will fail—it
    will move us to the left, and we’ll never reach C. The figure shows only one minimum,
    at C, but we can easily imagine a second minimum, say to the left of A, that doesn’t
    go as low (doesn’t have as small a *y* value) as C. If we start at A, we’ll move
    toward this minimum, and not the one at C. Our algorithm will fall into a *local
    minimum*. Once in, our algorithm can’t get us out, and we won’t be able to find
    the global minimum at C. We’ll see that this is a genuine issue for neural networks,
    but one that for modern deep networks is, almost magically, not much of an issue
    after all.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这一切都很好，甚至是直观的，但我们有一个小问题。如果我们不是从B或D开始，而是从A开始呢？A处的梯度指向的是左边，而不是右边。在这种情况下，我们的简单算法会失败——它会把我们向左移动，我们永远无法到达C。图中只显示了一个最小值，位于C处，但我们可以轻松想象出第二个最小值，比如位于A的左侧，它的值没有C低（即*y*值不如C小）。如果我们从A开始，算法就会朝这个最小值前进，而不是朝C的最小值前进。我们的算法会陷入一个*局部最小值*。一旦陷入，我们的算法就无法把我们带出来，我们也无法找到位于C的全局最小值。我们会看到这是神经网络的一个真正问题，但对于现代深度网络来说，几乎是神奇地，这个问题并不大。
- en: So how does all of this help us train a neural network? The gradient tells us
    how a small change in *x* changes *y*. If *x* is one of the parameters of our
    network and *y* is the error given by the loss function, then the gradient tells
    us how much a change in that parameter affects the overall error of the network.
    Once we know that, we’re in a position to modify the parameter by an amount based
    on the gradient, and we know that this will move us toward a minimum error. When
    the error over the training set is at a minimum, we can claim that the network
    has been trained.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 那么这一切如何帮助我们训练神经网络呢？梯度告诉我们*x*的微小变化如何改变*y*。如果*x*是我们网络的参数之一，而*y*是损失函数给出的误差，那么梯度告诉我们该参数的变化对网络整体误差的影响有多大。一旦我们知道这一点，我们就可以根据梯度修改参数，知道这样做会让我们朝着最小误差的方向前进。当训练集上的误差达到最小值时，我们可以说网络已经被训练好了。
- en: 'Let’s talk a bit more about the gradients and parameters. All of our discussion
    to this point, based on [Figure 9-1](ch09.xhtml#ch9fig1), has been rather one-dimensional;
    our functions are functions of *x* only. We talked about changing one thing, the
    position along the x-axis, to see how it affects the *y* position. In reality,
    we’re not working with just one dimension. Every weight and bias in our network
    is a parameter, and the loss function value depends upon all of them. For the
    simple network in [Figure 8-1](ch08.xhtml#ch8fig1) alone, there are 20 parameters,
    meaning that the loss function is a 20-dimensional function. Regardless, our approach
    remains much the same: if we know the gradient for each parameter, we can still
    apply our algorithm in an attempt to locate a set of parameters minimizing the
    loss.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再多谈一点关于梯度和参数的事情。到目前为止，我们基于[图9-1](ch09.xhtml#ch9fig1)的讨论都相当一维；我们的函数只是*x*的函数。我们讨论的是改变一个东西——沿着x轴的位置——来看看它如何影响*y*的位置。实际上，我们并不是仅仅在处理一个维度。我们网络中的每个权重和偏置都是一个参数，而损失函数的值取决于所有这些参数。仅对于[图8-1](ch08.xhtml#ch8fig1)中的简单网络，就有20个参数，这意味着损失函数是一个20维的函数。尽管如此，我们的方法基本保持不变：如果我们知道每个参数的梯度，我们仍然可以应用我们的算法，试图找到一组最小化损失的参数。
- en: Updating the Weights
  id: totrans-39
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 更新权重
- en: 'We’ll talk about how to get gradient values in a bit, but for the time being
    let’s assume we have them already. We’ll say that we have a set of numbers that
    tells us how, given the current configuration of the network, a change in any
    weight or bias value changes the loss. With that knowledge, we can apply gradient
    descent: we adjust the weight or bias by some fraction of that gradient value
    to move us, collectively, toward a minimum of the entire loss function.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们稍后会谈到如何获取梯度值，但目前我们假设已经获得了这些值。我们假设有一组数字，告诉我们在当前网络配置下，任何权重或偏置值的变化如何改变损失。凭借这些信息，我们可以应用梯度下降：我们通过该梯度值的一部分来调整权重或偏置，带领我们集体朝着整个损失函数的最小值迈进。
- en: 'Mathematically, we update each weight and bias using a simple rule:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学角度来看，我们使用一个简单的规则更新每个权重和偏置：
- en: '*w* ← *w* –Δ*w*'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '*w* ← *w* –Δ*w*'
- en: Here *w* is one of the weights (or biases), *η* (eta) is the learning rate (the
    step size), and *Δw* is the gradient value.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的 *w* 是其中一个权重（或偏置），*η*（eta）是学习率（步长），而 *Δw* 是梯度值。
- en: '[Listing 9-1](ch09.xhtml#ch9lis1) gives an algorithm for training a neural
    network using gradient descent.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '[清单 9-1](ch09.xhtml#ch9lis1) 给出了一个使用梯度下降训练神经网络的算法。'
- en: 1\. Pick some intelligent starting values for the weights and biases.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 为权重和偏置选择一些智能的起始值。
- en: 2\. Run the training set through the network using its current weights and
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 使用当前权重将训练集传递通过网络，并进行计算。
- en: biases and calculate the average loss.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 偏置并计算平均损失。
- en: 3\. Use this loss to get the gradient for each weight and bias.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 使用该损失值来计算每个权重和偏置的梯度。
- en: 4\. Update the weight or bias value by the step size times the gradient value.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. 根据步长与梯度值的乘积更新权重或偏置值。
- en: 5\. Repeat from step 2 until the loss is low enough.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 5\. 从步骤 2 开始重复，直到损失足够低。
- en: '*Listing 9-1: Gradient descent in five (deceptively) simple steps*'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单 9-1：梯度下降的五个（看似）简单步骤*'
- en: The algorithm appears simple, but as they say, the devil is in the details.
    We have to make choices at every step, and every choice we make will prompt further
    questions. For example, step 1 says to “Pick some intelligent starting values.”
    What should they be? It turns out that successfully training a neural network
    depends critically on choosing good initial values. We already saw how this might
    be so in our preceding example using [Figure 9-1](ch09.xhtml#ch9fig1) where if
    we start at A, we won’t find the minimum at C. Much research has been conducted
    over the years related to step 1.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这个算法看起来简单，但正如他们所说，魔鬼藏在细节中。我们必须在每一步做出选择，每个选择都会引发进一步的问题。例如，步骤 1 说要“选择一些智能的起始值。”它们应该是什么呢？事实证明，成功训练神经网络在很大程度上依赖于选择合适的初始值。我们在之前的例子中已经看到，如果从
    A 开始，就无法找到 C 处的最小值。多年来，关于步骤 1 的研究已取得了大量成果。
- en: Step 2 is straightforward; it’s the forward-pass through the network. We haven’t
    talked in detail about the loss function itself; for now, just think of it as
    a function measuring the effectiveness of the network on the training set.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤 2 是直接的；它是通过网络的前向传播。我们还没有详细讨论损失函数本身；目前，只需将其视为衡量网络在训练集上有效性的一个函数。
- en: Step 3 is a black box for the time being. We’ll explore how to do it shortly.
    For now, assume we can find the gradient values for each parameter.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤 3 目前是一个黑箱。我们稍后会探索如何完成这一部分。现在，假设我们能够找到每个参数的梯度值。
- en: Step 4 follows the form of the previous equation that moves the parameter from
    its current value to one that will reduce the overall loss. In practice, the simple
    form of this equation is not sufficient; there are other terms, like momentum,
    that preserve some fraction of the previous weight change for the next iteration
    (next pass of the training data through the network) so that parameters do not
    change too wildly. We’ll revisit momentum later. For now, let’s look at a variation
    of gradient descent, the one that is actually used to train deep networks.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤 4 遵循前面方程的形式，将参数从当前值更新为可以减少总体损失的值。实际上，这个方程的简单形式不足够；还有其他项，例如动量，能够保留前一轮权重变化的一部分，用于下一轮迭代（训练数据通过网络的下一次传递），以确保参数不会发生剧烈变化。我们稍后会重新讨论动量。现在，让我们来看一下梯度下降的一种变种，这种变种实际上被用于训练深度网络。
- en: Stochastic Gradient Descent
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 随机梯度下降
- en: The previous steps describe gradient descent training of a neural network. As
    we might expect, in practice there are many different flavors of this basic idea.
    One that’s in widespread use and works well empirically is called *stochastic
    gradient descent (SGD)*. The word *stochastic* refers to a random process. We’ll
    see next why the word *stochastic* goes before *gradient descent* in this case.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的步骤描述了神经网络的梯度下降训练。正如我们预期的那样，在实践中，这个基本思想有许多不同的变种。一种广泛使用并且在实践中表现良好的方法被称为*随机梯度下降（SGD）*。其中，*随机*一词指的是一个随机过程。接下来我们将看到为什么在这种情况下，*随机*一词放在*梯度下降*之前。
- en: Batches and Minibatches
  id: totrans-58
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 批次和小批次
- en: 'Step 2 of [Listing 9-1](ch09.xhtml#ch9lis1) says to run the complete training
    set through the network using the current values of the weights and biases. This
    approach is called *batch training*, so named because we use all of the training
    data to estimate the gradients. Intuitively, this is a reasonable thing to do:
    we’ve carefully constructed the training set to be a fair representation of the
    unknown parent process that generates the data, and it’s this parent process we
    want the network to successfully model for us.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[清单 9-1](ch09.xhtml#ch9lis1)的第2步说要使用当前的权重和偏置值将整个训练集通过网络处理。这种方法叫做*批量训练*，因为我们使用所有训练数据来估算梯度。直观来说，这是合理的做法：我们已经仔细构建了训练集，使其能够公平地代表生成数据的未知父过程，而正是这个父过程我们希望网络能够成功地为我们建模。'
- en: If our dataset is small, like the original iris dataset of [Chapter 5](ch05.xhtml#ch05),
    then batch training makes sense. But what if our training dataset isn’t small?
    What if it’s hundreds of thousands or even millions of samples? We’ll be facing
    longer and longer training times.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的数据集很小，比如 [第5章](ch05.xhtml#ch05)中的原始鸢尾花数据集，那么批量训练是有意义的。但是如果我们的训练数据集不是很小呢？如果它有数十万甚至数百万个样本呢？我们将面临越来越长的训练时间。
- en: We’ve run into a problem. We want a large training set as that will (hopefully)
    better represent the unknown parent process that we want to model. But the larger
    the training set, the longer it takes to pass each sample through the network,
    get an average value for the loss, and update the weights and biases. We call
    passing the entire training set through the network an *epoch*, and we’ll need
    many dozens to hundreds of epochs to train the network. Doing a better job of
    representing the thing we want to model means longer and longer computation times
    because of all the samples that must be passed through the network.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们遇到了一个问题。我们想要一个大的训练集，因为它（希望）能更好地代表我们想要建模的未知父过程。但是，训练集越大，每次通过网络处理每个样本、获取平均损失值并更新权重和偏置的时间就越长。我们称将整个训练集通过网络处理一遍为*一个epoch*，我们将需要许多几十到几百个epoch来训练网络。为了更好地表示我们想要建模的事物，这意味着必须通过网络的样本数量越来越多，从而导致计算时间越来越长。
- en: This is where SGD comes into play. Instead of using all the training data on
    each pass, let’s alternatively select a small subset of the training data and
    use the average loss calculated from it to update the parameters. We’ll calculate
    an “incorrect” gradient value because we’re estimating the loss over the full
    training set using only a small sample, but we’ll save a lot of time.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这时，SGD派上了用场。我们不再在每次迭代时使用所有训练数据，而是交替选择训练数据的一个小子集，并使用从中计算出的平均损失来更新参数。我们将计算一个“错误的”梯度值，因为我们仅使用一个小样本来估算整个训练集的损失，但这样可以节省大量时间。
- en: 'Let’s see how this sampling plays out with a simple example. We’ll define a
    vector of 100 random bytes using NumPy:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个简单的例子来看看这种采样是如何发挥作用的。我们将使用NumPy定义一个包含100个随机字节的向量：
- en: '>>> d = np.random.normal(128,20,size=100).astype("uint8")'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> d = np.random.normal(128, 20, size=100).astype("uint8")'
- en: '>>> d'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> d'
- en: 130, 141,  99, 106, 135, 119,  98, 147, 152, 163, 118, 149, 122,
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 130, 141, 99, 106, 135, 119, 98, 147, 152, 163, 118, 149, 122,
- en: 133, 115, 128, 176, 132, 173, 145, 152,  79, 124, 133, 158, 111,
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 133, 115, 128, 176, 132, 173, 145, 152, 79, 124, 133, 158, 111,
- en: 139, 140, 126, 117, 175, 123, 154, 115, 130, 108, 139, 129, 113,
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 139, 140, 126, 117, 175, 123, 154, 115, 130, 108, 139, 129, 113,
- en: 129, 123, 135, 112, 146, 125, 134, 141, 136, 155, 152, 101, 149,
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 129, 123, 135, 112, 146, 125, 134, 141, 136, 155, 152, 101, 149,
- en: 137, 119, 143, 136, 118, 161, 138, 112, 124,  86, 135, 161, 112,
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 137, 119, 143, 136, 118, 161, 138, 112, 124, 86, 135, 161, 112,
- en: 117, 145, 140, 123, 110, 163, 122, 105, 135, 132, 145, 121,  92,
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 117, 145, 140, 123, 110, 163, 122, 105, 135, 132, 145, 121, 92,
- en: 118, 125, 154, 148,  92, 142, 118, 128, 128, 129, 125, 121, 139,
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 118, 125, 154, 148, 92, 142, 118, 128, 128, 129, 125, 121, 139,
- en: 152, 122, 128, 126, 126, 157, 124, 120, 152
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 152, 122, 128, 126, 126, 157, 124, 120, 152
- en: Here the byte values are normally distributed around a mean of 128\. The actual
    mean of the 100 values is 130.9\. Selecting subsets of these values, 10 at a time,
    gives us an estimate of the actual mean value
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，字节值围绕128的均值呈正态分布。100个值的实际均值为130.9。每次选择这些值的子集，取10个值，会给出实际均值的估计值。
- en: '>>> i = np.argsort(np.random.random(100))'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> i = np.argsort(np.random.random(100))'
- en: '>>> d[i[:10]].mean()'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '>>> d[i[:10]].mean()'
- en: '138.9'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '138.9'
- en: with repeated subsets leading to estimated means of 135.7, 131.7, 134.2, 128.1,
    and so forth.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 通过重复子集，得到的估计均值分别为135.7、131.7、134.2、128.1，依此类推。
- en: None of the estimated means are the actual mean, but they are all close to it.
    If we can estimate the mean from a random subset of the full dataset, we can see
    by analogy that we should be able to estimate the gradients of the loss function
    with a subset of the full training set. Since the sample is randomly selected,
    the resulting gradient values are randomly varying estimates. This is why we add
    the word *stochastic* in front of *gradient descent*.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 所有估计的均值都不是实际均值，但它们都非常接近。如果我们可以通过随机选择一个子集来估计均值，那么我们可以通过类比来推测，应该也能够通过完整训练集的一个子集来估计损失函数的梯度。由于样本是随机选择的，结果的梯度值是随机变化的估计值。这就是为什么我们在*梯度下降*前加上了*随机*二字。
- en: 'Because passing the full training set through the network on each weight and
    bias update step is known as *batch training*, passing a subset through is known
    as *minibatch training*. You will hear people use the term *minibatch* quite frequently.
    A minibatch is the subset of the training data used for each stochastic gradient
    descent step. Training is usually some number of epochs, where the relationship
    between epochs and minibatches is as follows:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 由于每次通过网络进行权重和偏差更新时，都需要将完整的训练集传递给网络，这被称为*批量训练*；而传递子集则被称为*小批量训练*。你会经常听到有人提到*小批量*。小批量是用于每次随机梯度下降步骤的训练数据子集。训练通常包括若干个周期（epochs），周期与小批量的关系如下：
- en: '![image](Images/196equ01.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/196equ01.jpg)'
- en: 'In practice, we don’t really want to select the minibatches at random from
    the full training set. If we do that, we run the risk of not using all the samples:
    some might never be selected, and others might be selected too often. Typically,
    we randomize the order of the training samples and select fixed-size blocks of
    samples sequentially whenever a minibatch is required. When all available training
    samples are used, we can shuffle the full training set order and repeat the process.
    Some deep learning toolkits don’t even do this; they instead cycle through the
    same set of minibatches again.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，我们并不希望从完整的训练集中随机选择小批量数据。如果我们这么做，可能会面临无法使用所有样本的风险：有些样本可能永远不会被选择，而有些样本可能会被选择得过于频繁。通常，我们会打乱训练样本的顺序，并在每次需要小批量时顺序地选择固定大小的样本块。当所有可用的训练样本都被使用完后，我们可以重新打乱完整训练集的顺序并重复这一过程。一些深度学习工具包甚至不这么做；它们会再次循环使用同一组小批量数据。
- en: Convex vs. Nonconvex Functions
  id: totrans-83
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 凸函数与非凸函数
- en: SGD sounds like a concession to practicality. In theory, it seems that we’d
    never want to use it, and we might expect that our training results will suffer
    because of it. However, the opposite is generally true. In some sense, gradient
    descent training of a neural network shouldn’t work at all because we’re applying
    an algorithm meant for convex functions to one that is nonconvex. [Figure 9-2](ch09.xhtml#ch9fig2)
    illustrates the difference between a convex function and a nonconvex function.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: SGD 听起来像是对实践的妥协。从理论上看，我们似乎不应该使用它，而且我们可能会期望它会使我们的训练结果受损。然而，通常情况正好相反。从某种意义上说，神经网络的梯度下降训练本不应该有效，因为我们正在将一种针对凸函数的算法应用到非凸函数上。[图
    9-2](ch09.xhtml#ch9fig2)展示了凸函数与非凸函数之间的区别。
- en: '![image](Images/09fig02.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/09fig02.jpg)'
- en: '*Figure 9-2: A convex function of* x *(left). A nonconvex function of* x *(right)*.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 9-2：*x* 的凸函数（左）。*x* 的非凸函数（右）*。'
- en: A convex function is such that a line segment between any two points on the
    function does not cross the function at any other point. The black line on the
    left of [Figure 9-2](ch09.xhtml#ch9fig2) is one example, and any such segment
    will not cross the function at any other point, indicating that this is a convex
    function. However, the same can’t be said of the curve on the right of [Figure
    9-2](ch09.xhtml#ch9fig2). This is the curve from [Figure 9-1](ch09.xhtml#ch9fig1).
    Here the black line does cross the function.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 凸函数的特点是，函数上任意两点之间的线段不会与函数在其他点交叉。[图9-2](ch09.xhtml#ch9fig2)左侧的黑线就是一个例子，任何这样的线段都不会在其他点交叉函数，表明这是一个凸函数。然而，右侧的曲线就不能这么说了，那是[图9-1](ch09.xhtml#ch9fig1)中的曲线。这里的黑线确实与函数交叉。
- en: Gradient descent is designed to find the minimum when the function is convex,
    and because it relies only on the gradient, the first derivative, it’s sometimes
    known as a *first-order* optimization method. Gradient descent should not work,
    in general, with nonconvex functions because it runs the risk of getting trapped
    in a local minimum instead of finding the global minimum. Again, we saw this with
    the example in [Figure 9-1](ch09.xhtml#ch9fig1).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度下降法是为寻找函数的最小值而设计的，适用于凸函数，并且因为它仅依赖于梯度（一阶导数），所以有时被称为*一阶*优化方法。一般来说，梯度下降法在非凸函数中不应有效，因为它有可能陷入局部最小值，而无法找到全局最小值。我们在[图9-1](ch09.xhtml#ch9fig1)的例子中也看到了这一点。
- en: Here’s where stochastic gradient descent helps. In multiple dimensions, the
    gradient will point in a direction that isn’t necessarily toward the nearest minimum
    of the loss function. This means that our step will be in a slightly wrong direction,
    but that somewhat wrong direction might help us avoid getting trapped somewhere
    we don’t want to be.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是随机梯度下降法的帮助之处。在多维空间中，梯度会指向一个方向，这个方向不一定朝向损失函数的最近最小值。这意味着我们的步伐会稍微偏离正确的方向，但这种偏离可能帮助我们避免被困在不想去的地方。
- en: The situation is more complicated, of course, and more mysterious. The machine
    learning community has been struggling with the contradiction between the obvious
    success of using first-order optimization on the nonconvex loss function and the
    fact that it shouldn’t work at all.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，情况更加复杂，也更加神秘。机器学习社区一直在努力解决使用一阶优化方法在非凸损失函数上的明显成功与这种方法理论上不应有效之间的矛盾。
- en: Two ideas are emerging. The first is what we just stated, that stochastic gradient
    descent helps by actually moving us in a slightly wrong direction. The second
    idea, which seems to be pretty much proven now, is that, for the loss functions
    used in deep learning, it turns out that there are many, many local minimums and
    that these are all basically the same, so that landing in almost any one of them
    will result in a network that performs well.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 目前有两个观点正在浮现。第一个就是我们刚才提到的，随机梯度下降通过实际将我们引导到稍微错误的方向来帮助我们。第二个观点，目前似乎已经得到了充分证明，即在深度学习中使用的损失函数中，实际上存在着许多局部最小值，而且这些局部最小值基本上是相同的，因此几乎到达任何一个局部最小值都会得到一个表现良好的网络。
- en: Some researchers argue that most gradient descent learning winds up on a *saddle
    point*; this is a place that looks like a minimum but isn’t. Imagine a saddle
    for a horse and place a marble in the middle. The marble will sit in place, but
    you could push the marble in a certain direction and have it roll off the saddle.
    The argument, not without some justification, is that most training ends on a
    saddle point, and better results are possible with a better algorithm. Again,
    however, even the saddle point, if it is one, is still for practical purposes
    a good place to be, so the model is successful regardless.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 一些研究人员认为，大多数梯度下降学习最终停留在*鞍点*；这是一个看起来像最小值，但实际上不是的地方。想象一下马鞍，并在中间放一个弹珠。弹珠会停在原地，但你可以将弹珠推向某个方向，使它滚出鞍点。这个观点并非没有道理，认为大多数训练最终会停在鞍点，而更好的算法可能会带来更好的结果。然而，即使鞍点真的是鞍点，从实际应用的角度看，它仍然是一个不错的选择，因此模型依然是成功的。
- en: In practice, then, we should use stochastic gradient descent because it leads
    to better overall learning and reduces the training time by not requiring full
    batches. It does introduce a new hyperparameter, the minibatch size, that we must
    select at some point before training.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际操作中，我们应该使用随机梯度下降，因为它能带来更好的整体学习效果，并通过不需要完整批次来减少训练时间。它引入了一个新的超参数，即小批量大小，我们必须在训练前某个时刻选择它。
- en: Ending Training
  id: totrans-94
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 结束训练
- en: 'We haven’t yet discussed a critical question: when should we stop training?
    Remember that in [Chapter 5](ch05.xhtml#ch05), we went through some effort to
    create training sets, validation sets, and test sets. This is where we’ll use
    the validation sets. While training, we can use the accuracy, or some other metric,
    on the validation set to decide when to stop. If using SGD, we typically run the
    validation set through the network for each minibatch or set of minibatches to
    compute the accuracy. By tracking the accuracy on the validation set, we can decide
    when to stop training.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还没有讨论一个关键问题：我们应该在什么时候停止训练？记得在[第5章](ch05.xhtml#ch05)中，我们曾努力创建训练集、验证集和测试集。这就是我们将在此使用验证集的地方。在训练过程中，我们可以通过验证集上的准确率或其他度量来决定何时停止训练。如果使用SGD，我们通常会在每个小批次或小批次集上运行验证集，以计算准确率。通过跟踪验证集上的准确率，我们可以决定何时停止训练。
- en: If we train for a long time, eventually two things usually happen. The first
    is that the error on the training set goes toward zero; we get better and better
    on the training set. The second is that the error on the validation set goes down
    and then, eventually, starts to go back up.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们训练很长时间，最终通常会发生两件事。第一件事是训练集上的误差趋近于零；我们在训练集上的表现越来越好。第二件事是验证集上的误差先下降，然后最终开始回升。
- en: These effects are due to overfitting. The training error goes down and down
    as the model learns more and more to represent the parent distribution that generated
    the dataset. But, eventually, it will stop learning general things about the training
    set. At this point, we’re overfitting, and we want to stop training because the
    model is no longer learning general features and is instead learning minutiae
    about the particular training set we’re using. We can watch for this by using
    the validation set while training. Since we don’t use the samples in the validation
    set to update the weights and biases of the network, it should give us a fair
    test of the current state of the network. When overfitting starts, the error on
    the validation set will begin to go up from a minimum value. What we can do then
    is to keep the weights and biases that produced the minimum value on the validation
    set and claim that those represent the best model.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这些效果是由于过拟合造成的。随着模型不断学习更多、更好地表示生成数据集的母体分布，训练误差会不断下降。但最终，它将停止学习关于训练集的一般性特征。在这一点上，我们已经发生了过拟合，我们希望停止训练，因为模型不再学习一般特征，而是开始学习关于我们使用的特定训练集的细节。我们可以通过在训练过程中使用验证集来监控这一现象。由于我们不使用验证集中的样本来更新网络的权重和偏差，它应该能公正地测试当前网络的状态。当过拟合开始时，验证集上的误差将从最小值开始上升。此时，我们可以保留产生验证集最小误差的权重和偏差，并声称它们代表了最好的模型。
- en: We don’t want to use any data that has influenced training to measure the final
    effectiveness of our network. We use the validation set to decide when to stop
    training, so characteristics of the samples in the validation set have also influenced
    the final model; this means we can’t strongly rely on the validation set to give
    us an idea of how the model will behave on new data. It’s only the held-out test
    set, unused until we declare victory over training, that gives us some idea of
    how we might expect the model to perform on data in the wild. So, just as it is
    anathema to report training set accuracy as a measure of how good the model is,
    it’s also anathema to report the validation set accuracy.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不希望使用任何已经影响了训练的数据来衡量我们网络的最终效果。我们使用验证集来决定何时停止训练，因此验证集中的样本特征也影响了最终模型；这意味着我们不能过于依赖验证集来判断模型在新数据上的表现。只有在我们宣布训练成功后，未使用的测试集才能给我们一个大致的模型在实际数据上表现的预期。所以，正如将训练集的准确率作为模型好坏的衡量标准是错误的，报告验证集准确率同样也是错误的。
- en: Updating the Learning Rate
  id: totrans-99
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 更新学习率
- en: In our generic update equation for changing the weights and biases based on
    the gradient, we introduced a hyperparameter, *η* (eta), the learning rate or
    step size. It’s a scale factor indicating how much we should update the weight
    or bias based on the gradient value.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们用于基于梯度更新权重和偏差的通用更新方程中，我们引入了一个超参数，*η*（eta），即学习率或步长。它是一个缩放因子，表示我们应根据梯度值更新权重或偏差的幅度。
- en: We previously stated that the learning rate doesn’t need to be fixed and that
    it could, and even should, get smaller and smaller as we train under the assumption
    that we need smaller and smaller steps to get to the actual minimum value of the
    loss function. We didn’t state how we should actually update the learning rate.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: There’s more than one way to update the step size, but some are more helpful
    than others. The MLPClassifier class of sklearn, which uses SGD solvers, has three
    options. The first is to never change the learning rate—just leave *η* at its
    initial value, *η*[0]. The second is to scale *η* so that it decreases with epochs
    (minibatches) according to
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/199equ01.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
- en: where *η*[0] is set by the user, *t* is the iteration (epoch, minibatch), and
    *p* is an exponent on *t*, also picked by the user. The sklearn default *p* is
    0.5—that is, scale by ![Image](Images/199equ02.jpg), which seems a reasonable
    default.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: The third option is to adapt the learning rate by watching the loss function
    value. As long as the loss is decreasing, leave the learning rate where it is.
    When the loss stops decreasing for a set number of minibatches, divide the learning
    rate by some value like 5, the sklearn default. If we never change the learning
    rate, and it’s too large, we might end up moving around the minimum without ever
    being able to reach it because we’re consistently stepping over it. It’s a good
    idea then to decrease the learning rate when using SGD. Later in the book, we’ll
    encounter other optimization approaches that automatically adjust the learning
    rate for us.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: Momentum
  id: totrans-106
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: There’s one last wrinkle in SGD we have to cover. As we saw previously, the
    weight update equation for both gradient descent and SGD is
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: '*w* ← *w* – *η*Δ*w*'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: We update the weight by the learning rate (*η*) times the gradient, which we
    are representing here as Δ*w*.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: A common and powerful trick is to introduce a *momentum* term that adds back
    some fraction of the previous Δ*w*, the update of the prior minibatch. The momentum
    term prevents the *w* parameter from changing too quickly in response to a particular
    minibatch. Adding in this term gives us
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '*w*[*i*+1] ← *w*[*i*] – *η*Δ*w*[*i*] + *μ*Δ*w*[*i–1*]'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: We’ve added subscripts to indicate the next pass through the network (*i* +
    1), the current pass (*i*), and the previous pass (*i –* 1). The previous pass
    Δ*w* is the one we need to use. A typical value for *μ* (mu), the momentum, is
    around 0.9\. Virtually all toolkits implement momentum in some form, including
    sklearn.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: Backpropagation
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We’ve been operating under the assumption that we know the gradient value for
    each parameter. Let’s discuss how the backpropagation algorithm gives us these
    magic numbers. The backpropagation algorithm is perhaps the single most important
    development in the history of neural networks as it enables the training of large
    networks with hundreds, thousands, millions, and even billions of parameters.
    This is especially true of the convolutional networks we’ll work with in [Chapter
    12](ch12.xhtml#ch12).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: The backpropagation algorithm itself was published by Rumelhart, Hinton, and
    Williams in 1986 in their paper “Learning Representations by Back-propagating
    Errors.” It’s a careful application of the chain rule for derivatives. The algorithm
    is called *backpropagation* because it works backward from the output layer of
    the network toward the input layer, propagating the error from the loss function
    down to each parameter of the network. Colloquially, the algorithm is known as
    *backprop*; we’ll use that term here, so we sound more like native machine learning
    experts.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: Adding backprop into the training algorithm for gradient descent, and tailoring
    it to SGD, gives us the algorithm in [Listing 9-2](ch09.xhtml#ch9lis2).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Pick some intelligent starting values for the weights and biases.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Run a minibatch through the network using its current weights and biases
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: and calculate the average loss.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Use this loss and backprop to get the gradient for each weight and bias.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Update the weight or bias value by the step size times the gradient value.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Repeat from step 2 until the loss is low enough.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '*Listing 9-2: Stochastic gradient descent with backprop*'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: Step 2 of [Listing 9-2](ch09.xhtml#ch9lis2) is referred to as the *forward pass*;
    step 3 is the *backward pass*. The forward pass is also how we’ll use the network
    after it’s finally trained. The backward pass is backprop calculating the gradients
    for us so that we can update the parameters in step 4.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll describe backprop twice. First, we’ll do so with a simple example and
    work with the actual derivatives. Second, we’ll work with a more abstract notation
    to see how backprop applies to actual neural networks in a general sense. There
    is no way to sugarcoat this: this section involves derivatives, but we already
    have a good intuitive sense of what those are from our discussion of gradient
    descent, so we should be in good shape to proceed.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: Backprop, Take 1
  id: totrans-126
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Suppose we have two functions, *z* = *f* (*y*) and *y* = *g*(*x*), meaning
    *z* = *f* (*g*(*x*)). We know that the derivative of the function *g* gives us
    *dy*/*dx*, which tells us how *y* changes when *x* changes. Similarly, we know
    that the derivative of the function *f* will give us *dz*/*dy*. The value of *z*
    depends upon the composition of *f* and *g*, meaning the output of *g* is the
    input to *f*, so if we want to find an expression for *dz*/*dx*, how *z* changes
    with *x*, we need a way to link through the composed functions. This is what the
    chain rule for derivatives gives us:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有两个函数，*z* = *f* (*y*) 和 *y* = *g*(*x*)，意味着 *z* = *f* (*g*(*x*)）。我们知道函数 *g*
    的导数给我们 *dy*/*dx*，它告诉我们 *y* 如何随着 *x* 的变化而变化。类似地，我们知道函数 *f* 的导数会给我们 *dz*/*dy*。*z*
    的值依赖于 *f* 和 *g* 的复合，意味着 *g* 的输出是 *f* 的输入，因此，如果我们想找到 *dz*/*dx* 的表达式，也就是 *z* 如何随
    *x* 变化，我们需要一种通过复合函数进行链接的方式。这就是链式法则为导数提供的内容：
- en: '![image](Images/201equ01.jpg)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/201equ01.jpg)'
- en: This notation is especially nice because we can imagine the *dy* “term” canceling
    just as it would if these were actual fractions.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这种符号特别好，因为我们可以想象 *dy* “项”会像实际分数那样消去。
- en: How does this help us? In a neural network, the output of one layer is the input
    to the next, which is composition, so we can see intuitively that the chain rule
    might apply. Remember that we want the values that tell us how the loss function
    changes with respect to the weights and biases. Let’s call the loss function *L*
    and any given weight or bias *w*. We want to calculate *∂*ℒ/*∂w* for all the weights
    and biases.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这对我们有何帮助？在神经网络中，一层的输出是下一层的输入，这是一种复合关系，所以我们可以直观地看到链式法则可能适用。记住，我们想要的是告诉我们损失函数如何相对于权重和偏置变化的值。我们将损失函数称为
    *L*，任何给定的权重或偏置称为 *w*。我们想要计算所有权重和偏置的 *∂*ℒ/*∂w*。
- en: Alarm bells should be going off in your head. The previous paragraph slipped
    in new notation. So far, we’ve been writing derivatives as *dy*/*dx*, but the
    derivative for the loss with respect to a weight was written as *∂*ℒ/*∂w*. What
    is this fancy *∂*?
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 警钟应该在你脑中响起。前一段引入了新的符号。到目前为止，我们一直用 *dy*/*dx* 来表示导数，但损失函数相对于权重的导数被写作 *∂*ℒ/*∂w*。这个复杂的
    *∂* 是什么？
- en: When we had a function of one variable, just *x*, there was only one slope at
    a point to talk about. As soon as we have a function with more than one variable,
    the idea of the slope at a point becomes ambiguous. There are an infinite number
    of lines tangent to the function at any point. So we need the idea of the *partial
    derivative*, which is the slope of the line in the direction of the variable we’re
    considering when all other variables are treated as fixed. This tells us how the
    output will change as we change only the one variable. To note that we are using
    a partial derivative, we shift from *d* to *∂*, which is just a script *d*.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们只有一个变量的函数时，只有一个斜率可以讨论，即 *x*。一旦我们有了多个变量的函数，点处的斜率概念就变得模糊。任何一点都有无数条与函数相切的线。所以我们需要
    *偏导数* 的概念，它是沿着我们正在考虑的变量方向的切线斜率，同时将所有其他变量视为固定。这告诉我们当我们仅改变一个变量时，输出将如何变化。为了表示我们正在使用偏导数，我们将
    *d* 改为 *∂*，它只是一个手写体的 *d*。
- en: Let’s set up a straightforward network so that we can see how the chain rule
    leads directly to the expressions we want. We’re looking at the network in [Figure
    9-3](ch09.xhtml#ch9fig3), which consists of an input, two hidden layers of a single
    node each, and an output layer.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们建立一个简单的网络，这样我们就能看到链式法则如何直接得到我们想要的表达式。我们正在查看 [图 9-3](ch09.xhtml#ch9fig3) 中的网络，它由一个输入、两个各自包含一个节点的隐藏层和一个输出层组成。
- en: '![image](Images/09fig03.jpg)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![image](Images/09fig03.jpg)'
- en: '*Figure 9-3: A simple network to illustrate the chain rule*'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 9-3：一个简单的网络，用于说明链式法则*'
- en: For simplicity, we’ll ignore any bias values. Additionally, let’s define the
    activation function to be the identity function, *h*(*x*) = *x*. This simplification
    removes the derivative of the activation function to make things more transparent.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化，我们将忽略任何偏置值。此外，我们假设激活函数为恒等函数，*h*(*x*) = *x*。这个简化去除了激活函数的导数，使得事情更加清晰。
- en: For this network, the forward pass computes
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个网络，前向传播计算
- en: '*h*[1] = *w*[1]*x*'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '*h*[1] = *w*[1]*x*'
- en: '*h*[2] = *w*[2]*h*[1]'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '*h*[2] = *w*[2]*h*[1]'
- en: '*y* = *w*[3]*h*[2]'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '*y* = *w*[3]*h*[2]'
- en: which follows the form we’ve used previously, chaining things together by making
    the output of one layer the input to the next. This gives us the output of the
    network, *y*, for input *x*. If we’re looking to train the network, we’ll have
    a training set, a set of pairs, (*x*[*i*], *ŷ*), *i* = 0, 1, …, that are examples
    of what the output should be for a given input. Note that the forward pass moved
    from the input, *x*, to the output, *y*. We’ll next see why the backward pass
    moves from the output to the input.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s define the loss function, *ℒ*, to be the squared error between *y*,
    the network output for a given input *x*, and *ŷ*, the output we should get. Functionally,
    the loss looks like the following.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/202equ02.jpg)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
- en: For simplicity, we’re ignoring the fact that the loss is a mean over the training
    set or some minibatch drawn from it. The factor of ![Image](Images/1by2.jpg) is
    not strictly necessary but it’s commonly used to make the derivative a bit nicer.
    Since we’re looking to minimize the loss for a particular set of weights, it doesn’t
    matter that we’re always multiplying the loss by a constant factor of ![Image](Images/1by2.jpg)—the
    smallest loss will still be the smallest loss regardless of its actual numeric
    value.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: 'To use gradient descent, we need to find how the loss changes with the weights.
    In this simple network, that means we need to find three gradient values, one
    each for *w*[1], *w*[2], and *w*[3]. This is where the chain rule comes into play.
    We’ll write the equations first and then talk about them:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/202equ03.jpg)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
- en: 'The order of these equations shows why this algorithm is called *backpropagation*.
    To get the partial derivative for the output layer parameter, we need only the
    output and the loss, *y* and *ℒ*. To get the partial derivative for the middle
    layer weight, we need the following two partial derivatives from the output layer:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/203equ01.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
- en: Finally, to get the partial derivative for the input layer weight, we need partial
    derivatives from the output and middle layer. In effect, we have moved backward
    through the network propagating values from later layers.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: For each of these equations, the right-hand side matches the left-hand side
    if we imagine the “terms” canceling like fractions. Since we selected a particularly
    simple form for the network, we can calculate the actual gradients by hand. We
    need the following gradients, from the right-hand side of the preceding equations.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/203equ02.jpg)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
- en: The *∂ℒ*/*∂y* comes from the form we selected for the loss and the rules of
    differentiation from calculus.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: Putting these back into the equations for the gradients of the weights gives
    us
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/204equ01.jpg)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
- en: After a forward pass, we have numeric values for all the quantities on the right-hand
    side of these equations. Therefore, we know the numeric value of the gradients.
    The update rule from gradient descent then tells us to change the weights like
    the following.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/204equ02.jpg)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
- en: where *η* is the learning rate parameter defining how large a step to take when
    updating.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: To recap, we need to use the chain rule, the heart of the backprop algorithm,
    to find the gradients we need to update the weights during training. For our simple
    network, we were able to work out the value of these gradients explicitly by moving
    backward through the network from the output toward the input. Of course, this
    is just a toy network. Let’s now take a second look at how to use backprop in
    a more general sense to calculate the necessary gradients for any network.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: Backprop, Take 2
  id: totrans-159
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Let’s begin by revisiting the loss function and introducing some new notation.
    The loss function is a function of all the parameters in the network, meaning
    that every weight and bias value contributes to it. For example, the loss for
    the network of [Figure 8-1](ch08.xhtml#ch8fig1), which has 20 weights and biases,
    could be written as
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/205equ01.jpg)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
- en: 'Note we’ve introduced a new notation for the parameters:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/205equ02.jpg)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
- en: This represents the weight that links the *j*-th input, an output of the *i
    –* 1 layer, to the *k*-th node of layer *i*. We also have
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/205equ03.jpg)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
- en: to represent the bias value for the *k*-th node of the *i*-th layer. Here layer
    0 is the input layer itself. The parentheses on the exponent are a label, the
    layer number; they should not be interpreted as actual exponents. Therefore,
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/205equ04.jpg)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
- en: is the weight from the third output of the first layer to the first node of
    the second layer. This is the highlighted weight in [Figure 9-4](ch09.xhtml#ch9fig4).
    Remember that we always number nodes top to bottom, starting with 0.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/09fig04.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
- en: '*Figure 9-4: The network of [Figure 8-1](ch08.xhtml#ch8fig1) with weight w^((2))[20]
    marked with a bold line*'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: This notation is a bit daunting, but it will let us reference any weight or
    bias of the network precisely. The number we need to use backprop is the partial
    derivative of the loss with respect to each weight or bias. Therefore, what we
    want to find ultimately is written, in all its glorious mathematical notation,
    as
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/206equ01.jpg)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
- en: 'This gives us the slope: the amount the loss will change for a change in the
    weight linking the *k*-th node of the *i*-th layer to the *j*-th output of the
    *i –* 1 layer. A similar equation gives us the partial derivatives of the biases.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: We can simplify this cumbersome notation by dealing only with the layer number
    understanding that buried in the notation is a vector (biases, activations) or
    matrix (weights) so that we want to find
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/206equ02.jpg)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
- en: These correspond to a matrix for all the weights linking layer *i –* 1 to *i*,
    and a vector for all the biases of layer *i*, respectively.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: We’ll protect our notational sanity by looking at things in terms of vectors
    and matrices. Let’s start with the output layer and see what that buys us. We
    know that the activations of the output layer, layer *L*, are found via
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: '*a*^((*L*)) = *h*(*W*^((*L*))*a*^((*L*–1)) + *b*^((*L*)))'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: with *a* being the activations from layer *L –* 1, *b* the bias vector for layer
    *L*, and *W* the weight matrix between layers *L –* 1 and *L*. The activation
    function is *h*.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, we’ll define the argument to *h* to be *z*^((*L*))
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '*z*^((*L*)) ≡ *W*^((*L*))*a*^((*L*–1)) + *b*^((*L*))'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: and call *∂L*/*∂z*^((*l*)) the *error*, the contribution to the loss from the
    inputs to layer *l*. Next, we define
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/206equ03.jpg)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
- en: so that we can work with *δ* (delta) from now on.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: For the output layer, we can write *δ* as
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/207equ01.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
- en: The notation *h*′(*z*^((*L*))) is another way to write the derivative of *h*
    (with respect to *z*) evaluated at *z*^((*L*)). The ⋅ represents elementwise multiplication.
    This is the way NumPy works when multiplying two arrays of the same size so that
    if *C* = *A* ⋅ *B*, then *C*[*ij*] = *A*[*ij*]*B*[*ij*]. Technically, this product
    is called the *Hadamard product*, named for the French mathematician Jacques Hadamard.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: The preceding means that to use backpropagation, we need a loss function that
    can be differentiated—a loss function for which a derivative exists at every point.
    This isn’t too much of a burden; the loss functions we’ll examine in the next
    section meet this criterion. We also need an activation function that can be differentiated
    so we can find *h*(*z*). Again, the activation functions we have considered so
    far are essentially all differentiable.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: '**Note** *I say “essentially” because the derivative of the ReLU is undefined
    at* x = 0*. The derivative from the left is 0 while the derivative from the right
    is 1\. In practice, implementations choose a particular value to return should
    the argument to the derivative of the ReLU be exactly 0\. For example, TensorFlow
    simply asks if the argument is less than or equal to 0 and, if it is, returns
    0 as the derivative. Otherwise, it returns 1\. This works because, numerically,
    there is so much rounding off happening to floating-point values during calculations
    that it’s unlikely the value passed to the derivative of the ReLU function was
    actually meant to be identically 0.*'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: The equation for *δ* tells us the error due to the inputs to a particular layer.
    We’ll see next how to use this to get the error from each weight of a layer.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: With *δ*^((*L*)) in hand, we can propagate the error down to the next layer
    via
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '*δ*^((*l*)) = ((*W*^((*l*+1)))^(*Tδ*^(*l*+1))) · *h*′(*z*^((*l*)))'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: where, for the next-to-last layer, *l* + 1 = *L*. The *T* represents matrix
    transpose. This is a standard matrix operation that involves a reflection across
    the diagonal so that if
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/207equ02.jpg)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
- en: then
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/207equ03.jpg)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
- en: We need the transpose of the weight matrix because we are going in the opposite
    direction from the forward pass. If there are three nodes in layer *l* and two
    in layer *l* + 1, then the weight matrix between them, *W*, is a 2 × 3 matrix,
    so *Wx* is a two-element vector. In backprop, we are going from layer *l* + 1
    to layer *l*, so we transpose the weight matrix to map the two-element vector,
    here *δ*, to a three-element vector for layer *l*.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: The *δ*^((*l*)) equation is used for every layer moving backward through the
    network. The output layer values are given by *δ*^((*L*)), which starts the process.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: Once we have the errors per layer, we can finally find the gradient values we
    need. For the biases, the values are the elements of *δ* for that layer
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/208equ01.jpg)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
- en: for the *j*-th element of the bias for the *l*-th layer. For the weights, we
    need
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/208equ02.jpg)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
- en: linking the *k*-th output of the previous layer to the *j*-th error for the
    current layer, *l*.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: Using the preceding equations for each layer of the network gives us the set
    of weight and bias gradient values needed to continue applying gradient descent.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: As I hope you can see from this rather dense section, we can use a convenient
    mathematical definition of the error to set up an iterative process that moves
    the error from the output of the network back through the layers of the network
    to the input layer. We cannot calculate the errors for a layer without already
    knowing the errors for the layer after it, so we end up propagating the error
    backward through the network, hence the name *backpropagation*.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: Loss Functions
  id: totrans-206
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The *loss function* is used during training to measure how poorly the network
    is doing. The goal of training is to make this value as small as possible, while
    still generalizing to the true characteristics of the data. In theory, we can
    create any loss function we want if we feel it’s relevant to the problem at hand.
    If you read the deep learning literature, you’ll see papers do this all the time.
    Still, most research falls back on a few standard loss functions that, empirically,
    do a good job most of the time. We’ll discuss three of those here: absolute loss
    (sometimes called *L*[1] loss), mean squared error (sometimes called *L*[2] loss),
    and cross-entropy loss.'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: Absolute and Mean Squared Error Loss
  id: totrans-208
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Let’s start with the absolute and mean squared error loss functions. We’ll discuss
    them together because they’re very similar mathematically.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: We’ve seen mean squared error already in our discussion of backprop. Absolute
    loss is new. Mathematically, the two equations are
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/209equ01.jpg)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
- en: where we’ve labeled them *abs* for *absolute value* and *MSE* for *mean squared
    error*, respectively. Note that we’ll always use *y* for the network output, the
    output from the forward pass with input *x*. We’ll always use *ŷ* for the known
    training class label, which is always an integer label starting with 0.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: 'Even though we’re writing the loss functions in a simple form, we need to remember
    that when used, the value is really the mean of the loss over the training set
    or minibatch. This is also the origin of *mean* in *mean squared error*. Therefore,
    we really should be writing this:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/209equ02.jpg)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
- en: Here we’re finding the average of the squared error loss over the *N* values
    in the training set (or minibatch).
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: Both of these loss functions are reasonable if we consider what they are measuring.
    We want the network to output a value that matches the expected value, the sample
    label. The difference between these two is an indication of how wrong the network
    output is. For the absolute loss, we find the difference and drop the sign, which
    is what the absolute value does. For the MSE loss, we find the difference and
    then square it. This also makes the difference positive because multiplying a
    negative number by itself always results in a positive number. As mentioned in
    the “Backpropagation” section on [page 200](#lev1_56), the ![Image](Images/1by2.jpg)
    factor on the MSE loss simplifies the derivative of the loss function but does
    not change how it works.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: The absolute loss and MSE are different, however. The MSE is more sensitive
    to outliers. This is because we’re squaring the difference, and a plot of *y*
    = *x*² grows quickly as *x*, the difference, gets larger. For the absolute loss,
    this effect is minimized because there is no squaring; the difference is merely
    the difference.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: In truth, neither of these loss functions are commonly used for neural networks
    when the goal of the network is *classification*, which is our implicit assumption
    in this book. It’s more common to use the cross-entropy loss, presented next.
    We want the network output to lead to the correct class label for the input. However,
    it’s entirely possible to train a network to output a continuous real value instead.
    This is called *regression*, and both of these loss functions are quite useful
    in that context.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: Cross-Entropy Loss
  id: totrans-219
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Even though we can use the absolute and MSE loss functions in training a neural
    network for classification, the most commonly used loss is the *cross-entropy
    loss* (closely related to the log-loss). This loss function assumes the output
    of the network is a softmax (vector) for the multiclass case or a sigmoid (logistic,
    scalar) for the binary case. Mathematically, it looks like this for *M* classes
    in the multiclass case:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/210equ01.jpg)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
- en: 'What is the cross-entropy doing that often makes it a better choice for training
    a neural network for classification? Let’s think about the multiclass case with
    softmax outputs. The definition of *softmax* means that the network outputs can
    be thought of as probability estimates of the likelihood that the input represents
    each of the possible classes. If we have three classes, we might get a softmax
    output that looks like this:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: '*y* = (0.03, 0.87, 0.10)'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: This output roughly means that the network thinks there is a 3 percent chance
    the input is of class 0, an 87 percent chance it is of class 1, and a 10 percent
    chance it is of class 2\. This is the output vector, *y*. We compute the loss
    by supplying the actual label via a vector where 0 means *not this class* and
    1 means *this class*. So, the *ŷ* vector associated with the input that led to
    this *y* would be
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: '*ŷ* = (0,1,0)'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: for an overall loss value of
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: '*ℒ*[ent] = –(0(log 0.03) + 1(log 0.87) + 0(log 0.10)) = 0.139262'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: The three predictions of the network can be thought of together as a probability
    distribution, just like the one we get when we sum together the likelihoods of
    different outcomes for throwing two dice. We also have a known probability distribution
    from the class label. For the preceding example, the actual class is class 1,
    so we made a probability distribution that assigns no chance to classes 0 and
    2, and 100 percent probability to class 1, the actual class. As the network trains,
    we expect the output distribution to be closer and closer to (0,1,0), the distribution
    for the label.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: 'Minimizing the cross-entropy drives the network toward better and better predictions
    of the probability distribution for the different classes we want the network
    to learn about. Ideally, these output distributions will look like the training
    labels: 0 for all classes except the actual class, which has an output of 1.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: For classification tasks, we usually use the cross-entropy loss. The sklearn
    MLPClassifier class uses cross-entropy. Keras supports cross-entropy loss as well,
    but provides many others, including absolute and mean squared error.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: Weight Initialization
  id: totrans-231
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Before we can train a neural network, we need to initialize the weights and
    biases. Step 1 of [Listing 9-1](ch09.xhtml#ch9lis1) on gradient descent says to
    “Pick some intelligent starting values for the weights and biases.”
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: The initialization techniques examined here all depend upon selecting random
    numbers in some range. More than that, the random numbers need to be either uniform
    over that range or normally distributed. *Uniformly distributed* means that all
    the values in the range are equally likely to be selected. This is what you get
    for each number, 1 through 6, if you roll a fair die many times over. Normally
    distributed values were introduced in [Chapter 4](ch04.xhtml#ch04). These are
    values with a particular mean, the most likely value returned, and a range around
    the mean over which the likelihood of a value being selected falls off gradually
    toward 0 according to a parameter known as the *standard deviation*. This is the
    classic bell curve shape. Either distribution can be used. The main point is that
    the initial weights are not all the same value (like 0) because if they are, all
    gradients will be the same during backprop, and each weight will change in the
    same way. The initial weights need to be different to break this symmetry and
    allow individual weights to adapt themselves to the training data.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: In the early days of neural networks, people initialized the weights and biases
    by choosing values in [0,1) uniformly (*U*(0,1)) or by drawing them from the standard
    normal distribution, *N*(0,1), with a mean of 0 and a standard deviation of 1\.
    These values were often multiplied by some small constant, like 0.01\. In many
    cases, this approach works, at least for simple networks. However, as networks
    became more complex, this simple approach fell apart. Networks initialized in
    this way had trouble learning, and many failed to learn at all.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s fast-forward several decades and a great deal of research later. Researchers
    realized that precisely how the weights of a particular layer should be initialized
    depended primarily on a few things: the type of activation function used and the
    number of weights coming into the layer (*f*[*in*]) and, possibly, going out (*f*[*out*]).
    These realizations led to the main initialization approaches in use today.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: The sklearn MLPClassifier class uses *Glorot initialization*. This is also sometimes
    called *Xavier initialization*, though some toolkits mean something different
    when they use that term.^([1](ch09.xhtml#ch09fn1)) (Note *Xavier* and *Glorot*
    actually refer to the same person.) Let’s see how sklearn uses Glorot initialization.
    The key method in MLPClassifier for initializing the weights is _init_coef. This
    method uses a uniform distribution and sets the range for it so that the weights
    are in
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/212equ01.jpg)'
  id: totrans-237
  prefs: []
  type: TYPE_IMG
- en: where the bracket notation indicates the smallest possible value selected (left)
    to the largest possible value (right). As the distribution is uniform, every value
    in that range is equally likely to be selected.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: We did not yet specify what *A* is. This value depends upon the activation function
    used. According to the literature, if the activation function is a sigmoid (logistic),
    then *A* = 2 is suggested. Otherwise, *A* = 6 is recommended.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: Now to confuse things. Some toolkits, like Caffe, use an alternate form of Xavier
    initialization by which they mean a multiplier on samples from a standard normal
    distribution. In that case, we initialize the weights with draws from
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/212equ02.jpg)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
- en: 'To add even more confusion, the introduction of the rectified linear unit (ReLU)
    resulted in a further recommended change. This is known now as *He initialization*
    and it replaces the 1 in Xavier initialization with a 2:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/212equ03.jpg)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
- en: 'For more on this, see “Delving Deep into Rectifiers: Surpassing Human-Level
    Performance on ImageNet Classification” by Kaiming He et al.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: The key point with these initialization schemes is that the old-school “small
    random value” is replaced by a more principled set of values that take the network
    architecture into account via *f*[*in*] and *f*[*out*].
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: The preceding discussion ignored bias values. This was intentional. While it
    might be okay to initialize the bias values instead of leaving them all 0, prevailing
    wisdom, which is fickle and fluid, currently says it’s best to initialize them
    all to 0\. That said, sklearn MLPClassifier initializes the bias values in the
    same way as the weights.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: Overfitting and Regularization
  id: totrans-247
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The goal of training a model is for it to learn essential, general features
    of the parent distribution the dataset is sampled from. That way, when the model
    encounters new inputs, it’s prepared to interpret them correctly. As we’ve seen
    in this chapter, the primary method for training a neural network involves optimization—looking
    for the “best” set of parameters so that the network makes as few errors as possible
    on the training set.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: However, it’s not enough to simply look for the best set of values that minimizes
    the training error. If we make no mistakes when classifying the training data,
    it’s often the case that we’ve overfitted and haven’t actually learned general
    features of the data. This is more likely the situation with traditional models,
    neural network or classical, and less so with deep models like the convolutional
    networks of [Chapter 12](ch12.xhtml#ch12).
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Overfitting
  id: totrans-250
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We’ve mentioned overfitting from time to time before now but have not gained
    any good intuition as to what it is. One way to think of overfitting is to consider
    a separate problem, the problem of fitting a function to a set of points. This
    is known as *curve fitting*, and one approach to it is to optimize some measure
    of error over the points by finding parameters to the function that minimize the
    error. This should sound familiar. It’s exactly what we do when training a neural
    network.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example of curve fitting, consider the following points:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: '| *x* | *y* |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
- en: '| 0.00 | 50.0 |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
- en: '| 0.61 | –17.8 |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
- en: '| 1.22 | 74.1 |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
- en: '| 1.83 | 29.9 |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
- en: '| 2.44 | 114.8 |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
- en: '| 3.06 | 55.3 |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
- en: '| 3.67 | 66.0 |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
- en: '| 4.28 | 89.1 |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
- en: '| 4.89 | 128.3 |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
- en: '| 5.51 | 180.8 |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
- en: '| 6.12 | 229.7 |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
- en: '| 6.73 | 229.3 |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
- en: '| 7.34 | 227.7 |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
- en: '| 7.95 | 354.9 |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
- en: '| 8.57 | 477.1 |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
- en: '| 9.18 | 435.4 |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
- en: '| 9.79 | 470.1 |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
- en: We want to find a function, *y* = *f* (*x*), that describes these points—a function
    that might have been the parent function these points were measured from, albeit
    noisily.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: 'Typically, when curve fitting, we already know the form of the function; it’s
    the parameters we’re looking for. But what if we didn’t know the exact form of
    the function, only that it was some kind of polynomial? In general, a polynomial
    looks like this for some maximum exponent, *n*:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: '*y* = *a*[0] + *a*[1]*x* + *a*[2]*x*² + *a*[3]*x*³ + … + *a[n]x^n*'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: The goal of fitting a polynomial to a dataset is to find the parameters, *a*[0],*a*[1],*a*[2],…,*a*[*n*].
    The method for doing this usually minimizes the squared difference between *y*,
    a given output for a given *x* position, and *f* (*x*), the function output at
    the same *x* for the current set of parameters. This should sound very familiar,
    as we discussed using precisely this type of loss function for training a neural
    network.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: How does this relate to overfitting? Let’s plot the previous dataset, along
    with the result of fitting two different functions to it. The first function is
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: '*y* = *a*[0] + *a*[1]*x* + *a*[2]*x*²'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: which is a quadratic function, the type of function you may have learned to
    hate as a beginning algebra student. The second function is
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: '*y* = *a*[0] + *a*[1]*x* + *a*[2]*x*² + *a*[3]*x*³ + … + *a*[14]*x*^(14) +
    *a*[15]*x*^(15)'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: which is a 15th-degree polynomial. The results are shown in [Figure 9-5](ch09.xhtml#ch9fig5).
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/09fig05.jpg)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
- en: '*Figure 9-5: A dataset and two functions fit to it: a quadratic (dashed) and
    a 15th-degree polynomial (solid)*'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: Which function does a better job of capturing the general trend of the dataset?
    The quadratic clearly follows the general trend of the data, while the 15th-degree
    polynomial is all over the place. Look again at [Figure 9-5](ch09.xhtml#ch9fig5).
    If all we use to decide that we have fit the data well is the distance between
    the data points and the corresponding function value, we’d say that the 15th-degree
    polynomial is the better fit; it passes through nearly all the data points, after
    all. This is analogous to training a neural network and achieving perfection on
    the training set. The cost of that perfection might well be a poor ability to
    generalize to new inputs. The quadratic fit of [Figure 9-5](ch09.xhtml#ch9fig5)
    did not hit the data points, but it did capture the general trend of the data,
    making it more useful should we want to make predictions about the *y* values
    we’d expect to get for a new *x* value.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: When a human wants to fit a curve to something like our sample dataset, they
    usually look at the data and, noticing the general trend, select the function
    to fit. It might also be the case that the expected functional form is already
    known from theory. If we want to be analogous to neural networks, however, we’ll
    find ourselves in a situation where we don’t know the proper function to fit,
    and need to find a “best” one from the space of functions of *x* along with its
    parameters.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: Hopefully, this example drives home the idea that training a neural network
    is not an optimization problem like other optimization problems—we need something
    to push the function the network is learning in a direction that captures the
    essence of the data without falling into the trap of paying too much attention
    to specific features of the training data. That something is regularization, and
    you need it, especially for large networks that have a huge capacity.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Regularization
  id: totrans-286
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '*Regularization* is anything that pushes the network to learn the relevant
    features of the parent distribution and not the details of the training set. The
    best form of regularization is increasing the size and representative nature of
    the training set. The larger the dataset and the better it represents all the
    types of samples the network will encounter in the wild, the better it will learn.
    Of course, we’re typically forced to work with a finite training set. The machine
    learning community has spent, and is spending, untold time and energy learning
    how to get more from smaller datasets.'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 5](ch05.xhtml#ch05), we encountered perhaps the second-best way
    to regularize a model, data augmentation. This is a proxy for having a larger
    dataset, where we use the data we do have to generate new training samples that
    are plausibly from the parent distribution. For example, we considered increasing
    a limited set of training images by simple rotations, flips, and shifts of the
    images already in the training set. Data augmentation is powerful, and you should
    use it when possible. It’s particularly easy to apply when working with images
    as inputs, though in [Chapter 5](ch05.xhtml#ch05) we also saw a way to augment
    a dataset consisting of continuously valued vectors.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: 'We now have two tricks in our regularization toolbox: more data and data augmentation.
    These are the best tricks to know, but there others that you should use when available.
    Let’s look at two more: L2 regularization and dropout. The former is now standard
    and widely supported by the toolkits, including sklearn and Keras. The latter
    is powerful and was a game changer when it appeared in 2012.'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: L2 Regularization
  id: totrans-290
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A model with a few weights that have large values is somehow less simple than
    a model that has smaller weights. Therefore, keeping the weights small will hopefully
    allow the network to implement a simpler function better suited to the task we
    want it to learn.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: We can encourage the weights to be small by using L2 regularization. *L2 regularization*
    adds a term to the loss function so that the loss becomes
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/216equ01.jpg)'
  id: totrans-293
  prefs: []
  type: TYPE_IMG
- en: where the first term is whatever loss we’re already using, and the second term
    is the new L2 regularization term. Notice that the loss is a function of the input
    (*x*), the label (*y*), the weights (*w*), and the biases (*b*), where we mean
    all the weights and all the biases of the network. The regularization term is
    a sum over all the weights in the network and only the weights. The “L2” label
    is what causes us to square the weights.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: 'Here *L2* refers to the type of norm or distance. You might be familiar with
    the equation for the distance between two points on the plane: *d*² = (*x*[2]
    *– x*[1])² + (*y*[2] *– y*[1])². This is the *Euclidean distance*, also known
    as the *L2 distance*, because the values are squared. This is why the regularization
    term is called *L2* and the weight values are squared. It’s also possible to use
    an L1 loss term, where instead of squaring the weights, one uses the absolute
    value. In practice, L2 regularization is more common and, at least empirically,
    seems to work better for neural network classifiers.'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: The *λ* (lambda) multiplier sets the importance of this term; the larger it
    is, the more it dominates the overall loss used to train the network. Typical
    values of *λ* are around 0.0005\. We’ll see in a little bit why the multiplier
    is *λ*/2 and not just *λ*.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: What is the L2 term doing? Recall that the loss is the thing we want to minimize
    while training. The new L2 term sums the squares of the weights of the network.
    If weights are large, the loss is large, and that’s something we don’t want while
    training. Smaller weights make the L2 term smaller, so gradient descent will favor
    small weights, whether they are positive or negative, since we square the weight
    value. If all the weights of the network are relatively small, and none strongly
    dominate, then the network will use all of the weights to represent the data,
    and this is a good thing when it comes to preventing overfitting.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: L2 regularization is also known as *weight decay* because of what the L2 term
    does during backprop. Backprop gives us the partial derivative of the loss function
    with respect to *w*[*i*]. Adding L2 regularization means that the partial derivative
    of the total loss now adds in the partial derivative of the L2 term itself with
    respect to any particular weight, *w*[*i*]. The derivative of ![Image](Images/217equ01.jpg)
    is *λw*; the ![Image](Images/1by2.jpg) cancels the factor of 2 that would otherwise
    be there. Also, since we want the partial derivative with respect to a specific
    weight, *w*[*i*], all the other parts of the L2 term go to 0\. The net effect
    is that the update for weight *w*[*i*] during gradient descent becomes
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/217equ02.jpg)'
  id: totrans-299
  prefs: []
  type: TYPE_IMG
- en: where *η* (eta) is the learning rate, and we are ignoring any additional momentum
    term. The *ηλw*[*i*] term is new. It is due to L2 regularization, and we can see
    that it’s pushing the weights toward 0 as training progresses because both *η*
    and *λ* are < 1, so on each minibatch, we’re subtracting some small fraction of
    the weight value. The weight can still increase, but to do so, the gradient of
    the original loss must be large.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: We previously stated that the form of the loss function is up to us, the developer
    of the network. A regularization term isn’t the only kind of term we can add to
    the loss function. As we did with the L2 term, we can create and add terms to
    change the behavior of the network during training and help it learn what we want
    it to learn. This is a powerful technique that can be used to customize various
    aspects of what a neural network learns.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: Dropout
  id: totrans-302
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Dropout took the machine learning community by storm when it appeared in 2012,
    see “Imagenet Classification with Deep Convolutional Neural Networks” by Alex
    Krizhevsky et al. As of Fall 2020, this paper has been cited over 70,000 times,
    and as one well-known machine learning researcher told me privately at the time,
    “If we had had dropout in the 1980s, this would be a different world now.” So,
    what is dropout, and why was everyone so excited by it?
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: 'To answer that question, we need to review the concept of ensembles of models.
    We talked about them a bit in [Chapter 6](ch06.xhtml#ch06). An ensemble is a group
    of models, all slightly different and all trained on the same dataset or a slightly
    different version of the dataset. The idea is straightforward: since training
    most models involves randomness, training multiple similar models should result
    in a set that is mutually reinforcing—one where the set of outputs can be combined
    to produce a result that is better than any one model alone. Ensembles are useful,
    and we use them often, but they come at a price in terms of runtime. If it takes
    *x* milliseconds to run a sample through a neural network, and we have an ensemble
    of 20 networks, then our evaluation time (inference time) has jumped to 20*x*
    milliseconds, ignoring the possibility of parallel execution. In some situations,
    that is unacceptable (to say nothing of the storage and power requirements for
    20 big networks versus 1). Since the net result of an ensemble of models is better
    overall performance, we can say that an ensemble is a kind of regularizer as well
    since it embodies the “wisdom of the crowd.”'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: '*Dropout* takes the ensemble idea to an extreme but does so only during training
    and without creating a second network so that in the end, we still have one model
    to deal with. Like many good ideas in statistics, this one requires randomness.
    Right now, when we train the network, we do a forward pass using the current weights
    and biases. What if, during that forward pass, we randomly assign a 0 or a 1 to
    each node of the network so that nodes with a 1 are used in the next layer while
    nodes with a 0 are dropped out? We’d effectively be running the training samples
    through a different neural network configuration each time. For example, see [Figure
    9-6](ch09.xhtml#ch9fig6).'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/09fig06.jpg)'
  id: totrans-306
  prefs: []
  type: TYPE_IMG
- en: '*Figure 9-6: Possible networks used when applying dropout during training*'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: Here we show the network of [Figure 8-1](ch08.xhtml#ch8fig1) but with a 0 or
    1 for each of the hidden nodes. This 0 or 1 determines whether the output is used
    or not. The heavy lines in the network show the connections that are still valid.
    In other words, the heavy lines show the network that was actually used to create
    the output accumulated for backprop. If we do this for each training sample, we
    can readily see that we’ll be training a vast number of neural networks, each
    trained on a single sample. Moreover, since the weights and biases persist between
    forward passes, all the networks will share those weights in the hope that the
    process will reinforce good weight values that represent the essence of the dataset.
    As we’ve mentioned several times in this chapter, learning the essence of the
    data is the goal of training; we want to generalize well to new data from the
    same virtual parent distribution that generated the training set in the first
    place. Dropout is serious regularization.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: I previously said that we “randomly assign a 0 or a 1” to the nodes. Do we assign
    them equally? The probability with which we drop nodes in a layer is something
    we get to specify. Let’s call it *p*. Typically, *p* = 0.5, meaning about 50 percent
    of the nodes in a layer will be dropped for each training sample. Setting *p*
    = 0.8 would drop 80 percent of the nodes, while *p* = 0.1 would drop only 10 percent.
    Sometimes a different probability is used for different layers of the network,
    especially the first input layer, which should use a smaller probability than
    the hidden nodes. If we drop too many of the inputs, we’ll lose the source of
    the signal we’re trying to get the network to recognize. Dropout applied to the
    input layer can be thought of as a form of data augmentation.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: Conceptually, dropout is training a large set of networks that share weights.
    The output of each of these networks can be combined with the others via a geometric
    mean, assuming we use a softmax output. The geometric mean of two numbers is the
    square root of their product. The geometric mean of *n* numbers is the *n*th root
    of their product. In the case of dropout, it turns out that this can be approximated
    by using the entire network with all the weights multiplied by the probability
    that they would be included. Given we said *p* is the probability that a node
    is dropped, the weights need to be multiplied by 1 *– p*, as that is the probability
    the node would not be dropped. So, if we fix *p* = 0.5 and use it for all the
    nodes, then the final network is the one where all the weights are divided by
    2.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: As of this writing, sklearn’s MLPClassifier class does not support dropout,
    but Keras most certainly does, so we’ll see dropout again in [Chapter 12](ch12.xhtml#ch12).
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-312
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Because this is an important chapter, let’s review what we’ve learned in a
    little more depth. In this chapter, we described how to train a neural network
    using gradient descent and backpropagation. The overall sequence of steps is as
    follows:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: Select the architecture of the model. This means the number of layers, their
    sizes, and the type of activation function.
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Initialize the weights and biases of the network using intelligently selected
    initial values.
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run a minibatch of training samples through the network and compute the mean
    loss over the minibatch. We discussed common loss functions.
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using backpropagation, calculate the contribution of each weight and bias to
    the overall loss for the minibatch.
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using gradient descent, update the weight and bias values of the model based
    on the contributions found via backpropagation. We discussed stochastic gradient
    descent and its relationship to the concept of minibatches.
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat from step 3 until the desired number of epochs or minibatches have been
    processed, or the loss has dropped below some threshold, or stopped changing much,
    or when the score on a validation set of samples has reached its minimum value.
  id: totrans-319
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the network isn’t learning well, apply regularization and train again. We
    looked at L2 regularization and dropout in this chapter. Data augmentation, or
    increasing the size or representativeness of the training set, can also be thought
    of as regularization.
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The goal of training a neural network is to learn the parameters of a model
    that generalizes well to unseen inputs. This is the goal of all supervised machine
    learning. For a neural network, we know it’s able to approximate any function,
    with enough capacity and enough training data. Naïvely, we may think that we are
    doing nothing more than ordinary optimization, but, in an important sense, we
    are not. Perfection on the training set is often not a good thing; it’s often
    a sign of overfitting. Instead, we want the model to learn a function that captures
    the essential nature of the function implied by the training set. We use the test
    data to give us confidence that we’ve learned a useful function.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we’ll get real and explore traditional neural networks
    through a series of experiments using sklearn.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: '[1.](ch09.xhtml#Rch09fn1) For more on these, see Glorot, Xavier, and Yoshua
    Bengio. “Understanding the Difficulty of Training Deep Feedforward Neural Networks.”'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL

["```py\nItaly - Rome = X - Athens\n```", "```py\nX = Italy - Rome + Athens\n```", "```py\ncompete   -0.0535 -0.0207 0.0574 0.0562 ... -0.0389 -0.0389\n\nequations -0.0337 0.2013 -0.1587 0.1499 ...  0.1504 0.1151\n\nUpper     -0.1132 -0.0927 0.1991 -0.0302 ... -0.1209 0.2132\n\nmentor     0.0397 0.1639 0.1005 -0.1420 ... -0.2076 -0.0238\n\nreviewer  -0.0424 -0.0304 -0.0031 0.0874 ... 0.1403 -0.0258\n```", "```py\n>>> doc=nlp('I want a green apple.')\n\n>>> doc.similarity(doc[2:5])\n\n0.7305813588233471\n```", "```py\n>>> doc.similarity(doc)\n\n1.0\n\n>>> doc[2:5].similarity(doc[2:5])\n\n1.0\n```", "```py\n>>> doc2=nlp('I like red oranges.')\n\n>>> doc2.similarity(doc[2:5])\n\n0.28546574467463354\n```", "```py\n>>> token = doc2[3:4][0]\n\n>>> token\n\noranges\n\n>>> token.similarity(doc[4:5])\n\n0.3707084280155993\n```", "```py\nRedwoods are the tallest trees in the world. They are most common in the coastal forests of California.\n```", "```py\n$ python -m spacy init-model en /tmp/en_vectors_wiki_lg --vectors-loc wiki-news-300d-1M.vec\n```", "```py\nReading vectors from wiki-news-300d-1M.vec\n\nOpen loc\n\n999994it [02:05, 7968.84it/s]\n\nCreating model...\n\n0it [00:00, ?it/s]\n\n    Successfully compiled vocab\n\n    999731 entries, 999994 vectors\n```", "```py\nnlp = spacy.load('/tmp/en_vectors_wiki_lg')\n```", "```py\ndoc = nlp(u'Hi there!')\n```", "```py\nI want to buy this beautiful book at the end of the week. \n\nSales of citrus have increased over the last year. \n\nHow much do you know about this type of tree?\n```", "```py\n   import spacy\n\n   nlp = spacy.load('en')\n\n➊ token = nlp(u'fruits')[0]\n\n➋ doc = nlp(u'I want to buy this beautiful book at the end of the week. Sales of\n\n   citrus have increased over the last year. How much do you know about this type\n\n   of tree?')\n\n➌ for sent in doc.sents:\n\n     print(sent.text)\n\n ➍ print('similarity to', token.text, 'is', token.similarity(sent),'\\n')\n```", "```py\nI want to buy this beautiful book at the end of the week.\n\nsimilarity to fruits is 0.06307832979619851 \n\nSales of citrus have increased over the last year.\n\nsimilarity to fruits is 0.2712141843864381 \n\nHow much do you know about this type of tree?\n\nsimilarity to fruits is 0.24646341651210604\n```", "```py\n   import spacy\n\n   nlp = spacy.load('en')\n\n➊ token = nlp(u'fruits')[0]\n\n   doc = nlp(u'I want to buy this beautiful book at the end of the week. Sales of\n\n   citrus have increased over the last year. How much do you know about this type\n\n   of tree?')\n\nsimilarity = {}\n\n➋ for i, sent in enumerate(doc.sents):\n\n   ➌ noun_span_list = [sent[j].text for j in range(len(sent)) if sent[j].pos_ \n\n      == 'NOUN']\n\n   ➍ noun_span_str = ' '.join(noun_span_list)\n\n   ➎ noun_span_doc = nlp(noun_span_str)\n\n   ➏ similarity.update({i:token.similarity(noun_span_doc)})\n\n    print(similarity)\n```", "```py\n{0: 0.17012682516221458, 1: 0.5063824302533686, 2: 0.6277196645922878}\n```", "```py\n   import spacy\n\n   nlp = spacy.load('en')\n\n   #first sample text\n\n   doc1 = nlp(u'Google Search, often referred to as simply Google, is the most\n\n   used search engine nowadays. It handles a huge number of searches each day.') \n\n   #second sample text\n\n   doc2 = nlp(u'Microsoft Windows is a family of proprietary operating systems\n\n   developed and sold by Microsoft. The company also produces a wide range of\n\n   other software for desktops and servers.') \n\n   #third sample text\n\n   doc3 = nlp(u\"Titicaca is a large, deep, mountain lake in the Andes. It is\n\n   known as the highest navigable lake in the world.\")\n\n➊ docs = [doc1,doc2,doc3]\n\n➋ spans = {}\n\n➌ for j,doc in enumerate(docs):\n\n   ➍ named_entity_span = [doc[i].text for i in range(len(doc)) if \n\n      doc[i].ent_type != 0]\n\n   ➎ print(named_entity_span)\n\n   ➏ named_entity_span = ' '.join(named_entity_span)\n\n   ➐ named_entity_span = nlp(named_entity_span)\n\n   ➑ spans.update({j:named_entity_span})\n```", "```py\n['Google', 'Search', 'Google']\n\n['Microsoft', 'Windows', 'Microsoft']\n\n['Titicaca', 'Andes']\n```", "```py\nprint('doc1 is similar to doc2:',spans[0].similarity(spans[1]))\n\nprint('doc1 is similar to doc3:',spans[0].similarity(spans[2]))\n\nprint('doc2 is similar to doc3:',spans[1].similarity(spans[2]))\n```", "```py\ndoc1 is similar to doc2: 0.7864886939527678\n\ndoc1 is similar to doc3: 0.6797676349647936\n\ndoc2 is similar to doc3: 0.6621659567003596\n```"]
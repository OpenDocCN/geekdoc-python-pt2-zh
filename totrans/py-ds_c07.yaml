- en: '7'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Combining Datasets
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/book_art/chapterart.png)'
  prefs: []
  type: TYPE_IMG
- en: It’s common for data to be split across multiple containers. Therefore, you’ll
    often need to combine different datasets into one. You’ve done some combining
    in previous chapters, but in this chapter we’ll look at techniques for combining
    datasets in more depth.
  prefs: []
  type: TYPE_NORMAL
- en: In some cases, combining datasets may simply be a matter of adding one dataset
    to the end of another. For example, a financial analyst may receive a new batch
    of stock data each week that needs to be added to an existing collection of stock
    data. Other times, you may need to more selectively combine datasets that share
    a common column, joining them into a summary dataset. For instance, a retailer
    may want to merge general data about online orders with specific details about
    the items ordered, as you saw in Chapter 6. In either case, once you’ve combined
    the data, you can use it for further analysis. For example, you can run a range
    of filtering, grouping, or aggregation operations on the combined dataset.
  prefs: []
  type: TYPE_NORMAL
- en: As you’ve learned in previous chapters, datasets in Python can take the form
    of built-in data structures such as lists, tuples, and dictionaries, or they can
    be organized using third-party data structures such as NumPy arrays or pandas
    DataFrames. In the latter case, you have a richer set of tools for combining data,
    and therefore you have more options when you need to satisfy certain join conditions.
    This doesn’t mean, however, that you won’t be able to effectively combine built-in
    Python data structures. This chapter will show you how to do so, as well as how
    to combine third-party data structures.
  prefs: []
  type: TYPE_NORMAL
- en: Combining Built-in Data Structures
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The syntax for combining Python’s built-in data structures is quite straightforward.
    In this section, you’ll see how to combine lists or tuples using the `+` operator.
    Then, you’ll learn to combine dictionaries with the `**` operator. You’ll also
    explore how to perform joins, aggregations, and other operations on lists of tuples,
    essentially treating them as if they were database tables, with each tuple representing
    a row.
  prefs: []
  type: TYPE_NORMAL
- en: Combining Lists and Tuples with +
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The easiest way to combine two or more lists or two or more tuples is with the
    `+` operator. You simply write a statement adding the lists or tuples together,
    just as you would add multiple numbers. This method works well when you need to
    put the elements from the structures being combined into a single new structure
    without changing the elements themselves. This process is often referred to as
    *concatenation*.
  prefs: []
  type: TYPE_NORMAL
- en: 'To demonstrate, we’ll return to the example of the online fashion retailer
    introduced in the previous chapter. Suppose the information about orders placed
    throughout a day is collected in a list, so you have one list for each day. You
    might have the following three lists:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'For the purpose of further analysis, you may need to combine these lists into
    a single one. The `+` operator makes this easy; you simply add the three lists
    together:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting `orders` list looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the elements from the three original lists now all appear in
    a single list, with their order determined by the order in which you wrote the
    concatenation statement. In this particular example, the elements of the lists
    that were combined were all tuples. However, the `+` operator works for concatenating
    lists whose elements are of any type. Thus, you could just as easily combine lists
    of integers, strings, dictionaries, or anything else.
  prefs: []
  type: TYPE_NORMAL
- en: You can use the same `+` syntax to combine multiple tuples. However, if you
    try to use `+` to combine dictionaries, you’ll end up with an `unsupported operand
    type(s)` error. The following section explains the proper syntax for combining
    dictionaries.
  prefs: []
  type: TYPE_NORMAL
- en: Combining Dictionaries with **
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `**` operator breaks up, or unpacks, a dictionary into its individual key-value
    pairs. To combine two dictionaries into one, you unpack both dictionaries with
    `**` and store the results in a new dictionary. This works even if one or both
    of the dictionaries has a hierarchical structure. In the context of our retailer
    example, consider the following dictionary that contains some additional fields
    pertaining to an order:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Thanks to the use of meaningful key names, the dictionary’s nested structure
    is clear. Indeed, the ability to access data by keys rather than by positions
    makes dictionaries preferable to lists when you’re working with hierarchical data
    structures.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now suppose you have the other fields for this same order in another dictionary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Your task is to concatenate these dictionaries into a single dictionary that
    includes all the key-value pairs from both the original ones. You use the `**`
    operator as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'You place the dictionaries you want to concatenate inside curly brackets, preceding
    each dictionary name with `**`. The `**` operator unpacks the two dictionaries
    into their key-value pairs, and then the curly brackets package them back up into
    a single dictionary. Now `order_9423517` looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, all the elements from the original dictionaries are present,
    and their hierarchical structure has been preserved.
  prefs: []
  type: TYPE_NORMAL
- en: Combining Corresponding Rows from Two Structures
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You already know how to combine several lists into a single list without changing
    the elements of those lists. In practice, you’ll also often have to join two or
    more data structures that share a common column into a single structure, combining
    corresponding rows from these data structures into a single row. If your data
    structures are pandas DataFrames, you can use methods like `join()` and `merge()`,
    as you’ve seen in previous chapters. However, if your data structures are lists
    containing “rows” of tuples, these methods aren’t available. Instead, you need
    to iterate over the lists and join each row individually.
  prefs: []
  type: TYPE_NORMAL
- en: 'To illustrate, we’ll join the `orders` list you created in “Combining Lists
    and Tuples with +” earlier in this chapter with the `details` list introduced
    in “Data to Aggregate” in Chapter 6. As a reminder, here’s what that list looks
    like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Both lists contain tuples whose first element is an order number. The goal
    is to find the tuples with matching order numbers, merge them into a single tuple,
    and store all the tuples in a list. Here’s how this is done:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: First you create an empty list to receive the merged tuples ❶. Then you use
    a nested pair of loops to iterate over the lists ❷ and an `if` statement ❸ to
    merge only tuples with matching order numbers. To avoid repeating the order number
    twice in the tuple being combined and appended to the `orders_details` list, you
    use slicing for each `details` tuple ❹, picking up all its fields except for the
    first one, which contains the redundant order number.
  prefs: []
  type: TYPE_NORMAL
- en: 'Looking at this code, you might wonder if it could be implemented more elegantly
    as a one-liner. Indeed, with the help of list comprehensions, you can achieve
    the same result as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: In the outer list comprehension, you iterate over the tuples in the `details`
    list. In the inner list comprehension, you find a tuple in the `orders` list whose
    order number matches the current tuple from `details`. Since an order line in
    `details` is supposed to have only one matching tuple in `orders`, the inner list
    comprehension should generate a list with a single element (a tuple representing
    an order). So, you take the first element of the inner list comprehension with
    the `[0]` operator, then you concatenate this order’s tuple with the corresponding
    tuple from `details` using the `+` operator, excluding the redundant order number
    with `[1:]`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Whether you’ve created `orders_details` through list comprehensions or with
    the help of two `for` loops, as shown previously, the resulting list will look
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The list contains all the tuples from the `details` list, and each tuple also
    contains additional information from the corresponding tuple of the `orders` list.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing Different Types of Joins for Lists
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The operation you performed in the previous section is a standard one-to-many
    join: each order line in `details` has a matching order in `orders`, and each
    order in `orders` has one or more order lines in `details`. In practice, however,
    either or both of the datasets being joined might have rows with no matches in
    the other dataset. To account for these situations, you must be able to perform
    operations equivalent to the various database-style joins we discussed in Chapter
    3: left joins, right joins, inner joins, and outer joins.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, the `details` list might have order lines for orders not found
    in the `orders` list. One way this could happen is if you filter `orders` for
    a certain date range; since `details` doesn’t include a date field, you can’t
    filter the `details` list accordingly. To simulate this situation, add a new row
    to the `details` list that refers to an order that isn’t in `orders`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'If you now try to generate the `orders_details` list as you did before:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'you’ll get the following error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The problem occurs when you get to the unmatched order number in the `details`
    list and you try to retrieve the first element of the corresponding inner list
    comprehension. No such element exists, since the order number isn’t in the `orders`
    list. One way to solve this is to add an `if` clause to the `for d in details`
    loop within the outer list comprehension, checking whether the order number in
    a `details` row can be found in any row of `orders`, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: You eliminate the problem by excluding any `details` rows that don’t have a
    matching row in the `orders` list, implementing the check in the `if` clause that
    follows the `for d in details` loop ❶. Thus, the list comprehension shown here
    results in an inner join.
  prefs: []
  type: TYPE_NORMAL
- en: But what if you want to include all the `details` rows in the resulting `orders_details`
    list? You may want to do this, for example, so you can summarize the totals for
    all the orders, not only for those orders in the current ``orders list (which
    has hypothetically been filtered by date). You might then summarize totals for
    the orders that *are* in the current `orders` list and compare these sums.``
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15] orders_details_right = [[o for o in orders if d[0] in o][0] + d[1:]
    if d[0] in [o[0] for o                         in orders] ❶ else (d[0], None,
    None) + d[1:] for d in details] [PRE16] [  `--snip--`  (4626490, ''2022-02-06'',
    9004, ''Sweater'', ''Dickies'', 56.0, 1),  (4626592, None, None, ''Shorts'', ''Protest'',
    48.0, 1) ] [PRE17] sum(pr*qt for _, _, _, _, _, pr, qt in orders_details_right)
    [PRE18] 779.0 [PRE19] sum(pr*qt for _, dt, _, _, _, pr, qt in orders_details_right
    ❶ if dt != None) [PRE20] 731.0 [PRE21] import numpy as np jeff_salary = [2700,3000,3000]
    nick_salary = [2600,2800,2800] tom_salary = [2300,2500,2500] base_salary1 = np.array([jeff_salary,
    nick_salary, tom_salary]) [PRE22] maya_salary = [2200,2400,2400] john_salary =
    [2500,2700,2700] base_salary2 = np.array([maya_salary, john_salary]) [PRE23] base_salary
    = np.concatenate((base_salary1, base_salary2), axis=0) [PRE24] [[2700 3000 3000]  [2600
    2800 2800]  [2300 2500 2500],  [2200 2400 2400],  [2500 2700 2700]] [PRE25] new_month_salary
    = np.array([[3000],[2900],[2500],[2500],[2700]]) [PRE26] [[3000]  [2900]  [2500]  [2500]  [2700]]
    [PRE27] base_salary = np.concatenate((base_salary, new_month_salary), axis=1)
    [PRE28] [[2700 3000 3000 3000]  [2600 2800 2800 2900]  [2300 2500 2500 2500]  [2200
    2400 2400 2500]  [2500 2700 2700 2700]] [PRE29] import pandas as pd salary_df1
    = pd.DataFrame(     {''jeff'': jeff_salary,      ''nick'': nick_salary,      ''tom'':
    tom_salary     })  [PRE30] salary_df1.index = [''June'', ''July'', ''August'']
    [PRE31]  jeff  nick   tom June    2700  2600  2300 July    3000  2800  2500 August  3000  2800  2500
    [PRE32] salary_df1 = salary_df1.T [PRE33]  June  July  August jeff  2700  3000    3000
    nick  2600  2800    2800 tom   2300  2500    2500 [PRE34] salary_df2 = pd.DataFrame(     {''maya'':
    maya_salary,      ''john'': john_salary     },     index = [''June'', ''July'',
    ''August''] ).T  [PRE35]  June  July  August maya  2200  2400    2400 john  2500  2700    2700
    [PRE36] salary_df = pd.concat([salary_df1, salary_df2]) [PRE37]  June  July  August
    jeff  2700  3000    3000 nick  2600  2800    2800 tom   2300  2500    2500 maya  2200  2400    2400
    john  2500  2700    2700 [PRE38] salary_df3 = pd.DataFrame(     {''September'':
    [3000,2800,2500,2400,2700],      ''October'': [3200,3000,2700,2500,2900]     },     index
    = [''jeff'', ''nick'', ''tom'', ''maya'', ''john''] ) [PRE39] salary_df = pd.concat([salary_df,
    salary_df3], axis=1) [PRE40]  June  July  August  September  October jeff  2700  3000    3000       3000     3200
    nick  2600  2800    2800       2800     3000 tom   2300  2500    2500       2500     2700
    maya  2200  2400    2400       2400     2500 john  2500  2700    2700       2700     2900
    [PRE41] salary_df = salary_df.drop([''September'', ''October''], axis=1) [PRE42]
    salary_df = salary_df.drop([''nick'', ''maya''], axis=0) [PRE43]  June  July  August
    jeff  2700  3000    3000 tom   2300  2500    2500 john  2500  2700    2700 [PRE44]  Total
    Date       Region        2022-02-04 East     97.0            West    243.0 2022-02-05
    East    160.0            West     35.0 2022-02-06 East    110.0            West     86.0
    [PRE45] df_date_region1 = pd.DataFrame(  [         (''2022-02-04'', ''East'',
    97.0),   (''2022-02-04'', ''West'', 243.0),   (''2022-02-05'', ''East'', 160.0),   (''2022-02-05'',
    ''West'', 35.0),   (''2022-02-06'', ''East'', 110.0),   (''2022-02-06'', ''West'',
    86.0)  ],  columns =[''Date'', ''Region'', ''Total'']).set_index([''Date'',''Region''])
    [PRE46] df_date_region2 = pd.DataFrame(  [         (''2022-02-04'', ''South'',
    114.0),   (''2022-02-05'', ''South'', 325.0),   (''2022-02-06'', ''South'', 212.0)  ],  columns
    =[''Date'', ''Region'', ''Total'']).set_index([''Date'',''Region'']) [PRE47] df_date_region
    = pd.concat([df_date_region1,             df_date_region2]).sort_index(level=[''Date'',''Region''])
    [PRE48]  Total Date       Region        2022-02-04 East     97.0            South   114.0            West    243.0
    2022-02-05 East    160.0            South   325.0            West     35.0 2022-02-06
    East    110.0            South   212.0            West     86.0 [PRE49] import
    pandas as pd df_orders = pd.DataFrame(orders, columns =[''OrderNo'', ''Date'',
    ''Empno'']) df_details = pd.DataFrame(details, columns =[''OrderNo'', ''Item'',
    ''Brand'',                                              ''Price'', ''Quantity''])
    [PRE50] df_details = df_details.append(   {''OrderNo'': 4626592,    ''Item'':
    ''Shorts'',    ''Brand'': ''Protest'',    ''Price'': 48.0,    ''Quantity'': 1   },
    ❶ ignore_index = True ) [PRE51] df_orders_details_right = df_orders.merge(df_details,
    ❶ how=''right'',                   ❷ left_on=''OrderNo'', right_on=''OrderNo'')
    [PRE52]  OrderNo        Date   Empno          Item           Brand  Price  Quantity
    0   9423517  2022-02-04  9001.0         Jeans        Rip Curl   87.0         1
    1   9423517  2022-02-04  9001.0        Jacket  The North Face  112.0         1
    2   4626232  2022-02-04  9003.0         Socks            Vans   15.0         1
    3   4626232  2022-02-04  9003.0         Jeans      Quiksilver   82.0         1
    4   9423534  2022-02-04  9001.0         Socks              DC   10.0         2
    5   9423534  2022-02-04  9001.0         Socks      Quiksilver   12.0         2
    6   9423679  2022-02-05  9002.0       T-shirt       Patagonia   35.0         1
    7   4626377  2022-02-05  9003.0         Hoody          Animal   44.0         1
    8   4626377  2022-02-05  9003.0  Cargo Shorts          Animal   38.0         1
    9   4626412  2022-02-05  9004.0         Shirt          Volcom   78.0         1
    10  9423783  2022-02-06  9002.0  Boxer Shorts        Superdry   30.0         2
    11  9423783  2022-02-06  9002.0        Shorts           Globe   26.0         1
    12  4626490  2022-02-06  9004.0  Cargo Shorts       Billabong   54.0         1
    13  4626490  2022-02-06  9004.0       Sweater         Dickies   56.0         1
    14  4626592         NaN     NaN        Shorts         Protest   48.0         1
    [PRE53] print(df_orders_details_right.dtypes) [PRE54] OrderNo       int64 Date         object
    Empno       float64 Item         object Brand        object Price       float64
    Quantity      int64 dtype: object [PRE55] df_orders_details_right = df_orders_details_right.fillna({''Empno'':0}).astype({''Empno'':''int64''})
    [PRE56]`You end up with the following DataFrame:    [PRE57]    The `NaN` in the
    `Empno` column has become a `0`, and the employee numbers once again appear as
    integers. No more pesky decimal points!    #### Implementing a Many-to-Many Join    A
    many-to-many join can be established between datasets where a row in each dataset
    may relate to multiple rows in the other. For example, suppose you have two datasets
    containing books and authors, respectively. Every record in the authors dataset
    can be linked to one or more records in the books dataset, and every record in
    the books dataset can be linked to one or more records in the authors dataset.    Typically,
    you join datasets that have a many-to-many relationship using an *associative
    table*, also known as a *matching table*. This table maps two (or more) datasets
    together by referencing the primary keys of each dataset. The associative table
    has a one-to-many relationship with each of the datasets and functions as an intermediary
    between them, allowing them to be merged.    To see how a many-to-many join can
    be implemented through a matching table, create a `books` DataFrame and an `authors`
    DataFrame as follows:    [PRE58]    The `books` DataFrame includes three books,
    each with a unique `book_id`, while the `authors` DataFrame includes three authors,
    each with a unique `author_id`. Now create a third DataFrame, `matching`, that
    will serve as the associative table, connecting each book with its respective
    author(s) and vice versa:    [PRE59]    The `matching` DataFrame has two columns:
    one corresponding to author IDs and one corresponding to book IDs. Unlike in the
    other two DataFrames, each row in `matching` doesn’t just represent a single author
    or a single book. Instead, it contains information about the *relationship between*
    one particular author and one particular book. The DataFrame looks as follows:    [PRE60]    The
    first and second rows both reference the `author_id` of `jsn`, establishing that
    Johnson is the author of two different books. Likewise, the second and third rows
    both reference the `book_id` of `b2`, establishing that *Python for Web Development*
    has two authors.    Now you can create a many-to-many join between the `authors`
    and `books` datasets via `matching, as shown here`:    [PRE61]    The operation
    actually consists of two separate joins using the `merge()` method. First you
    join the `books` and `matching` DataFrames on their respective `book_id` columns.
    Then you join the result of the first join with the `authors` DataFrame via their
    `author_id` columns. Both of these are straightforward one-to-many joins, but
    together they result in a new DataFrame illustrating the many-to-many relationship
    between the `books` and `authors` datasets. You filter the DataFrame to include
    just the `title`, `topic`, and `author` columns, so that result looks as follows:    [PRE62]    As
    you can see, Johnson is listed twice as the author of both *Beautiful Coding*
    and *Python for Web Development*, while *Python for Web Development* is listed
    twice, once for each of its authors.    ## Summary    In this chapter, you looked
    at different ways of combining datasets presented in the form of built-in data
    structures such as lists, or third-party data structures such as NumPy arrays
    and pandas DataFrames. You learned to concatenate datasets, appending the columns
    or rows of one dataset to another. You also learned to join datasets, combining
    their matching rows.[PRE63]``'
  prefs: []
  type: TYPE_NORMAL

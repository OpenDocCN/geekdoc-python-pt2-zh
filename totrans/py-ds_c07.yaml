- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: Combining Datasets
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的结合
- en: '![](image_fi/book_art/chapterart.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](image_fi/book_art/chapterart.png)'
- en: It’s common for data to be split across multiple containers. Therefore, you’ll
    often need to combine different datasets into one. You’ve done some combining
    in previous chapters, but in this chapter we’ll look at techniques for combining
    datasets in more depth.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 数据常常分布在多个容器中。因此，你通常需要将不同的数据集合并成一个。在前几章中你已经进行过一些数据合并，但在本章中，我们将深入探讨更多结合数据集的技术。
- en: In some cases, combining datasets may simply be a matter of adding one dataset
    to the end of another. For example, a financial analyst may receive a new batch
    of stock data each week that needs to be added to an existing collection of stock
    data. Other times, you may need to more selectively combine datasets that share
    a common column, joining them into a summary dataset. For instance, a retailer
    may want to merge general data about online orders with specific details about
    the items ordered, as you saw in Chapter 6. In either case, once you’ve combined
    the data, you can use it for further analysis. For example, you can run a range
    of filtering, grouping, or aggregation operations on the combined dataset.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，结合数据集可能仅仅是将一个数据集添加到另一个数据集的末尾。例如，财务分析师每周可能会收到一批新的股票数据，需要将其添加到现有的股票数据集中。其他时候，你可能需要更有选择性地结合共享某个公共列的数据集，将它们合并为一个汇总数据集。例如，零售商可能希望将有关在线订单的通用数据与关于所订购商品的具体细节合并，正如你在第六章中所看到的。在任何情况下，一旦你将数据结合起来，就可以用它进行进一步的分析。例如，你可以对结合后的数据集运行一系列筛选、分组或聚合操作。
- en: As you’ve learned in previous chapters, datasets in Python can take the form
    of built-in data structures such as lists, tuples, and dictionaries, or they can
    be organized using third-party data structures such as NumPy arrays or pandas
    DataFrames. In the latter case, you have a richer set of tools for combining data,
    and therefore you have more options when you need to satisfy certain join conditions.
    This doesn’t mean, however, that you won’t be able to effectively combine built-in
    Python data structures. This chapter will show you how to do so, as well as how
    to combine third-party data structures.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在前几章中学到的那样，Python 中的数据集可以采用内建数据结构，如列表、元组和字典，或者可以使用第三方数据结构，如 NumPy 数组或 pandas
    DataFrame。在后者的情况下，你拥有更丰富的工具集来结合数据，因此在需要满足某些连接条件时，你有更多的选择。然而，这并不意味着你不能有效地结合内建的
    Python 数据结构。本章将展示如何做到这一点，以及如何结合第三方数据结构。
- en: Combining Built-in Data Structures
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结合内建数据结构
- en: The syntax for combining Python’s built-in data structures is quite straightforward.
    In this section, you’ll see how to combine lists or tuples using the `+` operator.
    Then, you’ll learn to combine dictionaries with the `**` operator. You’ll also
    explore how to perform joins, aggregations, and other operations on lists of tuples,
    essentially treating them as if they were database tables, with each tuple representing
    a row.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 将 Python 内建数据结构结合的语法非常简单。在这一节中，你将看到如何使用`+`运算符结合列表或元组。接着，你将学习如何使用`**`运算符结合字典。你还将探索如何对元组列表执行连接、聚合和其他操作，基本上将它们当作数据库表来处理，每个元组代表一行数据。
- en: Combining Lists and Tuples with +
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 `+` 结合列表和元组
- en: The easiest way to combine two or more lists or two or more tuples is with the
    `+` operator. You simply write a statement adding the lists or tuples together,
    just as you would add multiple numbers. This method works well when you need to
    put the elements from the structures being combined into a single new structure
    without changing the elements themselves. This process is often referred to as
    *concatenation*.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 将两个或更多列表或两个或更多元组结合起来的最简单方法是使用 `+` 运算符。你只需写一个语句，将列表或元组加在一起，就像你加多个数字一样。当你需要将结构中的元素合并到一个新的结构中，而不改变元素本身时，这个方法非常有效。这个过程通常被称为
    *连接*。
- en: 'To demonstrate, we’ll return to the example of the online fashion retailer
    introduced in the previous chapter. Suppose the information about orders placed
    throughout a day is collected in a list, so you have one list for each day. You
    might have the following three lists:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示，我们将回到上一章中介绍的在线时尚零售商的例子。假设每天的订单信息都被收集在一个列表中，因此你会为每一天有一个列表。你可能有以下三个列表：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'For the purpose of further analysis, you may need to combine these lists into
    a single one. The `+` operator makes this easy; you simply add the three lists
    together:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步分析，你可能需要将这些列表合并为一个单一的列表。`+` 运算符使这变得非常简单；你只需将三个列表加在一起：
- en: '[PRE1]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The resulting `orders` list looks as follows:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 合并后的`orders`列表如下所示：
- en: '[PRE2]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: As you can see, the elements from the three original lists now all appear in
    a single list, with their order determined by the order in which you wrote the
    concatenation statement. In this particular example, the elements of the lists
    that were combined were all tuples. However, the `+` operator works for concatenating
    lists whose elements are of any type. Thus, you could just as easily combine lists
    of integers, strings, dictionaries, or anything else.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，三个原始列表中的元素现在都出现在一个单一列表中，顺序由你写合并语句时的顺序决定。在这个特定的例子中，合并的列表元素都是元组。然而，`+`运算符同样适用于合并元素类型为任何类型的列表。因此，你可以轻松地合并包含整数、字符串、字典或其他任何内容的列表。
- en: You can use the same `+` syntax to combine multiple tuples. However, if you
    try to use `+` to combine dictionaries, you’ll end up with an `unsupported operand
    type(s)` error. The following section explains the proper syntax for combining
    dictionaries.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用相同的`+`语法来合并多个元组。然而，如果你尝试使用`+`合并字典，你将遇到`unsupported operand type(s)`错误。以下部分将解释合并字典的正确语法。
- en: Combining Dictionaries with **
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用**合并字典
- en: 'The `**` operator breaks up, or unpacks, a dictionary into its individual key-value
    pairs. To combine two dictionaries into one, you unpack both dictionaries with
    `**` and store the results in a new dictionary. This works even if one or both
    of the dictionaries has a hierarchical structure. In the context of our retailer
    example, consider the following dictionary that contains some additional fields
    pertaining to an order:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '`**`运算符将字典拆开，或称为解包，将其拆解为单个的键值对。要将两个字典合并为一个，你可以使用`**`解包两个字典，并将结果存储在一个新字典中。这即使在其中一个或两个字典具有层级结构的情况下也能工作。在我们的零售商示例中，考虑以下包含订单相关额外字段的字典：'
- en: '[PRE3]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Thanks to the use of meaningful key names, the dictionary’s nested structure
    is clear. Indeed, the ability to access data by keys rather than by positions
    makes dictionaries preferable to lists when you’re working with hierarchical data
    structures.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 得益于有意义的键名，字典的嵌套结构变得清晰。事实上，通过键而不是位置访问数据的能力，使得在处理层级数据结构时，字典比列表更为优越。
- en: 'Now suppose you have the other fields for this same order in another dictionary:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现在假设你有另一个字典，其中包含相同订单的其他字段：
- en: '[PRE4]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Your task is to concatenate these dictionaries into a single dictionary that
    includes all the key-value pairs from both the original ones. You use the `**`
    operator as follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 你的任务是将这些字典合并成一个单一的字典，包含原始字典中的所有键值对。你可以像下面这样使用`**`运算符：
- en: '[PRE5]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'You place the dictionaries you want to concatenate inside curly brackets, preceding
    each dictionary name with `**`. The `**` operator unpacks the two dictionaries
    into their key-value pairs, and then the curly brackets package them back up into
    a single dictionary. Now `order_9423517` looks like this:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 你将要连接的字典放在花括号内，每个字典名前面加上`**`。`**`运算符解包这两个字典为它们的键值对，然后花括号将它们重新包装成一个单一的字典。现在，`order_9423517`看起来像这样：
- en: '[PRE6]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: As you can see, all the elements from the original dictionaries are present,
    and their hierarchical structure has been preserved.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，原始字典中的所有元素都已存在，并且它们的层级结构得到了保留。
- en: Combining Corresponding Rows from Two Structures
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将两个结构中的对应行合并
- en: You already know how to combine several lists into a single list without changing
    the elements of those lists. In practice, you’ll also often have to join two or
    more data structures that share a common column into a single structure, combining
    corresponding rows from these data structures into a single row. If your data
    structures are pandas DataFrames, you can use methods like `join()` and `merge()`,
    as you’ve seen in previous chapters. However, if your data structures are lists
    containing “rows” of tuples, these methods aren’t available. Instead, you need
    to iterate over the lists and join each row individually.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经知道如何将多个列表合并成一个列表，而不改变这些列表的元素。实际上，你还经常需要将两个或多个共享公共列的数据结构合并为一个结构，将这些数据结构中的对应行合并为单一行。如果你的数据结构是pandas
    DataFrame，你可以使用像`join()`和`merge()`这样的方法，正如你在前几章中看到的那样。然而，如果你的数据结构是包含“行”的元组列表，那么这些方法并不可用。相反，你需要遍历这些列表，并逐行地合并。
- en: 'To illustrate, we’ll join the `orders` list you created in “Combining Lists
    and Tuples with +” earlier in this chapter with the `details` list introduced
    in “Data to Aggregate” in Chapter 6. As a reminder, here’s what that list looks
    like:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明，我们将结合本章中“通过+合并列表和元组”部分中创建的`orders`列表与第六章“数据聚合”中介绍的`details`列表。提醒一下，以下是该列表的样子：
- en: '[PRE7]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Both lists contain tuples whose first element is an order number. The goal
    is to find the tuples with matching order numbers, merge them into a single tuple,
    and store all the tuples in a list. Here’s how this is done:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 两个列表都包含元组，元组的第一个元素是订单号。目标是找到具有匹配订单号的元组，将它们合并为一个元组，并将所有元组存储在一个列表中。实现方法如下：
- en: '[PRE8]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: First you create an empty list to receive the merged tuples ❶. Then you use
    a nested pair of loops to iterate over the lists ❷ and an `if` statement ❸ to
    merge only tuples with matching order numbers. To avoid repeating the order number
    twice in the tuple being combined and appended to the `orders_details` list, you
    use slicing for each `details` tuple ❹, picking up all its fields except for the
    first one, which contains the redundant order number.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，创建一个空列表来接收合并后的元组 ❶。然后，使用一对嵌套循环来遍历`details`列表 ❷，并通过`if`语句 ❸来合并只有匹配订单号的元组。为了避免在合并并追加到`orders_details`列表的元组中重复出现订单号，您可以对每个`details`元组使用切片
    ❹，选择它的所有字段，除了第一个包含冗余订单号的字段。
- en: 'Looking at this code, you might wonder if it could be implemented more elegantly
    as a one-liner. Indeed, with the help of list comprehensions, you can achieve
    the same result as follows:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 看着这段代码，您可能会想，它是否可以更优雅地实现为一行代码。确实，借助列表推导式，您可以如下实现相同的结果：
- en: '[PRE9]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: In the outer list comprehension, you iterate over the tuples in the `details`
    list. In the inner list comprehension, you find a tuple in the `orders` list whose
    order number matches the current tuple from `details`. Since an order line in
    `details` is supposed to have only one matching tuple in `orders`, the inner list
    comprehension should generate a list with a single element (a tuple representing
    an order). So, you take the first element of the inner list comprehension with
    the `[0]` operator, then you concatenate this order’s tuple with the corresponding
    tuple from `details` using the `+` operator, excluding the redundant order number
    with `[1:]`.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在外部列表推导式中，您遍历`details`列表中的元组。在内部列表推导式中，您找到`orders`列表中与当前`details`元组的订单号匹配的元组。由于`details`中的订单行应该只有一个与`orders`中的元组匹配，内部列表推导式应该生成一个包含单个元素的列表（代表一个订单的元组）。因此，您通过`[0]`运算符取出内部列表推导式的第一个元素，然后使用`+`运算符将该订单的元组与`details`中对应的元组连接起来，省略冗余的订单号部分`[1:]`。
- en: 'Whether you’ve created `orders_details` through list comprehensions or with
    the help of two `for` loops, as shown previously, the resulting list will look
    as follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是通过列表推导式创建的`orders_details`，还是借助两个`for`循环创建的，如前所示，生成的列表将如下所示：
- en: '[PRE10]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The list contains all the tuples from the `details` list, and each tuple also
    contains additional information from the corresponding tuple of the `orders` list.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 该列表包含`details`列表中的所有元组，每个元组还包含来自`orders`列表中对应元组的附加信息。
- en: Implementing Different Types of Joins for Lists
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实现不同类型的列表连接
- en: 'The operation you performed in the previous section is a standard one-to-many
    join: each order line in `details` has a matching order in `orders`, and each
    order in `orders` has one or more order lines in `details`. In practice, however,
    either or both of the datasets being joined might have rows with no matches in
    the other dataset. To account for these situations, you must be able to perform
    operations equivalent to the various database-style joins we discussed in Chapter
    3: left joins, right joins, inner joins, and outer joins.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 您在前一部分执行的操作是一个标准的“一对多”连接：`details`中的每个订单行都有一个在`orders`中匹配的订单，而`orders`中的每个订单有一个或多个在`details`中的订单行。然而，在实际操作中，连接的两个数据集中的某些行可能没有在另一个数据集中找到匹配的行。为了应对这种情况，您必须能够执行类似于我们在第三章中讨论的各种数据库风格的连接操作：左连接、右连接、内连接和外连接。
- en: 'As an example, the `details` list might have order lines for orders not found
    in the `orders` list. One way this could happen is if you filter `orders` for
    a certain date range; since `details` doesn’t include a date field, you can’t
    filter the `details` list accordingly. To simulate this situation, add a new row
    to the `details` list that refers to an order that isn’t in `orders`:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 举个例子，`details`列表可能包含一些在`orders`列表中找不到的订单行。发生这种情况的一种方式是你对`orders`进行某个日期范围的过滤；由于`details`中没有日期字段，因此你无法相应地过滤`details`列表。为了模拟这种情况，向`details`列表中添加一行，引用一个不在`orders`中的订单：
- en: '[PRE11]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'If you now try to generate the `orders_details` list as you did before:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你现在像之前一样尝试生成`orders_details`列表：
- en: '[PRE12]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'you’ll get the following error:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 你会得到以下错误：
- en: '[PRE13]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The problem occurs when you get to the unmatched order number in the `details`
    list and you try to retrieve the first element of the corresponding inner list
    comprehension. No such element exists, since the order number isn’t in the `orders`
    list. One way to solve this is to add an `if` clause to the `for d in details`
    loop within the outer list comprehension, checking whether the order number in
    a `details` row can be found in any row of `orders`, as shown here:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 问题出现在你到达`details`列表中的不匹配订单号时，并试图检索对应内部列表推导中的第一个元素。由于订单号不在`orders`列表中，因此不存在这样的元素。解决此问题的一种方法是在外部列表推导中的`for
    d in details`循环内添加`if`语句，检查`details`行中的订单号是否可以在`orders`的任何行中找到，如下所示：
- en: '[PRE14]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: You eliminate the problem by excluding any `details` rows that don’t have a
    matching row in the `orders` list, implementing the check in the `if` clause that
    follows the `for d in details` loop ❶. Thus, the list comprehension shown here
    results in an inner join.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 你通过排除任何没有匹配行的`details`行来解决问题，并在`for d in details`循环后的`if`语句中实现检查❶。因此，下面显示的列表推导会导致一个内连接。
- en: But what if you want to include all the `details` rows in the resulting `orders_details`
    list? You may want to do this, for example, so you can summarize the totals for
    all the orders, not only for those orders in the current ``orders list (which
    has hypothetically been filtered by date). You might then summarize totals for
    the orders that *are* in the current `orders` list and compare these sums.``
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，如果你想在结果`orders_details`列表中包含所有的`details`行呢？你可能想这样做，例如，方便你总结所有订单的总额，而不仅仅是当前`orders`列表中的订单总额（该列表假设已经按日期进行过过滤）。你可能会总结当前`orders`列表中*存在*的订单总额，并比较这些总和。
- en: '[PRE15] orders_details_right = [[o for o in orders if d[0] in o][0] + d[1:]
    if d[0] in [o[0] for o                         in orders] ❶ else (d[0], None,
    None) + d[1:] for d in details] [PRE16] [  `--snip--`  (4626490, ''2022-02-06'',
    9004, ''Sweater'', ''Dickies'', 56.0, 1),  (4626592, None, None, ''Shorts'', ''Protest'',
    48.0, 1) ] [PRE17] sum(pr*qt for _, _, _, _, _, pr, qt in orders_details_right)
    [PRE18] 779.0 [PRE19] sum(pr*qt for _, dt, _, _, _, pr, qt in orders_details_right
    ❶ if dt != None) [PRE20] 731.0 [PRE21] import numpy as np jeff_salary = [2700,3000,3000]
    nick_salary = [2600,2800,2800] tom_salary = [2300,2500,2500] base_salary1 = np.array([jeff_salary,
    nick_salary, tom_salary]) [PRE22] maya_salary = [2200,2400,2400] john_salary =
    [2500,2700,2700] base_salary2 = np.array([maya_salary, john_salary]) [PRE23] base_salary
    = np.concatenate((base_salary1, base_salary2), axis=0) [PRE24] [[2700 3000 3000]  [2600
    2800 2800]  [2300 2500 2500],  [2200 2400 2400],  [2500 2700 2700]] [PRE25] new_month_salary
    = np.array([[3000],[2900],[2500],[2500],[2700]]) [PRE26] [[3000]  [2900]  [2500]  [2500]  [2700]]
    [PRE27] base_salary = np.concatenate((base_salary, new_month_salary), axis=1)
    [PRE28] [[2700 3000 3000 3000]  [2600 2800 2800 2900]  [2300 2500 2500 2500]  [2200
    2400 2400 2500]  [2500 2700 2700 2700]] [PRE29] import pandas as pd salary_df1
    = pd.DataFrame(     {''jeff'': jeff_salary,      ''nick'': nick_salary,      ''tom'':
    tom_salary     })  [PRE30] salary_df1.index = [''June'', ''July'', ''August'']
    [PRE31]  jeff  nick   tom June    2700  2600  2300 July    3000  2800  2500 August  3000  2800  2500
    [PRE32] salary_df1 = salary_df1.T [PRE33]  June  July  August jeff  2700  3000    3000
    nick  2600  2800    2800 tom   2300  2500    2500 [PRE34] salary_df2 = pd.DataFrame(     {''maya'':
    maya_salary,      ''john'': john_salary     },     index = [''June'', ''July'',
    ''August''] ).T  [PRE35]  June  July  August maya  2200  2400    2400 john  2500  2700    2700
    [PRE36] salary_df = pd.concat([salary_df1, salary_df2]) [PRE37]  June  July  August
    jeff  2700  3000    3000 nick  2600  2800    2800 tom   2300  2500    2500 maya  2200  2400    2400
    john  2500  2700    2700 [PRE38] salary_df3 = pd.DataFrame(     {''September'':
    [3000,2800,2500,2400,2700],      ''October'': [3200,3000,2700,2500,2900]     },     index
    = [''jeff'', ''nick'', ''tom'', ''maya'', ''john''] ) [PRE39] salary_df = pd.concat([salary_df,
    salary_df3], axis=1) [PRE40]  June  July  August  September  October jeff  2700  3000    3000       3000     3200
    nick  2600  2800    2800       2800     3000 tom   2300  2500    2500       2500     2700
    maya  2200  2400    2400       2400     2500 john  2500  2700    2700       2700     2900
    [PRE41] salary_df = salary_df.drop([''September'', ''October''], axis=1) [PRE42]
    salary_df = salary_df.drop([''nick'', ''maya''], axis=0) [PRE43]  June  July  August
    jeff  2700  3000    3000 tom   2300  2500    2500 john  2500  2700    2700 [PRE44]  Total
    Date       Region        2022-02-04 East     97.0            West    243.0 2022-02-05
    East    160.0            West     35.0 2022-02-06 East    110.0            West     86.0
    [PRE45] df_date_region1 = pd.DataFrame(  [         (''2022-02-04'', ''East'',
    97.0),   (''2022-02-04'', ''West'', 243.0),   (''2022-02-05'', ''East'', 160.0),   (''2022-02-05'',
    ''West'', 35.0),   (''2022-02-06'', ''East'', 110.0),   (''2022-02-06'', ''West'',
    86.0)  ],  columns =[''Date'', ''Region'', ''Total'']).set_index([''Date'',''Region''])
    [PRE46] df_date_region2 = pd.DataFrame(  [         (''2022-02-04'', ''South'',
    114.0),   (''2022-02-05'', ''South'', 325.0),   (''2022-02-06'', ''South'', 212.0)  ],  columns
    =[''Date'', ''Region'', ''Total'']).set_index([''Date'',''Region'']) [PRE47] df_date_region
    = pd.concat([df_date_region1,             df_date_region2]).sort_index(level=[''Date'',''Region''])
    [PRE48]  Total Date       Region        2022-02-04 East     97.0            South   114.0            West    243.0
    2022-02-05 East    160.0            South   325.0            West     35.0 2022-02-06
    East    110.0            South   212.0            West     86.0 [PRE49] import
    pandas as pd df_orders = pd.DataFrame(orders, columns =[''OrderNo'', ''Date'',
    ''Empno'']) df_details = pd.DataFrame(details, columns =[''OrderNo'', ''Item'',
    ''Brand'',                                              ''Price'', ''Quantity''])
    [PRE50] df_details = df_details.append(   {''OrderNo'': 4626592,    ''Item'':
    ''Shorts'',    ''Brand'': ''Protest'',    ''Price'': 48.0,    ''Quantity'': 1   },
    ❶ ignore_index = True ) [PRE51] df_orders_details_right = df_orders.merge(df_details,
    ❶ how=''right'',                   ❷ left_on=''OrderNo'', right_on=''OrderNo'')
    [PRE52]  OrderNo        Date   Empno          Item           Brand  Price  Quantity
    0   9423517  2022-02-04  9001.0         Jeans        Rip Curl   87.0         1
    1   9423517  2022-02-04  9001.0        Jacket  The North Face  112.0         1
    2   4626232  2022-02-04  9003.0         Socks            Vans   15.0         1
    3   4626232  2022-02-04  9003.0         Jeans      Quiksilver   82.0         1
    4   9423534  2022-02-04  9001.0         Socks              DC   10.0         2
    5   9423534  2022-02-04  9001.0         Socks      Quiksilver   12.0         2
    6   9423679  2022-02-05  9002.0       T-shirt       Patagonia   35.0         1
    7   4626377  2022-02-05  9003.0         Hoody          Animal   44.0         1
    8   4626377  2022-02-05  9003.0  Cargo Shorts          Animal   38.0         1
    9   4626412  2022-02-05  9004.0         Shirt          Volcom   78.0         1
    10  9423783  2022-02-06  9002.0  Boxer Shorts        Superdry   30.0         2
    11  9423783  2022-02-06  9002.0        Shorts           Globe   26.0         1
    12  4626490  2022-02-06  9004.0  Cargo Shorts       Billabong   54.0         1
    13  4626490  2022-02-06  9004.0       Sweater         Dickies   56.0         1
    14  4626592         NaN     NaN        Shorts         Protest   48.0         1
    [PRE53] print(df_orders_details_right.dtypes) [PRE54] OrderNo       int64 Date         object
    Empno       float64 Item         object Brand        object Price       float64
    Quantity      int64 dtype: object [PRE55] df_orders_details_right = df_orders_details_right.fillna({''Empno'':0}).astype({''Empno'':''int64''})
    [PRE56]`You end up with the following DataFrame:    [PRE57]    The `NaN` in the
    `Empno` column has become a `0`, and the employee numbers once again appear as
    integers. No more pesky decimal points!    #### Implementing a Many-to-Many Join    A
    many-to-many join can be established between datasets where a row in each dataset
    may relate to multiple rows in the other. For example, suppose you have two datasets
    containing books and authors, respectively. Every record in the authors dataset
    can be linked to one or more records in the books dataset, and every record in
    the books dataset can be linked to one or more records in the authors dataset.    Typically,
    you join datasets that have a many-to-many relationship using an *associative
    table*, also known as a *matching table*. This table maps two (or more) datasets
    together by referencing the primary keys of each dataset. The associative table
    has a one-to-many relationship with each of the datasets and functions as an intermediary
    between them, allowing them to be merged.    To see how a many-to-many join can
    be implemented through a matching table, create a `books` DataFrame and an `authors`
    DataFrame as follows:    [PRE58]    The `books` DataFrame includes three books,
    each with a unique `book_id`, while the `authors` DataFrame includes three authors,
    each with a unique `author_id`. Now create a third DataFrame, `matching`, that
    will serve as the associative table, connecting each book with its respective
    author(s) and vice versa:    [PRE59]    The `matching` DataFrame has two columns:
    one corresponding to author IDs and one corresponding to book IDs. Unlike in the
    other two DataFrames, each row in `matching` doesn’t just represent a single author
    or a single book. Instead, it contains information about the *relationship between*
    one particular author and one particular book. The DataFrame looks as follows:    [PRE60]    The
    first and second rows both reference the `author_id` of `jsn`, establishing that
    Johnson is the author of two different books. Likewise, the second and third rows
    both reference the `book_id` of `b2`, establishing that *Python for Web Development*
    has two authors.    Now you can create a many-to-many join between the `authors`
    and `books` datasets via `matching, as shown here`:    [PRE61]    The operation
    actually consists of two separate joins using the `merge()` method. First you
    join the `books` and `matching` DataFrames on their respective `book_id` columns.
    Then you join the result of the first join with the `authors` DataFrame via their
    `author_id` columns. Both of these are straightforward one-to-many joins, but
    together they result in a new DataFrame illustrating the many-to-many relationship
    between the `books` and `authors` datasets. You filter the DataFrame to include
    just the `title`, `topic`, and `author` columns, so that result looks as follows:    [PRE62]    As
    you can see, Johnson is listed twice as the author of both *Beautiful Coding*
    and *Python for Web Development*, while *Python for Web Development* is listed
    twice, once for each of its authors.    ## Summary    In this chapter, you looked
    at different ways of combining datasets presented in the form of built-in data
    structures such as lists, or third-party data structures such as NumPy arrays
    and pandas DataFrames. You learned to concatenate datasets, appending the columns
    or rows of one dataset to another. You also learned to join datasets, combining
    their matching rows.[PRE63]``'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL

## **5

**构建数据集**

![image](Images/common.jpg)

前一章有很多详细的建议。现在让我们把这些都付诸实践，构建我们将在本书剩余部分使用的数据集。部分数据集非常适合传统模型，因为它们由特征向量组成。其他一些则更适合深度学习模型，这些模型处理的是多维输入，特别是图像，或可以视作图像的内容。

我们将通过获取原始数据并对其进行预处理，使其适合我们的工具使用。直到我们将这些数据集应用于特定模型时，我们才会进行实际的训练/验证/测试数据划分。值得注意的是，预处理数据使其适合模型使用通常是机器学习任务中最为繁重的部分。尽管如此，如果没有做好这一步，或者做得不好，你的模型可能远不如你期望的那样有效。

### 鸢尾花

也许所有机器学习数据集中最经典的就是鸢尾花数据集，该数据集由R. A. Fisher于1936年在他的论文《多重测量在分类问题中的应用》中开发。它是一个包含三类、每类50个样本的小型数据集。数据集包括四个特征：萼片宽度、萼片长度、花瓣宽度和花瓣长度，单位为厘米。这三类分别是*I. setosa*、*I. versicolour*和*I. virginica*。这个数据集已经内置于sklearn库中，但我们将从加利福尼亚大学欧文分校的机器学习库下载它，以练习如何处理外部数据并引入适合许多传统机器学习模型的丰富数据集。主要的库位于*[https://archive.ics.uci.edu/ml/index.php](https://archive.ics.uci.edu/ml/index.php)*，你可以直接从*[https://archive.ics.uci.edu/ml/datasets/iris/](https://archive.ics.uci.edu/ml/datasets/iris/)*下载鸢尾花数据集。

截至本文撰写时，这个数据集已经被下载了近180万次。你可以通过点击页面顶部附近的**数据文件夹**链接，然后右键点击并保存*iris.data*文件，最好保存到一个名为*iris*的新目录中来下载它。我们来看看这个文件的开头部分：

5.1,3.5,1.4,0.2,Iris-setosa

4.9,3.0,1.4,0.2,Iris-setosa

4.7,3.2,1.3,0.2,Iris-setosa

4.6,3.1,1.5,0.2,Iris-setosa

5.0,3.6,1.4,0.2,Iris-setosa

5.4,3.9,1.7,0.4,Iris-setosa

4.6,3.4,1.4,0.3,Iris-setosa

由于每行末尾的类名都相同，我们应该立刻怀疑样本是按类排序的。查看文件的其余部分证实了这一点。因此，正如[第4章](ch04.xhtml#ch04)中强调的那样，我们在训练模型之前，必须确保对数据进行随机化。此外，我们还需要将类名替换为整数标签。我们可以使用[清单5-1](ch05.xhtml#ch5lis1)中的脚本将数据集加载到Python中。

import numpy as np

❶ with open("iris.data") as f:

lines = [i[:-1] for i in f.readlines()]

❷ n = ["Iris-setosa","Iris-versicolor","Iris-virginica"]

x = [n.index(i.split(",")[-1]) for i in lines if i != ""]

x = np.array(x, dtype="uint8")

❸ y = [[float(j) for j in i.split(",")[:-1]] for i in lines if i != ""]

y = np.array(y)

❹ i = np.argsort(np.random.random(x.shape[0]))

x = x[i]

y = y[i]

❺ np.save("iris_features.npy", y)

np.save("iris_labels.npy", x)

*清单 5-1：加载原始鸢尾花数据集并映射到我们的标准格式*

首先，我们加载包含数据的文本文件。列表推导式去除了多余的换行符❶。接着，我们通过将文本标签转换为整数（0到2之间）来创建标签向量。通过按逗号分割每行生成的列表中的最后一个元素是文本标签。我们希望使用NumPy数组，因此我们将列表转换为数组。虽然uint8并不是必须的，但由于标签从不为负，且最大值不超过2，因此通过将数据类型设置为无符号8位整数，我们节省了一些空间❷。

接下来，通过双重列表推导式创建一个150行4列的特征向量矩阵。外部推导式（i）遍历文件中的每一行，内部推导式（j）则将每个样本的测量数据转换为浮点数。我们随后将这些列表的列表转换为一个2D NumPy数组❸。接着，我们像之前一样对数据集进行随机化❹，最后，将NumPy数组保存到磁盘，以便以后使用❺。

[图 5-1](ch05.xhtml#ch5fig1)展示了特征的箱线图。这是一个行为良好的数据集，但第二个特征确实存在一些可能的离群值。由于所有特征的尺度相似，我们将保持原样使用这些特征。

![image](Images/05fig01.jpg)

*图 5-1：四个鸢尾花数据集特征的箱线图*

### 乳腺癌

我们的第二个数据集，威斯康星诊断乳腺癌数据集，也包含在sklearn中，你也可以从UCI机器学习库下载它。我们将遵循前述过程并下载数据集，看看如何处理它。虽然这看起来似乎没有必要，但正如构建一个良好的数据集对于训练一个好的模型至关重要一样，学会处理那些不符合我们期望格式的数据源同样重要。如果有一天你决定将机器学习和数据科学作为职业，你将几乎每天都面临这个问题。

通过访问*[https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)/](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)/)*下载数据集。然后，点击**Data Folder**链接，保存*wdbc.data*文件。

这个数据集包含从乳腺肿块的细针活检切片中提取的细胞测量数据。共有30个连续特征和两个类别：恶性（癌症，212个样本）和良性（无癌症，357个样本）。这也是一个热门数据集，下载量超过670,000次。文件的第一行如下所示：

842302,M,17.99,10.38,122.8,1001,0.1184, ...

该行的第一个元素是患者ID号，我们不需要关心。第二个元素是标签——*M*表示恶性，*B*表示良性。该行中的其余数字是与细胞大小相关的30个测量值。特征本身具有不同的尺度，因此除了创建原始数据集外，我们还将创建一个标准化版本。由于这是整个数据集，并且我们将需要将其一部分保留用于测试，因此我们不需要记录每个特征的均值和标准差。如果我们能够获得更多相同方式生成的数据，可能来自一个被遗忘的旧文件，我们就需要保存这些值，以便可以对新的输入进行标准化。构建这个数据集并生成总结箱型图的脚本在[清单 5-2](ch05.xhtml#ch5lis2)中。

import numpy as np

import matplotlib.pyplot as plt

❶ with open("wdbc.data") as f:

lines = [i[:-1] for i in f.readlines() if i != ""]

❷ n = ["B","M"]

x = np.array([n.index(i.split(",")[1]) for i in lines],dtype="uint8")

y = np.array([[float(j) for j in i.split(",")[2:]] for i in lines])

i = np.argsort(np.random.random(x.shape[0]))

x = x[i]

y = y[i]

z = (y - y.mean(axis=0)) / y.std(axis=0)

❸ np.save("bc_features.npy", y)

np.save("bc_features_standard.npy", z)

np.save("bc_labels.npy", x)

plt.boxplot(z)

plt.show()

*清单 5-2：加载原始乳腺癌数据集*

我们做的第一件事是读取原始文本数据❶。然后，我们提取每个标签并将其映射为0（良性）和1（恶性）。注意，这里我们使用1表示自然目标情况，这样一个输出概率值的模型就表示了找到癌症的可能性❷。我们提取每个样本的30个特征作为浮点数，使用嵌套列表推导式首先提取特征文本（i），然后将其映射为浮点数（j）。这会生成一个嵌套列表，NumPy会将其方便地转换为一个具有569行和30列的矩阵。

接下来，我们将数据集进行随机化，并通过减去每个特征的均值并除以标准差来计算标准化版本。我们将使用这个版本，并在[图 5-2](ch05.xhtml#ch5fig2)的箱型图❸中进行分析，该图展示了标准化后的所有30个特征。

![image](Images/05fig02.jpg)

*图 5-2：乳腺癌数据集30个特征的箱型图*

在这种情况下，我们不需要了解特征代表什么。我们将假设所选择的特征足以判断恶性程度。我们的模型会告诉我们这些假设是否成立。现在，所有特征的尺度都相同，从 y 轴上方框的位置可以看出：它们都覆盖了基本相同的范围。数据的一个特征立刻显现出来——即，明显的离群值，这由四分位间距（见 [Figure 4-6](ch04.xhtml#ch4fig6)）标识出来。这些离群值不一定是错误的值，但它们表明数据并不是正态分布的——它在每个特征上都不遵循钟形曲线分布。

### MNIST 数字

我们的下一个数据集通常不是由特征向量组成的，而是由成千上万张手写数字的小图像构成。这个数据集是现代机器学习中的“工作马”，也是深度学习研究人员测试新想法时最先使用的数据集之一。它虽然过于常用，但之所以被广泛使用，是因为它非常易于理解并且简单易用。

该数据集有着悠久的历史，但我们将使用的版本是最常见的版本，通常被称为 *MNIST 数据集*。数据集的权威来源是 [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)，其中包括一些背景材料。为了节省时间，我们将使用 Keras 来下载并格式化数据集。

Keras 将数据集作为 3D NumPy 数组返回。第一个维度是图像的数量——训练集为 60,000 张，测试集为 10,000 张。第二个和第三个维度是图像的像素值。每张图像的大小为 28×28 像素。每个像素是一个无符号的 8 位整数，范围为 [0,255]。

因为我们希望使用期望向量作为输入的模型，并且希望利用这个数据集来展示书中后续模型的一些特性，我们将基于这个初始数据集创建额外的数据集。首先，我们将展开图像，形成特征向量，这样就能用传统模型来处理这个数据集，传统模型期望输入的是向量。其次，我们将继续使用图像，但会打乱数据集中图像的顺序。我们会以相同的方式打乱每张图像的像素顺序，因此尽管像素不再按原来的顺序排列，生成数字图像，但这种重排是确定性的，并且在所有图像中一致应用。第三，我们将为这些打乱顺序的图像创建展开后的特征向量版本。我们将使用这些额外的数据集来探索传统神经网络和卷积神经网络模型之间的差异。

使用 [Listing 5-3](ch05.xhtml#ch5lis3) 来构建数据集文件。

import numpy as np

import keras

from keras.datasets import mnist

❶ (xtrn, ytrn), (xtst, ytst) = mnist.load_data()

idx = np.argsort(np.random.random(ytrn.shape[0]))

xtrn = xtrn[idx]

ytrn = ytrn[idx]

idx = np.argsort(np.random.random(ytst.shape[0]))

xtst = xtst[idx]

ytst = ytst[idx]

np.save("mnist_train_images.npy", xtrn)

np.save("mnist_train_labels.npy", ytrn)

np.save("mnist_test_images.npy", xtst)

np.save("mnist_test_labels.npy", ytst)

❷ xtrnv = xtrn.reshape((60000,28*28))

xtstv = xtst.reshape((10000,28*28))

np.save("mnist_train_vectors.npy", xtrnv)

np.save("mnist_test_vectors.npy", xtstv)

❸ idx = np.argsort(np.random.random(28*28))

for i in range(60000):

xtrnv[i,:] = xtrnv[i,idx]

for i in range(10000):

xtstv[i,:] = xtstv[i,idx]

np.save("mnist_train_scrambled_vectors.npy", xtrnv)

np.save("mnist_test_scrambled_vectors.npy", xtstv)

❹ t = np.zeros((60000,28,28))

for i in range(60000):

t[i,:,:] = xtrnv[i,:].reshape((28,28))

np.save("mnist_train_scrambled_images.npy", t)

t = np.zeros((10000,28,28))

for i in range(10000):

t[i,:,:] = xtstv[i,:].reshape((28,28))

np.save("mnist_test_scrambled_images.npy", t)

*清单 5-3：加载和构建各种 MNIST 数据集*

我们首先告诉 Keras 加载 MNIST 数据集 ❶。首次运行时，Keras 会显示一条关于下载数据集的消息。之后，再次运行时不会显示该消息。

数据集本身存储在四个 NumPy 数组中。第一个数组 xtrn 的形状为 (60000, 28, 28)，包含 60,000 张训练图像，每张图像大小为 28×28 像素。相关标签存储在 ytrn 中，值为整数 [0,9]。10,000 张测试图像存储在 xtst 中，标签存储在 ytst 中。我们还随机化样本顺序，并将数组写入磁盘以供将来使用。

接下来，我们将训练集和测试集图像展开，转化为 784 元素的向量 ❷。展开操作将每一行像素按顺序连接在一起，直到所有行都被排列成一行。由于 28 × 28 = 784，因此得到 784 个元素。

接下来，我们生成展开向量中 784 个元素的排列（idx） ❸。

我们使用打乱的向量形成新的、打乱的数字图像并存储到磁盘 ❹。这些打乱的图像是通过撤销展开操作，从打乱的向量中生成的。在 NumPy 中，这只是调用向量数组的 reshape 方法。请注意，在整个过程中，我们不会改变图像的相对顺序，因此我们只需为训练和测试标签分别存储一个文件。

[图 5-3](ch05.xhtml#ch5fig3) 展示了 MNIST 数据集中的代表性数字。

![image](Images/05fig03.jpg)

*图 5-3：代表性的 MNIST 数字图像*

我们无需标准化这些图像，因为我们知道它们已经在相同的尺度上，因为它们是像素图像。我们有时会在使用时对它们进行缩放，但现在可以将它们作为字节灰度图像存储在磁盘上。数据集本身比较平衡；[表 5-1](ch05.xhtml#ch5tab1) 显示了训练集的分布。因此，我们不需要担心数据不平衡的问题。

**表 5-1：** MNIST 训练集的数字频率

| **数字** | **数量** |
| --- | --- |
| 0 | 5,923 |
| 1 | 6,742 |
| 2 | 5,958 |
| 3 | 6,131 |
| 4 | 5,842 |
| 5 | 5,421 |
| 6 | 5,918 |
| 7 | 6,265 |
| 8 | 5,851 |
| 9 | 5,949 |

### CIFAR-10

*CIFAR-10* 是另一个标准的深度学习数据集，足够小，使得我们在不需要大量训练时间或 GPU 的情况下也能使用。与 MNIST 一样，我们可以通过 Keras 提取该数据集，首次请求时它会自动下载。CIFAR-10 的源页面在 *https://www.cs.toronto.edu/\%7Ekriz/cifar.html*。

值得浏览该页面，了解更多有关数据集来源的信息。它由 60,000 张 32×32 像素的 RGB 图像组成，来自 10 个类别，每个类别有 6,000 个样本。训练集包含 50,000 张图像，测试集包含 10,000 张图像。这 10 个类别在这里的 [表 5-2](ch05.xhtml#ch5tab2) 中展示。

**表 5-2:** CIFAR-10 类别标签和名称

| 标签 | 类别 |
| --- | --- |
| 0 | 飞机 |
| 1 | 汽车 |
| 2 | 鸟 |
| 3 | 猫 |
| 4 | 鹿 |
| 5 | 狗 |
| 6 | 青蛙 |
| 7 | 马 |
| 8 | 船 |
| 9 | 卡车 |

[图 5-4](ch05.xhtml#ch5fig4) 展示了每个类别的代表性图像，按行排列。让我们提取数据集，存储以供将来使用，并创建向量表示，就像我们对 MNIST 所做的那样。

![image](Images/05fig04.jpg)

*图 5-4：代表性的 CIFAR-10 图像*

执行这一切的脚本在 [清单 5-4](ch05.xhtml#ch5lis4) 中。

import numpy as np

import keras

from keras.datasets import cifar10

❶ (xtrn, ytrn), (xtst, ytst) = cifar10.load_data()

idx = np.argsort(np.random.random(ytrn.shape[0]))

xtrn = xtrn[idx]

ytrn = ytrn[idx]

idx = np.argsort(np.random.random(ytst.shape[0]))

xtst = xtst[idx]

ytst = ytst[idx]

np.save("cifar10_train_images.npy", xtrn)

np.save("cifar10_train_labels.npy", ytrn)

np.save("cifar10_test_images.npy", xtst)

np.save("cifar10_test_labels.npy", ytst)

❷ xtrnv = xtrn.reshape((50000,32*32*3))

xtstv = xtst.reshape((10000,32*32*3))

np.save("cifar10_train_vectors.npy", xtrnv)

np.save("cifar10_test_vectors.npy", xtstv)

*清单 5-4：加载并构建各类 CIFAR-10 数据集*

我们首先从 Keras 加载 CIFAR-10 ❶。与 MNIST 一样，数据集会在第一次运行代码时自动下载。而且，与 MNIST 一样，我们会随机化训练集和测试集的划分。训练数据存储在 xtrn 中，形状为（50,000; 32; 32; 3）的数组。最后一个维度表示每个像素的三个颜色分量：红色、绿色和蓝色。测试数据也类似，存储在 xtst 中，形状为（10,000; 32; 32; 3）的数组。最后，我们将随机化的训练图像和测试图像写入磁盘。接着，我们展开这些图像，生成 32 × 32 × 3 = 3072 元素的特征向量，表示这些图像 ❷，并将它们写入磁盘。

### 数据增强

正如我们在[第4章](ch04.xhtml#ch04)中看到的，数据集至关重要，因此它需要尽可能完整。通常，你可以通过精心选择适合模型在使用时可能遇到的输入范围的样本来实现这一点。回想我们之前的类比，我们需要模型进行*插值*而不是*外推*。但是，有时候，即使我们有广泛的可能样本范围，实际样本的数量却很少。此时，数据增强可以提供帮助。

*数据增强*使用现有数据集中的数据生成新的可能样本，并将其添加到数据集中。这些样本总是以某种方式基于现有数据。数据增强是一种强大的技术，特别适用于实际数据集较小的情况。从实践角度来看，数据增强应该在可行的情况下尽量使用。

数据增强利用我们已有的数据，通过修改它来创建可能来自与实际数据相同母体分布的新样本。这意味着，如果我们足够耐心地继续收集真实数据，我们可以测量那些新样本。有时候，数据增强甚至可以超出我们实际测量的范围，但仍然有助于模型学会对实际数据进行泛化。例如，使用图像作为输入的模型可能会从不切实际的颜色或背景中受益，即使模型的实际输入永远不会使用这些颜色或背景。

虽然数据增强在许多情况下都有效，并且是深度学习的常用方法，但并不是所有数据都能进行现实的增强，因此你并不总能使用它。

在这一部分，我们将探讨为什么我们要考虑使用数据增强以及如何实施。接下来，我们将增强之前开发的两个数据集，以便在构建模型时，我们能够看到数据增强如何影响模型的学习。关于数据增强，有一个经验法则：通常情况下，只要可能，特别是在数据集较小时，你应该进行数据增强。

#### 为什么要增强训练数据？

在[第4章](ch04.xhtml#ch04)中，我们遇到了维度灾难的问题。我们看到，许多模型解决这一问题的方法是通过更多的训练数据填充可能输入的空间。数据增强是我们可以用来填充这个空间的一种方式。我们将来还需要这样做；例如，在[第6章](ch06.xhtml#ch06)中，我们将遇到*k*-最近邻分类器，它可能是所有分类器中最简单的一种。

这个分类器关键依赖于足够的训练数据，以充分填充输入特征空间。如果有三个特征，那么空间就是三维的，训练数据将填充到该空间中的某个立方体里。我们拥有的训练数据越多，立方体中的样本就越多，分类器的表现就越好。这是因为分类器通过衡量训练数据中的点与新的、未知的特征向量之间的距离来进行投票，决定分配哪个标签。空间中训练点的密度越大，投票过程成功的频率就越高。宽泛地说，数据增强填补了这个空间。对于大多数数据集，获取更多的数据，即更多的父分布样本，并不能填补特征空间的每个部分，但它会逐渐呈现出父分布在特征空间中的完整图景。

当我们使用现代深度学习模型时（[第12章](ch12.xhtml#ch12)），我们会发现数据增强还有额外的好处。在训练过程中，神经网络会被训练去学习训练数据的特征。如果网络学习到的特征确实有助于区分不同类别，一切都很好。但正如我们在[第4章](ch04.xhtml#ch04)中看到的狼和哈士奇的例子，有时网络会学到错误的特征，这些特征不能用于对新输入进行泛化——比如狼类图像的背景有雪，而哈士奇图像则没有。

避免这种倾向的措施被称为*正则化*。正则化帮助网络学习训练数据中重要的特征，这些特征可以像我们希望的那样进行泛化。数据增强——除了获取更多的实际数据——或许是正则化网络学习过程的最简单方式。它使得学习过程不去关注选定训练集中特定样本的怪癖，而是转而关注数据的更一般性特征。至少，这是我们希望的结果。

数据增强的另一个好处是它减少了训练时过拟合的可能性。我们将在[第9章](ch09.xhtml#ch09)中进一步讨论过拟合，但简而言之，过拟合指的是模型几乎完美地记住训练数据，但没有学会对新输入进行泛化。当模型能够基本记住训练数据时，使用小数据集可能会导致过拟合。数据增强增加了数据集的大小，降低了过拟合的概率，并且可能允许使用一个具有更大容量的模型。（容量是一个模糊的概念，可以理解为“更大”，即模型能够学习训练数据中更多重要的部分，同时仍能对新数据进行泛化。）

有一个关于数据增强与训练/验证/测试数据集划分之间的极其重要的要点：你**必须**确保每个增强的样本都属于同一数据集。例如，如果我们增强了样本*X*[12345]，并且这个样本被分配到训练集中，那么我们必须确保基于*X*[12345]增强的**所有**样本也都属于训练集。这一点非常重要，值得再次强调：*确保绝对不要将基于原始样本的增强样本混入训练集、验证集和测试集中。*

如果我们不遵守这个规则，我们对模型质量的信任将是没有根据的，或者至少是部分不合理的，因为在验证集和测试集中将会出现一些样本，这些样本本质上也出现在训练集中，因为它们是基于训练数据生成的。这个警告可能看起来不必要，但实际上很容易犯这个错误，尤其是在与他人合作或使用某种数据库时。

增强数据的正确方式是**在**训练集、验证集和测试集划分之后进行。然后，至少增强训练数据，并将所有新样本标记为训练数据。

那么，增强验证集和测试集怎么样？这样做并没有错，如果你没有太多数据的话，可能也有意义。我还没有遇到过对增强验证集和测试数据的效果进行严格研究的论文，但从概念上讲，这样做应该不会造成坏影响，甚至可能有所帮助。

#### 增强训练数据的方法

要增强一个数据集，我们需要从中生成新的、合理的样本，也就是说，它们在数据集中确实可能出现。对于图像来说，这很简单；你可以旋转图像，或者水平或垂直翻转它。有时，你也可以操作像素本身来改变对比度或调整颜色。有些人甚至将颜色通道完全交换——例如将红色通道和蓝色通道交换。

当然，这些操作必须是合理的。细微的旋转可能模拟相机角度的变化，左右翻转可能模拟看镜子的体验。但上下翻转可能就不那么现实了。的确，一只猴子可能会倒挂在图片中，但翻转图片也会翻转树木和地面。另一方面，你可能能在航拍图像中进行上下翻转，因为它展示的物体可以是任何方向。

好的，所以图像的增强通常是简单明了的，且很容易判断增强是否合理。特征向量的增强则更为微妙。它并不总是很清楚如何操作，或者是否甚至可能做到。那么在这种情况下我们该怎么办呢？

再次强调，指导原则是增强必须有意义。如果我们将颜色编码为红色、绿色或蓝色的独热向量，而某个类别的实例可以是红色、绿色或蓝色，那么一种增强方式是改变颜色在红色、绿色和蓝色之间进行切换。如果一个样本可以表示男性或女性，那么我们也可以改变这些值，得到一个相同类别但性别不同的新样本。

然而，这些做法比较不常见。通常情况下，你会尝试增强连续值，创建一个新的特征向量，仍然代表原始类别。接下来，我们将通过增强鸢尾花数据集来探讨一种方法。之后，我们将增强CIFAR-10数据集，看看如何处理图像。

#### 扩展鸢尾花数据集

鸢尾花数据集包含来自三个类别的150个样本，每个样本有四个连续的特征。我们将通过使用*主成分分析（PCA）*来增强它。这是一种使用了超过一个世纪的旧技术。在深度学习出现之前，它在机器学习中常用于应对维度灾难，因为它能够减少数据集中的特征数量。它也在机器学习以外有许多其他用途。

假设我们有一个只有两个特征的数据集——例如，鸢尾花数据集的前两个特征。这些特征的散点图将展示样本在二维空间中的分布。[图 5-5](ch05.xhtml#ch5fig5)展示了鸢尾花数据集前两个特征的散点图，涵盖类别1和2。该图通过减去每个特征的均值，将原点移至(0,0)。这不会改变数据的方差或散布，只是改变了原点位置。

[图 5-5](ch05.xhtml#ch5fig5)中的图表还显示了两条箭头。这是数据的两个主成分。由于数据是二维的，所以我们有两个成分。如果我们有100个特征，那么我们最多会有100个主成分。这就是PCA的作用：它告诉你数据方差的方向。这些方向就是*主成分*。

![image](Images/05fig05.jpg)

*图 5-5：类别1和2的鸢尾花前两个特征及其主成分*

主成分还告诉你每个方向解释的数据方差的多少。在图中，箭头的长度对应于每个成分解释的总方差的比例。正如你所看到的，最大的成分沿着与数据点最大散布匹配的对角线方向。传统的机器学习使用PCA来减少特征数量，同时仍希望能够很好地表示数据集。这就是PCA如何帮助解决维度灾难的问题：找到主成分，然后丢弃那些影响较小的成分。然而，对于数据增强，我们希望保留所有的成分。

生成[图 5-5](ch05.xhtml#ch5fig5)的代码在[清单 5-5](ch05.xhtml#ch5lis5)中。

import numpy as np

import matplotlib.pylab as plt

from sklearn import decomposition

❶ x = np.load("../data/iris/iris_features.npy")[:,:2]

y = np.load("../data/iris/iris_labels.npy")

idx = np.where(y != 0)

x = x[idx]

x[:,0] -= x[:,0].mean()

x[:,1] -= x[:,1].mean()

❷ pca = decomposition.PCA(n_components=2)

pca.fit(x)

v = pca.explained_variance_ratio_

❸ plt.scatter(x[:,0],x[:,1],marker='o',color='b')

ax = plt.axes()

x0 = v[0]*pca.components_[0,0]

y0 = v[0]*pca.components_[0,1]

ax.arrow(0, 0, x0, y0, head_width=0.05, head_length=0.1, fc='r', ec='r')

x1 = v[1]*pca.components_[1,0]

y1 = v[1]*pca.components_[1,1]

ax.arrow(0, 0, x1, y1, head_width=0.05, head_length=0.1, fc='r', ec='r')

plt.xlabel("$x_0$", fontsize=16)

plt.ylabel("$x_1$", fontsize=16)

plt.show()

*示例5-5：鸢尾花PCA图*

上述代码的大部分是为了生成图表❸。导入部分是标准的，唯一不同的是新增了一个来自sklearn的`decomposition`模块。我们加载了之前保存的鸢尾花数据集，只保留x中的前两个特征以及y中的标签。然后，我们通过排除类别0，只保留类别1和类别2的特征。接下来，我们减去每个特征的均值，使数据围绕点(0,0)居中❶。

然后我们创建PCA对象并将鸢尾花数据拟合到该对象上❷。有两个特征，因此此时的主成分数目也是两个。PCA Python类模仿了sklearn的标准方法：首先定义模型，然后将数据拟合到模型上。一旦完成，我们就可以通过`components_`成员变量访问到存储在pca中的主成分。我们将v设置为一个向量，表示数据中由每个主成分方向解释的方差比例。由于有两个主成分，这个向量也有两个分量。

主成分总是按降序排列，因此第一个主成分是描述大部分方差的方向，第二个主成分是下一个最重要的方向，依此类推。在这个例子中，第一个主成分描述了大约84%的方差，第二个主成分描述了剩余的16%。我们将在生成新的增强样本时使用这种排序。这里，我们使用方差比例来缩放图中表示主成分方向及其相对重要性的箭头长度。

[图5-5](ch05.xhtml#ch5fig5)如何用于数据增强？一旦你知道了主成分，就可以使用PCA创建派生变量，这意味着你将数据旋转，使其与主成分对齐。PCA类的`transform`方法通过将输入（在我们这个例子中是原始数据）映射到一个新的表示形式来完成这一步，使得方差与主成分对齐。这个映射是精确的，你可以使用`inverse_transform`方法将其反转。

仅仅这样做并不会为我们生成新样本。如果我们将原始数据x转化为新的表示形式，然后再进行逆变换，我们最终会回到原点，得到x。但如果我们先转换x，然后在调用逆变换之前，*修改*一些主成分，我们将得到一组新的样本，这些样本不是x，但基于x。这正是我们所需要的数据增强。接下来，我们将看到修改哪些组件以及如何修改。

pca中的组件按其重要性排序。我们希望保持最重要的组件不变，因为我们希望逆变换能产生与原始数据相似的数据。我们不希望对数据进行过多的变换，否则新样本将不再是我们所声称的类别的合理实例。我们可以任意地设定，保留那些累计表示数据方差约90%到95%的组件，这些组件我们将完全不做修改。剩余的组件将通过添加正态分布的噪声进行修改。回想一下，*正态分布*意味着数据遵循钟形曲线，大部分时间值会接近中间值，我们将中间值设为0，表示对该组件不做改变，只有极少数情况下才会有较大的值。我们将把噪声添加到现有的组件中，并调用逆变换来生成非常相似但不完全相同的新样本。

前一段内容相当复杂，代码将使理解变得更加容易。我们生成增强数据的方法在[示例 5-6](ch05.xhtml#ch5lis6)中展示。

import numpy as np

from sklearn import decomposition

❶ def generateData(pca, x, start):

original = pca.components_.copy()

ncomp = pca.components_.shape[0]

a = pca.transform(x)

for i in range(start, ncomp):

pca.components_[i,:] += np.random.normal(scale=0.1, size=ncomp)

b = pca.inverse_transform(a)

pca.components_ = original.copy()

return b

def main():

❷ x = np.load("../../../data/iris/iris_features.npy")

y = np.load("../../../data/iris/iris_labels.npy")

N = 120

x_train = x[:N]

y_train = y[:N]

x_test = x[N:]

y_test = y[N:]

pca = decomposition.PCA(n_components=4)

pca.fit(x)

print(pca.explained_variance_ratio_)

start = 2

❸ nsets = 10

nsamp = x_train.shape[0]

newx = np.zeros((nsets*nsamp, x_train.shape[1]))

newy = np.zeros(nsets*nsamp, dtype="uint8")

❹ for i in range(nsets):

if (i == 0):

newx[0:nsamp,:] = x_train

newy[0:nsamp] = y_train

else:

newx[(i*nsamp):(i*nsamp+nsamp),:] =

generateData(pca, x_train, start)

newy[(i*nsamp):(i*nsamp+nsamp)] = y_train

❺ idx = np.argsort(np.random.random(nsets*nsamp))

newx = newx[idx]

newy = newy[idx]

np.save("iris_train_features_augmented.npy", newx)

np.save("iris_train_labels_augmented.npy", newy)

np.save("iris_test_features_augmented.npy", x_test)

np.save("iris_test_labels_augmented.npy", y_test)

main()

*示例 5-6：使用PCA增强鸢尾花数据。请参见* iris_data_augmentation.py。

主函数❷加载现有的鸢尾花数据x和对应的标签y，然后调用PCA，这次使用数据集的所有四个特征。这样，我们就得到了四个主成分，告诉我们每个成分解释了方差的多少：

0.92461621 0.05301557 0.01718514 0.00518309

前两个主成分描述了97%以上的方差。因此，我们将保持前两个组件不变，即索引0和1，当我们要生成新样本时，从索引2开始。

接下来，我们声明将要定义的集合数❸。这里的*集合*指的是一组新的样本集合。由于这些样本基于原始数据x，其中有150个样本，因此每个新集合也会包含150个样本。事实上，它们将与原始样本顺序相同，因此这些新样本的类别标签与y中的类别标签顺序一致。我们也不想丢失原始数据，因此nsets=10将原始数据和基于原始数据生成的九个新样本集合—总共1,500个样本—放入新数据集中。我们获取x中的样本数量150，并定义数组来存放我们的新特征(newx)和关联的标签(newy)。

接下来，我们循环生成新的样本，每次生成一组150个样本❹。第一次循环只是将原始数据复制到输出数组中。后续的循环类似，适当更新输出数组的源和目标索引，但我们不再直接赋值给x，而是赋值为generateData的输出。当循环完成后，我们将整个数据集的顺序打乱并写入磁盘❺。

所有的魔法都在generateData❶中。我们传入PCA对象(pca)、原始数据(x)以及起始主成分索引(start)。我们将最后一个参数设置为2，以保持最重要的两个组件不变。我们保留实际组件的副本，以便在返回之前重置pca对象。然后我们定义ncomp，即主成分的数量，便于使用，并调用前向变换，将原始数据映射到主成分上。

循环通过添加一个从均值为0，标准差为0.1的正态曲线中抽取的随机值，更新两个最不重要的组件。为什么是0.1？没有特别的原因；如果标准差较小，则新样本会接近旧样本，而如果标准差较大，则新样本会更远，可能不再具有代表性。接下来，我们使用修改后的主成分调用逆变换，并恢复实际的组件。最后，我们返回新的样本集。

让我们看一下新的数据集，如[图 5-6](ch05.xhtml#ch5fig6)所示。大的灰色点来自我们原始的数据集，而较小的黑色点是增强后的样本。如我们所见，它们都靠近现有的样本，这是我们从仅修改最弱的主成分所预期的结果。由于我们将原始数据复制到了增强数据集中，因此每个大点的中心都有一个小点。

![image](Images/05fig06.jpg)

*图 5-6：原始鸢尾花数据集的前两个特征（大点）和由[清单 5-6](ch05.xhtml#ch5lis6)生成的增强特征（小点）*

如前所述，这种方法仅适用于连续特征，且你应该小心只修改最弱的主成分，并且仅修改一个小量。这里的实验非常重要。作为练习，尝试将相同的技术应用于增强乳腺癌数据集，它也由连续特征组成。

#### 增强 CIFAR-10 数据集

增强鸢尾花数据集涉及了很多讨论和一些不太明显的数学运算。幸运的是，增强图像通常要简单得多，但在训练现代模型时仍然同样有效。当我们构建卷积神经网络模型（[第12章](ch12.xhtml#ch12)）时，我们将看到如何在训练时动态进行增强，这是一种特别有用的方法，但现在我们先进行增强，并通过现有图像的额外版本构建一个新的数据集。

[图 5-4](ch05.xhtml#ch5fig4)显示了CIFAR-10数据集中每个类别的代表性图像。这些是存储为RGB数据的彩色图像，分别表示红色、绿色和蓝色通道。它们是从地面拍摄的，因此上下翻转在这里没有意义，而左右翻转是可以的。平移——将图像在 *x* 或 *y* 方向上，或同时在两个方向上移动——是一种常见的技术。小角度旋转是另一种常见技术。

然而，每个问题都提出了一个问题：在位移或旋转后，对于没有数据的像素该怎么办？如果我将图像向左移动 3 个像素，我需要用某些东西填充右侧的三列。或者，如果我向右旋转，就会有右上角和左下角的像素需要填充。有几种方法可以处理这种情况。一种方法是简单地将这些像素保持为黑色，或全 0 值，并让模型学习这些地方没有有用的信息。另一种方法是将像素替换为图像的均值，这也不会提供任何信息，我们希望模型能忽略它。然而，最流行的解决方案是裁剪图像。

这张图片是32×32像素。比如，从图像中提取一个28×28像素的随机补丁，相当于将图像沿* x * 或 * y * 方向随机移动最多4个像素，而不需要担心填充问题。如果我们首先旋转图像（需要对像素进行插值），然后裁剪去除边缘区域，我们也不需要担心有空白像素。Keras 提供了一个用于训练时的图像生成器对象来实现这一过程。当我们使用 Keras 构建模型时，会使用到这个工具，但目前我们自己动手做所有工作，以便理解这个过程。

我们需要在这里提到一点。到目前为止，我们讨论了如何构建用于训练模型的数据集。那么，当我们想要使用模型时应该怎么办呢？我们是否也将随机裁剪的测试输入交给模型？不是。相反，我们将一个以图像为中心的裁剪交给模型。因此，对于 CIFAR-10，我们会将每个 32 × 32 的测试输入裁剪成 28 × 28，去掉外部的 6 个像素，然后将其提供给模型。我们这样做是因为中心裁剪仍然代表实际的测试图像，而不是某个增强版本的图像。

[图 5-7](ch05.xhtml#ch5fig7)展示了我们所说的旋转、翻转、训练时的随机裁剪和测试时的中心裁剪。在（a）中，我们旋转图像并进行中心裁剪。输出图像位于白色方框中。在（b）中，我们进行左右翻转并随机裁剪。在（c）中，我们进行两次随机裁剪，但不进行翻转，而在（d）中，我们进行测试时的中心裁剪，不进行旋转或翻转。有些人会增强测试图像，但我们这里不会这么做。

![image](Images/05fig07.jpg)

*图 5-7：首先旋转，然后中心裁剪（a）。从左到右翻转，然后随机裁剪（b）。训练时的两个随机裁剪（c）。测试时的中心裁剪，无旋转或翻转（d）。*

[清单 5-7](ch05.xhtml#ch5lis7)展示了如何通过随机裁剪、旋转和翻转来增强 CIFAR-10 训练集。

import numpy as np

from PIL import Image

❶ def augment(im, dim):

img = Image.fromarray(im)

if (np.random.random() < 0.5):

img = img.transpose(Image.FLIP_LEFT_RIGHT)

if (np.random.random() < 0.3333):

z = (32-维度)/2

r = 10*np.random.random()-5

img = img.rotate(r, resample=Image.BILINEAR)

img = img.crop((z,z,32-z,32-z))

else:

x = int((32-维度-1)*np.random.random())

y = int((32-维度-1)*np.random.random())

img = img.crop((x,y,x+dim,y+dim))

return np.array(img)

def main():

❷ x = np.load("../data/cifar10/cifar10_train_images.npy")

y = np.load("../data/cifar10/cifar10_train_labels.npy")

factor = 10

dim = 28

z = (32-维度)/2

newx = np.zeros((x.shape[0]*factor, dim,dim,3), dtype="uint8")

newy = np.zeros(y.shape[0]*factor, dtype="uint8")

k=0

❸ for i in range(x.shape[0]):

im = Image.fromarray(x[i,:])

im = im.crop((z,z,32-z,32-z))

newx[k,...] = np.array(im)

newy[k] = y[i]

k += 1

for j in range(factor-1):

newx[k,...] = augment(x[i,:], dim)

newy[k] = y[i]

k += 1

idx = np.argsort(np.random.random(newx.shape[0]))

newx = newx[idx]

newy = newy[idx]

np.save("../data/cifar10/cifar10_aug_train_images.npy", newx)

np.save("../data/cifar10/cifar10_aug_train_labels.npy", newy)

❹ x = np.load("../data/cifar10/cifar10_test_images.npy")

newx = np.zeros((x.shape[0], dim,dim,3), dtype="uint8")

for i in range(x.shape[0]):

im = Image.fromarray(x[i,:])

im = im.crop((z,z,32-z,32-z))

newx[i,...] = np.array(im)

np.save("../data/cifar10/cifar10_aug_test_images.npy", newx)

*Listing 5-7: 增强CIFAR-10数据集。请参见* cifar10_augment.py。

主函数加载现有数据集，并定义我们的增强因子、裁剪大小和用于定义中心裁剪的常量❷。

新的图像将放入newx中，其维度为：(500,000;28;28;3)；共有50,000张训练图像，每张图像为32×32像素，并且有三个颜色通道。我们将增强因子设置为10。同样，也会有500,000个标签。计数器k将索引到这个新数据集中。对于旧数据集中的每一张图像，我们将创建九个全新的版本，并对原始图像进行中心裁剪❶❸。

由于数据集由图像组成，最方便的方式是以图像的形式处理数据，因此我们将当前样本转换为实际的PIL图像，以便于裁剪。这是原始图像的中心裁剪。我们将其存储在新的输出数组中。

这里有两个Python惯用法，我们会多次看到。第一个是将表示图像的NumPy数组转换为PIL图像：

im = Image.fromarray(arr)

第二种方法是将PIL图像转换为NumPy数组：

arr = np.array(im)

我们必须确保NumPy数组是有效的图像数据类型，比如无符号字节（uint8）。使用astype NumPy数组方法在类型之间转换时，要记得你需要完全理解这种转换的含义。

回顾[Listing 5-7](ch05.xhtml#ch5lis7)，我们正在创建当前图像的九个版本。对于每一个版本，我们只需复制标签，并将增强版本分配给输出数组。稍后我们会详细描述augment函数。新数据集构建完成后，我们将打乱顺序并将增强后的训练数据集写入磁盘❸。

然而，我们还没有完全完成。我们创建了一个增强的训练集，将原始的32 × 32图像裁剪为28 × 28。因此，我们必须至少裁剪原始的测试集❹。如前所述，我们使用中心裁剪，并且不对测试数据进行增强。因此，我们只需加载测试数据集，定义新的输出测试数据集，并运行一个循环，将32 × 32的图像裁剪为28 × 28。完成后，我们将裁剪后的测试数据写入磁盘。注意，我们没有修改测试集中图像的*顺序*；我们只是裁剪了它们，因此不需要为测试标签写入新文件。

augment函数❶是所有操作的核心。我们立即将输入的NumPy数组转换为一个实际的PIL图像对象。接下来，我们以50%的概率决定是否左右翻转图像。请注意，我们暂时不对图像进行裁剪。

接下来，我们要判断是否旋转图像。我们以33%的概率（1/3的机会）选择旋转。为什么是33%？没有特别的原因，不过看起来我们可能更倾向于随机裁剪，而不是旋转。我们甚至可以将这个概率降低到20%（1/5的机会）。如果进行旋转，我们选择旋转角度，[*–*5,5]，然后使用双线性插值方法调用旋转函数，以使旋转后的图像比简单的使用最近邻插值（PIL默认方式）看起来更好。接下来，我们对旋转后的图像进行中心裁剪。这样，我们就不会在旋转过程中没有图像信息的边缘区域看到黑色像素。

如果不进行旋转，我们可以自由选择一个随机裁剪。我们选择这个随机裁剪的左上角，确保裁剪后的正方形不会超出原始图像的尺寸。最后，我们将数据转换回NumPy数组并返回。

### 总结

在本章中，我们构建了四个数据集，将在接下来的章节中作为示例使用。前两个，鸢尾花数据集（irises）和乳腺癌组织学数据集（breast cancer histology），基于特征向量。最后两个，MNIST和CIFAR-10，表示为图像。然后我们学习了两种数据增强方法：使用PCA增强连续值的特征向量，以及对深度学习更为关键的，通过基本变换增强图像。

在下一章，我们将过渡到经典机器学习模型的讨论。在接下来的章节中，我们将使用这些数据集与这些模型进行结合。

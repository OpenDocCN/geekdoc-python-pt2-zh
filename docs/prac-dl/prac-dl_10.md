## **10

神经网络实验**

![image](Images/common.jpg)

在[第9章](ch09.xhtml#ch09)中，我们讨论了神经网络背后的理论。在本章中，我们将用代码代替方程，运行一系列实验，旨在增加我们对神经网络基本参数的直觉：架构和激活函数、批量大小、基础学习率、训练集大小、L2 正则化、动量、权重初始化、特征排序以及权重和偏差的精度。

为了节省空间并消除繁琐的重复，我们不会展示每个实验的具体代码。在大多数情况下，代码与前一个示例仅有微小的不同；我们通常只会改变 MLPClassifier 构造函数中的特定参数。每个实验的代码包含在本书相关的文件集中，我们会列出网络参数和文件名。必要时，我们会提供代码来阐明特定的方法。我们将展示第一个实验的完整代码。

### 我们的数据集

我们将使用 MNIST 数据集的向量形式，该数据集在[第5章](ch05.xhtml#ch05)中已构建。回想一下，该数据集包含 28×28 像素的 8 位灰度手写数字图像，[0,9]。在向量形式中，每个 28 × 28 的图像被展开成一个 28 × 28 = 784 个元素的向量，所有元素都是字节（[0,255]）。展开过程将每一行连接在一起。因此，每个样本有 784 个元素，并且有一个关联标签。训练集包含 60,000 个样本，而测试集有 10,000 个样本。在我们的实验中，我们不会使用训练集中的所有数据。这样做是为了帮助说明网络参数的影响，并保持合理的训练时间。请参考[图5-3](ch05.xhtml#ch5fig3)了解代表性的 MNIST 手写数字。

### MLPClassifier 类

MLPClassifier 类遵循与其他 sklearn 分类器相同的格式。它有一个构造函数和预期的方法：fit 用于训练，score 用于将分类器应用于测试数据，predict 用于对未知输入进行预测。我们还将使用 predict_proba 来返回每个类别的实际预测概率。构造函数有许多选项：

MLPClassifier(hidden_layer_sizes=(100, ), activation='relu',

solver='adam', alpha=0.0001, batch_size='auto',

learning_rate='constant', learning_rate_init=0.001,

power_t=0.5, max_iter=200, shuffle=True,

random_state=None, tol=0.0001, verbose=False,

warm_start=False, momentum=0.9, nesterovs_momentum=True,

early_stopping=False, validation_fraction=0.1, beta_1=0.9,

beta_2=0.999, epsilon=1e-08)

在这里，我们提供了每个参数的默认值。有关每个参数的完整描述，请参阅 sklearn 文档页面 [http://scikit-learn.org/](http://scikit-learn.org/)。我们将设置其中一些为特定值，其他一些将在实验中进行更改，还有一些仅在特定情况下才相关。我们将使用的关键参数在[表 10-1](ch10.xhtml#ch10tab1)中。

以下一组实验探讨了不同 MLPClassifier 参数的影响。如前所述，我们将展示第一次实验中使用的所有代码，理解只需进行小的更改即可执行其他实验。有时，我们将展示一些代码片段，以使更改具体化。

**表 10-1：** 重要的 MLPClassifier 构造函数关键字及其默认值

| **关键字** | **描述** |
| --- | --- |
| hidden_layer_sizes | 给出隐藏层大小的元组 |
| activation | 激活函数类型；例如，ReLU |
| alpha | L2 参数——我们称之为 *λ*（lambda） |
| batch_size | 小批量大小 |
| learning_rate_init | 学习率，*η*（eta） |
| max_iter | 训练周期数 |
| warm_start | 继续训练或重新开始 |
| momentum | 动量 |
| solver | 求解算法（"sgd"） |
| nesterovs_momentum | 使用 Nesterov 动量（False） |
| early_stopping | 使用提前停止（False） |
| learning_rate | 学习率调度（"constant"） |
| tol | 如果损失变化 < tol (1e-8)，则提前停止 |
| verbose | 训练时输出到控制台（False） |

### 架构和激活函数

在设计神经网络时，我们立刻会面临两个根本性问题：什么架构和什么激活函数？这无疑是决定模型成功的最重要因素。让我们探讨当我们使用不同的架构和激活函数训练模型，同时保持训练数据集不变时会发生什么。

#### 代码

如承诺的那样，对于第一次实验，我们将展示完整的代码，从[清单 10-1](ch10.xhtml#ch10lis1)中的辅助函数开始。

import numpy as np

import time

from sklearn.neural_network import MLPClassifier

def run(x_train, y_train, x_test, y_test, clf):

s = time.time()

(*\pagebreak*)

clf.fit(x_train, y_train)

e = time.time()-s

loss = clf.loss_

weights = clf.coefs_

biases = clf.intercepts_

params = 0

for w in weights:

params += w.shape[0]*w.shape[1]

for b in biases:

params += b.shape[0]

return [clf.score(x_test, y_test), loss, params, e]

def nn(layers, act):

return MLPClassifier(solver="sgd", verbose=False, tol=1e-8,

nesterovs_momentum=False, early_stopping=False,

learning_rate_init=0.001, momentum=0.9, max_iter=200,

hidden_layer_sizes=layers, activation=act)

*清单 10-1：用于实验架构和激活函数的辅助函数。参见* mnist_nn_experiments.py。

[清单 10-1](ch10.xhtml#ch10lis1)导入了常用的模块，然后定义了两个辅助函数，run和nn。从nn开始，我们看到它所做的只是返回一个使用隐藏层大小和给定激活函数类型的MLPClassifier实例。

隐藏层的大小是以元组的形式给出的，每个元素是相应层中节点的数量。请记住，sklearn只支持全连接层，因此一个数字就足够指定层的大小。用于训练的输入样本决定了输入层的大小。这里，输入样本是表示数字图像的向量，因此输入层有28 × 28 = 784个节点。

那么输出层呢？它没有明确指定，因为它依赖于训练标签中的类别数量。MNIST数据集有10个类别，因此输出层将有10个节点。当调用predict_proba方法获取输出概率时，sklearn会对这10个输出应用softmax。如果模型是二分类的，即只有0和1这两个类别标签，那么只有一个输出节点，一个逻辑（sigmoid）节点，表示属于类别1的概率。

现在让我们看看我们传递给MLPClassifier的参数。首先，我们明确表示希望使用SGD求解器。求解器是用于在训练过程中修改权重和偏差的方法。所有的求解器都使用反向传播来计算梯度；我们如何使用这些梯度是不同的。普通的SGD目前对我们来说已经足够了。

接下来，我们设置了较低的容忍度，以便训练所请求的纪元数（max_iter）。我们还关闭了Nesterov动量（标准动量的变种）和提前停止（通常有用，但在这里不需要）。

初始学习率设置为默认值0.001，标准动量值为0.9。纪元数（epochs）被任意设置为200（默认值），但我们将在随后的实验中进一步探索这一点。请随时保持好奇心，看看更改这些值会对结果产生什么影响。为了保持一致性，除非我们要实验的参数，否则我们将在整个过程中使用这些默认值。

[清单 10-1](ch10.xhtml#ch10lis1)中的另一个辅助函数是run。这个函数将使用标准的sklearn fit和score方法来训练和测试传入的分类器对象。它还做了一些我们之前没有见过的事情。

特别地，在计时训练所需时间之后，我们从 MLPClassifier 对象中提取最终的训练损失值、网络权重和网络偏置，以便我们可以返回它们。MLPClassifier 类最小化我们在[第9章](ch09.xhtml#ch09)中描述的对数损失（log-loss）。我们将对数损失存储在 loss_ 成员变量中。这个值的大小，以及它在训练过程中如何变化，可以帮助我们判断网络的学习效果。一般来说，对数损失越小，网络表现越好。随着你对神经网络的了解越来越深入，你会开始对什么是好的损失值以及训练过程是否快速学习有直觉，通过损失值变化的速度来判断。

权重和偏置存储在 coefs_ 和 intercepts_ 成员变量中。这些分别是 NumPy 矩阵（权重）和向量（偏置）的列表。这里我们使用它们通过求和每个矩阵和向量中的元素数量来计算网络中的参数总数。这就是运行函数中的两个小循环的作用。最后，我们将所有这些信息，包括对测试集的评分，返回给主函数。主函数见[Listing 10-2](ch10.xhtml#ch10lis2)。

def main():

x_train = np.load("mnist_train_vectors.npy").astype("float64")/256.0

y_train = np.load("mnist_train_labels.npy")

x_test = np.load("mnist_test_vectors.npy").astype("float64")/256.0

y_test = np.load("mnist_test_labels.npy")

N = 1000

x_train = x_train[:N]

y_train = y_train[:N]

x_test = x_test[:N]

y_test = y_test[:N]

layers = [

(1,)、(500,)、(800,)、(1000,)、(2000,)、(3000,),

(1000,500), (3000,1500),

(2,2,2), (1000,500,250), (2000,1000,500),

]

for act in ["relu", "logistic", "tanh"]:

print("%s:" % act)

for layer in layers:

scores = []

loss = []

tm = []

for i in range(10):

s,l,params,e = run(x_train, y_train, x_test, y_test,

nn(layer, act))

scores.append(s)

loss.append(l)

tm.append(e)

s = np.array(scores)

l = np.array(loss)

t = np.array(tm)

n = np.sqrt(s.shape[0])

print("    layers: %14s, score= %0.4f +/- %0.4f,

loss = %0.4f +/- %0.4f (params = %6d, time = %0.2f s)" % \

(str(layer), s.mean(), s.std()/n, l.mean(),

l.std()/n, params, t.mean()))

*Listing 10-2：用于实验架构和激活函数的主函数。请参见* mnist_nn_experiments.py。

我们首先加载存储在 x_train（样本）和 y_train（标签）、x_test 和 y_test 中的 MNIST 训练和测试数据。注意，我们将样本除以 256.0，使其变为[0,1)范围内的浮点数。这个归一化是本章唯一的预处理操作。

由于完整的训练集有60,000个样本，而我们希望运行多个训练会话，因此我们只使用前1,000个样本进行训练。我们也会保留前1,000个测试样本。本章的目标是观察在改变参数时的相对差异，而不是构建最优模型，因此我们会牺牲模型质量，以便在合理的时间框架内获得结果。使用1,000个训练样本时，平均每种数字类型只有100个实例。我们将在特定实验中调整训练样本数量。

layers列表包含了我们将要探索的不同架构。最终，我们将这些值传递给MLPClassifier构造函数的hidden_layer_sizes参数。请注意，我们将检查从单一隐藏层和单个节点到三个隐藏层，每层最多2,000个节点的架构。

主循环遍历了三种激活函数类型：整流线性单元、逻辑（sigmoid）单元和双曲正切函数。我们将为每种激活函数类型和架构（层数）的组合训练一个模型。此外，由于我们知道神经网络训练是随机的，我们将为每种组合训练10个模型，并报告平均值和标准误差，以避免因为某个不具代表性的糟糕模型而影响结果。

**注意** *当你运行以下实验中的代码时，可能会生成类似以下的sklearn警告信息：*

ConvergenceWarning: 随机优化器：已达到最大迭代次数（200）

并且优化尚未收敛。

*这些信息是sklearn告诉你，在sklearn认为网络已经收敛到一组良好的权重之前，训练迭代次数已经完成。这些警告是可以安全忽略的，且可以通过在命令行中添加-W ignore来完全禁用，示例命令为：*

$ python3 -W ignore mnist_nn_experiments.py

#### 结果

运行此代码需要几个小时才能完成，并且输出的内容中有类似如下的行：

layers:(3000,1500), score=0.8822+/-0.0007, loss=0.2107+/-0.0006

(params=6871510, time=253.42s)

这告诉我们，使用ReLU激活函数和一个包含两个隐藏层（分别有3,000个和1,500个节点）的架构时，模型的平均得分为88.2%，平均最终训练损失为0.21（记住，越低越好）。它还告诉我们，神经网络总共有近690万个参数，平均训练时间稍超过四分钟。

[表 10-2](ch10.xhtml#ch10tab2)总结了不同网络架构和激活函数类型的得分。

**表 10-2：** 基于架构和激活函数类型的MNIST测试集平均得分（均值 ± 标准误差）

| 架构 | ReLU | Tanh | 逻辑（sigmoid） |
| --- | --- | --- | --- |
| 1 | 0.2066 ± 0.0046 | 0.2192 ± 0.0047 | 0.1718 ± 0.0118 |
| 500 | 0.8616 ± 0.0014 | 0.8576 ± 0.0011 | 0.6645 ± 0.0029 |
| 800 | 0.8669 ± 0.0014 | 0.8612 ± 0.0011 | 0.6841 ± 0.0030 |
| 1000 | 0.8670 ± 0.001 | 0.8592 ± 0.0014 | 0.6874 ± 0.0028 |
| 2000 | 0.8682 ± 0.0008 | 0.8630 ± 0.0012 | 0.7092 ± 0.0029 |
| 3000 | 0.8691 ± 0.0005 | 0.8652 ± 0.0011 | 0.7088 ± 0.0024 |
| 1000; 500 | 0.8779 ± 0.0011 | 0.8720 ± 0.0011 | 0.1184 ± 0.0033 |
| 3000; 1500 | 0.8822 ± 0.0007 | 0.8758 ± 0.0009 | 0.1221 ± 0.0001 |
| 1000; 500; 250 | 0.8829 ± 0.0011 | 0.8746 ± 0.0012 | 0.1220 ± 0.0000 |
| 2000; 1000; 500 | 0.8850 ± 0.0007 | 0.8771 ± 0.0010 | 0.1220 ± 0.0000 |

在每种情况下，我们展示了在减少后的测试集上，经过10个训练模型的平均得分（加减标准误差）。这个表格包含了大量的信息，因此让我们仔细查看一下。

如果我们看看激活类型，就会立刻发现有些不对劲。逻辑回归激活函数的结果显示，随着单一隐藏层的增大，得分有所提升，这似乎是可以预期的，但当我们使用超过一个隐藏层时，网络无法训练。我们知道它无法训练，因为测试集上的得分很差。如果你检查输出，你会发现损失值没有下降。如果在训练过程中损失值没有减少，那就说明出问题了。

目前还不清楚为什么逻辑回归激活函数的训练会失败。一种可能性是sklearn中的bug，但考虑到这个工具包的广泛使用，这种可能性较小。最可能的原因与网络初始化有关。sklearn工具包使用我们在[第8章](ch08.xhtml#ch08)中讨论的标准、常用初始化方案。但这些方案是为ReLU和tanh激活函数量身定制的，可能在逻辑回归情况下表现不好。

对于我们的目的来说，我们可以将这一失败视为一个显著的标志，表明逻辑回归激活函数并不是一个适合用于隐藏层的好选择。遗憾的是，这正是神经网络早期历史中广泛使用的激活函数，因此我们一开始就在自作自受。难怪神经网络花了这么长时间才最终找到它们的合适位置！从现在起，我们将忽略逻辑回归激活函数的结果。

再次考虑单层隐藏层网络的得分（参见[表 10-2](ch10.xhtml#ch10tab2)，第1–6行）。对于ReLU和tanh激活函数，我们看到网络性能稳步提升。此外，请注意，在每种情况下，ReLU激活函数在隐藏层节点数相同的情况下稍微优于tanh，尽管这些差异可能由于每种架构只有10个模型而不具有统计显著性。不过，这符合社区中普遍的观察：ReLU优于tanh。

如果我们查看[表10-2](ch10.xhtml#ch10tab2)的其余行，我们可以看到，增加第二层甚至第三层隐藏层继续提高测试分数，但回报递减。这也是一个广泛经验到的现象，我们应该更仔细地观察。特别是，我们应该考虑[表10-2](ch10.xhtml#ch10tab2)中模型的参数数量。这样比较就有点不公平。如果我们改为训练具有接近相同参数数量的模型，那么我们就可以更公平地比较模型的性能。我们看到的任何性能差异都可以合理地归因于使用的层数，因为模型的总参数数量几乎是相同的。

通过修改[清单10-2](ch10.xhtml#ch10lis2)中的层数组，我们可以训练[表10-3](ch10.xhtml#ch10tab3)中所示架构的多个版本。每层的节点数是根据模型中的总参数数量来选择的。

**表10-3：** 用于生成[图10-1](ch10.xhtml#ch10fig1)的模型架构测试

| 架构 | 参数数量 |
| --- | --- |
| 1000 | 795,010 |
| 2000 | 1,590,010 |
| 4000 | 3,180,010 |
| 8000 | 6,360,010 |
| 700; 350 | 798,360 |
| 1150; 575 | 1,570,335 |
| 1850; 925 | 3,173,685 |
| 2850; 1425 | 6,314,185 |
| 660; 330; 165 | 792,505 |
| 1080; 540; 270 | 1,580,320 |
| 1714; 857; 429 | 3,187,627 |
| 2620; 1310; 655 | 6,355,475 |

[表10-3](ch10.xhtml#ch10tab3)中的魔法数字是从哪里来的？我们首先选择了要测试的单层大小。然后，我们确定了具有这些架构的模型中的参数数量。接下来，我们使用[第8章](ch08.xhtml#ch08)中的经验法则设计了两层架构，以便这些模型中的参数数量接近于单层模型中的相应参数数量。最后，我们对三层模型重复了这个过程。通过这种方式，我们可以在非常相似的参数数量下比较模型的性能。从本质上讲，我们固定了模型中的参数数量，仅改变它们之间的交互方式。

按照我们在[清单10-2](ch10.xhtml#ch10lis2)中所做的方式训练模型，但这次我们平均了25个模型而不是仅仅10个，这给我们带来了[图10-1](ch10.xhtml#ch10fig1)。

![image](Images/10fig01.jpg)

*图10-1：不同架构的[表10-3](ch10.xhtml#ch10tab3)在MNIST测试集上的得分（均值 ± E），作为网络中参数数量的函数*

让我们解析一下[图10-1](ch10.xhtml#ch10fig1)。首先，注意x轴，即模型中的参数数量，是以百万为单位的。其次，我们可以比较三条垂直的线，因为这些模型的参数数量相似。图例告诉我们哪条图表示具有一个、两个或三个隐藏层的模型。

看左侧的点，代表每种情况下最小的模型，我们看到从单层到双层的转换会带来模型性能的跃升。而从双层到三层则带来了另一个较小的提升。对于从左到右的所有层数变化，这种趋势一直在重复。稍后我们会讨论单层和双层架构中最大模型之间性能下降的原因。保持参数数量不变，但增加网络的深度（层数），会带来更好的性能。我们可能会在这里忍不住说，“深度更重要，宽度不重要”，但在某些情况下，这样的做法可能并不奏效。不过，值得记住的是：更多的层可以带来帮助，而不仅仅是更宽的层和更多的节点。

那么，单层和双层情况下，最大模型的性能下降又是怎么回事呢？这些点是 [图 10-1](ch10.xhtml#ch10fig1) 的最右侧点。回想一下，绘制这个图的模型仅使用了 1000 个样本进行训练。对于最大的模型，可能没有足够的数据来充分训练这样一个宽大的模型。如果我们增加训练样本的数量（因为我们有 60,000 个 MNIST 样本可以选择），也许会看到性能下降消失。这个问题留给读者自己去探讨。

### 批量大小

现在让我们关注一下批量大小对训练的影响。记住，这里的 *batch size* 是指小批量的大小，它是从完整训练集中选出的一个子集，用于前向传播中计算该小批量的平均损失。基于这个损失，我们通过反向传播来更新权重和偏差。因此，处理单个小批量将导致一个梯度下降步骤——即网络参数的单次更新。

我们将使用 MNIST 的一个固定大小子集进行训练，训练一定数量的轮次，并使用不同的小批量大小，以查看这对最终测试得分的影响。在此之前，我们需要了解 sklearn 如何使用小批量和轮次来训练神经网络。

我们简要看一下实际的 sklearn 源代码，MLPClassifier 类中的 _fit_stochastic 方法，代码可以在 [https://github.com/scikit-learn/scikit-learn/blob/7389dba/sklearn/neural_network/multilayer_perceptron.py](https://github.com/scikit-learn/scikit-learn/blob/7389dba/sklearn/neural_network/multilayer_perceptron.py) 找到。了解这个方法是内部方法，并且可能会随版本更新而变化，我们看到的代码如下所示：

for it in range(self.max_iter):

X, y = shuffle(X, y, random_state=self._random_state)

accumulated_loss = 0.0

for batch_slice in gen_batches(n_samples, batch_size):

activations[0] = X[batch_slice]

batch_loss, coef_grads, intercept_grads = self._backprop(

X[batch_slice], y[batch_slice], activations, deltas,

coef_grads, intercept_grads)

accumulated_loss += batch_loss * (batch_slice.stop -

batch_slice.start)

grads = coef_grads + intercept_grads

self._optimizer.update_params(grads)

self.n_iter_ += 1

有两个 for 循环，第一个是针对 epoch 的数量（max_iter），第二个是针对训练数据中存在的小批量数量。gen_batches 函数从训练集中返回小批量。实际上，它返回的是切片索引，X[batch_slice] 返回实际的训练样本，但效果是一样的。对 _backprop 和 update_params 的调用完成了当前小批量的梯度下降步骤。  

一个 *epoch* 是训练集中小批量的完整遍历。小批量本身是训练数据的分组，循环遍历小批量时，训练集中的所有样本都会被使用一次。如果训练样本的数量不是小批量大小的整数倍，最后一个小批量将比预期的小，但这不会在长远来看影响训练。

我们可以像在 [图 10-2](ch10.xhtml#ch10fig2) 中那样直观地查看这个关系，其中我们可以看到一个 epoch 是如何由训练集中的小批量构建的。在 [图 10-2](ch10.xhtml#ch10fig2) 中，整个训练集被表示为包含 *n* 个样本的 epoch。一个小批量有 *m* 个样本，如图所示。最后一个小批量比其他的要小，表示 *n*/*m* 可能不是整数。  

![image](Images/10fig02.jpg)  

*图 10-2：Epoch（*n*）、mini-batch（*m*）和样本* {x[*0*],x[*1*], …,x[*n-1*]} 之间的关系*  

[图 10-2](ch10.xhtml#ch10fig2) 也暗示了训练集中的样本顺序是至关重要的，这就是我们在制作数据集时打乱它们的原因。如果需要，sklearn 工具包还会在每个训练轮次后重新排列样本。只要一个小批量在统计学上是从整个训练集中随机抽取的样本，训练应该没有问题。如果小批量不是随机抽样的，那么它可能会在反向传播时给出偏向的梯度方向。  

我们的 mini-batch 实验将把 MNIST 训练样本的数量固定为 16,384，同时变化小批量的大小。我们还将把 epoch 的数量固定为 100。我们报告的分数是五次不同运行同一模型的平均值和标准误差，每次运行使用不同的随机初始化。因此，MLPClassifier 对象通过以下方式实例化：  

MLPClassifier(solver="sgd", verbose=False, tol=1e-8,  

nesterovs_momentum=False, early_stopping=False,  

learning_rate_init=0.001, momentum=0.9, max_iter=100,  

hidden_layer_sizes=(1000,500), activation="relu",  

batch_size=bz)  

这段代码表示所有模型都有两个隐藏层，分别包含 1000 和 500 个节点，因此整个网络的架构是 784-1000-500-10（包括输入层和输出层的节点）。定义网络时唯一会变化的参数是 batch_size。我们将在 [表 10-4](ch10.xhtml#ch10tab4) 中使用的 batch size，并与每个 epoch 进行的梯度下降步骤数量一起使用（见 [图 10-2](ch10.xhtml#ch10fig2)）。  

**表10-4：** 小批量大小及对应的每周期梯度下降步数

| 小批量大小 | 每周期SGD步数 |
| --- | --- |
| 2 | 8,192 |
| 4 | 4,096 |
| 8 | 2,048 |
| 16 | 1,024 |
| 32 | 512 |
| 64 | 256 |
| 128 | 128 |
| 256 | 64 |
| 512 | 32 |
| 1,024 | 16 |
| 2,048 | 8 |
| 4,096 | 4 |
| 8,192 | 2 |
| 16,384 | 1 |

当小批量大小为2时，每个周期将进行超过8,000步梯度下降，但当小批量大小为8,192时，仅进行2步梯度下降。固定周期数应该有利于选择较小的小批量大小，因为这将对应更多的梯度下降步骤，意味着有更多的机会朝着最优的网络参数集前进。

[图10-3](ch10.xhtml#ch10fig3)绘制了小批量大小与均值得分的关系。生成该数据的代码在 *mnist_nn_experiments_batch_size.py* 文件中。绘图代码本身在 *mnist_nn_experiments_batch_size_plot.py* 中。此刻我们关心的曲线是使用圆形符号的那一条。稍后我们会解释方形符号曲线。

![image](Images/10fig03.jpg)

*图10-3：在固定周期数（100）下，无论小批量大小如何（圆形），或者固定小批量数量（方形），小批量大小与MNIST测试集平均得分（均值* ± *标准误差）的关系*

在这里，我们将周期数固定为100，因此通过变化小批量大小，我们会改变梯度下降步数：小批量越大，进行的梯度下降步数越*少*。由于小批量较大，步数本身基于实际梯度方向的更真实表现；然而，步数减少是因为每个周期的小批量较少，导致收敛性变差：我们未能达到损失函数的良好最小值。

更“公平”的测试可能是调整周期数，使得不管小批量大小如何，检查的小批量数量保持不变。实现这一点的一种方法是注意到每个周期内的小批量数量为 *n*/*m*，其中 *n* 是训练样本数，*m* 是小批量的数量。如果我们将希望运行的小批量总数称为 *M*，那么，为了保持它不变，我们需要将 *epochs* 设置为

![image](Images/235equ01.jpg)

这样，不管 *m* 如何，我们在训练过程中执行的总梯度下降步数将是 *M*。

我们保持相同的小批量集合，但根据前述公式调整训练周期数。我们需要选择 *M*，即小批量的总数（梯度下降步骤）。我们将其设置为 *M* = 8,192，这样每次的训练周期数就是整数。当小批量大小为2时，我们使用1个周期得到8,192个小批量。当小批量大小为16,384时（*n*仍然为16,384个样本），我们得到8,192个周期。如果我们这样做，就会得到完全不同的结果，如[图10-3](ch10.xhtml#ch10fig3)中的方形符号曲线，我们可以看到均值得分几乎是常数，代表训练过程中执行的恒定梯度下降更新次数。当小批量大小较小，对应于[图10-3](ch10.xhtml#ch10fig3)中接近0的点时，性能确实有所下降，但当小批量大小超过某个值后，性能趋于平稳，反映了训练期间恒定的梯度下降更新次数，以及通过使用足够大的小批量获得合理的真实梯度估计。

对于一组基础神经网络参数，特别是对于固定学习率的情况，固定训练周期数会因为sklearn的设计而导致性能下降。固定检查的小批量数则基本保持常量性能。

### 基础学习率

在[第9章](ch09.xhtml#ch09)中，我们介绍了更新神经网络权重的基本公式：

*w* ← *w* – *η*Δ*w*

这里的 *η*（eta）是学习率，它是控制步长大小的参数，基于梯度值 *Δw*。在sklearn中，*η*通过learning_rate_init参数指定。在训练过程中，学习率通常会逐渐减小，因此当我们接近训练的最小值时，步长会变得更小（希望如此！）。然而，在我们的实验中，我们使用的是一个常量学习率，因此无论我们将learning_rate_init设置为多少，这个值在整个训练过程中都会保持不变。让我们看看这个值是如何影响学习的。

在这个实验中，我们将小批量大小固定为64个样本，网络架构设置为（1000,500），即有两个隐藏层，分别包含1000和500个节点。接着，我们研究两个主要影响因素。第一个是当我们固定训练周期数时，不考虑基础学习率的影响。在这种情况下，我们在训练过程中始终进行固定次数的梯度下降步骤。第二种情况则固定基础学习率与训练周期数的乘积。这种情况很有趣，因为它考察了较少的大步长与更多的小步长对测试分数的影响。这些实验的代码在 *mnist_experiments_base_lr.py* 中。训练集是前20,000个MNIST样本。

第一个实验将训练周期数固定为50，并循环测试不同的基础学习率：

[0.2, 0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001]

第二个实验使用相同的基础学习率，但变化了轮次数量，使得在每种情况下基础学习率和轮次的乘积为1.5。这样就得到了以下与前述基础学习率相匹配的轮次数：

[8, 15, 30, 150, 300, 1500, 3000, 15000]

运行这两个实验需要一些时间。当它们完成时，我们可以将测试得分绘制为基础学习率大小的函数。这样做就得到了[图 10-4](ch10.xhtml#ch10fig4)。

![image](Images/10fig04.jpg)

*图 10-4：MNIST 测试得分与基础学习率的关系。圆圈代表固定轮次的情况。方块代表固定基础学习率和轮次乘积的情况。*

[图 10-4](ch10.xhtml#ch10fig4)展示了两个图。第一个图使用圆圈，固定了50个轮次。固定轮次就固定了训练过程中进行的梯度下降步数。然后我们改变学习率。学习率越大，我们所采取的步伐就越大。

想象一下在一个足球场上，从一个角落走到中心，在有限的步数内达到目标。如果我们采取大步伐，可能很快就能跨越大量的地面，但我们无法精准地走到中心，因为我们会不断跨过它。如果我们采取极小的步伐，我们只能从角落向中心走一小段距离。我们可能在正确的轨道上，但由于我们只能走一定的步数，我们无法到达中心。直观地，我们或许可以说服自己，存在一个“甜点”，在这个位置，步长和可用步数相结合，可以帮助我们到达中心。

我们可以在[图 10-4](ch10.xhtml#ch10fig4)的圆形图中看到这一效应。最左边的点代表了采取极小步长的情况。由于我们没有遍历足够的误差空间来找到最小值，因此表现较差。类似地，最右边的点代表了采取非常大步长的情况。我们表现不好，因为我们总是跨过最小值。最佳得分发生在我们能够采取的步数和步长大小相互配合，使我们能够到达最小值的时候。在图中，当基础学习率为0.1时，便发生了这种情况。

现在让我们来看[图 10-4](ch10.xhtml#ch10fig4)中的方块符号图。这个图来自于当基础学习率和轮次的乘积固定时得到的得分，也就是说，小的学习率会运行较多的轮次。大部分情况下，除了最大的基础学习率，所有的基础学习率的测试得分都相同。在我们的足球场上步行的假设实验中，方块符号图相当于采取几个大步或者非常多的小步。我们可以想象，这两种方法都会使我们接近场地的中心，至少直到步长太大而无法准确到达中心为止。

此时，一些读者可能会提出异议。如果我们比较[图10-4](ch10.xhtml#ch10fig4)中圆形和方形图的前几个点，就会看到一个较大的差距。对于圆形图，随着基础学习率的增加，性能逐渐提升。而对于方形图，无论基础学习率如何变化，性能始终保持高且稳定。对于圆形图，我们训练了50个周期，始终如此。这是一个比方形图使用的周期数更多的数量，后者在对应的基础学习率下进行了训练。这意味着，在圆形图的情况下，我们在接近场地中心后走了很多步。然而，对于方形图，我们限制了周期数，所以当我们接近场地中心时就停止了前进，因此性能得到了提升。这意味着我们需要调整周期数（即梯度下降步数）与学习率相匹配，以便快速接近损失函数的最小值，避免在过程中走过多的冗余步骤，同时也避免走得太快，导致步伐过大而无法收敛到最小值。

到目前为止，我们一直在训练过程中保持学习率不变。由于空间限制，我们无法完全探讨在训练过程中更改学习率的效果。不过，至少我们可以使用足球场的思维实验来帮助我们可视化为什么在训练过程中改变学习率是合理的。回想一下，网络是通过智能但随机的方式初始化的。这意味着我们随机地从场地上的某个位置开始。由于这个任意位置距离误差曲面的中心（最小值）可能很远，因此我们确实需要应用梯度下降来将我们推向中心。一开始，我们可以采取较大的步伐，以便快速穿越场地。由于我们是在沿梯度方向前进，这将使我们向中心靠近。然而，如果我们一直采取较大的步伐，可能会超过中心。在迈出几步大步之后，我们可能会认为开始采取较小的步伐是明智的，认为我们现在离目标中心更近了。我们走得越远，步伐就越小，这样我们就可以尽可能接近中心。这就是为什么学习率通常在训练过程中会逐渐降低的原因。

### 训练集大小

我们已经提到，训练集样本的数量对性能有显著影响。让我们用MNIST数据集来量化这个说法。在这个实验中，我们将调整训练集样本的数量，同时调整训练的周期数，以确保在每种情况下，我们都进行（大约）1,000步梯度下降。此实验的代码在*mnist_nn_experiments_samples.py*中。在所有情况下，小批量的大小是100，网络的架构有两个隐藏层，分别为1,000个和500个节点。[图10-5](ch10.xhtml#ch10fig5)展示了此实验的结果。

![image](Images/10fig05.jpg)

*图 10-5：MNIST测试分数与训练样本数量的关系*

[图 10-5](ch10.xhtml#ch10fig5)特别令人满意，因为它正好显示了我们预期的结果。如果训练数据太少，我们无法很好地学习到泛化能力，因为我们使用来自母体分布的非常稀疏样本来训练模型。随着训练数据的逐渐增加，我们预期网络性能会迅速提高，因为训练集变得越来越好地代表了我们希望模型学习的母体分布。

[图 10-5](ch10.xhtml#ch10fig5)显示了增加训练集大小会导致回报递减。从1,000到5,000个训练样本的增加会显著提升性能，但从5,000到甚至10,000个样本的增加，只会带来微小的性能提升，进一步增加训练集大小会趋于平稳，达到某个性能上限。我们可以认为这个水平区域已经达到了某种容量——模型几乎已经从数据集中学到了它能学到的所有知识。此时，我们可能会考虑扩大网络架构，看看是否能在足够的训练样本支持下，测试集分数会有所提高。

### L2正则化

在[第9章](ch09.xhtml#ch09)中，我们讨论了改善网络泛化能力的正则化技术，包括L2正则化。我们看到，L2正则化通过在训练过程中向损失函数添加一个新项，其功能等同于权重衰减，并在训练过程中如果权重过大，则对网络进行惩罚。

在sklearn中，控制L2正则化强度的参数是alpha。如果该参数为0，则没有L2正则化，而随着alpha的增大，正则化的强度也会增加。让我们来探讨一下L2正则化对MNIST网络的影响。

对于这次实验，我们将固定小批量大小为64。我们还将动量设置为0，以便我们看到的效果仅仅是L2正则化的影响。最后，我们将使用一个较小的网络，包含两个隐藏层，分别有100个和50个节点，以及一个包含前3,000个MNIST样本的小型训练集。代码位于*mnist_nn_experiments_L2.py*。

与之前的实验不同，在这种情况下，我们希望在每次训练周期之后评估测试数据，这样我们就可以观察到网络在训练过程中的学习情况。如果网络在学习，那么随着训练周期的增加，测试集上的错误率应该会下降。我们知道，sklearn会遍历数据集中的所有小批量进行一次周期，因此我们可以将训练周期数设置为1。然而，如果我们将max_iter设置为1，然后调用fit方法，那么下次调用fit时，网络将重新初始化，这对我们没有帮助；我们需要在调用fit之间保留权重和偏置。

幸运的是，sklearn的创建者已经考虑到这一点，并添加了warm_start参数。如果将此参数设置为True，则调用fit时*不会*重新初始化网络，而是使用现有的权重和偏置。如果我们将max_iter设置为1并将warm_start设置为True，我们将能够通过在每个训练周期后调用score来观察网络的学习过程。调用score会给出测试数据的准确性。如果我们想要误差，我们需要跟踪的值是1 - score。这是我们绘制的作为周期函数的值。我们将绘制的α值是

[0.0, 0.1, 0.2, 0.3, 0.4]

我们将这些值设置得相对较大，以便可以看到其效果。

专注于测试误差，评估单个周期的代码如下：

def epoch(x_train, y_train, x_test, y_test, clf):

clf.fit(x_train, y_train)

val_err = 1.0 - clf.score(x_test, y_test)

clf.warm_start = True

return val_err

在这里，调用fit进行一次训练周期。然后我们计算测试集上的误差并将其存储在val_err中。在调用fit后将warm_start设置为True，确保第一次调用epoch时会正确初始化网络，但随后的调用将保留之前调用中的权重和偏置。

训练然后发生在一个简单的循环中：

def run(x_train, y_train, x_test, y_test, clf, epochs):

val_err = []

clf.max_iter = 1

for i in range(epochs):

verr = epoch(x_train, y_train, x_test, y_test, clf)

val_err.append(verr)

return val_err

这个循环收集每个周期的结果并将其返回给主函数，主函数本身会遍历我们关注的*α*值。

让我们运行这段代码，并绘制val_err，即测试误差，作为每个α值的训练周期数的函数。[图10-6](ch10.xhtml#ch10fig6)是结果。

![image](Images/10fig06.jpg)

*图10-6：不同*α*值下训练周期数对MNIST测试误差的影响*

我们在[图10-6](ch10.xhtml#ch10fig6)中首先注意到，任何非零的*α*值都会比完全不使用L2正则化时产生更低的测试误差。我们可以得出结论，L2正则化是有帮助的。不同的*α*值都会导致大致相同的测试误差，但较大的值稍微更有效，并且更快达到较低的测试误差。例如，比较*α* = 0.1与*α* = 0.4。

注意到较大的*α*值似乎更为嘈杂：随着错误在较小*α*值相较之下波动更大，图表变得更加粗糙。为了理解这一点，可以考虑训练过程中最小化的总损失。当*α*值较大时，我们相对于小批量的网络误差更重视L2项。这意味着，当我们要求网络在反向传播时调整权重和偏置时，它将更多地受到网络参数大小的影响，而不是训练数据本身的影响。由于网络较少关注减少由于训练数据产生的损失，因此我们可能会期望每个时期的测试误差波动更大。

### 动量

动量通过将上一个小批量中用于更新权重的梯度值的一部分添加到当前权重更新中，从而改变训练过程中的权重更新。这个部分被指定为对之前梯度值的乘数，[0,1]之间的值。我们在[第9章](ch09.xhtml#ch09)中已经讨论过动量。

让我们看看改变这个参数如何影响训练。在这个例子中，实验的设置非常简单。它与之前用于L2正则化的设置相同，但我们将固定动量参数（*μ*）并变化L2权重（*α*）。我们将*α* = 0.0001，并改变*μ*。所有其他部分保持不变：按单个轮次训练，网络配置等。请参见文件*mnist_nn_experiments_momentum.py*。

我们将探讨这些动量值：

[0.0, 0.3, 0.5, 0.7, 0.9, 0.99]

它们的范围从没有动量项（*μ* = 0）到较大的动量项（*μ* = 0.99）。运行实验会产生[图10-7](ch10.xhtml#ch10fig7)。

在[图10-7](ch10.xhtml#ch10fig7)中，我们看到三个不同的区域。第一个区域，表示没有动量或动量值相对较小的情况（*μ* = 0.3，*μ* = 0.5），显示出最高的测试集误差。第二个区域，随着中等动量值的使用（*μ* = 0.7，*μ* = 0.9），表现出改善，包括“标准”（sklearn默认）值0.9。尽管如此，在这种情况下，动量为0.99时，测试集误差从约7.5%降至约6%。动量是有帮助的，应该使用，特别是接近0.9的标准值。在实践中，人们似乎很少改变动量，但正如这个例子所示，有时它对结果有很大影响。

![image](Images/10fig07.jpg)

*图10-7：不同μ值下，训练轮次对MNIST测试误差的影响*

请注意，我们将训练集限制得非常严格，仅使用了3000个样本，每个数字约300个样本，这可能使得动量变得更为重要，因为训练集是一个小而不完全的样本，代表了我们希望模型学习的父分布。将训练集的大小增加到30,000后，绘图的顺序发生了变化，更符合典型情况，其中0.9的动量是最佳选择。

### 权重初始化

曾经被视为不太重要的初始权重和偏置值，现在被认为是极其重要的。这个章节的简单实验清楚地展示了这一点。

sklearn工具包通过调用MLPClassifier类的_init_coef方法来初始化神经网络的权重和偏置。该方法根据我们在[第9章](ch09.xhtml#ch09)中讨论的Glorot算法随机选择权重和偏置。此算法将权重和偏置设置为从范围内均匀抽样的值：

![image](Images/243equ01.jpg)

其中*f*[*in*]是当前层输入的数量，*f*[*out*]是当前层输出的数量。如果激活函数是sigmoid，则*A* = 2；否则，*A* = 6。

如果我们稍微动动脑筋，就可以改变 sklearn 初始化网络的方式，从而尝试不同的初始化方案。这个方法利用了 Python 的面向对象编程能力。如果我们创建一个 MLPClassifier 的子类，暂且叫它 Classifier，我们可以用自己的方法重写 _init_coef 方法。Python 还允许我们随意为类实例添加新的成员变量，这正是我们所需要的。

剩下的实验部分遵循前面章节的格式。我们最终会绘制不同初始化方法下，基于部分数据训练的 MNIST 数字在每个 epoch 的测试误差。模型本身将使用前 6,000 个训练样本，mini-batch 大小为 64，学习率为 0.01，动量为 0.9，L2 正则化参数为 0.2，架构为两层隐藏层，分别有 100 和 50 个节点。请查看 *mnist_nn_experiments_init.py* 获取此实验的代码。

我们将测试四种新的权重初始化方案，以及 sklearn 的标准 Glorot 方法。这些方案列在 [表 10-5](ch10.xhtml#ch10tab5) 中。

**表 10-5:** 权重初始化方案

| 名称 | 方程式 | 描述 |
| --- | --- | --- |
| Glorot | ![Image](Images/244equ01.jpg) | sklearn 默认 |
| He | ![Image](Images/244equ02.jpg) | ReLU 的 He 初始化 |
| Xavier | ![Image](Images/244equ03.jpg) | 替代 Xavier |
| 均匀 | 0.01(*U*(0,1)-0.5) | 经典的小均匀分布 |
| 高斯 | 0.005*N*(0,1) | 经典的小高斯分布 |

记住，*N*(0,1) 表示从均值为 0、标准差为 1 的钟形曲线中抽样，而 *U*(0,1) 表示从 [0,1) 区间均匀抽样，意味着该区间内的所有值都是等可能的，除了 1.0。每种新的初始化方法都会将偏置值始终设置为 0。然而，sklearn 的 Glorot 实现则按照与设置权重相同的方式设置偏置值。

**注意** *如 [第9章](ch09.xhtml#ch09) 中提到的，* Xavier *和* Glorot *指的是同一个人，Xavier Glorot。我们这里区分是因为我们所调用的* Xavier *形式，在其他机器学习工具包如 Caffe 中也有提到，而其使用的方程与原论文中的方程不同。*

这一切听起来不错，但如何在代码中实现呢？首先，我们定义一个新的 Python 类 Classifier，它是 MLPClassifier 的子类。作为子类，新的类会立即继承父类（MLPClassifier）的所有功能，同时允许我们自由地用自己的实现重写任何父类方法。我们只需要定义我们自己的 _init_coef 版本，保持相同的参数和返回值。代码如下所示：

class Classifier(MLPClassifier):

def _init_coef(self, fan_in, fan_out):

if (self.init_scheme == 0):

return super(Classifier, self)._init_coef(fan_in, fan_out)

elif (self.init_scheme == 1):

weights = 0.01*(np.random.random((fan_in, fan_out))-0.5)

biases = np.zeros(fan_out)

elif (self.init_scheme == 2):

weights = 0.005*(np.random.normal(size=(fan_in, fan_out)))

biases = np.zeros(fan_out)

elif (self.init_scheme == 3):

weights = np.random.normal(size=(fan_in, fan_out))*  \

np.sqrt(2.0/fan_in)

biases = np.zeros(fan_out)

elif (self.init_scheme == 4):

weights = np.random.normal(size=(fan_in, fan_out))*  \

np.sqrt(1.0/fan_in)

biases = np.zeros(fan_out)

我们执行的初始化取决于 init_scheme 的值。这是一个新的成员变量，用来选择初始化方法（请参见[表 10-6](ch10.xhtml#ch10tab6)）。

**表 10-6：** 初始化方案和 init_scheme 值

| 值 | 初始化方法 |
| --- | --- |
| 0 | sklearn 默认 |
| 1 | 经典小均匀分布 |
| 2 | 经典小高斯分布 |
| 3 | He 初始化 |
| 4 | 交替 Xavier 初始化 |

我们在创建 Classifier 对象后立即设置该变量。

我们知道，训练一个网络多次会导致稍有不同的性能，因为网络的初始化方式不同。因此，仅训练一个网络进行每种初始化类型可能会导致对初始化效果的错误看法，因为我们可能会遇到一组不好的初始权重和偏置。为了解决这个问题，我们需要训练多个版本的网络，并报告其平均性能。由于我们希望绘制测试误差与训练周期的关系，我们需要在每次训练的每个初始化方案下追踪每个周期的测试误差。这意味着需要一个三维数组：

test_err = np.zeros((trainings, init_types, epochs))

我们为每种初始化类型（init_types）进行了多次训练（trainings），最大训练周期为 epochs。

有了这些设置，生成和存储实际实验结果就变得简单了，尽管过程相当慢，通常需要一天的时间来完成：

for i in range(trainings):

for k in range(init_types):

nn = Classifier(solver="sgd", verbose=False, tol=0,

nesterovs_momentum=False, early_stopping=False,

learning_rate_init=0.01, momentum=0.9,

hidden_layer_sizes=(100,50), activation="relu", alpha=0.2,

learning_rate="constant", batch_size=64, max_iter=1)

nn.init_scheme = k

test_err[i,k,:] = run(x_train, y_train, x_test, y_test, nn, epochs)

np.save("mnist_nn_experiments_init_results.npy", test_err)

这里的 nn 是用于训练的分类器实例，init_scheme 设置要使用的初始化方案，run 是我们之前定义的用于增量训练和测试网络的函数。

如果我们将训练次数设置为 10，训练周期数设置为 4000，并绘制每个周期的平均测试误差，我们将得到[图 10-8](ch10.xhtml#ch10fig8)。

![image](Images/10fig08.jpg)

*图 10-8：不同权重初始化方法下，MNIST 测试误差随训练周期的变化（10次训练结果的均值）*

让我们理解图表显示的内容。图中标记了五种初始化方法，每种方法都指向图中的一条曲线。这些曲线我们现在已经很熟悉了；它们显示的是训练周期与测试集误差之间的关系。在这种情况下，每条曲线所绘制的值是同一网络架构在相同初始化方法下，进行10次训练的平均值，且每次训练的随机值不同。

我们立刻看到两个明显不同的结果组。顶部是经典初始化方法的测试误差，这些方法使用的是小的均匀分布或正态分布（高斯）值。底部则是当前使用的更有原则性的初始化方法的结果。即使是这个基本实验，也清楚地展示了现代初始化方法的有效性。回想一下，经典方法曾是神经网络在几十年前名声不好的原因之一。网络容易出现问题并且难以训练，主要是因为初始化不当。

看底部的结果，我们看到在这个实验中，sklearn默认的初始化方法（我们称之为*Glorot*）和He初始化方法几乎没有区别。这两条曲线几乎是完全相同的。标记为*Xavier*的曲线一开始略差，但在训练的后期与其他两条曲线趋于一致。Sklearn使用了一种好的初始化策略。

该图还展示了其他信息。对于经典的初始化方法，我们看到测试集误差趋于平稳并保持基本不变。而对于现代的初始化方法，我们观察到随着训练周期的增加，测试误差略有上升。尤其是Glorot和He方法，这一增加是过拟合的明显迹象：随着训练的进行，模型不再学习父分布的通用特征，而是开始关注训练集的特定特征。我们没有绘制训练集误差，但它会在测试集误差开始上升时继续下降。最低的测试集误差出现在大约1,200个周期处。理想情况下，这就是我们应该停止训练的地方，因为我们有最可靠的证据表明，模型在正确预测新的、未见过的输入时处于最佳状态。继续训练往往会导致模型泛化能力下降。

为什么测试误差会增加？这种现象的可能原因是训练集太小，只有6,000个样本。此外，模型架构也不大，隐藏层仅有100个和50个节点。

这一部分明显展示了使用当前最先进的网络初始化方法的好处。当我们在[第12章](ch12.xhtml#ch12)中探讨卷积神经网络时，我们将完全采用这些方法。

### 特征排序

我们将通过一点有趣的实验结束 MNIST 实验，这个实验我们将在探索卷积神经网络时再次回顾。到目前为止的所有实验，都使用将 MNIST 数字图像的行连接成一个向量的方式。当我们这么做时，我们知道这个向量的元素是有关系的，如果我们将向量重塑成一个 28 × 28 的数组，就能重建数字图像。这意味着，除了某一行的结尾和下一行的开头，图像行中的像素仍然是数字的一部分——图像元素之间的空间关系得以保持。

然而，如果我们将图像的像素打乱，但每次打乱的方式都相同，我们会破坏像素之间的局部空间关系。我们在看图像时会用到这种局部关系来判断它表示的是哪个数字。例如，我们会注意到 5 的上半部分是一条直线段，下半部分在右侧弯曲，依此类推。

看看[图 7-3](ch07.xhtml#ch7fig3)。该图显示了 MNIST 数字图像的顶部行以及打乱后的数字图像（底部）。在[第 7 章](ch07.xhtml#ch07)中，我们展示了这种打乱并不会影响经典机器学习模型的准确性；这些模型是从整体上考虑输入的，而不像我们那样依赖局部空间关系。那么，神经网络是否也如此呢？如果是这样，网络在使用打乱输入时的学习速度会与使用原始图像时一样快吗？让我们来找出答案。

这个实验的代码在 *mnist_nn_experiments_scrambled.py* 中，我们在其中简单地定义了我们现在期望的神经网络模型

MLPClassifier(solver="sgd", verbose=False, tol=0,

nesterovs_momentum=False, early_stopping=False,

learning_rate_init=0.01, momentum=0.9,

hidden_layer_sizes=(100,50), activation="relu",

alpha=0.2, learning_rate="constant", batch_size=64, max_iter=1)

然后，我们使用前 6,000 个 MNIST 数字样本来训练它——首先按常规训练，然后使用打乱后的版本。我们将测试集误差作为训练轮次的函数计算，并在绘图之前对 10 次运行结果进行平均。结果如[图 10-9](ch10.xhtml#ch10fig9)所示。

![image](Images/10fig09.jpg)

*图 10-9：MNIST 测试误差与训练轮次的关系，分别对比打乱和未打乱的数字*

在图中，我们看到了之前问题的答案。首先，是的，传统的神经网络确实像经典模型一样，从整体上解读输入向量。其次，是的，网络在使用打乱后的数字时，学习速度与使用未打乱的数字时一样快。[图 10-9](ch10.xhtml#ch10fig9)中，打乱与未打乱的曲线之间的差异在统计上没有显著性。

这些结果表明，（传统的）神经网络“理解”其输入的整体信息，而不是寻找局部空间关系。当我们处理卷积神经网络时，实验的结果将有所不同（见[第12章](ch12.xhtml#ch12)）。正是这种缺乏空间意识（假设图像作为输入）限制了神经网络的应用，并促使卷积神经网络的发展，这类网络具有空间意识。

### 概要

在本章中，我们通过对MNIST数据集的实验探讨了[第8章](ch08.xhtml#ch08)和[第9章](ch09.xhtml#ch09)中提出的概念。通过改变与网络架构和梯度下降学习过程相关的关键参数，我们增强了对这些参数如何影响网络整体性能的直觉。由于篇幅限制，我们未能深入探索所有MLPClassifier的选项，因此我鼓励你自己进行更多实验。特别是，尝试使用不同的求解器、Nesterov动量、早期停止，以及对于训练卷积神经网络尤为重要的非常数学习率。

下一章将探讨评估机器学习模型性能的技术和指标。在我们进入卷积神经网络之前，这一章节为我们提供了一些工具，帮助我们理解更高级模型类型的性能。

## **1

开始使用**

![image](Images/common.jpg)

本章介绍了我们的操作环境，并详细讲解如何设置它。它还包括一些我们将遇到的数学基础知识。最后，我们会简要提及图形处理单元（GPU），你可能听说它们对深度学习至关重要。但就我们而言，它们并非必需，因此不必担心——本书不会突然让你花费大量资金。

### 操作环境

在本节中，我们将详细介绍我们假设的环境，这个环境贯穿本书的其余部分。我们的基本假设是我们使用的是 64 位的 Linux 系统。具体的发行版并不关键，但为了简化展示，我们假设使用的是 Ubuntu 20.04。考虑到 Ubuntu 发行版的优异支持，我们相信任何更新的发行版也能以类似的方式工作。Python 语言是我们的*通用语言*，是机器学习的共同语言。具体来说，我们将使用 Python 3.8.2，这是 Ubuntu 20.04 使用的版本。

让我们快速概览一下我们将使用的 Python 工具包。

#### NumPy

*NumPy* 是一个 Python 库，增加了数组处理的功能。虽然 Python 列表可以像一维数组一样使用，但实际上它们速度太慢且不够灵活。NumPy 库弥补了 Python 中缺少的数组特性，这些特性对许多科学应用至关重要。NumPy 是我们将使用的所有其他库的基础库。

#### scikit-learn

本书中我们将探讨的所有传统机器学习模型都可以在优秀的 scikit-learn 库中找到，通常当加载到 Python 中时，它被称为*sklearn*。还需要注意的是，我们在书中将*scikit-learn*全小写，这是因为文档作者一致如此称呼该库。这个库使用 NumPy 数组，提供了许多不同机器学习模型的标准化接口，并且包含了大量我们无法触及的其他功能。我强烈建议你在熟悉机器学习及其背后工具的过程中，查看官方的 sklearn 文档（[https://scikit-learn.org/stable/documentation.html](https://scikit-learn.org/stable/documentation.html)）。

#### 使用 TensorFlow 的 Keras

深度学习已经足够难以理解，更不用说高效且正确地实现它了，因此我们不打算从头编写卷积神经网络，而是将使用已在积极开发的流行工具包之一。从一开始，深度学习社区就支持工具包的开发，以便更容易使用深度网络，并且以非常宽松的开源许可证发布了这些工具包。在写作本书时，我们可以在 Python 中使用许多流行的工具包。除了其他工具包之外，以下是其中的一些：

+   Keras

+   PyTorch

+   Caffe

+   Caffe2

+   Apache MXnet

这些工具包中有些正在流行，而有些似乎在衰退。但目前可能拥有最多活跃追随者的是使用 TensorFlow 后端的 Keras，因此我们将在这里使用这个。

*Keras* (*[https://keras.io/](https://keras.io/)* ) 是一个 Python 深度学习工具包，底层使用 TensorFlow 工具包 (*[https://www.tensorflow.org/](https://www.tensorflow.org/)*)。*TensorFlow* 是一个开源的 Google 产品，实现了深度神经网络的核心功能，支持多个平台。我们选择 Keras 不仅因为它很受欢迎且正在积极开发，还因为它使用起来很简单。我们的目标是熟悉深度学习，达到能够实现模型并在最小的编程开销下使用它们的程度。

### 安装工具包

我们无法合理地提供在所有系统和硬件上安装工具包的详尽指南。相反，我们将为我们所使用的特定操作系统提供逐步的安装说明，并将其作为参考系统。这些步骤以及库的最小版本号，应该足够大多数读者能够安装并运行工作系统。

请记住，我们假设我们在 Linux 环境中工作，具体来说是在 Ubuntu 20.04 上。Ubuntu 是一个广泛使用的 Linux 发行版，几乎可以在任何现代计算机系统上运行。其他 Linux 发行版和 macOS 也能正常工作，但这里的说明仅适用于 Ubuntu。大部分机器学习社区已经放弃了 Windows 操作系统，但仍然有人将工具包移植到 Windows；因此，勇于尝试的读者可以尝试在 Windows 上使用。

新安装的 Ubuntu 20.04 基础桌面系统免费提供 Python 3.8.2。为了安装其余的包，我们需要进入一个 shell 并按照下面给出的步骤顺序执行：

$ sudo apt - get update

$ sudo apt - get install python3 - pip

$ sudo apt - get install build - essential python3 - dev

$ sudo apt - get install python3 - setuptools python3 - numpy

$ sudo apt - get install python3 - scipy libatlas - base - dev

$ sudo apt - get install python3 - matplotlib

$ pip3 install scikit - learn

$ pip3 install tensorflow

$ pip3 install pillow

$ pip3 install h5py

$ pip3 install keras

安装完成后，我们将安装以下版本的库和工具包：

NumPy 1.17.4

sklearn 0.23.2

keras 2.4.3

tensorflow 2.2.0

pillow 7.0.0

h5py 2.10.0

matplotlib 3.1.2

pillow 库是一个图像处理库，h5py 是一个处理 HDF5 格式数据文件的库，matplotlib 用于绘图。*HDF5* 是一种通用的层次化文件格式，用于存储科学数据。Keras 使用它来存储模型参数。

以下两个部分是本书中将涉及的一些数学概念的简单介绍。

### 基本线性代数

我们即将深入研究向量和矩阵。处理这些概念的数学属于*线性代数*或矩阵理论的范畴。正如你可能想象的那样，线性代数是一个复杂的领域。对于本书，我们只需要了解什么是向量，什么是矩阵，以及如何将两个向量、两个矩阵，或向量和矩阵相乘。稍后我们将看到，这为我们提供了一种强大的方式来实现特定的模型，特别是神经网络。

让我们从向量开始。

#### 向量

*向量*是一个一维的数字列表。数学上，向量可能表现为

*a* = [0, 1, 2, 3, 4]

第三个元素表示为 *a*[2] = 2。请注意，我们遵循从零开始索引的编程惯例，所以 *a*[2] 给我们的是向量中的第三个元素。

上面的向量是水平书写的，因此被称为*行向量*。然而，在数学表达式中，向量通常被假定为垂直书写：

![Image](Images/004equ02.jpg)

当向量垂直书写时，它被称为*列向量*。这个向量有五个元素，被表示为五元素列向量。在本书中，我们通常使用向量表示一个*样本*：一组我们输入到模型中的特征。

在数学上，向量用来表示空间中的点。如果我们谈论的是二维（2D）笛卡尔平面，我们用一个由两个数字组成的向量（*x*, *y*）来定位一个点，其中 *x* 是沿 x 轴的距离，*y* 是沿 y 轴的距离。这个向量表示一个二维的点，即使这个向量本身只有一个维度。如果我们有三维空间，我们需要一个包含三个元素的向量（*x*, *y*, *z*）。

在机器学习中，由于我们通常使用向量来表示模型的输入，所以我们将处理从几十到几百维的向量。当然，我们不能将它们作为空间中的点来绘制，但从数学角度来看，它们就是这样。正如我们将看到的，一些模型，比如*k*-最近邻模型，就将特征向量作为—高维空间中的点。

#### 矩阵

*矩阵*是一个二维的数字数组，我们通过其行号和列号来索引特定的条目。例如，这是一个矩阵：

![Image](Images/005equ01.jpg)

如果我们想引用 6，我们写 *a*[1,2] = 6。同样，我们从零开始索引。因为这个矩阵 *a* 有三行三列，所以我们称它为一个 3 × 3 矩阵。

#### 向量与矩阵的乘法

将两个向量相乘的最简单方式是将它们的对应元素相乘。例如：

[1, 2, 3] × [4, 5, 6] = [4, 10, 18]

这是使用像 NumPy 这样的工具包时最常见的数组乘法方式，我们将在接下来的章节中广泛使用这一方式。然而，在数学中，实际上很少这样做。

当我们将向量相乘时，需要知道它们是行向量还是列向量。我们将使用两个向量，*A* = (*a*,*b*,*c*) 和 *B* = (*d*,*e*,*f*)，按照数学惯例，它们被假定为列向量。添加一个上标 *T* 会将列向量转变为行向量。数学上允许的乘法方式有：

![Image](Images/005equ02.jpg)

这叫做*外积*，并且

![Image](Images/005equ03.jpg)

这叫做*内积*，或称为*点积*。注意，外积得到的是矩阵，而内积得到的是一个单一的数字，一个*标量*。

当矩阵和向量相乘时，向量通常位于矩阵的右侧。如果矩阵的列数与向量的元素数相匹配，乘法可以进行，这里假设向量是列向量。结果也是一个向量，其元素个数与矩阵的行数相等（将*ax* + *by* + *cz* 视为一个单一元素）。

例如：

![Image](Images/006equ01.jpg)

这里我们将一个 2 × 3 矩阵与一个 3 × 1 列向量相乘，得到一个 2 × 1 的输出向量。注意，矩阵的列数与向量的行数要匹配。如果不匹配，乘法是未定义的。同时，注意输出向量中的值是矩阵与向量的乘积之和。这个规则在乘法两个矩阵时也适用：

![Image](Images/006equ02.jpg)

这里将一个 2 × 3 矩阵与一个 3 × 2 矩阵相乘，得到了一个 2 × 2 的结果。

当我们进入卷积神经网络时，我们将处理具有三维甚至四维的数组。通常，这些被称为*张量*。如果我们想象一堆大小相同的矩阵，我们就得到了一个三维张量，我们可以使用第一个索引来引用其中任何一个矩阵，剩余的两个索引来引用该矩阵中的特定元素。类似地，如果我们有一堆三维张量，我们就得到了一个四维张量，我们可以使用其第一个索引来引用任何一个三维张量。

本节的重点是，向量是一维的，矩阵是二维的，有规则可以将这些对象相乘，最终我们的工具包将会处理四维张量。我们将在书中后面遇到时回顾这些要点。

### 统计与概率

统计和概率的主题非常广泛，以至于通常最好什么都不说，或者写几本书。因此，我将只提到一些我们将在全书中使用的关键概念，剩下的部分则交给你根据需要自行学习。我假设你对投掷硬币和掷骰子有一些基础的概率知识。

#### 描述性统计

当我们进行实验时，我们需要以某种有意义的方式报告结果。通常，对于我们来说，我们会报告结果为均值（算术平均数）加减一个叫做*均值标准误差（SE）*的量。我们通过一个例子来定义均值的标准误差。

如果我们有很多测量值*x*，比如说一朵花的一部分的长度，那么我们可以通过将所有的数值加起来，并除以加起来的数值的数量，来计算均值 (![Image](Images/xbar.jpg))。然后，一旦我们有了均值，我们可以通过将每个数值减去均值、平方结果并将所有这些平方值加起来，再除以加起来的数值数量减去一，来计算个别数值围绕均值的平均分散程度。这个数值就是*方差*。如果我们取这个数值的平方根，就能得到*标准差*（*σ*），我们稍后还会看到它。通过标准差，我们可以计算均值的标准误差为 ![Image](Images/007equ01.jpg)，其中*n*是用于计算均值的数值数量。SE越小，说明数值越紧密地集中在均值周围。我们可以将这个值解释为我们对均值的确定性程度。意味着我们期望实际均值（我们并不真正知道它）位于 ![Image](Images/007equ02.jpg) 和 ![Image](Images/007equ03.jpg) 之间。

有时候，我们会谈论中位数而不是均值。*中位数*是中间值，表示一半的样本值低于它，另一半高于它。要找到一组数值的中位数，我们首先按数值大小排序，然后找到中间的值。如果样本数是奇数，中位数就是正中间的值；如果样本数是偶数，中位数就是中间两个值的均值。如果样本分布不均匀，中位数有时比均值更有用。经典的例子是收入。少数非常富有的人会把均值拉高，导致均值的意义不大。相反，中位数，即一半人收入低于它，另一半收入高于它，更具代表性。

在后续章节中，我们将讨论*描述性统计*。这些是从数据集中得出的数值，可以用来理解数据集。我们刚才提到了其中的三个：均值、中位数和标准差。我们将学习如何使用这些指标以及如何将它们绘制出来，以帮助我们理解数据集。

#### 概率分布

在这本书中，我们将讨论一个被称为*概率分布*的东西。你可以把它看作是某种神谕——当被问及时，会给我们一个数字或一组数字。例如，当我们训练模型时，我们使用我们测量的数字或数字集合；我们可以把这些数字看作来自概率分布。我们将称之为*父分布*。可以将其视为生成我们将馈送给模型的数据的东西；另一种更柏拉图式的思考方式是将其视为我们的数据正在逼近的理想数据集。

概率分布有许多不同的形式；一些甚至有名字。我们将遇到的两种最常见的是均匀分布和正态分布。您已经遇到了均匀分布：这是我们掷一个公平的骰子所得到的。如果骰子有六个面，我们知道得到任何值，从1到6的可能性是相同的。如果我们掷100次骰子并记录出现的数字，我们知道每个数字的记录大致相等，并且在长期内，我们可以很容易地说服自己数字会平衡。

一个*均匀分布*是一个神谕，它同等可能地给出它允许的任何响应。在数学上，我们将均匀分布写为*U*(*a*,*b*)，其中*U*表示均匀分布，*a*和*b*是它用于括起其响应的值的范围。除非我们指定分布仅给出整数，否则任何实数都可以作为响应。在符号上，我们写*x* ~ *U*(0,1)来表示*x*是由神谕返回的值，该神谕在范围(0,1)内以相等的可能性给出。此外，请注意，使用“(”和“)”来括起范围会排除相关边界，而使用“[”和“]”会包括它。因此*U*[0,1)返回从0到1的值，包括0但不包括1。

一个*正态分布*，也称为*高斯*分布，在视觉上是一个钟形曲线——一个值最有可能，然后随着远离最可能值，其他值的可能性逐渐降低。最可能的值是平均值，![Image](Images/xbar.jpg)，控制可能性多快下降到零（但从未真正达到）的参数是标准差，*σ*（西格玛）。对于我们的目的，如果我们想要从正态分布中取样，我们将写![Image](Images/008equ01.jpg)表示*x*是从均值为![Image](Images/xbar.jpg)、标准差为*σ*的正态分布中抽取的样本。

#### 统计检验

另一个不时会出现的话题是*统计检验*的概念，这是一种用来判断某个假设是否可能成立的测量方法。通常，假设涉及到两组测量数据，假设是这两组测量来自同一个母体分布。如果检验计算出的统计量超出了某个范围，我们就会拒绝这个假设，并声称有证据表明这两组测量*不*来自同一个母体分布。

在这里，我们通常会使用* t 检验*，这是一种常见的统计检验，假设我们的数据是正态分布的。由于我们假设数据是正态分布的，这一假设可能对也可能不对，所以 t 检验被称为*参数检验*。

有时，我们会使用另一种检验，*曼–惠特尼 U 检验*，它与 t 检验类似，帮助我们判断两个样本是否来自同一个母体分布，但它不对样本中数据值的分布做任何假设。像这样的检验被称为*非参数检验*。

无论检验是参数检验还是非参数检验，我们最终得到的值被称为*p*-值。它表示在假设样本来自同一个母体分布的前提下，我们计算出的检验统计量值出现的概率。如果*p*-值较低，我们有证据表明假设不成立。

通常的*p*-值临界值是0.05，这意味着如果样本来自同一个母体分布，那么我们有1/20的机会测量到该检验统计量（t检验或曼–惠特尼U检验）。然而，近年来已经明确这个临界值过于宽松。当*p*-值接近0.05，但不超过时，我们开始怀疑有一些证据反对假设。如果*p*-值是0.001甚至更小，那么我们就有强有力的证据表明这些样本不来自同一个母体分布。在这种情况下，我们称差异是*统计显著*的。

### 图形处理单元

现代深度学习的一个重要技术是*图形处理单元（GPU）*的发展。这些是实现于显卡上的协同计算机。最初为视频游戏设计，GPU的高度并行特性已被应用于深度神经网络模型的极高计算需求。近年来的许多进展如果没有GPU提供的类似超级计算机的能力，即使是普通的桌面计算机，也不可能实现。NVIDIA是深度学习GPU创建的领导者，并且通过其计算统一设备架构（CUDA），NVIDIA为深度学习的成功奠定了基础。毫不夸张地说，如果没有GPU，深度学习就不可能发生，至少不会如此广泛应用。

也就是说，我们并不指望在本书中使用的模型中配备 GPU。我们将使用足够小的数据集和模型，以便仅使用 CPU 就能在合理的时间内完成训练。我们已经在安装的包中强制执行了这一决定，因为我们安装的 TensorFlow 版本是仅支持 CPU 的版本。

如果你确实拥有支持 CUDA 的 GPU，并希望将其用于本书的深度学习部分，可以使用它，但不要认为你需要购买一个 GPU 来运行示例。如果你使用 GPU，请确保在安装前正确安装 CUDA，并确保安装支持 GPU 的 TensorFlow 版本。sklearn 工具包仅支持 CPU。

### 总结

在这一章中，我们总结了我们的操作环境。接下来，我们介绍了本书中将要使用的基本 Python 工具包，并假设使用 Ubuntu 20.04 Linux 发行版，详细说明了安装工具包的步骤。如前所述，这些工具包在许多其他 Linux 发行版以及 macOS 上也能很好地工作。然后，我们简要回顾了后面会涉及到的一些数学内容，最后解释了为什么我们的模型不需要 GPU。

在下一章中，我们将回顾 Python 的基础知识。

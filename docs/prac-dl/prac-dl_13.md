## **13

使用Keras和MNIST的实验**

![image](Images/common.jpg)

在上一章中，我们介绍了卷积神经网络（CNN）的基本组件和功能。在本章中，我们将使用[第12章](ch12.xhtml#ch12)中的测试模型。我们将首先学习如何在Keras中实现并训练该模型。之后，我们将进行一系列实验，以帮助我们直观理解不同架构和学习参数选择如何影响模型。

从这里开始，我们将超越简单输入图像的分类，将网络扩展为一个全卷积模型，能够处理任意输入，并在输入中的任何位置定位数字。

在全卷积网络之后，我们将稍微深入一点深度学习的领域，并实现[第7章](ch07.xhtml#ch07)中做出的承诺：我们将探讨CNN在打乱的MNIST数字实验中的表现。我们在[第10章](ch10.xhtml#ch10)中看到，将数字的像素打乱几乎让我们无法辨认出数字，但对传统神经网络解析数字的能力几乎没有影响。那么，CNN也是如此吗？我们将揭晓答案。

### 在Keras中构建CNN

来自[图12-3](ch12.xhtml#ch12fig3)的模型可以通过Python中的Keras库轻松实现。我们首先列出代码，解释它，然后运行它，看看它产生了什么样的输出。代码自然分为三个部分：第一部分加载MNIST数据并为Keras配置它；第二部分构建模型；第三部分训练模型并将其应用于测试数据。

#### 加载MNIST数据

[清单 13-1](ch13.xhtml#ch13lis1)是我们代码的第一部分。

import keras

from keras.datasets import mnist

from keras.models import Sequential

from keras.layers import Dense, Dropout, Flatten

from keras.layers import Conv2D, MaxPooling2D

from keras import backend as K

batch_size = 128

num_classes = 10

epochs = 12

img_rows, img_cols = 28, 28

❶ (x_train, y_train), (x_test, y_test) = mnist.load_data()

❷ if K.image_data_format() == 'channels_first':

x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)

x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)

input_shape = (1, img_rows, img_cols)

else:

x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)

x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)

input_shape = (img_rows, img_cols, 1)

❸ x_train = x_train.astype('float32')

x_test = x_test.astype('float32')

x_train /= 255

x_test /= 255

❹ y_train = keras.utils.to_categorical(y_train, num_classes)

y_test = keras.utils.to_categorical(y_test, num_classes)

*清单13-1：加载和数据预处理*

Keras 是一个相当大的工具包，包含许多模块。我们首先导入库，然后从中导入特定的函数。mnist 模块让我们可以从 Keras 内部访问 MNIST 数据；Sequential 模型类型用于实现 CNN。我们的 CNN 需要一些特定的层，这些层在[图 12-3](ch12.xhtml#ch12fig3)中有所展示：Dense、Dropout、Flatten、Conv2D 和 MaxPool2D，我们都导入了。Keras 支持大量其他层；我鼓励你花些时间浏览它们的文档页面：*[https://keras.io/](https://keras.io/)*。

接下来，我们设置学习参数，包括 epochs 数量、类别数和小批量大小。有 10 个类别，图像是 28×28 像素的灰度图像。像 sklearn 一样，在 Keras 中，你指定的是 epochs 的数量（即完整通过训练集的次数），而不是应该处理的小批量数量。Keras 会自动按小批量大小处理整个训练集——这里是每次处理 128 个样本。回想一下，MNIST 的训练集包含 60,000 个样本，因此每个 epoch 至少有 60,000/128 = 468 个小批量（使用整数除法）。如果 Keras 使用余数，即那些不能组成完整小批量的样本，那么就会有 469 个小批量。记住，每处理一个小批量就会进行一次梯度下降更新：即更新网络的参数。

在加载 MNIST 的训练集和测试集数据❶之后，接下来的几行代码看起来可能会有些神秘❷。Keras 是一个高阶工具包，它使用潜在不同的低阶后端。在我们的例子中，后端是 TensorFlow，它在[第 1 章](ch01.xhtml#ch01)中已经安装。不同的后端期望模型输入的格式各异。image_data_format 函数返回一个字符串，指示底层工具包期望在哪里看到卷积层的通道数或滤波器数。TensorFlow 后端返回 channels_last，意味着它期望图像以 H × W × C 的 3D 数组表示，其中 H 是图像高度，W 是图像宽度，C 是通道数。对于像 MNIST 这样的灰度图像，通道数是 1。❷ 中的代码重新格式化了输入图像，以匹配 Keras 期望的格式。

接下来的代码块将字节图像值转换为范围在 [0,1] 之间的浮点数❸。这是对输入数据进行的唯一缩放操作，这种类型的缩放通常用于处理图像的 CNN。

最后，to_categorical 函数用于将 y_test 中的类标签映射到一热向量表示❹，这正是 Keras 所期望的标签格式。正如我们将看到的，模型有 10 个输出，因此映射到一个包含 10 个元素的向量；除了与 y_test 中标签对应索引的元素外，其他元素均为 0。该元素被设置为 1。例如，y_test[333] 属于类 6（一个“6”数字）。在调用 to_categorical 后，y_test[333] 变成了

array([0.,0.,0.,0.,0.,0.,1.,0.,0.,0.], dtype=float32)

其中所有条目的值为0，除了索引6的值为1。

#### 构建我们的模型

数据集预处理完成后，我们可以开始构建我们的模型。[列表13-2](ch13.xhtml#ch13lis2)中的代码构建了我们在[图12-3](ch12.xhtml#ch12fig3)中定义的完全相同的模型。

model = Sequential()

model.add(Conv2D(32, kernel_size=(3, 3),

activation='relu',

input_shape=input_shape))

model.add(Conv2D(64, (3, 3), activation='relu'))

model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Dropout(0.25))

model.add(Flatten())

model.add(Dense(128, activation='relu'))

model.add(Dropout(0.5))

model.add(Dense(num_classes, activation='softmax'))

model.compile(loss=keras.losses.categorical_crossentropy,

optimizer=keras.optimizers.Adadelta(),

metrics=['accuracy'])

print("模型参数 = %d" % model.count_params())

print(model.summary())

*列表13-2：构建MNIST模型*

Keras将模型定义为Sequential类的一个实例。通过向该实例添加层来构建模型，因此所有对add方法的调用都用于添加新层。添加的参数就是新层。层是从输入端到输出端依次添加的，所以我们首先需要添加的是一个2D卷积层，该层使用3 × 3的卷积核处理输入图像。注意，我们没有指定图像的数量或小批量大小；当模型组建并训练时，Keras会处理这些问题。目前，我们定义的是架构。

使用[图12-3](ch12.xhtml#ch12fig3)中定义的架构，第一层是一个Conv2D层。第一个参数是过滤器的数量，这里为32。卷积核大小是一个元组(3, 3)。卷积核不一定是方形的，因此需要指定宽度和高度。实际上，输入的各部分之间的空间关系可能通过非方形卷积核更好地被检测到。如果是这种情况，Keras允许使用非方形卷积核。尽管如此，实际应用中几乎所有的卷积核都是方形的。接着，定义一个激活函数来应用于卷积层的输出，这里是ReLU。输入到这一层的形状通过input_shape显式定义，之前我们已经看到过，对于使用TensorFlow后端的MNIST模型，形状是一个元组(28, 28, 1)。

接下来，我们添加第二个卷积层。这个层有64个过滤器，仍然使用3 × 3的卷积核，并在输出上应用ReLU激活函数。注意，我们不需要在这里指定形状：Keras知道输入形状，因为它知道前一个卷积层输出的形状。

接下来是最大池化层。我们明确指定池化的大小是2 × 2，步幅隐含为2。如果我们想在这里使用平均池化，我们只需将MaxPooling2D替换为AveragePooling2D。

在池化层之后是我们的第一个丢弃层，它使用25%的概率丢弃一个输出，这里是来自最大池化层的输出。

我们之前讨论了 Keras 如何将全连接层的操作分解为 Flatten 层和 Dense 层。这使得对架构有了更细粒度的控制。我们添加了一个 Flatten 层，将池化输出映射到一个向量，然后将这个向量传递给 Dense 层，以实现经典的全连接层。该 Dense 层有 128 个节点，并使用 ReLU 作为激活函数。如果我们希望在 Dense 层的输出上使用 dropout，我们需要显式地添加它，因此我们添加了一个具有 50% 概率的 dropout 层。

最后一层 Dense 层有 10 个节点，每个节点对应一个可能的类别标签。激活函数设置为 softmax，以便在该层的输入上得到 softmax 输出。由于这是我们定义的最后一层，这一层的输出，即每个类别的 softmax 概率，是整个模型的输出。

为了配置模型进行训练，我们需要调用 compile 方法。这会设置在训练过程中使用的损失函数（loss）和使用的具体优化算法（optimizer）。metrics 关键词用于定义在训练过程中报告的指标。对于我们的示例，我们使用的是分类交叉熵损失，这是二元交叉熵损失的多类版本。我们在[第 9 章](ch09.xhtml#ch09)中描述了这个损失函数；它是许多 CNN 使用的标准损失函数。

我们需要更详细地讨论 optimizer 关键词。在[第 9 章](ch09.xhtml#ch09)中，我们介绍了梯度下降法和更常见的版本——随机梯度下降法。正如你所预期的，机器学习社区并不满足于直接使用这个算法；大量的研究已经进行，以便看看是否可以改进它来训练神经网络。这导致了梯度下降法的多种变体的出现，其中许多是 Keras 支持的。

如果我们愿意，可以在这里使用经典的随机梯度下降法。然而，本示例使用的是一种名为 *Adadelta* 的变体。它本身是 Adagrad 算法的变体，旨在在训练过程中智能地调整学习率（步长）。从实用的角度来看，我们可以将 Adadelta 视为随机梯度下降法的改进版本。Keras 还支持其他优化方法，我们不打算在这里讨论，但你可以在 Keras 文档中阅读到，特别是 Adam 和 RMSprop。

在调用 compile 后，我们的模型就定义好了。方便的方法 count_params 和 summary 会输出模型本身的特征。运行代码时，我们将看到它们生成的输出。

#### 训练与评估模型

最后，在定义了数据和模型后，我们可以训练模型并在测试数据上进行评估。相关的代码见[代码清单 13-3](ch13.xhtml#ch13lis3)。

history = model.fit(x_train, y_train,

batch_size=batch_size,

epochs=epochs,

verbose=1,

validation_data=(x_test, y_test))

score = model.evaluate(x_test, y_test, verbose=0)

print('Test loss:', score[0])

print('测试准确率:', score[1])

model.save("mnist_cnn_model.h5")

*列表 13-3：训练和测试 MNIST 模型*

fit 方法使用提供的训练样本（x_train）和相应的类标签的一种独热编码版本（y_test）来训练网络。我们还会传入训练轮次的数量和小批量大小。设置 verbose 为 1 将产生在[列表 13-4](ch13.xhtml#ch13lis4)中显示的输出。最后，我们有验证 _data。在这个例子中，我们有点马虎，直接传入了所有的测试数据，而没有留出一些用于最终测试。（毕竟这只是一个简单的示例。）通常情况下，我们会保留一些测试数据，用于最终模型训练完成后进行测试。这可以确保在这个留出的测试数据上的结果能够代表我们在实际应用中遇到的情况。

注意 fit 方法会返回某个结果。这是一个 History 对象，它的 history 属性保存了每个训练轮次的训练和验证损失以及准确率的摘要。我们可以使用这些信息绘制摘要图。

一旦模型训练完成，我们可以通过调用 evaluate 方法并传入测试数据来获得类似于 sklearn 中的得分。该方法返回一个列表，其中包含模型在提供的数据上的损失和准确率，我们只需要打印它。

我们可以使用 save 方法将模型本身写入磁盘以备将来使用。注意文件扩展名。Keras 会将模型保存为一个 HDF5 文件。*HDF5* 是一种通用的层次化数据格式，广泛应用于科学领域。在这种情况下，文件包含了模型的所有权重、偏差以及层结构。

运行此代码将生成在[列表 13-4](ch13.xhtml#ch13lis4)中显示的输出：

使用 TensorFlow 后端。

模型参数 = 1199882

层（类型）                 输出形状             参数数量

==============================================================

conv2d_1 (Conv2D)            (None, 26, 26, 32)        320

conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496

max_pooling2d_1 (MaxPooling2) (None, 12, 12, 64)        0

dropout_1 (Dropout)          (None, 12, 12, 64)        0

flatten_1 (Flatten)          (None, 9216)              0

dense_1 (Dense)              (None, 128)               1179776

dropout_2 (Dropout)          (None, 128)               0

dense_2 (Dense)              (None, 10)                1290

==============================================================

总参数: 1,199,882

可训练参数: 1,199,882

不可训练参数: 0

训练数据样本 60000 个，验证数据样本 10000 个

训练轮次 1/12 - 损失: 0.2800 准确率: 0.9147 验证损失: 0.0624 验证准确率: 0.9794

训练轮次 2/12 - 损失: 0.1003 准确率: 0.9695 验证损失: 0.0422 验证准确率: 0.9854

训练轮次 3/12 - 损失: 0.0697 准确率: 0.9789 验证损失: 0.0356 验证准确率: 0.9880

训练轮次 4/12 - 损失: 0.0573 准确率: 0.9827 验证损失: 0.0282 验证准确率: 0.9910

训练轮次 5/12 - 损失: 0.0478 准确率: 0.9854 验证损失: 0.0311 验证准确率: 0.9901

训练轮次 6/12 - 损失: 0.0419 准确率: 0.9871 验证损失: 0.0279 验证准确率: 0.9908

Epoch 7/12-loss:0.0397 acc:0.9883 val_loss:0.0250 val_acc:0.9914

Epoch 8/12-loss:0.0344 acc:0.9891 val_loss:0.0288 val_acc:0.9910

Epoch 9/12-loss:0.0329 acc:0.9895 val_loss:0.0273 val_acc:0.9916

Epoch 10/12-loss:0.0305 acc:0.9909 val_loss:0.0296 val_acc:0.9904

Epoch 11/12-loss:0.0291 acc:0.9911 val_loss:0.0275 val_acc:0.9920

Epoch 12/12-loss:0.0274 acc:0.9916 val_loss:0.0245 val_acc:0.9916

测试损失: 0.02452171179684301

测试准确率: 0.9916

*列表 13-4: MNIST 训练输出*

我们排除了来自较低级别的 TensorFlow 工具包的一些信息性和警告消息，并简化了输出内容，使其更易于在文本中跟随。

在运行开始时，Keras 会通知我们 TensorFlow 是我们的后端。它还显示了训练数据的形状，即现在熟悉的 60,000 个样本，形状为 28 × 28 × 1（×1 是因为图像是灰度图）。我们也有常规的 10,000 个测试样本。

接下来是关于模型的报告。该报告显示了层的类型、层输出的形状以及层中参数的数量。例如，第一个卷积层使用了 32 个滤波器和 3 × 3 的卷积核，因此，输入为 28 × 28 时，输出将是 26 × 26 × 32。每一层中列出的 None 表示通常会出现的 minibatch 元素数量的位置。输出显示的只是各层之间的关系；由于架构中没有任何内容会改变 minibatch 中元素的数量，所以不需要显式地提及 minibatch 元素（因此显示为 None）。参数为 3 × 3 × 32 的滤波器，另外还有 32 个偏置项，总共列出了 320 个参数。

如[第 12 章](ch12.xhtml#ch12)所述，模型中大部分的参数位于 Flatten 层和 Dense 层之间。名为 dense_2 的层是 softmax 层，它将 Dense 层的 128 个元素映射到 softmax 的 10 个元素：128 × 10 + 10 = 1290，其中额外的 10 个是偏置项。请注意，Dropout 和 Pooling 层没有参数，因为这些层中没有需要学习的内容。

在报告模型结构之后，我们会看到训练调用的详细输出，以进行拟合。我们请求了12个epoch——即12次完整的训练数据迭代——使用一个128样本的小批量。输出列出了每次迭代的统计数据。我们看到，随着训练的进行，损失逐渐降低，这是预期中的情况，表示模型正在学习，同时训练数据上的准确度（acc）也在上升。验证数据在训练过程中用于测试模型，但这些数据不会用于更新模型的权重和偏置。验证数据的损失每个epoch也在下降，但下降的速度较慢。我们不希望看到的是验证损失上升，尽管它可能会有一些波动，尤其是在验证集不够大的时候。我们在验证准确度（val_acc）上看到了相反的效果。它在每个训练epoch中都在上升。如果模型开始过拟合，我们会看到这种准确度在某个时刻开始下降。这就是验证数据的价值：告诉我们何时停止训练。

输出的最后两行是模型在通过evaluate方法传入的测试样本上的损失和准确度。由于在这个例子中验证集和测试集是相同的，这两行与epoch 12的输出匹配。该模型的最终准确率为99.16%——这无疑是一个非常好的准确率。

#### 绘制误差图

我们可以使用保存的历史数据来绘制损失或误差（1 - 准确度）与训练epoch的关系。图形形状相似，因此我们仅展示[图13-1](ch13.xhtml#ch13fig1)中的误差图。

![image](Images/13fig01.jpg)

*图13-1：MNIST训练和验证错误与epoch的关系*

训练数据上的误差迅速下降，正如我们之前所看到的，随着训练的进行，误差趋向于0。在这种情况下，验证误差稍微下降，然后在一个与训练误差相似的值上趋于平稳。在本书的这一部分，看到[图13-1](ch13.xhtml#ch13fig1)时，可能会让你感到警觉：最初的训练误差*大于*最初的验证误差！

这背后的完全原因很难确定，但其中一个因素是网络中使用了dropout。Dropout只在训练期间适用，由于在层中丢弃节点，dropout实际上是在同时训练多个模型，这最初会导致较大的误差，直到模型“稳定”下来，误差才会逐渐减少。我们可以看到，这可能正是这里的情况，因为如果我们仅仅注释掉[Listing 13-4](ch13.xhtml#ch13lis4)中的Dropout层并重新训练，我们会得到一张新的误差图，[图13-2](ch13.xhtml#ch13fig2)。

![image](Images/13fig02.jpg)

*图13-2：当没有Dropout层时，MNIST训练和验证错误与epoch的关系*

在[图 13-2](ch13.xhtml#ch13fig2)中，我们看到验证误差迅速大于训练误差，这是我们所预期的。此外，我们还看到，最终的验证误差比[图 13-1](ch13.xhtml#ch13fig1)中的最终验证误差大得多，大约是 10% 对比 1%。如果 Dropout 确实是一个合理的使用方法，我们也会预期这种结果。还要注意的是，在第 12 轮迭代后，无论是否存在 Dropout 层，训练集的误差大致相同。

最后，我们在[图 13-1](ch13.xhtml#ch13fig1)和[图 13-2](ch13.xhtml#ch13fig2)中看到的部分内容，实际上是由于 Keras 报告训练和验证准确度的方式所致。在每个迭代结束时报告的训练准确度（和损失）是该迭代的平均值，但显然，随着模型的学习，这个值会不断变化并趋于上升。然而，报告的验证准确度是针对迭代结束时模型的状态，因此，有时训练准确度可能会低于验证准确度。

现在我们已经了解了如何构建一个简单的 CNN 并在数据集上运行它，我们可以开始对 CNN 进行实验了。当然，我们可以进行无数的实验——看看新论文在 [arxiv.org](http://arxiv.org) 上的发布频率，或者机器学习会议的参会人数激增——因此，我们需要将自己限制在一些基本的探索中。希望这些能够激励你自己进一步探索。

### 基本实验

我们已经进行了一些实验，当我们移除 Dropout 层时。我们所有的实验都遵循相同的一般模式：创建一个略有不同的模型版本，训练它，并用测试集进行评估。我们将尝试三种不同类型的实验。第一种类型修改了模型的架构；移除 Dropout 层属于这一类别。第二种类型探索了训练集大小、最小批量大小和迭代次数之间的相互作用。最后一种类型则改变了训练过程中使用的优化器。

在这三种情况下，为了避免过多列出代码，我们将仅对上一节中代码的变化进行评论，理解剩余的代码在每个实验中是相同的。我们将为每个实验编号，你可以通过编号匹配结果找到实际的 Python 源代码。代码可以在与本书相关的网站上找到： *[https://nostarch.com/practical-deep-learning-python/](https://nostarch.com/practical-deep-learning-python/)*。

在上一节中，我们使用了整个60,000样本的训练集，以及10,000样本的测试集进行验证和最终测试。在这里，我们将限制使用前1,000或1,024个训练样本作为整个训练集。此外，我们将使用测试集的前1,000个样本作为验证集，并将剩余的9,000个样本保留作为训练完成后使用的最终测试集。我们将报告这些在训练过程中未曾见过的9,000张图像的准确率。结果将包括基准模型的准确率和参数数量，供比较使用。

请记住，除非另有说明，否则我们呈现的准确率代表每个实验的单次训练过程。如果你自己运行这些实验，结果可能会略有不同，但这些小的差异不应该超过因模型和/或训练过程的变化而导致的准确率的更大差异。

最后，本节中的模型为多分类模型，因此我们可以通过检查混淆矩阵来查看模型的错误。然而，对每个实验进行此操作将是极其繁琐的。相反，我们将使用总体准确率作为衡量标准，相信在这种情况下它足够准确。

#### 架构实验

架构修改意味着移除或添加新层，或更改层的参数。我们做了一些架构修改，并在[表 13-1](ch13.xhtml#ch13tab1)中汇总了相应的准确率。

**表 13-1：** 修改模型架构的结果

| **实验** | **修改** | **测试准确率** | **参数数量** |
| --- | --- | --- | --- |
| 0 | 基准 | 92.70% | 1,199,882 |
| 1 | 在池化前添加Conv3，3 × 3 × 64 | 94.30% | 2,076,554 |
| 2 | 重复Conv2、池化层 | 94.11% | 261,962 |
| 3 | 将Conv1，3 × 3 × 32更改为5 × 5 × 32 | 93.56% | 1,011,978 |
| 4 | 将全连接层节点数设置为1,024 | 92.76% | 9,467,274 |
| 5 | Conv1、Conv2，滤波器数量减半 | 92.38% | 596,042 |
| 6 | 第二个全连接层，节点数为128 | 91.90% | 1,216,394 |
| 7 | 将全连接层节点数设置为32 | 91.43% | 314,090 |
| 8 | 移除池化层 | 90.68% | 4,738,826 |
| 9 | 卷积层后不使用ReLU | 90.48% | 1,199,882 |
| 10 | 移除Conv2 | 89.39% | 693,962 |

在[表 13-1](ch13.xhtml#ch13tab1)中，首先给出了基准结果和模型大小，随后列出了从最准确到最不准确的各种实验。让我们来看看表格并解读结果。

首先，我们看到在第二个卷积层后添加第三个卷积层（实验1）提高了模型的性能，但也增加了876,672个参数。增加网络深度似乎能够提高模型的性能，但代价是增加了参数数量。

然而，在实验2中，我们还通过复制第二个卷积层和随后的池化层来增加网络的深度，但由于第二个池化层的存在，网络中的总参数数减少了937,920个。这是一个相当大的节省，并且几乎没有影响性能。这表明，深度是有好处的，但合理使用池化层来保持参数数量小也是有益的。对于这个数据集，实验2是一个稳健的架构选择。

接下来，我们看到对第一个卷积层核大小的调整（实验3）相对于基准模型有所改进。第一个卷积层的参数更多（832比320），但是由于使用精确卷积时的边缘效应，到达Flatten层输出时，参数值已经从基准模型的9,216个减少到7,744个。这意味着，Flatten和Dense层之间的大矩阵从1,179,776个参数减少到991,360个参数，最终结果是，整个模型减少了187,904个参数。

这样很好：更好的性能和更少的参数需要学习。实验3的变化有不好的地方吗？其实没有。相反，有人可能会认为，调整第一个卷积层的核大小使得模型更适应数字图像中的空间信息，从而使卷积和池化层学习到的新表示在分类上表现得更加优秀。一般来说，似乎对于第一个卷积层（即处理模型输入的层）来说，存在一个最佳的核大小。这个核大小与输入的空间结构有关：某些大小在检测有助于区分类别的输入特征时会表现得更好。这个普遍规律似乎不适用于更高的卷积层，在这些层中，普遍的做法是对于大多数卷积层（除了第一个层）使用3 × 3的核。

我们可以将实验3和实验2结合起来吗？当然可以。我们只需将实验2中的第一个卷积层使用5 × 5的核，而不是3 × 3的核。如果这样做，我们可以得到一个总准确率为94.23%的模型，且只需要188,746个参数。通过这个微小的改变，我们仅使用了9%的参数就达到了实验10的性能。

你可能会想简单地增加Dense层的大小，这一层可以看作是利用卷积和池化层下方发现的新特征表示。然而，这样做（实验4）并没有带来总体准确率的实质性提升，反而大幅增加了参数数量。我们知道原因：Flatten和Dense层之间的9,216 × 128权重矩阵现在变成了9,216 × 1,024的矩阵。显然，对于卷积神经网络（CNNs）来说，我们希望创建最佳的特征表示，以便使用更简单的顶层结构。

在实验5中，我们看到通过简单地将每个卷积层中学习到的滤波器数量减半，我们可以显著减小模型的规模，减少603,840个参数，同时仍然保持相同的总体准确度：Conv1从32减到16，Conv2从64减到32。再次说明，这是一个不错的优化，前提是可以接受准确度上的轻微（也许在这种情况下毫无意义）差异。如果我们再次查看[图12-8](ch12.xhtml#ch12fig8)，可以看到，尤其是对于第二个卷积层的64个滤波器，许多滤波器的响应非常相似。这意味着存在冗余的滤波器，它们并未为呈现给Dense层的新特征表示做出太多贡献。尽管我们将滤波器数量减半，但仍然有一些滤波器能学习到输入数据中重要的方面，用于区分不同类别。

实验7对Dense层的节点进行了调整，实验6则添加了第二个Dense层。两者都没有带来实质性的好处。在实验7中，由于9,216 × 128的矩阵权重变为9,216 × 32矩阵，模型参数的变化较大。然而，32个节点似乎并不是理想的数量，无法充分利用新的特征表示。实验6中的第二个Dense层在增加学习参数的数量方面并不算糟糕，但它也没有带来太多好处。如果我们使用更大的训练集，可能会有所改善，但我们将这部分留给读者作为练习。

在上一章中，我们讨论了对池化层的批评。如果完全去掉池化层会怎样（实验8）？首先，我们看到相较于基线模型，准确率有所下降。更糟糕的是，我们看到网络的规模大幅增加，从1,199,882个参数增至4,738,826个，几乎是原来的四倍。这是由于Flatten层输出的元素数量增加，已从9,216增加到36,864，导致了一个36,864 × 128 + 128 = 4,718,720的权重矩阵。这个例子说明了即使池化层带来了关于物体部件相对位置的信息丧失，仍然需要使用池化层的原因。

基线模型中的每个卷积层都会对其输出使用ReLU激活函数。去除这些ReLU操作后，实验9在测试集上的准确率减少了2个百分点。显然，ReLU在一定程度上起到了帮助作用。它可能在做什么呢？ReLU保持正值不变，将负值设为0。当与卷积层的输出一起使用时，ReLU有助于保持对滤波器强烈激活的响应（即正响应），同时抑制负响应。这似乎有助于整个学习输入新表示的过程。

最后，实验10完全去除了Conv2层。这个变化对整体准确率有最大影响，因为传递到Dense层的特征仅基于第一层卷积层的输出。没有机会让模型从这些输出中学习，并基于第二层卷积层看到的更大有效感受野开发滤波器响应。

然而，考虑到我们在实验3中的结果，该实验增加了第一层卷积层使用的核大小，我们可能会想，这个从3×3到5×5的核变化是否在某种程度上能够弥补第二层卷积层的缺失。幸运的是，这很容易验证。我们只需将Conv1的3×3核参数改为5×5，并重新训练。这样做验证了我们的直觉：最终的整体准确率提高到92.39％，几乎与基线模型相同。而且，这个5×5模型只有592,074个参数，相比模型参数的数量，这个变化并不昂贵。

从所有这些结果来看，我们是否找到了一个赢家，一个简洁但高效的架构？我们找到了——那就是实验2，它将第一层卷积层的核大小设置为5×5。在Keras中，要构建这个架构，我们需要[Listing 13-5](ch13.xhtml#ch13lis5)中的代码。

model = Sequential()

model.add(Conv2D(32, kernel_size=(5, 5),

activation='relu',

input_shape=input_shape))

model.add(Conv2D(64, (3, 3), activation='relu'))

model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Dropout(0.25))

model.add(Conv2D(64, (3, 3), activation='relu'))

model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Dropout(0.25))

model.add(Flatten())

model.add(Dense(128, activation='relu'))

model.add(Dropout(0.5))

model.add(Dense(num_classes, activation='softmax'))

*Listing 13-5：为实验2构建架构*

我们仅仅复制了Conv2D、MaxPooling2D和Dropout层，并且将第一层的核大小设置为(5,5)。

如果我们使用MNIST训练集中的所有60,000个样本训练该模型，我们将得到一个最终的保留测试集准确率为99.51％，误差为0.49％。这是使用所有10,000个样本得到的结果。根据[benchmarks.ai](http://benchmarks.ai)，这是一个追踪当前不同机器学习数据集最佳表现的网站，当前最先进的MNIST误差为0.21％，因此我们不是最先进的，但我们比在[Listing 13-4](ch13.xhtml#ch13lis4)中看到的默认架构的99.16％准确率要好。

#### 训练集大小、迷你批次和周期

这些实验考察了训练集大小、迷你批次大小和周期数之间的相互作用。我们的模型将是我们之前使用的默认模型，即实验0，但这次我们将使用1,024个样本作为训练集。我们将使用2的幂作为迷你批次的大小；这是一个方便的大小，因为所有的迷你批次大小都能均匀地划分它。

回想一下，Keras和sklearn一样，都会运行给定的周期数，即完全通过训练集的次数。此外，迷你批量大小（batch_size）指定了每次迭代中使用的样本数量，之后使用平均误差（交叉熵损失）来更新参数。因此，每处理一个迷你批量，就会进行一次梯度下降步骤，训练集大小除以迷你批量大小就是每个周期内进行的梯度下降步骤数。

对于我们的实验，我们将使用以下迷你批量大小：

1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024

对于一个包含1,024个样本的训练集（每个数字大约100个样本），每个周期的梯度下降步数是该列表的逆序：当批量大小为1时为1,024，批量大小为1,024时为1。

让我们生成两个图。第一个图将绘制两种情况的最终测试集准确率：无论迷你批量大小如何，固定梯度下降步数，以及无论迷你批量大小如何，固定周期数。第二个图将显示每种情况下训练模型的时钟时间。导致这些图的代码位于实验26至31（固定梯度下降步数）和实验32至42（固定周期数）。

测试集准确率作为迷你批量大小的函数，以五次运行的平均值呈现，见[图13-3](ch13.xhtml#ch13fig3)，误差条表示均值的标准误差。让我们看看无论迷你批量大小如何固定梯度下降步数（用三角形表示）。在某些工具包中，这被称为使用固定的迭代次数，其中*迭代*指的是一次更新，导致一次梯度下降步。

![image](Images/13fig03.jpg)

*图13-3：MNIST测试集准确率作为迷你批量大小与固定梯度下降步数或固定周期数的函数*

梯度下降步数固定为1,024。意味着我们需要根据训练集中每个迷你批量的数量来调整周期数。对于每次更新使用单个样本的情况（batch_size=1），我们在一个周期内获得所需的1,024步，因此我们将周期数设置为1。对于迷你批量大小为2的情况，我们每个周期获得512步，因此我们将代码中的周期数设置为2，以获得1,024步。这个模式继续下去：为了每个迷你批量大小获得1,024个梯度下降步数，我们需要将周期数设置为迷你批量大小。

我们看到，除了最小的迷你批量大小外，当我们固定梯度下降的步数时，我们得到的整体准确率非常一致。大约16的迷你批量大小后，变化不大。对于卷积神经网络（CNNs），一般的规则是使用较小的批量大小。这似乎有助于提高模型在像MNIST这样不是那么简单的数据集上的泛化能力，正如我们很快会看到的，它显著减少了训练时间。

[图13-3](ch13.xhtml#ch13fig3)中的第二条曲线展示了在固定轮次下的准确率（圆圈）。如果我们改变小批量的大小，但不增加训练轮次以保持梯度下降步骤数不变，我们将使用更大且更好的梯度估计，但同时我们也会采取更少的步骤。我们看到，这样做很快会导致准确率显著下降。我们不应该感到惊讶。使用小批量大小为1时，训练12个轮次给我们带来了一个模型，它需要12 × 1,024 = 12,288个梯度下降步骤。当然，由于我们仅使用一个训练样本来估计梯度，估计结果在这种情况下尤其嘈杂，但由于步骤较多，我们依然得到了一个表现良好的模型。当我们增加到1,024个样本的小批量时，即我们整个训练集的大小，我们看到在结束训练前，我们只进行了12个梯度下降步骤。难怪结果如此差劲。

本节的第二张图是[图13-4](ch13.xhtml#ch13fig4)。

![image](Images/13fig04.jpg)

*图13-4：模型训练时间与小批量大小和固定梯度下降步骤或固定训练轮次的关系*

与之前一样，让我们从固定的梯度下降步骤数（三角形）开始。我们可以立刻看到，训练时间与小批量大小成线性关系。这是合理的，因为我们刚刚看到，为了保持梯度下降步骤数不变而增加小批量大小时，必须增加训练轮次。因此，传递给网络的数据量也在成比例增加，前向和反向训练传播所需的时间也会成比例增加。从这一点来看，大的小批量大小会增加训练时间。

对于固定的训练轮次，我们看到一个不同的情况。对于极小的小批量大小，由于前向和反向传播的次数增加，训练时间也会增加。在小批量为1的情况下，我们需要12,288次这样的传播，就如我们刚才看到的那样。然而，当我们使用每次32个样本的小批量时，我们每个轮次只需要进行1024/32 = 32次传播，总共进行384次传播。这比最小的小批量次数少得多，因此我们可以预期，对于这种大小或更大的小批量，训练时间大致会保持不变，正如我们在[图13-4](ch13.xhtml#ch13fig4)中看到的那样。

从这两张图中我们可以得出什么结论？以下几点：为了平衡运行时间和准确性，我们希望使用足够大的小批量大小来合理估计梯度，但又要小到足以在固定数量的模型更新（梯度下降步骤）下快速训练。这就意味着通常小批量大小应在16到128之间。实际上，深度学习文献中几乎所有应用都采用这个范围的小批量大小。以这个例子为例，基于[图13-3](ch13.xhtml#ch13fig3)（三角形标记），16以上的小批量大小，训练结果基本相同，但根据[图13-4](ch13.xhtml#ch13fig4)（三角形标记），使用16的小批量大小的模型训练时间是几秒钟，而使用1,024的小批量大小则约为30分钟。

#### 优化器

到目前为止，我们的所有实验都使用了相同的梯度下降算法，或者说优化器：Adadelta。让我们来看一下如果我们更换优化器而其他条件保持不变，MNIST模型的表现如何。我们的模型是实验 0，也就是本章中一直使用的模型。我们将继续使用1,000个测试样本进行验证，并用9,000个样本来确定最终准确性。然而，代替使用前1,000个或1,024个训练样本，我们将训练样本数增加到前16,384个样本。我们将小批量大小固定为128，训练周期数设为12，与之前相同。我们将报告结果为五次实验的均值和标准误差。

Keras目前支持以下优化器：随机梯度下降（SGD）、RMSprop、Adagrad、Adadelta和Adam。我们将依次使用这些优化器进行训练。对于Adagrad、Adadelta和Adam，我们保持参数为Keras文档推荐的默认设置。对于RMSprop，Keras文档推荐调整的唯一参数是学习率（lr），我们将其设置为0.01，这是一个典型的值。对于SGD，我们同样将学习率设置为0.01，并将标准动量设置为0.9，这也是一个非常典型的值。代码可以在实验43到47中找到。

[图13-5](ch13.xhtml#ch13fig5)显示了每个优化器的测试集准确性（上）和训练时间（下）。

![image](Images/13fig05.jpg)

*图13-5：按优化算法分的测试集准确性（上）和训练时间（下）*

首先，注意到每个优化器的结果差异并不大。这是一个好消息。然而，通过观察误差条，似乎很明显Adadelta、Adagrad和Adam的表现略优于SGD或RMSprop。这在深度学习文献中也得到了证实，尽管每个数据集应该单独分析。

在训练时间方面，不同的优化器大致相同，尽管SGD速度最快并且始终如此。这个性能差异对于非常大的数据集可能很重要。Adam也始终比Adadelta更快，而且性能几乎相同。再说一次，这些结果在文献中是显而易见的，SGD和Adam广泛使用。

本节详细介绍了与更改模型架构和训练参数相关的细节。希望它能够帮助你对如何配置CNN以及如何训练它产生直观理解。在这个领域，很难提出固定的经验法则，但我已经给出了一些一般性的指导。然而，这些规则也有很多例外，你需要通过尝试不同的方法、观察结果并根据新的数据集进行调整。

现在，让我们从对简单输入进行分类转到如何制作一个能够在任意图像中定位目标的模型。

### 完全卷积网络

我们在[第12章](ch12.xhtml#ch12)中介绍了完全卷积网络。让我们将基础的MNIST CNN模型转换为完全卷积版本，看看如何使用它来定位更大图像中的数字。我们基本的方法是首先使用完全连接层训练模型，然后创建一个完全卷积版本，并用完全连接模型的权重更新它。之后，我们可以将新模型应用于任意大小的输入来定位数字（希望如此）。

#### 构建与训练模型

首先，我们在完整的MNIST数据集上训练我们的基础模型。我们唯一的变化是将训练周期数从12增加到24。此过程的输出是一个包含训练好的权重和偏置的HDF5文件。接下来，我们只需要通过修改完全连接层来创建完全卷积版本，并将旧模型的权重和偏置复制到新模型中。这个过程的代码很简单，如[Listing 13-6](ch13.xhtml#ch13lis6)所示。

from keras.models import Sequential, load_model

from keras.layers import Dense, Dropout, Flatten

from keras.layers import Conv2D, MaxPooling2D

❶ weights = load_model('mnist_cnn_base_model.h5').get_weights()

model = Sequential()

model.add(Conv2D(32, kernel_size=(3, 3),

activation='relu',

❷ input_shape=(None,None,1)))

model.add(Conv2D(64, (3, 3), activation='relu'))

model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Dropout(0.25))

❸ model.add(Conv2D(128, (12,12), activation='relu'))

model.add(Dropout(0.5))

❹ model.add(Conv2D(10, (1,1), activation='softmax'))

❺ model.layers[0].set_weights([weights[0], weights[1]])

model.layers[1].set_weights([weights[2], weights[3]])

model.layers[4].set_weights([weights[4].reshape([12,12,64,128]), weights[5]])

model.layers[6].set_weights([weights[6].reshape([1,1,128,10]), weights[7]])

model.save('mnist_cnn_fcn_model.h5')

*Listing 13-6: 创建训练好的完全连接模型*

导入所需的Keras模块后，我们从全连接模型中加载训练好的权重❶。然后，我们构建完全卷积的版本，就像我们为全连接版本所做的那样。然而，这里有一些关键的不同之处。第一个不同之处在于输入卷积层❷。在全连接模型中，我们在这里指定了输入图像的大小，28×28像素，单通道（灰度）。对于完全卷积的情况，我们并不知道输入的大小，所以我们使用`None`来表示宽度和高度。我们知道输入将是单通道图像，所以我们保留1。

由于Dense层是我们需要使用固定大小输入的原因，因此我们将它们替换为等效的卷积层❸。我们将

model.add(Flatten())

model.add(Dense(128, activation='relu'))

with

model.add(Conv2D(128, (12,12), activation='relu'))

(12, 12)是上面最大池化层的输出大小，而128是学习的过滤器数量，代表之前的128个节点。再次强调，这里关键的一点是，这个卷积层的输出是1 × 1 × 128，因为12 × 12的输入与12 × 12的卷积核进行卷积，输出一个值。不同之处在于，卷积层不再像Flatten和Dense组合那样依赖于固定的输入大小。

最后的softmax层也需要变成完全卷积的❹。这里有十个输出，每个输出对应一个数字，激活函数保持不变。然而，卷积核的大小是1 × 1。此层的输入是1 × 1 × 128，因此覆盖它的卷积核大小也是1 × 1。再一次，如果我们通过数学运算，能发现1 × 1 × 128的输入与1 × 1 × 10的卷积层输出是匹配的，这就像一个128节点的全连接层映射到下一个层的10个节点。区别在于，如果输入大于1 × 1，我们仍然可以对其进行卷积操作。

现在我们已经构建了模型的完全卷积版本，接下来需要将训练好的全连接模型的权重复制到这个模型中❺。我们将训练好的权重加载到`weights`中。这个`weights`是一个包含每一层权重和偏置的NumPy数组列表。所以，weights[0]表示第一个Conv2D层的权重，而weights[1]是偏置。同样，weights[2]和weights[3]分别表示第二个卷积层的权重和偏置。我们通过`set_weights`方法更新新模型的相应层来设置这些权重。层0和层1是两个卷积层。

层4是新的Conv2D层，取代了原始模型中的Flatten和Dense层。在设置权重时，我们需要将它们重塑成卷积层的形式：12 × 12 × 64 × 128。这是针对12 × 12的卷积核在64个输入上进行卷积，输出128个结果。64是来自上面池化层的12 × 12输出的数量。

最后，我们设置输出层的权重。同样，我们需要将它们调整为 1 × 1 × 128 × 10，以适应 1 × 1 × 128 的输入和 10 个输出。两个新的 Conv2D 层的偏置在 weights[5] 和 weights[7] 中，因此我们也需要将它们加进去。

现在，全卷积模型已经定义并完全填充了来自全连接模型的权重和偏置。[图 13-6](ch13.xhtml#ch13fig6) 显示了模型之间的映射，左边是原始架构，右边是全卷积架构。方框表示层，顶部的数字是输入，底部是输出。对于全卷积模型，输入的高度和宽度是任意的，并标记为“--”。

![image](Images/13fig06.jpg)

*图 13-6: 将全连接模型（左）映射到全卷积模型（右）*

剩下的就是将新的全卷积模型写入磁盘，它就可以准备使用了。我们来看一下怎么做。

#### 制作测试图像

为了测试全卷积模型，我们首先需要带有数字的图像。与我们用于训练的图像不同，训练图像很小且只有一个数字在中央，而我们现在需要的是较大的测试图像，图像中包含许多数字，位置是任意的。MNIST 数据集由黑色背景上的灰度阴影组成；因此，我们的测试图像也应该有黑色背景。这将使得测试图像与训练图像来自相同的“领域”，正如我们之前强调过的，这一点至关重要。让模型适应不同数据领域是一个活跃的研究领域。请搜索 *领域适应*。

使用 Python 和 MNIST 测试集中的数字制作测试图像是直接的。我们没有使用测试集图像进行训练，因此使用它们来制作更大的测试图像并不算作弊。代码见[清单 13-7](ch13.xhtml#ch13lis7)。

import os

import sys

import numpy as np

import random

from PIL import Image

os.system("rm -rf images; mkdir images")

if (len(sys.argv) > 1):

N = int(sys.argv[1])

else:

N = 10

x_test = np.load("data/mnist/mnist_test_images.npy")

for i in range(N):

❶ r,c = random.randint(6,12), random.randint(6,12)

g = np.zeros(r*c)

❷ for j in range(r*c):

if (random.random() < 0.15):

g[j] = 1

g = g.reshape((r,c))

g[:,0] = g[0,:] = g[:,-1] = g[-1,:] = 0

❸ img = np.zeros((28*r,28*c), dtype="uint8")

for x in range(r):

for y in range(c):

if (g[x,y] == 1):

❹ n = random.randint(0, x_test.shape[0])

im = x_test[n]

img[28*x:(28*x+28), 28*y:(28*y+28)] = im

Image.fromarray(img).save("images/image_%04d.png" % i)

*清单 13-7: 构建大型 MNIST 测试集图像*

我们使用的是在[第 5 章](ch05.xhtml#ch05)中创建的 MNIST 测试集文件。我们也可以像之前在基本 CNN 实验中一样，通过 Keras 加载测试图像。代码本身创建了一个输出目录，*images*，并从命令行获取要构建的图像数量（如果给定的话，N）。

这些图像的尺寸是随机的❶。这里，r 和 c 是大图像中行和列的数量，单位是 28 × 28 的 MNIST 数字。为了决定我们放置数字的位置，以免它们重叠，我们创建了一个网格 g，在每个可能的数字位置（r*c 个位置）上放置 0 或 1❷。任意网格位置有 15% 的概率会包含 1。接着，我们将网格重塑为一个实际的 2D 数组，并将网格的边界位置设为 0，以确保没有数字出现在图像的边缘。

实际输出图像的定义是：当行和列的数量与 28（MNIST 数字的宽度和高度）相乘时，我们遍历每个数字位置（x 和 y），如果该行列的网格值为 1，则我们随机选择一个数字并将其复制到输出图像（img）的当前行列位置❹。当每个网格位置都被检查完毕后，图像会被写入磁盘，以便我们能将其用于完全卷积网络。

#### 测试模型

让我们来测试这个模型——首先是单个的 MNIST 数字，然后是随机生成的大数字图像。这个完全卷积模型应该和完全连接模型一样，在单个 MNIST 数字上表现得很好。用来验证这一说法的代码在[清单 13-8](ch13.xhtml#ch13lis8)中。

import numpy as np

from keras.models import load_model

x_test = np.load("data/mnist/mnist_test_images.npy")/255.0

y_test = np.load("data/mnist/mnist_test_labels.npy")

model = load_model("mnist_cnn_fcn_model.h5")

N = y_test.shape[0]

nc = nw = 0.0

for i in range(N):

❶ p = model.predict(x_test[i][np.newaxis,:,:,np.newaxis])

c = np.argmax(p)

if (c == y_test[i]):

nc += 1

else:

nw += 1

print("单个 MNIST 数字，n=%d，准确率 = %0.2f%%" % (N, 100*nc/N))

*清单 13-8：验证完全卷积模型是否能处理单个 MNIST 数字*

我们加载 MNIST 测试图像和标签，以及完全卷积模型，然后遍历每个测试图像并请求模型进行预测❶。请注意，图像是 2D 的，但我们必须传递一个 4D 数组给预测方法，因此使用 np.newaxis 来创建缺失的轴。数字的预测结果存储在 p 中，作为每个类别的概率向量。与这些概率最大值对应的标签是模型分配给输入数字的标签 c。如果 c 与实际的测试标签匹配，我们就增加正确预测的数量 (nc)；否则，增加错误预测的数量 (nw)。一旦所有 10,000 张测试图像处理完毕，我们就可以输出整体的准确率，对于我训练的完全卷积模型，准确率为 99.25%。

好的，完全卷积模型非常准确，但这又有什么意义呢？我们曾经将单数字图像作为输入，并获得一个输出值。在完全连接模型中，我们已经具备了这种能力。为了展示完全卷积模型的实用性，现在让我们将大尺寸的MNIST数字图像作为输入。在代码中，我们通过[清单 13-9](ch13.xhtml#ch13lis9)来实现。

import os

import numpy as np

from keras.models import load_model

from PIL import Image

model = load_model("mnist_cnn_fcn_model.h5")

os.system("rm -rf results; mkdir results")

n = len(os.listdir("images"))

for i in range(n):

f = "images/image_%04d.png" % i

❶ im = np.array(Image.open(f))/255.0

p = model.predict(im[np.newaxis,:,:,np.newaxis])

np.save("results/results_%04d.npy" % i, p[0,:,:,:])

*清单 13-9：在大尺寸测试图像上运行完全卷积模型*

我们导入必要的模块，然后加载完全卷积模型。接着，我们创建一个新的输出目录，*results*，并找到大尺寸数字图像的数量（n）。然后，我们遍历每一张大尺寸数字图像。

在从磁盘加载图像后，我们小心地将其转换为NumPy数组并通过255进行缩放，因为训练数据也经过了相同的缩放❶，然后进行预测并将模型输出存储在p中。请注意，我们对predict方法使用了4D输入，就像之前处理单数字图像时一样，但这次im的大小超过了28 × 28并包含了多个数字。由于模型是完全卷积的，这不会出现问题；我们不会得到错误。相反，p是一个4D数组，其中第一个维度为1，表示输入图像的数量，最后一个维度为10，表示数字的数量。p的中间两个维度是传递给predict方法的输入大小的函数。由于输入大于28×28像素，整个模型像一个28 × 28的卷积核一样卷积输入图像。具体来说，这次卷积的输出具有以下高度和宽度：

![image](Images/334equ01.jpg)

其中，*H*、*W*是输入图像的高度和宽度，*h*、*w*是从预测得到的输出数组的高度和宽度。公式中的28是我们最初训练时输入的大小，即28 × 28的数字图像。那么，分母中的神秘2从哪里来呢？这是28 × 28卷积核在输入图像上滑动的步幅（stride）。它是2，因为这是输入图像在经过两层卷积层和池化层后变换到完全卷积输出层时的变化因子。输入是28 × 28，但在经过两层卷积层和池化层后，输入图像映射为12 × 12，并且⌊28/12⌋ = 2。

我们之前提到p中的数组是4D的；现在我们知道，基于步幅为2的情况下，将28 × 28区域卷积到输入图像上，我们将得到一个特定大小的输出。那么在每个*h*，*w*输出数组位置上我们会得到什么？4D输出的最后一个元素大小为10；这些是对应28 × 28核的特定*h*，*w*输出位置的每类预测。

让我们将这个抽象描述变得更加具体。[图13-7](ch13.xhtml#ch13fig7)的左上角展示了其中一张大输入图像，我们已将其反转，使其呈现为黑色背景上的白色图像，并添加了边框，以便能够看到图像的完整大小。

![image](Images/13fig07.jpg)

*图13-7：全卷积模型对左上方输入图像的每个数字的热力图输出。该模型是在标准MNIST数据集上训练的。*

[图13-7](ch13.xhtml#ch13fig7)左上方的图像宽度为336像素，高度为308像素，这意味着将该图像输入模型后，输出将是一个1 × 141 × 155 × 10的数组，这正是我们从第744页的输出数组维度方程中预期的。该输出数组表示模型在使用步幅为2的情况下，对输入图像28 × 28区域的每个位置的预测。每个数字都有一个预测。例如，如果p是[图13-7](ch13.xhtml#ch13fig7)左侧图像的预测方法的4D输出，那么p[0,77,88,:]将返回一个包含10个元素的向量，表示图像28 × 28输入区域（映射到77 × 88）的每个数字类别的类概率。在这种情况下，我们得到以下结果：

array([0.10930195, 0.12363277, 0.131005  , 0.10506018, 0.05257199,

0.07958104, 0.0947836 , 0.11399861, 0.08733559, 0.10272926],

dtype=float32)

这告诉我们，根据模型的判断，在该位置没有强烈的可能性显示任何特定的数字。我们知道这一点，因为所有的输出概率都远低于0.5的最小阈值。predict的输出可以视为一个概率图，通常称为*热力图*，它给出了该位置是否有数字的概率。模型输出可以看作是10个热力图，每个数字一个热力图。

[图13-7](ch13.xhtml#ch13fig7)中的剩余图像显示了每个数字的热力图，再次进行了反转，使得较高的概率值显示为较暗。热力图在0.98的阈值下被处理，这意味着任何低于0.98的概率值都被设置为0。这去除了像我们刚才看到的那些较弱的输出。我们只关心模型在每个数字上的最强响应。为了制作热力图，我们将模型输出的大小加倍，并设置输出图像的位置，利用偏移量来考虑卷积输出的位置。这类似于我们在[图12-1](ch12.xhtml#ch12fig1)中看到的情况，其中卷积操作返回的输出比输入要小，当没有使用零填充时。具体来说，生成数字热力图的代码位于[列表13-10](ch13.xhtml#ch13lis10)中。

import os

import sys

import numpy as np

from PIL import Image

❶ threshold = float(sys.argv[1])

iname = sys.argv[2]

rname = sys.argv[3]

outdir= sys.argv[4]

os.system("rm -rf %s; mkdir %s" % (outdir, outdir))

❷ img = Image.open(iname)

c,r = img.size

hmap = np.zeros((r,c,10))

res = np.load(rname)

x,y,_ = res.shape

xoff = (r - 2*x) // 2

yoff = (c - 2*y) // 2

❸ for j in range(10):

h = np.array(Image.fromarray(res[:,:,j]).resize((2*y,2*x)))

hmap[xoff:(xoff+x*2), yoff:(yoff+y*2),j] = h

np.save("%s/graymaps.npy" % outdir, hmap)

❹ hmap[np.where(hmap < threshold)] = 0.0

for j in range(10):

img = np.zeros((r,c), dtype="uint8")

for x in range(r):

for y in range(c):

❺ img[x,y] = int(255.0*hmap[x,y,j])

img = 255-img

Image.fromarray(img).save("%s/graymap_digit_%d.png" % (outdir, j))

*列表13-10：构建热力图图像*

在这里，我们将输出图像称为*graymaps*，因为它们是灰度图像，表示模型对输入图像不同位置的响应。我们首先传入阈值、源图像名称、模型对该源图像的响应以及灰度图像将被写入的输出目录❶。该目录每次都会被覆盖。接下来，加载源图像以获取其尺寸❷。这些尺寸用于创建输出热力图（hmap）。我们还加载相关的模型响应（res）并计算偏移量。请注意，hmap与图像大小相同。然后，我们将每个数字的灰度图（hmap）填充为调整大小后的模型响应❸，并将完整的灰度图集存储在输出目录中。

为了生成像[图13-7](ch13.xhtml#ch13fig7)中所示的灰度输出图像，我们首先对热力图进行阈值处理，将任何小于指定截止值的数值设置为0 ❹。然后，对于每个数字，我们创建一个输出图像，并简单地通过255缩放剩余的热力图值，因为它们是[0,1)范围内的概率值 ❺。接下来，在将图像写入磁盘之前，我们通过从255中减去这些值来反转颜色。这使得较强的激活显示为较暗的颜色，而较弱的激活则为较亮的颜色。由于施加了强阈值（0.98），我们的输出灰度图实际上是二进制的；这正是我们想要的，用以表示模型最确定数字所在的位置。

让我们回头看看[图13-7](ch13.xhtml#ch13fig7)，看看我们能否解读这些反应。源图像的右下角有一个0。如果我们查看数字0的灰度图，我们会看到这个位置有一个深色的斑点。这意味着模型已经强烈地表示在这个位置有一个0数字。到目前为止，一切顺利。然而，我们也看到模型在输入图像左侧靠近4的地方有另一个强烈反应。模型犯了一个错误。输入图像中有两个4。如果我们查看数字4的灰度图，我们会看到对应这两个数字的两个深色斑点，但我们也看到许多其他小的强激活区域，出现在其他不是4的数字附近。我们训练的模型在单个MNIST测试数字上的准确率超过了99%，那么为什么完全卷积模型的反应如此嘈杂呢？只要看看所有关于数字2的小的强反应，当输入中并没有包含任何2时。有时候，模型表现得很好，比如在数字8上，灰度图显示了输入中所有8的强烈反应，但对于其他数字，如7，它表现得很差。而且，完全没有5，但模型却返回了许多匹配的结果。

这是一个让我们扩展思维和直觉的机会。我们在标准的MNIST数字数据集上训练了模型。这个数据集中的所有数字都在图像中很好地居中。然而，当模型对大输入图像进行卷积时，很多时候输入给模型的并不是一个居中的完整数字，而只是一个数字的一部分。模型从未见过部分数字，并且因为它必须给出答案，所以它有时会给出无意义的答案——它看到的数字部分可能是6的一部分，例如，但模型却“认为”它是5。

一种可能的解决方案是教模型识别部分的 MNIST 数字。我们可以通过将标准 MNIST 数据集与其数字的平移版本进行增强来实现这一点。假设数字 4 被平移到右下方，只露出部分。它仍然会被标记为 4，这样模型就有机会学习到平移后的 4 的样子。创建这个平移数据集的代码在 *make_shifted_mnist_dataset.py* 文件中，但我们这里只展示创建平移版 MNIST 数字副本的函数。该函数会被每个训练和测试图像调用四次（以创建一个平移后的测试数据集）。我们保留原始居中的数字和它的四个随机平移副本，从而生成一个比原始数据集大五倍的数据集。随机平移的函数是。

def shifted(im):

r,c = im.shape

x = random.randint(-r//4, r//4)

y = random.randint(-c//4, c//4)

img = np.zeros((2*r,2*c), dtype="uint8")

xoff = r//2 + x

yoff = c//2 + y

img[xoff:(xoff+r), yoff:(yoff+c)] = im

img = img[r//2:(r//2+r),c//2:(c//2+c)]

return img

其中 im 是作为 NumPy 数组提供的输入图像。根据输入大小，我们选择随机的 x 和 y 平移，平移量可以是正的或负的，最大为图像大小的四分之一。将这一限制调整为三分之一或二分之一也是值得实验的。创建一个新图像（img），其大小是原图的两倍。然后根据平移位置将原图放入大图中，并返回大图中与输入图像尺寸匹配的中心部分，作为输入图像的平移版本。

要使用增强的数据集，我们首先需要重新训练全连接的 MNIST 模型，然后使用新的权重和偏置重建全卷积模型，最后像以前一样将大尺寸测试图像输入模型。完成这些操作后，会得到新的灰度图（[图 13-8](ch13.xhtml#ch13fig8)）。

![image](Images/13fig08.jpg)

*图 13-8：全卷积模型对左上角输入图像的每个数字热图输出。该模型在通过平移数字增强的 MNIST 数据集上训练。*

我们看到显著的改进，因此有了令人印象深刻的证据，证明我们的直觉是正确的：最初的模型无法有效处理部分数字，但当我们用包含部分数字的数据进行训练时，最终的响应对实际数字非常稳健，对其他数字则几乎没有反应。我们不应该对这些结果感到惊讶。我们的第一个模型没有代表模型在实际应用中会遇到的输入空间。它对部分 MNIST 数字一无所知。第二个模型是在一个更能代表可能输入空间的数据集上进行训练的，因此表现明显更好。

近年来，使用全卷积网络的方法已被其他更先进的技术取代，而这些技术在本书中由于篇幅和计算能力的限制无法讨论。许多定位图像中物体的模型输出的不是热图，而是覆盖图像的边界框。例如，YOLO 模型（*[https://pjreddie.com/darknet/yolo/](https://pjreddie.com/darknet/yolo/)*) 能够实时进行物体检测，并且使用包围物体的边界框及其标签。在[第 12 章](ch12.xhtml#ch12)中，我们提到了语义分割和 U-Net，这些是当前最先进的模型，它们为输入的每个像素分配一个类别标签。这两种方法都非常有用，并且在某种意义上是我们在这里展示的全卷积模型方法的扩展。

### 打乱的 MNIST 数字

在[第 10 章](ch10.xhtml#ch10)中，我们展示了打乱 MNIST 数字中像素顺序（[图 7-3](ch07.xhtml#ch7fig3)）时，只要像素的重映射在每张图像上确定性地应用，传统神经网络并不会受到影响。它仍然能够很好地训练并像处理未打乱的数字一样有效地分配类别标签。见[图 10-9](ch10.xhtml#ch10fig9)。

让我们看看 CNN 是否仍然适用。我们在[第 5 章](ch05.xhtml#ch05)中制作了打乱的 MNIST 数字数据集。我们要做的就是将其替换为我们基准 CNN 模型中的标准 MNIST 数据集，就是我们在本章开始时使用的那个。如果我们用打乱的数据训练这个模型，并重复训练以获得一些误差条形图，我们会得到[图 13-9](ch13.xhtml#ch13fig9)。

![image](Images/13fig09.jpg)

*图 13-9：每个时期的测试集误差，模型分别在未打乱和打乱的 MNIST 数字上训练。六次训练会话的均值和标准误差。*

在这里我们看到，与传统的神经网络不同，CNN 确实存在一些问题：打乱顺序的数字测试误差高于未打乱顺序的数字。为什么？回想一下，CNN 使用卷积并学习帮助创建输入新表示的卷积核，这些表示能让简单的模型（即顶部层）更容易区分不同的类别。

卷积生成的响应是空间依赖的。对于打乱顺序的数字，这种空间依赖性大部分被消除；只有将数字图像作为整体来考虑，像传统神经网络那样，才能做出类别判定。这意味着 CNN 的低层几乎没有学习的东西。当然，CNN 仍然在学习，并且最终在处理打乱的数字时，比传统模型做得更好，误差大约是 2% 对比 4.4%，但是打乱与未打乱的区别更加显著。

### 小结

在这一章中，我们通过使用MNIST数据集构建了对CNN的直觉。我们探讨了基本架构变化的影响；了解了训练集大小、小批量大小和训练周期数之间的相互关系；并探索了优化算法的效果。

我们展示了如何将一个使用全连接层的模型转换为一个全卷积模型。接着，我们学习了如何将该模型应用于在任意大小的输入图像中搜索数字。我们还了解到，为了更好地表示模型在使用时所看到的输入分布，我们需要增加数据集的表现力。

最后，通过一个关于打乱MNIST数字的实验，我们看到了CNN的优势——它们能够学习数据中的空间关系——有时在空间关系较弱或不存在时，仍然可能无法发挥多大作用。

在下一章，我们将继续探索基本的卷积神经网络（CNN），使用一个新的数据集，它由实际图像组成：CIFAR-10。

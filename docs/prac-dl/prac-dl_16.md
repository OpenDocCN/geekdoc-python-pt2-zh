## **16

进一步探索**

![image](img/common.jpg)

你现在已经拥有我认为是现代机器学习的良好入门知识。我们已经涵盖了数据集构建、经典模型、模型评估以及入门级深度学习，从传统神经网络到卷积神经网络。本章内容旨在帮助你更进一步。

我们将探讨短期的“下一步”内容，也会探讨你可能希望探索的长期发展方向。我们还会提供一些在线资源，你可以在其中找到最新和最好的内容（始终记住，网络上的任何内容都是短暂的）。之后会列出一些你可能希望参加的会议。我们将在本章和全书的结尾，向你表示感谢并告别。

### 进一步探索 CNN

即使已经讲了四章内容，我们对卷积神经网络的能力也只是触及了表面。部分原因是我们有意识地限制了内容，以便你能掌握基础知识。另外部分原因是我们有意识地做出选择，不要求使用 GPU。使用 GPU 训练复杂模型通常比使用 CPU 快 20 到 25 倍。如果你的系统中有 GPU，最好是为深度学习应用设计的，那么可能性会大大增加。

我们开发的模型比较小，类似于 LeCun 在 1990 年代开发的原始 LeNet 模型。它们能够传达要点，但在许多情况下无法取得更远的进展。现代 CNN 有多种不同的架构，现如今有了“标准”架构。有了 GPU，你可以探索这些更大的架构。

以下架构应在你接下来需要关注的列表中：

+   ResNet

+   U-Net

+   VGG

+   DenseNet

+   Inception

+   AlexNet

+   YOLO

幸运的是，我们介绍的 Keras 工具包（尽管我们只略微探讨了它）支持所有这些架构。对我来说，特别有用的是 ResNet 和 U-Net。后者用于输入的语义分割，在医学影像领域尤其取得了广泛的成功。要想在计算机的电源供应或硬盘坏掉之前成功训练这些架构，更不用说你的心脏了，你确实需要一个 GPU。中高端的游戏 GPU（例如 NVIDIA）将支持足够新的 CUDA 版本，你可以以不到 500 美元的价格购买一张显卡。真正的挑战是确保你的计算机支持这张显卡。电源需求较高，通常需要 600W 或更高的电源，并且需要一个支持双宽 PCIe 显卡的插槽。选择内存而非性能；显卡的内存越大，它支持的模型也就越大。

即使你不升级系统，安装 GPU，花时间研究上述架构也是值得的。这样你可以理解它们的特别之处，并掌握额外层的工作原理。查看 Keras 文档了解更多细节：[keras.io](http://keras.io)。

### 强化学习和无监督学习

本书专门讨论了监督学习。在机器学习的三个主要分支中，监督学习可能是最广泛应用的。回想一下马尔克斯兄弟，监督学习就像是格劳乔，那个大家都记得的。这个说法并不是对哈波和奇科的记忆的侮辱，也不是对机器学习的另外两个分支的侮辱：强化学习和无监督学习。

*强化学习*是以目标为导向的；它鼓励模型学习如何行动，以最大化奖励。与监督学习中学习如何将输入映射到特定输出类别不同，强化学习学习如何在当前情境中采取行动以最大化整体目标，比如赢得一场比赛。许多与机器学习相关的令人印象深刻的新闻故事都涉及强化学习。这些故事包括第一款能够击败人类顶级玩家的 Atari 2600 游戏系统，以及世界围棋冠军被 AlphaGo 击败，甚至更令人印象深刻的是 AlphaGo Zero 的成就，它从零开始掌握围棋，而没有借助人类玩过的数百万局游戏。任何自动驾驶汽车系统可能都极其复杂，但可以确定的是，强化学习是该系统的关键组成部分。

*无监督学习*是指从未标记的输入数据中自我学习的系统。从历史上看，这意味着聚类算法，如*k*-均值算法，它通过某些相似性度量将未标记的特征向量进行分组。目前，有人可能认为无监督学习在监督学习和强化学习的巨大工作量面前显得有些不重要。这仅仅是部分正确；许多监督学习的研究正试图利用未标记的数据（可以搜索*领域适应*）。我们自己的学习有多少是无监督的呢？一个在外星世界上放任自流的自主系统，如果能学习到它的创造者不知道需要学习的内容，可能会更加成功。这表明无监督学习的重要性。

### 生成对抗网络

*生成对抗网络（GANs）*在 2014 年横空出世，由深度学习研究员伊恩·古德费洛（Ian Goodfellow）提出。GANs 很快被誉为 20 年来机器学习领域最重大的进展（扬·勒昆（Yann LeCun），在 2016 年 NIPS 大会巴塞罗那演讲中提到）。

最近关于能够生成无限数量逼真人脸的模型使用了 GAN 技术。创造模拟场景以及将一种风格（比如绘画）转换为另一种风格（比如照片）的模型也使用了 GAN。GAN 将一个生成输出的网络（通常基于输入的某种随机设置）与一个判别网络相结合，后者尝试学习如何区分真实输入和来自生成部分的输入。两个网络一起训练，以使生成网络越来越擅长欺骗判别网络。而判别网络则越来越擅长学习如何区分两者。最终，生成网络会非常擅长输出你希望它输出的内容。

对于生成对抗网络（GAN）的正确学习需要一本书，但它们非常值得一看，至少花一些时间去发展对其原理的直观理解。一个好的起点是特别流行的 GAN 架构——CycleGAN，CycleGAN 又衍生出了许多相似的模型。

### 循环神经网络

本书完全忽略的一个重要话题是*循环神经网络（RNNs）*。这些是具有反馈回路的网络，适用于处理时间序列数据等顺序数据——比如声音样本或视频帧。最常见的形式是 LSTM，即长短期记忆网络。循环神经网络广泛应用于神经翻译模型，如 Google 翻译，这使得实时翻译多种语言成为可能。

### 在线资源

机器学习的在线资源众多，且日益增长。以下是我觉得有用且可能经得起时间考验的几个地方，按顺序不分先后：

**Reddit 机器学习 (*[www.reddit.com/r/MachineLearning/](http://www.reddit.com/r/MachineLearning/)*)** 在这里查找最新的新闻和关于最新论文与研究的讨论。

**Arxiv (*[`arxiv.org/`](https://arxiv.org/)*)** 机器学习进展迅速，大多数论文无法通过传统期刊要求的漫长同行评审过程。因此，几乎所有研究人员和许多会议都会将他们的论文发布在这个预印本服务器上，提供对最新机器学习研究的免费访问。尽管这样做可能让人感到有些压倒性，但我个人使用 Arxiv 手机应用，每周几次浏览以下类别：计算机视觉与模式识别、人工智能、神经网络与进化计算、机器学习。仅这些类别每周发布的论文数量令人印象深刻，也很好地反映了这一领域的活跃程度。为了应对大量的论文，深度学习研究员 Andrej Karpathy 创建了有用的 Arxiv Sanity 网站，地址是 *[`www.arxiv-sanity.com/`](http://www.arxiv-sanity.com/)*。

**GitHub (*[`github.com/`](https://github.com/)*)** 这是一个人们可以托管软件项目的地方。你可以直接访问该网站，搜索机器学习项目，或者使用标准的搜索引擎并在搜索中添加关键词 *github*。随着机器学习项目的爆炸性增长，一件美妙的事情发生了。绝大多数项目都可以免费使用，甚至可以用于商业用途。这通常包括完整的源代码和数据集。如果你在 Arxiv 上阅读到某个研究，通常可以在 GitHub 上找到该研究的实现。

**Coursera (*[`www.coursera.org/`](https://www.coursera.org/)*)** Coursera 是一个优质的在线课程平台，其中绝大多数课程可以免费旁听。虽然还有其他平台，但 Coursera 是由 Andrew Ng 共同创办的，他的机器学习课程非常受欢迎。

**YouTube (*[`www.youtube.com/`](https://www.youtube.com/)*)** YouTube 目前已经成为一种自然力量，但它充满了机器学习视频。观众需要保持警惕，不过通过一些挖掘和明智的选择，你会发现这里有很多资源，包括最新和最棒的演示。搜索 “Neural Networks for Machine Learning” 这门由 Geoffrey Hinton 教授的课程。

**Kaggle (*[`www.kaggle.com/`](https://www.kaggle.com/)*)** Kaggle 主办机器学习竞赛，是获取数据集的好资源。获胜者会详细描述他们的模型和训练过程，提供了大量学习这一艺术的机会。

### 会议

学习新语言的最佳方式之一是沉浸在讲该语言的文化中。机器学习也不例外。沉浸在机器学习文化中的方式是参加会议。虽然这可能会很昂贵，但许多学校和公司认为这很重要，所以你可能能够获得支持参加会议。

机器学习兴趣的爆炸性增长导致了一种新现象，我在其他学科中没有见过：会议售罄。这不仅适用于最大的会议，可能其他一些较小的会议也会发生这种情况。如果你想参加，务必注意时机很重要。同样，以下内容没有特定顺序，并且漏掉了许多其他不错但较小的会议，考虑以下几项：

**NeurIPS (前身为 NIPS)** 是 *Neural Information Processing Systems* 的缩写，这可能是最大的机器学习会议。在这个学术会议上，你可以看到最新的研究成果。近年来，NeurIPS 的门票销售速度非常快，2018 年甚至在 12 分钟内就售罄，现已改为抽签系统，因此除非你是某种演讲者，否则很难收到允许注册的黄金票邮件。该会议通常在加拿大举行。

**ICML** 是 *International Conference on Machine Learning* 的缩写，这可能是第二大年度会议。这个学术会议有多个主题和工作坊，通常在欧洲或北美举行。

**ICLR** 国际学习表征会议是一个专注于深度学习的学术会议。如果你想要深入技术的深度学习讲解，这里就是你该去的地方。

**CVPR** 计算机视觉与模式识别会议是另一个大型会议，可能相比 ICLR 稍微少一些学术性。CVPR 非常受欢迎，并且不仅仅专注于机器学习。

**GTC** GPU 技术大会由 NVIDIA 主办，是一个技术型会议，而非学术型会议。每年在此展示新的 NVIDIA 硬件，并伴有大型博览会，地点在美国加利福尼亚州圣荷西市。

### 这本书

说市面上有几本机器学习书籍，就像说大海里有几条鱼一样。然而，就深度学习而言，有一本书脱颖而出：由 Ian Goodfellow、Yoshua Bengio 和 Aaron Courville 合著的《*Deep Learning*》（MIT Press，2016）。参见 *[`www.deeplearningbook.org/`](http://www.deeplearningbook.org/)*

如果你想认真成为一名机器学习研究者，《*Deep Learning*》是你应该阅读的书。即使你不打算深入研究，它也深入涵盖了关键主题，并且具有数学严谨性。这本书并不适合那些只想提高使用某个工具包的技能的人，而是为那些希望了解机器学习背后理论以及相关数学的人准备的。从本质上来说，这本书是一本高级本科—如果不是研究生水平的教材，但这不应该让你却步。总有一天，你会想要翻阅这本书，所以把它放在心里—或者放在书架上。

### 再见，感谢所有的鱼

我们已经读完了这本书。这里没有怪物，只有我们自己，以及通过前面章节的学习所获得的知识和直觉。感谢你坚持读完。写这本书对我来说很有趣；我真心希望你在阅读和思考时也能感到有趣。别停下，现在正是时候—拿着我们所学的内容去实践吧。如果你像我一样，你会发现机器学习在各个领域都有应用。去吧，开始分类吧！

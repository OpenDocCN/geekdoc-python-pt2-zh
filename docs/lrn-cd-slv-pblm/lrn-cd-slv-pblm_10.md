## 第十章：大 O 符号与程序效率

![image](img/common.jpg)

在本书的前七章中，我们专注于编写正确的程序：对于任何有效的输入，我们希望程序能够输出期望的结果。然而，除了正确的代码，我们通常还希望代码高效，能够在大量输入下仍然快速运行。你可能在阅读前七章时偶尔遇到过时间超限的错误，但我们正式进入程序效率的讨论是在第八章，当时我们解决了电子邮件地址的问题。我们在那时看到，有时我们需要提高程序的效率，以便它们能在规定的时间内完成。

在本章中，我们首先将学习程序员如何思考和沟通程序效率。然后，我们将研究两个需要编写高效代码的问题：确定围巾的最理想部分和绘制丝带。

对于每个问题，我们会发现最初的想法会导致一个效率不够高的算法。但我们会坚持下去，直到我们为同一个问题设计出一个更快的算法，比之前高效得多。这 exemplifies（体现）了程序员的常见工作流程：首先，提出一个正确的算法；然后，只有在需要时，再让它变得更快。

### 定时问题

本书中我们解决的每一个竞赛编程问题，都有一个时间限制，规定了我们的程序运行的最长时间。（从第八章开始，我就将时间限制包括在问题描述中，那时我们开始遇到效率成为严重问题的编程题。）如果我们的程序超过时间限制，评测系统将终止程序并给出时间超限的错误提示。时间限制旨在防止过慢的解决方案通过测试用例。例如，可能我们提出了一个完全搜索的解决方案，但问题的作者已经想出了一个更快的解决方案。那个更快的解决方案可能是完全搜索的变体，正如我们在第九章解决《牛的棒球问题》时那样，或者可能是完全不同的方法。不管怎样，时间限制的设置可能使得我们的完全搜索解法无法按时完成。因此，除了保证正确性，我们的程序可能还需要足够快。

我们可以运行程序来探索它是否足够高效。例如，回想一下在第八章中“搜索列表的效率”部分，我们尝试使用列表来解决电子邮件地址的问题。我们运行了使用越来越大的列表的代码，以了解列表操作所需的时间。这种测试可以帮助我们理解程序的效率。如果我们的程序太慢，超过了问题的时间限制，那么我们就知道需要优化当前的代码或找到一种全新的方法。

程序所需的时间取决于运行它的计算机。我们无法得知评测机使用的是什么类型的计算机，但在我们自己的计算机上运行程序仍然有参考价值，因为评测机可能至少和我们的计算机一样快。假设我们在笔记本上运行程序，某个小的测试用例需要 30 秒。如果问题的时间限制是三秒钟，我们可以确定我们的程序明显不够快。

然而，单纯专注于时间限制是有限的。想一想我们在第九章中对牛棒球问题的第一个解法。我们并不需要运行代码来确定它的执行速度。这是因为我们能够通过程序需要执行的工作量来描述程序的效率，就算我们没有真正运行它。例如，在第 253 页的“程序效率”部分，我们提到，对于*n*头牛，我们的程序会处理*n*³个牛的三元组。请注意，我们关注的不是程序运行所需的秒数，而是它在处理输入*n*时所需的工作量。

与运行程序并记录执行时间相比，这种分析方法有显著的优势。以下是五个优点：

**执行时间依赖于计算机**。对我们的程序进行计时，只能告诉我们程序在某一台计算机上运行需要多长时间。这是非常具体的信息，对于了解程序在其他计算机上的运行表现帮助不大。当你在阅读本书时，可能也注意到，即使在同一台计算机上，程序的执行时间也会有所不同。例如，你可能会在一个测试用例上运行程序，发现它需要三秒钟；然后你再运行同一个测试用例，可能发现它需要两秒半或三秒半。这种差异的原因在于，操作系统正在管理你的计算资源，并根据需要将它们分配给不同的任务。操作系统的决策会影响程序的运行时间。

**执行时间依赖于测试用例** 对程序进行计时只会告诉我们它在某个测试用例上运行了多长时间。假设我们的程序在一个小型测试用例上运行需要三秒钟。这看起来很快，但关于小型测试用例的真相是：每个合理的解决方案都能很快解决这些问题。如果我让你告诉我 10 个电子邮件地址中有多少个不同的地址，或者在 10 头牛中有多少组三个牛的组合，你可以通过第一个正确的想法迅速解决。真正有趣的是大型测试用例。它们是算法创新得以体现的地方。我们的程序在大型测试用例或巨型测试用例上需要多久？我们不知道。我们还需要在这些测试用例上运行程序。即使我们这么做了，也可能会有特定类型的测试用例导致程序性能较差。我们可能会误以为程序比实际更快。

**程序需要实现** 我们无法对一个尚未实现的程序进行计时。假设我们正在思考一个问题，并想到一个解决方案。它快吗？尽管我们可以通过实现它来找出答案，但如果能提前知道这个想法是否可能导致一个快速的程序，那将会更好。你不会实现一个你一开始就知道会出错的程序。同样，知道一个程序一开始就会太慢也是很有用的。

**计时并不能解释程序的慢速** 如果我们发现程序太慢，那么接下来的任务就是设计一个更快的程序。然而，单纯地计时程序并不能让我们深入了解程序为何慢。它只是慢而已。更进一步地，如果我们想到可能的改进方案，还需要实际实现它，以确定是否能提升性能。

**执行时间不容易传达** 由于许多原因，使用执行时间与他人讨论算法的效率是困难的。执行时间过于具体：它依赖于计算机、操作系统、测试用例、编程语言以及所使用的具体实现。我们必须提供所有这些信息，才能让其他人了解我们算法的效率。

不用担心：计算机科学家已经设计了一种符号来解决计时的这些不足之处。它独立于计算机、独立于测试用例，并且独立于特定的实现。它能指示为什么一个程序会慢。它易于传达。这就是*大 O 表示法*，接下来就会介绍。

### 大 O 表示法

大 O 表示法是计算机科学家用来简洁描述算法效率的符号。这里的关键概念是*效率类*，它告诉你算法的运行速度，或者更确切地说，它告诉你算法做了多少工作。算法越快，做的工作就越少；算法越慢，做的工作就越多。每个算法都属于一个效率类；效率类告诉你该算法在处理必须处理的输入时，所做的工作量。为了理解大 O，我们需要了解这些效率类。我们现在将学习七种最常见的效率类。我们将看到那些做最少工作的算法——你希望你的算法能符合这些效率类。我们还将看到那些做更多工作的算法——这些算法可能会让你遇到“超时限制”错误。

#### 常数时间

最理想的算法是那些随着输入量增加而不增加工作量的算法。无论问题实例如何，这种算法所需要的步骤数大致相同。这样的算法被称为*常数时间*算法。

这很难相信，对吧？一个做大致相同工作量的算法，无论输入是什么？的确，能用这种算法解决问题是很少见的。但当你能做到时，值得高兴：你无法做得比这更好了。

我们已经通过常数时间算法解决了这本书中的一些问题。回想一下在第二章中，我们需要确定提供的电话号码是否属于推销员。我在这里重新展示了我们在清单 2-2 中的解决方案：

```py
num1 = int(input())

num2 = int(input())

num3 = int(input())

num4 = int(input())

if ((num1 == 8 or num1 == 9) and

        (num4 == 8 or num4 == 9) and

        (num2 == num3)):

    print('ignore')

else:

    print('answer')
```

我们的解决方案做的工作量相同，无论电话号码的四个数字是什么。代码首先读取输入。然后它会与`num1`、`num2`、`num3`和`num4`做一些比较。如果电话号码属于推销员，我们输出某些内容；如果不属于推销员，我们输出其他内容。没有任何输入能让我们的程序做比这更多的工作。

在第二章的前面，我们解决了“获胜团队”问题。我们也用了常数时间来解决它吗？是的！这里是我们在清单 2-1 中的解决方案：

```py
apple_three = int(input())

apple_two = int(input())

apple_one = int(input())

banana_three = int(input())

banana_two = int(input())

banana_one = int(input())

apple_total = apple_three * 3 + apple_two * 2 + apple_one

banana_total = banana_three * 3 + banana_two * 2 + banana_one

if apple_total > banana_total:

    print('A')

elif banana_total > apple_total:

    print('B')

else:

    print('T')
```

我们读取输入，计算苹果的总分，计算香蕉的总分，比较这两个总分，并输出一条信息。苹果或香蕉的分数多少并不重要——我们的程序始终做相同量的工作。

等一下——如果苹果队投进了无数个三分球怎么办？难道计算机处理这么巨大的数字不会比处理像 10 或 50 这样的小数字需要更长的时间吗？虽然这是事实，但我们在这里不需要担心这个问题。问题描述中说明每支队伍每种类型的得分最多是 100 次。因此，我们处理的是小数字，可以公平地说计算机可以在固定的步骤数内读取或操作这些数字。一般来说，你可以将几亿以下的数字视为“小”数字。

在大 O 表示法中，我们说一个常数时间算法是 *O*(1)。这里的 1 并不意味着你只能在常数时间算法中执行一步操作。如果你执行固定次数的步骤，比如 10 步或甚至 10,000 步，它仍然是常数时间。但不要写 *O*(10) 或 *O*(10000)—所有常数时间算法都表示为 *O*(1)。

#### 线性时间

大多数算法不是常数时间算法。相反，它们的工作量取决于输入量。例如，它们处理 1,000 个值时要做的工作比处理 10 个值时要做的工作多。区分这些算法的特点在于输入量与算法所做的工作量之间的关系。

*线性时间* 算法是指输入量与工作量之间存在线性关系的算法。假设我们在一个包含 50 个值的输入上运行一个线性时间算法，然后再在一个包含 100 个值的输入上运行它。与处理 50 个值相比，算法在处理 100 个值时将大约多做一倍的工作。

作为一个例子，让我们来看一下 第三章中的三杯问题。我们在 清单 3-1 中解决了这个问题，我在这里重现了我们的解决方案：

```py
   swaps = input()

   ball_location = 1

❶ for swap_type in swaps:

       if swap_type == 'A' and ball_location == 1:

           ball_location = 2

       elif swap_type == 'A' and ball_location == 2:

           ball_location = 1

       elif swap_type == 'B' and ball_location == 2:

           ball_location = 3

       elif swap_type == 'B' and ball_location == 3:

           ball_location = 2

       elif swap_type == 'C' and ball_location == 1:

           ball_location = 3

       elif swap_type == 'C' and ball_location == 3:

           ball_location = 1

   print(ball_location)
```

有一个 `for` 循环 ❶，它所做的工作量与输入量成线性关系。如果有 5 次交换需要处理，那么循环就迭代 5 次。如果有 10 次交换需要处理，那么循环就迭代 10 次。每次循环迭代都执行固定数量的比较，并可能改变 `ball_location` 所指的内容。因此，这个算法所做的工作量与交换次数成正比。

我们通常用 *n* 来表示问题输入的数量。在这里，*n* 是交换的次数。如果我们需要执行 5 次交换，那么 *n* 就是 5；如果我们需要执行 10 次交换，那么 *n* 就是 10。

如果有 *n* 次交换，那么我们的程序大约做 *n* 次工作。这是因为 `for` 循环执行了 *n* 次迭代，每次迭代都执行固定数量的步骤。我们不关心每次迭代执行多少步骤，只要它是固定数量的。不管算法总共执行了 *n* 步、10*n* 步还是 10,000*n* 步，它都是一个线性时间算法。在大 O 表示法中，我们说这个算法是 *O*(*n*)。

在使用大 O 表示法时，我们不包括*n*前面的数字。例如，一个需要 10*n* 步骤的算法应该写成 *O*(*n*)，而不是 *O*(10*n*)。这帮助我们集中注意算法是线性时间，而不是线性关系的具体细节。

如果一个算法需要 2*n* + 8 步——这是什么类型的算法？这仍然是线性时间！原因是，当*n*足够大时，线性项（2*n*）将会主导常数项（8）。例如，如果*n*是 5000，那么 8*n* 就是 40000。数字 8 相比于 40000 是如此微不足道，以至于我们可以忽略它。在大 O 表示法中，我们忽略除了主导项之外的所有项。

许多 Python 操作执行工作时需要常数时间。例如，向列表添加元素、向字典中添加元素或索引序列或字典都需要常数时间。

但是有些 Python 操作执行工作时需要线性时间。请小心将它们计算为线性时间，而不是常数时间。例如，使用 Python 的`input`函数读取一个长字符串需要线性时间，因为 Python 必须逐个字符地读取输入行。任何检查字符串中每个字符或列表中每个值的操作也需要线性时间。

如果一个算法读取 *n* 个值，并且以常数步骤处理每个值，那么它就是线性时间算法。

我们不用走得很远就能看到另一个线性时间算法——我们在第三章中解决的占用空间问题就是另一个例子。我在这里复现了我们在示例 3-3 中的解决方案：

```py
n = int(input())

yesterday = input()

today = input()

occupied = 0

for i in range(len(yesterday)):

    if yesterday[i] == 'C' and today[i] == 'C':

        occupied = occupied + 1

print(occupied)
```

我们让 *n* 为停车位的数量。模式与三杯问题相同：我们读取输入，然后为每个停车位执行常数数量的步骤。

**概念检查**

在示例 1-1 中，我们解决了单词计数问题。这里是该解决方案的代码。

```py
line = input()

total_words = line.count(' ') + 1

print(total_words)
```

我们的算法的大 O 效率是多少？

A. *O*(1)

B. *O*(*n*)

答案：B. 很容易认为这个算法是*O*(1)。毕竟，代码中没有任何循环，看起来算法只执行了三步：读取输入，调用`count`来计算单词数量，输出单词数量。

但这个算法是 *O*(*n*)，其中 *n* 是输入字符的数量。`input`函数读取输入需要线性时间，因为它必须逐个字符地读取输入。使用`count`方法也需要线性时间，因为它必须处理字符串中的每个字符以找到匹配项。所以，这个算法执行的工作量是线性的，既有读取输入的线性工作量，也有计数单词的线性工作量。总的来说，这是线性的工作量。

**概念检查**

在示例 1-2 中，我们解决了圆锥体体积问题。这里是我复现的解决方案：

```py
PI = 3.141592653589793

radius = int(input())

height = int(input())

volume = (PI * radius ** 2 * height) / 3

print(volume)
```

我们的算法的大 O 效率是多少？（回忆一下，半径和高度的最大值是 100。）

A. *O*(1)

B. *O*(*n*)

答案：A。我们处理的是小数字，因此从输入中读取它们需要常数时间。计算体积也需要常数时间：这只是几个数学操作。因此，我们所做的只是一些常数时间的步骤。总体而言，这是一个常数量的工作。

**概念检查**

在 Listing 3-4 中，我们解决了数据计划问题。我已经在这里复现了该解决方案：

```py
monthly_mb = int(input())

n = int(input())

excess = 0

for i in range(n):

    used = int(input())

    excess = excess + monthly_mb - used

print(excess + monthly_mb)
```

我们的算法的大 O 效率是什么？

A. *O*(1)

B. *O*(*n*)

答案：B。这个算法的模式类似于我们解决“三个杯子”或“占用空间”问题的解决方案，不同之处在于它将读取输入与处理输入交替进行。我们让 *n* 代表每月的兆字节数值。程序对这些 *n* 个输入值执行一个常数数量的步骤。因此，这是一个 *O*(*n*) 算法。

#### 二次时间

到目前为止，我们讨论了常数时间算法（即随着输入量增加，工作量不变的算法）和线性时间算法（即随着输入量增加，工作量线性增加的算法）。像线性时间算法一样，*二次时间* 算法随着输入量的增加而做更多的工作；例如，它处理 1,000 个值所做的工作比处理 10 个值时要多。虽然我们可以在相对较大的输入量上使用线性时间算法，但在二次时间算法上，我们将受到更小的输入量限制。接下来我们将看到原因。

##### 典型形式

一个典型的线性时间算法如下所示：

```py
for i in range(n):

    <process input i in a constant number of steps>
```

相比之下，典型的二次时间算法如下所示：

```py
for i in range(n):

    for j in range(n):

        <process inputs i and j in a constant number of steps>
```

对于一个包含 *n* 个值的输入，每个算法处理多少个值？线性时间算法处理 *n* 个值，每次在 `for` 循环的迭代中处理一个值。相比之下，二次时间算法在外部 `for` 循环的每次迭代中处理 *n* 个值。

在外部 `for` 循环的第一次迭代中，处理 *n* 个值（每次迭代处理一个值）；在外部 `for` 循环的第二次迭代中，处理 *n* 个值（每次迭代处理一个值）；依此类推。随着外部 `for` 循环迭代 *n* 次，处理的值的总数是 *n* * *n*，即 *n*²。两个嵌套循环，每个循环都依赖于 *n*，产生了一个二次时间算法。在大 O 记法中，我们说二次时间算法是 *O*(*n*²)。

让我们比较一下线性时间算法和二次时间算法的工作量。假设我们处理一个包含 1,000 个值的输入，这意味着 *n* 等于 1,000。一个需要 *n* 步的线性时间算法将执行 1,000 步。一个需要 *n*² 步的二次时间算法将执行 1,000² = 1,000,000 步。一百万比一千多得多。但是谁在乎呢：计算机真的非常非常快，对吧？嗯，是的，对于一个包含 1,000 个值的输入，如果我们使用二次时间算法，可能也没什么大问题。在 第 253 页的《我们程序的效率》一节中，我给出了一个保守的规则，认为我们每秒可以执行大约五百万步。因此，一百万步应该在除最严格的时间限制外都能完成。

但是对于二次时间算法的乐观期待是短暂的。看看当我们将输入值的数量从 1,000 增加到 10,000 时会发生什么。线性时间算法仅需 10,000 步。二次时间算法需要 10,000² = 100,000,000 步。嗯……如果我们使用二次时间算法，计算机的速度就不那么快了。虽然线性时间算法仍然以毫秒为单位运行，但二次时间算法至少要花几秒钟。肯定会超时了，毫无疑问。

**概念检查**

以下算法的时间复杂度是多少？

```py
for i in range(10):

    for j in range(n):

        <process inputs i and j in a constant number of steps>
```

A. *O*(1)

B. *O*(*n*)

C. *O*(*n*^(*2*))

答案：B。这里有两个嵌套循环，所以你可能会直觉地认为这是一个二次时间算法。不过要小心，因为外层 `for` 循环仅执行 10 次，与 *n* 的值无关。因此，这个算法的总步骤数是 *10n*。这里并没有 *n*^(*2*)，*10n* 是线性的，就像 *n* 一样。所以，这是一个线性时间算法，而不是二次时间算法。我们可以将其效率写作 *O*(*n*)。

**概念检查**

以下算法的时间复杂度是多少？

```py
for i in range(n):

    <process input i in a constant number of steps>

for j in range(n):

    <process input j in a constant number of steps>
```

A. *O*(1)

B. *O*(*n*)

C. *O*(*n*^(*2*))

答案：B。这里有两个循环，它们都依赖于 *n*。那么这不就是二次时间复杂度吗？

不！这两个循环是顺序执行的，而不是嵌套的。第一个循环执行 *n* 步，第二个也执行 *n* 步，总共是 *2n* 步。因此，这是一个线性时间算法。

##### 备用形式

当你看到两个嵌套循环，每个循环都依赖于 *n* 时，可以合理推测你可能面对的是一个二次时间算法。但即便没有这样的嵌套循环，二次时间算法也有可能出现。我们可以在我们解决电子邮件地址问题的第一个解法中找到这样的例子，示例 8-2。我在这里重现了该解法：

```py
# clean function not shown

for dataset in range(10):

    n = int(input())

    addresses = []

    for i in range(n):

        address = input()

     ❶ address = clean(address)

     ❷ if not address in addresses:

            addresses.append(address)

    print(len(addresses))
```

假设 *n* 是我们在 10 个测试用例中看到的最大电子邮件地址数量。外层 `for` 循环执行 10 次；内层 `for` 循环最多执行 *n* 次。因此，我们最多处理 10*n* 个电子邮件地址，这在 *n* 上是线性的。

清理一个电子邮件地址 ❶ 需要恒定的步骤数，所以我们不需要担心这个。但这仍然不是线性时间算法，因为内层 `for` 循环的每次迭代都需要超过恒定步骤数的操作。具体来说，检查电子邮件地址是否已经在我们的列表中 ❷ 需要与列表中已经存在的电子邮件地址数量成比例的操作，因为 Python 必须遍历列表。这本身就是一个线性时间的操作！所以我们处理了 10*n* 个电子邮件地址，每个电子邮件地址需要 *n* 次操作，总共是 10*n*² 次操作，或者说是二次方时间复杂度的操作。正因为这段代码的二次方时间复杂度，我们才遇到了超时错误，最终我们使用了集合而不是列表。

#### 三次方时间

如果一个循环能导致线性时间，两个嵌套循环能导致二次方时间，那么三个嵌套循环会怎样呢？三个嵌套的循环，每个都依赖于 *n*，就会导致一个 *三次方时间* 的算法。在大 O 记法中，我们说一个三次方时间算法是 *O*(*n*³)。

如果你认为二次方时间复杂度的算法很慢，那等你看到三次方时间复杂度的算法有多慢吧。假设 *n* 是 1,000。我们已经知道线性时间算法大约需要 1,000 步，而二次方时间算法大约需要 1,000² = 1,000,000 步。三次方时间算法则需要 1,000³ = 1,000,000,000 步。十亿步！但事情更糟糕。例如，如果 *n* 是 10,000，这仍然是一个较小的输入量，那么三次方时间算法将需要 1,000,000,000,000（也就是一万亿）步。一万亿步将需要几分钟的计算时间。不是开玩笑：三次方时间复杂度的算法几乎永远不够好。

当我们尝试使用三次方时间复杂度的算法来解决示例 9-5 中的牛棒球问题时，显然它并不够好。我在这里重新展示了那个解决方案：

```py
   input_file = open('baseball.in', 'r')

   output_file = open('baseball.out', 'w')

   n = int(input_file.readline())

   positions = []

   for i in range(n):

       positions.append(int(input_file.readline()))

   total = 0

❶ for position1 in positions:

    ❷ for position2 in positions:

           first_two_diff = position2 - position1

           if first_two_diff > 0:

               low = position2 + first_two_diff

               high = position2 + first_two_diff * 2

            ❸ for position3 in positions:

                   if position3 >= low and position3 <= high:

                       total = total + 1

   output_file.write(str(total) + '\n')

   input_file.close()

   output_file.close()
```

你会在这段代码中看到三次方时间的特征：三个嵌套的循环 ❶ ❷ ❸，每个循环的迭代次数都依赖于输入的数量。正如你记得的那样，这个问题的时间限制是四秒，并且我们最多可以有 1,000 头牛。三次方时间复杂度的算法，处理十亿次迭代，显然太慢了。

#### 多个变量

在第五章中，我们解决了贝克奖金问题。我在这里重新展示了我们在示例 5-6 中的解决方案：

```py
for dataset in range(10):

    lst = input().split()

    franchisees = int(lst[0])

    days = int(lst[1])

    grid = []

 ❶ for i in range(days):

        row = input().split()

        for j in range(franchisees):

            row[j] = int(row[j])

        grid.append(row)

    bonuses = 0

 ❷ for row in grid:

        total = sum(row)

        if total % 13 == 0:

            bonuses = bonuses + total // 13

 ❸ for col_index in range(franchisees):

        total = 0

        for row_index in range(days):

            total = total + grid[row_index][col_index]

        if total % 13 == 0:

            bonuses = bonuses + total // 13

    print(bonuses)
```

这个算法的时间复杂度是什么？这里有一些嵌套循环，所以第一反应是这个算法的时间复杂度是 *O*(*n*²)。但是 *n* 代表什么呢？

在本章迄今为止讨论的问题中，我们使用单一变量 *n* 来表示输入的量：*n* 可能是交换的次数、停车位的数量、电子邮件地址的数量或奶牛的数量。但在贝克奖金问题中，我们处理的是二维输入，因此我们需要 *两个* 变量来表示其数量。我们将第一个变量称为 *d*，表示天数；第二个变量称为 *f*，表示加盟商的数量。更正式地说，由于每个输入包含多个测试案例，我们将 *d* 定义为天数的最大值，*f* 定义为加盟商的最大值。我们需要在 *d* 和 *f* 的基础上给出大 O 效率。

我们的算法由三个主要部分组成：读取输入、根据行计算奖金数量和根据列计算奖金数量。让我们分别来看一下每个部分。

为了读取输入 ❶，我们执行 *d* 次外循环。在每次迭代中，我们读取一行并调用 `split`，这个过程大约需要 *f* 步。然后我们再花 *f* 步遍历这些值并将它们转换为整数。总的来说，每次 *d* 次迭代都执行与 *f* 成比例的步骤。因此，读取输入需要 *O*(*df*) 时间。

现在来看行奖金 ❷。这里的外循环执行 *d* 次。每次迭代都调用 `sum`，该操作需要 *f* 步，因为它必须加总 *f* 个值。因此，与读取输入一样，这部分算法是 *O*(*df*)。

最后，让我们看一下列奖金 ❸ 的代码。外循环执行 *f* 次。每次迭代都导致内循环执行 *d* 次。这里的总时间复杂度同样是 *O*(*df*)。

该算法的每个组件是 *O*(*df*)。将三个 *O*(*df*) 组件加在一起，整体算法是 *O*(*df*)。

**概念检查**

以下算法的大 O 效率是多少？

```py
for i in range(m):

    <do something that takes one step>

for j in range(n):

    <do something that takes one step>
```

A. *O*(1)

B. *O*(*n*)

C. *O*(*n*^(*2*))

D. *O*(*m*+*n*)

E. *O*(*mn*)

答案：D。第一个循环依赖于 *m*，第二个循环依赖于 *n*。这些循环是顺序执行的，而不是嵌套的，因此它们的工作量是相加而非相乘。

#### 对数时间

在第 255 页的《程序效率》中，我们讨论了线性搜索与二分搜索的区别。线性搜索通过从头到尾搜索列表来查找值。这是一个 *O*(*n*) 算法，无论列表是否已排序都能工作。相比之下，二分搜索仅适用于已排序的列表。但如果你有一个已排序的列表，二分搜索会非常迅速。

二分搜索通过将我们要搜索的值与列表中间的值进行比较来工作。如果列表中间的值大于我们要搜索的值，我们继续在列表的左半部分进行搜索。如果列表中间的值小于我们要搜索的值，我们继续在列表的右半部分进行搜索。我们一直这样做，每次忽略列表的一半，直到找到我们要找的值。

假设我们使用二分搜索在一个包含 512 个值的列表中查找某个值。需要多少步？嗯，经过第一步后，我们忽略了一半的列表，所以剩下大约 512 / 2 = 256 个值。（无论我们的值是大于列表中一半的值，还是小于列表中一半的值，都会忽略列表的一半。）第二步后，剩下 256 / 2 = 128 个值。第三步后，剩下 128 / 2 = 64 个值。继续下去，第四步后剩下 32 个值，第五步后剩下 16 个值，第六步后剩下 8 个值，第七步后剩下 4 个值，第八步后剩下 2 个值，第九步后只剩下 1 个值。

九步——就这么简单！这比使用线性搜索最多需要 512 步要好得多。二分搜索比线性时间算法要少做很多工作。但它是什么样的算法呢？它不是常数时间：虽然它需要的步骤很少，但随着输入量的增加，步骤数确实会略微增加。

二分搜索是一个 *对数时间* 或 *对数时间* 算法的例子。在大 O 符号中，我们说一个对数时间算法是 *O*(log *n*)。

对数时间是指数学中的对数函数。给定一个数字，这个函数告诉你需要将该数字除以一个基数多少次，才能得到 1 或更小。我们在计算机科学中通常使用的基数是 2，所以我们要找的是将一个数字除以 2 多少次才能得到 1 或更小。例如，要将 512 除到 1，需要 9 次除法。我们写作 log[2] 512 = 9。

对数函数是指数函数的反函数，后者可能对你来说更加熟悉。另一种计算 log[2] 512 的方法是找到指数 *p*，使得 2*^p* = 512。由于 2⁹ = 512，我们确认 log[2] 512 = 9。

对数函数增长得如此缓慢，令人吃惊。例如，考虑一个包含一百万个值的列表。二分搜索要搜索这个列表需要多少步？它需要 log[2] 1,000,000 步，这大约是 20 步。对数时间比常数时间要接近得多，而不是线性时间。每当你能用对数时间算法代替线性时间算法时，这都是一次巨大的胜利。

#### n log n 时间

在 第五章中，我们解决了《村庄邻里问题》。我在这里重新展示了我们在 列表 5-1 中的解法：

```py
   n = int(input())

   positions = []

❶ for i in range(n):

       positions.append(int(input()))

❷ positions.sort()

   left = (positions[1] - positions[0]) / 2

   right = (positions[2] - positions[1]) / 2

   min_size = left + right

❸ for i in range(2, n - 1):

       left = (positions[i] - positions[i - 1]) / 2

       right = (positions[i + 1] - positions[i]) / 2

       size = left + right

       if size < min_size: 

           min_size = size

   print(min_size)
```

看起来像是线性时间算法，对吧？我的意思是，这里有一个线性时间的循环来读取输入❶，还有另一个线性时间的循环来找最小值❸。那么，这段代码是*O*(*n*)吗？

现在判断还为时过早！原因是我们还没有考虑到我们排序的位置❷。我们不能忽略这一点；我们需要了解排序的效率。正如我们将看到的那样，排序比线性时间要慢。因此，由于排序是这里最慢的步骤，无论排序的效率如何，它将决定整体的效率。

程序员和计算机科学家们设计了许多排序算法，这些算法大致可以分为两组。第一组包括需要*O*(*n*²)时间的算法。这些排序算法中最著名的三种是冒泡排序、选择排序和插入排序。如果你愿意，可以自行学习这些排序算法的更多内容，但在这里我们不需要了解它们的任何细节。我们要记住的只是，*O*(*n*²)可能非常慢。例如，要对一个包含 10,000 个值的列表进行排序，*O*(*n*²)排序算法需要大约 10,000² = 100,000,000 步。正如我们所知道的，这至少需要几秒钟的时间。这个结果相当令人失望：排序 10,000 个值似乎是计算机应该能够几乎瞬间完成的任务。

进入第二组排序算法。这一组包括那些只需要*O*(*n* log *n*)时间的算法。这个组里有两个著名的排序算法：快速排序和归并排序。同样的，如果你愿意，可以自己查找这些算法，但在这里我们不需要了解具体细节。

*O*(*n* log *n*)是什么意思？不要让符号弄混淆了你。这只是*n*和 log *n*的乘积。我们来尝试一下处理一个包含 10,000 个值的列表。在这里，我们有 10,000 * log 10,000 步，这只有大约 132,877 步。这是一个非常小的步数，特别是和需要 100,000,000 步的*O*(*n*²)排序算法相比。

现在我们可以问我们真正关心的问题：当我们要求 Python 对一个列表进行排序时，它使用的是哪种排序算法？答案是：*O*(*n* log *n*)的算法！（它叫 Timsort。如果你想了解更多，建议从归并排序开始，因为 Timsort 是一个加强版的归并排序。）这里没有慢的*O*(*n*²)排序算法。通常，排序是如此快速——几乎接近线性时间——我们可以使用它而不会对效率产生太大的影响。

回到“村庄邻里”这个例子，现在我们看到它的效率不是*O*(*n*)，而是由于排序的原因，变成了*O*(*n* log *n*)。实际上，*O*(*n* log *n*)算法所做的工作只比*O*(*n*)算法多一点，而远少于*O*(*n*²)算法。如果你的目标是设计一个*O*(*n*)算法，那么设计一个*O*(*n* log *n*)的算法应该已经足够好了。

#### 处理函数调用

从第六章开始，我们编写了自己的函数，帮助我们设计更大的程序。在我们的大 O 分析中，我们需要小心地包括调用这些函数时所做的工作。

让我们回顾一下第六章中的卡片游戏问题。我们在清单 6-1 中解决了这个问题，我们的解决方案的一部分是调用了我们的`no_high`函数。我在这里重新展示了该解决方案：

```py
   NUM_CARDS = 52

❶ def no_high(lst):

       """

       lst is a list of strings representing cards.

       Return True if there are no high cards in lst, False otherwise.

       """

       if 'jack' in lst:

           return False

       if 'queen' in lst:

           return False

       if 'king' in lst:

           return False

       if 'ace' in lst:

           return False

       return True

   deck = []

❷ for i in range(NUM_CARDS):

       deck.append(input())

   score_a = 0

   score_b = 0

   player = 'A'

❸ for i in range(NUM_CARDS):

       card = deck[i]

       points = 0

       remaining = NUM_CARDS - i - 1

       if card == 'jack' and remaining >= 1 and no_high(deck[i+1:i+2]):

           points = 1

       elif card == 'queen' and remaining >= 2 and no_high(deck[i+1:i+3]):

           points = 2

       elif card == 'king' and remaining >= 3 and no_high(deck[i+1:i+4]):

           points = 3

       elif card == 'ace' and remaining >= 4 and no_high(deck[i+1:i+5]):

           points = 4

       if points > 0:

           print(f'Player {player} scores {points} point(s).')

       if player == 'A':

           score_a = score_a + points

           player = 'B'

       else:

           score_b = score_b + points

           player = 'A'

   print(f'Player A: {score_a} point(s).')

   print(f'Player B: {score_b} point(s).')
```

我们将使用 *n* 来表示卡片的数量。`no_high`函数 ❶ 需要一个列表并对其使用`in`操作，因此我们可能会得出它是 *O*(*n*) 时间复杂度的结论（毕竟，`in` 可能需要搜索整个列表来找到它要找的东西）。然而，我们只会在常数大小的列表——最多四张卡片——上调用`no_high`，所以我们可以将每次调用`no_high`视为 *O*(1) 时间复杂度。

现在我们理解了`no_high`的效率后，我们可以确定完整程序的大 O 效率。我们从一个循环开始，这个循环花费 *O*(*n*) 时间来读取卡片 ❷。然后我们进入另一个循环，它迭代 *n* 次 ❸。每次迭代仅需常数步骤，可能包括调用`no_high`，该函数也只需要常数步骤。因此，这个循环花费 *O*(*n*) 时间。因此，程序由两个 *O*(*n*) 部分组成，总的时间复杂度是 *O*(*n*)。

小心准确判断函数调用时执行的工作量。正如你刚刚看到的`no_high`，这可能涉及到同时观察函数本身以及它被调用的上下文。

**概念检查**

以下算法的大 O 效率是多少？

```py
def f(lst):

    for i in range(len(lst)):

        lst[i] = lst[i] + 1

# Assume that lst refers to a list of numbers

for i in range(len(lst)):

    f(lst)
```

A. *O*(1)

B. *O*(*n*)

C. *O*(*n*^(*2*))

答案：C. 主程序中的循环迭代了 *n* 次。在每次迭代中，我们调用函数`f`，而`f`本身也有一个循环，迭代 *n* 次。

#### 总结

执行工作最少的算法是 *O*(1)，接着是 *O*(log *n*)，然后是 *O*(*n*)，再接着是 *O*(*n* log *n*)。你曾经用其中一个算法解决过问题吗？如果是，那么你可能已经完成。如果不是，那么根据时间限制，你可能还有更多工作要做。

现在我们将来看两个问题，在这些问题中，直接的解决方案效率不足——它在时间限制内无法运行。利用我们刚刚学到的大 O 表示法，我们即使不实现代码，也能够预测出这种低效！然后我们将尝试一个更快速的解决方案，并实现它，以在时间限制内解决问题。

### 问题 #24：最长围巾

在这个问题中，我们将确定通过剪裁初始围巾，可以生产出最长的目标围巾。阅读完以下描述后，停下来想一想：你会如何解决它？你能提出多个算法并分析它们的效率吗？

这是 DMOJ 问题`dmopc20c2p2`。

#### 挑战

你有一条长度为 *n* 英尺的围巾，每一英尺都有一个特定的颜色。

你还有 *m* 个亲戚。每个亲戚通过指定围巾的第一英尺和最后一英尺的颜色，来表示他们想要的围巾样式。

你的目标是将原始围巾剪裁成一种方式，以便为某个亲戚制作出最长的所需围巾。

#### 输入

输入包括以下几行：

+   一行包含整数围巾长度*n*和整数亲戚人数*m*，二者由空格分隔。*n*和*m*的值都在 1 到 100,000 之间。

+   一行包含*n*个整数，整数之间由空格分隔。每个整数表示围巾的一个脚的颜色，顺序从第一个脚到最后一个脚。每个整数的值在 1 到 1,000,000 之间。

+   *m*行，每行一个亲戚，包含两个整数，中间用空格分隔。这两个数描述了亲戚所需的围巾：第一个整数是所需围巾的第一个脚的颜色，第二个整数是所需围巾的最后一个脚的颜色。

#### 输出

输出通过剪裁原始围巾能制作的最长所需围巾的长度。

解决测试用例的时间限制是 0.4 秒。

### 探索一个测试用例

让我们确保通过处理一个小的测试用例来准确理解所问的问题。以下是测试用例：

```py
6 3

18 4 4 2 1 2

1 2

4 2

18 4
```

我们有一条 6 英尺长的围巾和三个亲戚。围巾的每个脚的颜色依次是 18、4、4、2、1 和 2。那么我们能做出最长的所需围巾是什么？

第一个亲戚想要一条围巾，其第一个脚是颜色 1，最后一个脚是颜色 2。我们能做的最好是给这个亲戚一条 2 英尺长的围巾：围巾的最后两脚（颜色 1 和颜色 2）。

第二个亲戚想要一条围巾，其第一个脚是颜色 4，最后一个脚是颜色 2。我们可以给他们一条 5 英尺长的围巾：4, 4, 2, 1, 2。

第三个亲戚想要一条围巾，其第一个脚是颜色 18，最后一个脚是颜色 4。我们可以给他们一条 3 英尺长的围巾：18, 4, 4。

我们可以制作的最长围巾长度为 5，因此这是该测试用例的答案。

### 算法 1

我们刚才处理这个测试用例的方法可能立刻给你启发，帮助你想到一种可以用来解决这个问题的算法。也就是说，我们应该能逐个检查亲戚，找出每个亲戚所需围巾的最大长度。例如，第一个亲戚的最大长度可能是 2，因此我们记下这个值。第二个亲戚的最大长度可能是 5。这个比 2 长，所以我们记下 5。第三个亲戚的最大长度可能是 3。但这并不超过 5——所以没有变化。如果这让你想到了一个完全搜索的算法（第九章）：很好，因为这正是一个！

有*m*个亲戚。如果我们知道处理每个亲戚所需的时间，那么我们就能计算出我们需要处理的时间复杂度。

这里有一个想法：对于每个亲戚，让我们找到第一个脚的颜色的最左边索引和最后一个脚的颜色的最右边索引。一旦找到了这些索引，无论围巾多长，我们都可以利用这些索引快速确定该亲戚所需的最长围巾的长度。例如，如果第一个脚的颜色的最左边索引是 100，最后一个脚的颜色的最右边索引是 110，那么他们所需的最长围巾是 110 – 100 + 1 = 11。

根据我们寻找这些索引的方法，我们可能会很幸运地迅速找到它们。例如，我们可能从左边扫描以找到第一个脚的颜色的最左边索引，并从右边扫描以找到最后一个脚的颜色的最右边索引。然后，如果第一个脚的颜色靠近围巾的开头，最后一个脚的颜色靠近围巾的结尾，我们就能非常快速地发现这些索引。

然而，我们可能并不幸运。找到一个或两个索引可能需要多达 *n* 步。例如，假设某个亲戚想要的围巾第一个脚的颜色出现在围巾的最后，或者根本没有出现在围巾上。我们将不得不检查围巾的整个 *n* 个脚，一次一个，才能搞清楚这一点。

所以，对于每个亲戚，约 *n* 步。那是线性时间，我们知道线性时间是很快的。我们可以接受吗？不，因为在这种情况下，线性时间的工作远比它看起来更具威胁。记住，我们将对每个 *m* 个亲戚执行 *O*(*n*) 的工作。因此，我们的整体算法是 *O*(*mn*)。*m* 和 *n* 的值可能高达 100,000。这样，*mn* 可能高达 100,000 *** 100,000 = 10,000,000,000。这是 100 亿！考虑到我们每秒能进行约五百万次操作，而我们的时间限制是 0.4 秒……是的，我们远远不够。没有必要实现这个算法。我们确信它会在大规模测试用例中超时。我们不如继续前进，花时间实现其他东西。（如果你仍然对代码感兴趣，请查看与书籍相关的在线资源。只要记住，即使不看代码，我们已经意识到它会太慢。大 O 分析的强大之处在于，它能帮助我们在实现之前就了解一个算法是否注定失败。）

### 算法 2

我们必须以某种方式处理每个亲戚——这是无法避免的。那么，我们将专注于优化每个亲戚所需的工作量。不幸的是，以我们在上一节中所做的方式处理亲戚可能导致我们检查围巾的很大一部分。正是这种每处理一个亲戚就要扫描一遍围巾的搜索过程，压垮了我们。我们需要控制住这个搜索过程。

假设我们只能在一开始就看一次围巾，在了解任何亲戚想要什么之前。我们可以记住围巾中每种颜色的两件事：它的最左索引和最右索引。然后，不管每个亲戚想要什么，我们都可以通过我们已经存储的左索引和右索引来计算他们所需围巾的最大长度。

例如，假设我们有这条围巾：

```py
18 4 4 2 1 2
```

我们会为它存储以下信息：

| **颜色** | **最左索引** | **最右索引** |
| --- | --- | --- |
| 1 | 4 | 4 |
| 2 | 3 | 5 |
| 4 | 1 | 2 |
| 18 | 0 | 0 |

假设某个亲戚想要一条围巾，第一只脚是颜色 1，最后一只脚是颜色 2。我们查找颜色 1 的最左索引，它是 4，查找颜色 2 的最右索引，它是 5。然后我们计算 5 – 4 + 1 = 2，这就是这个亲戚所需围巾的最大长度。

真棒：无论围巾多长，我们只需要为每个亲戚做一次快速计算。再也不需要反复浏览围巾。唯一棘手的是如何计算所有颜色的最左和最右索引，并且仅通过查看围巾一次来完成。

代码呈现在列表 10-1 中。在继续阅读我接下来的解释之前，尝试理解`leftmost_index`和`rightmost_index`字典是如何构建的。

```py
   lst = input().split()

   n = int(lst[0])

   m = int(lst[1])

   scarf = input().split()

   for i in range(n):

       scarf[i] = int(scarf[i])

❶ leftmost_index = {}

❷ rightmost_index = {}

❸ for i in range(n):

       color = scarf[i]

    ❹ if not color in leftmost_index:

           leftmost_index[color] = i

           rightmost_index[color] = i

    ❺ else:

           rightmost_index[color] = i

   max_length = 0

   for i in range(m):

       relative = input().split()

       first = int(relative[0])

       last = int(relative[1])

       if first in leftmost_index and last in leftmost_index:

        ❻ length = rightmost_index[last] - leftmost_index[first] + 1

           if length > max_length:

               max_length = length

   print(max_length)
```

*列表 10-1：解决最长围巾问题，算法 2*

该解决方案使用了两个字典：一个用于跟踪每种颜色的最左索引❶，另一个用于跟踪每种颜色的最右索引❷。

如承诺，我们每次只看围巾的一只脚❸。下面是我们如何保持`leftmost_index`和`rightmost_index`字典实时更新的方法：

+   如果当前脚的颜色以前从未见过❹，那么当前索引将既是该颜色的最左索引，也是最右索引。

+   否则，当前脚的颜色已经出现过❺。我们不想更新该颜色的最左索引，因为当前索引在旧索引的右侧。然而，我们确实想要更新最右索引，因为我们找到了一个位于旧索引右侧的索引。

现在来说说回报：对于每个亲戚，我们可以简单地从这些字典❻中查找最左索引和最右索引。所需围巾的最大长度是最后一只脚的颜色的最右索引减去第一只脚的颜色的最左索引，再加一。

正如我现在要论证的，这个算法比算法 1 要好得多。读取围巾的操作需要 *O*(*n*) 时间，处理围巾的脚也需要 *O*(*n*) 时间。到目前为止，总共是 *O*(*n*) 时间。接下来，我们对每个相对进行常数次数的处理（不像之前那样是 *n* 步！），所以这是 *O*(*m*) 时间。总的来说，我们得到了一个 *O*(*m* + *n*) 的算法，而不是一个 *O*(*mn*) 的算法。鉴于 *m* 和 *n* 最大为 100,000，我们只需进行大约 100,000 + 100,000 = 200,000 步，完全可以在时间限制内完成。你可以把我们的代码提交给评测系统来验证！

### 问题 #25：绸带绘制

这是另一个问题，其中我们可能首先想到的算法太慢了。不过我们不会浪费太多时间在这个算法上，因为我们的大 O 分析会在我们考虑实现代码之前告诉我们所有需要知道的内容。然后我们将花时间设计一个更快的算法。

这是 DMOJ 问题 `dmopc17c4p1`。

#### 挑战任务

你有一条紫色绸带，长度为 *n* 单位。第一单位从位置 0 开始，直到但不包括位置 1，第二单位从位置 1 开始，直到但不包括位置 2，依此类推。然后你进行 *q* 次油漆笔画，每次涂抹绸带的一段蓝色。

你的目标是确定仍然是紫色的绸带单位数和现在是蓝色的单位数。

#### 输入

输入包含以下几行：

+   一行包含整数绸带长度 *n* 和油漆笔画的整数数量 *q*，两者用空格分隔。*n* 和 *q* 都在 1 到 100,000 之间。

+   *q* 行，每行一个油漆笔画，包含两个整数，用空格分隔。第一个整数给出油漆笔画的起始位置；第二个整数给出油漆笔画的结束位置。起始位置保证小于结束位置；每个整数都在 0 和 *n* 之间。油漆笔画从起始位置涂抹直到但不包括结束位置。这里给出一个简单的例子，如果油漆笔画的起始位置是 5，结束位置是 12，那么涂抹的区域是从位置 5 到但不包括位置 12。

#### 输出

输出绸带仍然是紫色的单位数，一个空格，和现在是蓝色的单位数。

解决测试用例的时间限制为 2 秒。

### 探索一个测试用例

我们来看一个小的测试用例。这个用例不仅能确保我们正确理解了问题，还能展示朴素算法的危险。这里是：

```py
20 4

18 19

4 16

4 14

5 12
```

我们的绸带长度是 20，油漆笔画次数是四次。我们的油漆笔画将绸带的多少部分涂成蓝色？

第一次油漆笔画涂抹的是起始位置为 18 的单个单位蓝色。

第二次油漆笔画涂抹的绸带单位是从位置 4、5、6、7 等等，一直到位置 15。这次笔画涂抹了 12 个单位，总共涂抹了 13 个蓝色单位。

第三次涂漆涂了 10 个蓝色单元，但这些单元都已经被第二次涂漆涂成蓝色！如果我们还花时间“涂漆”这些单元，那将是极大的时间浪费。无论我们提出什么算法，都最好避免这种时间浪费的陷阱。

第四次涂漆涂了 7 个蓝色单元。但同样：这些单元都已经是蓝色了！

现在我们完成了涂漆，得到了 13 个蓝色单元。剩余的紫色单元为 20 – 13 = 7 个，所以该测试用例的正确输出是：

```py
7 13
```

### 解决问题

丝带的最大长度为 100,000，最大涂漆次数为 100,000。回想一下我们在解决《最长围巾》问题时使用的算法 1，当时我们发现*O*(*mn*)算法在这些边界下运行太慢。类似地，在这里，*O*(*nq*)算法也不合适，因为在大规模测试用例上，它无法在时间限制内完成。

这意味着我们不能逐个处理每个涂漆单元。假如我们能更容易地专注于仅由涂漆涂成蓝色的*新*单元就好了。这样我们就可以遍历每个涂漆，计算它所贡献的蓝色单元数量。

说得对，但我们如何确定每次涂漆的贡献呢？这很棘手，因为下一次涂漆的一部分可能已经被前面的涂漆覆盖成了蓝色。

然而，如果我们先对涂漆进行排序，这种情况会变得简单得多。还记得本章早些时候提到的“n log n 时间”吗？排序是极其快速的，仅需*O*(*n* log *n*)时间。使用排序没有效率上的问题，所以让我们理解为什么排序在这里能帮助我们。

对上一节测试用例中的涂漆进行排序后，我们得到以下涂漆列表：

```py
4 14

4 16

5 12

18 19
```

现在涂漆已经排序好了，我们可以高效地处理它们。在处理的过程中，我们会存储目前为止已处理的涂漆中最右端的位置。我们从 0 开始设置这个最右端位置，表示我们尚未涂漆任何地方。

我们的第一次涂漆涂了 14 – 4 = 10 个蓝色单元。现在我们存储的最右端位置是 14。

我们的第二次涂漆涂了 12 个蓝色单元，没错，但其中有多少单元是从紫色变成蓝色的呢？毕竟，它与之前的涂漆有重叠，因此有一些单元已经是蓝色的了。我们可以通过将 14（我们存储的最右端位置）从 16（当前涂漆的结束位置）中减去，来计算出新的蓝色单元数量。这样，我们就可以忽略之前涂漆过的蓝色单元。所以，新的蓝色单元为 16 – 14 = 2 个，总共有 12 个蓝色单元。关键是，我们在没有处理该涂漆单元的具体细节情况下就解决了这个问题。在继续之前，别忘了更新我们存储的最右端位置为 16。

我们的第三次涂漆和第二次类似，它的起始位置在我们已存储的最右位置之前。然而，不同的是，它的结束位置并没有超过我们已存储的最右位置。因此，这次涂漆不会增加任何新的蓝色单位，我们已存储的最右位置仍然是 16。再次强调，我们通过不逐个计算每个涂漆位置就得出了这个结论！

小心处理第四次涂漆。它*并没有*增加 19 – 16 = 3 个新的蓝色单位。我们必须以不同的方式处理这次涂漆，因为它的起始位置位于我们已存储的最右位置的右侧。在这种情况下，我们根本不使用存储的最右位置，而是计算 19 – 18 = 1 个新的蓝色单位，总共得到 13 个蓝色单位。同时，我们更新存储的最右位置为 19。

唯一的问题是如何在 Python 代码中对涂漆进行排序。我们需要按它们的起始位置进行排序；如果多个涂漆的起始位置相同，则需要按它们的结束位置进行排序。

也就是说，我们希望处理一个像这样的列表：

```py
[[18, 19], [4, 16], [4, 14], [5, 12]]
```

并生成如下内容：

```py
[[4, 14], [4, 16], [5, 12], [18, 19]]
```

高兴的是，正如我们在第六章的“任务 4：排序盒子”中发现的那样，`sort` 方法正是这样工作的。当给定一个包含列表的列表时，`sort` 会使用每个列表中的第一个值进行排序；如果这些值相同，则会根据第二个值进一步排序。请查看：

```py
>>> strokes = [[18, 19], [4, 16], [4, 14], [5, 12]]

>>> strokes.sort()

>>> strokes

[[4, 14], [4, 16], [5, 12], [18, 19]]
```

算法：检查。排序：检查。我们准备得很好！在看到代码之前，还有一个问题我们想知道：它的时间复杂度是多少？我们需要读取 *q* 个查询；这需要 *O*(*q*) 的时间。然后，我们需要对查询进行排序；这需要 *O*(*q* log *q*) 的时间。最后，我们需要处理查询；这需要 *O*(*q*) 的时间。最慢的操作是排序所需的 *O*(*q* log *q*) 时间，因此这是我们的整体时间复杂度。

现在我们拥有了快速解决问题所需的一切。在列表 10-2 中查看它。

```py
   lst = input().split()

   n = int(lst[0])

   q = int(lst[1])

   strokes = []

   for i in range(q):

       stroke = input().split()

    ❶ strokes.append([int(stroke[0]), int(stroke[1])])

❷ strokes.sort()

   rightmost_position = 0

   blue = 0

   for stroke in strokes:

       stroke_start = stroke[0]

       stroke_end = stroke[1]

    ❸ if stroke_start <= rightmost_position:

           if stroke_end > rightmost_position:

            ❹ blue = blue + stroke_end - rightmost_position

               rightmost_position = stroke_end

    ❺ else:

        ❻ blue = blue + stroke_end - stroke_start

           rightmost_position = stroke_end

   print(n - blue, blue)
```

*列表 10-2：解决 Ribbon Painting 问题*

我们读取每次涂漆，将其作为包含两个值的列表添加到我们的 `strokes` 列表中 ❶。然后，我们对所有涂漆进行排序 ❷。

接下来，我们需要从左到右处理每一次涂漆。有两个关键变量控制着这一过程：变量 `rightmost_position` 存储我们到目前为止涂漆的最右位置，变量 `blue` 存储我们到目前为止涂漆的蓝色单位数。

要处理一次涂漆，我们需要知道它是从已存储的最右位置之前开始，还是之后开始。让我们逐一考虑这两种情况。

首先：当涂漆开始位置在我们已存储的最右位置之前时 ❸，我们该怎么办？这次涂漆可能会给我们一些新的蓝色单位，但只有当它超出我们已存储的最右位置时，才会增加新的蓝色单位。如果是这样，那么新增的蓝色单位就是从存储的最右位置到涂漆结束位置之间的单位 ❹。

第二：当涂漆操作从我们存储的最右位置 ❺ 开始时，我们该怎么办？这次，涂漆操作与我们迄今为止的涂漆完全分开；这整个涂漆操作是一个新的蓝色段。因此，新的蓝色单位是从这次涂漆的结束位置到起始位置之间的部分 ❻。

注意，在每个情况下，我们也正确地更新了我们存储的最右位置，以便我们准备好处理任何进一步的涂漆操作。

完成了！在我们的大 O 分析指导下，我们能够淘汰一个我们知道会太慢的算法实现。然后，我们考虑了第二个算法——在实现之前，我们就知道它会足够快。现在是时候将我们的代码提交给评判，享受我们的成功了。

### 总结

在这一章中，我们学习了大 O 分析。大 O 是进一步研究算法设计的一个重要效率构建块。你将会在各个地方看到它：教程中、书籍中，也许在你下一次的工作面试中！

我们还解决了两个问题，在这些问题中，我们需要设计非常高效的算法。我们不仅能够做到这一点，还能利用大 O 符号清楚地理解我们的代码为何如此高效。

### 章节练习

这里有一些练习供你尝试。对于每个练习，使用大 O 来判断你提出的算法是否足够高效，能够在时间限制内解决问题。你也可以实现那些你知道会太慢的算法，这将帮助你巩固 Python 知识，并确认你的大 O 分析是否准确！

这些问题有些非常具有挑战性。原因有二。首先，基于你在本书中的工作，你可能会同意，想出*任何*一个算法都很困难。而想出一个更快的算法可能会更难。其次，这是我们共同学习的结束，但算法研究才刚刚开始。如果你想继续深入，这些问题将帮助你既欣赏自己所取得的成就，又能证明在本书之外，还有很多内容等待你去探索。

1.  DMOJ 问题 `dmopc17c1p1`，Fujo Neko（这个问题讲的是使用快速输入/输出。不要忽视这一点！）

1.  DMOJ 问题 `coci10c1p2`，Profesor

1.  DMOJ 问题 `coci19c4p1`，Pod starim krovovima（提示：为了最大化空玻璃杯的数量，你需要将尽可能多的液体倒入最大的玻璃杯中。）

1.  DMOJ 问题 `dmopc20c1p2`，Victor 的道德困境

1.  DMOJ 问题 `avocadotrees`，鳄梨树！

1.  DMOJ 问题 `coci11c5p2`，Eko（提示：树木的最大数量远小于高度的最大数量。从最高的树开始考虑。）

1.  DMOJ 问题 `wac6p2`，廉价的圣诞灯（提示：不要尝试每秒都切换一次开关——你怎么知道该切换哪个呢？相反，先把它们都存起来，并在能关掉所有亮着的灯时一次性使用它们。）

1.  DMOJ 问题 `ioi98p3`，派对灯（提示：每个按钮的关键是它被按下的次数是偶数次还是奇数次。）

### 注释

最长围巾最初来自 DMOPC ’14 三月竞赛。丝带绘画最初来自 DMOPC ’20 十月竞赛。

## **7

微分学**

![image](Images/common.jpg)

艾萨克·牛顿爵士和戈特弗里德·威廉·莱布尼茨分别发现的“微积分”，是数学史上最伟大的成就之一。微积分通常分为两大部分：微分学和积分学。微分学讨论的是变化率及其关系，体现在导数的概念中。积分学则关注像曲线下面积之类的内容。

深度学习不需要积分学，但我们会经常使用微分学。例如，我们用微分学来训练神经网络；我们使用梯度下降法调整神经网络的权重，而梯度下降法依赖于通过反向传播算法计算的导数。

导数将成为本章的重点。我们将从引入斜率的概念开始，并看到它如何引出导数的概念。接下来，我们将正式定义导数，并学习如何计算单变量函数的导数。然后，我们将学习如何使用导数来找到函数的最小值和最大值。接下来是偏导数，针对多变量函数的单变量导数。我们将在反向传播算法中广泛使用偏导数。最后，我们将介绍梯度，这将引出矩阵微积分，这是[第 8 章](ch08.xhtml#ch08)的内容。

### 坡度

在代数课上，我们学习了关于直线的所有知识。定义一条直线的一种方式是使用斜率-截距形式，

*y* = *mx* + *b*

其中 *m* 是斜率，*b* 是 *y* 截距，即直线与 y 轴交点的位置。我们关注的是斜率。如果我们知道直线上的两个点，(*x*[1], *y*[1]) 和 (*x*[0], *y*[0])，我们就能知道这条直线的斜率：

![Image](Images/164equ01.jpg)

*斜率* 告诉我们，*x* 位置的任何变化将导致 *y* 变化多少。如果斜率为正，则 *x* 的正向变化会导致 *y* 的正向变化。相反，负斜率意味着 *x* 的正向变化会导致 *y* 的负向变化。

直线的斜率-截距形式告诉我们，斜率是 *x* 和 *y* 之间的比例常数。截距 *b* 是一个常数偏移。这意味着，*x* 位置从 *x*[1] 变化到 *x*[0] 会导致 *m*(*x*[1] − *x*[0]) 的 *y* 变化。斜率将两个事物联系在一起，告诉我们改变一个事物如何影响另一个事物。我们将在本书的多次内容中回到这个概念。

现在，让我们通过一些例子来可视化这一点。[图 7-1](ch07.xhtml#ch07fig01)展示了一个曲线和一些与之相交的直线。

![image](Images/07fig01.jpg)

*图 7-1：一条曲线与一条割线 (*A*) 和一条切线 (*B*)*

标记为 *A* 的线在两个点 *x*[1] 和 *x*[0] 处与曲线相交。通过曲线上两个点的线叫做 *割线*。另一条线 *B* 仅在点 *x**[t]* 处与曲线相切。与曲线仅相切的线叫做 *切线*。我们将在下一节回到割线的讨论，但现在请注意，切线在 *x**[t]* 处有一个特定的斜率，并且当点 *x*[1] 和 *x*[0] 之间的距离趋向于零时，割线会变成切线。

假设我们将点 *x**[t]* 从曲线的一点移动到另一点；我们可以看到，切线在 *x**[t]* 处的斜率会随之变化。当我们接近曲线的最小点，接近 *x* = 0.3 时，我们会看到斜率变得越来越平缓。如果从左边接近，斜率是负的，且变得越来越不负。如果从右边接近，斜率是正的，但变得越来越小。在实际的最小点，接近 *x* = 0.3 时，切线是水平的，斜率为零。类似地，如果我们接近曲线的最大值，接近 *x* = −0.8，斜率也会接近零。

我们可以看到，切线告诉我们曲线在某一点的变化情况。正如我们将在本章后面看到的那样，切线斜率在曲线的最小值和最大值处为零，这为我们提供了一种找到这些点的方法。切线斜率为零的点被称为 *驻点*。

当然，为了利用切线的斜率，我们需要能够找到曲线上任何 *x* 点的切线斜率。下一节将向我们展示如何做到这一点。

### 导数

上一节介绍了割线和切线的概念，并暗示了在曲线的任何一点上知道切线的斜率是一个潜在有用的知识。切线在某一点 *x* 的斜率被称为该点的 *导数*。它告诉我们曲线（函数）在点 *x* 处是如何变化的，也就是说，函数值如何随着 *x* 的微小变化而变化。在这一节中，我们将正式定义导数，并学习计算单变量函数 *x* 导数的快捷规则。

#### 一个正式的定义

一门典型的第一学期微积分课程通过研究极限来介绍导数。我在上文中提到过，当曲线上两点之间的割线斜率随着两点重合而变成切线时，极限就发挥了作用。

例如，如果 *y* = *f*(*x*) 是一条曲线，并且我们有曲线上的两点 *x*[0] 和 *x*[1]，那么这两点之间的斜率，Δ*y*/Δ*x*，是

![Image](Images/07equ01.jpg)

这就是你可能在学校里学过的 *升除以跑*。*升*，Δy = *y*[1] − *y*[0] = *f*(*x*[1]) − *f*(*x*[0])，除以 *跑*，Δ*x* = *x*[1] − *x*[0]。我们通常使用Δ作为前缀，表示某个变量的变化。

如果我们定义 *h* = *x*[1] − *x*[0]，我们可以将 [方程 7.1](ch07.xhtml#ch07equ01) 重写为

![Image](Images/166equ01.jpg)

因为 *x*[1] = *x*[0] + *h*。

在这种新形式下，我们可以通过让 *h* 趋近于零，*h* → 0，来找到 *x*[0] 处切线的斜率。让一个值趋近于另一个值叫做 *极限*。让 *h* → 0 就是将我们计算斜率的两个点越来越接近。这直接引出了导数的定义。

![Image](Images/07equ02.jpg)

其中 *dy*/*dx* 或 *f′*(*x*) 用于表示 *f*(*x*) 的导数。

在我们深入探讨导数的含义之前，先花一点时间讨论符号。使用 *f*′(*x*) 表示导数的方式源自 Joseph-Louis Lagrange。Leibniz 使用 *dy*/*dx* 来模仿斜率符号，其中 Δ → *d*。如果 Δ*y* 表示两点间 *y* 的变化，那么 *dy* 表示在某一点 *y* 的无穷小变化。Newton 使用了另一种符号，![Image](Images/166equ02.jpg)，其中点代表 *f* 的导数。物理学家通常在涉及时间导数的特定情况下使用 Newton 的符号。例如，如果 *f*(*t*) 是一个粒子随时间 *t* 变化的位置，则 ![Image](Images/166equ03.jpg) 是关于 *t* 的导数，也就是位置随时间变化的情况。位置随时间的变化就是速度（如果使用向量则是速度）。你将在书籍中看到所有这些符号。我的偏好是，对于时间函数，保留 ![Image](Images/166equ02.jpg)，而在其他地方则交替使用 Lagrange 的 *f*′(*x*) 和 Leibniz 的 *dy*/*dx*。

尽管上面的 [方程 7.2](ch07.xhtml#ch07equ02) 非常繁琐，是许多初学微积分的学生的痛苦，至少直到他们遇到积分之前，你还是可以在需要时使用它。然而，在本书中我们不会讨论积分，所以你可以深呼吸，放松一下。

在经历了极限的艰难之后，微积分学生会得到一个秘密：一小组规则将使你能够*不使用*极限计算几乎所有的导数。我们将逐一介绍这些规则，并通过示例进行讲解，最后，在本节结束时，我们将把它们结合起来，形成适合印在 T 恤上的形式。

然而，在我们深入了解规则之前，让我们再花一点时间讨论 *导数* 传达给我们的含义。如上所述，我提到过位置随时间的变化由导数给出。这对于所有的导数都是适用的；它们告诉我们某个事物如何随另一个事物的变化而变化。我们甚至可以从 Leibniz 的符号 *dy*/*dx* 中看到这一点，即 *dy* 随 *dx* 的变化情况。*x* 处的导数告诉我们函数在 *x* 处如何变化。正如我们将看到的，*f*(*x*) 的导数本身就是 *x* 的新函数。如果我们选择一个特定的 *x*[0]，那么我们就知道 *f*(*x*[0]) 是函数在 *x*[0] 处的值。

类似地，如果我们知道导数，那么 *f*′(*x*[0]) 就是函数 *f*(*x*) 在 *x*[0] 处变化的速度和方向。可以将速度定义为位置随时间变化的量。我们甚至可以用话语表达：我的当前速度是 30 英里每小时（*miles per hour*）——即位置相对于时间变化的速度。

我们将使用导数来表示速率，并观察改变一件事如何影响另一件事。最终，对于深度学习，我们希望了解改变网络中某个参数的值将如何最终改变损失函数，即网络实际输出与预期输出之间的误差。

如果 *f*′(*x*) 是 *x* 的函数，那么我们应该能够对其进行微分。我们称 *f*′(*x*) 为 *一阶导数*。它的导数，记作 *f*′′(*x*)，就是 *二阶导数*。在莱布尼茨符号中，我们写作 *d*²*y*/*dx*²。二阶导数告诉我们一阶导数如何随 *x* 变化。物理学在这里有所帮助。位置相对于时间的导数 (*f*) 是 *速度*，![Image](Images/167equ01.jpg)——即位置随时间变化的速率。因此，位置的二阶导数，![Image](Images/167equ02.jpg)，是速度的一阶导数，表示速度随时间的变化。我们称之为 *加速度*。

从理论上讲，我们可以计算任意多的导数。而在实际中，许多函数最终会有一个常数值的导数。由于常数值不发生变化，因此它的导数为零。

总结一下，*f*(*x*) 的导数是另一个函数，*f*′(*x*) 或 *dy*/*dx*，它告诉我们 *f*(*x*) 在每个点处的切线斜率。并且，由于 *f*′(*x*) 是 *x* 的函数，它也有导数，即 *f*′′(*x*) 或 *d*²*y*/*dx*²，二阶导数，告诉我们 *f*′(*x*) 在每个 *x* 处如何变化，依此类推。接下来我们将看到如何利用一阶和二阶导数。现在，让我们学习 *微分* 的规则，即计算导数的过程。

#### 基本规则

在上一节中我们提到了一条规则：常数 *c* 的导数是零。所以我们写作

![Image](Images/167equ03.jpg)

在这里我们使用了莱布尼茨符号表示法：*d*/*dx*。可以将 *d*/*dx* 看作是作用于后面的内容，它的作用方式类似于否定：要否定 *c*，我们写作 *−c*；要对 *c* 进行微分，我们写作 ![Image](Images/167equ04.jpg)。如果我们的表达式中没有 *x*，我们就将其视为常数，其导数为零。

##### 幂法则

一个幂函数的导数遵循 *幂法则*，

![Image](Images/168equ01.jpg)

其中 *a* 是常数，*n* 是一个指数，且不需要是整数。让我们看一些例子：

![Image](Images/168equ02.jpg)

我们常常将代数表达式构建为加减法项。微分是一个线性运算符，因此我们可以写作

![Image](Images/168equ03.jpg)

这意味着我们逐项计算导数。例如，利用到目前为止我们掌握的规则，我们现在知道如何计算多项式的导数：

![Image](Images/168equ04.jpg)

一般来说，公式是：

![Image](Images/169equ01.jpg)

在这里我们看到，阶数为 *n* 的多项式的导数是另一个阶数为 *n* − 1 的多项式，且原多项式中的常数项将变为零。

##### 乘积法则

函数相乘的求导有其独特的规则，即*乘积法则*：

![Image](Images/169equ02.jpg)

乘积的导数是第一个函数的导数乘以第二个函数加上第二个函数的导数乘以第一个函数。考虑以下例子：

![Image](Images/169equ03.jpg)

##### 商法则

一个函数除以另一个函数的导数遵循*商法则*：

![Image](Images/169equ04.jpg)

这导致了像这样的例子：

![Image](Images/170equ01.jpg)

##### 链式法则

下一个规则涉及函数的合成。当一个函数的输出作为另一个函数的输入时，就形成了函数的合成。*链式法则*适用于函数合成，并且在神经网络的训练中具有基础性的重要性。该规则是：

![Image](Images/170equ02.jpg)

我们将外部函数的导数（使用 *g*(*x*) 作为变量）乘以内层函数相对于 *x* 的导数。

作为第一个例子，考虑函数 *f*(*x*) = (*x*² + 2*x* + 3)²。 这是两个函数的合成吗？是的。我们可以定义 *f*(*g*) = *g*² 和 *g*(*x*) = *x*² + 2*x* + 3。然后，我们可以通过将 *f*(*g*) 中的每个 *g* 替换为 *g* 在 *x* 下的定义，来找到 *f*(*x*)：*g*(*x*) = *x*² + 2*x* + 3。这样就得到了：

*f*(*x*) = *g*² = (*x*² + 2*x* + 3)²

这自然就是我们最初的公式。为了找到 *f*′(*x*)，我们首先找到 *f*′(*g*)，即 *f* 对 *g* 的导数，然后乘以 *g*′(*x*)，即 *g* 对 *x* 的导数。最后一步是将所有 *g* 替换为其在 *x* 下的定义。因此，我们计算 *f*′(*x*) 得到：

![Image](Images/170equ03.jpg)

我们通常不会明确写出 *f*(*g*) 和 *g*(*x*)，但在心里我们会按照相同的过程进行推导。让我们再看一些例子。在这个例子中，我们想要找到：

![Image](Images/171equ01.jpg)

如果我们使用链式法则，我们可以看到 *f*(*g*) = 2*g*² + 3 且 *g*(*x*) = 4*x* − 5。 因此，我们可以写成：

![Image](Images/171equ02.jpg)

其中 *f*′(*g*) = 2*g* 且 *g*′(*x*) = 4。通过一些练习，我们会在心里将 *f*(*x*) 中的 4*x* − 5 看作是自己的变量（即 *g* 的替代），并且记得在求导时乘上 4*x* − 5 的导数。如果我们没有看到合成呢？如果我们展开整个函数 *f*(*x*)，然后再求导呢？我们最好能得到使用链式法则时得到的答案。我们来看看……

![Image](Images/171equ03.jpg)

这是我们之前找到的结果，因此我们应用链式法则是正确的。

让我们看另一个例子。如果 ![图片](Images/171equ04.jpg)，我们应该如何考虑计算导数呢？如果我们把函数看作 ![图片](Images/171equ05.jpg)，其中 *u*(*x*) = 1 和 *v*(*x*) = 3*x*²，我们可以使用商法则，得到如下结果。

![图片](Images/172equ01.jpg)

在这里，我们使用了 *u* 和 *v* 的简写符号，省略了 *x* 的正式函数符号。

我们还可以将 *f*(*x*) 想象为 (3*x*²)^(−1)。如果我们这样思考，我们可以应用链式法则和幂法则得到

![图片](Images/172equ02.jpg)

证明了有时计算导数有不止一种方法。

我们用拉格朗日符号介绍了链式法则。稍后在本章中，我们将看到使用莱布尼茨符号的版本。现在让我们继续介绍一组三角函数的规则。

#### 三角函数规则

基本三角函数的导数是直接的：

![图片](Images/172equ03.jpg)

如果我们将基本的求导规则应用于切线的定义，可以看出最后一条规则是正确的：

![图片](Images/173equ01.jpg)

记住，sec *x* = 1/ cos *x* 且 sin² *x* + cos² *x* = 1。

让我们通过一些例子来使用新的三角函数规则。我们从一个包含三角函数的复合函数开始：

![图片](Images/173equ02.jpg)

我们可以看到这是一个复合函数 *f*(*g*) = sin(*g*) 和 *g*(*x*) = *x*³ − 3*x*，因此我们知道可以应用链式法则得到导数，即 *f*′(*g*)*g*′(*x*)，其中 *f*′(*g*) = cos(*g*) 和 *g*′(*x*) = 3*x*² − 3。第二行简化了答案。

让我们看一个更复杂的复合函数：

![图片](Images/173equ03.jpg)

这次，我们将复合函数分解为 *f*(*g*) = *g*² 和 *g*(*x*) = sin(*x*³ − 3*x*)。然而，*g*(*x*) 本身是 *g*(*u*) = sin(*u*) 和 *u*(*x*) = *x*³ − 3*x* 的复合函数，正如我们在前一个例子中所做的那样。所以，第一步是写出如下内容。

![图片](Images/174equ01.jpg)

第一行是复合函数导数的定义。第二行代入了 *f*(*g*) 的导数，即 *2g*，第三行将 *g*(*x*) 替换为 sin(*x*³ − 3*x*)。现在，我们只需要找到 *g*′(*x*)，我们可以通过第二次应用链式法则来做到这一点，令 *g*(*u*) = sin *u* 和 *u*(*x*) = *x*³ − 3*x*，正如上面的例子所示。这样我们得到 *g*′(*x*) = cos(*x*³ − 3*x*)(3*x*² − 3)，所以现在我们知道 *f*′(*x*) 是

![图片](Images/174equ02.jpg)

再做一个例子。这次涉及多个三角函数。我们想看看如何计算

![图片](Images/174equ03.jpg)

正如在处理三角函数时常见的那样，恒等式发挥了作用。在这里，我们看到 *f*(*x*) 可以重写为：

![图片](Images/174equ04.jpg)

现在，导数使用了三角函数规则、割线的定义、链式法则和乘积法则，如下所示。

![图片](Images/175equ01.jpg)

让我们继续看指数和对数的导数。

#### 指数和对数法则

*e**^x* 的导数，其中 *e* 是自然对数的底数（*e* ≈ 2.718…），特别简单。它就是它本身：

![Image](Images/175equ02.jpg)

当自变量是 *x* 的函数时，这变为

![Image](Images/07equ03.jpg)

如果 *e^x* 的导数是 *e^x*，那么当 *a* 是除 *e* 外的实数时，*a^x* 的导数是什么？为了看答案，我们需要记住，*e^x* 和 ln *x*（以 *e* 为底的自然对数）是反函数，所以 *e*^(ln*a*) = *a*。然后，我们可以写成

*a^x* = (*e*^(ln *a*))^(*x*) = *e^x*^(ln *a*)

我们知道如何从上面的 [方程 7.3](ch07.xhtml#ch07equ03) 找到 *e^x*^(ln*a*) 的导数。它是

![Image](Images/175equ03.jpg)

但 *e x* ln *a* = *a^x*，所以我们有

![Image](Images/175equ04.jpg)

一般来说，

![Image](Images/07equ04.jpg)

请注意，如果 *a* = *e*，我们有 ln(*e*) = 1，并且 [方程 7.4](ch07.xhtml#ch07equ04) 变成 [方程 7.3](ch07.xhtml#ch07equ03)。

现在让我们看一下自然对数本身的导数。它是

![Image](Images/176equ01.jpg)

当自变量是 *x* 的函数时，这变为

![Image](Images/07equ05.jpg)

你可能会问：如何找到使用非 *e* 为底的对数的导数？例如，log[10] *x* 的导数是什么？为了回答这个问题，我们做一些类似于我们之前对 *a**^x* 的导数所做的事情。我们把以某个底数 *b* 的对数写成自然对数的形式，如下：

![Image](Images/176equ02.jpg)

这里，ln *b* 是一个常数，不依赖于 *x*。此外，我们现在知道如何找到 ln *x* 的导数，因此我们可以看到，log*[b] x* 的导数必须是

![Image](Images/176equ03.jpg)

对于任何实数底数 *b* ≠ 1。并且，更一般地，

![Image](Images/07equ06.jpg)

在这里，我们再次注意到，如果 *b* = *e*，则得到 ln *e* = 1，并且 [方程 7.6](ch07.xhtml#ch07equ06) 变成了 [方程 7.5](ch07.xhtml#ch07equ05)。

使用 [方程 7.6](ch07.xhtml#ch07equ06)，我们已经完成了导数法则的总结。现在，让我们把它们合并成一个表格，供我们在书的其余部分中参考。结果是 [表 7-1](ch07.xhtml#ch07tab01)。

我们现在知道如何找到导数了。我鼓励你去找一些带有解答的练习题，以确保自己理解了这些法则以及如何应用它们。接下来，让我们继续看如何使用导数来寻找函数的最小值和最大值。寻找最小值对神经网络的训练至关重要。

**表 7-1：** 导数法则

| **类型** | **法则** |
| --- | --- |
| 常数 | ![Image](Images/177equ01.jpg) |
| 幂 | ![Image](Images/177equ02.jpg) |
| 和 | ![Image](Images/177equ03.jpg) |
| 积 | ![Image](Images/177equ04.jpg) |
| 商 | ![Image](Images/177equ05.jpg) |
| 链式法则 | ![Image](Images/177equ06.jpg) |
| 三角学 | ![Image](Images/177equ07.jpg) |
| 指数 | ![Image](Images/177equ08.jpg) |
| 对数 | ![Image](Images/177equ09.jpg) |

### 函数的最小值和最大值

之前，我定义了驻点是指函数的一阶导数为零的地方，也就是切线的斜率为零的地方。我们可以利用这些信息来判断一个特定点，假设它是 *x[m]*，是否是函数 *f*(*x*) 的最小值或最大值。如果 *x[m]* 是最小值，那么它是函数的一个低点，其中 *f*(*x[m]*) 小于 *f*(*x*) 左右相邻点的值。类似地，如果 *f*(*x[m]*) 大于左右相邻点的值，那么 *f*(*x[m]*) 是一个最大值。我们通常将最小值和最大值统称为 *f*(*x*) 的 *极值*（单数形式为 *极值点*）。

在导数的角度来看，*最小值*是指在 *x[m]* 左边的点的导数为负，而 *x[m]* 右边的点的导数为正的地方。*最大值*则相反：左边的导数为正，右边的导数为负。

回到 [图 7-1](ch07.xhtml#ch07fig01)。在图中，我们有一个局部最大值大约在 *x* = −0.8 处，局部最小值大约在 *x* = 0.3 处。假设最大值实际上出现在 *x[m]* = −0.8 处。这是一个最大值，因为如果我们查看 *x[m]* 附近的任何点 *x[p]*，*f*(*x[p]*) 都小于 *f*(*x[m]*)。同样，如果最小值出现在 *x[m]* = 0.3 处，那是因为其附近的任何点 *x[p]* 都有 *f*(*x[p]*) > *f*(*x[m]*)。如果我们想象切线沿着图像滑动，当它接近 *x* = −0.8 时，我们会看到斜率是正的，但正在趋向零。当我们越过 *x* = −0.8 时，斜率变为负数。对于 *x* = 0.3 处的最小值，情况则相反。从左边接近的切线斜率为负，但一旦超过 *x* = 0.3，斜率变为正。

你会看到并听到“*全局*”和“*局部*”这两个术语被应用于最小值和最大值。*f*(*x*) 的全局最小值是所有最小值中的最小值，而全局最大值是所有最大值中的最大值。其他的最小值和最大值则被视为局部的；它们仅在特定区域内有效，但还有其他更低的最小值或更高的最大值。我们需要注意的是，并非所有函数都有最小值或最大值。例如，直线 *f*(*x*) = *mx* + *b* 没有最小值或最大值，因为直线上的任何点都不符合最小值或最大值的要求。

所以，如果一阶导数 *f*′(*x*) 为零，我们是不是就得到了一个最小值或最大值呢？别急。在其他驻点处，一阶导数可能为零，但满足最小值或最大值的剩余条件并未满足。这些点通常被称为 *拐点*，如果是多维的，则称为 *鞍点*。例如，考虑 *y* = *x*³。其一阶导数为 *y*′ = 3*x*²，二阶导数为 *y*′′ = 6*x*。在 *x* = 0 处，一阶和二阶导数均为零。然而，正如我们在[图 7-2](ch07.xhtml#ch07fig02)中看到的，*x* = 0 处左右两侧的坡度都是正的。因此，坡度不会从正变负或从负变正，这意味着 *x* = 0 不是极值点，而是一个拐点。

![image](Images/07fig02.jpg)

*图 7-2：y = x³ 的图像，显示在 x = 0 处的拐点*

现在假设 *x[s]* 是一个驻点，因此 *f*′(*x[s]*) = 0。如果我们选择两个其他点，*x[s−∊]* 和 *x[s+∊]*，一个位于 *x[s]* 左侧，另一个位于右侧，且 ∊（epsilon）非常小，我们有四种 *f*′(*x[s]*[−∊]) 和 *f*′(*x[s]*[+∊]) 的可能值，如[表 7-2](ch07.xhtml#ch07tab02)所示。

**表 7-2：识别驻点**

| **f′(*x[s]* – ∊), f′(*x[s]* + ∊) 的符号** | **驻点 *x[s]* 类型 – ∊ < *x[s]* < *x[s]* + ∊** |
| --- | --- |
| +, – | 最大值 |
| –, + | 最小值 |
| +, + | 既不是 |
| –, – | 既不是 |

因此，候选驻点处的一阶导数值不足以告诉我们该点是极小值还是极大值。我们可以查看候选点周围的区域来帮助我们做出判断。我们还可以查看 *f*′′(*x*)，即 *f*(*x*) 的二阶导数的值。如果 *x[s]* 是一个驻点，且 *f*′(*x[s]*) = 0，*f*′′(*x[s]*) 的符号可以告诉我们 *x[s]* 可能是何种类型的驻点。如果 *f*′′(*x[s]*) < 0，那么 *x[s]* 是 *f*(*x*) 的一个 *最大值*。如果 *f*′′(*x[s]*) > 0，*x[s]* 是一个最小值。如果 *f*′′(*x[s]*) = 0，二阶导数无法提供帮助；我们需要通过一阶导数显式地测试附近的点。

我们如何找到候选的驻点呢？对于代数函数，我们解 *f*′(*x*) = 0；我们找到所有使得 *f*(*x*) 的一阶导数为零的 *x* 值的解集。然后，我们使用导数检验来决定这些点是最小值、最大值还是拐点。

对于许多函数，我们可以直接找到 *f*′(*x*) = 0 的解。例如，如果 *f*(*x*) = *x*³ − 2*x* + 4，我们有 *f*′(*x*) = 3*x*² − 2。如果我们将其设为零，*3x*[2] − 2 = 0，并使用二次公式解出，我们会发现有两个驻点：![图片](Images/179equ01.jpg) 和 ![图片](Images/179equ02.jpg)。*f*(*x*) 的二阶导数是 *f*′′(*x*) = 6*x*。*f*′′(*x*[0]) 的符号为负，因此 *x*[0] 代表一个最大值。由于 *f*′′(*x*[1]) 的符号为正，*x*[1] 是一个最小值。

我们可以看到，导数测试是正确的。图[7-3](ch07.xhtml#ch07fig03)的顶部显示了 *f*(*x*) = *x*³ − 2*x* + 4 的图像，其中 *x*[0] 是最大值，*x*[1] 是最小值。

让我们再看一个例子。这次我们有 *f*(*x*) = *x*⁵−2*x*³+*x*+2，图[7-3](ch07.xhtml#ch07fig03)的底部图像。我们找到一阶导数并将其设为零：

*f*′(*x*) = 5*x*⁴ − 6*x*² + 1 = 0

如果我们令 *u* = *x*²， 通过求解 5*u*²−6*u*+1 的根并将它们设为 *x*²，可以求出 *f*′(*x*) 的根。这样我们得到！[图片](Images/179equ03.jpg) 和！[图片](Images/179equ04.jpg)，因此我们有四个驻点。为了测试这些驻点，我们可以使用二阶导数测试。二阶导数是 *f*′′(*x*) = 20*x*³ − 12*x*。

将驻点代入 *f*′′ 得到

![图片](Images/180equ01.jpg)

这意味着 *x*[0] 是最大值，*x*[1] 是最小值，*x*[2] 是另一个最大值，*x*[3] 是最小值。图[7-3](ch07.xhtml#ch07fig03)再次确认了我们的结论。

![图片](Images/07fig03.jpg)

*图7-3：图像 f(x) = x³ – 2x + 4（上）和 x⁵ – 2x³ + x + 2（下），极值标记*

如果我们无法轻松找到一个函数的驻点该怎么办？也许我们无法代数解出该函数，或者它可能无法以封闭形式表示，即没有有限的运算集能表示它。典型的微积分课程不会关注这些情况。然而，我们需要关注这些问题，因为神经网络的一种思维方式是作为一个函数逼近器，它的函数不能直接表示。我们是否仍然可以有益地使用导数的知识呢？答案是肯定的，我们可以。我们可以利用导数作为指针，告诉我们如何不断接近极值点。这就是梯度下降法的作用，我们将在本书的后面部分详细讨论它。

然而，目前让我们继续前进，研究多变量函数，并看看这对导数的概念有什么影响。

### 偏导数

到目前为止，我们一直专注于单变量函数，*x*。当我们有多个变量的函数时，例如 *f*(*x*, *y*)，或者 *f*(*x*[0], *x*[1], *x*[2], . . . , *x[n]*)，微分的概念会发生什么变化呢？为了处理这些情况，我们将引入*偏导数*的概念。注意，为了更清晰起见，在本节中我们将使用莱布尼茨符号。

[方程 7.2](ch07.xhtml#ch07equ02) 定义了 *f*(*x*) 对 *x* 的导数。如果 *x* 是唯一的变量，为什么我们还要加上“关于 *x*”这一额外的描述呢？现在我们来找出原因：表达式中关于某个变量的偏导数是通过将所有其他变量保持固定来求得的。我们将它们当作常数来处理。然后我们说我们正在计算相对于那个没有被固定的变量的偏导数。

让我们看一个例子。假设 *f*(*x*, *y*) = *xy* + *x*/*y*。然后，我们可以计算出两个偏导数，一个关于 *x*，另一个关于 *y*：

![Image](Images/181equ01.jpg)

我们在本章早些时候学习的微分规则仍然适用。注意，*d* 已经变成了 ∂，这表示函数 *f* 是多变量函数。此外，在计算相应的导数时，我们保持其他变量不变，仿佛它们是参数。至于计算偏导数，就是这样。让我们看几个例子，帮助你更好地理解这个概念。

如果 *f*(*x*, *y*, *z*) = *x*² + *y*² + *z*² + 3*xyz*，我们可以求出三个偏导数：

![Image](Images/182equ01.jpg)

其他两个变量被视为常数。这就是为什么，例如，在关于 *x* 的偏导数中，*y*² 和 *z*²变成了0，而 3*xyz* 变成了 *3yz*。

如果 ![Image](Images/182equ02.jpg)，我们有四个偏导数：

![Image](Images/182equ03.jpg)

作为一个更复杂的例子，考虑 *f*(*x*, *y*) = *e^(xy)* cos *x* sin *y*。以下列出了偏导数，在每种情况下我们都使用了乘积法则。

![Image](Images/183equ01.jpg)

#### 混合偏导数

就像对单变量函数求导数一样，我们也可以对偏导数再求偏导数。这些被称为 *混合偏导数*。此外，我们还具有更多的灵活性，因为我们可以改变下一个偏导数所依赖的变量。例如，上面我们看到的 *f* 关于 *z* 的偏导数是：

![Image](Images/183equ03.jpg)

这仍然是 *x*、*y*、*z* 和 *t* 的函数。因此，我们可以像这样计算二阶偏导数：

![Image](Images/183equ04.jpg)

我来解释一下符号。我们从 *f* 关于 *z* 的偏导数开始，所以我们写 ∂*f*/∂*z*。然后，从这个起点出发，我们再继续求其他偏导数。所以，如果我们想表示关于 *x* 的偏导数，我们可以这样理解：

![Image](Images/184equ01.jpg)

我们可以将偏导数运算符“乘”以“分子”和“分母”像分数一样来理解。然而，明确地说，这些并不是分数；这种符号的用法继承了分数的形式，源自它的斜率表示。尽管如此，如果这个助记符有帮助，那么它就是有帮助的。对于二阶偏导数，与之相关的变量在左侧。此外，如果变量相同，使用一种类似指数的符号，如 ∂²*f*/∂*z*²。

#### 偏导数的链式法则

要将链式法则应用于偏导数，我们需要跟踪所有变量。因此，如果我们有 *f*(*x*, *y*)，其中 *x* 和 *y* 都是其他变量的函数，即 *x*(*r*, *s*) 和 *y*(*r*, *s*)，那么我们可以通过对每个变量 *x* 和 *y* 应用链式法则，找到 *f* 对 *r* 和 *s* 的偏导数。具体来说，

![Image](Images/184equ02.jpg)

作为一个例子，设 *f*(*x*, *y*) = *x*³ + *y*³，且 *x*(*r*, *s*) = 3*r* + 2*s*，*y*(*r*, *s*) = *r*² − 3*s*。现在求 ∂*f*/∂*r* 和 ∂*f*/∂*s*。为了求这些偏导数，我们需要计算六个表达式，

![Image](Images/184equ03.jpg)

因此，所需的偏导数为

![Image](Images/185equ01.jpg)

就像单变量函数一样，针对多变量函数的链式法则是递归的，因此，如果 *r* 和 *s* 本身是另一个变量的函数，我们可以再次应用链式法则，找到 *f* 对该变量的偏导数。例如，如果我们有 *x*(*r*, *s*)，*y*(*r*, *s*)，且 *r*(*w*)，*s*(*w*)，我们可以使用以下公式来求 ∂*f*/∂*w*，

![Image](Images/185equ02.jpg)

最终，我们需要记住，∂*f*/∂*w* 告诉我们 *f* 会如何随着 *w* 的小变化而变化。我们将在梯度下降过程中使用这一事实。

本节内容关注的是偏导数的机械计算。接下来我们将继续探讨这些量背后的意义，这将引导我们进入梯度的概念。

### 梯度

在[第8章](ch08.xhtml#ch08)中，我们将深入探讨在深度学习中使用的矩阵微积分表示方法。然而，在此之前，我们将通过引入*梯度*的概念来总结本章内容。梯度是建立在我们已计算的导数基础上的。简而言之，梯度告诉我们一个多变量函数如何变化，以及它在哪个方向变化最快。

#### 计算梯度

如果我们有*f*(*x*，*y*，*z*)，我们上面已经看到如何计算关于每个变量的偏导数。如果我们将这些变量解释为坐标轴上的位置，我们就会发现*f*是一个函数，它为3D空间中的任何位置（*x*，*y*，*z*）返回一个标量，即单一数字。我们甚至可以写*f*(***x***)，其中***x*** = (*x*，*y*，*z*)，以承认*f*是一个向量输入的函数。像前几章一样，我们将使用加粗的小写字母来表示向量，***x***。注意，有些人使用![Image](Images/xbar.jpg)来表示向量。

我们可以将向量水平书写，作为行向量，就像前面那一段，或者垂直书写，

![Image](Images/186equ01.jpg)

作为列向量，我们还使用了方括号而不是圆括号。两种表示方法都是可以接受的。除非我们故意疏忽，通常在讨论代码中的向量时，我们会假设向量是列向量。这意味着向量是一个具有*n*行和一列的矩阵，*n* × 1。

一个接受向量输入并返回单一数字作为输出的函数称为*标量场*。标量场的经典例子是温度。我们可以在房间中的任何一个点测量温度。我们将位置表示为相对于某个选定原点的3D向量，温度则是该点的数值，即该区域分子平均动能的大小。我们还可以讨论那些接受向量作为输入并返回向量作为输出的函数。这些称为*向量场*。在这两种情况下，场部分指的是在某个适当的定义域上，函数对所有输入都有一个值。

梯度是接受向量作为输入的函数的导数。从数学角度来看，我们将梯度表示为对*n*维的偏导数的推广。例如，在3D空间中，我们可以写

![Image](Images/187equ01.jpg)

其中梯度算子▽对*f*的每个维度进行偏导数运算。▽算子有多个名字，如*del*、*grad*或*nabla*。当我们不单纯说“梯度算子”时，我们将使用▽并称其为*del*。

一般来说，我们可以写

![Image](Images/07equ07.jpg)

让我们解析一下[方程7.7](ch07.xhtml#ch07equ07)。首先，我们有一个函数*f*，它接受向量输入***x***并返回一个标量值。对这个函数应用梯度算子：

![Image](Images/187equ02.jpg)

这将返回一个*向量*（***y***）。梯度算子将标量输出的*f*转换为一个向量。让我们花些时间思考这意味着什么，它在空间中的给定位置告诉我们标量场的值。（在处理向量时，我们会使用*空间*，即使没有一种有意义的方式去可视化这个空间。3D空间的类比有帮助，但也只是有限的；从数学角度看，空间的概念更为广泛。）

举个例子，考虑一个二维空间中的函数，*f*(***x***) = *f*(*x*, *y*) = *x*² + *xy* + *y*²。*f*的梯度是：

![Image](Images/07equ08.jpg)

由于*f*是标量场，二维平面上的每个点都有一个函数值。这就是*f*(***x***) = *f*(*x*, *y*)的输出。因此，我们可以在三维空间中绘制*f*，以展示随位置变化的曲面。然而，梯度则给出了我们一组方程。这些方程告诉我们在某一点***x*** = (*x*, *y*)处，函数值变化的方向和大小。

对于单变量函数，每个点只有一个斜率。再看看[图 7-1](ch07.xhtml#ch07fig01)中的切线。在点*x[t]*，只有一个斜率。导数在*x[t]*处的符号表示斜率的方向，导数的绝对值表示斜率的大小（陡峭度）。

然而，一旦我们转向多于一个维度的情况，就会遇到一些困惑。我们不再只有一个与函数相切的斜率，而是有无数个。我们可以想象某个点上的切线，并且这条线可以指向我们想要的任何方向。切线的斜率告诉我们在这个特定方向上函数值的变化。我们可以通过*方向导数*来找到这种变化的值，方向导数是梯度与我们感兴趣方向的单位向量的点积：

*D**[u]**f*(***x***) ≡ ***u**• ▽f*(***x***) = ***u**^T*▽*f*(***x***) = ||***u***||||▽*f*(***x***)|| cos *θ*

其中，***u***是特定方向的单位向量，▽*f*(***x***)是点***x***处函数的梯度，*θ*是它们之间的夹角。当cos *θ*最大时，方向导数也达到最大，这发生在*θ* = 0时。因此，函数在任何点的最大变化方向是该点的梯度。

举个例子，我们在二维平面上选一个点，假设***x*** = (*x*, *y*) = (0.5, −0.4)，并且有*f*(*x*, *y*) = *x*² + *xy* + *y*²。从上面的公式得出，点***x***处的函数值是 *x*² + *xy* + *y*² = (0.5)² + (0.5)(−0.4) + (−0.4)² = 0.21，这是一个标量。然而，这个点的梯度是：

![Image](Images/188equ01.jpg)

因此，我们现在知道，在点 (0.5, −0.4) 处，*f*的最大变化方向是 (0.6, −0.3)，其大小为 ![Image](Images/188equ02.jpg)。

#### 梯度可视化

让我们让这一切不那么抽象。[图 7-4](ch07.xhtml#ch07fig04)的上半部分显示了在选定点处的*f*(*x*, *y*) = *x*² + *xy* + *y*²的图形。

![image](Images/07fig04.jpg)

*图 7-4：x² + xy + y² 的绘图（上图）以及相关梯度场的二维投影（下图）*

生成此图的代码很简单：

import numpy as np

x = np.linspace(-1.0,1.0,50)

y = np.linspace(-1.0,1.0,50)

xx = []; yy = []; zz = []

for i in range (50):

for j in range (50):

xx.append(x[i])

yy.append(y[j])

zz.append(x[i]*x[i]+x[i]*y[j]+y[j]*y[j])

x = np.array(xx)

y = np.array(yy)

z = np.array(zz)

这里，我们显式地使用循环生成散点图的点集 x, y 和 z，以清晰地展示发生的情况。首先，我们使用 NumPy 生成在 x 和 y 范围 [−1, 1] 内均匀分布的 50 个点。然后，我们设置双重循环，使得每个 x 都与每个 y 配对，以计算函数值 z。临时列表 xx, yy 和 zz 保存这些三元组。最后，我们将这些列表转换为 NumPy 数组以便绘图。

生成散点图的代码是

from mpl_toolkits.mplot3d import Axes3D

import matplotlib.pylab as plt

fig = plt.figure()

ax = fig.add_subplot(111, projection='3d')

ax.scatter(x, y, z, marker='.', s=2, color='b')

ax.view_init(30,20)

plt.draw()

plt.show()

我们首先加载 matplotlib 的 3D 绘图扩展，然后设置 3D 投影的子图。图形本身是通过 ax.scatter 绘制的，而 ax.view_init 和 plt.draw 则旋转图形，让我们更好地查看函数的形状，然后再展示图形。

在[图 7-4](ch07.xhtml#ch07fig04)的下半部分，我们看到一个关于 *x*² + *xy* + *y*²的梯度场的向量图。这个图展示了在网格点（*x*, *y*）上梯度向量的方向和相对大小。回想一下，梯度是一个向量场，因此 *xy* 平面上的每个点都有一个与之相关的向量，指向函数值变化最快的方向。从思维上讲，我们可以看到该向量图如何与[图 7-4](ch07.xhtml#ch07fig04)上半部分的函数图相关，其中，靠近（−1, −1）和（1, 1）的函数值变化很快，而靠近（0, 0）的点变化较慢。

生成向量场图的代码是

fig = plt.figure()

ax = fig.add_subplot(111)

x = np.linspace(-1.0,1.0,20)

y = np.linspace(-1.0,1.0,20)

xv, yv = np.meshgrid(x, y, indexing='ij', sparse=False)

dx = 2*xv + yv

dy = 2*yv + xv

ax.quiver(xv, yv, dx, dy, color='b')

plt.axis('equal')

plt.show()

我们首先定义了图形（fig）和 2D 子图（没有 projection 关键字）。然后，我们需要一个网格点。上面我们通过循环获取了这个网格，以便了解需要生成什么。在这里，我们使用 NumPy 通过 np.meshgrid 生成网格。注意，我们传递给 np.meshgrid 的 x 和 y 向量与上面一样，用于定义域。

接下来的两行代码是 *f* 的梯度，[公式 7.8](ch07.xhtml#ch07equ08)的直接实现。这些是我们要绘制的向量，dx 和 dy 给我们方向和大小，而 xv 和 yv 是输入点的集合，共 400 个。

该图使用了 ax.quiver（因为它绘制了箭头）。参数是网格点（xv, yv）以及这些点上向量的 *x* 和 *y* 值（dx, dy）。最后，我们确保坐标轴是相等的（plt.axis），以避免向量显示变形，然后显示图像。

我们将在此结束梯度的介绍。在本书的其余部分，我们会再次看到梯度，尤其是在[第8章](ch08.xhtml#ch08)的符号表示以及[第11章](ch11.xhtml#ch11)的梯度下降讨论中。

### 总结

本章介绍了微分学的主要概念。我们从斜率的概念开始，学习了割线和切线的区别，这些都是针对单变量函数的。接着，我们正式定义了导数为割线在接近单一点时的斜率。之后，我们学习了微分的基本规则，并了解了如何应用这些规则。

接下来，我们了解了函数的极小值和极大值，以及如何使用导数找到这些点。然后，我们引入了偏导数，作为计算多变量函数导数的一种方法。偏导数进一步引导我们认识了梯度，梯度将标量场转换为向量场，并告诉我们函数变化最快的方向。我们计算了一个二维的梯度示例，并展示了如何生成图表，显示函数与梯度之间的关系。我们学到了一个关键事实：函数的梯度指向函数值在某一点变化最快的方向。

让我们继续探索深度学习背后的数学，并进入矩阵微积分的世界。

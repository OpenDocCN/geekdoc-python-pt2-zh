## **9

神经网络中的数据流**

![image](Images/common.jpg)

在本章中，我将展示数据如何在一个训练好的神经网络中流动。换句话说，我们将看到如何从输入向量或张量到输出，并且数据在这个过程中所采取的形式。如果你已经熟悉神经网络的工作原理，那太好了；如果不熟悉，了解数据如何从一层流动到另一层将有助于你建立对相关过程的理解。

首先，我们将查看如何在两种不同的网络中表示数据。然后，我们将通过一个传统的前馈网络来打下坚实的基础。我们将看到，使用神经网络进行推理在代码方面是多么简洁。最后，我们将通过引入卷积层和池化层，跟踪数据在卷积神经网络中的流动。本章的目标不是展示流行工具包如何传递数据。这些工具包是高度优化的软件，了解这些低级细节在目前阶段对我们并无太大帮助。相反，目标是帮助你理解数据是如何从输入流向输出的。

### 数据表示

最终，深度学习中的一切都与数据有关。我们有数据用于创建模型，并用更多数据来测试模型，最终让我们能够对更多数据做出预测。我们将从如何在两种类型的神经网络中表示数据开始：传统神经网络和深度卷积神经网络。

#### 传统神经网络

对于*传统神经网络*或其他经典机器学习模型，输入是一个数字向量，即特征向量。训练数据是这些向量的集合，每个向量都有一个相关的标签。（本章中我们将限制为基本的监督学习。）特征向量的集合通常实现为一个矩阵，其中每一行是一个特征向量，矩阵的行数与数据集中的样本数量相匹配。正如我们现在所知，计算机方便地使用二维数组来表示矩阵。因此，当我们使用传统神经网络或其他经典模型（如支持向量机、随机森林等）时，我们将数据集表示为二维数组。

例如，我们在[第6章](ch06.xhtml#ch06)首次遇到的鸢尾花数据集，每个特征向量包含四个特征。我们将其表示为一个矩阵：

>>> import numpy as np

>>> from sklearn import datasets

>>> iris = datasets.load_iris()

>>> X = iris.data[:5]

>>> X

array([[5.1, 3.5, 1.4, 0.2],

[4.9, 3\. , 1.4, 0.2],

[4.7, 3.2, 1.3, 0.2],

[4.6, 3.1, 1.5, 0.2],

[5\. , 3.6, 1.4, 0.2]])

>>> Y = iris.target[:5]

在这里，我们展示了前五个样本，就像我们在[第6章](ch06.xhtml#ch06)中做的一样。上面的样本都是类 0（*I. setosa*）的。为了将这些知识传递给模型，我们需要一个匹配的类别标签向量；X[i] 返回样本 i 的特征向量，Y[i] 返回类别标签。类别标签通常是一个整数，从零开始对数据集中的每个类别进行计数。一些工具包更喜欢使用独热编码的类别标签，但我们可以很容易地从更标准的整数标签中创建它们。

因此，传统数据集使用层与层之间的矩阵来存储权重，每一层的输入和输出都是一个向量。这相当简单。那么更现代的深度网络呢？

#### 深度卷积网络

深度网络可能会使用特征向量，特别是如果模型实现了 1D 卷积，但通常，使用深度网络的全部意义在于让*卷积层*利用数据中的空间关系。通常，这意味着输入是图像，我们使用二维数组来表示图像。但输入并不总是需要是图像。模型对输入表示的*是什么*一无所知；只有模型设计者知道，并且根据这些知识决定架构。为了简化起见，我们假设输入是图像，因为我们已经知道计算机如何处理图像，至少在高层次上是这样。

黑白图像，或者说带有灰度的图像，被称为灰度图像，使用一个数字来表示每个像素的强度。因此，灰度图像由一个矩阵组成，在计算机中表示为二维数组。然而，我们在计算机上看到的大多数图像都是彩色图像，而不是灰度图像。大多数软件通过三个数字来表示像素的颜色：红色的量，绿色的量和蓝色的量。这就是计算机上彩色图像被称为*RGB*的原因。还有许多其他表示颜色的方法，但 RGB 绝对是最常见的。通过混合这些基本颜色，计算机可以显示数百万种颜色。如果每个像素需要三个数字，那么彩色图像就不是一个单一的二维数组，而是三个二维数组，每个颜色一个。

例如，在[第4章](ch04.xhtml#ch04)中，我们从 sklearn 加载了一张彩色图像。让我们再次看看它，了解它在内存中的排列方式：

>>> from sklearn.datasets import load_sample_image

>>> china = load_sample_image('china.jpg')

>>> china.shape

(427, 640, 3)

该图像作为 NumPy 数组返回。请求数组的形状将返回一个元组：(427, 640, 3)。该数组有三个维度。第一个是图像的高度，427 像素。第二个是图像的宽度，640 像素。第三个是*波段*或*通道*的数量，这里是三个，因为它是一个 RGB 图像。第一个通道是每个像素的红色分量，第二个是绿色，最后一个是蓝色。如果我们愿意，可以将每个通道看作灰度图像：

>>> from PIL import Image

>>> Image.fromarray(china).show()

>>> Image.fromarray(china[:,:,0]).show()

>>> Image.fromarray(china[:,:,1]).show()

>>> Image.fromarray(china[:,:,2]).show()

PIL指的是Pillow，Python的图像处理库。如果你还没有安装它，可以使用以下命令安装：

pip3 install pillow

每张图像看起来相似，但如果你把它们并排放置，你会注意到一些差异。见[图9-1](ch09.xhtml#ch09fig01)。每个通道图像的净效应共同创建了显示的实际颜色。将china[:,:,0]替换为china，可以查看完整的彩色图像。

![image](Images/09fig01.jpg)

*图9-1：红色（左）、绿色（中）和蓝色（右）* *china* *图像通道*

深度网络的输入通常是多维的。如果输入是彩色图像，我们需要使用3D张量来存储图像。然而，我们还没有完全完成。每个输入样本是一个3D张量，但我们很少一次只处理一个样本。在训练深度网络时，我们使用*minibatches*，即一组一同处理的样本，以获得平均损失。这意味着输入张量需要再多一个维度，来指定我们要选择的*minibatch*中的*哪一个*样本。因此，输入是一个4D张量：*N* × *H* × *W* × *C*，其中*N*是minibatch中的样本数，*H*是每张图像的高度，*W*是每张图像的宽度，*C*是通道数。我们有时会将其写成元组形式（*N*，*H*，*W*，*C*）。

让我们来看一些实际的数据，这些数据是用于深度网络的。数据集是CIFAR-10数据集。这是一个广泛使用的基准数据集，可以在这里找到：[https://www.cs.toronto.edu/~kriz/cifar.html](https://www.cs.toronto.edu/~kriz/cifar.html)。不过你不需要下载原始数据集。我们已经为本书的代码提供了NumPy版本。如上所述，我们需要两个数组：一个用于图像，另一个用于对应的标签。你可以在*cifar10_test_images.npy*和*cifar10_test_labels.npy*文件中找到它们。让我们来看一下：

>>> images = np.load("cifar10_test_images.npy")

>>> labels = np.load("cifar10_test_labels.npy")

>>> images.shape

(10000, 32, 32, 3)

>>> labels.shape

(10000,)

请注意，图像数组有四个维度。第一个维度是数组中图像的数量（*N* = 10,000）。第二和第三个维度告诉我们图像是32×32像素。最后一个维度告诉我们有三个通道，意味着数据集包含彩色图像。请注意，通常情况下，通道数可能指任何按这种方式分组的数据集合——它不一定是实际的图像。标签向量也有10,000个元素。这些是类别标签，共有10个类别，混合了动物和交通工具。例如，

>>> labels[123]

2

>>> Image.fromarray(images[123]).show()

这表示图像123属于第2类（鸟类），标签是正确的；显示的图像应为鸟类图像。回想一下，在NumPy中，询问一个索引会返回整个子数组，所以images[123]等同于images[123,:,:,:]。Image类的fromarray方法将NumPy数组转换为图像，以便show能够显示它。

使用小批量处理意味着我们将整个数据集的一部分通过模型进行处理。如果我们的模型使用24个样本的小批量，那么深度网络的输入（如果使用CIFAR-10）就是一个(24, 32, 32, 3)的数组：24张图像，每张图像有32行、32列和3个通道。我们将在下面看到，通道的概念不仅仅局限于深度网络的输入；它也适用于层间传递的数据形状。

我们稍后会回到深度网络的数据处理部分。但现在，让我们转到传统前馈神经网络中数据流的更直接话题。

### 传统神经网络中的数据流

如前所述，在传统的神经网络中，层与层之间的权重存储为矩阵。如果第*i*层有*n*个节点，第*i* − 1层有*m*个输出，则这两层之间的权重矩阵***W[i]***是一个*n* × *m*的矩阵。当该矩阵与第*i* − 1层的*m* × 1列向量相乘时，结果是一个*n* × 1的输出，表示第*i*层的*n*个节点的输入。具体来说，我们计算

***a[i]*** = σ(***W[i]a[i−1]*** + ***b[i]***)

其中，***a[i]***[−1]是来自第*i* − 1层的*m* × 1输出向量，乘以***W[i]***产生一个*n* × 1的列向量。我们将***b[i]***（第*i*层的偏置值）加到这个向量上，并对结果向量***W[i]a[i]***[−1] + ***b[i]***中的每个元素应用激活函数σ，生成***a[i]***，即第*i*层的激活值。我们将激活值传递给第*i* + 1层作为第*i*层的输出。通过使用矩阵和向量，矩阵乘法的规则自动计算出所有必要的乘积，而不需要在代码中显式地使用循环。

让我们看一个简单神经网络的例子。我们将生成一个具有两个特征的随机数据集，然后将该数据集划分为训练集和测试集。我们将使用sklearn在训练集上训练一个简单的前馈神经网络。该网络有一个包含五个节点的隐藏层，并使用线性整流激活函数（ReLU）。然后，我们将测试训练后的网络，看它学习得如何，并且最重要的是，查看实际的权重矩阵和偏置向量。

为了构建数据集，我们将选择一组二维空间中的点，这些点有些簇状分布，但略微重叠。我们希望网络必须学习一些并非完全简单的内容。以下是代码：

from sklearn.neural_network import MLPClassifier

np.random.seed(8675309)

❶ x0 = np.random.random(50)-0.3

y0 = np.random.random(50)+0.3

x1 = np.random.random(50)+0.3

y1 = np.random.random(50)-0.3

x = np.zeros((100,2))

x[:50,0] = x0; x[:50,1] = y0

x[50:,0] = x1; x[50:,1] = y1

❷ y = np.array([0]*50+[1]*50)

❸ idx = np.argsort(np.random.random(100))

x = x[idx]; y = y[idx]

x_train = x[:75]; x_test = x[75:]

y_train = y[:75]; y_test = y[75:]

我们需要从 sklearn 导入 MLPClassifier 类，因此首先加载它。然后我们定义一个 2D 数据集 x，由两个各包含 50 个点的云组成。这些点是随机分布的（x0, y0 和 x1, y1），但分别集中在 (0.2, 0.8) 和 (0.8, 0.2) 处 ❶。注意，我们将 NumPy 随机数种子设置为固定值，因此每次运行都会产生相同的一组数字。你可以删除这行代码，尝试不同的种子值，看看神经网络在各种数据集生成上训练的效果如何。

我们知道 x 中的前 50 个点来自我们所称的类 0，接下来的 50 个点来自类 1，因此我们定义了一个标签向量 y ❷。最后，我们随机化 x 中点的顺序 ❸，同时确保以相同方式改变标签，并将其拆分为训练集 (x_train) 和标签 (y_train)，以及测试集 (x_test) 和标签 (y_test)。我们保留 75% 的数据用于训练，剩余 25% 用于测试。

[图 9-2](ch09.xhtml#ch09fig02) 显示了完整数据集的图示，每个特征在一个轴上。圆形对应类 0 的实例，方形对应类 1 的实例。两类之间有明显的重叠。

![image](Images/09fig02.jpg)

*图 9-2：用于训练神经网络的数据集，其中类 0 的实例以圆形表示，类 1 的实例以方形表示*

现在我们准备训练模型了。如果使用默认设置，sklearn 工具包会让我们轻松实现：

❶ clf = MLPClassifier(hidden_layer_sizes=(5,))

clf.fit(x_train, y_train)

❷ score = clf.score(x_test, y_test)

print("模型在测试集上的准确率：%0.4f" % score)

❸ W0 = clf.coefs_[0].T

b0 = clf.intercepts_[0].reshape((5,1))

W1 = clf.coefs_[1].T

b1 = clf.intercepts_[1]

训练过程包括创建模型类的一个实例 ❶。注意，通过使用默认设置（包括使用 ReLU 激活函数），我们只需指定隐藏层中节点的数量。我们希望有一个包含五个节点的隐藏层，因此传入元组 (5,)。训练只是调用 fit 函数，并传入训练数据 x_train 和相应的标签 y_train。训练完成后，我们通过计算测试集（x_test, y_test）上的准确率（得分）来测试模型，并显示结果。

神经网络是随机初始化的，但由于我们在生成数据集时固定了NumPy随机数种子，并且sklearn也使用NumPy随机数生成器，因此每次运行代码时，训练网络的结果应该是相同的。该模型在测试数据上的准确率为92% ❷。这对我们来说很方便，但也令人担忧——如此多的工具包在后台使用NumPy，因此由于固定随机数种子而产生的交互是很可能的，通常是不可取的，并且可能很难检测。

我们现在终于准备好从训练好的网络中获取权重矩阵和偏置向量 ❸。因为sklearn使用np.dot进行矩阵乘法，我们取权重矩阵W0和W1的转置，以便使其在数学上更容易理解。我们将在下面看到为什么这是必要的。同样，b0，隐藏层的偏置向量，是一个1D的NumPy数组，因此我们将其转换为列向量。输出层偏置b1是一个标量，因为这个网络只有一个输出，即我们传递给sigmoid函数以得到类别1的概率。

让我们来分析一下第一个测试样本的网络。为了节省空间，我们只显示数值的前三位数字，但我们的计算将使用全精度。网络的输入是

![图片](Images/228equ01.jpg)

我们希望网络给出一个输出，表示此输入属于类别1的概率。

为了得到隐藏层的输出，我们将***x***与权重矩阵***W***[0]相乘，加上偏置向量***b***[0]，然后通过ReLU函数传递这个结果：

![图片](Images/228equ02.jpg)

隐藏层到输出层的过渡使用相同的形式，只是***a***[0]取代了***x***，但是这里没有应用ReLU：

![图片](Images/229equ01.jpg)

为了得到最终的输出概率，我们使用***a*****[1]**，一个标量值，作为*sigmoid函数*（也称为*逻辑函数*）的参数：

![图片](Images/229equ02.jpg)

这意味着网络给输入值属于类别1的概率为35.5%。对于二分类模型，通常的分类阈值是50%，因此网络会将***x***归为类别0。查看y_test[0]告诉我们，在这种情况下，网络是正确的：***x***来自类别0。

### 卷积神经网络中的数据流

我们上面看到，传统神经网络中的数据流是直接的矩阵-向量运算。要追踪数据在*卷积神经网络（CNN）*中的流动，我们首先需要了解卷积操作是什么以及它是如何工作的。具体来说，我们将学习如何将数据通过卷积层和池化层传递到模型顶部的全连接层。这一过程至少在概念层面上解释了许多CNN架构。

#### 卷积

卷积涉及两个函数，并将其中一个滑动到另一个上。如果函数是*f*(*x*)和*g*(*x*)，则卷积定义为

![Image](Images/09equ01.jpg)

幸运的是，我们工作在离散域中，并且大多数情况下使用2D输入，所以实际上并没有使用积分，尽管*仍然是这个操作的有用符号。

[公式 9.1](ch09.xhtml#ch09equ01)的净效应是将*g*(*x*)滑动过*f*(*x*)，进行不同的平移。让我们通过一个一维离散例子来澄清。

##### 一维卷积

[图 9-3](ch09.xhtml#ch09fig03)显示了底部的图表，以及顶部标有*f*和*g*的两组数字。

![image](Images/09fig03.jpg)

*图 9-3：一维离散卷积*

让我们从[图 9-3](ch09.xhtml#ch09fig03)顶部显示的数字开始。第一行列出了*f*的离散值。下面是*g*，一个由三个元素组成的线性斜坡。卷积将*g*与*f*的左边缘对齐，如图所示。我们将两个数组之间对应的元素相乘，

[2, 6, 15] × [−1, 0, 1] = [−2, 0, 15]

然后对结果值求和，

−2 + 0 + 15 = 13

以产生输出中指定元素的值，*f* * *g*。为了完成卷积，*g*向右滑动一个元素，过程重复进行。请注意，在[图 9-3](ch09.xhtml#ch09fig03)中，为了清晰起见，我们显示了*f*和*g*的每隔一对齐，所以看起来像是*g*向右滑动了两个元素。通常，我们将*g*称为*kernel*，即滑过输入*f*的值集。

[图 9-3](ch09.xhtml#ch09fig03)底部的图表是*f*(*x*) = ⌊255 exp(−0.5*x*²)⌋，其中*x*在[−3, 3]区间内，且标有圆圈的点为参考。取整操作使得输出为整数，以简化以下讨论。

[图 9-3](ch09.xhtml#ch09fig03)中的方块点是*f*(*x*)与*g*(*x*) = [−1, 0, 1]的卷积结果。

[图 9-3](ch09.xhtml#ch09fig03)中的*f*和*f* * *g*点是通过以下方式生成的

x = np.linspace(-3,3,20)

f = (255*np.exp(-0.5*x**2)).astype("int32")

g = np.array([-1,0,1])

fp= np.convolve(f,g[::-1], mode='same')

这段代码需要一些解释。

首先，我们有x，这是一个在[−3, 3]区间内取20步的向量；这个向量生成*f*（上面的*f*(*x*)）。我们希望*f*是整数类型，这就是astype为我们所做的。接下来，我们定义*g*，即小的线性斜坡。正如我们将看到的，卷积操作将*g*滑动过*f*的元素，以生成输出。

接下来是卷积操作。由于卷积被广泛使用，NumPy提供了一个一维卷积函数np.convolve。第一个参数是*f*，第二个参数是*g*。我将很快解释为什么我们向*g*添加了[::-1]来反转它。我也会解释mode='same'的含义。卷积的输出存储在fp中。

[图9-3](ch09.xhtml#ch09fig03)顶部显示的第一个位置填充了输出中的13。那么，13左侧的6是从哪里来的呢？卷积在*f*的边缘有问题，在那里卷积核不能完全覆盖输入。对于一个包含三个元素的卷积核，*f*的每一端都会有一个边缘元素。卷积核通常有奇数个值，所以有一个明确的中间元素。如果*g*有五个元素，那么*f*的两端就会有两个元素*g*无法覆盖。

卷积函数需要对这些边缘情况做出选择。一种选择是仅返回卷积的有效部分，忽略边缘情况。如果我们使用这种方法，叫做*有效卷积*，那么输出yp将从元素13开始，长度比输入y短2个元素。

另一种方法是用零填充*f*中的缺失值。这被称为*零填充*，我们通常使用它来使卷积操作的输出与输入的大小相同。

使用mode='same'与np.convolve选择零填充。这解释了13左侧的6。它是我们在*f*前添加零并应用卷积核时得到的结果：

[0, 2, 6] × [−1, 0, 1] = [0, 0, 6]，0 + 0 + 6 = 6

如果我们只需要有效输出值，我们会改用mode='valid'。

上面对np.convolve的调用没有使用g，而是传递了g[::-1]，即g的反向。我们这么做是为了让np.convolve的行为像深度神经网络中的卷积操作。从数学和信号处理的角度看，卷积是使用卷积核的反向。因此，np.convolve函数会反转卷积核，这意味着我们需要事先反转它，以达到我们想要的效果。严格来说，如果我们执行的操作叫做*卷积*而不翻转卷积核，我们实际上是在执行*交叉相关*。在深度学习中，这个问题很少出现，因为我们在训练过程中*学习*卷积核的元素——而不是提前指定它们。考虑到这一点，工具包在执行卷积操作时翻转卷积核不会影响结果，因为学习到的卷积核值已经是在翻转状态下学习得到的。我们假设在接下来的过程中不会翻转卷积核，并且在必要时，我们会翻转传给NumPy和SciPy函数的卷积核。此外，我们将继续在没有翻转卷积核的深度学习语境下使用*卷积*这个术语。

一般来说，离散输入的卷积涉及将卷积核放在输入的左侧，进行匹配元素的乘法、求和，并将结果放入输出中，当卷积核的中心与当前位置对齐时。然后，卷积核向右滑动一个元素，重复该过程。我们可以将离散卷积操作扩展到二维。大多数现代深度卷积神经网络（CNN）使用二维卷积核，尽管也可以使用一维或三维卷积核。

##### 二维卷积

与 2D 核的卷积需要一个 2D 数组。图像是值的 2D 数组，而卷积是常见的图像处理操作。例如，假设我们加载图像，即我们在[第 3 章](ch03.xhtml#ch03)中看到的浣熊的面部，并使用 2D 卷积对其进行处理。考虑以下内容：

from scipy.signal import convolve2d

from scipy.misc import face

img = face(True)

img = img[:512,(img.shape[1]-612):(img.shape[1]-100)]

k = np.array([[1,0,0],[0,-8,0],[0,0,3]])

c = convolve2d(img, k, mode='same')

在这里，我们使用来自 signal 模块的 SciPy convolve2d 函数。首先，我们加载浣熊图像并将其子集化为一个 512×512 像素的浣熊面部图像 (img)。接下来，我们定义一个 3 × 3 的卷积核 k。最后，我们将卷积核直接与面部图像进行卷积，并将结果存储在 c 中。mode='same' 关键字通过零填充图像来处理边缘情况。

上述代码得到的结果是：

img[:8,:8]:

[[ 88 97 112 127 116  97  84  84]

[ 62 70 100 131 126  88  52  51]

[ 41 46  87 127 146 116  78  56]

[ 42 45  76 107 145 137 112  76]

[ 58 59  69  79 111 106  90  68]

[ 74 73  68  60  72  74  72  67]

[ 92 87  75  63  57  74  91  93]

[105 97  85  74  60  79 102 110]]

k:

[[ 1  0 0]

[ 0 -8 0]

[ 0  0 3]]

c[1:8,1:8]:

[[-209 -382 -566 -511 -278  -69 -101]

[-106 -379 -571 -638 -438 -284 -241]

[-168 -391 -484 -673 -568 -480 -318]

[-278 -357 -332 -493 -341 -242 -143]

[-335 -304 -216 -265 -168 -165 -184]

[-389 -307 -240 -197 -274 -396 -427]

[-404 -331 -289 -215 -368 -476 -488]]

在这里，我们显示了图像的上方 8 × 8 区域以及卷积的有效部分。回想一下，有效部分是卷积核完全覆盖输入数组的部分。

对于卷积核和图像，第一次有效的卷积输出是 −209。数学上，第一步是与卷积核进行逐元素相乘，

![Image](Images/233equ01.jpg)

随后进行求和，

264 + 0 + 0 + 0 + (−560) + 0 + 0 + 0 + 87 = −209

注意，使用的卷积核不是我们定义的 k。相反，convolve2d 在应用之前先将卷积核上下翻转，再左右翻转。c 的其余部分来自将卷积核向右移动一格，并重复乘法和加法操作。行末时，卷积核向下移动一格并回到左侧，直到整个图像处理完毕。深度学习工具包将这种运动称为 *步幅*，它不一定是每次移动一格，也不必在水平和垂直方向上相等。

[图 9-4](ch09.xhtml#ch09fig04) 显示了卷积的效果。

![image](Images/09fig04.jpg)

*图 9-4：原始浣熊面部图像（左）和卷积结果（右）*

为了生成图像，c被向上移动，所以最小值变为零，然后除以最大值以映射到[0, 1]。最后，输出乘以255并显示为灰度图像。左边是原始人脸图像，右边是卷积后的图像。与内核的图像卷积改变了图像，强调了某些特征，同时抑制了其他特征。

将内核与图像进行卷积不仅仅是帮助我们理解卷积操作的练习。它在卷积神经网络（CNN）的训练中具有深远的重要性。从概念上讲，CNN由两个主要部分组成：一组卷积层和其他层，用于学习输入的新表示；以及一个顶层分类器，用于利用新表示对输入进行分类。正是新表示和分类器的联合学习使得CNN如此强大。学习输入的新表示的关键是学习到的卷积内核。内核如何在数据通过CNN时改变输入，创造出新的表示。通过梯度下降和反向传播进行训练，教会网络创建哪些内核。

现在我们可以跟踪数据通过CNN的卷积层。让我们来看一看。

#### 卷积层

上面，我们讨论了深度网络如何将张量从一层传递到另一层，以及张量通常有四个维度，*N* × *H* × *W* × *C*。为了跟踪数据通过卷积层的流动，我们将忽略*N*，知道我们讨论的内容是应用于张量中的每个样本。这就剩下输入到卷积层的是*H* × *W* × *C*，一个三维张量。

卷积层的输出是另一个三维张量。输出的高度和宽度取决于卷积核的具体情况以及我们决定如何处理边缘。在这里的例子中，我们将使用有效卷积，这意味着我们会丢弃卷积核未完全覆盖的输入部分。如果卷积核是3 × 3，输出的高度和宽度会减少2，每个边缘减少1。一个5 × 5的卷积核会使高度和宽度减少4，每个边缘减少2。

卷积层使用一组*滤波器*来实现其目标。滤波器是一个内核堆栈。每个期望的输出通道需要一个滤波器。每个滤波器中内核堆栈的数量与输入通道的数量相匹配。所以，如果输入有*M*个通道，我们想要使用*K* × *K*的内核得到*N*个输出通道，我们需要*N*个滤波器，每个滤波器是一个*M K* × *K*内核的堆栈。

此外，我们为每个*N*个滤波器都有一个偏置值。我们将在下面看到偏置是如何使用的，但现在我们已经知道了要实现一个具有*M*输入通道、*K* × *K*内核和*N*输出的卷积层，我们需要学习多少个参数。它是*K* × *K* × *M* × *N*，每个滤波器有*K* × *K* × *M*个参数，再加上*N*个偏置项——每个滤波器一个。

让我们具体化一下。我们有一个卷积层。该层的输入是一个（*H*, *W*, *C*）= (5, 5, 2) 的张量，意味着高度和宽度都是五，且有两个通道。我们将使用一个 3 × 3 的卷积核并进行有效卷积，因此从 5 × 5 的输入得到的输出高度和宽度为 3 × 3。我们可以选择输出通道的数量。我们选择三个。因此，我们需要使用卷积和卷积核将（5, 5, 2）的输入映射为（3, 3, 3）的输出。从上面的讨论中，我们知道需要三个滤波器，每个滤波器有 3 × 3 × 2 个参数，并加上一个偏置项。

我们的输入堆栈是

![Image](Images/235equ01.jpg)

我们已将第三维度分割，以显示两个输入通道，每个通道为 5 × 5。

这三个滤波器是

![Image](Images/236equ01.jpg)

再次，我们已经分离了第三维度。注意，每个滤波器有两个 3 × 3 的卷积核，每个卷积核对应 5 × 5 × 2 输入的一个通道。

让我们来应用第一个滤波器 *f*[0]。我们需要将输入的第一个通道与 *f*[0] 的第一个卷积核进行卷积：

![Image](Images/236equ02.jpg)

然后，我们需要将第二个输入通道与 *f*[0] 的第二个卷积核进行卷积：

![Image](Images/236equ03.jpg)

最后，我们将两个卷积输出与一个偏置标量相加：

![Image](Images/236equ04.jpg)

现在我们得到了第一个 3 × 3 的输出。

对 *f*[1] 和 *f*[2] 重复上述过程得到

![Image](Images/236equ05.jpg)

我们已完成卷积层并生成了 3 × 3 × 3 的输出。

许多工具包使得在设置卷积层时添加操作变得容易，但从概念上讲，这些操作本身就是接受 3 × 3 × 3 输出作为输入的层。例如，如果需要，Keras 会对输出应用 ReLU 激活函数。对卷积输出应用 ReLU（一个非线性函数）会给我们带来

![Image](Images/237equ01.jpg)

请注意，所有小于零的元素现在都变成了零。我们在卷积层之间使用非线性操作，原因与我们在传统神经网络中使用非线性激活函数相同：防止卷积层塌缩为单一层。注意，生成滤波器输出的操作是纯线性的；每个输出元素都是输入值的线性组合。加入 ReLU 之后，打破了这种线性关系。

创建卷积层的一个原因是减少学习参数的数量。对于上面的例子，输入是 5 × 5 × 2 = 50 个元素。期望的输出是 3 × 3 × 3 = 27 个元素。如果是一个全连接层，它需要学习 50 × 27 = 1,350 个权重，还需要 27 个偏置值。然而，卷积层只学到了三个滤波器，每个滤波器有 3 × 3 × 2 个权重，以及三个偏置值，总共是 3(3 × 3 × 2) + 3 = 57 个参数。加入卷积层使得学习节省了大约 1,300 个额外的权重。

卷积层的输出通常是池化层的输入。接下来我们考虑这种类型的层。

#### 池化层

卷积神经网络通常在卷积层之后使用 *池化层*。它们的使用有些争议，因为它们会丢弃信息，而信息的丢失可能会使网络更难学习空间关系。池化通常在空间域中执行，沿着输入张量的高度和宽度进行，同时保持通道数不变。

池化操作非常简单：你将一个窗口在图像上滑动，通常是 2 × 2，步幅为二，以便对值进行分组。对每组进行的具体池化操作是最大池化或平均池化。最大池化操作保留窗口中的最大值，并丢弃其余值。平均池化则取窗口中所有值的平均值。

使用步幅为二的 2 × 2 窗口会导致每个空间方向的大小减少一倍。因此，一个 (24,24,32) 的输入张量会变成一个 (12,12,32) 的输出张量。[图 9-5](ch09.xhtml#ch09fig05) 说明了最大池化过程。

![图片](Images/09fig05.jpg)

*图 9-5：使用 2* × *2 窗口和步幅为二的最大池化*

输入的一个通道，宽高均为八，位于左侧。2 × 2 窗口在输入上滑动，每次跳跃两个位置，因此窗口之间没有重叠。每个 2 × 2 区域的输出是最大值。平均池化则会输出四个数字的平均值。与正常的卷积一样，行末时，窗口会下移两个位置，然后重复该过程，将 8 × 8 的输入通道转换为 4 × 4 的输出通道。

如上所述，窗口内没有重叠的池化会丢失空间信息。这让深度学习社区中的一些人，特别是 Geoffrey Hinton，感到遗憾，因为丢失空间信息会扭曲输入中物体或物体部分之间的关系。例如，使用步幅为一的 2 × 2 最大池化窗口，而不是步幅为二，作用于 [图 9-5](ch09.xhtml#ch09fig05) 的输入矩阵会产生

![图片](Images/238equ01.jpg)

这是一个 7 × 7 的输出，只丢失了原始 8 × 8 输入中的一行和一列。在这种情况下，输入矩阵是随机生成的，所以我们可以预期最大池化操作偏向于八和九——没有结构可捕捉。当然，这在实际的卷积神经网络中通常不是这样，因为我们希望利用输入中固有的空间结构。

池化在深度学习中非常常见，尤其是在卷积神经网络中，因此了解池化操作的作用并意识到其潜在的弊端非常重要。接下来，我们将讨论卷积神经网络的输出端，通常是全连接层。

#### 全连接层

深度网络中的全连接层，在权重和数据的意义上，与传统神经网络中的常规层相同。许多关注分类的深度网络将卷积层和池化层的输出通过一个展平张量的层传递给第一个全连接层，这个层本质上是将张量展开为一个向量。一旦输出变成向量，全连接层便使用权重矩阵，像传统神经网络一样，将向量输入映射为向量输出。

#### 卷积神经网络中的数据流

让我们将所有部分整合在一起，看看数据如何从输入流经CNN直到输出。我们将使用一个在MNIST数据集上训练的简单CNN，MNIST数据集包含28×28像素的手写数字灰度图像。其架构如下所示。

输入 → 卷积（32） → 卷积（64） → 池化 → 展平 → 全连接（128） → 全连接（10）

输入是一个28×28像素的灰度图像（一个通道）。卷积层（conv）使用3 × 3的卷积核和有效卷积，因此其输出的高度和宽度比输入少两个像素。第一个卷积层学习32个滤波器，而第二个卷积层学习64个滤波器。我们忽略了那些不影响网络数据量的层，例如卷积层后的ReLU层。假设最大池化层使用2 × 2窗口，并且步幅为2。第一个全连接层（dense）有128个节点，接着是一个输出层，包含10个节点，每个节点对应一个数字，0到9。

对于单个输入样本，传递通过该网络的张量是：

(28,28,1) →(26,26,32) →(24,24,64) →(12,12,64) → 9216 → 128 → 10

输入        卷积        卷积         池化      展平    全连接   全连接

展平层将（12,12,64）的张量展开，形成一个包含9,216个元素的向量（12 × 12 × 64 = 9,216）。我们将展平层输出的9,216个元素传递到第一个全连接层，以生成128个输出值，最后一步是将这个128维的向量映射到10个输出值。

请注意，上述数值指的是传递通过网络的*数据*，对应每个输入样本，是*小批量*中的*N*个样本之一。这与网络在训练期间需要学习的参数（权重和偏置）数量不同。

上面显示的网络是在MNIST数字数据集上使用Keras训练的。[图9-6](ch09.xhtml#ch09fig06)通过可视化每一层的输出，展示了该网络对两个输入的作用，具体而言，展示了每一层对于输入图像4和6的输出。

![image](Images/09fig06.jpg)

*图9-6：CNN对于两个样本输入的输出的可视化表示*

从顶部开始，我们看到两个输入。对于图示，强度已经反转，因此较暗表示较高的数值。输入是一个(28,28,1)张量，其中1表示单通道灰度图像。与3 × 3的核进行有效卷积会返回一个26 × 26的输出。第一个卷积层学习了32个滤波器，因此输出是一个(26,26,32)张量。在图中，我们将每个滤波器的输出显示为图像。零被缩放为中等灰色（强度128），更高的值较暗，较低的值较亮。我们可以看到输入如何受到学习滤波器的影响。单一的输入通道意味着这一层的每个滤波器都是一个3 × 3的核。明暗交替的过渡表示特定方向的边缘。

我们将(26,26,32)张量通过ReLU（此处未显示）传递，然后通过第二个卷积层。该层的输出是一个(24,24,64)张量，在图中以8 × 8的图像网格显示。我们可以看到输入数字的许多部分被突出显示。

池化层保留了通道数，但将空间维度减少了两倍。以图像形式显示，24×24像素的8 × 8网格图像现在变成了12×12像素的8 × 8网格图像。展平操作将(12,12,64)张量映射为一个9,216元素的向量。

第一个密集层的输出是一个包含128个数字的向量。对于[图9-6](ch09.xhtml#ch09fig06)，我们将其显示为一个128元素的条形码。值从左到右排列。每个条形的高度并不重要，仅仅是为了让条形码更容易看清。由输入图像生成的条形码是顶部10个节点层用来创建输出并通过softmax函数传递的最终表示。最高的softmax输出用于选择类别标签，“4”或“6”。

因此，我们可以将通过第一个密集层的所有CNN层视为将输入映射到一个新的表示形式，这种表示形式使得简单的分类器容易处理。事实上，如果我们通过这个网络传递10个“4”和“6”的示例，并显示结果的128节点特征向量，我们会得到[图9-7](ch09.xhtml#ch09fig07)，在那里我们可以轻松地看到数字模式之间的差异。

![image](Images/09fig07.jpg)

*图9-7：第一个全连接层输出多个“4”和“6”输入*

当然，我们写数字的整个目的就是让人类更容易看到它们之间的差异。虽然我们可以通过128元素的向量图像来区分数字，但我们自然更倾向于使用书写的数字，因为习惯的原因以及我们大脑视觉系统已经通过高度复杂的分层特征检测器来识别这些数字。

记住CNN学习新的输入表示形式的例子是值得的，因为人类在图像中可能用作分类线索的东西，并不一定是网络学会使用的内容。这或许能部分解释为什么某些预处理步骤，比如在数据增强过程中对训练样本所做的改变，会在帮助网络学会泛化方面如此有效，尽管这些改变对我们来说似乎很奇怪。

### 总结

本章的目标是展示神经网络如何从输入到输出操作数据。自然地，我们无法涵盖所有类型的网络，但总体来说，原理是相同的：对于传统的神经网络，数据作为向量从一层传递到另一层；而对于深度网络，它作为张量传递，通常是四维的。

我们学习了如何将数据呈现给网络，无论是作为特征向量还是多维输入。接着我们观察了如何通过传统神经网络传递数据。我们看到了作为输入和输出的向量如何使传统神经网络的实现变成了一个简单的矩阵-向量乘法和加法的练习。

接下来，我们看到了深度卷积网络是如何将数据从一层传递到另一层的。我们首先学习了卷积操作，然后了解了卷积层和池化层如何将数据作为张量进行处理——每个输入小批量中的样本都是一个三维张量。在用于分类的卷积神经网络（CNN）顶部是全连接层，我们看到它们的作用与传统神经网络中的全连接层完全一致。

本章最后我们通过可视化展示了输入图像如何通过CNN处理生成输出表示，从而使得网络能够正确地标注输入。我们简要讨论了这个过程在训练中网络所学习的内容，以及这可能与人类在图像中自然看到的内容有所不同。

我们现在可以讨论反向传播，这是两个关键算法中的第一个，与梯度下降一起，使得训练深度神经网络成为可能。

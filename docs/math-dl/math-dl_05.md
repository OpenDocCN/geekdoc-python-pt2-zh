## **5

线性代数**

![图片](Images/common.jpg)

从形式上讲，线性代数是研究线性方程的学科，其中变量的最高次幂为一。然而，就我们的目的而言，*线性代数*指的是多维数学对象——如向量和矩阵——以及对它们进行的运算。这就是线性代数在深度学习中的典型应用方式，以及在实现深度学习算法的程序中如何操作数据。通过做出这个区分，我们舍弃了大量令人着迷的数学内容，但由于我们的目标是理解深度学习中使用和应用的数学，希望能够得到谅解。

在本章中，我将介绍深度学习中使用的对象，特别是标量、向量、矩阵和张量。正如我们所看到的，这些对象实际上都是不同阶数的张量。我们将从数学符号的角度讨论张量，然后使用NumPy进行实验。NumPy显式设计用于将多维数组引入Python，它们是我们将在本章中处理的数学对象的良好（但不完全）类比。

本章的重点将是学习如何对张量进行算术运算，这是深度学习中的基础内容。实现高性能深度学习工具包的主要工作涉及寻找尽可能高效地对张量进行算术运算的方法。

### 标量、向量、矩阵和张量

让我们来介绍一下这些角色。我将它们与Python变量和NumPy数组进行关联，展示我们如何在代码中实现这些对象。接着，我会呈现一个张量和几何之间的概念性映射。

#### 标量

即使你不熟悉这个词，你从第一次学会数数那天起就已经知道什么是标量了。*标量*就是一个数字，如7、42或π。在表达式中，我们将使用* x *来表示标量，也就是用于变量的常规符号。对于计算机来说，标量是一个简单的数值变量：

>>> s = 66

>>> s

66

#### 向量

*向量*是一个一维的数字数组。从数学角度看，向量有一个方向，要么是水平的，要么是垂直的。如果是水平的，它就是一个*行向量*。例如，

![图片](Images/05equ01.jpg)

是一个包含三个元素或分量的行向量。请注意，我们将使用**x**，一个小写的粗体字母，表示一个向量。

从数学角度看，向量通常被假定为*列向量*，

![图片](Images/05equ02.jpg)

其中***y***有四个分量，使其成为一个四维（4D）向量。请注意，在[方程式 5.1](ch05.xhtml#ch05equ01)中，我们使用了方括号，而在[方程式 5.2](ch05.xhtml#ch05equ02)中我们使用了圆括号。两种符号都可以接受。

在代码中，我们通常将向量实现为一维数组：

>>> import numpy as np

>>> x = np.array([1,2,3])

>>> print(x)

[1 2 3]

>>> print(x.reshape((3,1)))

[[1]

[2]

[3]]

这里，我们使用reshape将包含三个元素的行向量转换成一个三行一列的列向量。

向量的分量通常被解释为沿着一组坐标轴的长度。例如，一个三分量的向量可以用来表示三维空间中的一个点。在这个向量中，

***x*** = [*x*, *y*, *z*]

*x* 可能是沿 x 轴的长度，*y* 是沿 y 轴的长度，*z* 是沿 z 轴的长度。这些是笛卡尔坐标，用来唯一标识三维空间中的所有点。

然而，在深度学习以及机器学习中，向量的分量通常在几何意义上互不相关。相反，它们用于表示*特征*，即模型将用来尝试得到有用输出（如类别标签或回归值）的一些样本的性质。也就是说，表示特征集合的向量，称为*特征向量*，有时会从几何角度进行思考。例如，一些机器学习模型，如*k*近邻算法，将向量解释为几何空间中的某个坐标。

你常常会听到深度学习领域的人讨论一个问题的*特征空间*。特征空间是指可能输入的集合。模型的训练集需要准确地代表模型在使用时可能遇到的特征空间。在这个意义上，特征向量是一个点，位于这个*n*维空间中，*n*是特征向量中的特征数量。

#### 矩阵

*矩阵* 是一个二维的数字数组：

![Image](Images/105equ01.jpg)

***A*** 的元素通过行号和列号进行下标表示。矩阵 ***A*** 有三行四列，所以我们说它是一个 3 × 4 的矩阵，其中 3 × 4 是矩阵的*阶*。注意，***A*** 的下标从 0 开始。数学书籍通常从 1 开始，但越来越多的数学书籍使用 0，这样就不会出现数学符号和计算机表示之间的偏差。还要注意，我们将使用***A***，一个粗体大写字母，来表示一个矩阵。

在代码中，矩阵表示为二维数组：

>>> A = np.array([[1,2,3],[4,5,6],[7,8,9]])

>>> print(A)

[[1 2 3]

[4 5 6]

[7 8 9]]

>>> print(np.arange(12).reshape((3,4)))

[[ 0 1 2 3]

[ 4 5 6 7]

[ 8 9 10 11]]

要在 Python 中获取矩阵 ***A*** 的元素 *a*[12]，我们写 A[1,2]。注意，当我们打印数组时，它们周围多了一个 [ 和 ]。NumPy 使用这些括号来表示二维数组可以被视为一个行向量，其中每个元素本身就是一个向量。在 Python 术语中，这意味着矩阵可以被看作是一个子列表的列表，其中每个子列表的长度相同。当然，这正是我们最初定义 A 的方式。

我们可以将向量看作是具有单行或单列的矩阵。例如，一个包含三个元素的列向量是一个3 × 1的矩阵：它有三行一列。类似地，一个包含四个元素的行向量相当于一个1 × 4的矩阵：它有一行四列。我们稍后会用到这个观察结果。

#### 张量

标量没有维度，向量有一维，矩阵有二维。正如你可能猜到的，我们不止于此。一个具有超过两维的数学对象通常被称为*张量*。在必要时，我们会用T表示张量，T是一个无衬线的大写字母。

张量的维度数量定义了它的*阶*，这与矩阵的阶不同。一个三维张量的阶是3，一个矩阵是阶为2的张量，一个向量是阶为1的张量，一个标量是阶为0的张量。当我们在[第9章](ch09.xhtml#ch09)讨论深度神经网络中的数据流时，我们会看到许多工具包使用阶为4（或更高）的张量。

在Python中，具有三维或更多维的NumPy数组用于实现张量。例如，我们可以如下定义一个阶为3的张量：

>>> t = np.arange(36).reshape((3,3,4))

>>> print(t)

[[[ 0 1 2 3]

[ 4 5 6 7]

[ 8 9 10 11]]

[[12 13 14 15]

[16 17 18 19]

[20 21 22 23]]

[[24 25 26 27]

[28 29 30 31]

[32 33 34 35]]]

在这里，我们使用np.arange定义t为一个包含36个元素的向量，元素值为0到35。然后，我们立即将该向量重塑为一个包含3 × 3 × 4个元素的张量（3 × 3 × 4 = 36）。一种理解3 × 3 × 4张量的方式是，它包含三张3 × 4的图像。如果我们记住这一点，接下来的陈述就能理解了：

>>> print(t[0])

[[ 0 1 2 3]

[ 4 5 6 7]

[ 8 9 10 11]]

>>> print(t[0,1])

[4 5 6 7]

>>> print(t[0,1,2])

6

请求t[0]将返回堆栈中的第一张3 × 4*图像*。接着，t[0,1]应该返回第一张图像的第二行，正如它所做的那样。最后，我们通过请求图像编号（0），行编号（1）和该行的元素（2）来得到t的一个单独元素。

将张量的维度分配给一个个越来越小的集合，是帮助记住维度含义的一种有效方式。例如，我们可以这样定义一个阶为5的张量：

>>> w = np.zeros((9,9,9,9,9))

>>> w[4,1,2,0,1]

0.0

但是，w[4,1,2,0,1]意味着什么呢？其确切含义取决于应用场景。例如，我们可能将w看作表示一个书架。第一个索引选择书架的层，第二个索引选择书架上的书籍。然后，第三个索引选择书中的页面，第四个索引选择页面上的行。最后一个索引选择行上的单词。因此，w[4,1,2,0,1]是在询问书架第五层上的第二本书的第三页中的第一行的第二个单词，这个含义是从右到左读索引来理解的。

书架类比确实有它的局限性。NumPy 数组有固定的维度，这意味着如果 w 是一个书架，那么它有九个架子，每个架子上有 *恰好* 九本书。同样，每本书有 *恰好* 九页，每一页有九行。最后，每行恰好有九个单词。NumPy 数组通常使用计算机中的连续内存，因此当数组被定义时，每个维度的大小是固定的。这样做并选择特定的数据类型，比如无符号整数，可以使得定位数组的一个元素变成通过简单公式从基址内存地址计算偏移量的索引操作。这就是为什么 NumPy 数组比 Python 列表要快得多。

任何小于 *n* 阶的张量都可以通过补充缺失的长度为一的维度来表示为 *n* 阶张量。我们在上面看到过一个例子，当我说一个 *m* 分量的向量可以被视为一个 1 × *m* 或 *m* × 1 的矩阵时，就是这个情况。通过添加一个缺失的长度为一的维度，1阶张量（向量）被转化为2阶张量（矩阵）。

作为一个极端例子，我们可以将一个标量（0阶张量）视为一个5阶张量，像这样：

>>> t = np.array(42).reshape((1,1,1,1,1))

>>> print(t)

[[[[[42]]]]]

>>> t.shape

(1, 1, 1, 1, 1)

>>> t[0,0,0,0,0]

42

在这里，我们将标量 42 重新塑造为一个 5 阶张量（一个五维 [5D] 数组），每个轴的长度为一。注意，NumPy 告诉我们，张量 t 具有五个维度，周围有 [[[[[ 和 ]]]]]。请求 t 的形状确认它是一个 5D 张量。最后，作为张量，我们可以通过指定 t[0,0,0,0,0] 来获取它包含的单个元素的值。我们经常会使用这种添加新维度的技巧。实际上，在 NumPy 中，有一种方法可以直接做到这一点，你会在使用深度学习工具包时看到：

>>> t = np.array([[1,2,3],[4,5,6]])

>>> print(t)

[[1 2 3]

[4 5 6]]

>>> w = t[np.newaxis,:,:]

>>> w.shape

(1, 2, 3)

>>> print(w)

[[[1 2 3]

[4 5 6]]]

在这里，我们通过使用 np.newaxis 创建一个新的长度为一的轴，将 t（一个2阶张量，矩阵）转化为一个3阶张量。这就是为什么 w.shape 返回 (1,2,3) 而不是 (2,3)，如同 t 那样。

张量与几何之间有一些类比，这有助于可视化不同阶张量之间的关系：

| **阶数（维度）** | **张量名称** | **几何名称** |
| --- | --- | --- |
| 0 | 标量 | 点 |
| 1 | 向量 | 直线 |
| 2 | 矩阵 | 平面 |
| 3 | 张量 | 体积 |

注意，在表格中我使用了 *张量* 这个术语的常见含义。似乎没有统一的名称来表示一个3阶张量。

在这一节中，我们将深度学习的数学对象与多维数组相关联，因为它们在代码中的实现方式就是这样。通过这样做，我们丢弃了很多数学内容，但保留了理解深度学习所需的部分。接下来我们继续，看看如何在表达式中使用张量。

### 张量运算

本节的目的是详细说明张量的操作，特别强调1阶张量（向量）和2阶张量（矩阵）。我们假设此时标量的操作已经很熟悉。

我们将从我称之为*数组操作*的内容开始，这指的是工具包如NumPy在所有维度的数组上执行的逐元素操作。然后我们将进入向量特有的操作。这为矩阵乘法这一关键主题奠定了基础。最后，我们将讨论块矩阵。

#### 数组操作

到目前为止，我们使用NumPy工具包的方式向我们展示了，所有正常的标量算术运算都可以直接转化为多维数组的运算。这包括标准的加法、减法、乘法、除法和指数运算，以及对数组应用函数。在所有这些情况下，标量操作都是逐元素应用到数组的每个元素上的。这里的示例为本节的其余部分定下了基调，也让我们探索了一些尚未提及的NumPy广播规则。

让我们首先定义一些数组来操作：

>>> a = np.array([[1,2,3],[4,5,6]])

>>> b = np.array([[7,8,9],[10,11,12]])

>>> c = np.array([10,100,1000])

>>> d = np.array([10,11])

>>> print(a)

[[1 2 3]

[4 5 6]]

>>> print(b)

[[ 7 8 9]

[10 11 12]]

>>> print(c)

[ 10 100 1000]

>>> print(d)

[10 11]

对于维度匹配的数组，逐元素的算术运算是直接的：

>>> print(a+b)

[[ 8 10 12]

[14 16 18]]

>>> print(a-b)

[[-6 -6 -6]

[-6 -6 -6]]

>>> print(a*b)

[[ 7 16 27]

[40 55 72]]

>>> print(a/b)

[[0.14285714 0.25 0.33333333]

[0.4 0.45454545 0.5 ]]

>>> print(b**a)

[[ 7 64 729]

[ 10000 161051 2985984]]

这些结果都足够简单，容易解释；NumPy将所需的操作应用于每个数组的相应元素。对两个矩阵（a 和 b）进行逐元素相乘通常被称为*哈达玛积*。（你在深度学习文献中时常会遇到这个术语。）

NumPy工具包将逐元素操作的概念扩展到它所称的*广播*。在广播过程中，NumPy应用一些规则，接下来我们将通过示例看到这些规则，规则是将一个数组应用到另一个数组上，从而生成有意义的输出。

当我们对一个数组与标量进行操作时，已经遇到过一种形式的广播。在这种情况下，标量值会广播到数组的每个值。

对于我们的第一个示例，尽管a是一个2 × 3的矩阵，NumPy允许通过广播将其与一个包含三个分量的向量c进行操作：

>>> print(a+c)

[[ 11 102 1003]

[ 14 105 1006]]

>>> print(c*a)

[[ 10 200 3000]

[ 40 500 6000]]

>>> print(a/c)

[[0.1 0.02 0.003]

[0.4 0.05 0.006]]

这里，三维向量 c 被广播到了 2 × 3 矩阵 a 的行上。NumPy 识别到 a 和 c 的最后一个维度都是三，所以该向量可以广播到矩阵上，得到预期的输出。当你查看深度学习代码时，很多代码都是 Python 编写的，你会遇到类似的情况。此时，有时需要一些思考，配合在 Python 提示符下的实验，才能理解发生了什么。

我们能否将 d 这个二维向量广播到 a 这个 2 × 3 的矩阵上？如果我们尝试以相同的方式将 c 广播到 a 上，我们会失败：

>>> print(a+d)

Traceback (most recent call last):

文件 "<stdin>", 第 1 行，位于 <module>

ValueError: 操作数无法在形状 (2,3) 和 (2,) 上广播。

然而，NumPy 的广播规则适用于长度为 1 的维度。d 的形状是 2；它是一个包含两个元素的向量。如果我们将 d 重塑为一个 2D 数组，形状为 2 × 1，那么我们就给 NumPy 提供了它所需要的格式：

>>> d = d.reshape((2,1))

>>> d.shape

(2, 1)

>>> print(a+d)

[[11 12 13]

[15 16 17]]

我们现在看到 Numpy 已经将 d 加到了 a 的列上。

让我们回到数学的世界，看看向量上的运算。

#### 向量运算

向量在代码中表示为一组数字，可以解释为沿着一组坐标轴的数值。在这里，我们将定义一些只适用于向量的运算。

##### 长度

在几何上，我们可以将向量理解为具有方向和长度的量。它们通常被画成箭头，我们将在 [第 6 章](ch06.xhtml#ch06) 中看到一个向量图的例子。人们常说向量的长度是它的 *大小*。因此，我们将首先考虑的向量运算是计算其大小。对于一个具有 *n* 个分量的向量 ***x***，其大小的公式是

![Image](Images/05equ03.jpg)

在 [方程 5.3](ch05.xhtml#ch05equ03) 中，围绕向量的双竖线表示它的大小。你也经常看到有人使用单竖线。单竖线也用于表示绝对值；我们通常依赖上下文来判断这两者之间的区别。

[方程 5.3](ch05.xhtml#ch05equ03)从哪里来的？考虑一个二维向量，***x*** = (*x*, *y*)。如果 *x* 和 *y* 分别是 x 轴和 y 轴上的长度，我们可以看到 *x* 和 *y* 形成了一个直角三角形的两条边。这个直角三角形的斜边长度就是向量的长度。因此，根据毕达哥拉斯定理，以及早在他之前的巴比伦人，这个长度是 ![Image](Images/112equ01.jpg)，将其推广到 *n* 维后，得到的就是 [方程 5.3](ch05.xhtml#ch05equ03)。

##### 单位向量

现在我们可以计算向量的大小，接下来我们引入一个有用的向量形式，称为 *单位向量*。如果我们将一个向量的分量除以它的大小，我们就得到一个方向与原向量相同，但大小为一的单位向量。这就是单位向量。对于一个向量 ***v***，与其方向相同的单位向量是

![Image](Images/112equ02.jpg)

其中，向量上方的帽子标记表示它是一个单位向量。让我们看一个具体的例子。我们的示例向量是 ***v*** = (2, –4,3)。因此，方向与 ***v*** 相同的单位向量是

![Image](Images/112equ03.jpg)

在代码中，我们通过以下方式计算单位向量：

>>> v = np.array((2, -4, 3))

>>> u = v / np.sqrt((v*v).sum())

>>> print(u)

[ 0.37139068 -0.74278135 0.55708601 ]

在这里，我们利用了这样的事实：要平方 v 的每个元素，我们将其与自身逐元素相乘，然后通过调用 sum 将各个分量加在一起，得到平方的大小。

##### 向量转置

我们之前提到过，行向量可以被看作是 1 × *n* 的矩阵，而列向量是 *n* × 1 的矩阵。将行向量转换为列向量，反之亦然，称为取 *转置*。我们将在[第六章](ch06.xhtml#ch06)中看到转置同样适用于矩阵。在符号表示上，我们用 ***y***^⊤ 来表示向量 ***y*** 的转置。因此，我们有

![Image](Images/113equ01.jpg)

当然，我们不仅仅局限于三个分量。

在代码中，我们可以通过几种方式转置向量。如上所示，我们可以使用 reshape 将向量重塑为 1 × *n* 或 *n* × 1 的矩阵。我们也可以谨慎地调用转置方法，或者使用转置的简写。让我们来看所有这些方法的示例。首先，我们定义一个 NumPy 向量，看看 reshape 如何将它转换为 3 × 1 的列向量和 1 × 3 的行向量，而不是普通的三元素向量：

>>> v = np.array([1,2,3])

>>> print(v)

[1 2 3]

>>> print(v.reshape((3,1)))

[[1]

[2]

[3]]

>>> print(v.reshape((1,3)))

[[1 2 3]]

注意，第一次打印 v 和最后一次调用 reshape((1,3)) 后的区别。输出现在多了一组括号，表示它的前导维度为 1。

接下来，我们对 v 应用转置操作：

>>> print(v.transpose())

[1 2 3]

>>> print(v.T)

[1 2 3]

这里，我们看到调用转置或 T 对 v 没有任何变化。这是因为 v 的形状仅为 3，而不是 (1,3) 或 (3,1)。如果我们显式地将 v 改为一个 1 × 3 的矩阵，我们会看到转置和 T 达到了预期效果：

>>> v = v.reshape((1,3))

>>> print(v.transpose())

[[1]

[2]

[3]]

>>> print(v.T)

[[1]

[2]

[3]]

这里，v 从行向量变为列向量，正如我们所期望的那样。那么，教训就是要小心 NumPy 代码中向量的实际维度。大多数时候我们可以不那么严格，但有时我们需要明确区分普通向量、行向量和列向量。

##### 内积

也许最常见的向量操作是*内积*，或者更常称为*点积*。在符号上，两个向量的内积写作

![Image](Images/05equ04.jpg)![Image](Images/05equ05.jpg)

这里，*θ* 是两个向量之间的夹角，如果它们在几何上被解释。内积的结果是一个标量。〈***a***, ***b***〉符号常常出现，尽管在深度学习文献中，***a*** • ***b*** 点积符号似乎更常见。***a***^⊤***b*** 矩阵乘法符号明确说明了如何计算内积，但我们会等到讨论矩阵乘法时再解释它的含义。目前，求和公式告诉我们：两个长度为 *n* 的向量的内积是 *n* 个分量乘积的和。

向量与自身的内积是其大小的平方：

***a*** • ***a*** = ||***a***||²

内积是可交换的，

***a*** • ***b*** = ***b*** • ***a***

且是分配的，

***a*** • (***b*** + ***c***) = ***a*** • ***b*** + ***a*** • ***c***

但它不是结合律的，因为第一个内积的输出是一个标量，而不是向量，且向量与标量相乘不是内积。

最后，注意到当两个向量之间的夹角为 90 度时，内积为零；这是因为 cos *θ* 为零（[公式 5.5](ch05.xhtml#ch05equ05)）。这意味着两个向量是垂直的，或者说是*正交*的。

让我们来看一些内积的例子。首先，我们将逐字实现 [公式 5.4](ch05.xhtml#ch05equ04)：

>>> a = np.array([1,2,3,4])

>>> b = np.array([5,6,7,8])

>>> def inner(a,b):

...   s = 0.0

...   for i in range(len(a)):

...     s += a[i]*b[i]

...   return s

...

>>> inner(a,b)

70.0

然而，由于 a 和 b 是 NumPy 数组，我们知道我们可以更高效：

>>> (a*b).sum()

70

或者，可能最有效的方式是，让 NumPy 来为我们处理，使用 np.dot：

>>> np.dot(a,b)

70

在深度学习代码中，你会经常看到 np.dot。它不仅仅能计算内积，下面我们会看到更多用法。

[公式 5.5](ch05.xhtml#ch05equ05)告诉我们，两个向量之间的夹角是

![Image](Images/115equ01.jpg)

在代码中，这可以这样计算

>>> A = np.sqrt(np.dot(a,a))

>>> B = np.sqrt(np.dot(b,b))

>>> t = np.arccos(np.dot(a,b)/(A*B))

>>> t*(180/np.pi)

14.335170291600924

这告诉我们，转换 t 为弧度后，***a*** 和 ***b*** 之间的夹角大约是 14°。

如果我们考虑三维空间中的向量，我们会看到，正交向量之间的点积为零，这意味着它们之间的夹角是 90°：

>>> a = np.array([1,0,0])

>>> b = np.array([0,1,0])

>>> np.dot(a,b)

0

>>> t = np.arccos(0)

>>> t*(180/np.pi)

90.0

这是因为 ***a*** 是沿 x 轴的单位向量，***b*** 是沿 y 轴的单位向量，并且我们知道它们之间存在直角。

有了内积作为工具箱中的一部分，让我们看看如何使用它将一个向量投影到另一个向量上。

##### 投影

一个向量在另一个向量上的投影计算的是第一个向量在第二个向量方向上的分量。***a*** 在 ***b*** 上的投影是

![Image](Images/116equ01.jpg)

[图 5-1](ch05.xhtml#ch05fig01) 直观地展示了投影在 2D 向量中的意义。

![image](Images/05fig01.jpg)

*图 5-1：***a*** 在 2D 平面上投影到 ***b*** 的图示表示*

投影找出 ***a*** 在 ***b*** 方向上的分量。注意，***a*** 在 ***b*** 上的投影与 ***b*** 在 ***a*** 上的投影并不相同。

因为我们在分子中使用了内积，我们可以看到一个向量投影到另一个与其正交的向量上的结果为零。第一个向量没有任何分量在第二个向量的方向上。再想想 x 轴和 y 轴。我们使用笛卡尔坐标系的根本原因是两个坐标轴，或在三维空间中的三个坐标轴，都是互相正交的；其中一个轴没有任何部分在其他轴的方向上。这让我们能够通过指定沿这些轴的分量来确定任意点及从原点到该点的向量。稍后当我们讨论特征向量和主成分分析（PCA）时，会看到这种将物体分解为相互正交分量的过程，详见[第 6 章](ch06.xhtml#ch06)。

在代码中，计算投影是直接的：

>>> a = np.array([1,1])

>>> b = np.array([1,0])

>>> p = (np.dot(a,b)/np.dot(b,b))*b

>>> print(p)

[1\. 0.]

>>> c = np.array([-1,1])

>>> p = (np.dot(c,b)/np.dot(b,b))*b

>>> print(p)

[-1\. -0.]

在第一个例子中，***a*** 在 x 轴上方 45° 方向，***b*** 则沿着 x 轴方向。我们可以预期，***a*** 的投影会沿着 x 轴，这正是它所表现的（p）。在第二个例子中，***c*** 在 x 轴上方 135° = 90° + 45° 方向。因此，我们可以预期，***c*** 沿着 ***b*** 的分量将会沿着 x 轴，但与 ***b*** 的方向相反，结果正是如此。

**注意**

*将 ***c*** 沿 ***b*** 投影得到的 y 轴分量为 –0。负号是 IEEE 754 浮点数表示法的特性。内部表示的有效数字（尾数）为零，但符号仍然可以指定，这导致有时输出负零。有关计算机数字格式（包括浮点数）的详细解释，请参阅我的书，*《数字与计算机》*（Springer-Verlag，2017）。*

现在让我们继续讨论两个向量的外积。

##### 外积

两个向量的内积返回一个标量值。两个向量的*外积*则返回一个矩阵。请注意，与内积不同，外积不要求两个向量具有相同数量的分量。具体而言，对于具有*m*个分量的向量***a***和具有*n*个分量的向量***b***，外积是一个矩阵，通过将***a***的每个元素与***b***的每个元素相乘得到，如下所示。

![图片](Images/118equ01.jpg)

***ab***^⊤符号表示通过矩阵乘法计算外积。请注意，这个符号与内积***a***^⊤***b***不同，并且它假设***a***和***b***是列向量。外积通常没有一致的操作符，主要是因为它可以通过矩阵乘法轻松地指定，并且比点积更少见。然而，当外积用二元操作符表示时，⊗似乎是最常用的符号。

在代码中，NumPy 为我们提供了一个外积函数：

>>> a = np.array([1,2,3,4])

>>> b = np.array([5,6,7,8])

>>> np.dot(a,b)

70

>>> np.outer(a,b)

array([[ 5, 6, 7, 8],

[10, 12, 14, 16],

[15, 18, 21, 24],

[20, 24, 28, 32]])

在上面讨论内积时，我们使用了a和b。如预期的那样，np.dot为***a***•***b***返回一个标量输出。然而，np.outer函数返回一个4 × 4的矩阵，其中我们看到每一行是向量b依次乘以向量a的每个元素，首先是1，然后是2，再是3，最后是4。因此，a的每个元素都与b的每个元素相乘。最终得到的矩阵是4 × 4，因为a和b都有四个元素。

笛卡尔积

两个向量的外积与两个集合*A*和*B*的笛卡尔积之间有直接的类比。*笛卡尔积*是一个新集合，其中每个元素都是从*A*和*B*中元素的可能配对。因此，如果*A*={1,2,3,4}，*B*={5,6,7,8}，那么笛卡尔积可以写作

![图片](Images/118equ02.jpg)

在这里，我们看到如果将每个元素替换为对应的数对乘积，就能得到我们之前用 NumPy np.outer 得到的向量积。另外，注意在处理集合时，×通常用于表示笛卡尔积。

外积能够混合其输入的所有组合，这一特性已在深度学习中用于神经协同过滤和视觉问答应用中。这些功能由高级网络执行，用于推荐或回答有关图像的文本问题。外积表现为两种不同嵌入向量的混合。*嵌入*是由网络低层生成的向量，例如传统卷积神经网络（CNN）中软最大层输出之前的倒数第二个全连接层。嵌入层通常被视为已学习了网络输入的一个新表示。它可以被认为是将复杂的输入（如图像）映射到一个几百到几千维的简化空间。

##### 叉积

我们的最终向量-向量运算符是*叉积*。这个运算符仅在三维空间（ℝ³）中定义。***a***和***b***的叉积是一个新向量，垂直于包含***a***和***b***的平面。请注意，这并不意味着***a***和***b***本身是垂直的。叉积定义为

![Image](Images/05equ06.jpg)

其中 ![Image](Images/ncap.jpg) 是单位向量，*θ* 是 ***a*** 和 ***b*** 之间的角度。![Image](Images/ncap.jpg) 的方向由*右手定则*给出。用你的右手，伸出食指指向 ***a*** 的方向，中指指向 ***b*** 的方向。然后，大拇指将指向 ![Image](Images/ncap.jpg) 的方向。[方程 5.6](ch05.xhtml#ch05equ06) 给出了叉积向量在 ℝ³ 中的实际分量。

NumPy 通过 np.cross 实现叉积：

>>> a = np.array([1,0,0])

>>> b = np.array([0,1,0])

>>> print(np.cross(a,b))

[0 0 1]

>>> c = np.array([1,1,0])

>>> print(np.cross(a,c))

[0 0 1]

在第一个示例中，a 指向 x 轴，b 指向 y 轴。因此，我们预计叉积会垂直于这些轴，结果也是如此：叉积指向 z 轴。第二个示例表明，a 和 b 是否垂直并不重要。在这里，c 与 x 轴成 45° 角，但 a 和 c 仍然在 xy 平面内。因此，叉积仍然沿着 z 轴。

叉积的定义涉及 sin *θ*，而内积则使用 cos *θ*。当两个向量互相正交时，内积为零。另一方面，当两个向量在同一方向时，叉积为零，当向量垂直时，叉积达到最大值。上面的第二个 NumPy 示例之所以有效，是因为 c 的大小为 ![Image](Images/120equ01.jpg) 且 sin ![Image](Images/120equ02.jpg)。因此，![Image](Images/120equ01.jpg)因子相互抵消，叉积的大小为 1，因为 a 是单位向量。

叉积在物理学和其他科学中被广泛使用，但在深度学习中不常用，因为它仅限于三维空间。然而，如果你打算阅读深度学习文献，你应该对它有所了解。

这就结束了我们对向量-向量操作的讨论。让我们离开一维世界，转而考虑所有深度学习中最重要的操作：矩阵乘法。

#### 矩阵乘法

在前一节中，我们看到了如何以不同的方式乘以两个向量：哈达玛积、内积（点积）、外积和叉积。在这一节中，我们将研究矩阵的乘法，回顾一下行向量和列向量本身就是只有一行或一列的矩阵。

##### 矩阵乘法的性质

我们将在稍后定义矩阵乘积运算，但在此之前，让我们先看一下矩阵乘法的性质。设***A***、***B***和***C***为矩阵。那么，根据代数习惯，符号通过放置在一起进行相乘，

***(AB)C*** = ***A***(***BC***)

这意味着矩阵乘法是结合律的。其次，矩阵乘法是分配律的：

![Image](Images/05equ07.jpg)![Image](Images/05equ08.jpg)

然而，通常情况下，矩阵乘法是*不*满足交换律的：

***AB*** ≠ ***BA***

正如你在[方程 5.8](ch05.xhtml#ch05equ08)中看到的，右侧的矩阵乘法加法与左侧的矩阵乘法加法会产生不同的结果，如[方程 5.7](ch05.xhtml#ch05equ07)所示。这也解释了为什么我们展示了[方程 5.7](ch05.xhtml#ch05equ07)和[方程 5.8](ch05.xhtml#ch05equ08)；矩阵乘法可以从左侧或右侧执行，结果会不同。

##### 如何乘以两个矩阵

要计算***AB***，知道***A***必须在***B***的左边，我们首先需要验证矩阵是否兼容。只有当***A***的列数与***B***的行数相同，才能相乘。因此，如果***A***是一个*n × m*矩阵，***B***是一个*m × k*矩阵，那么积***AB***可以计算出来，并且将是一个新的*n* × *k*矩阵。

要计算积，我们需要在***A***的行向量与***B***的列向量之间执行一系列内积乘法。[图 5-2](ch05.xhtml#ch05fig02)展示了一个3 × 3矩阵***A***与一个3 × 2矩阵***B***的乘法过程。

![image](Images/05fig02.jpg)

*图 5-2：将3* × *3矩阵与3* × *2矩阵相乘*

在 [图 5-2](ch05.xhtml#ch05fig02) 中，输出矩阵的第一行是通过计算 ***A*** 的第一行与 ***B*** 的每一列的内积得到的。输出矩阵的第一个元素是通过将 ***A*** 的第一行与 ***B*** 的第一列相乘得到的。输出矩阵的剩余第一行是通过对 ***A*** 的第一行与 ***B*** 的其余列的点积进行重复计算得到的。

让我们通过 [图 5-2](ch05.xhtml#ch05fig02) 中实际的矩阵数字来展示一个例子：

![Image](Images/121equ01.jpg)

请注意，***AB*** 是定义的，但 ***BA*** 不是，因为我们不能将一个 3 × 2 的矩阵与一个 3 × 3 的矩阵相乘。***B*** 的列数必须与 ***A*** 的行数相同。

另一种理解矩阵乘法的方式是考虑如何构成每个输出矩阵元素。例如，如果 ***A*** 是 *n* × *m* 且 ***B*** 是 *m* × *p*，我们知道矩阵乘积是一个 *n* × *p* 的矩阵，***C***。我们通过计算得到输出元素：

![Image](Images/05equ09.jpg)

对于 *i* = 0, . . . , *n* − 1 和 *j* = 0, . . . , *p* − 1。在上面的例子中，我们通过求和 *a*[20]*b*[01] + *a*[21]*b*[11] + *a*[22]*b*[21] 来得到 *c*[21]，这与 [公式 5.9](ch05.xhtml#ch05equ09) 相符，其中 *i* = 2，*j* = 1 和 *k* = 0, 1, 2。

[公式 5.9](ch05.xhtml#ch05equ09) 告诉我们如何找到单个输出矩阵元素。如果我们循环遍历 *i* 和 *j*，我们可以找到整个输出矩阵。这意味着矩阵乘法的直接实现：

def matrixmul(A,B):

I,K = A.shape

J = B.shape[1]

C = np.zeros((I,J), dtype=A.dtype)

for i in range(I):

for j in range(J):

for k in range(K):

C[i,j] += A[i,k]*B[k,j]

return C

我们假设参数 ***A*** 和 ***B*** 是兼容的矩阵。我们设置输出矩阵 ***C*** 的行数 (I) 和列数 (J)，并将它们作为 ***C*** 元素的循环限制。我们创建输出矩阵 C，并使其与 A 具有相同的数据类型。然后开始一个三重循环。对 *i* 的循环遍历输出的所有行。接下来的循环，针对 *j*，遍历当前行的列，最内层的循环，针对 *k*，遍历 A 和 B 中元素的组合，正如 [公式 5.9](ch05.xhtml#ch05equ09) 中所示。当所有循环完成时，我们返回矩阵乘积 C。

函数 matrixmul 可以工作。它找到矩阵乘积。然而，在实现方面，它相当简单。确实存在更先进的算法，并且在使用编译代码时，简单方法的优化也有很多。正如我们将在下面看到的，NumPy 支持矩阵乘法，并且内部使用高度优化的编译代码库，性能远超上面简单代码的执行。

##### 内积和外积的矩阵表示

现在我们可以理解上面关于内积***a***^⊤***b***和外积***ab***^⊤的矩阵表示了。对于内积的情况，我们有一个1 × *n*的行向量（由于转置），和一个*n* × 1的列向量。算法要求我们形成行向量和列向量的内积，得出一个1 × 1的输出矩阵，即一个标量值。注意，***a***和***b***必须都有*n*个分量。

对于外积，我们有一个*n* × 1的列向量在左边，一个1 × *m*的行向量在右边。因此，我们知道输出矩阵的形状是*n* × *m*。如果*m* = *n*，我们将得到一个*n* × *n*的输出矩阵。一个行数与列数相等的矩阵被称为*方阵*。这些矩阵有一些特殊的性质，其中一些我们将在[第6章](ch06.xhtml#ch06)中看到。

要通过矩阵乘法找到两个向量的外积，我们将***a***的每一行的每个元素与***b***的每一列相乘，就像一个行向量*。

![图片](Images/123equ01.jpg)

在这里，***b***^⊤的每一列，一个标量数值，将沿着***a***的行传递，从而形成两个向量之间的每一个可能的乘积。

我们已经看过如何手动进行矩阵乘法。现在让我们看看NumPy是如何支持矩阵乘法的。

##### NumPy中的矩阵乘法

NumPy提供了两个可以用于矩阵乘法的不同函数。第一个是我们已经见过的np.dot，虽然我们到目前为止仅使用它来计算向量的内积。第二个是np.matmul，当使用Python 3.5及更高版本中的@二进制运算符时也会调用它。无论使用哪个函数，矩阵乘法都会如我们所预期地工作。然而，NumPy有时会将1D数组与行向量或列向量区分对待。

我们可以使用shape来判断一个NumPy数组是1D数组、行向量还是列向量，如[列出5-1](ch05.xhtml#ch05ex01)所示：

>>> av = np.array([1,2,3])

>>> ar = np.array([[1,2,3]])

>>> ac = np.array([[1],[2],[3]])

>>> av.shape

(3,)

>>> ar.shape

(1, 3)

>>> ac.shape

(3, 1)

*列出5-1：NumPy向量*

在这里，我们看到一个包含三个元素的1D数组av，它的形状与一个包含三个分量的行向量ar或列向量ac不同。然而，这些数组都包含相同的三个整数：1、2和3。

让我们进行一个实验，帮助我们理解NumPy是如何实现矩阵乘法的。我们将测试np.dot，但如果使用np.matmul或@运算符，结果是相同的。我们需要一些向量和矩阵的集合来进行测试。然后，我们将它们的组合应用到np.dot，并考虑输出，如果该组合的操作未定义，可能会出现错误。

让我们创建我们需要的数组、向量和矩阵：

a1 = np.array([1,2,3])

ar = np.array([[1,2,3]])

ac = np.array([[1],[2],[3]])

b1 = np.array([1,2,3])

br = np.array([[1,2,3]])

bc = np.array([[1],[2],[3]])

A = np.array([[1,2,3],[4,5,6],[7,8,9]])

B = np.array([[9,8,7],[6,5,4],[3,2,1]])

对象的形状应该可以从定义中看出，如果我们记得 [清单 5-1](ch05.xhtml#ch05ex01) 的结果。我们还将定义两个 3 × 3 的矩阵 A 和 B。

接下来，我们将定义一个辅助函数来封装对 NumPy 的调用，以便捕获任何错误：

def dot(a,b):

try:

return np.dot(a,b)

except:

return "失败"

这个函数调用 np.dot 并在调用不成功时返回 “失败”。[表 5-1](ch05.xhtml#ch05tab01) 显示了 dot 对上述输入组合的输出。

[表 5-1](ch05.xhtml#ch05tab01) 说明了NumPy有时如何将一维数组与行向量或列向量区分对待。请参见 [表 5-1](ch05.xhtml#ch05tab01) 中 a1,A 与 ar,A 和 A,ac 的区别。A,ac 的输出是我们在数学上预期看到的结果，其中列向量 ***a[c]*** 被矩阵 ***A*** 从左侧相乘。

np.dot 和 np.matmul 之间有实际差异吗？有的。对于 1D 和 2D 数组，二者没有区别。然而，当处理大于二维的数组时，每个函数的处理方式不同，虽然我们这里不会使用那些数组。此外，np.dot 允许其中一个参数是标量，并将另一个参数的每个元素与之相乘。而使用 np.matmul 进行标量乘法会引发错误。

**表 5-1：** 对不同类型的参数应用 dot 或 matmul 的结果

| **参数** | **np.dot 或 np.matmul 的结果** |
| --- | --- |
| a1,b1 | 14 (标量) |
| a1,br | 失败 |
| a1,bc | [14] (1维向量) |
| ar,b1 | [14] (1维向量) |
| ar,br | 失败 |
| ar,bc | [14] (1 × 1 矩阵) |
| ac,b1 | 失败 |
| ac,br | ![Image](Images/124equ01.jpg) |
| ac,bc | 失败 |
| A,a1 | [14 32 50] (3维向量) |
| A,ar | 失败 |
| A,ac | ![Image](Images/124equ02.jpg) |
| a1,A | [30 36 42] (3维向量) |
| ar,A | [30 36 42] (1 × 3 矩阵) |
| ac,A | 失败 |
| A,B | ![Image](Images/124equ03.jpg) |

#### 克罗内克积

我们将讨论的矩阵乘法的最终形式是 *克罗内克积* 或 *矩阵直接积*。在计算矩阵乘积时，我们将矩阵的各个元素混合在一起并进行相乘。而对于克罗内克积，我们通过将一个矩阵的元素与另一个矩阵的所有元素相乘，生成一个比输入矩阵大的输出矩阵。克罗内克积也是引入 *块矩阵* 概念的方便途径，块矩阵是由较小矩阵（块）构成的矩阵。

例如，如果我们有三个矩阵

![Image](Images/05equ10.jpg)

我们可以定义一个块矩阵 ***M***，如下所示。

![Image](Images/126equ01.jpg)

其中每个 ***M*** 的元素是一个堆叠在一起的较小矩阵。

我们可以通过一个涉及块矩阵的可视化示例最容易地定义克罗内克积。***A*** 和 ***B*** 的克罗内克积，通常写作 ***A*** ⊗ ***B***，为：

![Image](Images/126equ02.jpg)

对于***A***，一个*m* × *n*的矩阵。这是一个块矩阵，因为有了***B***，因此完全展开后，克罗内克积会得到一个比***A***或***B***都要大的矩阵。注意，与矩阵乘法不同，克罗内克积适用于任意大小的***A***和***B***矩阵。例如，使用[方程 5.10](ch05.xhtml#ch05equ10)中的***A***和***B***，克罗内克积是

![Image](Images/126equ03.jpg)

注意到我们在上面使用了⊗表示克罗内克积。这是约定俗成的符号，尽管⊗有时也会被滥用，用于表示其他的运算。比如，我们就用它来表示两个向量的外积。NumPy通过np.kron支持克罗内克积。

### 总结

在本章中，我们介绍了深度学习中使用的数学对象：标量、向量、矩阵和张量。接着，我们探讨了张量的运算，尤其是与向量和矩阵的运算。我们看到了如何在数学上以及通过NumPy代码对这些对象进行操作。

然而，我们对线性代数的探索还没有完成。在下一章，我们将深入研究矩阵及其性质，讨论一些我们可以用或需要了解的关于矩阵的重要内容。

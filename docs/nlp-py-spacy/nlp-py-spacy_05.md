## **5

**使用词向量**

![Image](img/comm1.jpg)

词向量是表示自然语言单词意义的一系列实数。正如你在第一章中学到的，它们使机器能够理解人类语言。在这一章中，你将使用词向量计算不同文本的语义相似度，这将帮助你，例如，根据文本所涉及的主题对这些文本进行分类。

你将首先从概念上了解词向量，以便你能大致了解如何通过数学计算来评估以向量形式表示的单词之间的语义相似度。接着，你将学习机器学习算法如何生成在 spaCy 模型中实现的词向量。你将使用 spaCy 的*相似度方法*，该方法通过比较容器对象的词向量来确定它们意义的相近程度。你还将学习如何在实际操作中使用词向量，并执行一些预处理步骤，如选择关键词，以提高操作效率。

### **理解词向量**

在构建统计模型时，我们将单词映射到反映其语义相似度的实数向量。你可以把词向量空间想象成一个云，词义相似的单词的向量靠得比较近。例如，表示“土豆”的词向量应该比表示“哭泣”的词向量更靠近表示“胡萝卜”的词向量。为了生成这些向量，我们必须能够编码这些单词的意义。这里有几种编码意义的方法，我们将在本节中介绍。

#### ***通过坐标定义意义***

生成有意义的词向量的一种方式是为每个词向量的坐标分配来自现实世界的对象或类别。例如，假设你正在为以下单词生成词向量：罗马、意大利、雅典和希腊。这些词向量应当在数学上反映出罗马是意大利的首都，并且与意大利的关系不同于雅典与意大利的关系。同时，它们应当反映出雅典和罗马是首都城市，而希腊和意大利是国家。表 5-1 展示了这个向量空间的样子，以矩阵的形式呈现。

**表 5-1：** 简化的词向量空间

|  | **国家** | **首都** | **希腊语** | **意大利语** |
| --- | --- | --- | --- | --- |
| 意大利 | 1 | 0 | 0 | 1 |
| 罗马 | 0 | 1 | 0 | 1 |
| 希腊 | 1 | 0 | 1 | 0 |
| 雅典 | 0 | 1 | 1 | 0 |

我们已经将每个词的意义分配到四维空间中的坐标上，表示“国家”、“首都”、“希腊语”和“意大利语”这几个类别。在这个简化的例子中，坐标值可以是 1 或 0，表示一个对应的单词是否属于某个类别。

一旦你拥有一个向量空间，其中数字向量捕捉了相应单词的含义，你就可以在这个向量空间上进行向量运算，以深入了解单词的含义。为了找出雅典是哪个国家的首都，你可以使用以下方程，其中每个符号代表其对应的向量，X 是一个未知向量：

意大利 - 罗马 = X - 雅典

这个方程表示一种类比，其中 X 代表与雅典的关系与意大利与罗马的关系相同的词向量。为了解出 X，我们可以将方程重写为：

X = 意大利 - 罗马 + 雅典

我们首先通过逐个减去相应的词向量元素，将罗马的向量从意大利的向量中减去。然后我们将得到的向量与雅典的向量相加。表 5-2 总结了这一计算过程。

**表 5-2：** 对词向量空间进行向量运算

|  |  | **国家** | **首都** | **希腊语** | **意大利语** |
| --- | --- | --- | --- | --- | --- |
| ― | 意大利 | 1 | 0 | 0 | 1 |
| + | 罗马 | 0 | 1 | 0 | 1 |
|  | 雅典 | 0 | 1 | 1 | 0 |
|  | 希腊 | 1 | 0 | 1 | 0 |

通过从意大利的词向量中减去罗马的词向量，再加上雅典的词向量，我们得到一个与希腊词向量相等的向量。

#### ***使用维度表示含义***

尽管我们刚刚创建的向量空间只有四个类别，但现实世界中的向量空间可能需要数万个类别。如此大小的向量空间对于大多数应用来说是不可行的，因为它需要一个庞大的词嵌入矩阵。例如，如果你有 10,000 个类别和 1,000,000 个实体需要编码，那么你将需要一个 10,000 × 1,000,000 的嵌入矩阵，这使得对它的操作非常耗时。减少嵌入矩阵大小的显而易见的方法是减少向量空间中的类别数量。

现实世界中实现的词向量空间并不是通过坐标来表示所有类别，而是通过向量之间的距离来量化和分类语义相似性。各个维度通常没有固有的含义。相反，它们表示向量空间中的位置，向量之间的距离表示相应单词含义的相似度。

以下是从*fastText*词向量库中提取的 300 维词向量空间的一部分，你可以在* [`fasttext.cc/docs/en/english-vectors.html`](https://fasttext.cc/docs/en/english-vectors.html) *下载该库：*

compete   -0.0535 -0.0207 0.0574 0.0562 ... -0.0389 -0.0389

equations -0.0337 0.2013 -0.1587 0.1499 ...  0.1504 0.1151

Upper     -0.1132 -0.0927 0.1991 -0.0302 ... -0.1209 0.2132

mentor     0.0397 0.1639 0.1005 -0.1420 ... -0.2076 -0.0238

reviewer  -0.0424 -0.0304 -0.0031 0.0874 ... 0.1403 -0.0258

每一行包含一个作为实数向量表示的词，位于多维空间中。从图形上看，我们可以用二维或三维投影来表示一个 300 维的向量空间。为了准备这种投影，我们可以分别使用向量的前两或前三个主坐标。图 5-1 显示了来自 300 维向量空间的向量在二维投影中的表现。

![image](img/fig5-1.jpg)

*图 5-1：多维向量空间二维投影的一个片段*

你可能会注意到的一个有趣细节是，连接希腊与雅典和意大利与罗马的线条几乎是平行的。它们的长度看起来也很相似。在实际应用中，这意味着如果你有上述四个向量中的三个，你可以计算出缺失的那个的近似位置，因为你知道应该如何移动向量以及移动的距离。

图中的向量表示了一个国家与首都之间的关系，但它们也可以表示其他类型的关系，比如男女关系、动词时态等。

#### ***相似度方法***

在 spaCy 中，每种容器对象都有一个*相似度方法*，通过比较它们的词向量，允许你计算两个任意类型容器对象之间的语义相似度估算值。对于没有自己词向量的跨度和文档，spaCy 会对其包含的标记词向量取平均值以计算相似度。

**注意**

*spaCy 的小型模型（模型大小指示器为 %sm 的那些）不包括词向量。你仍然可以使用相似度方法来比较标记、跨度和文档，但结果的准确性较差。*

即使两个容器对象不同，你也可以计算它们的语义相似度。例如，你可以将一个 Token 对象与一个 Span 对象进行比较，将一个 Span 对象与一个 Doc 对象进行比较，等等。

以下示例计算了一个 Span 对象与一个 Doc 对象的相似度：

>>> doc=nlp('I want a green apple.')

>>> doc.similarity(doc[2:5])

0.7305813588233471

这段代码计算了句子“I want a green apple.”与从同一句子中提取的短语“a green apple”之间的语义相似度估算值。如你所见，计算出的相似度足够高，可以认为这两个对象的内容相似（相似度的范围从 0 到 1）。

不出所料，当你将一个对象与它自身进行比较时，similarity() 方法返回 1：

>>> doc.similarity(doc)

1.0

>>> doc[2:5].similarity(doc[2:5])

1.0

你还可以将一个 Doc 对象与另一个 Doc 对象的切片进行比较：

>>> doc2=nlp('I like red oranges.')

>>> doc2.similarity(doc[2:5])

0.28546574467463354

在这里，我们将存储在 doc2 中的句子“I like red oranges.”与从 doc 中提取的短语“a green apple”进行比较。在这种情况下，相似度并不高。是的，橙子和苹果都是水果（相似度方法识别了这一事实），但是动词“want”和“like”表达了不同的状态。

你也可以比较两个词项。在以下示例中，我们将 Token 对象“oranges”与包含单一词项“apple”的 Span 对象进行比较。

>>> token = doc2[3:4][0]

>>> token

oranges

>>> token.similarity(doc[4:5])

0.3707084280155993

首先，我们通过引用该跨度中的第一个元素，将包含单一词项“oranges”的 Span 对象显式转换为 Token 对象。然后，我们计算它与短语“apple”之间的相似度。

similarity() 方法可以识别属于相同或相似类别且经常出现在相关语境中的单词，对这些单词显示出较高的相似度。

#### ***选择语义相似度计算的关键词***

相似度方法将为你计算语义相似度，但为了使计算结果有用，你需要选择合适的关键词进行比较。为了理解为什么，考虑以下文本片段：

红杉是世界上最高的树木。它们在加利福尼亚的沿海森林中最为常见。

我们可能根据想要使用的类别集以多种方式对这段文本进行分类。例如，如果我们在寻找有关地球上最高植物的文本，“tallest trees”和“in the world”将是关键短语。将这些短语与搜索短语“highest plants”和“on the planet”进行比较，应该会显示出较高的语义相似度。我们可以通过使用 Doc 对象的 doc.noun_chunk 属性提取名词短语，然后通过相似度方法检查这些名词短语与搜索短语的相似度来做到这一点。

但如果我们在寻找关于世界各地的文本，那么“California”将是关键词。当然，我们无法预先知道文本中可能出现哪个地名：它可能是加利福尼亚，或者比如亚马逊。无论是什么，它应该在语义上与像“地理”这样的词相似，我们可以将其与文本中的其他名词（或者更好地，只与其命名实体）进行比较。如果我们能够确定存在较高的相似度，那么我们可以假设该命名实体代表的是一个地名。（我们还可以提取 Token 对象的 token.ent_type 属性来做到这一点，正如在第二章中所描述的。但是，我们无法使用命名实体识别来检查那些不是命名实体的单词的相似度，比如水果。）

### **安装词向量**

如果在你的 Python 环境中安装了 spaCy 模型，你可以立即开始使用词向量。你也可以安装第三方词向量包。不同的统计模型使用不同的词向量，因此你执行操作时的结果会根据所使用的模型略有不同。你可以尝试多个模型，以确定哪一个在你的特定应用中效果更好。

#### ***利用 spaCy 模型中提供的词向量***

词向量是许多 spaCy 模型的一部分。例如，en_vectors_web_lg 包含超过一百万个唯一的词向量，定义在 300 维向量空间中。有关特定模型的详细信息，请查看*[`github.com/explosion/spacy-models/releases/`](https://github.com/explosion/spacy-models/releases/)*。

通常，小型模型（名称以 sm 结尾）不包含词向量。相反，它们提供上下文敏感的*tensors*，这些仍然允许你使用相似性方法比较标记、跨度和文档——尽管牺牲了准确性。

要跟随本章中的示例，你可以使用任何 spaCy 模型，甚至是小型模型。但是，如果你安装更大的模型，你将获得更准确的结果。有关如何安装 spaCy 模型的详细信息，请参阅“安装 spaCy 统计模型”的第 16 页。请注意，你的环境中可能安装了多个模型。

#### ***使用第三方词向量***

你还可以使用第三方的词向量包与 spaCy 一起使用。你可以检查第三方是否比 spaCy 模型中提供的本地词向量更适合你的应用。例如，你可以使用包含英语词向量的 fastText 预训练模型，这些词向量可以从*[`fasttext.cc/docs/en/english-vectors.html`](https://fasttext.cc/docs/en/english-vectors.html)*下载。包的名称将指示包的大小、词向量的维度以及用于训练词向量的数据类型。例如，*wiki-news-300d-1M.vec.zip*表示它包含一百万个 300 维的词向量，这些词向量是基于维基百科和*statmt.org*新闻数据集进行训练的。

下载包后，解压缩它，然后从包中的向量创建一个新的模型，可以与 spaCy 一起使用。为此，请导航到保存包的文件夹，然后使用 init-model 命令行工具，如下所示：

$ python -m spacy init-model en /tmp/en_vectors_wiki_lg --vectors-loc wiki-news-300d-1M.vec

该命令将从*wiki-news-300d-1M.vec*文件中提取的向量转换为 spaCy 的格式，并为它们创建新的模型目录*/tmp/en_vectors_wiki_lg*。如果一切顺利，你将看到以下信息：

从 wiki-news-300d-1M.vec 读取向量

打开位置

999994it [02:05, 7968.84it/s]

正在创建模型...

0it [00:00, ?it/s]

成功编译词汇

999731 条条目，999994 个向量

一旦你创建了模型，你就可以像常规的 spaCy 模型一样加载它：

nlp = spacy.load('/tmp/en_vectors_wiki_lg')

然后你可以像平常一样创建一个 Doc 对象：

doc = nlp(u'Hi there!')

与常规的 spaCy 模型不同，转换为 spaCy 使用的第三方模型可能不支持对 doc 对象中包含的文本进行某些 spaCy 操作。例如，如果你尝试使用 doc.sents 将一个 doc 分解成句子，你会遇到以下错误：ValueError: [E030] 句子边界未设置...

### **比较 spaCy 对象**

让我们使用词向量来计算容器对象的相似性，这是我们使用词向量最常见的任务。在本章的其余部分，我们将探索一些你可能想要确定语言单元语义相似性的场景。

#### ***使用语义相似性进行分类任务***

确定两个对象的句法相似性可以帮助你将文本分类，或者挑选出相关的文本。例如，假设你正在整理网站上发布的用户评论，找出所有与“水果”相关的评论。假设你有以下几个需要评估的句子：

我想在本周末买这本漂亮的书。

柑橘类的销售在过去一年有所增加。

你对这种树了解多少？

你可以很容易地识别出只有第二个句子与水果直接相关，因为它包含了单词“柑橘”。但要通过编程挑选出这个句子，你必须将“水果”这个词的词向量与样本文本中的词向量进行比较。

让我们从最简单但最不成功的方式开始做这个任务：将“水果”与每个句子进行比较。如前所述，spaCy 通过比较两个容器对象的对应词向量来确定它们的相似性。为了将单个词语与整个句子进行比较，spaCy 会对句子的词向量求平均，从而生成一个全新的向量。以下脚本将每个前面的句子样本与词“水果”进行比较：

import spacy

nlp = spacy.load('en')

➊ token = nlp(u'fruits')[0]

➋ doc = nlp(u'我想在本周末买这本漂亮的书。柑橘类的销售在过去一年有所增加。')

柑橘类的销售在过去一年有所增加。你对这种类型的树了解多少

的树？')

➌ for sent in doc.sents:

print(sent.text)

➍ print('与', token.text, '的相似度是', token.similarity(sent),'\n')

我们首先为单词“水果”创建一个 Token 对象 ➊。然后，我们将管道应用于我们正在分类的句子，创建一个单一的 Doc 对象来保存它们 ➋。我们将文档分解成句子 ➌，然后打印每个句子及其与词“水果”的语义相似度，我们通过使用 Token 对象的相似性方法来获取这一相似度 ➍。

输出应该是这样的（尽管实际的数字将取决于你使用的模型）：

我想在本周末买这本漂亮的书。

与水果的相似度是 0.06307832979619851

柑橘的销量在过去一年中有所增加。

与水果的相似度是 0.2712141843864381

你对这种类型的树了解多少？

与水果的相似度是 0.24646341651210604

“水果”这个词与第一句话的相似度非常小，表明这句话与水果没有关系。第二句话——包含“柑橘”这个词的句子——与“水果”最为相关，这意味着脚本正确地识别出了相关句子。

但是请注意，脚本也将第三句话识别为与水果相关，可能是因为它包含了“树”这个词，而水果通常长在树上。如果认为相似度测量算法“知道”橙子和柑橘是水果，那就太天真了。它所知道的仅仅是这些词（“橙子”和“柑橘”）通常与“水果”共享相同的上下文，因此它们在向量空间中被放得很接近。但“树”这个词也经常出现在与“水果”相关的上下文中。例如，“果树”这个词组并不少见。基于这个原因，计算得出的“水果”（或其词元“果”）与“树”的相似度值与“柑橘”和“水果”的相似度结果接近。

这种分类文本的方法还有另一个问题。实际上，当然，你有时可能需要处理比本节中使用的示例文本大得多的文本。如果你正在计算的文本非常大，那么最重要的词汇可能对句法相似度值几乎没有影响。

为了从相似度方法中获得更准确的结果，我们需要对文本进行一些准备工作。让我们看看如何改进脚本。

#### ***提取名词作为预处理步骤***

执行分类的更好方法是提取最重要的词汇，只比较这些词。以这种方式准备文本进行处理叫做*预处理*，它可以帮助提高你的自然语言处理操作的成功率。例如，你可以尝试不比较整个对象的词向量，而是比较某些词性（如名词）的词向量。在大多数情况下，你会集中注意力在名词上——无论它们作为主语、直接宾语还是间接宾语——来识别它们所传达的意义。例如，在句子“几乎所有野生狮子生活在非洲”中，你可能会专注于“狮子”、“非洲”或“狮子在非洲”这些词。类似地，在关于水果的句子中，我们集中精力挑选出名词“柑橘”。在其他情况下，你可能需要其他词汇，如动词，来判断一篇文章的主题是什么。假设你经营着一个农产品业务，必须对来自种植、加工和销售农产品的供应商的报价进行分类。你经常会看到像“我们种植蔬菜”或“我们将西红柿进行加工”这样的句子。在这个例子中，动词与前面例子中的名词一样重要。

我们来修改第 70 页的脚本。我们不再将“fruits”与整个句子进行比较，而是仅与句子中的名词进行比较：

import spacy

nlp = spacy.load('en')

➊ token = nlp(u'fruits')[0]

doc = nlp(u'I want to buy this beautiful book at the end of the week. Sales of

柑橘类水果的销量在过去一年有所增加。你对这种类型了解多少？

的树？')

similarity = {}

➋ for i, sent in enumerate(doc.sents):

➌ noun_span_list = [sent[j].text for j in range(len(sent)) if sent[j].pos_

== 'NOUN']

➍ noun_span_str = ' '.join(noun_span_list)

➎ noun_span_doc = nlp(noun_span_str)

➏ similarity.update({i:token.similarity(noun_span_doc)})

print(similarity)

我们首先定义了“fruits”这个标记，然后用它进行一系列比较 ➊。通过遍历每个句子中的标记 ➋，我们提取名词并将它们存储在一个 Python 列表中 ➌。接着，我们将列表中的名词合并成一个普通字符串 ➍，然后将该字符串转换为一个 Doc 对象 ➎。然后我们将这个 Doc 与标记“fruits”进行比较，以确定它们的语义相似度。我们将每个标记的句法相似度值存储在一个 Python 字典中 ➏，最后打印出来。

脚本的输出应类似如下：

{0: 0.17012682516221458, 1: 0.5063824302533686, 2: 0.6277196645922878}

如果您将这些数字与之前脚本的结果进行比较，您会注意到，这次每个句子与“fruits”一词的相似度都更高了。但总体结果相似：第一句的相似度最低，而另外两句的相似度则明显更高。

#### ***试试看***

在前面的例子中，您仅将“fruits”与名词进行比较，通过只考虑最重要的单词（在这种情况下是名词），您提高了相似度计算的结果。您将“fruits”与每个句子提取出来的所有名词进行比较。进一步来说，您可以查看这些名词与“fruits”之间的语义关系，找出哪个名词与“fruits”最为相似。这对于评估文档与“fruits”一词的整体相似度是非常有用的。为此，您需要修改之前的脚本，以便它能确定“fruits”与每个句子中的名词之间的相似度，并找到与之最相似的名词。

#### ***提取和比较命名实体***

在某些情况下，您可能不想从比较的文本中提取每一个名词，而是只提取某种特定类型的名词，比如命名实体。假设您正在比较以下文本：

“谷歌搜索，通常简称为谷歌，是如今最常用的搜索引擎。它每天处理大量的搜索。”

“Microsoft Windows 是一系列由 Microsoft 开发和销售的专有操作系统。该公司还生产其他广泛的桌面和服务器软件。”

“Titicaca 是安第斯山脉中的一个大而深的湖泊。它被认为是世界上最高的可通航湖泊。”

理想情况下，您的脚本应识别出前两篇文本讨论的是大型科技公司，而第三篇文本则不是。但比较该文本中的所有名词并没有什么帮助，因为许多词汇，如第一句中的“number”，与上下文无关。句子之间的差异体现在以下词汇：“Google”，“Search”，“Microsoft”，“Windows”，“Titicaca”和“Andes”。spaCy 将这些词都识别为命名实体，这使得从文本中提取它们变得轻松，如以下脚本所示：

导入 spacy

nlp = spacy.load('en')

#第一个示例文本

doc1 = nlp(u'Google Search, 通常简称为 Google，是最常用的搜索引擎。')

当前最常用的搜索引擎。每天处理大量的搜索请求。')

#第二个示例文本

doc2 = nlp(u'Microsoft Windows 是一系列由 Microsoft 开发和销售的专有操作系统')

由 Microsoft 开发和销售。该公司还生产一系列广泛的

其他桌面和服务器软件。')

#第三个示例文本

doc3 = nlp(u"Titicaca 是安第斯山脉中的一个大而深的湖泊。它被认为是世界上最高的可通航湖泊。")

被认为是世界上最高的可通航湖泊。”

➊ docs = [doc1, doc2, doc3]

➋ spans = {}

➌ for j, doc in enumerate(docs):

➍ named_entity_span = [doc[i].text for i in range(len(doc)) if

doc[i].ent_type != 0]

➎ print(named_entity_span)

➏ named_entity_span = ' '.join(named_entity_span)

➐ named_entity_span = nlp(named_entity_span)

➑ spans.update({j:named_entity_span})

我们将 Docs 与示例文本分组到一个列表中，以便可以在循环中迭代 ➊。我们定义一个 Python 字典来存储每个文本的关键字 ➋。在一个遍历 Docs 的循环中 ➌，我们为每个文本提取这些关键字，单独列出仅标记为命名实体的单词 ➍。然后，我们打印出该列表，以查看它包含什么内容 ➎。接下来，我们将此列表转换为普通字符串 ➏，然后应用管道，将其转换为 Doc 对象 ➐。然后，我们将 Doc 追加到之前定义的 spans 字典 ➑。

脚本应生成以下输出：

['Google', 'Search', 'Google']

['Microsoft', 'Windows', 'Microsoft']

['Titicaca', 'Andes']

现在我们可以看到每个文本中我们将比较其向量的单词。

接下来，我们调用这些 spans 的 similarity()方法并打印结果：

print('doc1 与 doc2 相似度：', spans[0].similarity(spans[1]))

print('doc1 与 doc3 相似度：', spans[0].similarity(spans[2]))

print('doc2 与 doc3 相似度：', spans[1].similarity(spans[2]))

这次的输出应如下所示：

doc1 与 doc2 相似度：0.7864886939527678

doc1 与 doc3 相似度：0.6797676349647936

doc2 与 doc3 相似度：0.6621659567003596

这些数据表明，第一篇和第二篇文本之间的相似性最高，它们都涉及美国 IT 公司。词向量是如何“知道”这一事实的呢？它们可能知道，因为“Google”和“Microsoft”这两个词在训练文本语料库中的相同文本中出现得更频繁，而不是和“湖泊”（Titicaca）和“安第斯山脉”（Andes）这些词一起出现。

### **总结**

在本章中，你使用了词向量，它们是表示单词意义的实数向量。这些表示方式让你能够利用数学来确定语言单位的语义相似性，这是一个有用的任务，用于文本分类。

但是当你试图在没有对文本进行任何预处理的情况下确定两篇文本的相似性时，数学方法可能效果不佳。通过应用预处理，你可以将文本简化为最重要的单词，这些单词有助于了解文本的主题。在特别大的文本中，你可能会挑选出其中的命名实体，因为它们最可能最好地描述文本的类别。

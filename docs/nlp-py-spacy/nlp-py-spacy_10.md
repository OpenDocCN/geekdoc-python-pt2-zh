## **10

**训练模型**

![Image](img/comm1.jpg)

如你在第一章中所学，spaCy 包含经过训练的统计神经网络模型，用于执行命名实体识别、词性标注、句法依存解析和语义相似性预测。但你并不限于仅使用预训练的现成模型。你还可以使用自己的训练示例训练模型，调整其管道组件，以满足你的应用程序需求。

本章介绍如何训练 spaCy 的命名实体识别器和依存解析器，这些是你最常需要自定义的管道组件，以使你使用的模型适应特定的用例。原因是某些领域通常需要一组特定的实体，并且有时需要特定的依存解析方式。你将学习如何使用新的示例训练现有模型，或从头开始训练一个空模型。你还将保存一个自定义的管道组件到磁盘，以便以后在另一个脚本或模型中加载它。

### **训练模型的管道组件**

你很少需要从头开始训练模型，以满足应用程序的特定要求。相反，你可以使用现有模型，并仅更新你需要更改的管道组件。这个过程通常包括两步：准备*训练示例*（包含注释的句子集，模型可以从中学习），然后将管道组件暴露给训练示例，如图 10-1 所示。

![image](img/fig10-1.jpg)

*图 10-1：管道组件的训练过程*

为了准备训练示例，你需要将原始文本数据转换为包含句子和每个标记注释的训练示例。在训练过程中，spaCy 使用训练示例来修正模型的权重：目标是最小化模型预测的误差（称为*损失*）。简单来说，算法计算标记与其注释之间的关系，以确定一个标记是否应该被分配该注释的可能性。

现实中的实现可能需要数百甚至数千个训练示例，才能高效地教授模型的某个组件。在开始训练组件之前，你需要暂时禁用模型的所有其他管道组件，以保护它们免受不必要的修改。

### **训练实体识别器**

假设你正在为一家出租车公司开发聊天机器人应用程序。该应用程序必须能够正确识别所有指代城市及其周边地区的名称。为了实现这一目标，你可能需要使用自己的示例更新模型的命名实体识别系统，使其能够识别比如“Solnce”这个词，表示城市中的一个社区，作为一个地理政治实体。以下部分将描述如何完成这一任务。

#### ***决定是否需要训练实体识别器***

让我们首先看一下默认英文模型（通常是 en_core_web_sm 模型）中的现有命名实体识别器如何识别感兴趣的命名实体。你可能不需要更新命名实体识别器。对于这项任务，你可以使用一些常见的出租车预订句子，例如：

你能从 Solnce 接我吗？

要查看识别器如何在句子中分类“Solnce”，可以使用以下脚本打印句子的命名实体：

import spacy

nlp = spacy.load('en')

doc = nlp(u'你能从 Solnce 接我吗？')

for ent in doc.ents:

print(ent.text, ent.label_)

在这个示例中，“Solnce”是唯一的命名实体，因此脚本会生成以下单行输出：

Solnce LOC

注意，这个实体的输出可能会根据你使用的模型和句子有所不同。要获取 LOC 实体标签的描述，你可以使用 spacy.explain()函数：

>>> print(spacy.explain('LOC'))

'非 GPE 地点，山脉，水体'

结果是，命名实体识别器将“Solnce”分类为一个非 GPE 地点，这与预期的结果不符。为了使识别器将“Solnce”分类为 GPE 类型的实体，你需要更新识别器，具体步骤将在以下章节中讨论。

**注意**

*为了简化起见，我们在这个示例中使用了单一名称的实体。但你可以创建更多的区域名称，以训练识别器。*

与其更新现有的识别器，你也可以用一个自定义的识别器替代它。然而，在这种情况下，你将需要更多的训练示例，以保持与 GPE 实体无关的功能，尽管这些功能可能仍然需要。

#### ***创建训练示例***

一旦你知道需要训练实体识别器以满足应用需求，下一步就是创建一组适当的训练示例。为此，你需要一些相关的文本。

最好的数据源，通常是你之前收集的真实客户输入。选择包含你需要用于训练的命名实体的句子。通常，你会将客户输入以纯文本形式记录在文件中。例如，出租车应用的客户输入日志文件可能包含以下句子：

你能派出租车到 Solnce 吗？

从 Solnce 到机场有固定票价吗？

现在等出租车要多久？

要从这些句子中创建训练示例，你需要将它们转换为一个元组列表，其中每个训练示例表示一个单独的元组，如下所示：

train_exams = [

➊ ('你能派出租车到 Solnce 吗？', {

➋ '实体': [(25, 32, 'GPE')]

}),

('从 Solnce 到机场有固定票价吗？', {

'实体': [(41, 48, 'GPE')]

}),

('现在等出租车要多久？', {

'实体': []

})

]

每个元组由两个值组成：表示语句的字符串 ➊ 和一个字典，用于标注在该语句中找到的实体。实体的标注包括其在语句中的起始和结束字符位置，以及要分配给实体的标签 ➋。

#### ***自动化示例创建过程***

正如你无疑已经意识到的那样，手动创建一组训练样本可能既费时又容易出错，特别是当你需要处理成百上千个语句时。你可以通过使用以下脚本来自动化这一繁琐的任务，该脚本可以迅速从提交的文本中创建一组训练样本。

import spacy

nlp = spacy.load('en')

➊ doc = nlp(u'你能给 Solnce 送一辆出租车吗？我需要去 Google。Could

你一个小时后发送出租车吗？')

➋ #f = open("test.txt","rb")

#contents =f.read()

#doc = nlp(contents.decode('utf8'))

➌ train_exams = []

➍ districts = ['Solnce', 'Greenwal', 'Downtown']

for sent in doc.sents:

entities = []

for token in sent:

如果 token.ent_type != 0:

➎ start = token.idx - sent.start_char

如果 token.text 在 districts 中：

entity = (start, start + len(token), 'GPE')

else:

entity = (start, start + len(token), token.ent_type_)

entities.append(entity)

tpl = (sent.text, {'entities': entities})

➏ train_exams.append(tpl)

为了提高可读性，我们像往常一样选择一些语句进行处理：通过在脚本中硬编码它们 ➊。但是注释掉的代码行展示了我们如何从文件中获取语句 ➋。

一旦我们获得了语句——无论是从文件中读取还是显式传入 doc——我们就可以开始从中生成训练样本列表。我们首先创建一个空列表 ➌。接下来，我们需要定义一个包含实体名称的列表，以便我们可以让模型以与当前不同的方式识别它们 ➍。（在这个示例中，这是一个包含区域名称的列表。）

记住，真实的客户输入可能包含识别器已经正确识别的实体（比如 Google 或 London），因此我们不应该改变识别器对它们的分类行为。我们为这些实体创建训练样本，并处理所有在生成训练样本时所用语句中出现的实体，而不仅仅是新的实体。一个实际应用中的训练集必须包括大量不同类型实体的样本。根据应用的需求，训练集可能包含几百个样本。

我们遍历提交的语句，在每次迭代时创建一个空的实体列表。然后，为了填充这个列表，我们遍历语句中的标记，找到实体。对于每个找到的实体，我们确定它在语句中的起始字符索引 ➎。然后，我们通过将 len(token) 加到起始索引来计算结束索引。

此外，我们必须检查该实体是否在我们希望分配新标签的实体列表中。如果是，我们就给它分配 GPE 标签。否则，识别器将使用实体注释中的当前标签。之后，我们可以定义一个元组来表示训练示例，然后将其添加到训练集中➏。

脚本将生成的训练示例发送到 train_exams 列表，在脚本执行后该列表应如下所示：

>>> train_exams

[

➊ ('你能把出租车送到 Solnce 吗？', {'entities': [(25, 31, 'GPE')]}),

➋ ('我需要去 Google。', {'entities': [(17, 23, 'ORG')]}),

➌ ('你能把出租车送一个小时后吗？', {'entities': []})

]

为了简化起见，这里使用的训练集仅包含几个训练示例。请注意，只有第一个示例包含了需要让识别器熟悉的实体（在本示例中是地区列表）➊。这并不意味着第二个和第三个训练示例没有用处。第二个训练示例➋混入了另一种实体类型，这可以防止识别器“忘记”之前已经学过的内容。

第三个训练示例不包含任何实体➌。为了改善学习效果，我们不仅需要混入其他实体类型的示例，还需要加入不包含任何实体的示例。下一节“训练过程”将讨论训练过程的详细内容。

#### ***禁用其他管道组件***

spaCy 文档建议在开始训练某个管道组件之前，禁用所有其他管道组件，这样你只会修改你想要更新的组件。以下代码禁用了除了命名实体识别器以外的所有管道组件。你需要将此代码附加到前一节介绍的脚本中，或在该脚本执行后在同一个 Python 会话中执行它（我们将在下一节讨论训练过程时附加这段代码）：

other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']

nlp.disable_pipes(*other_pipes)

现在你可以开始训练命名实体识别器，让它学会在训练示例中找到新的实体。

#### ***训练过程***

在训练过程中，你需要对训练示例进行洗牌并进行循环遍历，通过调整模型的权重，使其更加准确地反映标记与注释之间的关系。有关神经网络模型的更详细解释，包括什么是权重，请参考第一章。

为了提高准确性，你可以在训练循环中应用几种技术。例如，以下代码展示了如何将训练示例按批次处理。这种技术通过不同的表现形式向模型展示训练示例，以避免训练语料中出现的泛化问题。

将以下代码添加到在《创建训练示例》中首次介绍并在上一节中修改的脚本中，参考第 144 页。

import random

from spacy.util import minibatch, compounding

➊ optimizer = nlp.entity.create_optimizer()

for i in range(25):

➋ random.shuffle(train_exams)

max_batch_size = 3

➌ batch_size = compounding(2.0, max_batch_size, 1.001)

➍ batches = minibatch(train_exams, size=batch_size)

for batch in batches:

texts, annotations = zip(*batch)

➎ nlp.update(texts, annotations, sgd=optimizer)

➏ ner = nlp.get_pipe('ner')

➐ ner.to_disk('/usr/to/ner')

在我们开始训练之前，我们需要创建一个*优化器* ➊——一个在训练过程中用来存储模型权重更新间的中间结果的函数。我们可以使用 nlp.begin_training()方法来创建优化器。但是这个方法会移除现有的实体类型。在这个示例中，因为我们正在更新一个已有的模型且不希望它“遗忘”现有的实体类型，我们使用 nlp.entity.create_optimizer()方法。这个方法为命名实体识别器创建一个优化器，并且不会丢失现有的实体类型。

在训练过程中，脚本将示例以循环的方式展示给模型，顺序是随机的，以避免来自示例顺序的任何泛化 ➋。脚本还会对训练示例进行批处理，spaCy 文档建议当训练示例的数量足够大时，这样做可能会提高训练过程的效果。为了在每一步中使批处理大小变化，我们使用 compounding()方法，它返回一个批处理大小的生成器。特别地，它生成一个无限的复合值序列：它从第一个参数指定的值开始，并通过将前一个值乘以第三个参数指定的复合速率来计算下一个值，而不超过第二个参数指定的最大值 ➌。然后我们使用 minibatch()方法对训练示例进行批处理。这样做会将批处理大小设置为前一行代码中调用 compounding()方法生成的迭代器 ➍。

接下来，我们遍历批次，在每次迭代时更新命名实体识别器模型。每个批次都需要通过调用 nlp.update() ➎来更新模型，这会为批次中的每个示例中的实体进行预测，然后检查提供的注释，看看预测是否正确。如果预测错误，训练过程会调整底层模型中的权重，以便下次能做出更准确的预测。

最后，我们需要将更新后的命名实体识别组件序列化到磁盘，以便稍后在另一个脚本（或另一个 Python 会话）中加载它。为此，我们首先必须从管道中获取该组件➏，然后使用其 to_disk()方法将其保存到磁盘➐。确保你在系统中创建了*/usr/to*目录。

#### ***评估更新后的识别器***

现在你可以测试更新后的识别器。如果你在 Python 会话中执行本章讨论的示例，关闭它，打开一个新的会话，然后输入以下代码，确保模型已经做出了正确的概括。（如果你已经根据前面章节讨论的代码构建了一个独立的脚本并运行它，你可以将以下代码作为一个独立的脚本运行，或者在 Python 会话中运行。）

import spacy

from spacy.pipeline import EntityRecognizer

➊ nlp = spacy.load('en', disable=['ner'])

➋ ner = EntityRecognizer(nlp.vocab)

➌ ner.from_disk('/usr/to/ner')

➍ nlp.add_pipe(ner, "custom_ner")

➎ print(nlp.meta['pipeline'])

➏ doc = nlp(u'你能在 Solnce 接我吗？')

for ent in doc.ents:

print(ent.text, ent.label_)

我们首先加载没有命名实体识别组件的管道组件➊。原因是训练现有模型的管道组件不会永久覆盖组件的原始行为。当我们加载模型时，默认会加载组成模型管道的组件的原始版本；因此，要使用更新版本，我们必须显式地从磁盘加载它。这允许我们拥有多个自定义版本的相同管道组件，并在需要时加载适当的版本。

我们通过两步创建这个新组件：首先从 EntityRecognizer 类构造一个新的管道实例➋，然后从磁盘加载数据，指定我们序列化识别器的目录➌。

接下来，我们将加载的命名实体识别组件添加到当前管道中，使用一个自定义名称（可选）➍。如果我们打印出当前可用的管道组件的名称➎，应该能看到该自定义名称与'tagger'和'parser'的名称一起列出。

唯一剩下的任务是测试加载的命名实体识别组件。确保使用一个与训练数据集中不同的句子➏。

结果，我们应该看到以下输出：

可用的管道组件：['tagger', 'parser', 'custom_ner']

Solnce GPE

更新后的命名实体识别组件现在可以正确识别自定义实体名称。

### **创建一个新的依赖解析器**

在接下来的章节中，你将学习如何创建一个适合特定任务的自定义依赖解析器。特别地，你将训练一个解析器，它揭示句子中的语义关系，而不是语法依赖。*语义关系*是指句子中单词和短语之间的意义关系。

#### ***自定义句法解析以理解用户输入***

为什么你需要语义关系呢？假设你的聊天机器人应用程序应该能够理解用户用简单英语表达的请求，并将其转换为 SQL 查询，然后传递给数据库。为了实现这一点，应用程序会执行句法分析，以提取意义，将输入拆分成多个部分，用于构建数据库查询。例如，假设你有以下句子需要解析：

找到一个无需经验的高薪工作。

从这个句子生成的 SQL 查询可能如下所示：

SELECT * FROM jobs WHERE salary = 'high' AND experience = 'no'

首先，让我们看看一个常规依赖解析器如何处理示例句子。为此，你可以使用以下脚本：

import spacy

nlp = spacy.load('en')

doc = nlp(u'Find a high paid job with no experience.')

print([(t.text, t.dep_, t.head.text) for t in doc])

脚本输出每个词元的文本、其依赖标签和句法头。如果你使用的是 en_core_web_sm 模型，结果应该如下所示：

[

('Find', 'ROOT', 'Find'),

('a', 'det', 'job'),

('high', 'amod', 'job'),

('paid', 'amod', 'job'),

('job', 'dobj', 'Find'),

('with', 'prep', 'Find'),

('no', 'det', 'experience'),

('experience', 'pobj', 'with'),

('.', 'punct', 'Find')

]

从图示上看，这种依赖分析如下所示：图 10-2。

![image](img/fig10-2.jpg)

*图 10-2：示例句子的依赖分析*

这种句法分析可能无法帮助你从句子生成所需的数据库查询。前面这一节中显示的 SQL 查询使用了 SELECT 语句来选择满足“高薪”和“无需经验”要求的职位。在这个逻辑中，单词“job”不仅应该与“high paid”连接，还应该与“no experience”连接，但句法分析并没有将“job”与“no experience”连接起来。

为了满足你的处理需求，你可能希望改变标注方式，简化生成数据库查询的任务。为此，你需要实现一个自定义解析器，该解析器显示语义关系而不是句法依赖关系。在这种情况下，这意味着你希望在“job”和“experience”之间建立一条弧线。以下章节将描述如何实现这一点。

#### ***决定使用的语义关系类型***

首先，你需要选择一组关系类型用于标注。spaCy 文档中包含了一个自定义消息解析器的示例 (*[`spacy.io/usage/training/#intent-parser`](https://spacy.io/usage/training/#intent-parser)*)，该解析器使用以下语义关系：ROOT、PLACE、ATTRIBUTE、QUALITY、TIME 和 LOCATION。例如，你可能会将 PLACE 分配给某个活动发生的地方，例如在“我需要一个位于柏林的酒店”中的“hotel”一词。在这个语境中，“Berlin”将是 LOCATION，帮助你区分地理区域和较小的环境。

为了符合此示例中使用的语义，你可能需要在列表中添加一个新的类型：ACTIVITY，您可以用它来标记样本句子中的“job”一词。（当然，你也可以仅使用原有的关系类型集合。毕竟，“job”通常与工作场所相关联，你可以使用类型 PLACE 来表示这个关系。）

#### ***创建训练示例***

如同训练管道组件的常规过程，你需要从准备训练示例开始。当训练一个解析器时，你需要每个标记的依赖标签和每个关系的头节点信息。在这个示例中，你只使用了几个训练示例，以保持简短和简单。当然，现实中的实现需要更多的示例来训练解析器组件。

TRAINING_DATA = [

('find a high paying job with no experience', {

'heads': [0, 4, 4, 4, 0, 7, 7, 4],

'deps': ['ROOT', '-', 'QUALITY', 'QUALITY', 'ACTIVITY', '-', 'QUALITY', 'ATTRIBUTE']

}),

('find good workout classes near home', {

'heads': [0, 4, 4, 4, 0, 6, 4],

'deps': ['ROOT', '-', 'QUALITY', 'QUALITY', 'ACTIVITY', 'QUALITY', 'ATTRIBUTE']

})

]

请注意，语法上相关的词可能不总是语义上相关的。在新的解析器中，要清楚地看到这一点，你可以进行以下测试，这会生成从 TRAINING_DATA 列表中的第一个训练示例中找到的样本句子的*句法*依赖的标头列表：

import spacy

nlp = spacy.load('en')

doc = nlp(u'find a high paying job with no experience')

heads = []

for token in doc:

heads.append(token.head.i)

print(heads)

假设你使用的是 en_core_web_sm 模型，这段代码应该会输出以下的标头索引：

[0, 4, 4, 4, 0, 4, 7, 5]

当你将这个列表与在 TRAINING_DATA 列表中为这个相同句子提供的标头进行比较时，你应该注意到一些不一致之处。例如，在训练示例中，“with”是“experience”的子节点，而根据标准语法规则，“with”应该是“job”的子节点。若我们稍微修改句子，这种偏差就更能解释清楚：

找到一份高薪的工作，哪怕没有任何经验

从语义上讲，“without”可以视为“experience”的修饰词，因为“without”改变了“experience”的意义。修饰词通常依赖于它所修饰的词。因此，在考虑到语义的情况下，将“without”视为“without/experience”对中的子节点是相当合理的。

#### ***训练解析器***

以下脚本演示了如何从零开始训练一个解析器，使用的是空白模型。在这个例子中，创建一个全新的解析器比更新现有的解析器更为合理：原因在于，试图训练一个现有的句法依赖解析器同时识别语义关系将非常困难，因为这两种关系往往会发生冲突。但这并不意味着你不能将自定义解析器与现有模型一起使用。你可以将它加载到任何模型中，以替代原始的句法依赖解析器。

为了训练解析器，以下脚本使用了前面部分定义的 TRAINING_DATA 列表中的训练示例。确保将 TRAINING_DATA 列表添加到后续代码之前：

import spacy

➊ nlp = spacy.blank('en')

➋ parser = nlp.create_pipe('parser')

➌ nlp.add_pipe(parser, first=True)

➍ for text, annotations in TRAINING_DATA:

➎ for d in annotations.get('deps', []):

➏ parser.add_label(d)

➐ optimizer = nlp.begin_training()

import random

➑ for i in range(25):

➒ random.shuffle(TRAINING_DATA)

for text, annotations in TRAINING_DATA:

nlp.update([text], [annotations], sgd=optimizer)

➓ parser.to_disk('/home/oracle/to/parser')

我们首先创建一个空白模型 ➊。然后，我们创建一个空白解析器组件 ➋ 并将其添加到模型的管道 ➌ 中。

在这个例子中，我们从必须添加到代码中的 TRAINING_DATA 列表中推导出解析器要使用的标签集。我们在两个循环中实现这个操作。在外循环中，我们遍历训练示例，从每个示例中提取包含主语和依赖注释的元组 ➍。在内循环中，我们遍历注释的元组，从 deps 列表 ➎ 中提取每个标签，并将其添加到解析器 ➏ 中。

现在我们可以开始训练过程。首先，我们获取一个优化器 ➐，然后实现一个简单的训练循环 ➑，将训练示例随机打乱 ➒。接下来，我们遍历训练示例，在每次迭代时更新解析器模型。

最后，我们将自定义解析器序列化到磁盘，这样就可以在另一个脚本中加载并使用它 ➓。

#### ***测试自定义解析器***

你可以使用以下脚本将自定义解析器从磁盘加载到现有模型的管道中：

import spacy

from spacy.pipeline import DependencyParser

➊   nlp = spacy.load('en', disable=['parser'])

➋ parser = DependencyParser(nlp.vocab)

➌ parser.from_disk('/home/oracle/to/parser')

➍ nlp.add_pipe(parser, "custom_parser")

print(nlp.meta['pipeline'])

doc = nlp(u'find a high paid job with no degree')

➎ print([(w.text, w.dep_, w.head.text) for w in doc if w.dep_ != '-'])

注意，这个脚本与之前在“评估更新后的识别器”中显示的加载自定义命名实体识别器的脚本类似，见 第 148 页。我们加载一个常规模型，禁用其中某个组件——在此示例中是解析器 ➊。接下来，我们创建一个解析器 ➋，并加载之前序列化到磁盘的数据 ➌。为了使解析器可用，我们需要将其添加到模型的管道中 ➍。然后我们可以测试它 ➎。

该脚本应产生以下输出：

['tagger', 'ner', 'custom_parser']

[

('find', 'ROOT', 'find'),

('high', 'QUALITY', 'job'),

('paid', 'QUALITY', 'job'),

('job', 'ACTIVITY', 'find'),

('no', 'QUALITY', 'degree'),

('degree', 'ATTRIBUTE', 'job')

]

原始解析器组件已被自定义解析器替换为常规模型中的一部分，而其他管道组件保持不变。稍后，我们可以通过使用 spacy.load('en') 加载模型来重新加载原始组件。

#### ***尝试这个***

既然你已经训练了一个自定义解析器来揭示语义关系，你可以开始使用它。继续本节中的示例，编写一个脚本，从纯英文请求生成 SQL 语句。在该脚本中，检查每个请求的 ROOT 元素，以确定是否需要构造一个 SELECT 语句。然后，使用 ACTIVITY 元素引用将要执行该语句的数据库表。在语句的 WHERE 子句中使用 QUALITY 和 ATTRIBUTE 元素。

### **总结**

你可以从 spaCy 下载一组预训练的统计模型，立即使用。但这些模型可能并不总是适合你的需求。你可能想要改善现有模型中的某个管道组件，或者在空白模型中创建一个新的组件，以更好地满足你应用程序的需求。

在本章中，你学习了如何训练现有的命名实体识别组件，以识别默认未正确标注的额外实体。然后，你学习了如何训练一个自定义解析器组件，以预测与输入文本相关的树状结构类型，该结构展示的是语义关系而非句法依赖关系。

在这两种情况下，第一步（也许是最重要且最耗时的一步）是准备训练数据。一旦完成，你只需要再写几行代码，就能实现你的自定义组件的训练循环。
